{"2025-03-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2402.18668v2","updated":"2025-03-07T18:57:52Z","published":"2024-02-28T19:28:27Z","title":"Simple linear attention language models balance the recall-throughput\n  tradeoff","summary":"  Recent work has shown that attention-based language models excel at recall,\nthe ability to ground generations in tokens previously seen in context.\nHowever, the efficiency of attention-based models is bottle-necked during\ninference by the KV-cache's aggressive memory consumption. In this work, we\nexplore whether we can improve language model efficiency (e.g. by reducing\nmemory consumption) without compromising on recall. By applying experiments and\ntheory to a broad set of architectures, we identify a key tradeoff between a\nmodel's state size and recall ability. We show that efficient alternatives to\nattention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but\nstruggle at recall. We propose BASED a simple architecture combining linear and\nsliding window attention. By varying BASED window size and linear attention\nfeature dimension, we can dial the state size and traverse the pareto frontier\nof the recall-memory tradeoff curve, recovering the full quality of attention\non one end and the small state size of attention-alternatives on the other. We\ntrain language models up to 1.3b parameters and show that BASED matches the\nstrongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them\non real-world recall-intensive tasks by 6.22 accuracy points. Implementations\nof linear attention are often less efficient than optimized standard attention\nimplementations. To make BASED competitive, we develop IO-aware algorithms that\nenable 24x higher throughput on language generation than FlashAttention-2, when\ngenerating 1024 tokens using 1.3b parameter models. Code for this work is\nprovided at: https://github.com/HazyResearch/based.\n","authors":["Simran Arora","Sabri Eyuboglu","Michael Zhang","Aman Timalsina","Silas Alberti","Dylan Zinsley","James Zou","Atri Rudra","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2402.18668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00226v2","updated":"2025-03-07T18:48:54Z","published":"2024-05-31T23:05:04Z","title":"Entangled Relations: Leveraging NLI and Meta-analysis to Enhance\n  Biomedical Relation Extraction","summary":"  Recent research efforts have explored the potential of leveraging natural\nlanguage inference (NLI) techniques to enhance relation extraction (RE). In\nthis vein, we introduce MetaEntailRE, a novel adaptation method that harnesses\nNLI principles to enhance RE performance. Our approach follows past works by\nverbalizing relation classes into class-indicative hypotheses, aligning a\ntraditionally multi-class classification task to one of textual entailment. We\nintroduce three key enhancements: (1) Meta-class analysis which, instead of\nlabeling non-entailed premise-hypothesis pairs with the less informative\n\"neutral\" entailment label, provides additional context by analyzing\noverarching meta-relationships between classes; (2) Feasible hypothesis\nfiltering, which removes unlikely hypotheses from consideration based on domain\nknowledge derived from data; and (3) Group-based prediction selection, which\nfurther improves performance by selecting highly confident predictions.\nMetaEntailRE is conceptually simple and empirically powerful, yielding\nsignificant improvements over conventional relation extraction techniques and\nother NLI formulations. We observe surprisingly large F1 gains of 17.6 points\non BioRED and 13.4 points on ReTACRED compared to conventional methods,\nunderscoring the versatility of MetaEntailRE across both biomedical and general\ndomains.\n","authors":["William Hogan","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2406.00226v2.pdf","comment":"17 pages, 1 figure"},{"id":"http://arxiv.org/abs/2503.05683v1","updated":"2025-03-07T18:45:42Z","published":"2025-03-07T18:45:42Z","title":"Understanding the Limits of Lifelong Knowledge Editing in LLMs","summary":"  Keeping large language models factually up-to-date is crucial for deployment,\nyet costly retraining remains a challenge. Knowledge editing offers a promising\nalternative, but methods are only tested on small-scale or synthetic edit\nbenchmarks. In this work, we aim to bridge research into lifelong knowledge\nediting to real-world edits at practically relevant scale. We first introduce\nWikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to\nautomatically extend lifelong for future-proof benchmarking. In its first\ninstance, it includes over 500K question-answer pairs for knowledge editing\nalongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to\nstudy existing knowledge editing techniques' ability to incorporate large\nvolumes of real-world facts and contrast their capabilities to generic\nmodification techniques such as retrieval augmentation and continual finetuning\nto acquire a complete picture of the practical extent of current lifelong\nknowledge editing.\n","authors":["Lukas Thede","Karsten Roth","Matthias Bethge","Zeynep Akata","Tom Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.05683v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.10297v2","updated":"2025-03-07T18:31:55Z","published":"2025-02-14T16:59:05Z","title":"DeltaProduct: Increasing the Expressivity of DeltaNet Through Products\n  of Householders","summary":"  Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive\nalternatives to Transformers for sequence modeling, offering efficient training\nand linear-time inference. However, existing architectures face a fundamental\ntrade-off between expressivity and efficiency, dictated by the structure of\ntheir state-transition matrices. While diagonal matrices used in architectures\nlike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited\nexpressivity. To address this, recent architectures such as (Gated) DeltaNet\nand RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous\ntoken-channel mixing, which overcomes some expressivity limitations with only a\nslight decrease in training efficiency. Building on the interpretation of\nDeltaNet's recurrence as performing one step of online gradient descent per\ntoken on an associative recall loss, we introduce DeltaProduct, which instead\ntakes multiple ($n_h$) steps per token. This naturally leads to diagonal plus\nrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized\nHouseholder transformations, providing a tunable mechanism to balance\nexpressivity and efficiency and a stable recurrence. Through extensive\nexperiments, we demonstrate that DeltaProduct achieves superior state-tracking\nand language modeling capabilities while exhibiting significantly improved\nlength extrapolation compared to DeltaNet. Additionally, we also strengthen the\ntheoretical foundation of DeltaNet's expressivity by proving that it can solve\ndihedral group word problems in just two layers.\n","authors":["Julien Siems","Timur Carstensen","Arber Zela","Frank Hutter","Massimiliano Pontil","Riccardo Grazzi"],"pdf_url":"https://arxiv.org/pdf/2502.10297v2.pdf","comment":"Accepted at ICLR 2025 Workshop on Foundation Models in the Wild"},{"id":"http://arxiv.org/abs/2503.04625v2","updated":"2025-03-07T18:13:22Z","published":"2025-03-06T17:11:51Z","title":"START: Self-taught Reasoner with Tools","summary":"  Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\ndemonstrated remarkable capabilities in complex reasoning tasks through the\nutilization of long Chain-of-thought (CoT). However, these models often suffer\nfrom hallucinations and inefficiencies due to their reliance solely on internal\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\nenhances reasoning capabilities by leveraging external tools. Through code\nexecution, START is capable of performing complex computations, self-checking,\nexploring diverse methods, and self-debugging, thereby addressing the\nlimitations of LRMs. The core innovation of START lies in its self-learning\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\nhere is a good idea.'') during the inference process of a LRM effectively\nstimulates its ability to utilize external tools without the need for any\ndemonstration data. Hint-infer can also serve as a simple and effective\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\nmodifying the reasoning trajectories with tool invocation generated by a LRM\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\noutperforms the base QwQ-32B and achieves performance comparable to the\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\nmodel o1-Preview.\n","authors":["Chengpeng Li","Mingfeng Xue","Zhenru Zhang","Jiaxi Yang","Beichen Zhang","Xiang Wang","Bowen Yu","Binyuan Hui","Junyang Lin","Dayiheng Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04625v2.pdf","comment":"38 pages, 5 figures and 6 tables"},{"id":"http://arxiv.org/abs/2503.05641v1","updated":"2025-03-07T18:03:13Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v1.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic_moe.github.io/"},{"id":"http://arxiv.org/abs/2404.00242v4","updated":"2025-03-07T17:47:42Z","published":"2024-03-30T04:34:54Z","title":"DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured\n  LLM Inference","summary":"  Large language models (LLMs) are increasingly employed for complex tasks that\nprocess multiple generation calls in a tree structure with shared prefixes of\ntokens, including few-shot prompting, multi-step reasoning, speculative\ndecoding, etc. However, existing inference systems for tree-based applications\nare inefficient due to improper partitioning of queries and KV cache during\nattention calculation. This leads to two main issues: (1) a lack of memory\naccess (IO) reuse for KV cache of shared prefixes, and (2) poor load\nbalancing.As a result, there is redundant KV cache IO between GPU global memory\nand shared memory, along with low GPU utilization. To address these challenges,\nwe propose DeFT(Decoding with Flash Tree-Attention), a hardware-efficient\nattention algorithm with prefix-aware and load-balanced KV cache partitions.\nDeFT reduces the number of read/write operations of KV cache during attention\ncalculation through KV-Guided Grouping, a method that avoids repeatedly loading\nKV cache of shared prefixes in attention computation. Additionally, we propose\nFlattened Tree KV Splitting, a mechanism that ensures even distribution of the\nKV cache across partitions with little computation redundancy, enhancing GPU\nutilization during attention computations. By reducing 73-99% KV cache IO and\nnearly 100% IO for partial results during attention calculation, DeFT achieves\nup to 2.23/3.59x speedup in the end-to-end/attention latency across three\npractical tree-based workloads compared to state-of-the-art attention\nalgorithms. Our code is available at https://github.com/LINs-lab/DeFT.\n","authors":["Jinwei Yao","Kaiqi Chen","Kexun Zhang","Jiaxuan You","Binhang Yuan","Zeke Wang","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2404.00242v4.pdf","comment":"Update DeFT-v4, accepted by ICLR'25\n  (https://openreview.net/forum?id=2c7pfOqu9k). Our code is available at\n  https://github.com/LINs-lab/DeFT"},{"id":"http://arxiv.org/abs/2503.05620v1","updated":"2025-03-07T17:46:13Z","published":"2025-03-07T17:46:13Z","title":"Learning LLM Preference over Intra-Dialogue Pairs: A Framework for\n  Utterance-level Understandings","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities in\nhandling complex dialogue tasks without requiring use case-specific\nfine-tuning. However, analyzing live dialogues in real-time necessitates\nlow-latency processing systems, making it impractical to deploy models with\nbillions of parameters due to latency constraints. As a result, practitioners\noften prefer smaller models with millions of parameters, trained on\nhigh-quality, human-annotated datasets. Yet, curating such datasets is both\ntime-consuming and costly. Consequently, there is a growing need to combine the\nscalability of LLM-generated labels with the precision of human annotations,\nenabling fine-tuned smaller models to achieve both higher speed and accuracy\ncomparable to larger models. In this paper, we introduce a simple yet effective\nframework to address this challenge. Our approach is specifically designed for\nper-utterance classification problems, which encompass tasks such as intent\ndetection, dialogue state tracking, and more. To mitigate the impact of\nlabeling errors from LLMs -- the primary source of inaccuracies in student\nmodels -- we propose a noise-reduced preference learning loss. Experimental\nresults demonstrate that our method significantly improves accuracy across\nutterance-level dialogue tasks, including sentiment detection (over $2\\%$),\ndialogue act classification (over $1.5\\%$), etc.\n","authors":["Xuanqing Liu","Luyang Kong","Wei Niu","Afshin Khashei","Belinda Zeng","Steve Johnson","Jon Jay","Davor Golac","Matt Pope"],"pdf_url":"https://arxiv.org/pdf/2503.05620v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05613v1","updated":"2025-03-07T17:38:00Z","published":"2025-03-07T17:38:00Z","title":"A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of\n  Large Language Models","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.\n","authors":["Dong Shu","Xuansheng Wu","Haiyan Zhao","Daking Rai","Ziyu Yao","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2503.05613v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.09433v3","updated":"2025-03-07T17:33:50Z","published":"2023-04-19T06:00:26Z","title":"Language Models Enable Simple Systems for Generating Structured Views of\n  Heterogeneous Data Lakes","summary":"  A long standing goal of the data management community is to develop general,\nautomated systems that ingest semi-structured documents and output queryable\ntables without human effort or domain specific customization. Given the sheer\nvariety of potential documents, state-of-the art systems make simplifying\nassumptions and use domain specific training. In this work, we ask whether we\ncan maintain generality by using large language models (LLMs). LLMs, which are\npretrained on broad data, can perform diverse downstream tasks simply\nconditioned on natural language task descriptions.\n  We propose and evaluate EVAPORATE, a simple, prototype system powered by\nLLMs. We identify two fundamentally different strategies for implementing this\nsystem: prompt the LLM to directly extract values from documents or prompt the\nLLM to synthesize code that performs the extraction. Our evaluations show a\ncost-quality tradeoff between these two approaches. Code synthesis is cheap,\nbut far less accurate than directly processing each document with the LLM. To\nimprove quality while maintaining low cost, we propose an extended code\nsynthesis implementation, EVAPORATE-CODE+, which achieves better quality than\ndirect extraction. Our key insight is to generate many candidate functions and\nensemble their extractions using weak supervision. EVAPORATE-CODE+ not only\noutperforms the state-of-the art systems, but does so using a sublinear pass\nover the documents with the LLM. This equates to a 110x reduction in the number\nof tokens the LLM needs to process, averaged across 16 real-world evaluation\nsettings of 10k documents each.\n","authors":["Simran Arora","Brandon Yang","Sabri Eyuboglu","Avanika Narayan","Andrew Hojel","Immanuel Trummer","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2304.09433v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06826v2","updated":"2025-03-07T17:32:57Z","published":"2025-01-12T14:39:26Z","title":"Correcting Annotator Bias in Training Data: Population-Aligned Instance\n  Replication (PAIR)","summary":"  Models trained on crowdsourced labels may not reflect broader population\nviews, because those who work as annotators do not represent the population. We\npropose Population-Aligned Instance Replication (PAIR), a method to address\nbias caused by non-representative annotator pools. Using a simulation study of\noffensive language and hate speech, we create two types of annotators with\ndifferent labeling tendencies and generate datasets with varying proportions of\nthe types. We observe that models trained on unbalanced annotator pools show\npoor calibration compared to those trained on representative data. By\nduplicating labels from underrepresented annotator groups to match population\nproportions, PAIR reduces bias without collecting additional annotations. These\nresults suggest that statistical techniques from survey research can improve\nmodel performance. We conclude with practical recommendations for improving the\nrepresentativity of training data and model performance.\n","authors":["Stephanie Eckman","Bolei Ma","Christoph Kern","Rob Chew","Barbara Plank","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2501.06826v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05592v1","updated":"2025-03-07T17:14:44Z","published":"2025-03-07T17:14:44Z","title":"R1-Searcher: Incentivizing the Search Capability in LLMs via\n  Reinforcement Learning","summary":"  Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.\n","authors":["Huatong Song","Jinhao Jiang","Yingqian Min","Jie Chen","Zhipeng Chen","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.05592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05587v1","updated":"2025-03-07T17:11:34Z","published":"2025-03-07T17:11:34Z","title":"Quantifying the Robustness of Retrieval-Augmented Language Models\n  Against Spurious Features in Grounding Data","summary":"  Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.\n","authors":["Shiping Yang","Jie Wu","Wenbiao Ding","Ning Wu","Shining Liang","Ming Gong","Hengyuan Zhang","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08936v2","updated":"2025-03-07T17:09:02Z","published":"2024-09-13T15:55:15Z","title":"SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical\n  Records","summary":"  We present the SynSUM benchmark, a synthetic dataset linking unstructured\nclinical notes to structured background variables. The dataset consists of\n10,000 artificial patient records containing tabular variables (like symptoms,\ndiagnoses and underlying conditions) and related notes describing the fictional\npatient encounter in the domain of respiratory diseases. The tabular portion of\nthe data is generated through a Bayesian network, where both the causal\nstructure between the variables and the conditional probabilities are proposed\nby an expert based on domain knowledge. We then prompt a large language model\n(GPT-4o) to generate a clinical note related to this patient encounter,\ndescribing the patient symptoms and additional context. We conduct both an\nexpert evaluation study to assess the quality of the generated notes, as well\nas running some simple predictor models on both the tabular and text portions\nof the dataset, forming a baseline for further research. The SynSUM dataset is\nprimarily designed to facilitate research on clinical information extraction in\nthe presence of tabular background variables, which can be linked through\ndomain knowledge to concepts of interest to be extracted from the text - the\nsymptoms, in the case of SynSUM. Secondary uses include research on the\nautomation of clinical reasoning over both tabular data and text, causal effect\nestimation in the presence of tabular and/or textual confounders, and\nmulti-modal synthetic data generation.\n","authors":["Paloma Rabaey","Henri Arno","Stefan Heytens","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2409.08936v2.pdf","comment":"The dataset can be downloaded from https://github.com/prabaey/synsum.\n  Presented at the GenAI4Health workshop at AAAI 2025"},{"id":"http://arxiv.org/abs/2410.02355v3","updated":"2025-03-07T17:06:04Z","published":"2024-10-03T10:06:27Z","title":"AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models","summary":"  Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.4%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.\n","authors":["Junfeng Fang","Houcheng Jiang","Kun Wang","Yunshan Ma","Shi Jie","Xiang Wang","Xiangnan He","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.02355v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02068v2","updated":"2025-03-07T16:48:14Z","published":"2025-01-03T19:28:53Z","title":"The interplay between domain specialization and model size","summary":"  Scaling laws for language models have often focused on finding the optimal\nmodel size and token count for training from scratch. However, achieving this\noptimal balance requires significant compute resources due to the extensive\ndata demands when training models from randomly-initialized weights. Continued\npretraining offers a cost-effective alternative, leveraging the compute\ninvestment from pretrained models to incorporate new knowledge without\nrequiring extensive new data. Recent findings suggest that data quality\ninfluences constants in scaling laws, thereby altering the optimal\nparameter-token allocation ratio. Building on this insight, we investigate the\ninterplay between domain specialization and model size during continued\npretraining under compute-constrained scenarios. Our goal is to identify an\noptimal training regime for this scenario and detect patterns in this interplay\nthat can be generalized across different model sizes and domains. To compare\ngeneral and specialized training, we filtered a web-based dataset to extract\ndata from three domains: legal, medical, and accounting. We pretrained models\nwith 1.5B, 3B, 7B, and 14B parameters on both the unfiltered and filtered\ndatasets, then evaluated their performance on domain-specific exams. Results\nshow that as model size increases, specialized models outperform general models\nwhile requiring less training compute. Additionally, their growing compute\nefficiency leads to reduced forgetting of previously learned knowledge.\n","authors":["Roseval Malaquias Junior","Ramon Pires","Thales Sales Almeida","Kenzo Sakiyama","Roseli A. F. Romero","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2501.02068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05565v1","updated":"2025-03-07T16:45:33Z","published":"2025-03-07T16:45:33Z","title":"Evaluating open-source Large Language Models for automated fact-checking","summary":"  The increasing prevalence of online misinformation has heightened the demand\nfor automated fact-checking solutions. Large Language Models (LLMs) have\nemerged as potential tools for assisting in this task, but their effectiveness\nremains uncertain. This study evaluates the fact-checking capabilities of\nvarious open-source LLMs, focusing on their ability to assess claims with\ndifferent levels of contextual information. We conduct three key experiments:\n(1) evaluating whether LLMs can identify the semantic relationship between a\nclaim and a fact-checking article, (2) assessing models' accuracy in verifying\nclaims when given a related fact-checking article, and (3) testing LLMs'\nfact-checking abilities when leveraging data from external knowledge sources\nsuch as Google and Wikipedia. Our results indicate that LLMs perform well in\nidentifying claim-article connections and verifying fact-checked stories but\nstruggle with confirming factual news, where they are outperformed by\ntraditional fine-tuned models such as RoBERTa. Additionally, the introduction\nof external knowledge does not significantly enhance LLMs' performance, calling\nfor more tailored approaches. Our findings highlight both the potential and\nlimitations of LLMs in automated fact-checking, emphasizing the need for\nfurther refinements before they can reliably replace human fact-checkers.\n","authors":["Nicolo' Fontana","Francesco Corso","Enrico Zuccolotto","Francesco Pierri"],"pdf_url":"https://arxiv.org/pdf/2503.05565v1.pdf","comment":"Main: 10 pages, 13 figures. Supplementary Materials: 7 pages, 29\n  figures, 1 table ### This work has been submitted to the IEEE for possible\n  publication. ###"},{"id":"http://arxiv.org/abs/2406.17975v3","updated":"2025-03-07T16:30:07Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from measuring\nprivacy leakage to detecting copyright violations, has become a rapidly growing\narea of research. In the last few months, more than 10 new methods have been\nproposed to perform Membership Inference Attacks (MIAs) against LLMs. Contrary\nto traditional MIAs which rely on fixed-but randomized-records or models, these\nmethods are mostly trained and tested on datasets collected post-hoc. Sets of\nmembers and non-members, used to evaluate the MIA, are constructed using\ninformed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In\nthis work, we first extensively review the literature on MIAs against LLMs and\nshow that, while most work focuses on sequence-level MIAs evaluated in post-hoc\nsetups, a range of target models, motivations and units of interest are\nconsidered. We then quantify distribution shifts present in 6 datasets used in\nthe literature using a model-less bag of word classifier and show that all\ndatasets constructed post-hoc suffer from strong distribution shifts. These\nshifts invalidate the claims of LLMs memorizing strongly in real-world\nscenarios and, potentially, also the methodological contributions of the recent\npapers based on these datasets. Yet, all hope might not be lost. We introduce\nimportant considerations to properly evaluate MIAs against LLMs and discuss, in\nturn, potential ways forwards: randomized test splits, injections of randomized\n(unique) sequences, randomized fine-tuning, and several post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide MIA development and\nstudy LLM memorization. We conclude with an overview of recommended approaches\nto benchmark sequence-level and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v3.pdf","comment":"IEEE Conference on Secure and Trustworthy Machine Learning (SaTML\n  2025)"},{"id":"http://arxiv.org/abs/2503.05543v1","updated":"2025-03-07T16:15:00Z","published":"2025-03-07T16:15:00Z","title":"Pi-GPS: Enhancing Geometry Problem Solving by Unleashing the Power of\n  Diagrammatic Information","summary":"  Geometry problem solving has garnered increasing attention due to its\npotential applications in intelligent education field. Inspired by the\nobservation that text often introduces ambiguities that diagrams can clarify,\nthis paper presents Pi-GPS, a novel framework that unleashes the power of\ndiagrammatic information to resolve textual ambiguities, an aspect largely\noverlooked in prior research. Specifically, we design a micro module comprising\na rectifier and verifier: the rectifier employs MLLMs to disambiguate text\nbased on the diagrammatic context, while the verifier ensures the rectified\noutput adherence to geometric rules, mitigating model hallucinations.\nAdditionally, we explore the impact of LLMs in theorem predictor based on the\ndisambiguated formal language. Empirical results demonstrate that Pi-GPS\nsurpasses state-of-the-art models, achieving a nearly 10\\% improvement on\nGeometry3K over prior neural-symbolic approaches. We hope this work highlights\nthe significance of resolving textual ambiguity in multimodal mathematical\nreasoning, a crucial factor limiting performance.\n","authors":["Junbo Zhao","Ting Zhang","Jiayu Sun","Mi Tian","Hua Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19202v2","updated":"2025-03-07T16:11:10Z","published":"2025-02-26T15:09:28Z","title":"LiGT: Layout-infused Generative Transformer for Visual Question\n  Answering on Vietnamese Receipts","summary":"  Document Visual Question Answering (Document VQA) challenges multimodal\nsystems to holistically handle textual, layout, and visual modalities to\nprovide appropriate answers. Document VQA has gained popularity in recent years\ndue to the increasing amount of documents and the high demand for digitization.\nNonetheless, most of document VQA datasets are developed in high-resource\nlanguages such as English. In this paper, we present ReceiptVQA\n(\\textbf{Receipt} \\textbf{V}isual \\textbf{Q}uestion \\textbf{A}nswering), the\ninitial large-scale document VQA dataset in Vietnamese dedicated to receipts, a\ndocument kind with high commercial potentials. The dataset encompasses\n\\textbf{9,000+} receipt images and \\textbf{60,000+} manually annotated\nquestion-answer pairs. In addition to our study, we introduce LiGT\n(\\textbf{L}ayout-\\textbf{i}nfused \\textbf{G}enerative \\textbf{T}ransformer), a\nlayout-aware encoder-decoder architecture designed to leverage embedding layers\nof language models to operate layout embeddings, minimizing the use of\nadditional neural modules. Experiments on ReceiptVQA show that our architecture\nyielded promising performance, achieving competitive results compared with\noutstanding baselines. Furthermore, throughout analyzing experimental results,\nwe found evident patterns that employing encoder-only model architectures has\nconsiderable disadvantages in comparison to architectures that can generate\nanswers. We also observed that it is necessary to combine multiple modalities\nto tackle our dataset, despite the critical role of semantic understanding from\nlanguage models. We hope that our work will encourage and facilitate future\ndevelopment in Vietnamese document VQA, contributing to a diverse multimodal\nresearch community in the Vietnamese language.\n","authors":["Thanh-Phong Le","Trung Le Chi Phan","Nghia Hieu Nguyen","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2502.19202v2.pdf","comment":"Accepted at IJDAR"},{"id":"http://arxiv.org/abs/2503.05516v1","updated":"2025-03-07T15:35:37Z","published":"2025-03-07T15:35:37Z","title":"Cognitive Bias Detection Using Advanced Prompt Engineering","summary":"  Cognitive biases, systematic deviations from rationality in judgment, pose\nsignificant challenges in generating objective content. This paper introduces a\nnovel approach for real-time cognitive bias detection in user-generated text\nusing large language models (LLMs) and advanced prompt engineering techniques.\nThe proposed system analyzes textual data to identify common cognitive biases\nsuch as confirmation bias, circular reasoning, and hidden assumption. By\ndesigning tailored prompts, the system effectively leverages LLMs' capabilities\nto both recognize and mitigate these biases, improving the quality of\nhuman-generated content (e.g., news, media, reports). Experimental results\ndemonstrate the high accuracy of our approach in identifying cognitive biases,\noffering a valuable tool for enhancing content objectivity and reducing the\nrisks of biased decision-making.\n","authors":["Frederic Lemieux","Aisha Behr","Clara Kellermann-Bryant","Zaki Mohammed"],"pdf_url":"https://arxiv.org/pdf/2503.05516v1.pdf","comment":"17 pages. 6 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2406.09760v2","updated":"2025-03-07T15:26:03Z","published":"2024-06-14T06:57:18Z","title":"Bootstrapping Language Models with DPO Implicit Rewards","summary":"  Human alignment in large language models (LLMs) is an active area of\nresearch. A recent groundbreaking work, direct preference optimization (DPO),\nhas greatly simplified the process from past work in reinforcement learning\nfrom human feedback (RLHF) by bypassing the reward learning stage in RLHF. DPO,\nafter training, provides an implicit reward model. In this work, we make a\nnovel observation that this implicit reward model can by itself be used in a\nbootstrapping fashion to further align the LLM. Our approach is to use the\nrewards from a current LLM to construct a preference dataset, which is then\nused in subsequent DPO rounds. We incorporate two refinements to further\nimprove our approach: 1) length-regularized reward shaping to make the\npreference dataset length-unbiased; 2) experience replay to enhance the quality\nof the preference dataset. Our approach, named self-alignment with DPO ImpliCit\nrEwards (DICE), shows great improvements in alignment. It achieves an increase\nof more than 8$\\\\%$ in lengthcontrolled win rate on AlpacaEval 2 for all the\ndifferent base models that we tried, without relying on external feedback. Our\ncode is available at https://github.com/sail-sg/dice.\n","authors":["Changyu Chen","Zichen Liu","Chao Du","Tianyu Pang","Qian Liu","Arunesh Sinha","Pradeep Varakantham","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2406.09760v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05505v1","updated":"2025-03-07T15:22:10Z","published":"2025-03-07T15:22:10Z","title":"Statistical Guarantees of Correctness Coverage for Medical\n  Multiple-Choice Question Answering","summary":"  Large language models (LLMs) are increasingly deployed in real-world\nquestion-answering (QA) applications. However, LLMs have been proven to\ngenerate hallucinations and nonfactual information, undermining their\ntrustworthiness in high-stakes medical tasks. Conformal prediction (CP) is\nwell-known to be model-agnostic and distribution-free, which creates\nstatistically rigorous prediction sets in classification tasks. In this work,\nwe for the first time adapt the CP framework to medical multiple-choice\nquestion-answering (MCQA) tasks, by correlating the nonconformity score with\nthe frequency score of correct options grounded in self-consistency theory,\nassuming no access to internal model information. Considering that the adapted\nCP framework can only control the (mis)coverage rate, we employ a risk control\nframework, which can manage task-specific metrics by devising a monotonically\ndecreasing loss function. We evaluate our framework on 3 popular medical MCQA\ndatasets utilizing 4 ``off-the-shelf'' LLMs. Empirical results demonstrate that\nwe achieve user-specified average (or marginal) error rates on the test set.\nFurthermore, we observe that the average prediction set size (APSS) on the test\nset decreases as the risk level increases, which concludes a promising\nevaluation metric for the uncertainty of LLMs.\n","authors":["Yusong Ke"],"pdf_url":"https://arxiv.org/pdf/2503.05505v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.08080v2","updated":"2025-03-07T15:17:43Z","published":"2025-02-12T02:54:12Z","title":"NLI under the Microscope: What Atomic Hypothesis Decomposition Reveals","summary":"  Decomposition of text into atomic propositions is a flexible framework\nallowing for the closer inspection of input and output text. We use atomic\ndecomposition of hypotheses in two natural language reasoning tasks,\ntraditional NLI and defeasible NLI, to form atomic sub-problems, or granular\ninferences that models must weigh when solving the overall problem. These\natomic sub-problems serve as a tool to further understand the structure of both\nNLI and defeasible reasoning, probe a model's consistency and understanding of\ndifferent inferences, and measure the diversity of examples in benchmark\ndatasets. Our results indicate that LLMs still struggle with logical\nconsistency on atomic NLI and defeasible NLI sub-problems. Lastly, we identify\ncritical atomic sub-problems of defeasible NLI examples, or those that most\ncontribute to the overall label, and propose a method to measure the\ninferential consistency of a model, a metric designed to capture the degree to\nwhich a model makes consistently correct or incorrect predictions about the\nsame fact under different contexts.\n","authors":["Neha Srikanth","Rachel Rudinger"],"pdf_url":"https://arxiv.org/pdf/2502.08080v2.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.05500v1","updated":"2025-03-07T15:13:58Z","published":"2025-03-07T15:13:58Z","title":"EuroBERT: Scaling Multilingual Encoders for European Languages","summary":"  General-purpose multilingual vector representations, used in retrieval,\nregression and classification, are traditionally obtained from bidirectional\nencoder models. Despite their wide applicability, encoders have been recently\novershadowed by advances in generative decoder-only models. However, many\ninnovations driving this progress are not inherently tied to decoders. In this\npaper, we revisit the development of multilingual encoders through the lens of\nthese advances, and introduce EuroBERT, a family of multilingual encoders\ncovering European and widely spoken global languages. Our models outperform\nexisting alternatives across a diverse range of tasks, spanning multilingual\ncapabilities, mathematics, and coding, and natively supporting sequences of up\nto 8,192 tokens. We also examine the design decisions behind EuroBERT, offering\ninsights into our dataset composition and training pipeline. We publicly\nrelease the EuroBERT models, including intermediate training checkpoints,\ntogether with our training framework.\n","authors":["Nicolas Boizard","Hippolyte Gisserot-Boukhlef","Duarte M. Alves","André Martins","Ayoub Hammal","Caio Corro","Céline Hudelot","Emmanuel Malherbe","Etienne Malaboeuf","Fanny Jourdan","Gabriel Hautreux","João Alves","Kevin El-Haddad","Manuel Faysse","Maxime Peyrard","Nuno M. Guerreiro","Patrick Fernandes","Ricardo Rei","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2503.05500v1.pdf","comment":"26 pages, 6 figures, 11 tables"},{"id":"http://arxiv.org/abs/2503.04346v2","updated":"2025-03-07T15:13:32Z","published":"2025-03-06T11:42:03Z","title":"Adding Alignment Control to Language Models","summary":"  Post-training alignment has increasingly become a crucial factor in enhancing\nthe usability of language models (LMs). However, the strength of alignment\nvaries depending on individual preferences. This paper proposes a method to\nincorporate alignment control into a single model, referred to as CLM. This\napproach adds one identity layer preceding the initial layers and performs\npreference learning only on this layer to map unaligned input token embeddings\ninto the aligned space. Experimental results demonstrate that this efficient\nfine-tuning method performs comparable to full fine-tuning. During inference,\nthe input embeddings are processed through the aligned and unaligned layers,\nwhich are then merged through the interpolation coefficient. By controlling\nthis parameter, the alignment exhibits a clear interpolation and extrapolation\nphenomenon.\n","authors":["Wenhong Zhu","Weinan Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05493v1","updated":"2025-03-07T15:05:23Z","published":"2025-03-07T15:05:23Z","title":"Benchmarking LLMs in Recommendation Tasks: A Comparative Evaluation with\n  Conventional Recommenders","summary":"  In recent years, integrating large language models (LLMs) into recommender\nsystems has created new opportunities for improving recommendation quality.\nHowever, a comprehensive benchmark is needed to thoroughly evaluate and compare\nthe recommendation capabilities of LLMs with traditional recommender systems.\nIn this paper, we introduce RecBench, which systematically investigates various\nitem representation forms (including unique identifier, text, semantic\nembedding, and semantic identifier) and evaluates two primary recommendation\ntasks, i.e., click-through rate prediction (CTR) and sequential recommendation\n(SeqRec). Our extensive experiments cover up to 17 large models and are\nconducted across five diverse datasets from fashion, news, video, books, and\nmusic domains. Our findings indicate that LLM-based recommenders outperform\nconventional recommenders, achieving up to a 5% AUC improvement in the CTR\nscenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,\nthese substantial performance gains come at the expense of significantly\nreduced inference efficiency, rendering the LLM-as-RS paradigm impractical for\nreal-time recommendation environments. We aim for our findings to inspire\nfuture research, including recommendation-specific model acceleration methods.\nWe will release our code, data, configurations, and platform to enable other\nresearchers to reproduce and build upon our experimental results.\n","authors":["Qijiong Liu","Jieming Zhu","Lu Fan","Kun Wang","Hengchang Hu","Wei Guo","Yong Liu","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05488v1","updated":"2025-03-07T14:58:14Z","published":"2025-03-07T14:58:14Z","title":"KIEval: Evaluation Metric for Document Key Information Extraction","summary":"  Document Key Information Extraction (KIE) is a technology that transforms\nvaluable information in document images into structured data, and it has become\nan essential function in industrial settings. However, current evaluation\nmetrics of this technology do not accurately reflect the critical attributes of\nits industrial applications. In this paper, we present KIEval, a novel\napplication-centric evaluation metric for Document KIE models. Unlike prior\nmetrics, KIEval assesses Document KIE models not just on the extraction of\nindividual information (entity) but also of the structured information\n(grouping). Evaluation of structured information provides assessment of\nDocument KIE models that are more reflective of extracting grouped information\nfrom documents in industrial settings. Designed with industrial application in\nmind, we believe that KIEval can become a standard evaluation metric for\ndeveloping or applying Document KIE models in practice. The code will be\npublicly available.\n","authors":["Minsoo Khang","Sang Chul Jung","Sungrae Park","Teakgyu Hong"],"pdf_url":"https://arxiv.org/pdf/2503.05488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19723v3","updated":"2025-03-07T14:56:45Z","published":"2025-02-27T03:25:34Z","title":"CNsum:Automatic Summarization for Chinese News Text","summary":"  Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.\n","authors":["Yu Zhao","Songping Huang","Dongsheng Zhou","Zhaoyun Ding","Fei Wang","Aixin Nian"],"pdf_url":"https://arxiv.org/pdf/2502.19723v3.pdf","comment":"This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version"},{"id":"http://arxiv.org/abs/2403.02694v4","updated":"2025-03-07T14:49:07Z","published":"2024-03-05T06:23:50Z","title":"MeanCache: User-Centric Semantic Caching for LLM Web Services","summary":"  Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.\n","authors":["Waris Gill","Mohamed Elidrisi","Pallavi Kalapatapu","Ammar Ahmed","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2403.02694v4.pdf","comment":"Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)"},{"id":"http://arxiv.org/abs/2503.00435v2","updated":"2025-03-07T14:33:10Z","published":"2025-03-01T10:24:42Z","title":"AILS-NTUA at SemEval-2025 Task 8: Language-to-Code prompting and Error\n  Fixing for Tabular Question Answering","summary":"  In this paper, we present our submission to SemEval-2025 Task 8: Question\nAnswering over Tabular Data. This task, evaluated on the DataBench dataset,\nassesses Large Language Models' (LLMs) ability to answer natural language\nquestions over structured data while addressing topic diversity and table size\nlimitations in previous benchmarks. We propose a system that employs effective\nLLM prompting to translate natural language queries into executable code,\nenabling accurate responses, error correction, and interpretability. Our\napproach ranks first in both subtasks of the competition in the proprietary\nmodel category, significantly outperforming the organizer's baseline.\n","authors":["Andreas Evangelatos","Giorgos Filandrianos","Maria Lymperaiou","Athanasios Voulodimos","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.00435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14644v2","updated":"2025-03-07T14:18:56Z","published":"2025-02-20T15:32:24Z","title":"LIFT: Improving Long Context Understanding of Large Language Models\n  through Long Input Fine-Tuning","summary":"  Long context understanding remains challenging for large language models due\nto their limited context windows. This paper presents Long Input Fine-Tuning\n(LIFT), a novel framework for long-context modeling that can improve the\nlong-context performance of arbitrary (short-context) LLMs by dynamically\nadapting model parameters based on the long input. Importantly, LIFT, rather\nthan endlessly extending the context window size to accommodate increasingly\nlonger inputs in context, chooses to store and absorb the long input in\nparameter. By fine-tuning the long input into model parameters, LIFT allows\nshort-context LLMs to answer questions even when the required information is\nnot provided in the context during inference. Furthermore, to enhance LIFT\nperformance while maintaining the original in-context learning (ICL)\ncapabilities, we introduce Gated Memory, a specialized attention adapter that\nautomatically balances long input memorization and ICL. We provide a\ncomprehensive analysis of the strengths and limitations of LIFT on long context\nunderstanding, offering valuable directions for future research.\n","authors":["Yansheng Mao","Yufei Xu","Jiaqi Li","Fanxu Meng","Haotong Yang","Zilong Zheng","Xiyuan Wang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.14644v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2412.13626"},{"id":"http://arxiv.org/abs/2503.05447v1","updated":"2025-03-07T14:17:45Z","published":"2025-03-07T14:17:45Z","title":"Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts","summary":"  Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.\n","authors":["Weigao Sun","Disen Lan","Tong Zhu","Xiaoye Qu","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05447v1.pdf","comment":"Technical report, 17 pages"},{"id":"http://arxiv.org/abs/2503.05439v1","updated":"2025-03-07T14:10:10Z","published":"2025-03-07T14:10:10Z","title":"An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for\n  Robust Reasoning","summary":"  In this paper, we examine the use of Conformal Language Modelling (CLM)\nalongside Answer Set Programming (ASP) to enhance the performance of standard\nopen-weight LLMs on complex multi-step reasoning tasks. Using the StepGame\ndataset, which requires spatial reasoning, we apply CLM to generate sets of ASP\nprograms from an LLM, providing statistical guarantees on the correctness of\nthe outputs. Experimental results show that CLM significantly outperforms\nbaseline models that use standard sampling methods, achieving substantial\naccuracy improvements across different levels of reasoning complexity.\nAdditionally, the LLM-as-Judge metric enhances CLM's performance, especially in\nassessing structurally and logically correct ASP outputs. However, calibrating\nCLM with diverse calibration sets did not improve generalizability for tasks\nrequiring much longer reasoning steps, indicating limitations in handling more\ncomplex tasks.\n","authors":["Navdeep Kaur","Lachlan McPheat","Alessandra Russo","Anthony G Cohn","Pranava Madhyastha"],"pdf_url":"https://arxiv.org/pdf/2503.05439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20576v2","updated":"2025-03-07T13:35:33Z","published":"2025-02-27T22:35:31Z","title":"ECCOS: Efficient Capability and Cost Coordinated Scheduling for\n  Multi-LLM Serving","summary":"  As large language models (LLMs) are increasingly deployed as service\nendpoints in systems, the surge in query volume creates significant scheduling\nchallenges. Existing scheduling frameworks mainly target at latency\noptimization while neglecting the capability of LLMs to serve different level\nof queries, which could lead to computational resource waste. This paper\naddresses this challenge by proposing a capability-cost coordinated scheduling\nframework, ECCOS, for multi-LLM serving, which explicitly constrains response\nquality and workload to optimize LLM inference cost. Specifically, it\nintroduces the two-stage scheduling by designing a multi-objective predictor\nand a constrained optimizer. The predictor estimates both model capabilities\nand computational costs through training-based and retrieval-based approaches,\nwhile the optimizer determines cost-optimal assignments under quality and\nworkload constraints. It also introduces QAServe, a dataset collected for\nsample-wise response quality and costs by zero-shot prompting different LLMs on\nknowledge QA and mathematical reasoning. Extensive experiments demonstrate that\nECCOS improves success rates by 6.30% while reducing costs by 10.15% compared\nto existing methods, consuming less than 0.5% of LLM response time. The code is\navailable at: https://github.com/agiresearch/ECCOS.\n","authors":["Kai Mei","Wujiang Xu","Shuhang Lin","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20576v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05397v1","updated":"2025-03-07T13:20:12Z","published":"2025-03-07T13:20:12Z","title":"Multi Agent based Medical Assistant for Edge Devices","summary":"  Large Action Models (LAMs) have revolutionized intelligent automation, but\ntheir application in healthcare faces challenges due to privacy concerns,\nlatency, and dependency on internet access. This report introduces an ondevice,\nmulti-agent healthcare assistant that overcomes these limitations. The system\nutilizes smaller, task-specific agents to optimize resources, ensure\nscalability and high performance. Our proposed system acts as a one-stop\nsolution for health care needs with features like appointment booking, health\nmonitoring, medication reminders, and daily health reporting. Powered by the\nQwen Code Instruct 2.5 7B model, the Planner and Caller Agents achieve an\naverage RougeL score of 85.5 for planning and 96.5 for calling for our tasks\nwhile being lightweight for on-device deployment. This innovative approach\ncombines the benefits of ondevice systems with multi-agent architectures,\npaving the way for user-centric healthcare solutions.\n","authors":["Sakharam Gawade","Shivam Akhouri","Chinmay Kulkarni","Jagdish Samant","Pragya Sahu"," Aastik","Jai Pahal","Saswat Meher"],"pdf_url":"https://arxiv.org/pdf/2503.05397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02645v2","updated":"2025-03-07T12:39:10Z","published":"2024-09-04T12:22:05Z","title":"Emergent Language: A Survey and Taxonomy","summary":"  The field of emergent language represents a novel area of research within the\ndomain of artificial intelligence, particularly within the context of\nmulti-agent reinforcement learning. Although the concept of studying language\nemergence is not new, early approaches were primarily concerned with explaining\nhuman language formation, with little consideration given to its potential\nutility for artificial agents. In contrast, studies based on reinforcement\nlearning aim to develop communicative capabilities in agents that are\ncomparable to or even superior to human language. Thus, they extend beyond the\nlearned statistical representations that are common in natural language\nprocessing research. This gives rise to a number of fundamental questions, from\nthe prerequisites for language emergence to the criteria for measuring its\nsuccess. This paper addresses these questions by providing a comprehensive\nreview of 181 scientific publications on emergent language in artificial\nintelligence. Its objective is to serve as a reference for researchers\ninterested in or proficient in the field. Consequently, the main contributions\nare the definition and overview of the prevailing terminology, the analysis of\nexisting evaluation methods and metrics, and the description of the identified\nresearch gaps.\n","authors":["Jannik Peters","Constantin Waubert de Puiseau","Hasan Tercan","Arya Gopikrishnan","Gustavo Adolpho Lucas De Carvalho","Christian Bitter","Tobias Meisen"],"pdf_url":"https://arxiv.org/pdf/2409.02645v2.pdf","comment":"published in Journal of Autonomous Agents and Multi-Agent Systems"},{"id":"http://arxiv.org/abs/2503.05373v1","updated":"2025-03-07T12:29:21Z","published":"2025-03-07T12:29:21Z","title":"Leveraging Semantic Type Dependencies for Clinical Named Entity\n  Recognition","summary":"  Previous work on clinical relation extraction from free-text sentences\nleveraged information about semantic types from clinical knowledge bases as a\npart of entity representations. In this paper, we exploit additional evidence\nby also making use of domain-specific semantic type dependencies. We encode the\nrelation between a span of tokens matching a Unified Medical Language System\n(UMLS) concept and other tokens in the sentence. We implement our method and\ncompare against different named entity recognition (NER) architectures (i.e.,\nBiLSTM-CRF and BiLSTM-GCN-CRF) using different pre-trained clinical embeddings\n(i.e., BERT, BioBERT, UMLSBert). Our experimental results on clinical datasets\nshow that in some cases NER effectiveness can be significantly improved by\nmaking use of domain-specific semantic type dependencies. Our work is also the\nfirst study generating a matrix encoding to make use of more than three\ndependencies in one pass for the NER task.\n","authors":["Linh Le","Guido Zuccon","Gianluca Demartini","Genghong Zhao","Xia Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05371v1","updated":"2025-03-07T12:25:29Z","published":"2025-03-07T12:25:29Z","title":"Shifting Perspectives: Steering Vector Ensembles for Robust Bias\n  Mitigation in LLMs","summary":"  We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.\n","authors":["Zara Siddique","Irtaza Khalid","Liam D. Turner","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.05371v1.pdf","comment":"Submitted to ACL 2025"},{"id":"http://arxiv.org/abs/2503.05362v1","updated":"2025-03-07T12:07:59Z","published":"2025-03-07T12:07:59Z","title":"Chain of Strategy Optimization Makes Large Language Models Better\n  Emotional Supporter","summary":"  The growing emotional stress in modern society has increased the demand for\nEmotional Support Conversations (ESC). While Large Language Models (LLMs) show\npromise for ESC, they face two key challenges: (1) low strategy selection\naccuracy, and (2) preference bias, limiting their adaptability to emotional\nneeds of users. Existing supervised fine-tuning (SFT) struggles to address\nthese issues, as it rigidly trains models on single gold-standard responses\nwithout modeling nuanced strategy trade-offs. To overcome these limitations, we\npropose Chain-of-Strategy Optimization (CSO), a novel approach that optimizes\nstrategy selection preferences at each dialogue turn. We first leverage Monte\nCarlo Tree Search to construct ESC-Pro, a high-quality preference dataset with\nturn-level strategy-response pairs. Training on ESC-Pro with CSO improves both\nstrategy accuracy and bias mitigation, enabling LLMs to generate more\nempathetic and contextually appropriate responses. Experiments on LLaMA-3.1-8B,\nGemma-2-9B, and Qwen2.5-7B demonstrate that CSO outperforms standard SFT,\nhighlighting the efficacy of fine-grained, turn-level preference modeling in\nESC.\n","authors":["Weixiang Zhao","Xingyu Sui","Xinyang Han","Yang Deng","Yulin Hu","Jiahe Guo","Libo Qin","Qianyun Du","Shijin Wang","Yanyan Zhao","Bing Qin","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2503.05362v1.pdf","comment":"19 pages, 9 figures, 15 tables"},{"id":"http://arxiv.org/abs/2503.05357v1","updated":"2025-03-07T12:01:02Z","published":"2025-03-07T12:01:02Z","title":"Improving Hate Speech Classification with Cross-Taxonomy Dataset\n  Integration","summary":"  Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.\n","authors":["Jan Fillies","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2503.05357v1.pdf","comment":"Accepted for publication at LaTeCH-CLfL 2025. The 9th Joint ACL\n  Special Interest Group on Language Technologies for the Socio-Economic\n  Sciences and Humanities (SIGHUM) Workshop on Computational Linguistics for\n  Cultural Heritage, Social Sciences, Humanities and Literature"},{"id":"http://arxiv.org/abs/2412.10121v2","updated":"2025-03-07T11:54:22Z","published":"2024-12-13T13:06:58Z","title":"Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by\n  Quantifying Label Shifts in Synthetic Training Data","summary":"  Zero-shot named entity recognition (NER) is the task of detecting named\nentities of specific types (such as 'Person' or 'Medicine') without any\ntraining examples. Current research increasingly relies on large synthetic\ndatasets, automatically generated to cover tens of thousands of distinct entity\ntypes, to train zero-shot NER models. However, in this paper, we find that\nthese synthetic datasets often contain entity types that are semantically\nhighly similar to (or even the same as) those in standard evaluation\nbenchmarks. Because of this overlap, we argue that reported F1 scores for\nzero-shot NER overestimate the true capabilities of these approaches. Further,\nwe argue that current evaluation setups provide an incomplete picture of\nzero-shot abilities since they do not quantify the label shift (i.e., the\nsimilarity of labels) between training and evaluation datasets. To address\nthese issues, we propose Familiarity, a novel metric that captures both the\nsemantic similarity between entity types in training and evaluation, as well as\ntheir frequency in the training data, to provide an estimate of label shift. It\nallows researchers to contextualize reported zero-shot NER scores when using\ncustom synthetic training datasets. Further, it enables researchers to generate\nevaluation setups of various transfer difficulties for fine-grained analysis of\nzero-shot NER.\n","authors":["Jonas Golde","Patrick Haller","Max Ploner","Fabio Barth","Nicolaas Jedema","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2412.10121v2.pdf","comment":"9 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.05347v1","updated":"2025-03-07T11:42:22Z","published":"2025-03-07T11:42:22Z","title":"GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report\n  Evaluation","summary":"  Automatic medical report generation supports clinical diagnosis, reduces the\nworkload of radiologists, and holds the promise of improving diagnosis\nconsistency. However, existing evaluation metrics primarily assess the accuracy\nof key medical information coverage in generated reports compared to\nhuman-written reports, while overlooking crucial details such as the location\nand certainty of reported abnormalities. These limitations hinder the\ncomprehensive assessment of the reliability of generated reports and pose risks\nin their selection for clinical use. Therefore, we propose a Granular\nExplainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both\nobjective quantification and subjective evaluation through a large language\nmodel-based multi-agent workflow. Our GEMA-Score parses structured reports and\nemploys NER-F1 calculations through interactive exchanges of information among\nagents to assess disease diagnosis, location, severity, and uncertainty.\nAdditionally, an LLM-based scoring agent evaluates completeness, readability,\nand clinical terminology while providing explanatory feedback. Extensive\nexperiments validate that GEMA-Score achieves the highest correlation with\nhuman expert evaluations on a public dataset, demonstrating its effectiveness\nin clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall\ncoefficient = 0.54 for RadEvalX dataset). The anonymous project demo is\navailable at: https://github.com/Zhenxuan-Zhang/GEMA_score.\n","authors":["Zhenxuan Zhang","Kinhei Lee","Weihang Deng","Huichi Zhou","Zihao Jin","Jiahao Huang","Zhifan Gao","Dominic C Marshall","Yingying Fang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.05347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05346v1","updated":"2025-03-07T11:40:52Z","published":"2025-03-07T11:40:52Z","title":"AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT\n  Applications","summary":"  The advent of Large Language Models (LLMs) has profoundly transformed our\nlives, revolutionizing interactions with AI and lowering the barrier to AI\nusage. While LLMs are primarily designed for natural language interaction, the\nextensive embedded knowledge empowers them to comprehend digital sensor data.\nThis capability enables LLMs to engage with the physical world through IoT\nsensors and actuators, performing a myriad of AIoT tasks. Consequently, this\nevolution triggers a paradigm shift in conventional AIoT application\ndevelopment, democratizing its accessibility to all by facilitating the design\nand development of AIoT applications via natural language. However, some\nlimitations need to be addressed to unlock the full potential of LLMs in AIoT\napplication development. First, existing solutions often require transferring\nraw sensor data to LLM servers, which raises privacy concerns, incurs high\nquery fees, and is limited by token size. Moreover, the reasoning processes of\nLLMs are opaque to users, making it difficult to verify the robustness and\ncorrectness of inference results. This paper introduces AutoIOT, an LLM-based\nautomated program generator for AIoT applications. AutoIOT enables users to\nspecify their requirements using natural language (input) and automatically\nsynthesizes interpretable programs with documentation (output). AutoIOT\nautomates the iterative optimization to enhance the quality of generated code\nwith minimum user involvement. AutoIOT not only makes the execution of AIoT\ntasks more explainable but also mitigates privacy concerns and reduces token\ncosts with local execution of synthesized programs. Extensive experiments and\nuser studies demonstrate AutoIOT's remarkable capability in program synthesis\nfor various AIoT tasks. The synthesized programs can match and even outperform\nsome representative baselines.\n","authors":["Leming Shen","Qiang Yang","Yuanqing Zheng","Mo Li"],"pdf_url":"https://arxiv.org/pdf/2503.05346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08944v3","updated":"2025-03-07T11:23:19Z","published":"2023-10-13T08:19:31Z","title":"A Confidence-based Acquisition Model for Self-supervised Active Learning\n  and Label Correction","summary":"  Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present CAMEL (Confidence-based Acquisition Model for Efficient\nself-supervised active Learning), a pool-based active learning framework\ntailored to sequential multi-output problems. CAMEL possesses two core\nfeatures: (1) it requires expert annotators to label only a fraction of a\nchosen sequence, and (2) it facilitates self-supervision for the remainder of\nthe sequence. By deploying a label correction mechanism, CAMEL can also be\nutilised for data cleaning. We evaluate CAMEL on two sequential tasks, with a\nspecial emphasis on dialogue belief tracking, a task plagued by the constraints\nof limited and noisy datasets. Our experiments demonstrate that CAMEL\nsignificantly outperforms the baselines in terms of efficiency. Furthermore,\nthe data corrections suggested by our method contribute to an overall\nimprovement in the quality of the resulting datasets.\n","authors":["Carel van Niekerk","Christian Geishauser","Michael Heck","Shutong Feng","Hsien-chin Lin","Nurul Lubis","Benjamin Ruppik","Renato Vukovic","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2310.08944v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14352v2","updated":"2025-03-07T11:16:40Z","published":"2023-08-28T06:56:08Z","title":"EdgeMoE: Empowering Sparse Large Language Models on Mobile Devices","summary":"  Large language models (LLMs) such as GPTs and Mixtral-8x7B have\nrevolutionized machine intelligence due to their exceptional abilities in\ngeneric ML tasks. Transiting LLMs from datacenters to edge devices brings\nbenefits like better privacy and availability, but is challenged by their\nmassive parameter size and thus unbearable runtime costs. To this end, we\npresent EdgeMoE, an on-device inference engine for mixture-of-expert (MoE) LLMs\n-- a popular form of sparse LLM that scales its parameter size with almost\nconstant computing complexity. EdgeMoE achieves both memory- and\ncompute-efficiency by partitioning the model into the storage hierarchy:\nnon-expert weights are held in device memory; while expert weights are held on\nexternal storage and fetched to memory only when activated. This design is\nmotivated by a key observation that expert weights are bulky but infrequently\nused due to sparse activation. To further reduce the expert I/O swapping\noverhead, EdgeMoE incorporates two novel techniques: (1) expert-wise bitwidth\nadaptation that reduces the expert sizes with tolerable accuracy loss; (2)\nexpert preloading that predicts the activated experts ahead of time and\npreloads it with the compute-I/O pipeline. On popular MoE LLMs and edge\ndevices, EdgeMoE showcase significant memory savings and speedup over\ncompetitive baselines. The code is available at\nhttps://github.com/UbiquitousLearning/mllm.\n","authors":["Rongjie Yi","Liwei Guo","Shiyun Wei","Ao Zhou","Shangguang Wang","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2308.14352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05330v1","updated":"2025-03-07T11:15:36Z","published":"2025-03-07T11:15:36Z","title":"Speculative Decoding for Multi-Sample Inference","summary":"  We propose a novel speculative decoding method tailored for multi-sample\nreasoning scenarios, such as self-consistency and Best-of-N sampling. Our\nmethod exploits the intrinsic consensus of parallel generation paths to\nsynthesize high-quality draft tokens without requiring auxiliary models or\nexternal databases. By dynamically analyzing structural patterns across\nparallel reasoning paths through a probabilistic aggregation mechanism, it\nidentifies consensus token sequences that align with the decoding distribution.\nEvaluations on mathematical reasoning benchmarks demonstrate a substantial\nimprovement in draft acceptance rates over baselines, while reducing the\nlatency in draft token construction. This work establishes a paradigm shift for\nefficient multi-sample inference, enabling seamless integration of speculative\ndecoding with sampling-based reasoning techniques.\n","authors":["Yiwei Li","Jiayi Shi","Shaoxiong Feng","Peiwen Yuan","Xinglin Wang","Yueqi Zhang","Ji Zhang","Chuyi Tan","Boyuan Pan","Yao Hu","Kan Li"],"pdf_url":"https://arxiv.org/pdf/2503.05330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05328v1","updated":"2025-03-07T11:13:33Z","published":"2025-03-07T11:13:33Z","title":"Dynamic Knowledge Integration for Evidence-Driven Counter-Argument\n  Generation with Large Language Models","summary":"  This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.\n","authors":["Anar Yeginbergen","Maite Oronoz","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2503.05328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v2","updated":"2025-03-07T11:12:17Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2408.02361v2.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05326v1","updated":"2025-03-07T11:10:33Z","published":"2025-03-07T11:10:33Z","title":"Fine-Grained Evaluation for Implicit Discourse Relation Recognition","summary":"  Implicit discourse relation recognition is a challenging task in discourse\nanalysis due to the absence of explicit discourse connectives between spans of\ntext. Recent pre-trained language models have achieved great success on this\ntask. However, there is no fine-grained analysis of the performance of these\npre-trained language models for this task. Therefore, the difficulty and\npossible directions of this task is unclear. In this paper, we deeply analyze\nthe model prediction, attempting to find out the difficulty for the pre-trained\nlanguage models and the possible directions of this task. In addition to having\nan in-depth analysis for this task by using pre-trained language models, we\nsemi-manually annotate data to add relatively high-quality data for the\nrelations with few annotated examples in PDTB 3.0. The annotated data\nsignificantly help improve implicit discourse relation recognition for level-2\nsenses.\n","authors":["Xinyi Cai"],"pdf_url":"https://arxiv.org/pdf/2503.05326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19103v2","updated":"2025-03-07T11:05:01Z","published":"2025-02-26T12:46:36Z","title":"LongEval: A Comprehensive Analysis of Long-Text Generation Through a\n  Plan-based Paradigm","summary":"  Large Language Models (LLMs) have achieved remarkable success in various\nnatural language processing tasks, yet their ability to generate long-form\ncontent remains poorly understood and evaluated. Our analysis reveals that\ncurrent LLMs struggle with length requirements and information density in\nlong-text generation, with performance deteriorating as text length increases.\nTo quantitively locate such a performance degradation and provide further\ninsights on model development, we present LongEval, a benchmark that evaluates\nlong-text generation through both direct and plan-based generation paradigms,\ninspired by cognitive and linguistic writing models. The comprehensive\nexperiments in this work reveal interesting findings such as that while model\nsize correlates with generation ability, the small-scale model (e.g.,\nLongWriter), well-trained on long texts, has comparable performance. All code\nand datasets are released in https://github.com/Wusiwei0410/LongEval.\n","authors":["Siwei Wu","Yizhi Li","Xingwei Qu","Rishi Ravikumar","Yucheng Li","Tyler Loakman","Shanghaoran Quan","Xiaoyong Wei","Riza Batista-Navarro","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2502.19103v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.05318v1","updated":"2025-03-07T10:55:12Z","published":"2025-03-07T10:55:12Z","title":"Uncertainty-Aware Decoding with Minimum Bayes Risk","summary":"  Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.\n","authors":["Nico Daheim","Clara Meister","Thomas Möllenhoff","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.05318v1.pdf","comment":"ICLR 2025 (Poster)"},{"id":"http://arxiv.org/abs/2503.05298v1","updated":"2025-03-07T10:23:22Z","published":"2025-03-07T10:23:22Z","title":"Coreference as an indicator of context scope in multimodal narrative","summary":"  We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality.\n","authors":["Nikolai Ilinykh","Shalom Lappin","Asad Sayeed","Sharid Loáiciga"],"pdf_url":"https://arxiv.org/pdf/2503.05298v1.pdf","comment":"20 pages, 4 tables"},{"id":"http://arxiv.org/abs/2410.14677v3","updated":"2025-03-07T10:17:34Z","published":"2024-10-18T17:59:57Z","title":"Are AI Detectors Good Enough? A Survey on Quality of Datasets With\n  Machine-Generated Texts","summary":"  The rapid development of autoregressive Large Language Models (LLMs) has\nsignificantly improved the quality of generated texts, necessitating reliable\nmachine-generated text detectors. A huge number of detectors and collections\nwith AI fragments have emerged, and several detection methods even showed\nrecognition quality up to 99.9% according to the target metrics in such\ncollections. However, the quality of such detectors tends to drop dramatically\nin the wild, posing a question: Are detectors actually highly trustworthy or do\ntheir high benchmark scores come from the poor quality of evaluation datasets?\nIn this paper, we emphasise the need for robust and qualitative methods for\nevaluating generated data to be secure against bias and low generalising\nability of future model. We present a systematic review of datasets from\ncompetitions dedicated to AI-generated content detection and propose methods\nfor evaluating the quality of datasets containing AI-generated fragments. In\naddition, we discuss the possibility of using high-quality generated data to\nachieve two goals: improving the training of detection models and improving the\ntraining datasets themselves. Our contribution aims to facilitate a better\nunderstanding of the dynamics between human and machine text, which will\nultimately support the integrity of information in an increasingly automated\nworld. The code is available at\nhttps://github.com/Advacheck-OU/ai-dataset-analysing.\n","authors":["German Gritsai","Anastasia Voznyuk","Andrey Grabovoy","Yury Chekhovich"],"pdf_url":"https://arxiv.org/pdf/2410.14677v3.pdf","comment":"Presented at Preventing and Detecting LLM Misinformation (PDLM) at\n  AAAI 2025"},{"id":"http://arxiv.org/abs/2502.08662v2","updated":"2025-03-07T09:55:19Z","published":"2025-02-10T09:34:15Z","title":"RoToR: Towards More Reliable Responses for Order-Invariant Inputs","summary":"  Mitigating positional bias of language models (LMs) for listwise inputs is a\nwell-known and important problem (e.g., lost-in-the-middle). While zero-shot\norder-invariant LMs have been proposed to solve this issue, their success on\npractical listwise problems has been limited. In this work, as a first\ncontribution, we identify and overcome two limitations to make zero-shot\ninvariant LMs more practical: (1) training and inference distribution mismatch\narising from modifying positional ID assignments to enforce invariance, and (2)\nfailure to adapt to a mixture of order-invariant and sensitive inputs in\npractical listwise problems. Then, to overcome these issues we propose (1)\nRoToR, a zero-shot invariant LM for genuinely order-invariant inputs with\nminimal modifications of positional IDs, and (2) Selective Routing, an adaptive\nframework that handles both order-invariant and order-sensitive inputs in\nlistwise tasks. On the Lost in the middle (LitM), Knowledge Graph QA (KGQA),\nand MMLU benchmarks, we show that RoToR with Selective Routing can effectively\nhandle practical listwise input tasks in a zero-shot manner.\n","authors":["Soyoung Yoon","Dongha Ahn","Youngwon Lee","Minkyu Jung","HyungJoo Jang","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2502.08662v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05281v1","updated":"2025-03-07T09:51:07Z","published":"2025-03-07T09:51:07Z","title":"Similarity-Based Domain Adaptation with LLMs","summary":"  Unsupervised domain adaptation leverages abundant labeled data from various\nsource domains to generalize onto unlabeled target data. Prior research has\nprimarily focused on learning domain-invariant features across the source and\ntarget domains. However, these methods often require training a model using\nsource domain data, which is time-consuming and can limit model usage for\napplications with different source data. This paper introduces a simple\nframework that utilizes the impressive generalization capabilities of Large\nLanguage Models (LLMs) for target data annotation without the need of source\nmodel training, followed by a novel similarity-based knowledge distillation\nloss. Our extensive experiments on cross-domain text classification reveal that\nour framework achieves impressive performance, specifically, 2.44\\% accuracy\nimprovement when compared to the SOTA method.\n","authors":["Jie He","Wendi Zhou","Xiang Lorraine Li","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2503.05281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05280v1","updated":"2025-03-07T09:49:31Z","published":"2025-03-07T09:49:31Z","title":"Revealing Hidden Mechanisms of Cross-Country Content Moderation with\n  Natural Language Processing","summary":"  The ability of Natural Language Processing (NLP) methods to categorize text\ninto multiple classes has motivated their use in online content moderation\ntasks, such as hate speech and fake news detection. However, there is limited\nunderstanding of how or why these methods make such decisions, or why certain\ncontent is moderated in the first place. To investigate the hidden mechanisms\nbehind content moderation, we explore multiple directions: 1) training\nclassifiers to reverse-engineer content moderation decisions across countries;\n2) explaining content moderation decisions by analyzing Shapley values and\nLLM-guided explanations. Our primary focus is on content moderation decisions\nmade across countries, using pre-existing corpora sampled from the Twitter\nStream Grab. Our experiments reveal interesting patterns in censored posts,\nboth across countries and over time. Through human evaluations of LLM-generated\nexplanations across three LLMs, we assess the effectiveness of using LLMs in\ncontent moderation. Finally, we discuss potential future directions, as well as\nthe limitations and ethical considerations of this work. Our code and data are\navailable at https://github.com/causalNLP/censorship\n","authors":["Neemesh Yadav","Jiarui Liu","Francesco Ortu","Roya Ensafi","Zhijing Jin","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2503.05280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04150v2","updated":"2025-03-07T09:37:53Z","published":"2025-03-06T06:59:09Z","title":"Ticktack : Long Span Temporal Alignment of Large Language Models\n  Leveraging Sexagenary Cycle Time Expression","summary":"  Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.\n","authors":["Xue Han","Qian Hu","Yitong Wang","Wenchun Gao","Lianlian Zhang","Qing Wang","Lijun Mei","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05268v1","updated":"2025-03-07T09:33:30Z","published":"2025-03-07T09:33:30Z","title":"ZOGRASCOPE: A New Benchmark for Property Graphs","summary":"  Natural language interfaces to knowledge graphs have become increasingly\nimportant in recent years, enabling easy and efficient access to structured\ndata. In particular property graphs have seen growing adoption. However, these\nkind of graphs remain relatively underrepresented in research, which has\nfocused in large part on RDF-style graphs. As a matter of fact there is a lack\nof resources for evaluating systems on property graphs, with many existing\ndatasets featuring relatively simple queries. To address this gap, we introduce\nZOGRASCOPE, a benchmark designed specifically for the cypher query language.\nThe benchmark includes a diverse set of manually annotated queries of varying\ncomplexity. We complement this paper with a set of experiments that test the\nperformance of out-of-the-box LLMs of different sizes. Our experiments show\nthat semantic parsing over graphs is still a challenging open problem that can\nnot be solved by prompting LLMs alone.\n","authors":["Francesco Cazzaro","Justin Kleindienst","Sofia Marquez","Ariadna Quattoni"],"pdf_url":"https://arxiv.org/pdf/2503.05268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02972v3","updated":"2025-03-07T09:31:42Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Assessing the reasoning capabilities of large language models (LLMs) is\nsusceptible to overestimation due to data exposure of evaluation benchmarks. We\nintroduce a framework for producing linguistic reasoning problems that reduces\nthe effect of memorisation in model performance estimates and apply this\nframework to develop LINGOLY-TOO, a challenging benchmark for linguistic\nreasoning. By developing orthographic templates, we dynamically obfuscate the\nwriting systems of real languages to generate numerousquestion variations.\nThese variations preserve the reasoning steps required for each solution while\nreducing the likelihood of specific problem instances appearing in model\ntraining data. Our experiments demonstrate that frontier models, including\nClaud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.\nOur analysis also shows that LLMs exhibit noticeable variance in accuracy\nacross permutations of the same problem, and on average perform better on\nquestions appearing in their original orthography. Our findings highlight the\nopaque nature of response generation in LLMs and provide evidence that prior\ndata exposure contributes to over estimating the reasoning capabilities of\nfrontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacsu","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05265v1","updated":"2025-03-07T09:30:16Z","published":"2025-03-07T09:30:16Z","title":"PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and\n  Latin Lexicons","summary":"  We present PhiloBERTA, a cross-lingual transformer model that measures\nsemantic relationships between ancient Greek and Latin lexicons. Through\nanalysis of selected term pairs from classical texts, we use contextual\nembeddings and angular similarity metrics to identify precise semantic\nalignments. Our results show that etymologically related pairs demonstrate\nsignificantly higher similarity scores, particularly for abstract philosophical\nconcepts such as epist\\=em\\=e (scientia) and dikaiosyn\\=e (iustitia).\nStatistical analysis reveals consistent patterns in these relationships (p =\n0.012), with etymologically related pairs showing remarkably stable semantic\npreservation compared to control pairs. These findings establish a quantitative\nframework for examining how philosophical concepts moved between Greek and\nLatin traditions, offering new methods for classical philological research.\n","authors":["Rumi A. Allbert","Makai L. Allbert"],"pdf_url":"https://arxiv.org/pdf/2503.05265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23746v2","updated":"2025-03-07T09:06:03Z","published":"2024-10-31T09:01:25Z","title":"DetectRL: Benchmarking LLM-Generated Text Detection in Real-World\n  Scenarios","summary":"  Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xinyi Yang","Yulin Yuan","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2410.23746v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)"},{"id":"http://arxiv.org/abs/2503.01743v2","updated":"2025-03-07T09:05:58Z","published":"2025-03-03T17:05:52Z","title":"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs","summary":"  We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n","authors":[" Microsoft"," :","Abdelrahman Abouelenin","Atabak Ashfaq","Adam Atkinson","Hany Awadalla","Nguyen Bach","Jianmin Bao","Alon Benhaim","Martin Cai","Vishrav Chaudhary","Congcong Chen","Dong Chen","Dongdong Chen","Junkun Chen","Weizhu Chen","Yen-Chun Chen","Yi-ling Chen","Qi Dai","Xiyang Dai","Ruchao Fan","Mei Gao","Min Gao","Amit Garg","Abhishek Goswami","Junheng Hao","Amr Hendy","Yuxuan Hu","Xin Jin","Mahmoud Khademi","Dongwoo Kim","Young Jin Kim","Gina Lee","Jinyu Li","Yunsheng Li","Chen Liang","Xihui Lin","Zeqi Lin","Mengchen Liu","Yang Liu","Gilsinia Lopez","Chong Luo","Piyush Madan","Vadim Mazalov","Arindam Mitra","Ali Mousavi","Anh Nguyen","Jing Pan","Daniel Perez-Becker","Jacob Platin","Thomas Portet","Kai Qiu","Bo Ren","Liliang Ren","Sambuddha Roy","Ning Shang","Yelong Shen","Saksham Singhal","Subhojit Som","Xia Song","Tetyana Sych","Praneetha Vaddamanu","Shuohang Wang","Yiming Wang","Zhenghao Wang","Haibin Wu","Haoran Xu","Weijian Xu","Yifan Yang","Ziyi Yang","Donghan Yu","Ishmam Zabir","Jianwen Zhang","Li Lyna Zhang","Yunan Zhang","Xiren Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01743v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2501.13983v4","updated":"2025-03-07T09:02:42Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v4.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2503.05244v1","updated":"2025-03-07T08:56:20Z","published":"2025-03-07T08:56:20Z","title":"WritingBench: A Comprehensive Benchmark for Generative Writing","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.\n","authors":["Yuning Wu","Jiahao Mei","Ming Yan","Chenliang Li","SHaopeng Lai","Yuran Ren","Zijia Wang","Ji Zhang","Mengyue Wu","Qin Jin","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v2","updated":"2025-03-07T08:55:13Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05242v1","updated":"2025-03-07T08:53:10Z","published":"2025-03-07T08:53:10Z","title":"MM-StoryAgent: Immersive Narrated Storybook Video Generation with a\n  Multi-Agent Paradigm across Text, Image and Audio","summary":"  The rapid advancement of large language models (LLMs) and artificial\nintelligence-generated content (AIGC) has accelerated AI-native applications,\nsuch as AI-based storybooks that automate engaging story production for\nchildren. However, challenges remain in improving story attractiveness,\nenriching storytelling expressiveness, and developing open-source evaluation\nbenchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent,\nwhich creates immersive narrated video storybooks with refined plots,\nrole-consistent images, and multi-channel audio. MM-StoryAgent designs a\nmulti-agent framework that employs LLMs and diverse expert tools (generative\nmodels and APIs) across several modalities to produce expressive storytelling\nvideos. The framework enhances story attractiveness through a multi-stage\nwriting pipeline. In addition, it improves the immersive storytelling\nexperience by integrating sound effects with visual, music and narrative\nassets. MM-StoryAgent offers a flexible, open-source platform for further\ndevelopment, where generative modules can be substituted. Both objective and\nsubjective evaluation regarding textual story quality and alignment between\nmodalities validate the effectiveness of our proposed MM-StoryAgent system. The\ndemo and source code are available.\n","authors":["Xuenan Xu","Jiahao Mei","Chenliang Li","Yuning Wu","Ming Yan","Shaopeng Lai","Ji Zhang","Mengyue Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05605v2","updated":"2025-03-07T08:35:00Z","published":"2025-02-08T15:21:55Z","title":"ARIES: Stimulating Self-Refinement of Large Language Models by Iterative\n  Preference Optimization","summary":"  A truly intelligent Large Language Model (LLM) should be capable of\ncorrecting errors in its responses through external interactions. However, even\nthe most advanced models often face challenges in improving their outputs. In\nthis paper, we explore how to cultivate LLMs with the self-refinement\ncapability through iterative preference training, and how this ability can be\nleveraged to improve model performance during inference. To this end, we\nintroduce a novel post-training and inference framework, called ARIES: Adaptive\nRefinement and Iterative Enhancement Structure. This method iteratively\nperforms preference training and self-refinement-based data collection. During\ntraining, ARIES strengthen the model's direct question-answering capability\nwhile simultaneously unlocking its self-refinement potential. During inference,\nARIES harnesses this self-refinement capability to generate a series of\nprogressively refined responses, which are then filtered using either the\nReward Model Scoring or a simple yet effective Rule-Based Selection mechanism,\nspecifically tailored to our approach, to construct a dataset for the next\nround of preference training. Experimental results demonstrate the remarkable\nperformance of ARIES. When applied to the Llama-3.1-8B model and under the\nself-refinement setting, ARIES surpasses powerful models such as GPT-4o,\nachieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval\n2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a\n50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore,\nARIES consistently enhances performance on mathematical reasoning tasks like\nGSM8K and MATH.\n","authors":["Yongcheng Zeng","Xinyu Cui","Xuanfa Jin","Guoqing Liu","Zexu Sun","Quan He","Dong Li","Ning Yang","Jianye Hao","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.05605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04685v2","updated":"2025-03-07T08:19:07Z","published":"2025-03-06T18:27:41Z","title":"DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module","summary":"  We look at reasoning on GSM8k, a dataset of short texts presenting primary\nschool, math problems. We find, with Mirzadeh et al. (2024), that current LLM\nprogress on the data set may not be explained by better reasoning but by\nexposure to a broader pretraining data distribution. We then introduce a novel\ninformation source for helping models with less data or inferior training\nreason better: discourse structure. We show that discourse structure improves\nperformance for models like Llama2 13b by up to 160%. Even for models that have\nmost likely memorized the data set, adding discourse structural information to\nthe model still improves predictions and dramatically improves large model\nperformance on out of distribution examples.\n","authors":["Krish Sharma","Niyar R Barman","Akshay Chaturvedi","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2503.04685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19346v2","updated":"2025-03-07T08:08:18Z","published":"2024-11-28T19:48:54Z","title":"CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image\n  Collections","summary":"  In the era of foundation models, CLIP has emerged as a powerful tool for\naligning text & visual modalities into a common embedding space. However, the\nalignment objective used to train CLIP often results in subpar visual features\nfor fine-grained tasks. In contrast, SSL-pretrained models like DINO excel at\nextracting rich visual features due to their specialized training paradigm.\nYet, these SSL models require an additional supervised linear probing step,\nwhich relies on fully labeled data which is often expensive and difficult to\nobtain at scale. In this paper, we propose a label-free prompt-tuning method\nthat leverages the rich visual features of self-supervised learning models\n(DINO) and the broad textual knowledge of large language models (LLMs) to\nlargely enhance CLIP-based image classification performance using unlabeled\nimages. Our approach unfolds in three key steps: (1) We generate robust textual\nfeature embeddings that more accurately represent object classes by leveraging\nclass-specific descriptions from LLMs, enabling more effective zero-shot\nclassification compared to CLIP's default name-specific prompts. (2) These\ntextual embeddings are then used to produce pseudo-labels to train an alignment\nmodule that integrates the complementary strengths of LLM description-based\ntextual embeddings & DINO's visual features. (3) Finally, we prompt-tune CLIP's\nvision encoder through DINO-assisted supervision using the trained alignment\nmodule. This three-step process allows us to harness the best of visual &\ntextual foundation models, resulting in a powerful and efficient approach that\nsurpasses state-of-the-art label-free classification methods. Notably, our\nframework, NoLA (No Labels Attached), achieves an average absolute gain of 3.6%\nover the state-of-the-art LaFTer across 11 diverse image classification\ndatasets. Our code & models can be found at https://github.com/fazliimam/NoLA.\n","authors":["Mohamed Fazli Imam","Rufael Fedaku Marew","Jameel Hassan","Mustansar Fiaz","Alham Fikri Aji","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2411.19346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05213v1","updated":"2025-03-07T08:07:15Z","published":"2025-03-07T08:07:15Z","title":"Personalized Text Generation with Contrastive Activation Steering","summary":"  Personalized text generation aims to infer users' writing style preferences\nfrom their historical texts and generate outputs that faithfully reflect these\nstylistic characteristics. Existing solutions primarily adopt two paradigms:\nretrieval-augmented generation (RAG) and parameter-efficient fine-tuning\n(PEFT). While these approaches have advanced the field, they suffer from two\ncritical limitations: (1) the entanglement of content semantics and stylistic\npatterns in historical texts impedes accurate modeling of user-specific writing\npreferences; and (2) scalability challenges arising from both RAG's inference\nlatency by retrieval operations and PEFT's parameter storage requirements for\nper user model. To overcome these limitations, we propose StyleVector, a\ntraining-free framework that disentangles and represents personalized writing\nstyle as a vector in LLM's activation space, enabling style-steered generation\nduring inference without requiring costly retrieval or parameter storage.\nComprehensive experiments demonstrate that our framework achieves a significant\n8% relative improvement in personalized generation while reducing storage\nrequirements by 1700 times over PEFT method.\n","authors":["Jinghao Zhang","Yuting Liu","Wenjie Wang","Qiang Liu","Shu Wu","Liang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.05213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05212v1","updated":"2025-03-07T08:04:25Z","published":"2025-03-07T08:04:25Z","title":"Knowledge Updating? No More Model Editing! Just Selective Contextual\n  Reasoning","summary":"  As real-world knowledge evolves, the information embedded within large\nlanguage models (LLMs) can become outdated, inadequate, or erroneous. Model\nediting has emerged as a prominent approach for updating LLMs' knowledge with\nminimal computational costs and parameter changes. This approach typically\nidentifies and adjusts specific model parameters associated with newly acquired\nknowledge. However, existing methods often underestimate the adverse effects\nthat parameter modifications can have on broadly distributed knowledge. More\ncritically, post-edit LLMs frequently struggle with multi-hop reasoning and\ncontinuous knowledge updates. Although various studies have discussed these\nshortcomings, there is a lack of comprehensive evaluation. In this paper, we\nprovide an evaluation of ten model editing methods along four dimensions:\nreliability, generalization, locality, and portability. Results confirm that\nall ten popular model editing methods show significant shortcomings across\nmultiple dimensions, suggesting model editing is less promising. We then\npropose a straightforward method called Selective Contextual Reasoning (SCR),\nfor knowledge updating. SCR does not modify model parameters but harnesses\nLLM's inherent contextual reasoning capabilities utilizing the updated\nknowledge pieces. Under SCR, an LLM first assesses whether an incoming query\nfalls within the scope of an external knowledge base. If it does, the relevant\nexternal knowledge texts are contextualized to enhance reasoning; otherwise,\nthe query is answered directly. We evaluate SCR against the ten model editing\nmethods on two counterfactual datasets with three backbone LLMs. Empirical\nresults confirm the effectiveness and efficiency of contextual reasoning for\nknowledge updating.\n","authors":["Guoxiu He","Xin Song","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2503.05212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05203v1","updated":"2025-03-07T07:48:30Z","published":"2025-03-07T07:48:30Z","title":"Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge\n  Graph Retrieval-Augmented Generation","summary":"  Although Large Language Models achieve strong success in many tasks, they\nstill suffer from hallucinations and knowledge deficiencies in real-world\napplications. Many knowledge graph-based retrieval-augmented generation\n(KG-RAG) methods enhance the quality and credibility of LLMs by leveraging\nstructure and semantic information in KGs as external knowledge bases. However,\nthese methods struggle to effectively incorporate structure information, either\nincurring high computational costs or underutilizing available knowledge.\nInspired by smoothing operations in graph representation learning, we propose\npath pooling, a simple, train-free strategy that introduces structure\ninformation through a novel path-centric pooling operation. It seamlessly\nintegrates into existing KG-RAG methods in a plug-and-play manner, enabling\nricher structure information utilization. Extensive experiments demonstrate\nthat incorporating the path pooling into the state-of-the-art KG-RAG method\nconsistently improves performance across various settings while introducing\nnegligible additional cost. Code is coming soon at\nhttps://github.com/hrwang00/path-pooling.\n","authors":["Hairu Wang","Yuan Feng","Xike Xie","S Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05200v1","updated":"2025-03-07T07:44:31Z","published":"2025-03-07T07:44:31Z","title":"ORANSight-2.0: Foundational LLMs for O-RAN","summary":"  Despite the transformative impact of Large Language Models (LLMs) across\ncritical domains such as healthcare, customer service, and business marketing,\ntheir integration into Open Radio Access Networks (O-RAN) remains limited. This\ngap is primarily due to the absence of domain-specific foundational models,\nwith existing solutions often relying on general-purpose LLMs that fail to\naddress the unique challenges and technical intricacies of O-RAN. To bridge\nthis gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative\naimed at developing specialized foundational LLMs tailored for O-RAN. Built on\n18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes\nmodels ranging from 1 to 70B parameters, significantly reducing reliance on\nproprietary, closed-source models while enhancing performance for O-RAN. At the\ncore of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation\n(RAG) based instruction-tuning framework that employs two LLM agents to create\nhigh-quality instruction-tuning datasets. The generated dataset is then used to\nfine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate\nORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code\ngeneration and codebase understanding in the context of srsRAN, a widely used\n5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for\nassessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate\nthat ORANSight-2.0 models outperform general-purpose and closed-source models,\nsuch as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on\nsrsRANBench, achieving superior performance while maintaining lower\ncomputational and energy costs. We also experiment with RAG-augmented variants\nof ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics,\ndemonstrating costs for training, standard inference, and RAG-augmented\ninference.\n","authors":["Pranshav Gajjar","Vijay K. Shah"],"pdf_url":"https://arxiv.org/pdf/2503.05200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05193v1","updated":"2025-03-07T07:28:32Z","published":"2025-03-07T07:28:32Z","title":"Memory-augmented Query Reconstruction for LLM-based Knowledge Graph\n  Reasoning","summary":"  Large language models (LLMs) have achieved remarkable performance on\nknowledge graph question answering (KGQA) tasks by planning and interacting\nwith knowledge graphs. However, existing methods often confuse tool utilization\nwith knowledge reasoning, harming readability of model outputs and giving rise\nto hallucinatory tool invocations, which hinder the advancement of KGQA. To\naddress this issue, we propose Memory-augmented Query Reconstruction for\nLLM-based Knowledge Graph Reasoning (MemQ) to decouple LLM from tool invocation\ntasks using LLM-built query memory. By establishing a memory module with\nexplicit descriptions of query statements, the proposed MemQ facilitates the\nKGQA process with natural language reasoning and memory-augmented query\nreconstruction. Meanwhile, we design an effective and readable reasoning to\nenhance the LLM's reasoning capability in KGQA. Experimental results that MemQ\nachieves state-of-the-art performance on widely used benchmarks WebQSP and CWQ.\n","authors":["Mufan Xu","Gewen Liang","Kehai Chen","Wei Wang","Xun Zhou","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05188v1","updated":"2025-03-07T07:20:24Z","published":"2025-03-07T07:20:24Z","title":"Rewarding Curse: Analyze and Mitigate Reward Modeling Issues for LLM\n  Reasoning","summary":"  Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.\n","authors":["Jiachun Li","Pengfei Cao","Yubo Chen","Jiexin Xu","Huaijun Li","Xiaojian Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05188v1.pdf","comment":"18 pages, 21 figures"},{"id":"http://arxiv.org/abs/2412.12643v2","updated":"2025-03-07T07:14:33Z","published":"2024-12-17T08:07:16Z","title":"LLM-based Discriminative Reasoning for Knowledge Graph Question\n  Answering","summary":"  Large language models (LLMs) based on generative pre-trained Transformer have\nachieved remarkable performance on knowledge graph question-answering (KGQA)\ntasks. However, LLMs often produce ungrounded subgraph planning or reasoning\nresults in KGQA due to the hallucinatory behavior brought by the generative\nparadigm. To tackle this issue, we propose READS to reformulate the KGQA\nprocess into discriminative subtasks, which simplifies the search space for\neach subtasks. Based on the subtasks, we design a new corresponding\ndiscriminative inference strategy to conduct the reasoning for KGQA, thereby\nalleviating hallucination and ungrounded reasoning issues in LLMs. Experimental\nresults show that the proposed approach outperforms multiple strong comparison\nmethods, along with achieving state-of-the-art performance on widely used\nbenchmarks WebQSP and CWQ.\n","authors":["Mufan Xu","Kehai Chen","Xuefeng Bai","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.12643v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05179v1","updated":"2025-03-07T06:57:17Z","published":"2025-03-07T06:57:17Z","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching","summary":"  Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.\n","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02295v2","updated":"2025-03-07T06:16:34Z","published":"2025-01-04T14:08:52Z","title":"Explicit vs. Implicit: Investigating Social Bias in Large Language\n  Models through Self-Reflection","summary":"  Large Language Models (LLMs) have been shown to exhibit various biases and\nstereotypes in their generated content. While extensive research has\ninvestigated bias in LLMs, prior work has predominantly focused on explicit\nbias, leaving the more nuanced implicit biases largely unexplored. This paper\npresents a systematic framework grounded in social psychology theories to\ninvestigate and compare explicit and implicit biases in LLMs. We propose a\nnovel \"self-reflection\" based evaluation framework that operates in two phases:\nfirst measuring implicit bias through simulated psychological assessment\nmethods, then evaluating explicit bias by prompting LLMs to analyze their own\ngenerated content. Through extensive experiments on state-of-the-art LLMs\nacross multiple social dimensions, we demonstrate that LLMs exhibit a\nsubstantial inconsistency between explicit and implicit biases, where explicit\nbiases manifest as mild stereotypes while implicit biases show strong\nstereotypes. Furthermore, we investigate the underlying factors contributing to\nthis explicit-implicit bias inconsistency. Our experiments examine the effects\nof training data scale, model parameters, and alignment techniques. Results\nindicate that while explicit bias diminishes with increased training data and\nmodel size, implicit bias exhibits a contrasting upward trend. Notably,\ncontemporary alignment methods (e.g., RLHF, DPO) effectively suppress explicit\nbias but show limited efficacy in mitigating implicit bias. These findings\nsuggest that while scaling up models and alignment training can address\nexplicit bias, the challenge of implicit bias requires novel approaches beyond\ncurrent methodologies.\n","authors":["Yachao Zhao","Bo Wang","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2501.02295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11142v3","updated":"2025-03-07T06:06:29Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00691v2","updated":"2025-03-07T05:38:47Z","published":"2025-03-02T02:04:58Z","title":"How Diversely Can Language Models Solve Problems? Exploring the\n  Algorithmic Diversity of Model-Generated Code","summary":"  Language models (LMs) have exhibited impressive abilities in generating code\nfrom natural language requirements. In this work, we highlight the diversity of\ncode generated by LMs as a critical criterion for evaluating their code\ngeneration capabilities. There is a lack of studies focused on assessing the\ndiversity of generated code, which overlooks its importance in code LMs.\nTherefore, we propose a systematic approach to evaluate code diversity,\nintroducing various metrics with inter-code similarity. Specifically, we\nintroduce code clustering methods that leverages LMs' capabilities in code\nunderstanding and reasoning, resulting in a set of metrics that represent the\nnumber of algorithms in model-generated solutions. We extensively investigate\nthe property of model-generated solutions by contrasting them with\nhuman-written ones and quantifying the impact of various factors on code\ndiversity: model size, temperature, instruction tuning, and problem complexity.\nOur analysis demonstrates that model-generated solutions exhibit low\nalgorithmic diversity, which was neglected by the research community. Moreover,\nwe explore methods to increase code diversity by combining solutions from\ndifferent models and increasing sampling temperatures. Our findings highlight\nthat code diversity can be enhanced with the help of heterogeneous models and\nsetting temperature beyond 1.0 that has not been fully explored due to the\nfunctional correctness degradation. To facilitate our research direction, we\npublicly share our code and datasets through open-source repositories.\n","authors":["Seonghyeon Lee","Heejae Chon","Joonwon Jang","Dongha Lee","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2503.00691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05157v1","updated":"2025-03-07T05:34:31Z","published":"2025-03-07T05:34:31Z","title":"Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting\n  Accuracy","summary":"  Language models are strong few-shot learners and achieve good overall\naccuracy in text classification tasks, masking the fact that their results\nsuffer from great class accuracy imbalance. We believe that the pursuit of\noverall accuracy should not come from enriching the strong classes, but from\nraising up the weak ones. To address the imbalance, we propose a post-hoc\nnonlinear integer programming based debiasing method that ensembles weight\ncorrection and membership correction to enable flexible rectifications of class\nprobabilities at both class and sample levels, enhancing the performance of\nLLMs directly from their outputs. Evaluations with Llama-2-13B on seven text\nclassification benchmarks show that our approach achieves state-of-the-art\noverall accuracy gains with balanced class accuracies. The resulted probability\ncorrection scheme demonstrates that sample-level corrections are necessary to\nelevate weak classes. In addition, due to effectively correcting weak classes,\nour method also brings significant performance gains to Llama-2-70B, especially\non a biomedical domain task, demonstrating its effectiveness across both small\nand large model variants.\n","authors":["Ruixi Lin","Ziqiao Wang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2503.05157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10510v3","updated":"2025-03-07T05:29:18Z","published":"2024-01-19T05:58:30Z","title":"When Large Language Models Meet Evolutionary Algorithms: Potential\n  Enhancements and Challenges","summary":"  Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.\n","authors":["Chao Wang","Jiaxuan Zhao","Licheng Jiao","Lingling Li","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2401.10510v3.pdf","comment":"The article has been accepted for publication in Research"},{"id":"http://arxiv.org/abs/2503.05150v1","updated":"2025-03-07T05:19:17Z","published":"2025-03-07T05:19:17Z","title":"Interpersonal Memory Matters: A New Task for Proactive Dialogue\n  Utilizing Conversational History","summary":"  Proactive dialogue systems aim to empower chatbots with the capability of\nleading conversations towards specific targets, thereby enhancing user\nengagement and service autonomy. Existing systems typically target pre-defined\nkeywords or entities, neglecting user attributes and preferences implicit in\ndialogue history, hindering the development of long-term user intimacy. To\naddress these challenges, we take a radical step towards building a more\nhuman-like conversational agent by integrating proactive dialogue systems with\nlong-term memory into a unified framework. Specifically, we define a novel task\nnamed Memory-aware Proactive Dialogue (MapDia). By decomposing the task, we\nthen propose an automatic data construction method and create the first Chinese\nMemory-aware Proactive Dataset (ChMapData). Furthermore, we introduce a joint\nframework based on Retrieval Augmented Generation (RAG), featuring three\nmodules: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting\nDetection and Generation, designed to steer dialogues towards relevant\nhistorical topics at the right time. The effectiveness of our dataset and\nmodels is validated through both automatic and human evaluations. We release\nthe open-source framework and dataset at\nhttps://github.com/FrontierLabs/MapDia.\n","authors":["Bowen Wu","Wenqing Wang","Haoran Li","Ying Li","Jingsong Yu","Baoxun Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04095v2","updated":"2025-03-07T05:18:44Z","published":"2025-03-06T05:08:40Z","title":"Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts","summary":"  Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.\n","authors":["Xiangnan Chen","Yuancheng Fang","Qian Xiao","Juncheng Li","Jun Lin","Siliang Tang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.04095v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.05142v1","updated":"2025-03-07T04:51:30Z","published":"2025-03-07T04:51:30Z","title":"RocketEval: Efficient Automated LLM Evaluation via Grading Checklist","summary":"  Evaluating large language models (LLMs) in diverse and challenging scenarios\nis essential to align them with human preferences. To mitigate the prohibitive\ncosts associated with human evaluations, utilizing a powerful LLM as a judge\nhas emerged as a favored approach. Nevertheless, this methodology encounters\nseveral challenges, including substantial expenses, concerns regarding privacy\nand security, and reproducibility. In this paper, we propose a straightforward,\nreplicable, and accurate automated evaluation method by leveraging a\nlightweight LLM as the judge, named RocketEval. Initially, we identify that the\nperformance disparity between lightweight and powerful LLMs in evaluation tasks\nprimarily stems from their ability to conduct comprehensive analyses, which is\nnot easily enhanced through techniques such as chain-of-thought reasoning. By\nreframing the evaluation task as a multi-faceted Q&A using an instance-specific\nchecklist, we demonstrate that the limited judgment accuracy of lightweight\nLLMs is largely attributes to high uncertainty and positional bias. To address\nthese challenges, we introduce an automated evaluation process grounded in\nchecklist grading, which is designed to accommodate a variety of scenarios and\nquestions. This process encompasses the creation of checklists, the grading of\nthese checklists by lightweight LLMs, and the reweighting of checklist items to\nalign with the supervised annotations. Our experiments carried out on the\nautomated evaluation benchmarks, MT-Bench and WildBench datasets, reveal that\nRocketEval, when using Gemma-2-2B as the judge, achieves a high correlation\n(0.965) with human preferences, which is comparable to GPT-4o. Moreover,\nRocketEval provides a cost reduction exceeding 50-fold for large-scale\nevaluation and comparison scenarios. Our code is available at\nhttps://github.com/Joinn99/RocketEval-ICLR .\n","authors":["Tianjun Wei","Wei Wen","Ruizhi Qiao","Xing Sun","Jianghong Ma"],"pdf_url":"https://arxiv.org/pdf/2503.05142v1.pdf","comment":"Accepted by ICLR 2025: https://openreview.net/forum?id=zJjzNj6QUe"},{"id":"http://arxiv.org/abs/2503.05139v1","updated":"2025-03-07T04:43:39Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2409.11283v4","updated":"2025-03-07T04:29:19Z","published":"2024-09-17T15:38:36Z","title":"Zero-resource Hallucination Detection for Text Generation via\n  Graph-based Contextual Knowledge Triples Modeling","summary":"  LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.\n","authors":["Xinyue Fang","Zhen Huang","Zhiliang Tian","Minghui Fang","Ziyi Pan","Quntian Fang","Zhihua Wen","Hengyue Pan","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2409.11283v4.pdf","comment":"Accepted by AAAI25"},{"id":"http://arxiv.org/abs/2410.21357v4","updated":"2025-03-07T04:28:45Z","published":"2024-10-28T17:25:56Z","title":"Energy-Based Diffusion Language Models for Text Generation","summary":"  Despite remarkable progress in autoregressive language models, alternative\ngenerative paradigms beyond left-to-right generation are still being actively\nexplored. Discrete diffusion models, with the capacity for parallel generation,\nhave recently emerged as a promising alternative. Unfortunately, these models\nstill underperform the autoregressive counterparts, with the performance gap\nincreasing when reducing the number of sampling steps. Our analysis reveals\nthat this degradation is a consequence of an imperfect approximation used by\ndiffusion models. In this work, we propose Energy-based Diffusion Language\nModel (EDLM), an energy-based model operating at the full sequence level for\neach diffusion step, introduced to improve the underlying approximation used by\ndiffusion models. More specifically, we introduce an EBM in a residual form,\nand show that its parameters can be obtained by leveraging a pretrained\nautoregressive model or by finetuning a bidirectional transformer via noise\ncontrastive estimation. We also propose an efficient generation algorithm via\nparallel important sampling. Comprehensive experiments on language modeling\nbenchmarks show that our model can consistently outperform state-of-the-art\ndiffusion models by a significant margin, and approaches autoregressive models'\nperplexity. We further show that, without any generation performance drop, our\nframework offers a 1.3$\\times$ sampling speedup over existing diffusion models.\nReproduced code is available at\nhttps://github.com/MinkaiXu/Energy-Diffusion-LLM.\n","authors":["Minkai Xu","Tomas Geffner","Karsten Kreis","Weili Nie","Yilun Xu","Jure Leskovec","Stefano Ermon","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.21357v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04723v2","updated":"2025-03-07T03:14:02Z","published":"2025-03-06T18:59:37Z","title":"Shifting Long-Context LLMs Research from Input to Output","summary":"  Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.\n","authors":["Yuhao Wu","Yushi Bai","Zhiqing Hu","Shangqing Tu","Ming Shan Hee","Juanzi Li","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04723v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.05102v1","updated":"2025-03-07T02:44:17Z","published":"2025-03-07T02:44:17Z","title":"AutoTestForge: A Multidimensional Automated Testing Framework for\n  Natural Language Processing Models","summary":"  In recent years, the application of behavioral testing in Natural Language\nProcessing (NLP) model evaluation has experienced a remarkable and substantial\ngrowth. However, the existing methods continue to be restricted by the\nrequirements for manual labor and the limited scope of capability assessment.\nTo address these limitations, we introduce AutoTestForge, an automated and\nmultidimensional testing framework for NLP models in this paper. Within\nAutoTestForge, through the utilization of Large Language Models (LLMs) to\nautomatically generate test templates and instantiate them, manual involvement\nis significantly reduced. Additionally, a mechanism for the validation of test\ncase labels based on differential testing is implemented which makes use of a\nmulti-model voting system to guarantee the quality of test cases. The framework\nalso extends the test suite across three dimensions, taxonomy, fairness, and\nrobustness, offering a comprehensive evaluation of the capabilities of NLP\nmodels. This expansion enables a more in-depth and thorough assessment of the\nmodels, providing valuable insights into their strengths and weaknesses. A\ncomprehensive evaluation across sentiment analysis (SA) and semantic textual\nsimilarity (STS) tasks demonstrates that AutoTestForge consistently outperforms\nexisting datasets and testing tools, achieving higher error detection rates (an\naverage of $30.89\\%$ for SA and $34.58\\%$ for STS). Moreover, different\ngeneration strategies exhibit stable effectiveness, with error detection rates\nranging from $29.03\\% - 36.82\\%$.\n","authors":["Hengrui Xing","Cong Tian","Liang Zhao","Zhi Ma","WenSheng Wang","Nan Zhang","Chao Huang","Zhenhua Duan"],"pdf_url":"https://arxiv.org/pdf/2503.05102v1.pdf","comment":"15 pages, 4 figures, Under review"},{"id":"http://arxiv.org/abs/2503.05096v1","updated":"2025-03-07T02:27:51Z","published":"2025-03-07T02:27:51Z","title":"SpecServe: Efficient and SLO-Aware Large Language Model Serving with\n  Adaptive Speculative Decoding","summary":"  Large Language Model (LLM) services often face challenges in achieving low\ninference latency and meeting Service Level Objectives (SLOs) under dynamic\nrequest patterns. Speculative decoding, which exploits lightweight models for\ndrafting and LLMs for verification, has emerged as a compelling technique to\naccelerate LLM inference. However, existing speculative decoding solutions\noften fail to adapt to varying workloads and system environments, resulting in\nperformance variability and SLO violations. In this paper, we introduce\nSpecServe, an efficient LLM inference system that dynamically adjusts\nspeculative strategies according to real-time request loads and system\nconfigurations. SpecServe proposes a theoretical model to understand and\npredict the efficiency of speculative decoding across diverse scenarios.\nAdditionally, it implements intelligent drafting and verification algorithms to\nguarantee optimal performance while achieving high SLO attainment. Experimental\nresults on real-world LLM traces demonstrate that SpecServe consistently meets\nSLOs and achieves substantial performance improvements, yielding\n1.14$\\times$-14.3$\\times$ speedups over state-of-the-art speculative inference\nsystems.\n","authors":["Kaiyu Huang","Hao Wu","Zhubo Shi","Han Zou","Minchen Yu","Qingjiang Shi"],"pdf_url":"https://arxiv.org/pdf/2503.05096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05085v1","updated":"2025-03-07T02:07:00Z","published":"2025-03-07T02:07:00Z","title":"S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following\n  with Paralinguistic Information","summary":"  The rapid development of large language models (LLMs) has brought significant\nattention to speech models, particularly recent progress in speech2speech\nprotocols supporting speech input and output. However, the existing benchmarks\nadopt automatic text-based evaluators for evaluating the instruction following\nability of these models lack consideration for paralinguistic information in\nboth speech understanding and generation. To address these issues, we introduce\nS2S-Arena, a novel arena-style S2S benchmark that evaluates\ninstruction-following capabilities with paralinguistic information in both\nspeech-in and speech-out across real-world tasks. We design 154 samples that\nfused TTS and live recordings in four domains with 21 tasks and manually\nevaluate existing popular speech models in an arena-style manner. The\nexperimental results show that: (1) in addition to the superior performance of\nGPT-4o, the speech model of cascaded ASR, LLM, and TTS outperforms the jointly\ntrained model after text-speech alignment in speech2speech protocols; (2)\nconsidering paralinguistic information, the knowledgeability of the speech\nmodel mainly depends on the LLM backbone, and the multilingual support of that\nis limited by the speech module; (3) excellent speech models can already\nunderstand the paralinguistic information in speech input, but generating\nappropriate audio with paralinguistic information is still a challenge.\n","authors":["Feng Jiang","Zhiyu Lin","Fan Bu","Yuhao Du","Benyou Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2503.05085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10541v2","updated":"2025-03-07T01:18:37Z","published":"2023-11-17T14:08:44Z","title":"Detection and Analysis of Offensive Online Content in Hausa Language","summary":"  Hausa, a major Chadic language spoken by over 100 million people mostly in\nWest Africa is considered a low-resource language from a computational\nlinguistic perspective. This classification indicates a scarcity of linguistic\nresources and tools necessary for handling various natural language processing\n(NLP) tasks, including the detection of offensive content. To address this gap,\nwe conducted two set of studies (1) a user study (n=101) to explore\ncyberbullying in Hausa and (2) an empirical study that led to the creation of\nthe first dataset of offensive terms in the Hausa language. We developed\ndetection systems trained on this dataset and compared their performance\nagainst relevant multilingual models, including Google Translate. Our detection\nsystem successfully identified over 70% of offensive, whereas baseline models\nfrequently mistranslated such terms. We attribute this discrepancy to the\nnuanced nature of the Hausa language and the reliance of baseline models on\ndirect or literal translation due to limited data to build purposive detection\nsystems. These findings highlight the importance of incorporating cultural\ncontext and linguistic nuances when developing NLP models for low-resource\nlanguages such as Hausa. A post hoc analysis further revealed that offensive\nlanguage is particularly prevalent in discussions related to religion and\npolitics. To foster a safer online environment, we recommend involving diverse\nstakeholders with expertise in local contexts and demographics. Their insights\nwill be crucial in developing more accurate detection systems and targeted\nmoderation strategies that align with cultural sensitivities.\n","authors":["Fatima Muhammad Adam","Abubakar Yakubu Zandam","Isa Inuwa-Dutse"],"pdf_url":"https://arxiv.org/pdf/2311.10541v2.pdf","comment":"21 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.05066v1","updated":"2025-03-07T01:11:39Z","published":"2025-03-07T01:11:39Z","title":"Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of\n  Experts","summary":"  The Mixture of Experts (MoE) is an effective architecture for scaling large\nlanguage models by leveraging sparse expert activation, optimizing the\ntrade-off between performance and efficiency. However, under expert\nparallelism, MoE suffers from inference inefficiencies due to imbalanced\ntoken-to-expert assignment, where some experts are overloaded while others\nremain underutilized. This imbalance leads to poor resource utilization and\nincreased latency, as the most burdened expert dictates the overall delay, a\nphenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate\nthis, we propose Capacity-Aware Inference, including two key techniques: (1)\n\\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens\nto regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware\nToken Reroute}}, which reallocates overflowed tokens to underutilized experts,\nbalancing the token distribution. These techniques collectively optimize both\nhigh-load and low-load expert utilization, leading to a more efficient MoE\ninference pipeline. Extensive experiments demonstrate the effectiveness of our\nmethods, showing significant improvements in inference efficiency, e.g., 0.2\\%\naverage performance increase and a 1.94$\\times$ inference speedup on\nMixtral-8$\\times$7B-Instruct.\n","authors":["Shwai He","Weilin Cai","Jiayi Huang","Ang Li"],"pdf_url":"https://arxiv.org/pdf/2503.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05065v1","updated":"2025-03-07T01:05:46Z","published":"2025-03-07T01:05:46Z","title":"The study of short texts in digital politics: Document aggregation for\n  topic modeling","summary":"  Statistical topic modeling is widely used in political science to study text.\nResearchers examine documents of varying lengths, from tweets to speeches.\nThere is ongoing debate on how document length affects the interpretability of\ntopic models. We investigate the effects of aggregating short documents into\nlarger ones based on natural units that partition the corpus. In our study, we\nanalyze one million tweets by U.S. state legislators from April 2016 to\nSeptember 2020. We find that for documents aggregated at the account level,\ntopics are more associated with individual states than when using individual\ntweets. This finding is replicated with Wikipedia pages aggregated by birth\ncities, showing how document definitions can impact topic modeling results.\n","authors":["Nitheesha Nakka","Omer F. Yalcin","Bruce A. Desmarais","Sarah Rajtmajer","Burt Monroe"],"pdf_url":"https://arxiv.org/pdf/2503.05065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05061v1","updated":"2025-03-07T00:42:08Z","published":"2025-03-07T00:42:08Z","title":"No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding","summary":"  LLM-as-a-Judge is a framework that uses an LLM (large language model) to\nevaluate the quality of natural language text - typically text that is also\ngenerated by an LLM. This framework holds great promise due to its relative\nlow-cost, ease of use, and strong correlations with human stylistic\npreferences. However, LLM Judges have been shown to exhibit biases that can\ndistort their judgments. We evaluate how well LLM Judges can grade whether a\ngiven response to a conversational question is correct, an ability crucial to\nsoundly estimating the overall response quality. To do so, we create and\npublicly release a human-annotated dataset with labels of correctness for 1,200\nLLM responses. We source questions from a combination of existing datasets and\na novel, challenging benchmark (BFF-Bench) created for this analysis. We\ndemonstrate a strong connection between an LLM's ability to correctly answer a\nquestion and grade responses to that question. Although aggregate level\nstatistics might imply a judge has high agreement with human annotators, it\nwill struggle on the subset of questions it could not answer. To address this\nissue, we recommend a simple solution: provide the judge with a correct,\nhuman-written reference answer. We perform an in-depth analysis on how\nreference quality can affect the performance of an LLM Judge. We show that\nproviding a weaker judge (e.g. Qwen 2.5 7B) with higher quality references\nreaches better agreement with human annotators than a stronger judge (e.g.\nGPT-4o) with synthetic references.\n","authors":["Michael Krumdick","Charles Lovering","Varshini Reddy","Seth Ebner","Chris Tanner"],"pdf_url":"https://arxiv.org/pdf/2503.05061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05060v1","updated":"2025-03-07T00:28:08Z","published":"2025-03-07T00:28:08Z","title":"ModernBERT is More Efficient than Conventional BERT for Chest CT\n  Findings Classification in Japanese Radiology Reports","summary":"  Objective: This study aims to evaluate and compare the performance of two\nJapanese language models-conventional Bidirectional Encoder Representations\nfrom Transformers (BERT) and the newer ModernBERT-in classifying findings from\nchest CT reports, with a focus on tokenization efficiency, processing time, and\nclassification performance. Methods: We conducted a retrospective study using\nthe CT-RATE-JPN dataset containing 22,778 training reports and 150 test\nreports. Both models were fine-tuned for multi-label classification of 18\ncommon chest CT conditions. The training data was split in 18,222:4,556 for\ntraining and validation. Performance was evaluated using F1 scores for each\ncondition and exact match accuracy across all 18 labels. Results: ModernBERT\ndemonstrated superior tokenization efficiency, requiring 24.0% fewer tokens per\ndocument (258.1 vs. 339.6) compared to BERT Base. This translated to\nsignificant performance improvements, with ModernBERT completing training in\n1877.67 seconds versus BERT's 3090.54 seconds (39% reduction). ModernBERT\nprocessed 38.82 samples per second during training (1.65x faster) and 139.90\nsamples per second during inference (1.66x faster). Despite these efficiency\ngains, classification performance remained comparable, with ModernBERT\nachieving superior F1 scores in 8 conditions, while BERT performed better in 4\nconditions. Overall exact match accuracy was slightly higher for ModernBERT\n(74.67% vs. 72.67%), though this difference was not statistically significant\n(p=0.6291). Conclusion: ModernBERT offers substantial improvements in\ntokenization efficiency and training speed without sacrificing classification\nperformance. These results suggest that ModernBERT is a promising candidate for\nclinical applications in Japanese radiology reports analysis.\n","authors":["Yosuke Yamagishi","Tomohiro Kikuchi","Shouhei Hanaoka","Takeharu Yoshikawa","Osamu Abe"],"pdf_url":"https://arxiv.org/pdf/2503.05060v1.pdf","comment":"23 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.05980v1","updated":"2025-03-07T23:25:19Z","published":"2025-03-07T23:25:19Z","title":"SINdex: Semantic INconsistency Index for Hallucination Detection in LLMs","summary":"  Large language models (LLMs) are increasingly deployed across diverse\ndomains, yet they are prone to generating factually incorrect outputs -\ncommonly known as \"hallucinations.\" Among existing mitigation strategies,\nuncertainty-based methods are particularly attractive due to their ease of\nimplementation, independence from external data, and compatibility with\nstandard LLMs. In this work, we introduce a novel and scalable\nuncertainty-based semantic clustering framework for automated hallucination\ndetection. Our approach leverages sentence embeddings and hierarchical\nclustering alongside a newly proposed inconsistency measure, SINdex, to yield\nmore homogeneous clusters and more accurate detection of hallucination\nphenomena across various LLMs. Evaluations on prominent open- and closed-book\nQA datasets demonstrate that our method achieves AUROC improvements of up to\n9.3% over state-of-the-art techniques. Extensive ablation studies further\nvalidate the effectiveness of each component in our framework.\n","authors":["Samir Abdaljalil","Hasan Kurban","Parichit Sharma","Erchin Serpedin","Rachad Atat"],"pdf_url":"https://arxiv.org/pdf/2503.05980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15018v2","updated":"2025-03-07T22:41:19Z","published":"2024-07-21T00:10:23Z","title":"Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice\n  Questions","summary":"  Multiple-choice question answering (MCQA) is a key competence of performant\ntransformer language models that is tested by mainstream benchmarks. However,\nrecent evidence shows that models can have quite a range of performance,\nparticularly when the task format is diversified slightly (such as by shuffling\nanswer choice order). In this work we ask: how do successful models perform\nformatted MCQA? We employ vocabulary projection and activation patching methods\nto localize key hidden states that encode relevant information for predicting\nthe correct answer. We find that the prediction of a specific answer symbol is\ncausally attributed to a few middle layers, and specifically their multi-head\nself-attention mechanisms. We show that subsequent layers increase the\nprobability of the predicted answer symbol in vocabulary space, and that this\nprobability increase is associated with a sparse set of attention heads with\nunique roles. We additionally uncover differences in how different models\nadjust to alternative symbols. Finally, we demonstrate that a synthetic task\ncan disentangle sources of model error to pinpoint when a model has learned\nformatted MCQA, and show that logit differences between answer choice tokens\ncontinue to grow over the course of training.\n","authors":["Sarah Wiegreffe","Oyvind Tafjord","Yonatan Belinkov","Hannaneh Hajishirzi","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2407.15018v2.pdf","comment":"ICLR 2025 (spotlight). Substantially updated from previous preprint\n  to contain experiments on 4-way multiple-choice with various answer choice\n  symbols, 3 open model families, and extensive activation patching results,\n  including on individual attention heads"},{"id":"http://arxiv.org/abs/2503.03874v2","updated":"2025-03-07T22:25:17Z","published":"2025-03-05T20:09:59Z","title":"LEWIS (LayEr WIse Sparsity) -- A Training Free Guided Model Merging\n  Approach","summary":"  As specialized large language models (LLMs) become increasingly prevalent,\nmodel merging methods are being used to combine them to create a single\nmulti-task model without requiring any additional data or training. However,\nthese approaches fall short when the objective of merging is to increase the\ndownstream model's performance on a particular task-specific benchmark. In this\nwork, we propose LEWIS (Layer Wise Sparsity), a guided model-merging framework\nthat uses activation-based layer importance to dynamically adjust layer-wise\ntask-vector sparsity required for the merge process. LEWIS uses a calibration\ndataset to prioritize critical layers during the task-vector pruning process\nrequired for model merging. This approach guides existing merging methods by\npreserving essential layer-wise task-specific knowledge while ensuring the\nmerged model performs the best at benchmarks resembling the calibration\ndataset. Our experiments demonstrate the effectiveness of LEWIS with\nperformance improvements of code instruction-following and math-solving models\ncreated through model merging up to 4 percent and 11.3 percent, respectively,\noutperforming unguided data-less model merging approaches that use\nuniform-sparsity.\n","authors":["Hetarth Chopra","Vidhi Rambhia","Vikram Adve"],"pdf_url":"https://arxiv.org/pdf/2503.03874v2.pdf","comment":"Accepted at ICLR 2025 Workshop: SLLM (Sparsity in Large Language\n  Models)"},{"id":"http://arxiv.org/abs/2503.00203v3","updated":"2025-03-07T22:12:14Z","published":"2025-02-28T21:39:22Z","title":"Llamarine: Open-source Maritime Industry-specific Large Language Model","summary":"  Large Language Models (LLMs) have demonstrated substantial potential in\naddressing complex reasoning tasks, yet their general-purpose nature often\nlimits their effectiveness in specialized domains such as maritime navigation.\nTo bridge this gap, we introduce Llamarine, the first open-source LLM designed\nspecifically for maritime navigation. Llamarine 1.0 is developed through\ncontinued pretraining and fine-tuning on a high-quality corpus comprising\nmaritime textbooks, research publications, and web text from Wikipedia. This\ndomain-specific training enables the model to acquire expert-level knowledge in\nnavigational principles, collision avoidance, route optimization, and\nregulatory compliance. Our key contributions include (a) the curation of a\ncomprehensive maritime dataset from authoritative sources, ensuring depth and\nreliability in the model's knowledge base; (b) the development of a\nfoundational model capable of reasoning about complex navigational challenges\nwith greater accuracy than general-purpose LLMs; and (c) the establishment of a\nbenchmark to evaluate performance in maritime-specific decision-making tasks.\nExperimental results demonstrate that Llamarine outperforms both\ngeneral-purpose and commercial LLMs in critical navigation-related tasks, such\nas trajectory planning, risk assessment, and compliance with maritime\nregulations. By providing an open-source foundation model trained exclusively\non high-quality maritime literature, Llamarine paves the way for AI-driven\nadvancements in maritime safety, efficiency, and operational decision-making.\n","authors":["William Nguyen","An Phan","Konobu Kimura","Hitoshi Maeno","Mika Tanaka","Quynh Le","William Poucher","Christopher Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.00203v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.08793v2","updated":"2025-03-07T22:09:42Z","published":"2024-10-11T13:20:54Z","title":"On the State of NLP Approaches to Modeling Depression in Social Media: A\n  Post-COVID-19 Outlook","summary":"  Computational approaches to predicting mental health conditions in social\nmedia have been substantially explored in the past years. Multiple reviews have\nbeen published on this topic, providing the community with comprehensive\naccounts of the research in this area. Among all mental health conditions,\ndepression is the most widely studied due to its worldwide prevalence. The\nCOVID-19 global pandemic, starting in early 2020, has had a great impact on\nmental health worldwide. Harsh measures employed by governments to slow the\nspread of the virus (e.g., lockdowns) and the subsequent economic downturn\nexperienced in many countries have significantly impacted people's lives and\nmental health. Studies have shown a substantial increase of above 50% in the\nrate of depression in the population. In this context, we present a review on\nnatural language processing (NLP) approaches to modeling depression in social\nmedia, providing the reader with a post-COVID-19 outlook. This review\ncontributes to the understanding of the impacts of the pandemic on modeling\ndepression in social media. We outline how state-of-the-art approaches and new\ndatasets have been used in the context of the COVID-19 pandemic. Finally, we\nalso discuss ethical issues in collecting and processing mental health data,\nconsidering fairness, accountability, and ethics.\n","authors":["Ana-Maria Bucur","Andreea-Codrina Moldovan","Krutika Parvatikar","Marcos Zampieri","Ashiqur R. KhudaBukhsh","Liviu P. Dinu"],"pdf_url":"https://arxiv.org/pdf/2410.08793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05958v1","updated":"2025-03-07T21:52:32Z","published":"2025-03-07T21:52:32Z","title":"SANDWiCH: Semantical Analysis of Neighbours for Disambiguating Words in\n  Context ad Hoc","summary":"  The rise of generative chat-based Large Language Models (LLMs) over the past\ntwo years has spurred a race to develop systems that promise near-human\nconversational and reasoning experiences. However, recent studies indicate that\nthe language understanding offered by these models remains limited and far from\nhuman-like performance, particularly in grasping the contextual meanings of\nwords, an essential aspect of reasoning. In this paper, we present a simple yet\ncomputationally efficient framework for multilingual Word Sense Disambiguation\n(WSD). Our approach reframes the WSD task as a cluster discrimination analysis\nover a semantic network refined from BabelNet using group algebra. We validate\nour methodology across multiple WSD benchmarks, achieving a new state of the\nart for all languages and tasks, as well as in individual assessments by part\nof speech. Notably, our model significantly surpasses the performance of\ncurrent alternatives, even in low-resource languages, while reducing the\nparameter count by 72%.\n","authors":["Daniel Guzman-Olivares","Lara Quijano-Sanchez","Federico Liberatore"],"pdf_url":"https://arxiv.org/pdf/2503.05958v1.pdf","comment":"15 pages, 2 figures, 7 tables, NAACL 2025"},{"id":"http://arxiv.org/abs/2503.05935v1","updated":"2025-03-07T21:11:35Z","published":"2025-03-07T21:11:35Z","title":"DETQUS: Decomposition-Enhanced Transformers for QUery-focused\n  Summarization","summary":"  Query-focused tabular summarization is an emerging task in table-to-text\ngeneration that synthesizes a summary response from tabular data based on user\nqueries. Traditional transformer-based approaches face challenges due to token\nlimitations and the complexity of reasoning over large tables. To address these\nchallenges, we introduce DETQUS (Decomposition-Enhanced Transformers for\nQUery-focused Summarization), a system designed to improve summarization\naccuracy by leveraging tabular decomposition alongside a fine-tuned\nencoder-decoder model. DETQUS employs a large language model to selectively\nreduce table size, retaining only query-relevant columns while preserving\nessential information. This strategy enables more efficient processing of large\ntables and enhances summary quality. Our approach, equipped with table-based QA\nmodel Omnitab, achieves a ROUGE-L score of 0.4437, outperforming the previous\nstate-of-the-art REFACTOR model (ROUGE-L: 0.422). These results highlight\nDETQUS as a scalable and effective solution for query-focused tabular\nsummarization, offering a structured alternative to more complex architectures.\n","authors":["Yasir Khan","Xinlei Wu","Sangpil Youm","Justin Ho","Aryaan Shaikh","Jairo Garciga","Rohan Sharma","Bonnie J. Dorr"],"pdf_url":"https://arxiv.org/pdf/2503.05935v1.pdf","comment":"12 pages, 2 figures, Accepted to NAACL 2025 main conference"},{"id":"http://arxiv.org/abs/2503.05931v1","updated":"2025-03-07T20:57:43Z","published":"2025-03-07T20:57:43Z","title":"Training and Inference Efficiency of Encoder-Decoder Speech Models","summary":"  Attention encoder-decoder model architecture is the backbone of several\nrecent top performing foundation speech models: Whisper, Seamless, OWSM, and\nCanary-1B. However, the reported data and compute requirements for their\ntraining are prohibitive for many in the research community. In this work, we\nfocus on the efficiency angle and ask the questions of whether we are training\nthese speech models efficiently, and what can we do to improve? We argue that a\nmajor, if not the most severe, detrimental factor for training efficiency is\nrelated to the sampling strategy of sequential data. We show that negligence in\nmini-batch sampling leads to more than 50% computation being spent on padding.\nTo that end, we study, profile, and optimize Canary-1B training to show gradual\nimprovement in GPU utilization leading up to 5x increase in average batch sizes\nversus its original training settings. This in turn allows us to train an\nequivalent model using 4x less GPUs in the same wall time, or leverage the\noriginal resources and train it in 2x shorter wall time. Finally, we observe\nthat the major inference bottleneck lies in the autoregressive decoder steps.\nWe find that adjusting the model architecture to transfer model parameters from\nthe decoder to the encoder results in a 3x inference speedup as measured by\ninverse real-time factor (RTFx) while preserving the accuracy and compute\nrequirements for convergence. The training code and models will be available as\nopen-source.\n","authors":["Piotr Żelasko","Kunal Dhawan","Daniel Galvez","Krishna C. Puvvada","Ankita Pasad","Nithin Rao Koluguri","Ke Hu","Vitaly Lavrukhin","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2503.05931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05919v1","updated":"2025-03-07T20:35:31Z","published":"2025-03-07T20:35:31Z","title":"From Style to Facts: Mapping the Boundaries of Knowledge Injection with\n  Finetuning","summary":"  Finetuning provides a scalable and cost-effective means of customizing\nlanguage models for specific tasks or response styles, with greater reliability\nthan prompting or in-context learning. In contrast, the conventional wisdom is\nthat injecting knowledge via finetuning results in brittle performance and poor\ngeneralization. We argue that the dichotomy of \"task customization\" (e.g.,\ninstruction tuning) and \"knowledge injection\" (e.g., teaching new facts) is a\ndistinction without a difference. We instead identify concrete factors that\nexplain the heterogeneous effectiveness observed with finetuning. To this end,\nwe conduct a large-scale experimental study of finetuning the frontier Gemini\nv1.5 model family on a spectrum of datasets that are artificially engineered to\ninterpolate between the strengths and failure modes of finetuning. Our findings\nindicate that question-answer training data formats provide much stronger\nknowledge generalization than document/article-style training data, numerical\ninformation can be harder for finetuning to retain than categorical\ninformation, and models struggle to apply finetuned knowledge during multi-step\nreasoning even when trained on similar examples -- all factors that render\n\"knowledge injection\" to be especially difficult, even after controlling for\nconsiderations like data augmentation and information volume. On the other\nhand, our findings also indicate that it is not fundamentally more difficult to\nfinetune information about a real-world event than information about what a\nmodel's writing style should be.\n","authors":["Eric Zhao","Pranjal Awasthi","Nika Haghtalab"],"pdf_url":"https://arxiv.org/pdf/2503.05919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05920v1","updated":"2025-03-07T20:35:31Z","published":"2025-03-07T20:35:31Z","title":"IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative\n  Language Model Pretraining","summary":"  Recent advancements in large language models have intensified the need for\nefficient and deployable models within limited inference budgets. Structured\npruning pipelines have shown promise in token efficiency compared to training\ntarget-size models from scratch. In this paper, we advocate incorporating\nenlarged model pretraining, which is often ignored in previous works, into\npruning. We study the enlarge-and-prune pipeline as an integrated system to\naddress two critical questions: whether it is worth pretraining an enlarged\nmodel even when the model is never deployed, and how to optimize the entire\npipeline for better pruned models. We propose an integrated enlarge-and-prune\npipeline, which combines enlarge model training, pruning, and recovery under a\nsingle cosine annealing learning rate schedule. This approach is further\ncomplemented by a novel iterative structured pruning method for gradual\nparameter removal. The proposed method helps to mitigate the knowledge loss\ncaused by the rising learning rate in naive enlarge-and-prune pipelines and\nenable effective redistribution of model capacity among surviving neurons,\nfacilitating smooth compression and enhanced performance. We conduct\ncomprehensive experiments on compressing 2.8B models to 1.3B with up to 2T\ntokens in pretraining. It demonstrates the integrated approach not only\nprovides insights into the token efficiency of enlarged model pretraining but\nalso achieves superior performance of pruned models.\n","authors":["Yixiao Li","Xianzhi Du","Ajay Jaiswal","Tao Lei","Tuo Zhao","Chong Wang","Jianyu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05920v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19865v2","updated":"2025-03-07T20:33:35Z","published":"2024-11-29T17:27:05Z","title":"Reverse Thinking Makes LLMs Stronger Reasoners","summary":"  Reverse thinking plays a crucial role in human reasoning. Humans can reason\nnot only from a problem to a solution but also in reverse, i.e., start from the\nsolution and reason towards the problem. This often enhances overall reasoning\nperformance as it enables consistency checks between their forward and backward\nthinking. To enable Large Language Models (LLMs) to perform reverse thinking,\nwe introduce Reverse-Enhanced Thinking (RevThink), a framework composed of data\naugmentation and learning objectives. In RevThink, we augment the dataset by\ncollecting structured forward-backward reasoning from a teacher model,\nconsisting of: (1) the original question, (2) forward reasoning, (3) backward\nquestion, and (4) backward reasoning. We then employ three objectives to train\na smaller student model in a multi-task learning fashion: (a) generate forward\nreasoning from a question, (b) generate a backward question from a question,\nand (c) generate backward reasoning from the backward question. Experiments\nacross 12 datasets covering commonsense, math, and logical reasoning show an\naverage 13.53% improvement over the student model's zero-shot performance and a\n6.84% improvement over the strongest knowledge distillation baselines.\nMoreover, our method demonstrates sample efficiency -- using only 10% of the\ncorrect forward reasoning from the training data, it outperforms a standard\nfine-tuning method trained on 10x more forward reasoning. RevThink also\nexhibits strong generalization to out-of-distribution held-out datasets.\n","authors":["Justin Chih-Yao Chen","Zifeng Wang","Hamid Palangi","Rujun Han","Sayna Ebrahimi","Long Le","Vincent Perot","Swaroop Mishra","Mohit Bansal","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2411.19865v2.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2407.19580v3","updated":"2025-03-07T20:12:27Z","published":"2024-07-28T20:39:16Z","title":"Mini-batch Coresets for Memory-efficient Language Model Training on Data\n  Mixtures","summary":"  Training with larger mini-batches improves the convergence rate and can yield\nsuperior performance. However, training with large mini-batches becomes\nprohibitive for Large Language Models (LLMs), due to the large GPU memory\nrequirement. To address this problem, an effective approach is finding small\nmini-batch coresets that closely match the gradient of larger mini-batches.\nHowever, this approach becomes infeasible and ineffective for LLMs, due to the\nhighly imbalanced mixture of sources in language data, use of the Adam\noptimizer, and the very large gradient dimensionality of LLMs. In this work, we\naddress the above challenges by proposing Coresets for Training LLMs (CoLM).\nFirst, we show that mini-batch coresets found by gradient matching do not\ncontain representative examples of the small sources w.h.p., and thus including\nall examples of the small sources in the mini-batch coresets is crucial for\noptimal performance. Second, we normalize the gradients by their historical\nexponential to find mini-batch coresets for training with Adam. Finally, we\nleverage zeroth-order methods to find smooth gradient of the last V-projection\nmatrix and sparsify it to keep the dimensions with the largest normalized\ngradient magnitude. We apply CoLM to fine-tuning Phi-2, Phi-3, Zephyr, and\nLlama-3 models with LoRA on MathInstruct and SuperGLUE benchmark. Remarkably,\nCoLM reduces the memory requirement of fine-tuning by 2x and even outperforms\ntraining with 4x larger mini-batches. Moreover, CoLM seamlessly integrates with\nexisting memory-efficient training methods like LoRA, further reducing the\nmemory requirements of training LLMs.\n","authors":["Dang Nguyen","Wenhan Yang","Rathul Anand","Yu Yang","Baharan Mirzasoleiman"],"pdf_url":"https://arxiv.org/pdf/2407.19580v3.pdf","comment":"21 pages, 6 figures, 9 tables"},{"id":"http://arxiv.org/abs/2409.15861v3","updated":"2025-03-07T19:50:00Z","published":"2024-09-24T08:33:41Z","title":"A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding","summary":"  Dialogue State Tracking (DST) is crucial for understanding user needs and\nexecuting appropriate system actions in task-oriented dialogues. Majority of\nexisting DST methods are designed to work within predefined ontologies and\nassume the availability of gold domain labels, struggling with adapting to new\nslots values. While Large Language Models (LLMs)-based systems show promising\nzero-shot DST performance, they either require extensive computational\nresources or they underperform existing fully-trained systems, limiting their\npracticality. To address these limitations, we propose a zero-shot,\nopen-vocabulary system that integrates domain classification and DST in a\nsingle pipeline. Our approach includes reformulating DST as a\nquestion-answering task for less capable models and employing self-refining\nprompts for more adaptable ones. Our system does not rely on fixed slot values\ndefined in the ontology allowing the system to adapt dynamically. We compare\nour approach with existing SOTA, and show that it provides up to 20% better\nJoint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,\nwith up to 90% fewer requests to the LLM API.\n","authors":["Abdulfattah Safa","Gözde Gül Şahin"],"pdf_url":"https://arxiv.org/pdf/2409.15861v3.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2408.11252v4","updated":"2025-03-07T19:28:58Z","published":"2024-08-21T00:17:59Z","title":"Counterfactuals As a Means for Evaluating Faithfulness of Attribution\n  Methods in Autoregressive Language Models","summary":"  Despite the widespread adoption of autoregressive language models,\nexplainability evaluation research has predominantly focused on span infilling\nand masked language models. Evaluating the faithfulness of an explanation\nmethod -- how accurately it explains the inner workings and decision-making of\nthe model -- is challenging because it is difficult to separate the model from\nits explanation. Most faithfulness evaluation techniques corrupt or remove\ninput tokens deemed important by a particular attribution (feature importance)\nmethod and observe the resulting change in the model's output. However, for\nautoregressive language models, this approach creates out-of-distribution\ninputs due to their next-token prediction training objective. In this study, we\npropose a technique that leverages counterfactual generation to evaluate the\nfaithfulness of attribution methods for autoregressive language models. Our\ntechnique generates fluent, in-distribution counterfactuals, making the\nevaluation protocol more reliable.\n","authors":["Sepehr Kamahi","Yadollah Yaghoobzadeh"],"pdf_url":"https://arxiv.org/pdf/2408.11252v4.pdf","comment":"Accepted to BlackboxNLP @ EMNLP 2024"},{"id":"http://arxiv.org/abs/2503.05891v1","updated":"2025-03-07T19:24:59Z","published":"2025-03-07T19:24:59Z","title":"MastermindEval: A Simple But Scalable Reasoning Benchmark","summary":"  Recent advancements in large language models (LLMs) have led to remarkable\nperformance across a wide range of language understanding and mathematical\ntasks. As a result, increasing attention has been given to assessing the true\nreasoning capabilities of LLMs, driving research into commonsense, numerical,\nlogical, and qualitative reasoning. However, with the rapid progress of\nreasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been\na growing demand for reasoning benchmarks that can keep pace with ongoing model\ndevelopments. In this paper, we introduce MastermindEval, a simple, scalable,\nand interpretable deductive reasoning benchmark inspired by the board game\nMastermind. Our benchmark supports two evaluation paradigms: (1) agentic\nevaluation, in which the model autonomously plays the game, and (2) deductive\nreasoning evaluation, in which the model is given a pre-played game state with\nonly one possible valid code to infer. In our experimental results we (1) find\nthat even easy Mastermind instances are difficult for current models and (2)\ndemonstrate that the benchmark is scalable to possibly more advanced models in\nthe future Furthermore, we investigate possible reasons why models cannot\ndeduce the final solution and find that current models are limited in deducing\nthe concealed code as the number of statement to combine information from is\nincreasing.\n","authors":["Jonas Golde","Patrick Haller","Fabio Barth","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2503.05891v1.pdf","comment":"9 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2503.05888v1","updated":"2025-03-07T19:21:59Z","published":"2025-03-07T19:21:59Z","title":"QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation","summary":"  While the Question Generation (QG) task has been increasingly adopted in\neducational assessments, its evaluation remains limited by approaches that lack\na clear connection to the educational values of test items. In this work, we\nintroduce test item analysis, a method frequently used by educators to assess\ntest question quality, into QG evaluation. Specifically, we construct pairs of\ncandidate questions that differ in quality across dimensions such as topic\ncoverage, item difficulty, item discrimination, and distractor efficiency. We\nthen examine whether existing QG evaluation approaches can effectively\ndistinguish these differences. Our findings reveal significant shortcomings in\nthese approaches with respect to accurately assessing test item quality in\nrelation to student performance. To address this gap, we propose a novel QG\nevaluation framework, QG-SMS, which leverages Large Language Model for Student\nModeling and Simulation to perform test item analysis. As demonstrated in our\nextensive experiments and human evaluation study, the additional perspectives\nintroduced by the simulated student profiles lead to a more effective and\nrobust assessment of test items.\n","authors":["Bang Nguyen","Tingting Du","Mengxia Yu","Lawrence Angrave","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.05888v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.05856v1","updated":"2025-03-07T14:46:39Z","published":"2025-03-07T14:46:39Z","title":"This Is Your Doge, If It Please You: Exploring Deception and Robustness\n  in Mixture of LLMs","summary":"  Mixture of large language model (LLMs) Agents (MoA) architectures achieve\nstate-of-the-art performance on prominent benchmarks like AlpacaEval 2.0 by\nleveraging the collaboration of multiple LLMs at inference time. Despite these\nsuccesses, an evaluation of the safety and reliability of MoA is missing. We\npresent the first comprehensive study of MoA's robustness against deceptive LLM\nagents that deliberately provide misleading responses. We examine factors like\nthe propagation of deceptive information, model size, and information\navailability, and uncover critical vulnerabilities. On AlpacaEval 2.0, the\npopular LLaMA 3.1-70B model achieves a length-controlled Win Rate (LC WR) of\n49.2% when coupled with 3-layer MoA (6 LLM agents). However, we demonstrate\nthat introducing only a $\\textit{single}$ carefully-instructed deceptive agent\ninto the MoA can reduce performance to 37.9%, effectively nullifying all MoA\ngains. On QuALITY, a multiple-choice comprehension task, the impact is also\nsevere, with accuracy plummeting by a staggering 48.5%. Inspired in part by the\nhistorical Doge of Venice voting process, designed to minimize influence and\ndeception, we propose a range of unsupervised defense mechanisms that recover\nmost of the lost performance.\n","authors":["Lorenz Wolf","Sangwoong Yoon","Ilija Bogunovic"],"pdf_url":"https://arxiv.org/pdf/2503.05856v1.pdf","comment":"35 pages, 9 figures, 16 tables"},{"id":"http://arxiv.org/abs/2503.05846v1","updated":"2025-03-07T06:05:34Z","published":"2025-03-07T06:05:34Z","title":"Extracting and Emulsifying Cultural Explanation to Improve Multilingual\n  Capability of LLMs","summary":"  Large Language Models (LLMs) have achieved remarkable success, but their\nEnglish-centric training data limits performance in non-English languages,\nhighlighting the need for enhancements in their multilingual capabilities.\nWhile some work on multilingual prompting methods handles non-English queries\nby utilizing English translations or restructuring them to more closely align\nwith LLM reasoning patterns, these works often overlook the importance of\ncultural context, limiting their effectiveness. To address this limitation, we\npropose EMCEI, a simple yet effective approach that improves LLMs' multilingual\ncapabilities by incorporating cultural context for more accurate and\nappropriate responses. Specifically, EMCEI follows a two-step process that\nfirst extracts relevant cultural context from the LLM's parametric knowledge\nvia prompting. Then, EMCEI employs an LLM-as-Judge mechanism to select the most\nappropriate response by balancing cultural relevance and reasoning ability.\nExperiments on diverse multilingual benchmarks show that EMCEI outperforms\nexisting baselines, demonstrating its effectiveness in handling multilingual\nqueries with LLMs.\n","authors":["Hamin Koo","Jaehyung Kim"],"pdf_url":"https://arxiv.org/pdf/2503.05846v1.pdf","comment":"under review, 18pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.05696v1","updated":"2025-03-07T18:58:23Z","published":"2025-03-07T18:58:23Z","title":"Multi-Fidelity Policy Gradient Algorithms","summary":"  Many reinforcement learning (RL) algorithms require large amounts of data,\nprohibiting their use in applications where frequent interactions with\noperational systems are infeasible, or high-fidelity simulations are expensive\nor unavailable. Meanwhile, low-fidelity simulators--such as reduced-order\nmodels, heuristic reward functions, or generative world models--can cheaply\nprovide useful data for RL training, even if they are too coarse for direct\nsim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL\nframework that mixes a small amount of data from the target environment with a\nlarge volume of low-fidelity simulation data to form unbiased, reduced-variance\nestimators (control variates) for on-policy policy gradients. We instantiate\nthe framework by developing multi-fidelity variants of two policy gradient\nalgorithms: REINFORCE and proximal policy optimization. Experimental results\nacross a suite of simulated robotics benchmark problems demonstrate that when\ntarget-environment samples are limited, MFPG achieves up to 3.9x higher reward\nand improves training stability when compared to baselines that only use\nhigh-fidelity data. Moreover, even when the baselines are given more\nhigh-fidelity samples--up to 10x as many interactions with the target\nenvironment--MFPG continues to match or outperform them. Finally, we observe\nthat MFPG is capable of training effective policies even when the low-fidelity\nenvironment is drastically different from the target environment. MFPG thus not\nonly offers a novel paradigm for efficient sim-to-real transfer but also\nprovides a principled approach to managing the trade-off between policy\nperformance and data collection costs.\n","authors":["Xinjie Liu","Cyrus Neary","Kushagra Gupta","Christian Ellis","Ufuk Topcu","David Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2503.05696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18668v2","updated":"2025-03-07T18:57:52Z","published":"2024-02-28T19:28:27Z","title":"Simple linear attention language models balance the recall-throughput\n  tradeoff","summary":"  Recent work has shown that attention-based language models excel at recall,\nthe ability to ground generations in tokens previously seen in context.\nHowever, the efficiency of attention-based models is bottle-necked during\ninference by the KV-cache's aggressive memory consumption. In this work, we\nexplore whether we can improve language model efficiency (e.g. by reducing\nmemory consumption) without compromising on recall. By applying experiments and\ntheory to a broad set of architectures, we identify a key tradeoff between a\nmodel's state size and recall ability. We show that efficient alternatives to\nattention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but\nstruggle at recall. We propose BASED a simple architecture combining linear and\nsliding window attention. By varying BASED window size and linear attention\nfeature dimension, we can dial the state size and traverse the pareto frontier\nof the recall-memory tradeoff curve, recovering the full quality of attention\non one end and the small state size of attention-alternatives on the other. We\ntrain language models up to 1.3b parameters and show that BASED matches the\nstrongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them\non real-world recall-intensive tasks by 6.22 accuracy points. Implementations\nof linear attention are often less efficient than optimized standard attention\nimplementations. To make BASED competitive, we develop IO-aware algorithms that\nenable 24x higher throughput on language generation than FlashAttention-2, when\ngenerating 1024 tokens using 1.3b parameter models. Code for this work is\nprovided at: https://github.com/HazyResearch/based.\n","authors":["Simran Arora","Sabri Eyuboglu","Michael Zhang","Aman Timalsina","Silas Alberti","Dylan Zinsley","James Zou","Atri Rudra","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2402.18668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05684v1","updated":"2025-03-07T18:49:57Z","published":"2025-03-07T18:49:57Z","title":"Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints","summary":"  Pre-trained foundation models can be adapted for specific tasks using\nLow-Rank Adaptation (LoRA). However, the fairness properties of these adapted\nclassifiers remain underexplored. Existing fairness-aware fine-tuning methods\nrely on direct access to sensitive attributes or their predictors, but in\npractice, these sensitive attributes are often held under strict consumer\nprivacy controls, and neither the attributes nor their predictors are available\nto model developers, hampering the development of fair models. To address this\nissue, we introduce a set of LoRA-based fine-tuning methods that can be trained\nin a distributed fashion, where model developers and fairness auditors\ncollaborate without sharing sensitive attributes or predictors. In this paper,\nwe evaluate three such methods - sensitive unlearning, adversarial training,\nand orthogonality loss - against a fairness-unaware baseline, using experiments\non the CelebA and UTK-Face datasets with an ImageNet pre-trained ViT-Base\nmodel. We find that orthogonality loss consistently reduces bias while\nmaintaining or improving utility, whereas adversarial training improves False\nPositive Rate Parity and Demographic Parity in some cases, and sensitive\nunlearning provides no clear benefit. In tasks where significant biases are\npresent, distributed fairness-aware fine-tuning methods can effectively\neliminate bias without compromising consumer privacy and, in most cases,\nimprove model utility.\n","authors":["Parameswaran Kamalaruban","Mark Anderson","Stuart Burrell","Maeve Madigan","Piotr Skalski","David Sutton"],"pdf_url":"https://arxiv.org/pdf/2503.05684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05683v1","updated":"2025-03-07T18:45:42Z","published":"2025-03-07T18:45:42Z","title":"Understanding the Limits of Lifelong Knowledge Editing in LLMs","summary":"  Keeping large language models factually up-to-date is crucial for deployment,\nyet costly retraining remains a challenge. Knowledge editing offers a promising\nalternative, but methods are only tested on small-scale or synthetic edit\nbenchmarks. In this work, we aim to bridge research into lifelong knowledge\nediting to real-world edits at practically relevant scale. We first introduce\nWikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to\nautomatically extend lifelong for future-proof benchmarking. In its first\ninstance, it includes over 500K question-answer pairs for knowledge editing\nalongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to\nstudy existing knowledge editing techniques' ability to incorporate large\nvolumes of real-world facts and contrast their capabilities to generic\nmodification techniques such as retrieval augmentation and continual finetuning\nto acquire a complete picture of the practical extent of current lifelong\nknowledge editing.\n","authors":["Lukas Thede","Karsten Roth","Matthias Bethge","Zeynep Akata","Tom Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.05683v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2501.10605v2","updated":"2025-03-07T18:35:41Z","published":"2025-01-17T23:37:21Z","title":"Wasserstein Adaptive Value Estimation for Actor-Critic Reinforcement\n  Learning","summary":"  We present Wasserstein Adaptive Value Estimation for Actor-Critic (WAVE), an\napproach to enhance stability in deep reinforcement learning through adaptive\nWasserstein regularization. Our method addresses the inherent instability of\nactor-critic algorithms by incorporating an adaptively weighted Wasserstein\nregularization term into the critic's loss function. We prove that WAVE\nachieves $\\mathcal{O}\\left(\\frac{1}{k}\\right)$ convergence rate for the\ncritic's mean squared error and provide theoretical guarantees for stability\nthrough Wasserstein-based regularization. Using the Sinkhorn approximation for\ncomputational efficiency, our approach automatically adjusts the regularization\nbased on the agent's performance. Theoretical analysis and experimental results\ndemonstrate that WAVE achieves superior performance compared to standard\nactor-critic methods.\n","authors":["Ali Baheri","Zahra Shahrooei","Chirayu Salgarkar"],"pdf_url":"https://arxiv.org/pdf/2501.10605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05675v1","updated":"2025-03-07T18:35:11Z","published":"2025-03-07T18:35:11Z","title":"Algorithmic Data Minimization for Machine Learning over\n  Internet-of-Things Data Streams","summary":"  Machine learning can analyze vast amounts of data generated by IoT devices to\nidentify patterns, make predictions, and enable real-time decision-making. By\nprocessing sensor data, machine learning models can optimize processes, improve\nefficiency, and enhance personalized user experiences in smart systems.\nHowever, IoT systems are often deployed in sensitive environments such as\nhouseholds and offices, where they may inadvertently expose identifiable\ninformation, including location, habits, and personal identifiers. This raises\nsignificant privacy concerns, necessitating the application of data\nminimization -- a foundational principle in emerging data regulations, which\nmandates that service providers only collect data that is directly relevant and\nnecessary for a specified purpose. Despite its importance, data minimization\nlacks a precise technical definition in the context of sensor data, where\ncollections of weak signals make it challenging to apply a binary \"relevant and\nnecessary\" rule. This paper provides a technical interpretation of data\nminimization in the context of sensor streams, explores practical methods for\nimplementation, and addresses the challenges involved. Through our approach, we\ndemonstrate that our framework can reduce user identifiability by up to 16.7%\nwhile maintaining accuracy loss below 1%, offering a viable path toward\nprivacy-preserving IoT data processing.\n","authors":["Ted Shaowang","Shinan Liu","Jonatas Marques","Nick Feamster","Sanjay Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.05675v1.pdf","comment":"9 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.01120v2","updated":"2025-03-07T18:34:16Z","published":"2024-12-02T04:45:10Z","title":"Reliable and scalable variable importance estimation via warm-start and\n  early stopping","summary":"  As opaque black-box predictive models become more prevalent, the need to\ndevelop interpretations for these models is of great interest. The concept of\nvariable importance and Shapley values are interpretability measures that\napplies to any predictive model and assesses how much a variable or set of\nvariables improves prediction performance. When the number of variables is\nlarge, estimating variable importance presents a significant computational\nchallenge because re-training neural networks or other black-box algorithms\nrequires significant additional computation. In this paper, we address this\nchallenge for algorithms using gradient descent and gradient boosting (e.g.\nneural networks, gradient-boosted decision trees). By using the ideas of early\nstopping of gradient-based methods in combination with warm-start using the\ndropout method, we develop a scalable method to estimate variable importance\nfor any algorithm that can be expressed as an iterative kernel update equation.\nImportantly, we provide theoretical guarantees by using the theory for early\nstopping of kernel-based methods for neural networks with sufficiently large\n(but not necessarily infinite) width and gradient-boosting decision trees that\nuse symmetric trees as a weaker learner. We also demonstrate the efficacy of\nour methods through simulations and a real data example which illustrates the\ncomputational benefit of early stopping rather than fully re-training the model\nas well as the increased accuracy of our approach.\n","authors":["Zexuan Sun","Garvesh Raskutti"],"pdf_url":"https://arxiv.org/pdf/2412.01120v2.pdf","comment":"Preliminary version accepted in AISTATS, 2025"},{"id":"http://arxiv.org/abs/2502.10297v2","updated":"2025-03-07T18:31:55Z","published":"2025-02-14T16:59:05Z","title":"DeltaProduct: Increasing the Expressivity of DeltaNet Through Products\n  of Householders","summary":"  Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive\nalternatives to Transformers for sequence modeling, offering efficient training\nand linear-time inference. However, existing architectures face a fundamental\ntrade-off between expressivity and efficiency, dictated by the structure of\ntheir state-transition matrices. While diagonal matrices used in architectures\nlike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited\nexpressivity. To address this, recent architectures such as (Gated) DeltaNet\nand RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous\ntoken-channel mixing, which overcomes some expressivity limitations with only a\nslight decrease in training efficiency. Building on the interpretation of\nDeltaNet's recurrence as performing one step of online gradient descent per\ntoken on an associative recall loss, we introduce DeltaProduct, which instead\ntakes multiple ($n_h$) steps per token. This naturally leads to diagonal plus\nrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized\nHouseholder transformations, providing a tunable mechanism to balance\nexpressivity and efficiency and a stable recurrence. Through extensive\nexperiments, we demonstrate that DeltaProduct achieves superior state-tracking\nand language modeling capabilities while exhibiting significantly improved\nlength extrapolation compared to DeltaNet. Additionally, we also strengthen the\ntheoretical foundation of DeltaNet's expressivity by proving that it can solve\ndihedral group word problems in just two layers.\n","authors":["Julien Siems","Timur Carstensen","Arber Zela","Frank Hutter","Massimiliano Pontil","Riccardo Grazzi"],"pdf_url":"https://arxiv.org/pdf/2502.10297v2.pdf","comment":"Accepted at ICLR 2025 Workshop on Foundation Models in the Wild"},{"id":"http://arxiv.org/abs/2503.05665v1","updated":"2025-03-07T18:26:48Z","published":"2025-03-07T18:26:48Z","title":"AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning\n  Biased Models with Contextual Synthetic Data","summary":"  Recent advances in generative models have sparked research on improving model\nfairness with AI-generated data. However, existing methods often face\nlimitations in the diversity and quality of synthetic data, leading to\ncompromised fairness and overall model accuracy. Moreover, many approaches rely\non the availability of demographic group labels, which are often costly to\nannotate. This paper proposes AIM-Fair, aiming to overcome these limitations\nand harness the potential of cutting-edge generative models in promoting\nalgorithmic fairness. We investigate a fine-tuning paradigm starting from a\nbiased model initially trained on real-world data without demographic\nannotations. This model is then fine-tuned using unbiased synthetic data\ngenerated by a state-of-the-art diffusion model to improve its fairness. Two\nkey challenges are identified in this fine-tuning paradigm, 1) the low quality\nof synthetic data, which can still happen even with advanced generative models,\nand 2) the domain and bias gap between real and synthetic data. To address the\nlimitation of synthetic data quality, we propose Contextual Synthetic Data\nGeneration (CSDG) to generate data using a text-to-image diffusion model (T2I)\nwith prompts generated by a context-aware LLM, ensuring both data diversity and\ncontrol of bias in synthetic data. To resolve domain and bias shifts, we\nintroduce a novel selective fine-tuning scheme in which only model parameters\nmore sensitive to bias and less sensitive to domain shift are updated.\nExperiments on CelebA and UTKFace datasets show that our AIM-Fair improves\nmodel fairness while maintaining utility, outperforming both fully and\npartially fine-tuned approaches to model fairness.\n","authors":["Zengqun Zhao","Ziquan Liu","Yu Cao","Shaogang Gong","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2503.05665v1.pdf","comment":"Accepted at CVPR 2025. Github:\n  https://github.com/zengqunzhao/AIM-Fair. Project page:\n  https://zengqunzhao.github.io/AIMFair"},{"id":"http://arxiv.org/abs/2503.05662v1","updated":"2025-03-07T18:23:58Z","published":"2025-03-07T18:23:58Z","title":"On Mitigating Affinity Bias through Bandits with Evolving Biased\n  Feedback","summary":"  Unconscious bias has been shown to influence how we assess our peers, with\nconsequences for hiring, promotions and admissions. In this work, we focus on\naffinity bias, the component of unconscious bias which leads us to prefer\npeople who are similar to us, despite no deliberate intention of favoritism. In\na world where the people hired today become part of the hiring committee of\ntomorrow, we are particularly interested in understanding (and mitigating) how\naffinity bias affects this feedback loop. This problem has two distinctive\nfeatures: 1) we only observe the biased value of a candidate, but we want to\noptimize with respect to their real value 2) the bias towards a candidate with\na specific set of traits depends on the fraction of people in the hiring\ncommittee with the same set of traits. We introduce a new bandits variant that\nexhibits those two features, which we call affinity bandits. Unsurprisingly,\nclassical algorithms such as UCB often fail to identify the best arm in this\nsetting. We prove a new instance-dependent regret lower bound, which is larger\nthan that in the standard bandit setting by a multiplicative function of $K$.\nSince we treat rewards that are time-varying and dependent on the policy's past\nactions, deriving this lower bound requires developing proof techniques beyond\nthe standard bandit techniques. Finally, we design an elimination-style\nalgorithm which nearly matches this regret, despite never observing the real\nrewards.\n","authors":["Matthew Faw","Constantine Caramanis","Jessica Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2503.05662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02482v2","updated":"2025-03-07T18:20:38Z","published":"2024-11-04T18:59:36Z","title":"NeRF-Aug: Data Augmentation for Robotics with Neural Radiance Fields","summary":"  Training a policy that can generalize to unknown objects is a long standing\nchallenge within the field of robotics. The performance of a policy often drops\nsignificantly in situations where an object in the scene was not seen during\ntraining. To solve this problem, we present NeRF-Aug, a novel method that is\ncapable of teaching a policy to interact with objects that are not present in\nthe dataset. This approach differs from existing approaches by leveraging the\nspeed, photorealism, and 3D consistency of a neural radiance field for\naugmentation. NeRF-Aug both creates more photorealistic data and runs 63%\nfaster than existing methods. We demonstrate the effectiveness of our method on\n5 tasks with 9 novel objects that are not present in the expert demonstrations.\nWe achieve an average performance boost of 55.6% when comparing our method to\nthe next best method. You can see video results at https://nerf-aug.github.io.\n","authors":["Eric Zhu","Mara Levy","Matthew Gwilliam","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2411.02482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05657v1","updated":"2025-03-07T18:19:19Z","published":"2025-03-07T18:19:19Z","title":"NoT: Federated Unlearning via Weight Negation","summary":"  Federated unlearning (FU) aims to remove a participant's data contributions\nfrom a trained federated learning (FL) model, ensuring privacy and regulatory\ncompliance. Traditional FU methods often depend on auxiliary storage on either\nthe client or server side or require direct access to the data targeted for\nremoval-a dependency that may not be feasible if the data is no longer\navailable. To overcome these limitations, we propose NoT, a novel and efficient\nFU algorithm based on weight negation (multiplying by -1), which circumvents\nthe need for additional storage and access to the target data. We argue that\neffective and efficient unlearning can be achieved by perturbing model\nparameters away from the set of optimal parameters, yet being well-positioned\nfor quick re-optimization. This technique, though seemingly contradictory, is\ntheoretically grounded: we prove that the weight negation perturbation\neffectively disrupts inter-layer co-adaptation, inducing unlearning while\npreserving an approximate optimality property, thereby enabling rapid recovery.\nExperimental results across three datasets and three model architectures\ndemonstrate that NoT significantly outperforms existing baselines in unlearning\nefficacy as well as in communication and computational efficiency.\n","authors":["Yasser H. Khalil","Leo Brunswic","Soufiane Lamghari","Xu Li","Mahdi Beitollahi","Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2503.05657v1.pdf","comment":"The 42nd IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition, Nashville TN, US. 2025"},{"id":"http://arxiv.org/abs/2503.05652v1","updated":"2025-03-07T18:15:21Z","published":"2025-03-07T18:15:21Z","title":"BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation\n  for Everyday Household Activities","summary":"  Real-world household tasks present significant challenges for mobile\nmanipulation robots. An analysis of existing robotics benchmarks reveals that\nsuccessful task performance hinges on three key whole-body control\ncapabilities: bimanual coordination, stable and precise navigation, and\nextensive end-effector reachability. Achieving these capabilities requires\ncareful hardware design, but the resulting system complexity further\ncomplicates visuomotor policy learning. To address these challenges, we\nintroduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for\nwhole-body manipulation in diverse household tasks. Built on a bimanual,\nwheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body\nteleoperation interface for data collection and a novel algorithm for learning\nwhole-body visuomotor policies. We evaluate BRS on five challenging household\ntasks that not only emphasize the three core capabilities but also introduce\nadditional complexities, such as long-range navigation, interaction with\narticulated and deformable objects, and manipulation in confined spaces. We\nbelieve that BRS's integrated robotic embodiment, data collection interface,\nand learning framework mark a significant step toward enabling real-world\nwhole-body manipulation for everyday household tasks. BRS is open-sourced at\nhttps://behavior-robot-suite.github.io/\n","authors":["Yunfan Jiang","Ruohan Zhang","Josiah Wong","Chen Wang","Yanjie Ze","Hang Yin","Cem Gokmen","Shuran Song","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2503.05652v1.pdf","comment":"Project website: https://behavior-robot-suite.github.io/"},{"id":"http://arxiv.org/abs/2503.05648v1","updated":"2025-03-07T18:11:23Z","published":"2025-03-07T18:11:23Z","title":"Physics-based machine learning framework for predicting NOx emissions\n  from compression ignition engines using on-board diagnostics data","summary":"  This work presents a physics-based machine learning framework to predict and\nanalyze oxides of nitrogen (NOx) emissions from compression-ignition\nengine-powered vehicles using on-board diagnostics (OBD) data as input.\nAccurate NOx prediction from OBD datasets is difficult because NOx formation\ninside an engine combustion chamber is governed by complex processes occurring\non timescales much shorter than the data collection rate. Thus, emissions\ngenerally cannot be predicted accurately using simple empirically derived\nphysics models. Black box models like genetic algorithms or neural networks can\nbe more accurate, but have poor interpretability. The transparent model\npresented in this paper has both high accuracy and can explain potential\nsources of high emissions. The proposed framework consists of two major steps:\na physics-based NOx prediction model combined with a novel Divergent Window\nCo-occurrence (DWC) Pattern detection algorithm to analyze operating conditions\nthat are not adequately addressed by the physics-based model. The proposed\nframework is validated for generalizability with a second vehicle OBD dataset,\na sensitivity analysis is performed, and model predictions are compared with\nthat from a deep neural network. The results show that NOx emissions\npredictions using the proposed model has around 55% better root mean square\nerror, and around 60% higher mean absolute error compared to the baseline NOx\nprediction model from previously published work. The DWC Pattern Detection\nAlgorithm identified low engine power conditions to have high statistical\nsignificance, indicating an operating regime where the model can be improved.\nThis work shows that the physics-based machine learning framework is a viable\nmethod for predicting NOx emissions from engines that do not incorporate NOx\nsensing.\n","authors":["Harish Panneer Selvam","Bharat Jayaprakash","Yan Li","Shashi Shekhar","William F. Northrop"],"pdf_url":"https://arxiv.org/pdf/2503.05648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05641v1","updated":"2025-03-07T18:03:13Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v1.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic_moe.github.io/"},{"id":"http://arxiv.org/abs/2503.05631v1","updated":"2025-03-07T17:54:05Z","published":"2025-03-07T17:54:05Z","title":"Strategy Coopetition Explains the Emergence and Transience of In-Context\n  Learning","summary":"  In-context learning (ICL) is a powerful ability that emerges in transformer\nmodels, enabling them to learn from context without weight updates. Recent work\nhas established emergent ICL as a transient phenomenon that can sometimes\ndisappear after long training times. In this work, we sought a mechanistic\nunderstanding of these transient dynamics. Firstly, we find that, after the\ndisappearance of ICL, the asymptotic strategy is a remarkable hybrid between\nin-weights and in-context learning, which we term \"context-constrained\nin-weights learning\" (CIWL). CIWL is in competition with ICL, and eventually\nreplaces it as the dominant strategy of the model (thus leading to ICL\ntransience). However, we also find that the two competing strategies actually\nshare sub-circuits, which gives rise to cooperative dynamics as well. For\nexample, in our setup, ICL is unable to emerge quickly on its own, and can only\nbe enabled through the simultaneous slow development of asymptotic CIWL. CIWL\nthus both cooperates and competes with ICL, a phenomenon we term \"strategy\ncoopetition.\" We propose a minimal mathematical model that reproduces these key\ndynamics and interactions. Informed by this model, we were able to identify a\nsetup where ICL is truly emergent and persistent.\n","authors":["Aaditya K. Singh","Ted Moskovitz","Sara Dragutinovic","Felix Hill","Stephanie C. Y. Chan","Andrew M. Saxe"],"pdf_url":"https://arxiv.org/pdf/2503.05631v1.pdf","comment":"20 pages, 18 figures"},{"id":"http://arxiv.org/abs/2503.05622v1","updated":"2025-03-07T17:49:55Z","published":"2025-03-07T17:49:55Z","title":"Decision-aware training of spatiotemporal forecasting models","summary":"  Optimal allocation of scarce resources is a common problem for decision\nmakers faced with choosing a limited number of locations for intervention.\nSpatiotemporal prediction models could make such decisions data-driven. A\nrecent performance metric called fraction of best possible reach (BPR) measures\nthe impact of using a model's recommended size K subset of sites compared to\nthe best possible top-K in hindsight. We tackle two open problems related to\nBPR. First, we explore how to rank all sites numerically given a probabilistic\nmodel that predicts event counts jointly across sites. Ranking via the per-site\nmean is suboptimal for BPR. Instead, we offer a better ranking for BPR backed\nby decision theory. Second, we explore how to train a probabilistic model's\nparameters to maximize BPR. Discrete selection of K sites implies all-zero\nparameter gradients which prevent standard gradient training. We overcome this\nbarrier via advances in perturbed optimizers. We further suggest a training\nobjective that combines likelihood with a decision-aware BPR constraint to\ndeliver high-quality top-K rankings as well as good forecasts for all sites. We\ndemonstrate our approach on two where-to-intervene applications: mitigating\nopioid-related fatal overdoses for public health and monitoring endangered\nwildlife.\n","authors":["Kyle Heuton","F. Samuel Muench","Shikhar Shrestha","Thomas J. Stopka","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2503.05622v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05618v1","updated":"2025-03-07T17:42:30Z","published":"2025-03-07T17:42:30Z","title":"Conformal Prediction for Image Segmentation Using Morphological\n  Prediction Sets","summary":"  Image segmentation is a challenging task influenced by multiple sources of\nuncertainty, such as the data labeling process or the sampling of training\ndata. In this paper we focus on binary segmentation and address these\nchallenges using conformal prediction, a family of model- and data-agnostic\nmethods for uncertainty quantification that provide finite-sample theoretical\nguarantees and applicable to any pretrained predictor. Our approach involves\ncomputing nonconformity scores, a type of prediction residual, on held-out\ncalibration data not used during training. We use dilation, one of the\nfundamental operations in mathematical morphology, to construct a margin added\nto the borders of predicted segmentation masks. At inference, the predicted set\nformed by the mask and its margin contains the ground-truth mask with high\nprobability, at a confidence level specified by the user. The size of the\nmargin serves as an indicator of predictive uncertainty for a given model and\ndataset. We work in a regime of minimal information as we do not require any\nfeedback from the predictor: only the predicted masks are needed for computing\nthe prediction sets. Hence, our method is applicable to any segmentation model,\nincluding those based on deep learning; we evaluate our approach on several\nmedical imaging applications.\n","authors":["Luca Mossina","Corentin Friedrich"],"pdf_url":"https://arxiv.org/pdf/2503.05618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05617v1","updated":"2025-03-07T17:42:24Z","published":"2025-03-07T17:42:24Z","title":"Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as\n  hyperelastic constitutive artificial neural networks (CANs)","summary":"  Traditional constitutive models rely on hand-crafted parametric forms with\nlimited expressivity and generalizability, while neural network-based models\ncan capture complex material behavior but often lack interpretability. To\nbalance these trade-offs, we present Input-Convex Kolmogorov-Arnold Networks\n(ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs\nleverage the Kolmogorov-Arnold representation, decomposing the model into\ncompositions of trainable univariate spline-based activation functions for rich\nexpressivity. We introduce trainable input-convex splines within the KAN\narchitecture, ensuring physically admissible polyconvex hyperelastic models.\nThe resulting models are both compact and interpretable, enabling explicit\nextraction of analytical constitutive relationships through an input-convex\nsymbolic regression techinque. Through unsupervised training on full-field\nstrain data and limited global force measurements, ICKANs accurately capture\nnonlinear stress-strain behavior across diverse strain states. Finite element\nsimulations of unseen geometries with trained ICKAN hyperelastic constitutive\nmodels confirm the framework's robustness and generalization capability.\n","authors":["Prakash Thakolkaran","Yaqi Guo","Shivam Saini","Mathias Peirlinck","Benjamin Alheit","Siddhant Kumar"],"pdf_url":"https://arxiv.org/pdf/2503.05617v1.pdf","comment":"34 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.05613v1","updated":"2025-03-07T17:38:00Z","published":"2025-03-07T17:38:00Z","title":"A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of\n  Large Language Models","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.\n","authors":["Dong Shu","Xuansheng Wu","Haiyan Zhao","Daking Rai","Ziyu Yao","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2503.05613v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05602v1","updated":"2025-03-07T17:28:02Z","published":"2025-03-07T17:28:02Z","title":"On the similarity of bandwidth-tuned quantum kernels and classical\n  kernels","summary":"  Quantum kernels (QK) are widely used in quantum machine learning\napplications; yet, their potential to surpass classical machine learning\nmethods on classical datasets remains uncertain. This limitation can be\nattributed to the exponential concentration phenomenon, which can impair both\ntrainability and generalization. A common strategy to alleviate this is\nbandwidth tuning, which involves rescaling data points in the quantum model to\nimprove generalization. In this work, we numerically demonstrate that optimal\nbandwidth tuning results in QKs that closely resemble radial basis function\n(RBF) kernels, leading to a lack of quantum advantage over classical methods.\nMoreover, we reveal that the size of optimal bandwidth tuning parameters\nfurther simplifies QKs, causing them to behave like polynomial kernels,\ncorresponding to a low-order Taylor approximation of a RBF kernel. We\nthoroughly investigate this for fidelity quantum kernels and projected quantum\nkernels using various data encoding circuits across several classification\ndatasets. We provide numerical evidence and derive a simple analytical model\nthat elucidates how bandwidth tuning influences key quantities in\nclassification tasks. Overall, our findings shed light on the mechanisms that\nrender QK methods classically simulatable.\n","authors":["Roberto Flórez Ablan","Marco Roth","Jan Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.05602v1.pdf","comment":"9 main pages with 5 figures, and 9 appendix pages with 12 figures"},{"id":"http://arxiv.org/abs/2503.05598v1","updated":"2025-03-07T17:25:25Z","published":"2025-03-07T17:25:25Z","title":"From Theory to Application: A Practical Introduction to Neural Operators\n  in Scientific Computing","summary":"  This focused review explores a range of neural operator architectures for\napproximating solutions to parametric partial differential equations (PDEs),\nemphasizing high-level concepts and practical implementation strategies. The\nstudy covers foundational models such as Deep Operator Networks (DeepONet),\nPrincipal Component Analysis-based Neural Networks (PCANet), and Fourier Neural\nOperators (FNO), providing comparative insights into their core methodologies\nand performance. These architectures are demonstrated on two classical linear\nparametric PDEs: the Poisson equation and linear elastic deformation. Beyond\nforward problem-solving, the review delves into applying neural operators as\nsurrogates in Bayesian inference problems, showcasing their effectiveness in\naccelerating posterior inference while maintaining accuracy. The paper\nconcludes by discussing current challenges, particularly in controlling\nprediction accuracy and generalization. It outlines emerging strategies to\naddress these issues, such as residual-based error correction and multi-level\ntraining. This review can be seen as a comprehensive guide to implementing\nneural operators and integrating them into scientific computing workflows.\n","authors":["Prashant K. Jha"],"pdf_url":"https://arxiv.org/pdf/2503.05598v1.pdf","comment":"53 pages, 17 figures, Github repository:\n  https://github.com/CEADpx/neural_operators"},{"id":"http://arxiv.org/abs/2406.16976v3","updated":"2025-03-07T17:24:35Z","published":"2024-06-23T06:22:49Z","title":"Efficient Evolutionary Search Over Chemical Space with Large Language\n  Models","summary":"  Molecular discovery, when formulated as an optimization problem, presents\nsignificant computational challenges because optimization objectives can be\nnon-differentiable. Evolutionary Algorithms (EAs), often used to optimize\nblack-box objectives in molecular discovery, traverse chemical space by\nperforming random mutations and crossovers, leading to a large number of\nexpensive objective evaluations. In this work, we ameliorate this shortcoming\nby incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely,\nwe redesign crossover and mutation operations in EAs using LLMs trained on\nlarge corpora of chemical information. We perform extensive empirical studies\non both commercial and open-source models on multiple tasks involving property\noptimization, molecular rediscovery, and structure-based drug design,\ndemonstrating that the joint usage of LLMs with EAs yields superior performance\nover all baseline models across single- and multi-objective settings. We\ndemonstrate that our algorithm improves both the quality of the final solution\nand convergence speed, thereby reducing the number of required objective\nevaluations. Our code is available at http://github.com/zoom-wang112358/MOLLEO\n","authors":["Haorui Wang","Marta Skreta","Cher-Tian Ser","Wenhao Gao","Lingkai Kong","Felix Strieth-Kalthoff","Chenru Duan","Yuchen Zhuang","Yue Yu","Yanqiao Zhu","Yuanqi Du","Alán Aspuru-Guzik","Kirill Neklyudov","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16976v3.pdf","comment":"Published in ICLR 2025"},{"id":"http://arxiv.org/abs/2303.17251v3","updated":"2025-03-07T17:23:53Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05587v1","updated":"2025-03-07T17:11:34Z","published":"2025-03-07T17:11:34Z","title":"Quantifying the Robustness of Retrieval-Augmented Language Models\n  Against Spurious Features in Grounding Data","summary":"  Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.\n","authors":["Shiping Yang","Jie Wu","Wenbiao Ding","Ning Wu","Shining Liang","Ming Gong","Hengyuan Zhang","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19492v2","updated":"2025-03-07T17:08:45Z","published":"2024-10-25T11:49:40Z","title":"TRADE: Transfer of Distributions between External Conditions with\n  Normalizing Flows","summary":"  Modeling distributions that depend on external control parameters is a common\nscenario in diverse applications like molecular simulations, where system\nproperties like temperature affect molecular configurations. Despite the\nrelevance of these applications, existing solutions are unsatisfactory as they\nrequire severely restricted model architectures or rely on energy-based\ntraining, which is prone to instability. We introduce TRADE, which overcomes\nthese limitations by formulating the learning process as a boundary value\nproblem. By initially training the model for a specific condition using either\ni.i.d.~samples or backward KL training, we establish a boundary distribution.\nWe then propagate this information across other conditions using the gradient\nof the unnormalized density with respect to the external parameter. This\nformulation, akin to the principles of physics-informed neural networks, allows\nus to efficiently learn parameter-dependent distributions without restrictive\nassumptions. Experimentally, we demonstrate that TRADE achieves excellent\nresults in a wide range of applications, ranging from Bayesian inference and\nmolecular simulations to physical lattice models.\n","authors":["Stefan Wahl","Armand Rousselot","Felix Draxler","Henrik Schopmans","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2410.19492v2.pdf","comment":"Accepted as Poster at AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.05582v1","updated":"2025-03-07T17:07:51Z","published":"2025-03-07T17:07:51Z","title":"MPTSNet: Integrating Multiscale Periodic Local Patterns and Global\n  Dependencies for Multivariate Time Series Classification","summary":"  Multivariate Time Series Classification (MTSC) is crucial in extensive\npractical applications, such as environmental monitoring, medical EEG analysis,\nand action recognition. Real-world time series datasets typically exhibit\ncomplex dynamics. To capture this complexity, RNN-based, CNN-based,\nTransformer-based, and hybrid models have been proposed. Unfortunately, current\ndeep learning-based methods often neglect the simultaneous construction of\nlocal features and global dependencies at different time scales, lacking\nsufficient feature extraction capabilities to achieve satisfactory\nclassification accuracy. To address these challenges, we propose a novel\nMultiscale Periodic Time Series Network (MPTSNet), which integrates multiscale\nlocal patterns and global correlations to fully exploit the inherent\ninformation in time series. Recognizing the multi-periodicity and complex\nvariable correlations in time series, we use the Fourier transform to extract\nprimary periods, enabling us to decompose data into multiscale periodic\nsegments. Leveraging the inherent strengths of CNN and attention mechanism, we\nintroduce the PeriodicBlock, which adaptively captures local patterns and\nglobal dependencies while offering enhanced interpretability through attention\nintegration across different periodic scales. The experiments on UEA benchmark\ndatasets demonstrate that the proposed MPTSNet outperforms 21 existing advanced\nbaselines in the MTSC tasks.\n","authors":["Yang Mu","Muhammad Shahzad","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.05582v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2503.05577v1","updated":"2025-03-07T16:59:18Z","published":"2025-03-07T16:59:18Z","title":"opXRD: Open Experimental Powder X-ray Diffraction Database","summary":"  Powder X-ray diffraction (pXRD) experiments are a cornerstone for materials\nstructure characterization. Despite their widespread application, analyzing\npXRD diffractograms still presents a significant challenge to automation and a\nbottleneck in high-throughput discovery in self-driving labs. Machine learning\npromises to resolve this bottleneck by enabling automated powder diffraction\nanalysis. A notable difficulty in applying machine learning to this domain is\nthe lack of sufficiently sized experimental datasets, which has constrained\nresearchers to train primarily on simulated data. However, models trained on\nsimulated pXRD patterns showed limited generalization to experimental patterns,\nparticularly for low-quality experimental patterns with high noise levels and\nelevated backgrounds. With the Open Experimental Powder X-Ray Diffraction\nDatabase (opXRD), we provide an openly available and easily accessible dataset\nof labeled and unlabeled experimental powder diffractograms. Labeled opXRD data\ncan be used to evaluate the performance of models on experimental data and\nunlabeled opXRD data can help improve the performance of models on experimental\ndata, e.g. through transfer learning methods. We collected \\numpatterns\ndiffractograms, 2179 of them labeled, from a wide spectrum of materials\nclasses. We hope this ongoing effort can guide machine learning research toward\nfully automated analysis of pXRD data and thus enable future self-driving\nmaterials labs.\n","authors":["Daniel Hollarek","Henrik Schopmans","Jona Östreicher","Jonas Teufel","Bin Cao","Adie Alwen","Simon Schweidler","Mriganka Singh","Tim Kodalle","Hanlin Hu","Gregoire Heymans","Maged Abdelsamie","Arthur Hardiagon","Alexander Wieczorek","Siarhei Zhuk","Ruth Schwaiger","Sebastian Siol","François-Xavier Coudert","Moritz Wolf","Carolin M. Sutter-Fella","Ben Breitung","Andrea M. Hodge","Tong-yi Zhang","Pascal Friederich"],"pdf_url":"https://arxiv.org/pdf/2503.05577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06525v3","updated":"2025-03-07T16:58:08Z","published":"2024-08-12T23:04:30Z","title":"The NP-hardness of the Gromov-Wasserstein distance","summary":"  This note addresses the property frequently mentioned in the literature that\nthe Gromov-Wasserstein (GW) distance is NP-hard. We provide the details on the\nnon-convex nature of the GW optimization problem that imply NP-hardness of the\nGW distance between finite spaces for any instance of an input data. We further\nillustrate the non-convexity of the problem with several explicit examples.\n","authors":["Natalia Kravtsova"],"pdf_url":"https://arxiv.org/pdf/2408.06525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05574v1","updated":"2025-03-07T16:56:09Z","published":"2025-03-07T16:56:09Z","title":"BARK: A Fully Bayesian Tree Kernel for Black-box Optimization","summary":"  We perform Bayesian optimization using a Gaussian process perspective on\nBayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree\nagreement to define a posterior over piecewise-constant functions, and we\nexplore the space of tree kernels using a Markov chain Monte Carlo approach.\nWhere BART only samples functions, the resulting BARK model obtains samples of\nGaussian processes defining distributions over functions, which allow us to\nbuild acquisition functions for Bayesian optimization. Our tree-based approach\nenables global optimization over the surrogate, even for mixed-feature spaces.\nMoreover, where many previous tree-based kernels provide uncertainty\nquantification over function values, our sampling scheme captures uncertainty\nover the tree structure itself. Our experiments show the strong performance of\nBARK on both synthetic and applied benchmarks, due to the combination of our\nfully Bayesian surrogate and the optimization procedure.\n","authors":["Toby Boyne","Jose Pablo Folch","Robert M Lee","Behrang Shafei","Ruth Misener"],"pdf_url":"https://arxiv.org/pdf/2503.05574v1.pdf","comment":"8 main pages, 22 total pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.05573v1","updated":"2025-03-07T16:56:00Z","published":"2025-03-07T16:56:00Z","title":"InDRiVE: Intrinsic Disagreement based Reinforcement for Vehicle\n  Exploration through Curiosity Driven Generalized World Model","summary":"  Model-based Reinforcement Learning (MBRL) has emerged as a promising paradigm\nfor autonomous driving, where data efficiency and robustness are critical. Yet,\nexisting solutions often rely on carefully crafted, task specific extrinsic\nrewards, limiting generalization to new tasks or environments. In this paper,\nwe propose InDRiVE (Intrinsic Disagreement based Reinforcement for Vehicle\nExploration), a method that leverages purely intrinsic, disagreement based\nrewards within a Dreamer based MBRL framework. By training an ensemble of world\nmodels, the agent actively explores high uncertainty regions of environments\nwithout any task specific feedback. This approach yields a task agnostic latent\nrepresentation, allowing for rapid zero shot or few shot fine tuning on\ndownstream driving tasks such as lane following and collision avoidance.\nExperimental results in both seen and unseen environments demonstrate that\nInDRiVE achieves higher success rates and fewer infractions compared to\nDreamerV2 and DreamerV3 baselines despite using significantly fewer training\nsteps. Our findings highlight the effectiveness of purely intrinsic exploration\nfor learning robust vehicle control behaviors, paving the way for more scalable\nand adaptable autonomous driving systems.\n","authors":["Feeza Khan Khanzada","Jaerock Kwon"],"pdf_url":"https://arxiv.org/pdf/2503.05573v1.pdf","comment":"This work has been submitted to IROS 2025 and is currently under\n  review"},{"id":"http://arxiv.org/abs/2212.11805v2","updated":"2025-03-07T16:52:17Z","published":"2022-12-22T15:36:15Z","title":"BSAC-CoEx: Coexistence of URLLC and Distributed Learning Services via\n  Device Selection","summary":"  Recent advances in distributed intelligence have driven impressive progress\nacross a diverse range of applications, from industrial automation to\nautonomous transportation. Nevertheless, deploying distributed learning\nservices over wireless networks poses numerous challenges. These arise from\ninherent uncertainties in wireless environments (e.g., random channel\nfluctuations), limited resources (e.g., bandwidth and transmit power), and the\npresence of coexisting services on the network. In this paper, we investigate a\nmixed service scenario wherein high-priority ultra-reliable low latency\ncommunication (URLLC) and low-priority distributed learning services run\nconcurrently over a network. Utilizing device selection, we aim to minimize the\nconvergence time of distributed learning while simultaneously fulfilling the\nrequirements of the URLLC service. We formulate this problem as a Markov\ndecision process and address it via BSAC-CoEx, a framework based on the\nbranching soft actor-critic (BSAC) algorithm that determines each device's\nparticipation decision through distinct branches in the actor's neural network.\nWe evaluate our solution with a realistic simulator that is compliant with 3GPP\nstandards for factory automation use cases. Our simulation results confirm that\nour solution can significantly decrease the training delays of the distributed\nlearning service while keeping the URLLC availability above its required\nthreshold and close to the scenario where URLLC solely consumes all wireless\nresources.\n","authors":["Milad Ganjalizadeh","Hossein Shokri Ghadikolaei","Deniz Gündüz","Marina Petrova"],"pdf_url":"https://arxiv.org/pdf/2212.11805v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.05563v1","updated":"2025-03-07T16:43:25Z","published":"2025-03-07T16:43:25Z","title":"Tractable Representations for Convergent Approximation of Distributional\n  HJB Equations","summary":"  In reinforcement learning (RL), the long-term behavior of decision-making\npolicies is evaluated based on their average returns. Distributional RL has\nemerged, presenting techniques for learning return distributions, which provide\nadditional statistics for evaluating policies, incorporating risk-sensitive\nconsiderations. When the passage of time cannot naturally be divided into\ndiscrete time increments, researchers have studied the continuous-time RL\n(CTRL) problem, where agent states and decisions evolve continuously. In this\nsetting, the Hamilton-Jacobi-Bellman (HJB) equation is well established as the\ncharacterization of the expected return, and many solution methods exist.\nHowever, the study of distributional RL in the continuous-time setting is in\nits infancy. Recent work has established a distributional HJB (DHJB) equation,\nproviding the first characterization of return distributions in CTRL. These\nequations and their solutions are intractable to solve and represent exactly,\nrequiring novel approximation techniques. This work takes strides towards this\nend, establishing conditions on the method of parameterizing return\ndistributions under which the DHJB equation can be approximately solved.\nParticularly, we show that under a certain topological property of the mapping\nbetween statistics learned by a distributional RL algorithm and corresponding\ndistributions, approximation of these statistics leads to close approximations\nof the solution of the DHJB equation. Concretely, we demonstrate that the\nquantile representation common in distributional RL satisfies this topological\nproperty, certifying an efficient approximation algorithm for continuous-time\ndistributional RL.\n","authors":["Julie Alhosh","Harley Wiltzer","David Meger"],"pdf_url":"https://arxiv.org/pdf/2503.05563v1.pdf","comment":"Accepted to RLDM 2025"},{"id":"http://arxiv.org/abs/2503.05560v1","updated":"2025-03-07T16:38:41Z","published":"2025-03-07T16:38:41Z","title":"Global graph features unveiled by unsupervised geometric deep learning","summary":"  Graphs provide a powerful framework for modeling complex systems, but their\nstructural variability makes analysis and classification challenging. To\naddress this, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive\nInformation), a novel unsupervised geometric deep learning framework that\ncaptures both local details and global structure. GAUDI employs an innovative\nhourglass architecture with hierarchical pooling and upsampling layers, linked\nthrough skip connections to preserve essential connectivity information\nthroughout the encoding-decoding process. By mapping different realizations of\na system - generated from the same underlying parameters - into a continuous,\nstructured latent space, GAUDI disentangles invariant process-level features\nfrom stochastic noise. We demonstrate its power across multiple applications,\nincluding modeling small-world networks, characterizing protein assemblies from\nsuper-resolution microscopy, analyzing collective motion in the Vicsek model,\nand capturing age-related changes in brain connectivity. This approach not only\nimproves the analysis of complex graphs but also provides new insights into\nemergent phenomena across diverse scientific domains.\n","authors":["Mirja Granfors","Jesús Pineda","Blanca Zufiria Gerbolés","Joana B. Pereira","Carlo Manzo","Giovanni Volpe"],"pdf_url":"https://arxiv.org/pdf/2503.05560v1.pdf","comment":"23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.05558v1","updated":"2025-03-07T16:33:16Z","published":"2025-03-07T16:33:16Z","title":"Diffusion Models for Cayley Graphs","summary":"  We review the problem of finding paths in Cayley graphs of groups and group\nactions, using the Rubik's cube as an example, and we list several more\nexamples of significant mathematical interest. We then show how to formulate\nthese problems in the framework of diffusion models. The exploration of the\ngraph is carried out by the forward process, while finding the target nodes is\ndone by the inverse backward process. This systematizes the discussion and\nsuggests many generalizations. To improve exploration, we propose a ``reversed\nscore'' ansatz which substantially improves over previous comparable\nalgorithms.\n","authors":["Michael R. Douglas","Cristofero Fraser-Taliente"],"pdf_url":"https://arxiv.org/pdf/2503.05558v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17975v3","updated":"2025-03-07T16:30:07Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from measuring\nprivacy leakage to detecting copyright violations, has become a rapidly growing\narea of research. In the last few months, more than 10 new methods have been\nproposed to perform Membership Inference Attacks (MIAs) against LLMs. Contrary\nto traditional MIAs which rely on fixed-but randomized-records or models, these\nmethods are mostly trained and tested on datasets collected post-hoc. Sets of\nmembers and non-members, used to evaluate the MIA, are constructed using\ninformed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In\nthis work, we first extensively review the literature on MIAs against LLMs and\nshow that, while most work focuses on sequence-level MIAs evaluated in post-hoc\nsetups, a range of target models, motivations and units of interest are\nconsidered. We then quantify distribution shifts present in 6 datasets used in\nthe literature using a model-less bag of word classifier and show that all\ndatasets constructed post-hoc suffer from strong distribution shifts. These\nshifts invalidate the claims of LLMs memorizing strongly in real-world\nscenarios and, potentially, also the methodological contributions of the recent\npapers based on these datasets. Yet, all hope might not be lost. We introduce\nimportant considerations to properly evaluate MIAs against LLMs and discuss, in\nturn, potential ways forwards: randomized test splits, injections of randomized\n(unique) sequences, randomized fine-tuning, and several post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide MIA development and\nstudy LLM memorization. We conclude with an overview of recommended approaches\nto benchmark sequence-level and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v3.pdf","comment":"IEEE Conference on Secure and Trustworthy Machine Learning (SaTML\n  2025)"},{"id":"http://arxiv.org/abs/2411.02975v2","updated":"2025-03-07T16:28:13Z","published":"2024-11-05T10:24:45Z","title":"Transformer-Based Fault-Tolerant Control for Fixed-Wing UAVs Using\n  Knowledge Distillation and In-Context Adaptation","summary":"  This study presents a transformer-based approach for fault-tolerant control\nin fixed-wing Unmanned Aerial Vehicles (UAVs), designed to adapt in real time\nto dynamic changes caused by structural damage or actuator failures. Unlike\ntraditional Flight Control Systems (FCSs) that rely on classical control theory\nand struggle under severe alterations in dynamics, our method directly maps\nouter-loop reference values -- altitude, heading, and airspeed -- into control\ncommands using the in-context learning and attention mechanisms of\ntransformers, thus bypassing inner-loop controllers and fault-detection layers.\nEmploying a teacher-student knowledge distillation framework, the proposed\napproach trains a student agent with partial observations by transferring\nknowledge from a privileged expert agent with full observability, enabling\nrobust performance across diverse failure scenarios. Experimental results\ndemonstrate that our transformer-based controller outperforms industry-standard\nFCS and state-of-the-art reinforcement learning (RL) methods, maintaining high\ntracking accuracy and stability in nominal conditions and extreme failure\ncases, highlighting its potential for enhancing UAV operational safety and\nreliability.\n","authors":["Francisco Giral","Ignacio Gómez","Ricardo Vinuesa","Soledad Le Clainche"],"pdf_url":"https://arxiv.org/pdf/2411.02975v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05551v1","updated":"2025-03-07T16:25:09Z","published":"2025-03-07T16:25:09Z","title":"Revitalizing Saturated Benchmarks: A Weighted Metric Approach for\n  Differentiating Large Language Model Performance","summary":"  Existing benchmarks are becoming saturated and struggle to separate model\nperformances due to factors like data contamination and advancing LLM\ncapabilities. This paper introduces EMDM (Enhanced Model Differentiation\nMetric), a novel weighted metric that revitalizes benchmarks by enhancing model\nseparation. EMDM integrates final answer and Chain-of-Thought (CoT) reasoning\ncorrectness, assigning weights based on the complexity and reasoning depth\nrequired to solve a given sample in the evaluation data. Using a baseline LLM\nin two setups-Unguided, where the model has no prior exposure to test samples,\nand Guided, where the model has prior knowledge of the desired answer-EMDM\ndistinguishes instances of varying difficulty. The CoT and answer correctness\nfrom these setups inform an optimization objective for weight assignment,\nresulting in a more nuanced evaluation of model performance. Compared to the\nexact match (EM) metric, which achieves 17% separation on ARC-Challenge, EMDM\nachieves 46%, demonstrating its effectiveness in differentiating models based\non reasoning and knowledge requirements.\n","authors":["Bryan Etzine","Masoud Hashemi","Nishanth Madhusudhan","Sagar Davasam","Roshnee Sharma","Sathwik Tejaswi Madhusudhan","Vikas Yadav"],"pdf_url":"https://arxiv.org/pdf/2503.05551v1.pdf","comment":"conference NAACL, TrustNLP Workshop"},{"id":"http://arxiv.org/abs/2503.05546v1","updated":"2025-03-07T16:19:19Z","published":"2025-03-07T16:19:19Z","title":"Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement\n  Learning","summary":"  As image-based deep reinforcement learning tackles more challenging tasks,\nincreasing model size has become an important factor in improving performance.\nRecent studies achieved this by focusing on the parameter efficiency of scaled\nnetworks, typically using Impala-CNN, a 15-layer ResNet-inspired network, as\nthe image encoder. However, while Impala-CNN evidently outperforms older CNN\narchitectures, potential advancements in network design for deep reinforcement\nlearning-specific image encoders remain largely unexplored. We find that\nreplacing the flattening of output feature maps in Impala-CNN with global\naverage pooling leads to a notable performance improvement. This approach\noutperforms larger and more complex models in the Procgen Benchmark,\nparticularly in terms of generalization. We call our proposed encoder model\nImpoola-CNN. A decrease in the network's translation sensitivity may be central\nto this improvement, as we observe the most significant gains in games without\nagent-centered observations. Our results demonstrate that network scaling is\nnot just about increasing model size - efficient network design is also an\nessential factor.\n","authors":["Raphael Trumpp","Ansgar Schäfftlein","Mirco Theile","Marco Caccamo"],"pdf_url":"https://arxiv.org/pdf/2503.05546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10457v2","updated":"2025-03-07T16:10:36Z","published":"2024-02-16T05:27:13Z","title":"Learning-Augmented Search Data Structures","summary":"  We study the integration of machine learning advice to improve upon\ntraditional data structure designed for efficient search queries. Although\nthere has been recent effort in improving the performance of binary search\ntrees using machine learning advice, e.g., Lin et. al. (ICML 2022), the\nresulting constructions nevertheless suffer from inherent weaknesses of binary\nsearch trees, such as complexity of maintaining balance across multiple updates\nand the inability to handle partially-ordered or high-dimensional datasets. For\nthese reasons, we focus on skip lists and KD trees in this work. Given access\nto a possibly erroneous oracle that outputs estimated fractional frequencies\nfor search queries on a set of items, we construct skip lists and KD trees that\nprovably provides the optimal expected search time, within nearly a factor of\ntwo. In fact, our learning-augmented skip lists and KD trees are still optimal\nup to a constant factor, even if the oracle is only accurate within a constant\nfactor. We also demonstrate robustness by showing that our data structures\nachieves an expected search time that is within a constant factor of an\noblivious skip list/KD tree construction even when the predictions are\narbitrarily incorrect. Finally, we empirically show that our learning-augmented\nsearch data structures outperforms their corresponding traditional analogs on\nboth synthetic and real-world datasets.\n","authors":["Chunkai Fu","Brandon G. Nguyen","Jung Hoon Seo","Ryan Zesch","Samson Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.10457v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05540v1","updated":"2025-03-07T16:08:53Z","published":"2025-03-07T16:08:53Z","title":"Riemann$^2$: Learning Riemannian Submanifolds from Riemannian Data","summary":"  Latent variable models are powerful tools for learning low-dimensional\nmanifolds from high-dimensional data. However, when dealing with constrained\ndata such as unit-norm vectors or symmetric positive-definite matrices,\nexisting approaches ignore the underlying geometric constraints or fail to\nprovide meaningful metrics in the latent space. To address these limitations,\nwe propose to learn Riemannian latent representations of such geometric data.\nTo do so, we estimate the pullback metric induced by a Wrapped Gaussian Process\nLatent Variable Model, which explicitly accounts for the data geometry. This\nenables us to define geometry-aware notions of distance and shortest paths in\nthe latent space, while ensuring that our model only assigns probability mass\nto the data manifold. This generalizes previous work and allows us to handle\ncomplex tasks in various domains, including robot motion synthesis and analysis\nof brain connectomes.\n","authors":["Leonel Rozo","Miguel González-Duque","Noémie Jaquier","Søren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2503.05540v1.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.05538v1","updated":"2025-03-07T16:04:34Z","published":"2025-03-07T16:04:34Z","title":"Additive Model Boosting: New Insights and Path(ologie)s","summary":"  Additive models (AMs) have sparked a lot of interest in machine learning\nrecently, allowing the incorporation of interpretable structures into a wide\nrange of model classes. Many commonly used approaches to fit a wide variety of\npotentially complex additive models build on the idea of boosting additive\nmodels. While boosted additive models (BAMs) work well in practice, certain\ntheoretical aspects are still poorly understood, including general convergence\nbehavior and what optimization problem is being solved when accounting for the\nimplicit regularizing nature of boosting. In this work, we study the solution\npaths of BAMs and establish connections with other approaches for certain\nclasses of problems. Along these lines, we derive novel convergence results for\nBAMs, which yield crucial insights into the inner workings of the method. While\nour results generally provide reassuring theoretical evidence for the practical\nuse of BAMs, they also uncover some ``pathologies'' of boosting for certain\nadditive model classes concerning their convergence behavior that require\ncaution in practice. We empirically validate our theoretical findings through\nseveral numerical experiments.\n","authors":["Rickmer Schulte","David Rügamer"],"pdf_url":"https://arxiv.org/pdf/2503.05538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04836v3","updated":"2025-03-07T15:55:55Z","published":"2024-02-07T13:32:53Z","title":"On the Completeness of Invariant Geometric Deep Learning Models","summary":"  Invariant models, one important class of geometric deep learning models, are\ncapable of generating meaningful geometric representations by leveraging\ninformative geometric features in point clouds. These models are characterized\nby their simplicity, good experimental results and computational efficiency.\nHowever, their theoretical expressive power still remains unclear, restricting\na deeper understanding of the potential of such models. In this work, we\nconcentrate on characterizing the theoretical expressiveness of a wide range of\ninvariant models under fully-connected conditions. We first rigorously\ncharacterize the expressiveness of the most classic invariant model,\nmessage-passing neural networks incorporating distance (DisGNN), restricting\nits unidentifiable cases to be only highly symmetric point clouds. We then\nprove that GeoNGNN, the geometric counterpart of one of the simplest subgraph\ngraph neural networks, can effectively break these corner cases' symmetry and\nthus achieve E(3)-completeness. By leveraging GeoNGNN as a theoretical tool, we\nfurther prove that: 1) most subgraph GNNs developed in traditional graph\nlearning can be seamlessly extended to geometric scenarios with\nE(3)-completeness; 2) DimeNet, GemNet and SphereNet, three well-established\ninvariant models, are also all capable of achieving E(3)-completeness. Our\ntheoretical results fill the gap in the expressive power of invariant models,\ncontributing to a rigorous and comprehensive understanding of their\ncapabilities.\n","authors":["Zian Li","Xiyuan Wang","Shijia Kang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.04836v3.pdf","comment":"The Thirteenth International Conference on Learning Representations"},{"id":"http://arxiv.org/abs/2503.05530v1","updated":"2025-03-07T15:54:04Z","published":"2025-03-07T15:54:04Z","title":"Leveraging Approximate Caching for Faster Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances the reliability of large\nlanguage model (LLM) answers by integrating external knowledge. However, RAG\nincreases the end-to-end inference time since looking for relevant documents\nfrom large vector databases is computationally expensive. To address this, we\nintroduce Proximity, an approximate key-value cache that optimizes the RAG\nworkflow by leveraging similarities in user queries. Instead of treating each\nquery independently, Proximity reuses previously retrieved documents when\nsimilar queries appear, reducing reliance on expensive vector database lookups.\nWe evaluate Proximity on the MMLU and MedRAG benchmarks, demonstrating that it\nsignificantly improves retrieval efficiency while maintaining response\naccuracy. Proximity reduces retrieval latency by up to 59% while maintaining\naccuracy and lowers the computational burden on the vector database. We also\nexperiment with different similarity thresholds and quantify the trade-off\nbetween speed and recall. Our work shows that approximate caching is a viable\nand effective strategy for optimizing RAG-based systems.\n","authors":["Shai Bergman","Zhang Ji","Anne-Marie Kermarrec","Diana Petrescu","Rafael Pires","Mathis Randl","Martijn de Vos"],"pdf_url":"https://arxiv.org/pdf/2503.05530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05525v1","updated":"2025-03-07T15:46:30Z","published":"2025-03-07T15:46:30Z","title":"Machine Learning for Improved Density Functional Theory Thermodynamics","summary":"  The predictive accuracy of density functional theory (DFT) for alloy\nformation enthalpies is often limited by intrinsic energy resolution errors,\nparticularly in ternary phase stability calculations. In this work, we present\na machine learning (ML) approach to systematically correct these errors,\nimproving the reliability of first-principles predictions. A neural network\nmodel has been trained to predict the discrepancy between DFT-calculated and\nexperimentally measured enthalpies for binary and ternary alloys and compounds.\nThe model utilizes a structured feature set comprising elemental\nconcentrations, atomic numbers, and interaction terms to capture key chemical\nand structural effects. By applying supervised learning and rigorous data\ncuration we ensure a robust and physically meaningful correction. The model is\nimplemented as a multi-layer perceptron (MLP) regressor with three hidden\nlayers, optimized through leave-one-out cross-validation (LOOCV) and k-fold\ncross-validation to prevent overfitting. We illustrate the effectiveness of\nthis method by applying it to the Al-Ni-Pd and Al-Ni-Ti systems, which are of\ninterest for high-temperature applications in aerospace and protective\ncoatings.\n","authors":["Sergei I. Simak","Erna K. Delczeg-Czirjak","Olle Eriksson"],"pdf_url":"https://arxiv.org/pdf/2503.05525v1.pdf","comment":"9 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.05522v1","updated":"2025-03-07T15:45:43Z","published":"2025-03-07T15:45:43Z","title":"Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept\n  Representations","summary":"  Concept Activation Vectors (CAVs) are widely used to model\nhuman-understandable concepts as directions within the latent space of neural\nnetworks. They are trained by identifying directions from the activations of\nconcept samples to those of non-concept samples. However, this method often\nproduces similar, non-orthogonal directions for correlated concepts, such as\n\"beard\" and \"necktie\" within the CelebA dataset, which frequently co-occur in\nimages of men. This entanglement complicates the interpretation of concepts in\nisolation and can lead to undesired effects in CAV applications, such as\nactivation steering. To address this issue, we introduce a post-hoc concept\ndisentanglement method that employs a non-orthogonality loss, facilitating the\nidentification of orthogonal concept directions while preserving directional\ncorrectness. We evaluate our approach with real-world and controlled correlated\nconcepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18\narchitectures. We further demonstrate the superiority of orthogonalized concept\nrepresentations in activation steering tasks, allowing (1) the insertion of\nisolated concepts into input images through generative models and (2) the\nremoval of concepts for effective shortcut suppression with reduced impact on\ncorrelated concepts in comparison to baseline CAVs.\n","authors":["Eren Erogullari","Sebastian Lapuschkin","Wojciech Samek","Frederik Pahde"],"pdf_url":"https://arxiv.org/pdf/2503.05522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05520v1","updated":"2025-03-07T15:42:51Z","published":"2025-03-07T15:42:51Z","title":"Removing Geometric Bias in One-Class Anomaly Detection with Adaptive\n  Feature Perturbation","summary":"  One-class anomaly detection aims to detect objects that do not belong to a\npredefined normal class. In practice training data lack those anomalous\nsamples; hence state-of-the-art methods are trained to discriminate between\nnormal and synthetically-generated pseudo-anomalous data. Most methods use data\naugmentation techniques on normal images to simulate anomalies. However the\nbest-performing ones implicitly leverage a geometric bias present in the\nbenchmarking datasets. This limits their usability in more general conditions.\nOthers are relying on basic noising schemes that may be suboptimal in capturing\nthe underlying structure of normal data. In addition most still favour the\nimage domain to generate pseudo-anomalies training models end-to-end from only\nthe normal class and overlooking richer representations of the information. To\novercome these limitations we consider frozen yet rich feature spaces given by\npretrained models and create pseudo-anomalous features with a novel adaptive\nlinear feature perturbation technique. It adapts the noise distribution to each\nsample applies decaying linear perturbations to feature vectors and further\nguides the classification process using a contrastive learning objective.\nExperimental evaluation conducted on both standard and geometric bias-free\ndatasets demonstrates the superiority of our approach with respect to\ncomparable baselines. The codebase is accessible via our public repository.\n","authors":["Romain Hermary","Vincent Gaudillière","Abd El Rahman Shabayek","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2503.05520v1.pdf","comment":"Published in WACV 2025"},{"id":"http://arxiv.org/abs/2406.09760v2","updated":"2025-03-07T15:26:03Z","published":"2024-06-14T06:57:18Z","title":"Bootstrapping Language Models with DPO Implicit Rewards","summary":"  Human alignment in large language models (LLMs) is an active area of\nresearch. A recent groundbreaking work, direct preference optimization (DPO),\nhas greatly simplified the process from past work in reinforcement learning\nfrom human feedback (RLHF) by bypassing the reward learning stage in RLHF. DPO,\nafter training, provides an implicit reward model. In this work, we make a\nnovel observation that this implicit reward model can by itself be used in a\nbootstrapping fashion to further align the LLM. Our approach is to use the\nrewards from a current LLM to construct a preference dataset, which is then\nused in subsequent DPO rounds. We incorporate two refinements to further\nimprove our approach: 1) length-regularized reward shaping to make the\npreference dataset length-unbiased; 2) experience replay to enhance the quality\nof the preference dataset. Our approach, named self-alignment with DPO ImpliCit\nrEwards (DICE), shows great improvements in alignment. It achieves an increase\nof more than 8$\\\\%$ in lengthcontrolled win rate on AlpacaEval 2 for all the\ndifferent base models that we tried, without relying on external feedback. Our\ncode is available at https://github.com/sail-sg/dice.\n","authors":["Changyu Chen","Zichen Liu","Chao Du","Tianyu Pang","Qian Liu","Arunesh Sinha","Pradeep Varakantham","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2406.09760v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.02126v2","updated":"2025-03-07T15:21:42Z","published":"2024-11-04T14:37:07Z","title":"Unsupervised detection of semantic correlations in big data","summary":"  In real-world data, information is stored in extremely large feature vectors.\nThese variables are typically correlated due to complex interactions involving\nmany features simultaneously. Such correlations qualitatively correspond to\nsemantic roles and are naturally recognized by both the human brain and\nartificial neural networks. This recognition enables, for instance, the\nprediction of missing parts of an image or text based on their context. We\npresent a method to detect these correlations in high-dimensional data\nrepresented as binary numbers. We estimate the binary intrinsic dimension of a\ndataset, which quantifies the minimum number of independent coordinates needed\nto describe the data, and is therefore a proxy of semantic complexity. The\nproposed algorithm is largely insensitive to the so-called curse of\ndimensionality, and can therefore be used in big data analysis. We test this\napproach identifying phase transitions in model magnetic systems and we then\napply it to the detection of semantic correlations of images and text inside\ndeep neural networks.\n","authors":["Santiago Acevedo","Alex Rodriguez","Alessandro Laio"],"pdf_url":"https://arxiv.org/pdf/2411.02126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03463v3","updated":"2025-03-07T15:17:02Z","published":"2024-09-05T12:19:07Z","title":"Massive Activations in Graph Neural Networks: Decoding Attention for\n  Domain-Dependent Interpretability","summary":"  Graph Neural Networks (GNNs) have become increasingly popular for effectively\nmodeling graph-structured data, and attention mechanisms have been pivotal in\nenabling these models to capture complex patterns. In our study, we reveal a\ncritical yet underexplored consequence of integrating attention into\nedge-featured GNNs: the emergence of Massive Activations (MAs) within attention\nlayers. By developing a novel method for detecting MAs on edge features, we\nshow that these extreme activations are not only activation anomalies but\nencode domain-relevant signals. Our post-hoc interpretability analysis\ndemonstrates that, in molecular graphs, MAs aggregate predominantly on common\nbond types (e.g., single and double bonds) while sparing more informative ones\n(e.g., triple bonds). Furthermore, our ablation studies confirm that MAs can\nserve as natural attribution indicators, reallocating to less informative\nedges. Our study assesses various edge-featured attention-based GNN models\nusing benchmark datasets, including ZINC, TOX21, and PROTEINS. Key\ncontributions include (1) establishing the direct link between attention\nmechanisms and MAs generation in edge-featured GNNs, (2) developing a robust\ndefinition and detection method for MAs enabling reliable post-hoc\ninterpretability. Overall, our study reveals the complex interplay between\nattention mechanisms, edge-featured GNNs model, and MAs emergence, providing\ncrucial insights for relating GNNs internals to domain knowledge.\n","authors":["Lorenzo Bini","Marco Sorbi","Stephane Marchand-Maillet"],"pdf_url":"https://arxiv.org/pdf/2409.03463v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05239v4","updated":"2025-03-07T15:13:45Z","published":"2023-08-09T21:54:34Z","title":"Enhancing Architecture Frameworks by Including Modern Stakeholders and\n  their Views/Viewpoints","summary":"  Various architecture frameworks for software, systems, and enterprises have\nbeen proposed in the literature. They identified several stakeholders and\ndefined modeling perspectives, architecture viewpoints, and views to frame and\naddress stakeholder concerns. However, the stakeholders with data science and\nMachine Learning (ML) related concerns, such as data scientists and data\nengineers, are yet to be included in existing architecture frameworks. Only\nthis way can we envision a holistic system architecture description of an\nML-enabled system. Note that the ML component behavior and functionalities are\nspecial and should be distinguished from traditional software system behavior\nand functionalities. The main reason is that the actual functionality should be\ninferred from data instead of being specified at design time. Additionally, the\nstructural models of ML components, such as ML model architectures, are\ntypically specified using different notations and formalisms from what the\nSoftware Engineering (SE) community uses for software structural models. Yet,\nthese two aspects, namely ML and non-ML, are becoming so intertwined that it\nnecessitates an extension of software architecture frameworks and modeling\npractices toward supporting ML-enabled system architectures. In this paper, we\naddress this gap through an empirical study using an online survey instrument.\nWe surveyed 61 subject matter experts from over 25 organizations in 10\ncountries.\n","authors":["Armin Moin","Atta Badii","Stephan Günnemann","Moharram Challenger"],"pdf_url":"https://arxiv.org/pdf/2308.05239v4.pdf","comment":"ICICT 2025"},{"id":"http://arxiv.org/abs/2503.04704v2","updated":"2025-03-07T15:12:57Z","published":"2025-03-06T18:54:32Z","title":"Universality of Layer-Level Entropy-Weighted Quantization Beyond Model\n  Architecture and Size","summary":"  We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.\n","authors":["Alireza Behtash","Marijan Fofonjka","Ethan Baird","Tyler Mauer","Hossein Moghimifam","David Stout","Joel Dennison"],"pdf_url":"https://arxiv.org/pdf/2503.04704v2.pdf","comment":"29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements"},{"id":"http://arxiv.org/abs/2404.10386v2","updated":"2025-03-07T15:11:30Z","published":"2024-04-16T08:37:36Z","title":"I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey","summary":"  Growing interest in Artificial Intelligence (AI) has resulted in a surge in\ndemand for faster methods of Machine Learning (ML) model training and\ninference. This demand for speed has prompted the use of high performance\ncomputing (HPC) systems that excel in managing distributed workloads. Because\ndata is the main fuel for AI applications, the performance of the storage and\nI/O subsystem of HPC systems is critical. In the past, HPC applications\naccessed large portions of data written by simulations or experiments or\ningested data for visualizations or analysis tasks. ML workloads perform small\nreads spread across a large number of random files. This shift of I/O access\npatterns poses several challenges to modern parallel storage systems. In this\npaper, we survey I/O in ML applications on HPC systems, and target literature\nwithin a 6-year time window from 2019 to 2024. We define the scope of the\nsurvey, provide an overview of the common phases of ML, review available\nprofilers and benchmarks, examine the I/O patterns encountered during offline\ndata preparation, training, and inference, and explore I/O optimizations\nutilized in modern ML frameworks and proposed in recent literature. Lastly, we\nseek to expose research gaps that could spawn further R&D.\n","authors":["Noah Lewis","Jean Luca Bez","Surendra Byna"],"pdf_url":"https://arxiv.org/pdf/2404.10386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05499v1","updated":"2025-03-07T15:10:37Z","published":"2025-03-07T15:10:37Z","title":"Mol-CADiff: Causality-Aware Autoregressive Diffusion for Molecule\n  Generation","summary":"  The design of novel molecules with desired properties is a key challenge in\ndrug discovery and materials science. Traditional methods rely on\ntrial-and-error, while recent deep learning approaches have accelerated\nmolecular generation. However, existing models struggle with generating\nmolecules based on specific textual descriptions. We introduce Mol-CADiff, a\nnovel diffusion-based framework that uses causal attention mechanisms for\ntext-conditional molecular generation. Our approach explicitly models the\ncausal relationship between textual prompts and molecular structures,\novercoming key limitations in existing methods. We enhance dependency modeling\nboth within and across modalities, enabling precise control over the generation\nprocess. Our extensive experiments demonstrate that Mol-CADiff outperforms\nstate-of-the-art methods in generating diverse, novel, and chemically valid\nmolecules, with better alignment to specified properties, enabling more\nintuitive language-driven molecular design.\n","authors":["Md Atik Ahamed","Qiang Ye","Qiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05491v1","updated":"2025-03-07T15:00:28Z","published":"2025-03-07T15:00:28Z","title":"Statistical Deficiency for Task Inclusion Estimation","summary":"  Tasks are central in machine learning, as they are the most natural objects\nto assess the capabilities of current models. The trend is to build general\nmodels able to address any task. Even though transfer learning and multitask\nlearning try to leverage the underlying task space, no well-founded tools are\navailable to study its structure. This study proposes a theoretically grounded\nsetup to define the notion of task and to compute the {\\bf inclusion} between\ntwo tasks from a statistical deficiency point of view. We propose a tractable\nproxy as information sufficiency to estimate the degree of inclusion between\ntasks, show its soundness on synthetic data, and use it to reconstruct\nempirically the classic NLP pipeline.\n","authors":["Loïc Fosse","Frédéric Béchet","Benoît Favre","Géraldine Damnati","Gwénolé Lecorvé","Maxime Darrin","Philippe Formont","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2503.05491v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2501.08998v2","updated":"2025-03-07T14:55:40Z","published":"2025-01-15T18:26:35Z","title":"CrystalGRW: Generative Modeling of Crystal Structures with Targeted\n  Properties via Geodesic Random Walks","summary":"  Determining whether a candidate crystalline material is thermodynamically\nstable depends on identifying its true ground-state structure, a central\nchallenge in computational materials science. We introduce CrystalGRW, a\ndiffusion-based generative model on Riemannian manifolds that proposes novel\ncrystal configurations and can predict stable phases validated by density\nfunctional theory. The crystal properties, such as fractional coordinates,\natomic types, and lattice matrices, are represented on suitable Riemannian\nmanifolds, ensuring that new predictions generated through the diffusion\nprocess preserve the periodicity of crystal structures. We incorporate an\nequivariant graph neural network to also account for rotational and\ntranslational symmetries during the generation process. CrystalGRW demonstrates\nthe ability to generate realistic crystal structures that are close to their\nground states with accuracy comparable to existing models, while also enabling\nconditional control, such as specifying a desired crystallographic point group.\nThese features help accelerate materials discovery and inverse design by\noffering stable, symmetry-consistent crystal candidates for experimental\nvalidation.\n","authors":["Krit Tangsongcharoen","Teerachote Pakornchote","Chayanon Atthapak","Natthaphon Choomphon-anomakhun","Annop Ektarawong","Björn Alling","Christopher Sutton","Thiti Bovornratanaraks","Thiparat Chotibut"],"pdf_url":"https://arxiv.org/pdf/2501.08998v2.pdf","comment":"10+12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.05482v1","updated":"2025-03-07T14:51:32Z","published":"2025-03-07T14:51:32Z","title":"Bridging the Semantic Gap in Virtual Machine Introspection and Forensic\n  Memory Analysis","summary":"  Forensic Memory Analysis (FMA) and Virtual Machine Introspection (VMI) are\ncritical tools for security in a virtualization-based approach. VMI and FMA\ninvolves using digital forensic methods to extract information from the system\nto identify and explain security incidents. A key challenge in both FMA and VMI\nis the \"Semantic Gap\", which is the difficulty of interpreting raw memory data\nwithout specialized tools and expertise. In this work, we investigate how a\npriori knowledge, metadata and engineered features can aid VMI and FMA,\nleveraging machine learning to automate information extraction and reduce the\nworkload of forensic investigators. We choose OpenSSH as our use case to test\ndifferent methods to extract high level structures. We also test our method on\ncomplete physical memory dumps to showcase the effectiveness of the engineered\nfeatures. Our features range from basic statistical features to advanced\ngraph-based representations using malloc headers and pointer translations. The\ntraining and testing are carried out on public datasets that we compare against\nalready recognized baseline methods. We show that using metadata, we can\nimprove the performance of the algorithm when there is very little training\ndata and also quantify how having more data results in better generalization\nperformance. The final contribution is an open dataset of physical memory\ndumps, totalling more than 1 TB of different memory state, software\nenvironments, main memory capacities and operating system versions. Our methods\nshow that having more metadata boosts performance with all methods obtaining an\nF1-Score of over 80%. Our research underscores the possibility of using feature\nengineering and machine learning techniques to bridge the semantic gap.\n","authors":["Christofer Fellicious","Hans P. Reiser","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2503.05482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02694v4","updated":"2025-03-07T14:49:07Z","published":"2024-03-05T06:23:50Z","title":"MeanCache: User-Centric Semantic Caching for LLM Web Services","summary":"  Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.\n","authors":["Waris Gill","Mohamed Elidrisi","Pallavi Kalapatapu","Ammar Ahmed","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2403.02694v4.pdf","comment":"Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)"},{"id":"http://arxiv.org/abs/2503.05477v1","updated":"2025-03-07T14:47:56Z","published":"2025-03-07T14:47:56Z","title":"Enhancing Network Security: A Hybrid Approach for Detection and\n  Mitigation of Distributed Denial-of-Service Attacks Using Machine Learning","summary":"  The distributed denial-of-service (DDoS) attack stands out as a highly\nformidable cyber threat, representing an advanced form of the denial-of-service\n(DoS) attack. A DDoS attack involves multiple computers working together to\noverwhelm a system, making it unavailable. On the other hand, a DoS attack is a\none-on-one attempt to make a system or website inaccessible. Thus, it is\ncrucial to construct an effective model for identifying various DDoS incidents.\nAlthough extensive research has focused on binary detection models for DDoS\nidentification, they face challenges to adapt evolving threats, necessitating\nfrequent updates. Whereas multiclass detection models offer a comprehensive\ndefense against diverse DDoS attacks, ensuring adaptability in the\never-changing cyber threat landscape. In this paper, we propose a Hybrid Model\nto strengthen network security by combining the featureextraction abilities of\n1D Convolutional Neural Networks (CNNs) with the classification skills of\nRandom Forest (RF) and Multi-layer Perceptron (MLP) classifiers. Using the\nCIC-DDoS2019 dataset, we perform multiclass classification of various DDoS\nattacks and conduct a comparative analysis of evaluation metrics for RF, MLP,\nand our proposed Hybrid Model. After analyzing the results, we draw meaningful\nconclusions and confirm the superiority of our Hybrid Model by performing\nthorough cross-validation. Additionally, we integrate our machine learning\nmodel with Snort, which provides a robust and adaptive solution for detecting\nand mitigating various DDoS attacks.\n","authors":["Nizo Jaman Shohan","Gazi Tanbhir","Faria Elahi","Ahsan Ullah","Md. Nazmus Sakib"],"pdf_url":"https://arxiv.org/pdf/2503.05477v1.pdf","comment":"Part of the book series: Communications in Computer and Information\n  Science ((CCIS,volume 2091))"},{"id":"http://arxiv.org/abs/2503.05474v1","updated":"2025-03-07T14:47:03Z","published":"2025-03-07T14:47:03Z","title":"Personalized Federated Learning via Learning Dynamic Graphs","summary":"  Personalized Federated Learning (PFL) aims to train a personalized model for\neach client that is tailored to its local data distribution, learning fails to\nperform well on individual clients due to variations in their local data\ndistributions. Most existing PFL methods focus on personalizing the aggregated\nglobal model for each client, neglecting the fundamental aspect of federated\nlearning: the regulation of how client models are aggregated. Additionally,\nalmost all of them overlook the graph structure formed by clients in federated\nlearning. In this paper, we propose a novel method, Personalized Federated\nLearning with Graph Attention Network (pFedGAT), which captures the latent\ngraph structure between clients and dynamically determines the importance of\nother clients for each client, enabling fine-grained control over the\naggregation process. We evaluate pFedGAT across multiple data distribution\nscenarios, comparing it with twelve state of the art methods on three datasets:\nFashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs\nwell.\n","authors":["Ziran Zhou","Guanyu Gao","Xiaohu Wu","Yan Lyu"],"pdf_url":"https://arxiv.org/pdf/2503.05474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12481v2","updated":"2025-03-07T14:46:22Z","published":"2024-08-22T15:17:02Z","title":"Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio\n  Sensors","summary":"  This paper proposes a self-learning method to incrementally train (fine-tune)\na personalized Keyword Spotting (KWS) model after the deployment on ultra-low\npower smart audio sensors. We address the fundamental problem of the absence of\nlabeled training data by assigning pseudo-labels to the new recorded audio\nframes based on a similarity score with respect to few user recordings. By\nexperimenting with multiple KWS models with a number of parameters up to 0.5M\non two public datasets, we show an accuracy improvement of up to +19.2% and\n+16.0% vs. the initial models pretrained on a large set of generic keywords.\nThe labeling task is demonstrated on a sensor system composed of a low-power\nmicrophone and an energy-efficient Microcontroller (MCU). By efficiently\nexploiting the heterogeneous processing engines of the MCU, the always-on\nlabeling task runs in real-time with an average power cost of up to 8.2 mW. On\nthe same platform, we estimate an energy cost for on-device training 10x lower\nthan the labeling energy if sampling a new utterance every 6.1 s or 18.8 s with\na DS-CNN-S or a DS-CNN-M model. Our empirical result paves the way to\nself-adaptive personalized KWS sensors at the extreme edge.\n","authors":["Manuele Rusci","Francesco Paci","Marco Fariselli","Eric Flamand","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2408.12481v2.pdf","comment":"Published on IEEE IoT Journal"},{"id":"http://arxiv.org/abs/2410.04209v2","updated":"2025-03-07T14:32:12Z","published":"2024-10-05T15:56:57Z","title":"Equivariant Neural Functional Networks for Transformers","summary":"  This paper systematically explores neural functional networks (NFN) for\ntransformer architectures. NFN are specialized neural networks that treat the\nweights, gradients, or sparsity patterns of a deep neural network (DNN) as\ninput data and have proven valuable for tasks such as learnable optimizers,\nimplicit data representations, and weight editing. While NFN have been\nextensively developed for MLP and CNN, no prior work has addressed their design\nfor transformers, despite the importance of transformers in modern deep\nlearning. This paper aims to address this gap by providing a systematic study\nof NFN for transformers. We first determine the maximal symmetric group of the\nweights in a multi-head attention module as well as a necessary and sufficient\ncondition under which two sets of hyperparameters of the multi-head attention\nmodule define the same function. We then define the weight space of transformer\narchitectures and its associated group action, which leads to the design\nprinciples for NFN in transformers. Based on these, we introduce\nTransformer-NFN, an NFN that is equivariant under this group action.\nAdditionally, we release a dataset of more than 125,000 Transformers model\ncheckpoints trained on two datasets with two different tasks, providing a\nbenchmark for evaluating Transformer-NFN and encouraging further research on\ntransformer training and performance.\n","authors":["Viet-Hoang Tran","Thieu N. Vo","An Nguyen The","Tho Tran Huu","Minh-Khoi Nguyen-Nhat","Thanh Tran","Duy-Tung Pham","Tan Minh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.04209v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2502.09685v2","updated":"2025-03-07T14:32:04Z","published":"2025-02-13T14:30:11Z","title":"A Novel Hybrid Approach to Contraceptive Demand Forecasting: Integrating\n  Point Predictions with Probabilistic Distributions","summary":"  Accurate demand forecasting is vital for ensuring reliable access to\ncontraceptive products, supporting key processes like procurement, inventory,\nand distribution. However, forecasting contraceptive demand in developing\ncountries presents challenges, including incomplete data, poor data quality,\nand the need to account for multiple geographical and product factors. Current\nmethods often rely on simple forecasting techniques, which fail to capture\ndemand uncertainties arising from these factors, warranting expert involvement.\nOur study aims to improve contraceptive demand forecasting by combining\nprobabilistic forecasting methods with expert knowledge. We developed a hybrid\nmodel that combines point forecasts from domain-specific model with\nprobabilistic distributions from statistical and machine learning approaches,\nenabling human input to fine-tune and enhance the system-generated forecasts.\nThis approach helps address the uncertainties in demand and is particularly\nuseful in resource-limited settings. We evaluate different forecasting methods,\nincluding time series, Bayesian, machine learning, and foundational time series\nmethods alongside our new hybrid approach. By comparing these methods, we\nprovide insights into their strengths, weaknesses, and computational\nrequirements. Our research fills a gap in forecasting contraceptive demand and\noffers a practical framework that combines algorithmic and human expertise. Our\nproposed model can also be generalized to other humanitarian contexts with\nsimilar data patterns.\n","authors":["Harsha Chamara Hewage","Bahman Rostami-Tabar","Aris Syntetos","Federico Liberatore","Glenn Milano"],"pdf_url":"https://arxiv.org/pdf/2502.09685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01639v2","updated":"2025-03-07T14:31:52Z","published":"2025-03-03T15:19:16Z","title":"Cauchy-Schwarz Regularizers","summary":"  We introduce a novel class of regularization functions, called Cauchy-Schwarz\n(CS) regularizers, which can be designed to induce a wide range of properties\nin solution vectors of optimization problems. To demonstrate the versatility of\nCS regularizers, we derive regularization functions that promote\ndiscrete-valued vectors, eigenvectors of a given matrix, and orthogonal\nmatrices. The resulting CS regularizers are simple, differentiable, and can be\nfree of spurious stationary points, making them suitable for gradient-based\nsolvers and large-scale optimization problems. In addition, CS regularizers\nautomatically adapt to the appropriate scale, which is, for example, beneficial\nwhen discretizing the weights of neural networks. To demonstrate the efficacy\nof CS regularizers, we provide results for solving underdetermined systems of\nlinear equations and weight quantization in neural networks. Furthermore, we\ndiscuss specializations, variations, and generalizations, which lead to an even\nbroader class of new and possibly more powerful regularizers.\n","authors":["Sueda Taner","Ziyi Wang","Christoph Studer"],"pdf_url":"https://arxiv.org/pdf/2503.01639v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.00962v3","updated":"2025-03-07T14:31:49Z","published":"2025-01-01T21:47:52Z","title":"OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes","summary":"  Images generated by text-to-image (T2I) models often exhibit visual biases\nand stereotypes of concepts such as culture and profession. Existing\nquantitative measures of stereotypes are based on statistical parity that does\nnot align with the sociological definition of stereotypes and, therefore,\nincorrectly categorizes biases as stereotypes. Instead of oversimplifying\nstereotypes as biases, we propose a quantitative measure of stereotypes that\naligns with its sociological definition. We then propose OASIS to measure the\nstereotypes in a generated dataset and understand their origins within the T2I\nmodel. OASIS includes two scores to measure stereotypes from a generated image\ndataset: (M1) Stereotype Score to measure the distributional violation of\nstereotypical attributes, and (M2) WALS to measure spectral variance in the\nimages along a stereotypical attribute. OASIS also includes two methods to\nunderstand the origins of stereotypes in T2I models: (U1) StOP to discover\nattributes that the T2I model internally associates with a given concept, and\n(U2) SPI to quantify the emergence of stereotypical attributes in the latent\nspace of the T2I model during image generation. Despite the considerable\nprogress in image fidelity, using OASIS, we conclude that newer T2I models such\nas FLUX.1 and SDv3 contain strong stereotypical predispositions about concepts\nand still generate images with widespread stereotypical attributes.\nAdditionally, the quantity of stereotypes worsens for nationalities with lower\nInternet footprints.\n","authors":["Sepehr Dehdashtian","Gautam Sreekumar","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2501.00962v3.pdf","comment":"Accepted as a Spotlight paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05453v1","updated":"2025-03-07T14:23:40Z","published":"2025-03-07T14:23:40Z","title":"Soft Policy Optimization: Online Off-Policy RL for Sequence Models","summary":"  RL-based post-training of language models is almost exclusively done using\non-policy methods such as PPO. These methods cannot learn from arbitrary\nsequences such as those produced earlier in training, in earlier runs, by human\nexperts or other policies, or by decoding and exploration methods. This results\nin severe sample inefficiency and exploration difficulties, as well as a\npotential loss of diversity in the policy responses. Moreover, asynchronous PPO\nimplementations require frequent and costly model transfers, and typically use\nvalue models which require a large amount of memory. In this paper we introduce\nSoft Policy Optimization (SPO), a simple, scalable and principled Soft RL\nmethod for sequence model policies that can learn from arbitrary online and\noffline trajectories and does not require a separate value model. In\nexperiments on code contests, we shows that SPO outperforms PPO on pass@10, is\nsignificantly faster and more memory efficient, is able to benefit from\noff-policy data, enjoys improved stability, and learns more diverse (i.e. soft)\npolicies.\n","authors":["Taco Cohen","David W. Zhang","Kunhao Zheng","Yunhao Tang","Remi Munos","Gabriel Synnaeve"],"pdf_url":"https://arxiv.org/pdf/2503.05453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06287v3","updated":"2025-03-07T14:20:58Z","published":"2024-02-09T09:54:01Z","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","summary":"  Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.\n","authors":["Clara Punzi","Roberto Pellungrini","Mattia Setzu","Fosca Giannotti","Dino Pedreschi"],"pdf_url":"https://arxiv.org/pdf/2402.06287v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19798v2","updated":"2025-03-07T14:20:23Z","published":"2024-09-29T21:49:32Z","title":"Membership Inference Attacks Cannot Prove that a Model Was Trained On\n  Your Data","summary":"  We consider the problem of a training data proof, where a data creator or\nowner wants to demonstrate to a third party that some machine learning model\nwas trained on their data. Training data proofs play a key role in recent\nlawsuits against foundation models trained on web-scale data. Many prior works\nsuggest to instantiate training data proofs using membership inference attacks.\nWe argue that this approach is fundamentally unsound: to provide convincing\nevidence, the data creator needs to demonstrate that their attack has a low\nfalse positive rate, i.e., that the attack's output is unlikely under the null\nhypothesis that the model was not trained on the target data. Yet, sampling\nfrom this null hypothesis is impossible, as we do not know the exact contents\nof the training set, nor can we (efficiently) retrain a large foundation model.\nWe conclude by offering two paths forward, by showing that data extraction\nattacks and membership inference on special canary data can be used to create\nsound training data proofs.\n","authors":["Jie Zhang","Debeshee Das","Gautam Kamath","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2409.19798v2.pdf","comment":"position paper at IEEE SaTML 2025"},{"id":"http://arxiv.org/abs/2503.05447v1","updated":"2025-03-07T14:17:45Z","published":"2025-03-07T14:17:45Z","title":"Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts","summary":"  Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.\n","authors":["Weigao Sun","Disen Lan","Tong Zhu","Xiaoye Qu","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05447v1.pdf","comment":"Technical report, 17 pages"},{"id":"http://arxiv.org/abs/2503.05431v1","updated":"2025-03-07T14:01:25Z","published":"2025-03-07T14:01:25Z","title":"Quantum-PEFT: Ultra parameter-efficient fine-tuning","summary":"  This paper introduces Quantum-PEFT that leverages quantum computations for\nparameter-efficient fine-tuning (PEFT). Unlike other additive PEFT methods,\nsuch as low-rank adaptation (LoRA), Quantum-PEFT exploits an underlying\nfull-rank yet surprisingly parameter efficient quantum unitary\nparameterization. With the use of Pauli parameterization, the number of\ntrainable parameters grows only logarithmically with the ambient dimension, as\nopposed to linearly as in LoRA-based PEFT methods. Quantum-PEFT achieves\nvanishingly smaller number of trainable parameters than the lowest-rank LoRA as\ndimensions grow, enhancing parameter efficiency while maintaining a competitive\nperformance. We apply Quantum-PEFT to several transfer learning benchmarks in\nlanguage and vision, demonstrating significant advantages in parameter\nefficiency.\n","authors":["Toshiaki Koike-Akino","Francesco Tonin","Yongtao Wu","Frank Zhengqing Wu","Leyla Naz Candogan","Volkan Cevher"],"pdf_url":"https://arxiv.org/pdf/2503.05431v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03292v2","updated":"2025-03-07T13:54:48Z","published":"2024-10-04T10:06:17Z","title":"Demystifying the Token Dynamics of Deep Selective State Space Models","summary":"  Selective state space models (SSM), such as Mamba, have gained prominence for\ntheir effectiveness in modeling sequential data. Despite their outstanding\nempirical performance, a comprehensive theoretical understanding of deep\nselective SSM remains elusive, hindering their further development and adoption\nfor applications that need high fidelity. In this paper, we investigate the\ndynamical properties of tokens in a pre-trained Mamba model. In particular, we\nderive the dynamical system governing the continuous-time limit of the Mamba\nmodel and characterize the asymptotic behavior of its solutions. In the\none-dimensional case, we prove that only one of the following two scenarios\nhappens: either all tokens converge to zero, or all tokens diverge to infinity.\nWe provide criteria based on model parameters to determine when each scenario\noccurs. For the convergent scenario, we empirically verify that this scenario\nnegatively impacts the model's performance. For the divergent scenario, we\nprove that different tokens will diverge to infinity at different rates,\nthereby contributing unequally to the updates during model training. Based on\nthese investigations, we propose two refinements for the model: excluding the\nconvergent scenario and reordering tokens based on their importance scores,\nboth aimed at improving practical performance. Our experimental results\nvalidate these refinements, offering insights into enhancing Mamba's\neffectiveness in real-world applications.\n","authors":["Thieu N Vo","Tung D. Pham","Xin T. Tong","Tan Minh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.03292v2.pdf","comment":"Accepted at ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2503.05424v1","updated":"2025-03-07T13:50:37Z","published":"2025-03-07T13:50:37Z","title":"Towards Locally Explaining Prediction Behavior via Gradual Interventions\n  and Measuring Property Gradients","summary":"  Deep learning models achieve high predictive performance but lack intrinsic\ninterpretability, hindering our understanding of the learned prediction\nbehavior. Existing local explainability methods focus on associations,\nneglecting the causal drivers of model predictions. Other approaches adopt a\ncausal perspective but primarily provide more general global explanations.\nHowever, for specific inputs, it's unclear whether globally identified factors\napply locally. To address this limitation, we introduce a novel framework for\nlocal interventional explanations by leveraging recent advances in\nimage-to-image editing models. Our approach performs gradual interventions on\nsemantic properties to quantify the corresponding impact on a model's\npredictions using a novel score, the expected property gradient magnitude. We\ndemonstrate the effectiveness of our approach through an extensive empirical\nevaluation on a wide range of architectures and tasks. First, we validate it in\na synthetic scenario and demonstrate its ability to locally identify biases.\nAfterward, we apply our approach to analyze network training dynamics,\ninvestigate medical skin lesion classifiers, and study a pre-trained CLIP model\nwith real-life interventional data. Our results highlight the potential of\ninterventional explanations on the property level to reveal new insights into\nthe behavior of deep models.\n","authors":["Niklas Penzel","Joachim Denzler"],"pdf_url":"https://arxiv.org/pdf/2503.05424v1.pdf","comment":"44 pages, 39 figures, 14 tables"},{"id":"http://arxiv.org/abs/2503.05423v1","updated":"2025-03-07T13:50:29Z","published":"2025-03-07T13:50:29Z","title":"Semantic Shift Estimation via Dual-Projection and Classifier\n  Reconstruction for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn\nfrom distinct categories without retaining exemplars but easily suffers from\ncatastrophic forgetting of learned knowledge. While existing EFCIL methods\nleverage knowledge distillation to alleviate forgetting, they still face two\ncritical challenges: semantic shift and decision bias. Specifically, the\nembeddings of old tasks shift in the embedding space after learning new tasks,\nand the classifier becomes biased towards new tasks due to training solely with\nnew data, thereby hindering the balance between old and new knowledge. To\naddress these issues, we propose the Dual-Projection Shift Estimation and\nClassifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates\nsemantic shift through a dual-projection, which combines a learnable\ntransformation with a row-space projection to capture both task-wise and\ncategory-wise shifts. Furthermore, to mitigate decision bias, DPCR employs\nridge regression to reformulate classifier training as a reconstruction\nprocess. This reconstruction exploits previous information encoded in\ncovariance and prototype of each class after calibration with estimated shift,\nthereby reducing decision bias. Extensive experiments demonstrate that, across\nvarious datasets, DPCR effectively balances old and new tasks, outperforming\nstate-of-the-art EFCIL methods.\n","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.05423v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.13593v2","updated":"2025-03-07T13:45:22Z","published":"2025-02-19T10:12:19Z","title":"Toward Robust Non-Transferable Learning: A Survey and Benchmark","summary":"  Over the past decades, researchers have primarily focused on improving the\ngeneralization abilities of models, with limited attention given to regulating\nsuch generalization. However, the ability of models to generalize to unintended\ndata (e.g., harmful or unauthorized data) can be exploited by malicious\nadversaries in unforeseen ways, potentially resulting in violations of model\nethics. Non-transferable learning (NTL), a task aimed at reshaping the\ngeneralization abilities of deep learning models, was proposed to address these\nchallenges. While numerous methods have been proposed in this field, a\ncomprehensive review of existing progress and a thorough analysis of current\nlimitations remain lacking. In this paper, we bridge this gap by presenting the\nfirst comprehensive survey on NTL and introducing NTLBench, the first benchmark\nto evaluate NTL performance and robustness within a unified framework.\nSpecifically, we first introduce the task settings, general framework, and\ncriteria of NTL, followed by a summary of NTL approaches. Furthermore, we\nemphasize the often-overlooked issue of robustness against various attacks that\ncan destroy the non-transferable mechanism established by NTL. Experiments\nconducted via NTLBench verify the limitations of existing NTL methods in\nrobustness. Finally, we discuss the practical applications of NTL, along with\nits future directions and associated challenges.\n","authors":["Ziming Hong","Yongli Xiang","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13593v2.pdf","comment":"Code is available at https://github.com/tmllab/NTLBench"},{"id":"http://arxiv.org/abs/2503.05419v1","updated":"2025-03-07T13:45:06Z","published":"2025-03-07T13:45:06Z","title":"Physics-based machine learning for fatigue lifetime prediction under\n  non-uniform loading scenarios","summary":"  Accurate lifetime prediction of structures subjected to cyclic loading is\nvital, especially in scenarios involving non-uniform loading histories where\nload sequencing critically influences structural durability. Addressing this\ncomplexity requires advanced modeling approaches capable of capturing the\nintricate relationship between loading sequences and fatigue lifetime.\nTraditional fatigue simulations are computationally prohibitive, necessitating\nmore efficient methods. This study highlights the potential of physics-based\nmachine learning ($\\phi$ML) to predict the fatigue lifetime of materials.\nSpecifically, a FFNN is designed to embed physical constraints from\nexperimental evidence directly into its architecture to enhance prediction\naccuracy. It is trained using numerical simulations generated by a physically\nbased anisotropic continuum damage fatigue model. The model is calibrated and\nvalidated against experimental fatigue data of concrete cylinder specimens\ntested in uniaxial compression. The proposed approach demonstrates superior\naccuracy compared to purely data-driven neural networks, particularly in\nsituations with limited training data, achieving realistic predictions of\ndamage accumulation. Thus, a general algorithm is developed and successfully\napplied to predict fatigue lifetimes under complex loading scenarios with\nmultiple loading ranges. Hereby, the $\\phi$ML model serves as a surrogate to\ncapture damage evolution across load transitions. The $\\phi$ML based algorithm\nis subsequently employed to investigate the influence of multiple loading\ntransitions on accumulated fatigue life, and its predictions align with trends\nobserved in recent experimental studies. This work demonstrates $\\phi$ML as a\npromising technique for efficient and reliable fatigue life prediction in\nengineering structures, with possible integration into digital twin models for\nreal-time assessment.\n","authors":["Abedulgader Baktheer","Fadi Aldakheel"],"pdf_url":"https://arxiv.org/pdf/2503.05419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03467v2","updated":"2025-03-07T13:43:19Z","published":"2024-02-02T14:29:38Z","title":"Stochastic Modified Flows for Riemannian Stochastic Gradient Descent","summary":"  We give quantitative estimates for the rate of convergence of Riemannian\nstochastic gradient descent (RSGD) to Riemannian gradient flow and to a\ndiffusion process, the so-called Riemannian stochastic modified flow (RSMF).\nUsing tools from stochastic differential geometry we show that, in the small\nlearning rate regime, RSGD can be approximated by the solution to the RSMF\ndriven by an infinite-dimensional Wiener process. The RSMF accounts for the\nrandom fluctuations of RSGD and, thereby, increases the order of approximation\ncompared to the deterministic Riemannian gradient flow. The RSGD is build using\nthe concept of a retraction map, that is, a cost efficient approximation of the\nexponential map, and we prove quantitative bounds for the weak error of the\ndiffusion approximation under assumptions on the retraction map, the geometry\nof the manifold, and the random estimators of the gradient.\n","authors":["Benjamin Gess","Sebastian Kassing","Nimit Rana"],"pdf_url":"https://arxiv.org/pdf/2402.03467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09787v2","updated":"2025-03-07T13:25:18Z","published":"2024-05-16T03:23:57Z","title":"Analysis of the BraTS 2023 Intracranial Meningioma Segmentation\n  Challenge","summary":"  We describe the design and results from the BraTS 2023 Intracranial\nMeningioma Segmentation Challenge. The BraTS Meningioma Challenge differed from\nprior BraTS Glioma challenges in that it focused on meningiomas, which are\ntypically benign extra-axial tumors with diverse radiologic and anatomical\npresentation and a propensity for multiplicity. Nine participating teams each\ndeveloped deep-learning automated segmentation models using image data from the\nlargest multi-institutional systematically expert annotated multilabel\nmulti-sequence meningioma MRI dataset to date, which included 1000 training set\ncases, 141 validation set cases, and 283 hidden test set cases. Each case\nincluded T2, FLAIR, T1, and T1Gd brain MRI sequences with associated tumor\ncompartment labels delineating enhancing tumor, non-enhancing tumor, and\nsurrounding non-enhancing FLAIR hyperintensity. Participant automated\nsegmentation models were evaluated and ranked based on a scoring system\nevaluating lesion-wise metrics including dice similarity coefficient (DSC) and\n95% Hausdorff Distance. The top ranked team had a lesion-wise median dice\nsimilarity coefficient (DSC) of 0.976, 0.976, and 0.964 for enhancing tumor,\ntumor core, and whole tumor, respectively and a corresponding average DSC of\n0.899, 0.904, and 0.871, respectively. These results serve as state-of-the-art\nbenchmarks for future pre-operative meningioma automated segmentation\nalgorithms. Additionally, we found that 1286 of 1424 cases (90.3%) had at least\n1 compartment voxel abutting the edge of the skull-stripped image edge, which\nrequires further investigation into optimal pre-processing face anonymization\nsteps.\n","authors":["Dominic LaBella","Ujjwal Baid","Omaditya Khanna","Shan McBurney-Lin","Ryan McLean","Pierre Nedelec","Arif Rashid","Nourel Hoda Tahon","Talissa Altes","Radhika Bhalerao","Yaseen Dhemesh","Devon Godfrey","Fathi Hilal","Scott Floyd","Anastasia Janas","Anahita Fathi Kazerooni","John Kirkpatrick","Collin Kent","Florian Kofler","Kevin Leu","Nazanin Maleki","Bjoern Menze","Maxence Pajot","Zachary J. Reitman","Jeffrey D. Rudie","Rachit Saluja","Yury Velichko","Chunhao Wang","Pranav Warman","Maruf Adewole","Jake Albrecht","Udunna Anazodo","Syed Muhammad Anwar","Timothy Bergquist","Sully Francis Chen","Verena Chung","Rong Chai","Gian-Marco Conte","Farouk Dako","James Eddy","Ivan Ezhov","Nastaran Khalili","Juan Eugenio Iglesias","Zhifan Jiang","Elaine Johanson","Koen Van Leemput","Hongwei Bran Li","Marius George Linguraru","Xinyang Liu","Aria Mahtabfar","Zeke Meier","Ahmed W. Moawad","John Mongan","Marie Piraud","Russell Takeshi Shinohara","Walter F. Wiggins","Aly H. Abayazeed","Rachel Akinola","András Jakab","Michel Bilello","Maria Correia de Verdier","Priscila Crivellaro","Christos Davatzikos","Keyvan Farahani","John Freymann","Christopher Hess","Raymond Huang","Philipp Lohmann","Mana Moassefi","Matthew W. Pease","Phillipp Vollmuth","Nico Sollmann","David Diffley","Khanak K. Nandolia","Daniel I. Warren","Ali Hussain","Pascal Fehringer","Yulia Bronstein","Lisa Deptula","Evan G. Stein","Mahsa Taherzadeh","Eduardo Portela de Oliveira","Aoife Haughey","Marinos Kontzialis","Luca Saba","Benjamin Turner","Melanie M. T. Brüßeler","Shehbaz Ansari","Athanasios Gkampenis","David Maximilian Weiss","Aya Mansour","Islam H. Shawali","Nikolay Yordanov","Joel M. Stein","Roula Hourani","Mohammed Yahya Moshebah","Ahmed Magdy Abouelatta","Tanvir Rizvi","Klara Willms","Dann C. Martin","Abdullah Okar","Gennaro D'Anna","Ahmed Taha","Yasaman Sharifi","Shahriar Faghani","Dominic Kite","Marco Pinho","Muhammad Ammar Haider","Alejandro Aristizabal","Alexandros Karargyris","Hasan Kassem","Sarthak Pati","Micah Sheller","Michelle Alonso-Basanta","Javier Villanueva-Meyer","Andreas M. Rauschecker","Ayman Nada","Mariam Aboian","Adam E. Flanders","Benedikt Wiestler","Spyridon Bakas","Evan Calabrese"],"pdf_url":"https://arxiv.org/pdf/2405.09787v2.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2025:003 22 pages, 6\n  tables, 12 figures, MICCAI, MELBA"},{"id":"http://arxiv.org/abs/2503.05379v1","updated":"2025-03-07T12:46:42Z","published":"2025-03-07T12:46:42Z","title":"R1-Omni: Explainable Omni-Multimodal Emotion Recognition with\n  Reinforcing Learning","summary":"  In this work, we present the first application of Reinforcement Learning with\nVerifiable Reward (RLVR) to an Omni-multimodal large language model in the\ncontext of emotion recognition, a task where both visual and audio modalities\nplay crucial roles. We leverage RLVR to optimize the Omni model, significantly\nenhancing its performance in three key aspects: reasoning capability, emotion\nrecognition accuracy, and generalization ability. The introduction of RLVR not\nonly improves the model's overall performance on in-distribution data but also\ndemonstrates superior robustness when evaluated on out-of-distribution\ndatasets. More importantly, the improved reasoning capability enables clear\nanalysis of the contributions of different modalities, particularly visual and\naudio information, in the emotion recognition process. This provides valuable\ninsights into the optimization of multimodal large language models.\n","authors":["Jiaxing Zhao","Xihan Wei","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2503.05379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05053v2","updated":"2025-03-07T12:46:14Z","published":"2024-06-07T16:22:51Z","title":"Hints-In-Browser: Benchmarking Language Models for Programming Feedback\n  Generation","summary":"  Generative AI and large language models hold great promise in enhancing\nprogramming education by generating individualized feedback and hints for\nlearners. Recent works have primarily focused on improving the quality of\ngenerated feedback to achieve human tutors' quality. While quality is an\nimportant performance criterion, it is not the only criterion to optimize for\nreal-world educational deployments. In this paper, we benchmark language models\nfor programming feedback generation across several performance criteria,\nincluding quality, cost, time, and data privacy. The key idea is to leverage\nrecent advances in the new paradigm of in-browser inference that allow running\nthese models directly in the browser, thereby providing direct benefits across\ncost and data privacy. To boost the feedback quality of small models compatible\nwith in-browser inference engines, we develop a fine-tuning pipeline based on\nGPT-4 generated synthetic data. We showcase the efficacy of fine-tuned\nLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser\ninference engine on three different Python programming datasets. We will\nrelease the full implementation along with a web app and datasets to facilitate\nfurther research on in-browser language models.\n","authors":["Nachiket Kotalwar","Alkis Gotovos","Adish Singla"],"pdf_url":"https://arxiv.org/pdf/2406.05053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.01196v3","updated":"2025-03-07T12:31:27Z","published":"2023-07-27T22:57:55Z","title":"Sustainable transparency in Recommender Systems: Bayesian Ranking of\n  Images for Explainability","summary":"  Recommender Systems have become crucial in the modern world, commonly guiding\nusers towards relevant content or products, and having a large influence over\nthe decisions of users and citizens. However, ensuring transparency and user\ntrust in these systems remains a challenge; personalized explanations have\nemerged as a solution, offering justifications for recommendations. Among the\nexisting approaches for generating personalized explanations, using existing\nvisual content created by users is a promising option to maximize transparency\nand user trust. State-of-the-art models that follow this approach, despite\nleveraging highly optimized architectures, employ surrogate learning tasks that\ndo not efficiently model the objective of ranking images as explanations for a\ngiven recommendation; this leads to a suboptimal training process with high\ncomputational costs that may not be reduced without affecting model\nperformance. This work presents BRIE, a novel model where we leverage Bayesian\nPairwise Ranking to enhance the training process, allowing us to consistently\noutperform state-of-the-art models in six real-world datasets while reducing\nits model size by up to 64 times and its CO2 emissions by up to 75% in training\nand inference.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Berta Guijarro-Berdiñas","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2308.01196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01614v2","updated":"2025-03-07T12:31:27Z","published":"2024-05-02T16:17:29Z","title":"RULSurv: A probabilistic survival-based method for early censoring-aware\n  prediction of remaining useful life in ball bearings","summary":"  Censored data refers to situations where the full information about a\nparticular event or process is only partially known. In survival analysis,\ncensoring plays an important role, as ignoring such observations can bias the\nmodel parameters and overestimate the probability of when the event is likely\nto occur. There has been a renewed interest in using data-driven methods to\npredict the remaining useful life (RUL) of ball bearings for predictive\nmaintenance. However, few studies have explicitly addressed the challenge of\nhandling censored data. To address this issue, we introduce a novel and\nflexible method for early fault detection using Kullback-Leibler (KL)\ndivergence and RUL estimation using survival analysis that naturally supports\ncensored data. We demonstrate our approach in the XJTU-SY dataset using a\n5-fold cross-validation across three different operating conditions. When\npredicting the time to failure for bearings under the highest load (C1, 12.0 kN\nand 2100 RPM) with 25\\% random censoring, our approach achieves a mean absolute\nerror (MAE) of 14.7 minutes (95\\% CI 13.6-15.8) using a linear CoxPH model, and\nan MAE of 12.6 minutes (95\\% CI 11.8-13.4) using a nonlinear Random Survival\nForests model, compared to an MAE of 18.5 minutes (95\\% 17.4-19.6) using a\nlinear LASSO model that does not support censoring. Moreover, our approach\nachieves a mean cumulative relative accuracy (CRA) of 0.7586 over 5 bearings\nunder the highest load, which improves over several state-of-the-art baselines.\nOur work highlights the importance of considering censored observations as part\nof the model design when building predictive models for early fault detection\nand RUL estimation.\n","authors":["Christian Marius Lillelund","Fernando Pannullo","Morten Opprud Jakobsen","Manuel Morante","Christian Fischer Pedersen"],"pdf_url":"https://arxiv.org/pdf/2405.01614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05371v1","updated":"2025-03-07T12:25:29Z","published":"2025-03-07T12:25:29Z","title":"Shifting Perspectives: Steering Vector Ensembles for Robust Bias\n  Mitigation in LLMs","summary":"  We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.\n","authors":["Zara Siddique","Irtaza Khalid","Liam D. Turner","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.05371v1.pdf","comment":"Submitted to ACL 2025"},{"id":"http://arxiv.org/abs/2406.09898v2","updated":"2025-03-07T12:25:03Z","published":"2024-06-14T10:14:01Z","title":"Positive-Unlabelled Learning for identifying new candidate Dietary\n  Restriction-related genes among Ageing-related genes","summary":"  Dietary Restriction (DR) is one of the most popular anti-ageing\ninterventions; recently, Machine Learning (ML) has been explored to identify\npotential DR-related genes among ageing-related genes, aiming to minimize\ncostly wet lab experiments needed to expand our knowledge on DR. However, to\ntrain a model from positive (DR-related) and negative (non-DR-related)\nexamples, the existing ML approach naively labels genes without known DR\nrelation as negative examples, assuming that lack of DR-related annotation for\na gene represents evidence of absence of DR-relatedness, rather than absence of\nevidence. This hinders the reliability of the negative examples (non-DR-related\ngenes) and the method's ability to identify novel DR-related genes. This work\nintroduces a novel gene prioritisation method based on the two-step\nPositive-Unlabelled (PU) Learning paradigm: using a similarity-based,\nKNN-inspired approach, our method first selects reliable negative examples\namong the genes without known DR associations. Then, these reliable negatives\nand all known positives are used to train a classifier that effectively\ndifferentiates DR-related and non-DR-related genes, which is finally employed\nto generate a more reliable ranking of promising genes for novel\nDR-relatedness. Our method significantly outperforms (p<0.05) the existing\nstate-of-the-art approach in three predictive accuracy metrics with up to 40%\nlower computational cost in the best case, and we identify 4 new promising\nDR-related genes (PRKAB1, PRKAB2, IRS2, PRKAG1), all with evidence from the\nexisting literature supporting their potential DR-related role.\n","authors":["Jorge Paz-Ruza","Alex A. Freitas","Amparo Alonso-Betanzos","Bertha Guijarro-Berdiñas"],"pdf_url":"https://arxiv.org/pdf/2406.09898v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05367v1","updated":"2025-03-07T12:21:09Z","published":"2025-03-07T12:21:09Z","title":"Semi-Supervised Learning for Dose Prediction in Targeted Radionuclide: A\n  Synthetic Data Study","summary":"  Targeted Radionuclide Therapy (TRT) is a modern strategy in radiation\noncology that aims to administer a potent radiation dose specifically to cancer\ncells using cancer-targeting radiopharmaceuticals. Accurate radiation dose\nestimation tailored to individual patients is crucial. Deep learning,\nparticularly with pre-therapy imaging, holds promise for personalizing TRT\ndoses. However, current methods require large time series of SPECT imaging,\nwhich is hardly achievable in routine clinical practice, and thus raises issues\nof data availability. Our objective is to develop a semi-supervised learning\n(SSL) solution to personalize dosimetry using pre-therapy images. The aim is to\ndevelop an approach that achieves accurate results when PET/CT images are\navailable, but are associated with only a few post-therapy dosimetry data\nprovided by SPECT images. In this work, we introduce an SSL method using a\npseudo-label generation approach for regression tasks inspired by the FixMatch\nframework. The feasibility of the proposed solution was preliminarily evaluated\nthrough an in-silico study using synthetic data and Monte Carlo simulation.\nExperimental results for organ dose prediction yielded promising outcomes,\nshowing that the use of pseudo-labeled data provides better accuracy compared\nto using only labeled data.\n","authors":["Jing Zhang","Alexandre Bousse","Laetitia Imbert","Song Xue","Kuangyu Shi","Julien Bert"],"pdf_url":"https://arxiv.org/pdf/2503.05367v1.pdf","comment":"12 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.04263v2","updated":"2025-03-07T12:18:32Z","published":"2024-10-05T18:52:54Z","title":"DeFoG: Discrete Flow Matching for Graph Generation","summary":"  Graph generative models are essential across diverse scientific domains by\ncapturing complex distributions over relational data. Among them, graph\ndiffusion models achieve superior performance but face inefficient sampling and\nlimited flexibility due to the tight coupling between training and sampling\nstages. We introduce DeFoG, a novel graph generative framework that\ndisentangles sampling from training, enabling a broader design space for more\neffective and efficient model optimization. DeFoG employs a discrete\nflow-matching formulation that respects the inherent symmetries of graphs. We\ntheoretically ground this disentangled formulation by explicitly relating the\ntraining loss to the sampling algorithm and showing that DeFoG faithfully\nreplicates the ground truth graph distribution. Building on these foundations,\nwe thoroughly investigate DeFoG's design space and propose novel sampling\nmethods that significantly enhance performance and reduce the required number\nof refinement steps. Extensive experiments demonstrate state-of-the-art\nperformance across synthetic, molecular, and digital pathology datasets,\ncovering both unconditional and conditional generation settings. It also\noutperforms most diffusion-based models with just 5-10% of their sampling\nsteps.\n","authors":["Yiming Qin","Manuel Madeira","Dorina Thanou","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.04263v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05357v1","updated":"2025-03-07T12:01:02Z","published":"2025-03-07T12:01:02Z","title":"Improving Hate Speech Classification with Cross-Taxonomy Dataset\n  Integration","summary":"  Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.\n","authors":["Jan Fillies","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2503.05357v1.pdf","comment":"Accepted for publication at LaTeCH-CLfL 2025. The 9th Joint ACL\n  Special Interest Group on Language Technologies for the Socio-Economic\n  Sciences and Humanities (SIGHUM) Workshop on Computational Linguistics for\n  Cultural Heritage, Social Sciences, Humanities and Literature"},{"id":"http://arxiv.org/abs/2310.17332v2","updated":"2025-03-07T11:58:06Z","published":"2023-10-26T11:55:30Z","title":"On Forecast Stability","summary":"  Forecasts are typically not produced in a vacuum but in a business context,\nwhere forecasts are generated on a regular basis and interact with each other.\nFor decisions, it may be important that forecasts do not change arbitrarily,\nand are stable in some sense. However, this area has received only limited\nattention in the forecasting literature. In this paper, we explore two types of\nforecast stability that we call vertical stability and horizontal stability.\nThe existing works in the literature are only applicable to certain base models\nand extending these frameworks to be compatible with any base model is not\nstraightforward. Furthermore, these frameworks can only stabilise the forecasts\nvertically. To fill this gap, we propose a simple linear-interpolation-based\napproach that is applicable to stabilise the forecasts provided by any base\nmodel vertically and horizontally. The approach can produce both accurate and\nstable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base\nmodels, in our evaluation on four publicly available datasets, the proposed\nframework is able to achieve significantly higher stability and/or accuracy\ncompared to a set of benchmarks including a state-of-the-art forecast\nstabilisation method across three error metrics and six stability metrics.\n","authors":["Rakshitha Godahewa","Christoph Bergmeir","Zeynep Erkin Baz","Chengjun Zhu","Zhangdi Song","Salvador García","Dario Benavides"],"pdf_url":"https://arxiv.org/pdf/2310.17332v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05349v1","updated":"2025-03-07T11:44:49Z","published":"2025-03-07T11:44:49Z","title":"Spatial Distillation based Distribution Alignment (SDDA) for\n  Cross-Headset EEG Classification","summary":"  A non-invasive brain-computer interface (BCI) enables direct interaction\nbetween the user and external devices, typically via electroencephalogram (EEG)\nsignals. However, decoding EEG signals across different headsets remains a\nsignificant challenge due to differences in the number and locations of the\nelectrodes. To address this challenge, we propose a spatial distillation based\ndistribution alignment (SDDA) approach for heterogeneous cross-headset transfer\nin non-invasive BCIs. SDDA uses first spatial distillation to make use of the\nfull set of electrodes, and then input/feature/output space distribution\nalignments to cope with the significant differences between the source and\ntarget domains. To our knowledge, this is the first work to use knowledge\ndistillation in cross-headset transfers. Extensive experiments on six EEG\ndatasets from two BCI paradigms demonstrated that SDDA achieved superior\nperformance in both offline unsupervised domain adaptation and online\nsupervised domain adaptation scenarios, consistently outperforming 10 classical\nand state-of-the-art transfer learning algorithms.\n","authors":["Dingkun Liu","Siyang Li","Ziwei Wang","Wei Li","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05349v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.04398v2","updated":"2025-03-07T11:41:53Z","published":"2025-03-06T12:52:22Z","title":"Speculative MoE: Communication Efficient Parallel MoE Inference with\n  Speculative Token and Expert Pre-scheduling","summary":"  MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.\n","authors":["Yan Li","Pengfei Zheng","Shuang Chen","Zewei Xu","Yuanhao Lai","Yunfei Du","Zhengang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05336v1","updated":"2025-03-07T11:23:48Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Deb Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Sayash Kapoor","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2310.08944v3","updated":"2025-03-07T11:23:19Z","published":"2023-10-13T08:19:31Z","title":"A Confidence-based Acquisition Model for Self-supervised Active Learning\n  and Label Correction","summary":"  Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present CAMEL (Confidence-based Acquisition Model for Efficient\nself-supervised active Learning), a pool-based active learning framework\ntailored to sequential multi-output problems. CAMEL possesses two core\nfeatures: (1) it requires expert annotators to label only a fraction of a\nchosen sequence, and (2) it facilitates self-supervision for the remainder of\nthe sequence. By deploying a label correction mechanism, CAMEL can also be\nutilised for data cleaning. We evaluate CAMEL on two sequential tasks, with a\nspecial emphasis on dialogue belief tracking, a task plagued by the constraints\nof limited and noisy datasets. Our experiments demonstrate that CAMEL\nsignificantly outperforms the baselines in terms of efficiency. Furthermore,\nthe data corrections suggested by our method contribute to an overall\nimprovement in the quality of the resulting datasets.\n","authors":["Carel van Niekerk","Christian Geishauser","Michael Heck","Shutong Feng","Hsien-chin Lin","Nurul Lubis","Benjamin Ruppik","Renato Vukovic","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2310.08944v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15429v3","updated":"2025-03-07T11:20:12Z","published":"2024-12-19T22:29:03Z","title":"Offline Safe Reinforcement Learning Using Trajectory Classification","summary":"  Offline safe reinforcement learning (RL) has emerged as a promising approach\nfor learning safe behaviors without engaging in risky online interactions with\nthe environment. Most existing methods in offline safe RL rely on cost\nconstraints at each time step (derived from global cost constraints) and this\ncan result in either overly conservative policies or violation of safety\nconstraints. In this paper, we propose to learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories. To be specific, we\nfirst partition the pre-collected dataset of state-action trajectories into\ndesirable and undesirable subsets. Intuitively, the desirable set contains high\nreward and safe trajectories, and undesirable set contains unsafe trajectories\nand low-reward safe trajectories. Second, we learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories, where\n(un)desirability scores are provided by a classifier learnt from the dataset of\ndesirable and undesirable trajectories. This approach bypasses the\ncomputational complexity and stability issues of a min-max objective that is\nemployed in existing methods. Theoretically, we also show our approach's strong\nconnections to existing learning paradigms involving human feedback. Finally,\nwe extensively evaluate our method using the DSRL benchmark for offline safe\nRL. Empirically, our method outperforms competitive baselines, achieving higher\nrewards and better constraint satisfaction across a wide variety of benchmark\ntasks.\n","authors":["Ze Gong","Akshat Kumar","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2412.15429v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2308.14352v2","updated":"2025-03-07T11:16:40Z","published":"2023-08-28T06:56:08Z","title":"EdgeMoE: Empowering Sparse Large Language Models on Mobile Devices","summary":"  Large language models (LLMs) such as GPTs and Mixtral-8x7B have\nrevolutionized machine intelligence due to their exceptional abilities in\ngeneric ML tasks. Transiting LLMs from datacenters to edge devices brings\nbenefits like better privacy and availability, but is challenged by their\nmassive parameter size and thus unbearable runtime costs. To this end, we\npresent EdgeMoE, an on-device inference engine for mixture-of-expert (MoE) LLMs\n-- a popular form of sparse LLM that scales its parameter size with almost\nconstant computing complexity. EdgeMoE achieves both memory- and\ncompute-efficiency by partitioning the model into the storage hierarchy:\nnon-expert weights are held in device memory; while expert weights are held on\nexternal storage and fetched to memory only when activated. This design is\nmotivated by a key observation that expert weights are bulky but infrequently\nused due to sparse activation. To further reduce the expert I/O swapping\noverhead, EdgeMoE incorporates two novel techniques: (1) expert-wise bitwidth\nadaptation that reduces the expert sizes with tolerable accuracy loss; (2)\nexpert preloading that predicts the activated experts ahead of time and\npreloads it with the compute-I/O pipeline. On popular MoE LLMs and edge\ndevices, EdgeMoE showcase significant memory savings and speedup over\ncompetitive baselines. The code is available at\nhttps://github.com/UbiquitousLearning/mllm.\n","authors":["Rongjie Yi","Liwei Guo","Shiyun Wei","Ao Zhou","Shangguang Wang","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2308.14352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v2","updated":"2025-03-07T11:12:17Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2408.02361v2.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05324v1","updated":"2025-03-07T11:02:17Z","published":"2025-03-07T11:02:17Z","title":"Routing for Large ML Models","summary":"  Training large language models (LLMs), and other large machine learning\nmodels, involves repeated communication of large volumes of data across a data\ncenter network. The communication patterns induced by these training process\nexhibit high regularity and persistence, giving rise to significant\nopportunities for optimizing the manner in which flows are routed across the\nnetwork. We present an algorithmic framework for \\textit{quantifying}\nnetwork-wide efficiency in the context of training LLMs (and other large-scale\nML models), and for periodically \\textit{optimizing} routing with respect to\nthis global metric.\n","authors":["Ofir Cohen","Jose Yallouz Michael Schapira","Shahar Belkar","Tal Mizrahi"],"pdf_url":"https://arxiv.org/pdf/2503.05324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05323v1","updated":"2025-03-07T11:01:35Z","published":"2025-03-07T11:01:35Z","title":"Graph Alignment via Birkhoff Relaxation","summary":"  We consider the graph alignment problem, wherein the objective is to find a\nvertex correspondence between two graphs that maximizes the edge overlap. The\ngraph alignment problem is an instance of the quadratic assignment problem\n(QAP), known to be NP-hard in the worst case even to approximately solve. In\nthis paper, we analyze Birkhoff relaxation, a tight convex relaxation of QAP,\nand present theoretical guarantees on its performance when the inputs follow\nthe Gaussian Wigner Model. More specifically, the weighted adjacency matrices\nare correlated Gaussian Orthogonal Ensemble with correlation\n$1/\\sqrt{1+\\sigma^2}$. Denote the optimal solutions of the QAP and Birkhoff\nrelaxation by $\\Pi^\\star$ and $X^\\star$ respectively. We show that\n$\\|X^\\star-\\Pi^\\star\\|_F^2 = o(n)$ when $\\sigma = o(n^{-1.25})$ and\n$\\|X^\\star-\\Pi^\\star\\|_F^2 = \\Omega(n)$ when $\\sigma = \\Omega(n^{-0.5})$. Thus,\nthe optimal solution $X^\\star$ transitions from a small perturbation of\n$\\Pi^\\star$ for small $\\sigma$ to being well separated from $\\Pi^\\star$ as\n$\\sigma$ becomes larger than $n^{-0.5}$. This result allows us to guarantee\nthat simple rounding procedures on $X^\\star$ align $1-o(1)$ fraction of\nvertices correctly whenever $\\sigma = o(n^{-1.25})$. This condition on $\\sigma$\nto ensure the success of the Birkhoff relaxation is state-of-the-art.\n","authors":["Sushil Mahavir Varma","Irène Waldspurger","Laurent Massoulié"],"pdf_url":"https://arxiv.org/pdf/2503.05323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05321v1","updated":"2025-03-07T11:00:29Z","published":"2025-03-07T11:00:29Z","title":"Riemannian Metric Learning: Closer to You than You Imagine","summary":"  Riemannian metric learning is an emerging field in machine learning,\nunlocking new ways to encode complex data structures beyond traditional\ndistance metric learning. While classical approaches rely on global distances\nin Euclidean space, they often fall short in capturing intrinsic data geometry.\nEnter Riemannian metric learning: a powerful generalization that leverages\ndifferential geometry to model the data according to their underlying\nRiemannian manifold. This approach has demonstrated remarkable success across\ndiverse domains, from causal inference and optimal transport to generative\nmodeling and representation learning. In this review, we bridge the gap between\nclassical metric learning and Riemannian geometry, providing a structured and\naccessible overview of key methods, applications, and recent advances. We argue\nthat Riemannian metric learning is not merely a technical refinement but a\nfundamental shift in how we think about data representations. Thus, this review\nshould serve as a valuable resource for researchers and practitioners\ninterested in exploring Riemannian metric learning and convince them that it is\ncloser to them than they might imagine-both in theory and in practice.\n","authors":["Samuel Gruffaz","Josua Sassen"],"pdf_url":"https://arxiv.org/pdf/2503.05321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05320v1","updated":"2025-03-07T11:00:24Z","published":"2025-03-07T11:00:24Z","title":"Disentangling Task Interference within Neurons: Model Merging in\n  Alignment with Neuronal Mechanisms","summary":"  Fine-tuning pre-trained models on targeted datasets enhances task-specific\nperformance but often comes at the expense of generalization. Model merging\ntechniques, which integrate multiple fine-tuned models into a single multi-task\nmodel through task arithmetic at various levels: model, layer, or parameter,\noffer a promising solution. However, task interference remains a fundamental\nchallenge, leading to performance degradation and suboptimal merged models.\nExisting approaches largely overlook the fundamental role of individual neurons\nand their connectivity, resulting in a lack of interpretability in both the\nmerging process and the merged models. In this work, we present the first study\non the impact of neuronal alignment in model merging. We decompose\ntask-specific representations into two complementary neuronal subspaces that\nregulate neuron sensitivity and input adaptability. Leveraging this\ndecomposition, we introduce NeuroMerging, a novel merging framework developed\nto mitigate task interference within neuronal subspaces, enabling training-free\nmodel fusion across diverse tasks. Through extensive experiments, we\ndemonstrate that NeuroMerging achieves superior performance compared to\nexisting methods on multi-task benchmarks across both vision and natural\nlanguage domains. Our findings highlight the importance of aligning neuronal\nmechanisms in model merging, offering new insights into mitigating task\ninterference and improving knowledge fusion.\n","authors":["Zitao Fang","Guodong DU","Shuyang Yu","Yifei Guo","Yiwei Zhang","Jing Li","Ho-Kin Tang","Sim Kuan Goh"],"pdf_url":"https://arxiv.org/pdf/2503.05320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05657v2","updated":"2025-03-07T10:55:23Z","published":"2024-12-07T14:02:57Z","title":"Long-Term Auto-Regressive Prediction using Lightweight AI Models:\n  Adams-Bashforth Time Integration with Adaptive Multi-Step Rollout","summary":"  This study addresses the critical challenge of error accumulation in\nspatio-temporal auto-regressive predictions within scientific machine learning\nmodels by introducing innovative temporal integration schemes and adaptive\nmulti-step rollout strategies. We present a comprehensive analysis of time\nintegration methods, highlighting the adaptation of the two-step\nAdams-Bashforth scheme to enhance long-term prediction robustness in\nauto-regressive models. Additionally, we improve temporal prediction accuracy\nthrough a multi-step rollout strategy that incorporates multiple future time\nsteps during training, supported by three newly proposed approaches that\ndynamically adjust the importance of each future step. Despite using an\nextremely lightweight graph neural network with just 1,177 trainable parameters\nand training on only 50 snapshots, our framework accurately predicts 350 future\ntime steps (a 7:1 prediction-to-training ratio) achieving an error of only 1.6%\ncompared to the vanilla auto-regressive approach. Moreover, our framework\ndemonstrates an 83% improvement in rollout performance over the standard noise\ninjection method, a standard technique for enhancing long-term rollout\nperformance. Its effectiveness is further validated in more challenging\nscenarios with truncated meshes, showcasing its adaptability and robustness in\npractical applications. This work introduces a versatile framework for robust\nlong-term spatio-temporal auto-regressive predictions that shows potential for\nmitigating error accumulation across various model types and engineering\ndisciplines.\n","authors":["Sunwoong Yang","Ricardo Vinuesa","Namwoo Kang"],"pdf_url":"https://arxiv.org/pdf/2412.05657v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05318v1","updated":"2025-03-07T10:55:12Z","published":"2025-03-07T10:55:12Z","title":"Uncertainty-Aware Decoding with Minimum Bayes Risk","summary":"  Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.\n","authors":["Nico Daheim","Clara Meister","Thomas Möllenhoff","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.05318v1.pdf","comment":"ICLR 2025 (Poster)"},{"id":"http://arxiv.org/abs/2410.04166v3","updated":"2025-03-07T10:51:04Z","published":"2024-10-05T14:04:03Z","title":"Learning from negative feedback, or positive feedback or both","summary":"  Existing preference optimization methods often assume scenarios where paired\npreference feedback (preferred/positive vs. dis-preferred/negative examples) is\navailable. This requirement limits their applicability in scenarios where only\nunpaired feedback--for example, either positive or negative--is available. To\naddress this, we introduce a novel approach that decouples learning from\npositive and negative feedback. This decoupling enables control over the\ninfluence of each feedback type and, importantly, allows learning even when\nonly one feedback type is present. A key contribution is demonstrating stable\nlearning from negative feedback alone, a capability not well-addressed by\ncurrent methods. Our approach builds upon the probabilistic framework\nintroduced in (Dayan and Hinton, 1997), which uses expectation-maximization\n(EM) to directly optimize the probability of positive outcomes (as opposed to\nclassic expected reward maximization). We address a key limitation in current\nEM-based methods: they solely maximize the likelihood of positive examples,\nwhile neglecting negative ones. We show how to extend EM algorithms to\nexplicitly incorporate negative examples, leading to a theoretically grounded\nalgorithm that offers an intuitive and versatile way to learn from both\npositive and negative feedback. We evaluate our approach for training language\nmodels based on human feedback as well as training policies for sequential\ndecision-making problems, where learned value functions are available.\n","authors":["Abbas Abdolmaleki","Bilal Piot","Bobak Shahriari","Jost Tobias Springenberg","Tim Hertweck","Rishabh Joshi","Junhyuk Oh","Michael Bloesch","Thomas Lampe","Nicolas Heess","Jonas Buchli","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2410.04166v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05316v1","updated":"2025-03-07T10:50:58Z","published":"2025-03-07T10:50:58Z","title":"CoinRobot: Generalized End-to-end Robotic Learning for Physical\n  Intelligence","summary":"  Physical intelligence holds immense promise for advancing embodied\nintelligence, enabling robots to acquire complex behaviors from demonstrations.\nHowever, achieving generalization and transfer across diverse robotic platforms\nand environments requires careful design of model architectures, training\nstrategies, and data diversity. Meanwhile existing systems often struggle with\nscalability, adaptability to heterogeneous hardware, and objective evaluation\nin real-world settings. We present a generalized end-to-end robotic learning\nframework designed to bridge this gap. Our framework introduces a unified\narchitecture that supports cross-platform adaptability, enabling seamless\ndeployment across industrial-grade robots, collaborative arms, and novel\nembodiments without task-specific modifications. By integrating multi-task\nlearning with streamlined network designs, it achieves more robust performance\nthan conventional approaches, while maintaining compatibility with varying\nsensor configurations and action spaces. We validate our framework through\nextensive experiments on seven manipulation tasks. Notably, Diffusion-based\nmodels trained in our framework demonstrated superior performance and\ngeneralizability compared to the LeRobot framework, achieving performance\nimprovements across diverse robotic platforms and environmental conditions.\n","authors":["Yu Zhao","Huxian Liu","Xiang Chen","Jiankai Sun","Jiahuan Yan","Luhui Hu"],"pdf_url":"https://arxiv.org/pdf/2503.05316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05315v1","updated":"2025-03-07T10:50:45Z","published":"2025-03-07T10:50:45Z","title":"LoRACode: LoRA Adapters for Code Embeddings","summary":"  Code embeddings are essential for semantic code search; however, current\napproaches often struggle to capture the precise syntactic and contextual\nnuances inherent in code. Open-source models such as CodeBERT and UniXcoder\nexhibit limitations in scalability and efficiency, while high-performing\nproprietary systems impose substantial computational costs. We introduce a\nparameter-efficient fine-tuning method based on Low-Rank Adaptation (LoRA) to\nconstruct task-specific adapters for code retrieval. Our approach reduces the\nnumber of trainable parameters to less than two percent of the base model,\nenabling rapid fine-tuning on extensive code corpora (2 million samples in 25\nminutes on two H100 GPUs). Experiments demonstrate an increase of up to 9.1% in\nMean Reciprocal Rank (MRR) for Code2Code search, and up to 86.69% for Text2Code\nsearch tasks across multiple programming languages. Distinction in task-wise\nand language-wise adaptation helps explore the sensitivity of code retrieval\nfor syntactical and linguistic variations.\n","authors":["Saumya Chaturvedi","Aman Chadha","Laurent Bindschaedler"],"pdf_url":"https://arxiv.org/pdf/2503.05315v1.pdf","comment":"Accepted at the Deep Learning for Code (DL4C) Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.03983v2","updated":"2025-03-07T10:39:01Z","published":"2024-12-05T08:58:41Z","title":"Safe and Efficient Online Convex Optimization with Linear Budget\n  Constraints and Partial Feedback","summary":"  This paper studies online convex optimization with unknown linear budget\nconstraints, where only the gradient information of the objective and the\nbandit feedback of constraint functions are observed. We propose a safe and\nefficient Lyapunov-optimization algorithm (SELO) that can achieve an\n$O(\\sqrt{T})$ regret and zero cumulative constraint violation. The result also\nimplies SELO achieves $O(\\sqrt{T})$ regret when the budget is hard and not\nallowed to be violated. The proposed algorithm is computationally efficient as\nit resembles a primal-dual algorithm where the primal problem is an\nunconstrained, strongly convex and smooth problem, and the dual problem has a\nsimple gradient-type update. The algorithm and theory are further justified in\na simulated application of energy-efficient task processing in distributed data\ncenters.\n","authors":["Shanqi Liu","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2412.03983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05306v1","updated":"2025-03-07T10:35:01Z","published":"2025-03-07T10:35:01Z","title":"Adversarial Policy Optimization for Offline Preference-based\n  Reinforcement Learning","summary":"  In this paper, we study offline preference-based reinforcement learning\n(PbRL), where learning is based on pre-collected preference feedback over pairs\nof trajectories. While offline PbRL has demonstrated remarkable empirical\nsuccess, existing theoretical approaches face challenges in ensuring\nconservatism under uncertainty, requiring computationally intractable\nconfidence set constructions. We address this limitation by proposing\nAdversarial Preference-based Policy Optimization (APPO), a computationally\nefficient algorithm for offline PbRL that guarantees sample complexity bounds\nwithout relying on explicit confidence sets. By framing PbRL as a two-player\ngame between a policy and a model, our approach enforces conservatism in a\ntractable manner. Using standard assumptions on function approximation and\nbounded trajectory concentrability, we derive a sample complexity bound. To our\nknowledge, APPO is the first offline PbRL algorithm to offer both statistical\nefficiency and practical applicability. Experimental results on continuous\ncontrol tasks demonstrate that APPO effectively learns from complex datasets,\nshowing comparable performance with existing state-of-the-art methods.\n","authors":["Hyungkyu Kang","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2503.05306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05303v1","updated":"2025-03-07T10:31:59Z","published":"2025-03-07T10:31:59Z","title":"Robust Intrusion Detection System with Explainable Artificial\n  Intelligence","summary":"  Machine learning (ML) models serve as powerful tools for threat detection and\nmitigation; however, they also introduce potential new risks. Adversarial input\ncan exploit these models through standard interfaces, thus creating new attack\npathways that threaten critical network operations. As ML advancements\nprogress, adversarial strategies become more advanced, and conventional\ndefenses such as adversarial training are costly in computational terms and\noften fail to provide real-time detection. These methods typically require a\nbalance between robustness and model performance, which presents challenges for\napplications that demand instant response. To further investigate this\nvulnerability, we suggest a novel strategy for detecting and mitigating\nadversarial attacks using eXplainable Artificial Intelligence (XAI). This\napproach is evaluated in real time within intrusion detection systems (IDS),\nleading to the development of a zero-touch mitigation strategy. Additionally,\nwe explore various scenarios in the Radio Resource Control (RRC) layer within\nthe Open Radio Access Network (O-RAN) framework, emphasizing the critical need\nfor enhanced mitigation techniques to strengthen IDS defenses against advanced\nthreats and implement a zero-touch mitigation solution. Extensive testing\nacross different scenarios in the RRC layer of the O-RAN infrastructure\nvalidates the ability of the framework to detect and counteract integrated\nRRC-layer attacks when paired with adversarial strategies, emphasizing the\nessential need for robust defensive mechanisms to strengthen IDS against\ncomplex threats.\n","authors":["Betül Güvenç Paltun","Ramin Fuladi","Rim El Malki"],"pdf_url":"https://arxiv.org/pdf/2503.05303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16838v7","updated":"2025-03-07T10:15:41Z","published":"2023-06-29T10:29:29Z","title":"Fast Robust Kernel Regression through Sign Gradient Descent with Early\n  Stopping","summary":"  Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the model parameters. Here, we\nintroduce an equivalent formulation of the objective function of KRR, which\nopens up for replacing the ridge penalty with the $\\ell_\\infty$ and $\\ell_1$\npenalties. Using the $\\ell_\\infty$ and $\\ell_1$ penalties, we obtain robust and\nsparse kernel regression, respectively. We study the similarities between\nexplicitly regularized kernel regression and the solutions obtained by early\nstopping of iterative gradient-based methods, where we connect $\\ell_\\infty$\nregularization to sign gradient descent, $\\ell_1$ regularization to forward\nstagewise regression (also known as coordinate descent), and $\\ell_2$\nregularization to gradient descent, and, in the last case, theoretically bound\nfor the differences. We exploit the close relations between $\\ell_\\infty$\nregularization and sign gradient descent, and between $\\ell_1$ regularization\nand coordinate descent to propose computationally efficient methods for robust\nand sparse kernel regression. We finally compare robust kernel regression\nthrough sign gradient descent to existing methods for robust kernel regression\non five real data sets, demonstrating that our method is one to two orders of\nmagnitude faster, without compromised accuracy.\n","authors":["Oskar Allerbo"],"pdf_url":"https://arxiv.org/pdf/2306.16838v7.pdf","comment":"Article arXiv:2306.16838v1 has been updated and split into two\n  articles: this article and arXiv:2311.01762. Thus, some of the content in\n  arXiv:2306.16838v1 is not a part of arXiv:2306.16838v2, but of\n  arXiv:2311.01762"},{"id":"http://arxiv.org/abs/2503.05289v1","updated":"2025-03-07T10:09:16Z","published":"2025-03-07T10:09:16Z","title":"An Analytical Model for Overparameterized Learning Under Class Imbalance","summary":"  We study class-imbalanced linear classification in a high-dimensional\nGaussian mixture model. We develop a tight, closed form approximation for the\ntest error of several practical learning methods, including logit adjustment\nand class dependent temperature. Our approximation allows us to analytically\ntune and compare these methods, highlighting how and when they overcome the\npitfalls of standard cross-entropy minimization. We test our theoretical\nfindings on simulated data and imbalanced CIFAR10, MNIST and FashionMNIST\ndatasets.\n","authors":["Eliav Mor","Yair Carmon"],"pdf_url":"https://arxiv.org/pdf/2503.05289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15247v2","updated":"2025-03-07T10:07:37Z","published":"2024-11-22T08:00:20Z","title":"Reward Fine-Tuning Two-Step Diffusion Models via Learning Differentiable\n  Latent-Space Surrogate Reward","summary":"  Recent research has shown that fine-tuning diffusion models (DMs) with\narbitrary rewards, including non-differentiable ones, is feasible with\nreinforcement learning (RL) techniques, enabling flexible model alignment.\nHowever, applying existing RL methods to timestep-distilled DMs is challenging\nfor ultra-fast ($\\le2$-step) image generation. Our analysis suggests several\nlimitations of policy-based RL methods such as PPO or DPO toward this goal.\nBased on the insights, we propose fine-tuning DMs with learned differentiable\nsurrogate rewards. Our method, named LaSRO, learns surrogate reward models in\nthe latent space of SDXL to convert arbitrary rewards into differentiable ones\nfor efficient reward gradient guidance. LaSRO leverages pre-trained latent DMs\nfor reward modeling and specifically targets image generation $\\le2$ steps for\nreward optimization, enhancing generalizability and efficiency. LaSRO is\neffective and stable for improving ultra-fast image generation with different\nreward objectives, outperforming popular RL methods including PPO and DPO. We\nfurther show LaSRO's connection to value-based RL, providing theoretical\ninsights. See our webpage at https://sites.google.com/view/lasro.\n","authors":["Zhiwei Jia","Yuesong Nan","Huixi Zhao","Gengdai Liu"],"pdf_url":"https://arxiv.org/pdf/2411.15247v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04280v2","updated":"2025-03-07T10:06:29Z","published":"2025-03-06T10:08:44Z","title":"Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.\n","authors":["Niccolò Turcato","Matteo Iovino","Aris Synodinos","Alberto Dalla Libera","Ruggero Carli","Pietro Falco"],"pdf_url":"https://arxiv.org/pdf/2503.04280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03315v2","updated":"2025-03-07T10:05:23Z","published":"2024-10-08T11:01:12Z","title":"Learning Force Distribution Estimation for the GelSight Mini Optical\n  Tactile Sensor Based on Finite Element Analysis","summary":"  Contact-rich manipulation remains a major challenge in robotics. Optical\ntactile sensors like GelSight Mini offer a low-cost solution for contact\nsensing by capturing soft-body deformations of the silicone gel. However,\naccurately inferring shear and normal force distributions from these gel\ndeformations has yet to be fully addressed. In this work, we propose a machine\nlearning approach using a U-net architecture to predict force distributions\ndirectly from the sensor's raw images. Our model, trained on force\ndistributions inferred from Finite Element Analysis (FEA), demonstrates\npromising accuracy in predicting normal and shear force distributions for the\ncommercially available GelSight Mini sensor. It also shows potential for\ngeneralization across indenters, sensors of the same type, and for enabling\nreal-time application. The codebase, dataset and models are open-sourced and\navailable at https://feats-ai.github.io .\n","authors":["Erik Helmut","Luca Dziarski","Niklas Funk","Boris Belousov","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2411.03315v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04638v2","updated":"2025-03-07T09:18:06Z","published":"2025-03-06T17:25:46Z","title":"No Forgetting Learning: Memory-free Continual Learning","summary":"  Continual Learning (CL) remains a central challenge in deep learning, where\nmodels must sequentially acquire new knowledge while mitigating Catastrophic\nForgetting (CF) of prior tasks. Existing approaches often struggle with\nefficiency and scalability, requiring extensive memory or model buffers. This\nwork introduces ``No Forgetting Learning\" (NFL), a memory-free CL framework\nthat leverages knowledge distillation to maintain stability while preserving\nplasticity. Memory-free means the NFL does not rely on any memory buffer.\nThrough extensive evaluations of three benchmark datasets, we demonstrate that\nNFL achieves competitive performance while utilizing approximately 14.75 times\nless memory than state-of-the-art methods. Furthermore, we introduce a new\nmetric to better assess CL's plasticity-stability trade-off.\n","authors":["Mohammad Ali Vahedifar","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04638v2.pdf","comment":"This paper is submitted to ICCV 2025"},{"id":"http://arxiv.org/abs/2503.01743v2","updated":"2025-03-07T09:05:58Z","published":"2025-03-03T17:05:52Z","title":"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs","summary":"  We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n","authors":[" Microsoft"," :","Abdelrahman Abouelenin","Atabak Ashfaq","Adam Atkinson","Hany Awadalla","Nguyen Bach","Jianmin Bao","Alon Benhaim","Martin Cai","Vishrav Chaudhary","Congcong Chen","Dong Chen","Dongdong Chen","Junkun Chen","Weizhu Chen","Yen-Chun Chen","Yi-ling Chen","Qi Dai","Xiyang Dai","Ruchao Fan","Mei Gao","Min Gao","Amit Garg","Abhishek Goswami","Junheng Hao","Amr Hendy","Yuxuan Hu","Xin Jin","Mahmoud Khademi","Dongwoo Kim","Young Jin Kim","Gina Lee","Jinyu Li","Yunsheng Li","Chen Liang","Xihui Lin","Zeqi Lin","Mengchen Liu","Yang Liu","Gilsinia Lopez","Chong Luo","Piyush Madan","Vadim Mazalov","Arindam Mitra","Ali Mousavi","Anh Nguyen","Jing Pan","Daniel Perez-Becker","Jacob Platin","Thomas Portet","Kai Qiu","Bo Ren","Liliang Ren","Sambuddha Roy","Ning Shang","Yelong Shen","Saksham Singhal","Subhojit Som","Xia Song","Tetyana Sych","Praneetha Vaddamanu","Shuohang Wang","Yiming Wang","Zhenghao Wang","Haibin Wu","Haoran Xu","Weijian Xu","Yifan Yang","Ziyi Yang","Donghan Yu","Ishmam Zabir","Jianwen Zhang","Li Lyna Zhang","Yunan Zhang","Xiren Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01743v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2503.05246v1","updated":"2025-03-07T08:58:07Z","published":"2025-03-07T08:58:07Z","title":"Mastering Continual Reinforcement Learning through Fine-Grained Sparse\n  Network Allocation and Dormant Neuron Exploration","summary":"  Continual Reinforcement Learning (CRL) is essential for developing agents\nthat can learn, adapt, and accumulate knowledge over time. However, a\nfundamental challenge persists as agents must strike a delicate balance between\nplasticity, which enables rapid skill acquisition, and stability, which ensures\nlong-term knowledge retention while preventing catastrophic forgetting. In this\npaper, we introduce SSDE, a novel structure-based approach that enhances\nplasticity through a fine-grained allocation strategy with Structured Sparsity\nand Dormant-guided Exploration. SSDE decomposes the parameter space into\nforward-transfer (frozen) parameters and task-specific (trainable) parameters.\nCrucially, these parameters are allocated by an efficient co-allocation scheme\nunder sparse coding, ensuring sufficient trainable capacity for new tasks while\npromoting efficient forward transfer through frozen parameters. However,\nstructure-based methods often suffer from rigidity due to the accumulation of\nnon-trainable parameters, limiting exploration and adaptability. To address\nthis, we further introduce a sensitivity-guided neuron reactivation mechanism\nthat systematically identifies and resets dormant neurons, which exhibit\nminimal influence in the sparse policy network during inference. This approach\neffectively enhance exploration while preserving structural efficiency.\nExtensive experiments on the CW10-v1 Continual World benchmark demonstrate that\nSSDE achieves state-of-the-art performance, reaching a success rate of 95%,\nsurpassing prior methods significantly in both plasticity and stability\ntrade-offs (code is available at: https://github.com/chengqiArchy/SSDE).\n","authors":["Chengqi Zheng","Haiyan Yin","Jianda Chen","Terrence Ng","Yew-Soon Ong","Ivor Tsang"],"pdf_url":"https://arxiv.org/pdf/2503.05246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v2","updated":"2025-03-07T08:55:13Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.11977v2","updated":"2025-03-07T08:52:46Z","published":"2021-04-24T16:16:30Z","title":"Generalized moduli of continuity under irregular or random deformations\n  via multiscale analysis","summary":"  Motivated by the problem of robustness to deformations of the input for deep\nconvolutional neural networks, we identify signal classes which are inherently\nstable to irregular deformations induced by distortion fields $\\tau\\in\nL^\\infty(\\mathbb{R}^d;\\mathbb{R}^d)$, to be characterized in terms of a\ngeneralized modulus of continuity associated with the deformation operator.\nResorting to ideas of harmonic and multiscale analysis, we prove that for\nsignals in multiresolution approximation spaces $U_s$ at scale $s$, stability\nin $L^2$ holds in the regime $\\|\\tau\\|_{L^\\infty}/s\\ll 1$ - essentially as an\neffect of the uncertainty principle. Instability occurs when\n$\\|\\tau\\|_{L^\\infty}/s\\gg 1$, and we provide a sharp upper bound for the\nasymptotic growth rate. The stability results are then extended to signals in\nthe Besov space $B^{d/2}_{2,1}$ tailored to the given multiresolution\napproximation. We also consider the case of more general time-frequency\ndeformations. Finally, we provide stochastic versions of the aforementioned\nresults, namely we study the issue of stability in mean when $\\tau(x)$ is\nmodeled as a random field (not bounded, in general) with identically\ndistributed variables $|\\tau(x)|$, $x\\in\\mathbb{R}^d$.\n","authors":["Fabio Nicola","S. Ivan Trapasso"],"pdf_url":"https://arxiv.org/pdf/2104.11977v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.05239v1","updated":"2025-03-07T08:41:53Z","published":"2025-03-07T08:41:53Z","title":"Robust Conformal Prediction with a Single Binary Certificate","summary":"  Conformal prediction (CP) converts any model's output to prediction sets with\na guarantee to cover the true label with (adjustable) high probability. Robust\nCP extends this guarantee to worst-case (adversarial) inputs. Existing\nbaselines achieve robustness by bounding randomly smoothed conformity scores.\nIn practice, they need expensive Monte-Carlo (MC) sampling (e.g. $\\sim10^4$\nsamples per point) to maintain an acceptable set size. We propose a robust\nconformal prediction that produces smaller sets even with significantly lower\nMC samples (e.g. 150 for CIFAR10). Our approach binarizes samples with an\nadjustable (or automatically adjusted) threshold selected to preserve the\ncoverage guarantee. Remarkably, we prove that robustness can be achieved by\ncomputing only one binary certificate, unlike previous methods that certify\neach calibration (or test) point. Thus, our method is faster and returns\nsmaller robust sets. We also eliminate a previous limitation that requires a\nbounded score function.\n","authors":["Soroush H. Zargarbashi","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2503.05239v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05238v1","updated":"2025-03-07T08:40:41Z","published":"2025-03-07T08:40:41Z","title":"Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition\n  Estimation","summary":"  An issue concerning the use of deep reinforcement learning (RL) agents is\nwhether they can be trusted to perform reliably when deployed, as training\nenvironments may not reflect real-life environments. Anticipating instances\noutside their training scope, learning-enabled systems are often equipped with\nout-of-distribution (OOD) detectors that alert when a trained system encounters\na state it does not recognize or in which it exhibits uncertainty. There exists\nlimited work conducted on the problem of OOD detection within RL, with prior\nstudies being unable to achieve a consensus on the definition of OOD execution\nwithin the context of RL. By framing our problem using a Markov Decision\nProcess, we assume there is a transition distribution mapping each state-action\npair to another state with some probability. Based on this, we consider the\nfollowing definition of OOD execution within RL: A transition is OOD if its\nprobability during real-life deployment differs from the transition\ndistribution encountered during training. As such, we utilize conditional\nvariational autoencoders (CVAE) to approximate the transition dynamics of the\ntraining environment and implement a conformity-based detector using\nreconstruction loss that is able to guarantee OOD detection with a\npre-determined confidence level. We evaluate our detector by adapting existing\nbenchmarks and compare it with existing OOD detection models for RL.\n","authors":["Mohit Prashant","Arvind Easwaran","Suman Das","Michael Yuhas"],"pdf_url":"https://arxiv.org/pdf/2503.05238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10690v4","updated":"2025-03-07T08:40:19Z","published":"2024-01-19T13:41:08Z","title":"Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and\n  unfairness in dyadic regression models","summary":"  Dyadic regression models, which output real-valued predictions for pairs of\nentities, are fundamental in many domains (e.g. obtaining user-product ratings\nin Recommender Systems) and promising and under exploration in others (e.g.\ntuning patient-drug dosages in precision pharmacology). In this work, we prove\nthat non-uniform observed value distributions of individual entities lead to\nsevere biases in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet crucial cases; we name this phenomenon\neccentricity bias. We show that global error metrics like Root Mean Squared\nError (RMSE) are insufficient to capture this bias, and we introduce\nEccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it\nin all studied domains and models. We prove the intuitive interpretation of\nEAUC by experimenting with naive post-training bias corrections, and theorize\nother options to use EAUC to guide the construction of fair models. This work\ncontributes a bias-aware evaluation of dyadic regression to prevent unfairness\nin critical real-world applications of such systems.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Bertha Guijarro-Berdiñas","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2401.10690v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05605v2","updated":"2025-03-07T08:35:00Z","published":"2025-02-08T15:21:55Z","title":"ARIES: Stimulating Self-Refinement of Large Language Models by Iterative\n  Preference Optimization","summary":"  A truly intelligent Large Language Model (LLM) should be capable of\ncorrecting errors in its responses through external interactions. However, even\nthe most advanced models often face challenges in improving their outputs. In\nthis paper, we explore how to cultivate LLMs with the self-refinement\ncapability through iterative preference training, and how this ability can be\nleveraged to improve model performance during inference. To this end, we\nintroduce a novel post-training and inference framework, called ARIES: Adaptive\nRefinement and Iterative Enhancement Structure. This method iteratively\nperforms preference training and self-refinement-based data collection. During\ntraining, ARIES strengthen the model's direct question-answering capability\nwhile simultaneously unlocking its self-refinement potential. During inference,\nARIES harnesses this self-refinement capability to generate a series of\nprogressively refined responses, which are then filtered using either the\nReward Model Scoring or a simple yet effective Rule-Based Selection mechanism,\nspecifically tailored to our approach, to construct a dataset for the next\nround of preference training. Experimental results demonstrate the remarkable\nperformance of ARIES. When applied to the Llama-3.1-8B model and under the\nself-refinement setting, ARIES surpasses powerful models such as GPT-4o,\nachieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval\n2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a\n50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore,\nARIES consistently enhances performance on mathematical reasoning tasks like\nGSM8K and MATH.\n","authors":["Yongcheng Zeng","Xinyu Cui","Xuanfa Jin","Guoqing Liu","Zexu Sun","Quan He","Dong Li","Ning Yang","Jianye Hao","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.05605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05224v1","updated":"2025-03-07T08:22:50Z","published":"2025-03-07T08:22:50Z","title":"Deep Sequence Models for Predicting Average Shear Wave Velocity from\n  Strong Motion Records","summary":"  This study explores the use of deep learning for predicting the time averaged\nshear wave velocity in the top 30 m of the subsurface ($V_{s30}$) at strong\nmotion recording stations in T\\\"urkiye. $V_{s30}$ is a key parameter in site\ncharacterization and, as a result for seismic hazard assessment. However, it is\noften unavailable due to the lack of direct measurements and is therefore\nestimated using empirical correlations. Such correlations however are commonly\ninadequate in capturing complex, site-specific variability and this motivates\nthe need for data-driven approaches. In this study, we employ a hybrid deep\nlearning model combining convolutional neural networks (CNNs) and long\nshort-term memory (LSTM) networks to capture both spatial and temporal\ndependencies in strong motion records. Furthermore, we explore how using\ndifferent parts of the signal influence our deep learning model. Our results\nsuggest that the hybrid approach effectively learns complex, nonlinear\nrelationships within seismic signals. We observed that an improved P-wave\narrival time model increased the prediction accuracy of $V_{s30}$. We believe\nthe study provides valuable insights into improving $V_{s30}$ predictions using\na CNN-LSTM framework, demonstrating its potential for improving site\ncharacterization for seismic studies. Our codes are available via this repo:\nhttps://github.com/brsylmz23/CNNLSTM_DeepEQ\n","authors":["Baris Yilmaz","Erdem Akagündüz","Salih Tileylioglu"],"pdf_url":"https://arxiv.org/pdf/2503.05224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05223v1","updated":"2025-03-07T08:21:48Z","published":"2025-03-07T08:21:48Z","title":"DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker\n  Characteristics And Intelligibility","summary":"  Video-to-speech (V2S) synthesis, the task of generating speech directly from\nsilent video input, is inherently more challenging than other speech synthesis\ntasks due to the need to accurately reconstruct both speech content and speaker\ncharacteristics from visual cues alone. Recently, audio-visual pre-training has\neliminated the need for additional acoustic hints in V2S, which previous\nmethods often relied on to ensure training convergence. However, even with\npre-training, existing methods continue to face challenges in achieving a\nbalance between acoustic intelligibility and the preservation of\nspeaker-specific characteristics. We analyzed this limitation and were\nmotivated to introduce DiVISe (Direct Visual-Input Speech Synthesis), an\nend-to-end V2S model that predicts Mel-spectrograms directly from video frames\nalone. Despite not taking any acoustic hints, DiVISe effectively preserves\nspeaker characteristics in the generated audio, and achieves superior\nperformance on both objective and subjective metrics across the LRS2 and LRS3\ndatasets. Our results demonstrate that DiVISe not only outperforms existing V2S\nmodels in acoustic intelligibility but also scales more effectively with\nincreased data and model parameters. Code and weights can be found at\nhttps://github.com/PussyCat0700/DiVISe.\n","authors":["Yifan Liu","Yu Fang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2503.05223v1.pdf","comment":"to be published in NAACL 25"},{"id":"http://arxiv.org/abs/2503.05215v1","updated":"2025-03-07T08:10:45Z","published":"2025-03-07T08:10:45Z","title":"Robustness of Generalized Median Computation for Consensus Learning in\n  Arbitrary Spaces","summary":"  Robustness in terms of outliers is an important topic and has been formally\nstudied for a variety of problems in machine learning and computer vision.\nGeneralized median computation is a special instance of consensus learning and\na common approach to finding prototypes. Related research can be found in\nnumerous problem domains with a broad range of applications. So far, however,\nrobustness of generalized median has only been studied in a few specific\nspaces. To our knowledge, there is no robustness characterization in a general\nsetting, i.e. for arbitrary spaces. We address this open issue in our work. The\nbreakdown point >=0.5 is proved for generalized median with metric distance\nfunctions in general. We also study the detailed behavior in case of outliers\nfrom different perspectives. In addition, we present robustness results for\nweighted generalized median computation and non-metric distance functions.\nGiven the importance of robustness, our work contributes to closing a gap in\nthe literature. The presented results have general impact and applicability,\ne.g. providing deeper understanding of generalized median computation and\npractical guidance to avoid non-robust computation.\n","authors":["Andreas Nienkötter","Sandro Vega-Pons","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.05215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19346v2","updated":"2025-03-07T08:08:18Z","published":"2024-11-28T19:48:54Z","title":"CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image\n  Collections","summary":"  In the era of foundation models, CLIP has emerged as a powerful tool for\naligning text & visual modalities into a common embedding space. However, the\nalignment objective used to train CLIP often results in subpar visual features\nfor fine-grained tasks. In contrast, SSL-pretrained models like DINO excel at\nextracting rich visual features due to their specialized training paradigm.\nYet, these SSL models require an additional supervised linear probing step,\nwhich relies on fully labeled data which is often expensive and difficult to\nobtain at scale. In this paper, we propose a label-free prompt-tuning method\nthat leverages the rich visual features of self-supervised learning models\n(DINO) and the broad textual knowledge of large language models (LLMs) to\nlargely enhance CLIP-based image classification performance using unlabeled\nimages. Our approach unfolds in three key steps: (1) We generate robust textual\nfeature embeddings that more accurately represent object classes by leveraging\nclass-specific descriptions from LLMs, enabling more effective zero-shot\nclassification compared to CLIP's default name-specific prompts. (2) These\ntextual embeddings are then used to produce pseudo-labels to train an alignment\nmodule that integrates the complementary strengths of LLM description-based\ntextual embeddings & DINO's visual features. (3) Finally, we prompt-tune CLIP's\nvision encoder through DINO-assisted supervision using the trained alignment\nmodule. This three-step process allows us to harness the best of visual &\ntextual foundation models, resulting in a powerful and efficient approach that\nsurpasses state-of-the-art label-free classification methods. Notably, our\nframework, NoLA (No Labels Attached), achieves an average absolute gain of 3.6%\nover the state-of-the-art LaFTer across 11 diverse image classification\ndatasets. Our code & models can be found at https://github.com/fazliimam/NoLA.\n","authors":["Mohamed Fazli Imam","Rufael Fedaku Marew","Jameel Hassan","Mustansar Fiaz","Alham Fikri Aji","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2411.19346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03796v2","updated":"2025-03-07T08:06:15Z","published":"2025-03-05T14:33:18Z","title":"Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent\n  Reinforcement Learning in USV Swarm","summary":"  Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.\n","authors":["Hyeonjun Kim","Kanghoon Lee","Junho Park","Jiachen Li","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2503.03796v2.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05207v1","updated":"2025-03-07T07:55:51Z","published":"2025-03-07T07:55:51Z","title":"Policy Constraint by Only Support Constraint for Offline Reinforcement\n  Learning","summary":"  Offline reinforcement learning (RL) aims to optimize a policy by using\npre-collected datasets, to maximize cumulative rewards. However, offline\nreinforcement learning suffers challenges due to the distributional shift\nbetween the learned and behavior policies, leading to errors when computing\nQ-values for out-of-distribution (OOD) actions. To mitigate this issue, policy\nconstraint methods aim to constrain the learned policy's distribution with the\ndistribution of the behavior policy or confine action selection within the\nsupport of the behavior policy. However, current policy constraint methods tend\nto exhibit excessive conservatism, hindering the policy from further surpassing\nthe behavior policy's performance. In this work, we present Only Support\nConstraint (OSC) which is derived from maximizing the total probability of\nlearned policy in the support of behavior policy, to address the conservatism\nof policy constraint. OSC presents a regularization term that only restricts\npolicies to the support without imposing extra constraints on actions within\nthe support. Additionally, to fully harness the performance of the new policy\nconstraints, OSC utilizes a diffusion model to effectively characterize the\nsupport of behavior policies. Experimental evaluations across a variety of\noffline RL benchmarks demonstrate that OSC significantly enhances performance,\nalleviating the challenges associated with distributional shifts and mitigating\nconservatism of policy constraints. Code is available at\nhttps://github.com/MoreanP/OSC.\n","authors":["Yunkai Gao","Jiaming Guo","Fan Wu","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01194v2","updated":"2025-03-07T07:47:19Z","published":"2024-07-01T11:39:15Z","title":"A Learned Generalized Geodesic Distance Function-Based Approach for Node\n  Feature Augmentation on Graphs","summary":"  Geodesic distances on manifolds have numerous applications in image\nprocessing, computer graphics and computer vision. In this work, we introduce\nan approach called `LGGD' (Learned Generalized Geodesic Distances). This method\ninvolves generating node features by learning a generalized geodesic distance\nfunction through a training pipeline that incorporates training data, graph\ntopology and the node content features. The strength of this method lies in the\nproven robustness of the generalized geodesic distances to noise and outliers.\nOur contributions encompass improved performance in node classification tasks,\ncompetitive results with state-of-the-art methods on real-world graph datasets,\nthe demonstration of the learnability of parameters within the generalized\ngeodesic equation on graph, and dynamic inclusion of new labels.\n","authors":["Amitoz Azad","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2407.01194v2.pdf","comment":"Accepted at KDD 2024 Research Track"},{"id":"http://arxiv.org/abs/2503.02407v2","updated":"2025-03-07T07:46:34Z","published":"2025-03-04T08:50:10Z","title":"Wyckoff Transformer: Generation of Symmetric Crystals","summary":"  Symmetry rules that atoms obey when they bond together to form an ordered\ncrystal play a fundamental role in determining their physical, chemical, and\nelectronic properties such as electrical and thermal conductivity, optical and\npolarization behavior, and mechanical strength. Almost all known crystalline\nmaterials have internal symmetry. Consistently generating stable crystal\nstructures is still an open challenge, specifically because such symmetry rules\nare not accounted for. To address this issue, we propose WyFormer, a generative\nmodel for materials conditioned on space group symmetry. We use Wyckoff\npositions as the basis for an elegant, compressed, and discrete structure\nrepresentation. To model the distribution, we develop a permutation-invariant\nautoregressive model based on the Transformer and an absence of positional\nencoding. WyFormer has a unique and powerful synergy of attributes, proven by\nextensive experimentation: best-in-class symmetry-conditioned generation,\nphysics-motivated inductive bias, competitive stability of the generated\nstructures, competitive material property prediction quality, and unparalleled\ninference speed.\n","authors":["Nikita Kazeev","Wei Nong","Ignat Romanov","Ruiming Zhu","Andrey Ustyuzhanin","Shuya Yamazaki","Kedar Hippalgaonkar"],"pdf_url":"https://arxiv.org/pdf/2503.02407v2.pdf","comment":"https://github.com/SymmetryAdvantage/WyckoffTransformer"},{"id":"http://arxiv.org/abs/2503.05201v1","updated":"2025-03-07T07:46:26Z","published":"2025-03-07T07:46:26Z","title":"Deep Muscle EMG construction using A Physics-Integrated Deep Learning\n  approach","summary":"  Electromyography (EMG)--based computational musculoskeletal modeling is a\nnon-invasive method for studying musculotendon function, human movement, and\nneuromuscular control, providing estimates of internal variables like muscle\nforces and joint torques. However, EMG signals from deeper muscles are often\nchallenging to measure by placing the surface EMG electrodes and unfeasible to\nmeasure directly using invasive methods. The restriction to the access of EMG\ndata from deeper muscles poses a considerable obstacle to the broad adoption of\nEMG-driven modeling techniques. A strategic alternative is to use an estimation\nalgorithm to approximate the missing EMG signals from deeper muscle. A similar\nstrategy is used in physics-informed deep learning, where the features of\nphysical systems are learned without labeled data. In this work, we propose a\nhybrid deep learning algorithm, namely the neural musculoskeletal model (NMM),\nthat integrates physics-informed and data-driven deep learning to approximate\nthe EMG signals from the deeper muscles. While data-driven modeling is used to\npredict the missing EMG signals, physics-based modeling engraves the\nsubject-specific information into the predictions. Experimental verifications\non five test subjects are carried out to investigate the performance of the\nproposed hybrid framework. The proposed NMM is validated against the joint\ntorque computed from 'OpenSim' software. The predicted deep EMG signals are\nalso compared against the state-of-the-art muscle synergy extrapolation (MSE)\napproach, where the proposed NMM completely outperforms the existing MSE\nframework by a significant margin.\n","authors":["Rajnish Kumar","Tapas Tripura","Souvik Chakraborty","Sitikantha Roy"],"pdf_url":"https://arxiv.org/pdf/2503.05201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05194v1","updated":"2025-03-07T07:29:48Z","published":"2025-03-07T07:29:48Z","title":"Uncertainty-Aware Explainable Federated Learning","summary":"  Federated Learning (FL) is a collaborative machine learning paradigm for\nenhancing data privacy preservation. Its privacy-preserving nature complicates\nthe explanation of the decision-making processes and the evaluation of the\nreliability of the generated explanations. In this paper, we propose the\nUncertainty-aware eXplainable Federated Learning (UncertainXFL) to address\nthese challenges. It generates explanations for decision-making processes under\nFL settings and provides information regarding the uncertainty of these\nexplanations. UncertainXFL is the first framework to explicitly offer\nuncertainty evaluation for explanations within the FL context. Explanatory\ninformation is initially generated by the FL clients and then aggregated by the\nserver in a comprehensive and conflict-free manner during FL training. The\nquality of the explanations, including the uncertainty score and tested\nvalidity, guides the FL training process by prioritizing clients with the most\nreliable explanations through higher weights during model aggregation.\nExtensive experimental evaluation results demonstrate that UncertainXFL\nachieves superior model accuracy and explanation accuracy, surpassing the\ncurrent state-of-the-art model that does not incorporate uncertainty\ninformation by 2.71% and 1.77%, respectively. By integrating and quantifying\nuncertainty in the data into the explanation process, UncertainXFL not only\nclearly presents the explanation alongside its uncertainty, but also leverages\nthis uncertainty to guide the FL training process, thereby enhancing the\nrobustness and reliability of the resulting models.\n","authors":["Yanci Zhang","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2503.05194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16927v2","updated":"2025-03-07T07:28:39Z","published":"2025-02-24T07:37:29Z","title":"BigMac: A Communication-Efficient Mixture-of-Experts Model Structure for\n  Fast Training and Inference","summary":"  The Mixture-of-Experts (MoE) structure scales the Transformer-based large\nlanguage models (LLMs) and improves their performance with only the sub-linear\nincrease in computation resources. Recently, a fine-grained DeepSeekMoE\nstructure is proposed, which can further improve the computing efficiency of\nMoE without performance degradation. However, the All-to-All communication\nintroduced by MoE has become a bottleneck, especially for the fine-grained\nstructure, which typically involves and activates more experts, hence\ncontributing to heavier communication overhead.\n  In this paper, we propose a novel MoE structure named BigMac, which is also\nfine-grained but with high communication efficiency. The innovation of BigMac\nis mainly due to that we abandon the\n\\textbf{c}ommunicate-\\textbf{d}escend-\\textbf{a}scend-\\textbf{c}ommunicate\n(CDAC) manner used by fine-grained MoE, which leads to the All-to-All\ncommunication always taking place at the highest dimension. Instead, BigMac\ndesigns an efficient\n\\textbf{d}escend-\\textbf{c}ommunicate-\\textbf{c}ommunicate-\\textbf{a}scend\n(DCCA) manner. Specifically, we add a descending and ascending projection at\nthe entrance and exit of the expert, respectively, which enables the\ncommunication to perform at a very low dimension. Furthermore, to adapt to\nDCCA, we re-design the structure of small experts, ensuring that the expert in\nBigMac has enough complexity to address tokens. Experimental results show that\nBigMac achieves comparable or even better model quality than fine-grained MoEs\nwith the same number of experts and a similar number of total parameters.\nEqually importantly, BigMac reduces the end-to-end latency by up to\n3.09$\\times$ for training and increases the throughput by up to 3.11$\\times$\nfor inference on state-of-the-art AI computing frameworks including Megatron,\nTutel, and DeepSpeed-Inference.\n","authors":["Zewen Jin","Shengnan Wang","Jiaan Zhu","Hongrui Zhan","Youhui Bai","Lin Zhang","Zhenyu Ming","Cheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.16927v2.pdf","comment":"Typo Fixed"},{"id":"http://arxiv.org/abs/2503.05180v1","updated":"2025-03-07T06:59:27Z","published":"2025-03-07T06:59:27Z","title":"Safety-Critical Traffic Simulation with Adversarial Transfer of Driving\n  Intentions","summary":"  Traffic simulation, complementing real-world data with a long-tail\ndistribution, allows for effective evaluation and enhancement of the ability of\nautonomous vehicles to handle accident-prone scenarios. Simulating such\nsafety-critical scenarios is nontrivial, however, from log data that are\ntypically regular scenarios, especially in consideration of dynamic adversarial\ninteractions between the future motions of autonomous vehicles and surrounding\ntraffic participants. To address it, this paper proposes an innovative and\nefficient strategy, termed IntSim, that explicitly decouples the driving\nintentions of surrounding actors from their motion planning for realistic and\nefficient safety-critical simulation. We formulate the adversarial transfer of\ndriving intention as an optimization problem, facilitating extensive\nexploration of diverse attack behaviors and efficient solution convergence.\nSimultaneously, intention-conditioned motion planning benefits from powerful\ndeep models and large-scale real-world data, permitting the simulation of\nrealistic motion behaviors for actors. Specially, through adapting driving\nintentions based on environments, IntSim facilitates the flexible realization\nof dynamic adversarial interactions with autonomous vehicles. Finally,\nextensive open-loop and closed-loop experiments on real-world datasets,\nincluding nuScenes and Waymo, demonstrate that the proposed IntSim achieves\nstate-of-the-art performance in simulating realistic safety-critical scenarios\nand further improves planners in handling such scenarios.\n","authors":["Zherui Huang","Xing Gao","Guanjie Zheng","Licheng Wen","Xuemeng Yang","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2503.05180v1.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.05179v1","updated":"2025-03-07T06:57:17Z","published":"2025-03-07T06:57:17Z","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching","summary":"  Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.\n","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05175v1","updated":"2025-03-07T06:42:17Z","published":"2025-03-07T06:42:17Z","title":"Self-Supervised Penalty-Based Learning for Robust Constrained\n  Optimization","summary":"  We propose a new methodology for parameterized constrained robust\noptimization, an important class of optimization problems under uncertainty,\nbased on learning with a self-supervised penalty-based loss function. Whereas\nsupervised learning requires pre-solved instances for training, our approach\nleverages a custom loss function derived from the exact penalty method in\noptimization to learn an approximation, typically defined by a neural network\nmodel, of the parameterized optimal solution mapping. Additionally, we adapt\nour approach to robust constrained combinatorial optimization problems by\nincorporating a surrogate linear cost over mixed integer domains, and a smooth\napproximations thereof, into the final layer of the network architecture. We\nperform computational experiments to test our approach on three different\napplications: multidimensional knapsack with continuous variables,\ncombinatorial multidimensional knapsack with discrete variables, and an\ninventory management problem. Our results demonstrate that our self-supervised\napproach is able to effectively learn neural network approximations whose\ninference time is significantly smaller than the computation time of\ntraditional solvers for this class of robust optimization problems.\nFurthermore, our results demonstrate that by varying the penalty parameter we\nare able to effectively balance the trade-off between sub-optimality and robust\nfeasibility of the obtained solutions.\n","authors":["Wyame Benslimane","Paul Grigas"],"pdf_url":"https://arxiv.org/pdf/2503.05175v1.pdf","comment":"To appear in the proceedings of CPAIOR 2025"},{"id":"http://arxiv.org/abs/2503.05169v1","updated":"2025-03-07T06:25:20Z","published":"2025-03-07T06:25:20Z","title":"phepy: Visual Benchmarks and Improvements for Out-of-Distribution\n  Detectors","summary":"  Applying machine learning to increasingly high-dimensional problems with\nsparse or biased training data increases the risk that a model is used on\ninputs outside its training domain. For such out-of-distribution (OOD) inputs,\nthe model can no longer make valid predictions, and its error is potentially\nunbounded.\n  Testing OOD detection methods on real-world datasets is complicated by the\nambiguity around which inputs are in-distribution (ID) or OOD. We design a\nbenchmark for OOD detection, which includes three novel and easily-visualisable\ntoy examples. These simple examples provide direct and intuitive insight into\nwhether the detector is able to detect (1) linear and (2) non-linear concepts\nand (3) identify thin ID subspaces (needles) within high-dimensional spaces\n(haystacks). We use our benchmark to evaluate the performance of various\nmethods from the literature.\n  Since tactile examples of OOD inputs may benefit OOD detection, we also\nreview several simple methods to synthesise OOD inputs for supervised training.\nWe introduce two improvements, $t$-poking and OOD sample weighting, to make\nsupervised detectors more precise at the ID-OOD boundary. This is especially\nimportant when conflicts between real ID and synthetic OOD sample blur the\ndecision boundary.\n  Finally, we provide recommendations for constructing and applying\nout-of-distribution detectors in machine learning.\n","authors":["Juniper Tyree","Andreas Rupp","Petri S. Clusius","Michael H. Boy"],"pdf_url":"https://arxiv.org/pdf/2503.05169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05167v1","updated":"2025-03-07T06:14:26Z","published":"2025-03-07T06:14:26Z","title":"FMCHS: Advancing Traditional Chinese Medicine Herb Recommendation with\n  Fusion of Multiscale Correlations of Herbs and Symptoms","summary":"  Traditional Chinese medicine (TCM) exhibits remarkable therapeutic efficacy\nin disease treatment and healthcare through personalized herb prescriptions.\nHowever, current herb recommendation models inadequately capture the multiscale\nrelations between herbs and clinical symptoms, particularly neglecting latent\ncorrelations at the chemical-molecular scale. To address these limitations, we\npropose the Fusion of Multiscale Correlations of Herbs and Symptoms (FMCHS), an\ninnovative framework that synergistically integrates molecular-scale chemical\ncharacteristics of herbs with clinical symptoms. The framework employs\nmulti-relational graph transformer layers to generate enriched embeddings that\npreserve both structural and semantic features within herbs and symptoms.\nThrough systematic incorporation of herb chemical profiles into node embeddings\nand implementation of attention-based feature fusion, FMCHS effectively\nutilizes multiscale correlations. Comprehensive evaluations demonstrate FMCHS's\nsuperior performance over the state-of-the-art (SOTA) baseline, achieving\nrelative improvements of 8.85% in Precision@5, 12.30% in Recall@5, and 10.86%\nin F1@5 compared to the SOTA model on benchmark datasets. This work facilitates\nthe practical application of TCM in disease treatment and healthcare.\n","authors":["Xinhan Zheng","Huyu Wu","Haopeng Jin","Ruotai Li"],"pdf_url":"https://arxiv.org/pdf/2503.05167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v3","updated":"2025-03-07T05:49:35Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v3.pdf","comment":"22 pages, 5 figures, 16 tables"},{"id":"http://arxiv.org/abs/2407.12282v2","updated":"2025-03-07T05:47:20Z","published":"2024-07-17T03:02:24Z","title":"Chip Placement with Diffusion Models","summary":"  Macro placement is a vital step in digital circuit design that defines the\nphysical location of large collections of components, known as macros, on a 2D\nchip. Because key performance metrics of the chip are determined by the\nplacement, optimizing it is crucial. Existing learning-based methods typically\nfall short because of their reliance on reinforcement learning (RL), which is\nslow and struggles to generalize, requiring online training on each new\ncircuit. Instead, we train a diffusion model capable of placing new circuits\nzero-shot, using guided sampling in lieu of RL to optimize placement quality.\nTo enable such models to train at scale, we designed a capable yet efficient\narchitecture for the denoising model, and propose a novel algorithm to generate\nlarge synthetic datasets for pre-training. To allow zero-shot transfer to real\ncircuits, we empirically study the design decisions of our dataset generation\nalgorithm, and identify several key factors enabling generalization. When\ntrained on our synthetic data, our models generate high-quality placements on\nunseen, realistic circuits, achieving competitive performance on placement\nbenchmarks compared to state-of-the-art methods.\n","authors":["Vint Lee","Minh Nguyen","Leena Elzeiny","Chun Deng","Pieter Abbeel","John Wawrzynek"],"pdf_url":"https://arxiv.org/pdf/2407.12282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10510v3","updated":"2025-03-07T05:29:18Z","published":"2024-01-19T05:58:30Z","title":"When Large Language Models Meet Evolutionary Algorithms: Potential\n  Enhancements and Challenges","summary":"  Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.\n","authors":["Chao Wang","Jiaxuan Zhao","Licheng Jiao","Lingling Li","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2401.10510v3.pdf","comment":"The article has been accepted for publication in Research"},{"id":"http://arxiv.org/abs/2411.06042v2","updated":"2025-03-07T05:25:46Z","published":"2024-11-09T02:41:53Z","title":"Personalized Hierarchical Split Federated Learning in Wireless Networks","summary":"  Extreme resource constraints make large-scale machine learning (ML) with\ndistributed clients challenging in wireless networks. On the one hand,\nlarge-scale ML requires massive information exchange between clients and\nserver(s). On the other hand, these clients have limited battery and\ncomputation powers that are often dedicated to operational computations. Split\nfederated learning (SFL) is emerging as a potential solution to mitigate these\nchallenges, by splitting the ML model into client-side and server-side model\nblocks, where only the client-side block is trained on the client device.\nHowever, practical applications require personalized models that are suitable\nfor the client's personal task. Motivated by this, we propose a personalized\nhierarchical split federated learning (PHSFL) algorithm that is specially\ndesigned to achieve better personalization performance. More specially, owing\nto the fact that regardless of the severity of the statistical data\ndistributions across the clients, many of the features have similar attributes,\nwe only train the body part of the federated learning (FL) model while keeping\nthe (randomly initialized) classifier frozen during the training phase. We\nfirst perform extensive theoretical analysis to understand the impact of model\nsplitting and hierarchical model aggregations on the global model. Once the\nglobal model is trained, we fine-tune each client classifier to obtain the\npersonalized models. Our empirical findings suggest that while the globally\ntrained model with the untrained classifier performs quite similarly to other\nexisting solutions, the fine-tuned models show significantly improved\npersonalized performance.\n","authors":["Md-Ferdous Pervej","Andreas F. Molisch"],"pdf_url":"https://arxiv.org/pdf/2411.06042v2.pdf","comment":"Accepted for publication in IEEE ICC 2025"},{"id":"http://arxiv.org/abs/2503.05153v1","updated":"2025-03-07T05:22:52Z","published":"2025-03-07T05:22:52Z","title":"Generative Trajectory Stitching through Diffusion Composition","summary":"  Effective trajectory stitching for long-horizon planning is a significant\nchallenge in robotic decision-making. While diffusion models have shown promise\nin planning, they are limited to solving tasks similar to those seen in their\ntraining data. We propose CompDiffuser, a novel generative approach that can\nsolve new tasks by learning to compositionally stitch together shorter\ntrajectory chunks from previously seen tasks. Our key insight is modeling the\ntrajectory distribution by subdividing it into overlapping chunks and learning\ntheir conditional relationships through a single bidirectional diffusion model.\nThis allows information to propagate between segments during generation,\nensuring physically consistent connections. We conduct experiments on benchmark\ntasks of various difficulties, covering different environment sizes, agent\nstate dimension, trajectory types, training data quality, and show that\nCompDiffuser significantly outperforms existing methods.\n","authors":["Yunhao Luo","Utkarsh A. Mishra","Yilun Du","Danfei Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05153v1.pdf","comment":"Project page: https://comp-diffuser.github.io/"},{"id":"http://arxiv.org/abs/2404.10220v2","updated":"2025-03-07T05:09:28Z","published":"2024-04-16T02:01:56Z","title":"Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V","summary":"  Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.\n","authors":["Peiyuan Zhi","Zhiyuan Zhang","Yu Zhao","Muzhi Han","Zeyu Zhang","Zhitian Li","Ziyuan Jiao","Baoxiong Jia","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2404.10220v2.pdf","comment":"6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/"},{"id":"http://arxiv.org/abs/2503.05146v1","updated":"2025-03-07T05:08:23Z","published":"2025-03-07T05:08:23Z","title":"Unity RL Playground: A Versatile Reinforcement Learning Framework for\n  Mobile Robots","summary":"  This paper introduces Unity RL Playground, an open-source reinforcement\nlearning framework built on top of Unity ML-Agents. Unity RL Playground\nautomates the process of training mobile robots to perform various locomotion\ntasks such as walking, running, and jumping in simulation, with the potential\nfor seamless transfer to real hardware. Key features include one-click training\nfor imported robot models, universal compatibility with diverse robot\nconfigurations, multi-mode motion learning capabilities, and extreme\nperformance testing to aid in robot design optimization and morphological\nevolution. The attached video can be found at\nhttps://linqi-ye.github.io/video/iros25.mp4 and the code is coming soon.\n","authors":["Linqi Ye","Rankun Li","Xiaowen Hu","Jiayi Li","Boyang Xing","Yan Peng","Bin Liang"],"pdf_url":"https://arxiv.org/pdf/2503.05146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05143v1","updated":"2025-03-07T04:52:20Z","published":"2025-03-07T04:52:20Z","title":"FedMABench: Benchmarking Mobile Agents on Decentralized Heterogeneous\n  User Data","summary":"  Mobile agents have attracted tremendous research participation recently.\nTraditional approaches to mobile agent training rely on centralized data\ncollection, leading to high cost and limited scalability. Distributed training\nutilizing federated learning offers an alternative by harnessing real-world\nuser data, providing scalability and reducing costs. However, pivotal\nchallenges, including the absence of standardized benchmarks, hinder progress\nin this field.\n  To tackle the challenges, we introduce FedMABench, the first benchmark for\nfederated training and evaluation of mobile agents, specifically designed for\nheterogeneous scenarios. FedMABench features 6 datasets with 30+ subsets, 8\nfederated algorithms, 10+ base models, and over 800 apps across 5 categories,\nproviding a comprehensive framework for evaluating mobile agents across diverse\nenvironments. Through extensive experiments, we uncover several key insights:\nfederated algorithms consistently outperform local training; the distribution\nof specific apps plays a crucial role in heterogeneity; and, even apps from\ndistinct categories can exhibit correlations during training. FedMABench is\npublicly available at: https://github.com/wwh0411/FedMABench with the datasets\nat: https://huggingface.co/datasets/wwh0411/FedMABench.\n","authors":["Wenhao Wang","Zijie Yu","Rui Ye","Jianqing Zhang","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09898v3","updated":"2025-03-07T04:45:23Z","published":"2025-01-17T01:01:44Z","title":"FoundationStereo: Zero-Shot Stereo Matching","summary":"  Tremendous progress has been made in deep stereo matching to excel on\nbenchmark datasets through per-domain fine-tuning. However, achieving strong\nzero-shot generalization - a hallmark of foundation models in other computer\nvision tasks - remains challenging for stereo matching. We introduce\nFoundationStereo, a foundation model for stereo depth estimation designed to\nachieve strong zero-shot generalization. To this end, we first construct a\nlarge-scale (1M stereo pairs) synthetic training dataset featuring large\ndiversity and high photorealism, followed by an automatic self-curation\npipeline to remove ambiguous samples. We then design a number of network\narchitecture components to enhance scalability, including a side-tuning feature\nbackbone that adapts rich monocular priors from vision foundation models to\nmitigate the sim-to-real gap, and long-range context reasoning for effective\ncost volume filtering. Together, these components lead to strong robustness and\naccuracy across domains, establishing a new standard in zero-shot stereo depth\nestimation. Project page: https://nvlabs.github.io/FoundationStereo/\n","authors":["Bowen Wen","Matthew Trepte","Joseph Aribido","Jan Kautz","Orazio Gallo","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2501.09898v3.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.05139v1","updated":"2025-03-07T04:43:39Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2411.11521v2","updated":"2025-03-07T04:39:05Z","published":"2024-11-18T12:31:22Z","title":"Preempting Text Sanitization Utility in Resource-Constrained\n  Privacy-Preserving LLM Interactions","summary":"  Interactions with online Large Language Models raise privacy issues where\nproviders can gather sensitive information about users and their companies from\nthe prompts. While Differential Privacy can be applied on textual prompts\nthrough the Multidimensional Laplace Mechanism, we show that it is difficult to\nanticipate the utility of such sanitized prompt. Poor utility has clear\nmonetary consequences for LLM services charging on a pay-per-use model as well\nas great amount of computing resources wasted. To this end, we propose an\narchitecture to predict the utility of a given sanitized prompt before it is\nsent to the LLM. We experimentally show that our architecture helps prevent\nsuch resource waste for up to 12% of the prompts. We also reproduce experiments\nfrom one of the most cited paper on distance-based DP for text sanitization and\nshow that a potential performance-driven implementation choice completely\nchanges the output while not being explicitly defined in the paper.\n","authors":["Robin Carpentier","Benjamin Zi Hao Zhao","Hassan Jameel Asghar","Dali Kaafar"],"pdf_url":"https://arxiv.org/pdf/2411.11521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10020v3","updated":"2025-03-07T04:29:35Z","published":"2025-02-14T09:01:12Z","title":"Improved Online Confidence Bounds for Multinomial Logistic Bandits","summary":"  In this paper, we propose an improved online confidence bound for multinomial\nlogistic (MNL) models and apply this result to MNL bandits, achieving\nvariance-dependent optimal regret. Recently, Lee & Oh (2024) established an\nonline confidence bound for MNL models and achieved nearly minimax-optimal\nregret in MNL bandits. However, their results still depend on the\nnorm-boundedness of the unknown parameter $B$ and the maximum size of possible\noutcomes $K$. To address this, we first derive an online confidence bound of\n$O\\left(\\sqrt{d \\log t} + B \\right)$, which is a significant improvement over\nthe previous bound of $O (B \\sqrt{d} \\log t \\log K )$ (Lee & Oh, 2024). This is\nmainly achieved by establishing tighter self-concordant properties of the MNL\nloss and introducing a novel intermediary term to bound the estimation error.\nUsing this new online confidence bound, we propose a constant-time algorithm,\nOFU-MNL++, which achieves a variance-dependent regret bound of $O \\Big( d \\log\nT \\sqrt{ \\sum_{t=1}^T \\sigma_t^2 } \\Big) $ for sufficiently large $T$, where\n$\\sigma_t^2$ denotes the variance of the rewards at round $t$, $d$ is the\ndimension of the contexts, and $T$ is the total number of rounds. Furthermore,\nwe introduce a Maximum Likelihood Estimation (MLE)-based algorithm,\nOFU-MN$^2$L, which achieves an anytime poly(B)-free regret of $O \\Big( d \\log\n(BT) \\sqrt{ \\sum_{t=1}^T \\sigma_t^2 } \\Big) $.\n","authors":["Joongkyu Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2502.10020v3.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2410.21357v4","updated":"2025-03-07T04:28:45Z","published":"2024-10-28T17:25:56Z","title":"Energy-Based Diffusion Language Models for Text Generation","summary":"  Despite remarkable progress in autoregressive language models, alternative\ngenerative paradigms beyond left-to-right generation are still being actively\nexplored. Discrete diffusion models, with the capacity for parallel generation,\nhave recently emerged as a promising alternative. Unfortunately, these models\nstill underperform the autoregressive counterparts, with the performance gap\nincreasing when reducing the number of sampling steps. Our analysis reveals\nthat this degradation is a consequence of an imperfect approximation used by\ndiffusion models. In this work, we propose Energy-based Diffusion Language\nModel (EDLM), an energy-based model operating at the full sequence level for\neach diffusion step, introduced to improve the underlying approximation used by\ndiffusion models. More specifically, we introduce an EBM in a residual form,\nand show that its parameters can be obtained by leveraging a pretrained\nautoregressive model or by finetuning a bidirectional transformer via noise\ncontrastive estimation. We also propose an efficient generation algorithm via\nparallel important sampling. Comprehensive experiments on language modeling\nbenchmarks show that our model can consistently outperform state-of-the-art\ndiffusion models by a significant margin, and approaches autoregressive models'\nperplexity. We further show that, without any generation performance drop, our\nframework offers a 1.3$\\times$ sampling speedup over existing diffusion models.\nReproduced code is available at\nhttps://github.com/MinkaiXu/Energy-Diffusion-LLM.\n","authors":["Minkai Xu","Tomas Geffner","Karsten Kreis","Weili Nie","Yilun Xu","Jure Leskovec","Stefano Ermon","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.21357v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09831v8","updated":"2025-03-07T04:23:19Z","published":"2024-05-16T06:07:31Z","title":"Nearly Minimax Optimal Regret for Multinomial Logistic Bandit","summary":"  In this paper, we study the contextual multinomial logit (MNL) bandit problem\nin which a learning agent sequentially selects an assortment based on\ncontextual information, and user feedback follows an MNL choice model. There\nhas been a significant discrepancy between lower and upper regret bounds,\nparticularly regarding the maximum assortment size $K$. Additionally, the\nvariation in reward structures between these bounds complicates the quest for\noptimality. Under uniform rewards, where all items have the same expected\nreward, we establish a regret lower bound of $\\Omega(d\\sqrt{T/K})$ and propose\na constant-time algorithm, OFU-MNL+, that achieves a matching upper bound of\n$\\tilde{O}(d\\sqrt{T/K})$. We also provide instance-dependent minimax regret\nbounds under uniform rewards. Under non-uniform rewards, we prove a lower bound\nof $\\Omega(d\\sqrt{T})$ and an upper bound of $\\tilde{O}(d\\sqrt{T})$, also\nachievable by OFU-MNL+. Our empirical studies support these theoretical\nfindings. To the best of our knowledge, this is the first work in the\ncontextual MNL bandit literature to prove minimax optimality -- for either\nuniform or non-uniform reward setting -- and to propose a computationally\nefficient algorithm that achieves this optimality up to logarithmic factors.\n","authors":["Joongkyu Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2405.09831v8.pdf","comment":"Accepted in NeurIPS 2024"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2503.05696v1","updated":"2025-03-07T18:58:23Z","published":"2025-03-07T18:58:23Z","title":"Multi-Fidelity Policy Gradient Algorithms","summary":"  Many reinforcement learning (RL) algorithms require large amounts of data,\nprohibiting their use in applications where frequent interactions with\noperational systems are infeasible, or high-fidelity simulations are expensive\nor unavailable. Meanwhile, low-fidelity simulators--such as reduced-order\nmodels, heuristic reward functions, or generative world models--can cheaply\nprovide useful data for RL training, even if they are too coarse for direct\nsim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL\nframework that mixes a small amount of data from the target environment with a\nlarge volume of low-fidelity simulation data to form unbiased, reduced-variance\nestimators (control variates) for on-policy policy gradients. We instantiate\nthe framework by developing multi-fidelity variants of two policy gradient\nalgorithms: REINFORCE and proximal policy optimization. Experimental results\nacross a suite of simulated robotics benchmark problems demonstrate that when\ntarget-environment samples are limited, MFPG achieves up to 3.9x higher reward\nand improves training stability when compared to baselines that only use\nhigh-fidelity data. Moreover, even when the baselines are given more\nhigh-fidelity samples--up to 10x as many interactions with the target\nenvironment--MFPG continues to match or outperform them. Finally, we observe\nthat MFPG is capable of training effective policies even when the low-fidelity\nenvironment is drastically different from the target environment. MFPG thus not\nonly offers a novel paradigm for efficient sim-to-real transfer but also\nprovides a principled approach to managing the trade-off between policy\nperformance and data collection costs.\n","authors":["Xinjie Liu","Cyrus Neary","Kushagra Gupta","Christian Ellis","Ufuk Topcu","David Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2503.05696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12561v2","updated":"2025-03-07T18:51:48Z","published":"2024-12-17T05:43:35Z","title":"Tell Me What to Track: Infusing Robust Language Guidance for Enhanced\n  Referring Multi-Object Tracking","summary":"  Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to localize an arbitrary number of targets based on a language expression\nand continuously track them in a video. This intricate task involves reasoning\non multi-modal data and precise target localization with temporal association.\nHowever, prior studies overlook the imbalanced data distribution between\nnewborn targets and existing targets due to the nature of the task. In\naddition, they only indirectly fuse multi-modal features, struggling to deliver\nclear guidance on newborn target detection. To solve the above issues, we\nconduct a collaborative matching strategy to alleviate the impact of the\nimbalance, boosting the ability to detect newborn targets while maintaining\ntracking performance. In the encoder, we integrate and enhance the cross-modal\nand multi-scale fusion, overcoming the bottlenecks in previous work, where\nlimited multi-modal information is shared and interacted between feature maps.\nIn the decoder, we also develop a referring-infused adaptation that provides\nexplicit referring guidance through the query tokens. The experiments showcase\nthe superior performance of our model (+3.42%) compared to prior works,\ndemonstrating the effectiveness of our designs.\n","authors":["Wenjun Huang","Yang Ni","Hanning Chen","Yirui He","Ian Bryant","Yezi Liu","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2412.12561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05652v1","updated":"2025-03-07T18:15:21Z","published":"2025-03-07T18:15:21Z","title":"BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation\n  for Everyday Household Activities","summary":"  Real-world household tasks present significant challenges for mobile\nmanipulation robots. An analysis of existing robotics benchmarks reveals that\nsuccessful task performance hinges on three key whole-body control\ncapabilities: bimanual coordination, stable and precise navigation, and\nextensive end-effector reachability. Achieving these capabilities requires\ncareful hardware design, but the resulting system complexity further\ncomplicates visuomotor policy learning. To address these challenges, we\nintroduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for\nwhole-body manipulation in diverse household tasks. Built on a bimanual,\nwheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body\nteleoperation interface for data collection and a novel algorithm for learning\nwhole-body visuomotor policies. We evaluate BRS on five challenging household\ntasks that not only emphasize the three core capabilities but also introduce\nadditional complexities, such as long-range navigation, interaction with\narticulated and deformable objects, and manipulation in confined spaces. We\nbelieve that BRS's integrated robotic embodiment, data collection interface,\nand learning framework mark a significant step toward enabling real-world\nwhole-body manipulation for everyday household tasks. BRS is open-sourced at\nhttps://behavior-robot-suite.github.io/\n","authors":["Yunfan Jiang","Ruohan Zhang","Josiah Wong","Chen Wang","Yanjie Ze","Hang Yin","Cem Gokmen","Shuran Song","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2503.05652v1.pdf","comment":"Project website: https://behavior-robot-suite.github.io/"},{"id":"http://arxiv.org/abs/2503.05646v1","updated":"2025-03-07T18:07:54Z","published":"2025-03-07T18:07:54Z","title":"dARt Vinci: Egocentric Data Collection for Surgical Robot Learning at\n  Scale","summary":"  Data scarcity has long been an issue in the robot learning community.\nParticularly, in safety-critical domains like surgical applications, obtaining\nhigh-quality data can be especially difficult. It poses challenges to\nresearchers seeking to exploit recent advancements in reinforcement learning\nand imitation learning, which have greatly improved generalizability and\nenabled robots to conduct tasks autonomously. We introduce dARt Vinci, a\nscalable data collection platform for robot learning in surgical settings. The\nsystem uses Augmented Reality (AR) hand tracking and a high-fidelity physics\nengine to capture subtle maneuvers in primitive surgical tasks: By eliminating\nthe need for a physical robot setup and providing flexibility in terms of time,\nspace, and hardware resources-such as multiview sensors and\nactuators-specialized simulation is a viable alternative. At the same time, AR\nallows the robot data collection to be more egocentric, supported by its body\ntracking and content overlaying capabilities. Our user study confirms the\nproposed system's efficiency and usability, where we use widely-used primitive\ntasks for training teleoperation with da Vinci surgical robots. Data throughput\nimproves across all tasks compared to real robot settings by 41% on average.\nThe total experiment time is reduced by an average of 10%. The temporal demand\nin the task load survey is improved. These gains are statistically significant.\nAdditionally, the collected data is over 400 times smaller in size, requiring\nfar less storage while achieving double the frequency.\n","authors":["Yihao Liu","Yu-Chun Ku","Jiaming Zhang","Hao Ding","Peter Kazanzides","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2503.05646v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.05641v1","updated":"2025-03-07T18:03:13Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v1.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic_moe.github.io/"},{"id":"http://arxiv.org/abs/2503.05639v1","updated":"2025-03-07T17:59:46Z","published":"2025-03-07T17:59:46Z","title":"VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play\n  Context Control","summary":"  Video inpainting, which aims to restore corrupted video content, has\nexperienced substantial progress. Despite these advances, existing methods,\nwhether propagating unmasked region pixels through optical flow and receptive\nfield priors, or extending image-inpainting models temporally, face challenges\nin generating fully masked objects or balancing the competing objectives of\nbackground context preservation and foreground generation in one model,\nrespectively. To address these limitations, we propose a novel dual-stream\nparadigm VideoPainter that incorporates an efficient context encoder\n(comprising only 6% of the backbone parameters) to process masked videos and\ninject backbone-aware background contextual cues to any pre-trained video DiT,\nproducing semantically consistent content in a plug-and-play manner. This\narchitectural separation significantly reduces the model's learning complexity\nwhile enabling nuanced integration of crucial background context. We also\nintroduce a novel target region ID resampling technique that enables any-length\nvideo inpainting, greatly enhancing our practical applicability. Additionally,\nwe establish a scalable dataset pipeline leveraging current vision\nunderstanding models, contributing VPData and VPBench to facilitate\nsegmentation-based inpainting training and assessment, the largest video\ninpainting dataset and benchmark to date with over 390K diverse clips. Using\ninpainting as a pipeline basis, we also explore downstream applications\nincluding video editing and video editing pair data generation, demonstrating\ncompetitive performance and significant practical potential. Extensive\nexperiments demonstrate VideoPainter's superior performance in both any-length\nvideo inpainting and editing, across eight key metrics, including video\nquality, mask region preservation, and textual coherence.\n","authors":["Yuxuan Bian","Zhaoyang Zhang","Xuan Ju","Mingdeng Cao","Liangbin Xie","Ying Shan","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05639v1.pdf","comment":"Project page available at\n  https://yxbian23.github.io/project/video-painter"},{"id":"http://arxiv.org/abs/2503.05638v1","updated":"2025-03-07T17:57:53Z","published":"2025-03-07T17:57:53Z","title":"TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos\n  via Diffusion Models","summary":"  We present TrajectoryCrafter, a novel approach to redirect camera\ntrajectories for monocular videos. By disentangling deterministic view\ntransformations from stochastic content generation, our method achieves precise\ncontrol over user-specified camera trajectories. We propose a novel dual-stream\nconditional video diffusion model that concurrently integrates point cloud\nrenders and source videos as conditions, ensuring accurate view transformations\nand coherent 4D content generation. Instead of leveraging scarce multi-view\nvideos, we curate a hybrid training dataset combining web-scale monocular\nvideos with static multi-view datasets, by our innovative double-reprojection\nstrategy, significantly fostering robust generalization across diverse scenes.\nExtensive evaluations on multi-view and large-scale monocular videos\ndemonstrate the superior performance of our method.\n","authors":["Mark YU","Wenbo Hu","Jinbo Xing","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2503.05638v1.pdf","comment":"Project webpage: https://trajectorycrafter.github.io/"},{"id":"http://arxiv.org/abs/2503.05629v1","updated":"2025-03-07T17:53:29Z","published":"2025-03-07T17:53:29Z","title":"Exploring FMCW Radars and Feature Maps for Activity Recognition: A\n  Benchmark Study","summary":"  Human Activity Recognition has gained significant attention due to its\ndiverse applications, including ambient assisted living and remote sensing.\nWearable sensor-based solutions often suffer from user discomfort and\nreliability issues, while video-based methods raise privacy concerns and\nperform poorly in low-light conditions or long ranges. This study introduces a\nFrequency-Modulated Continuous Wave radar-based framework for human activity\nrecognition, leveraging a 60 GHz radar and multi-dimensional feature maps.\nUnlike conventional approaches that process feature maps as images, this study\nfeeds multi-dimensional feature maps -- Range-Doppler, Range-Azimuth, and\nRange-Elevation -- as data vectors directly into the machine learning (SVM,\nMLP) and deep learning (CNN, LSTM, ConvLSTM) models, preserving the spatial and\ntemporal structures of the data. These features were extracted from a novel\ndataset with seven activity classes and validated using two different\nvalidation approaches. The ConvLSTM model outperformed conventional machine\nlearning and deep learning models, achieving an accuracy of 90.51% and an\nF1-score of 87.31% on cross-scene validation and an accuracy of 89.56% and an\nF1-score of 87.15% on leave-one-person-out cross-validation. The results\nhighlight the approach's potential for scalable, non-intrusive, and\nprivacy-preserving activity monitoring in real-world scenarios.\n","authors":["Ali Samimi Fard","Mohammadreza Mashhadigholamali","Samaneh Zolfaghari","Hajar Abedi","Mainak Chakraborty","Luigi Borzì","Masoud Daneshtalab","George Shaker"],"pdf_url":"https://arxiv.org/pdf/2503.05629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05628v1","updated":"2025-03-07T17:53:24Z","published":"2025-03-07T17:53:24Z","title":"Superintelligence Strategy: Expert Version","summary":"  Rapid advances in AI are beginning to reshape national security.\nDestabilizing AI developments could rupture the balance of power and raise the\nodds of great-power conflict, while widespread proliferation of capable AI\nhackers and virologists would lower barriers for rogue actors to cause\ncatastrophe. Superintelligence -- AI vastly better than humans at nearly all\ncognitive tasks -- is now anticipated by AI researchers. Just as nations once\ndeveloped nuclear strategies to secure their survival, we now need a coherent\nsuperintelligence strategy to navigate a new period of transformative change.\nWe introduce the concept of Mutual Assured AI Malfunction (MAIM): a deterrence\nregime resembling nuclear mutual assured destruction (MAD) where any state's\naggressive bid for unilateral AI dominance is met with preventive sabotage by\nrivals. Given the relative ease of sabotaging a destabilizing AI project --\nthrough interventions ranging from covert cyberattacks to potential kinetic\nstrikes on datacenters -- MAIM already describes the strategic picture AI\nsuperpowers find themselves in. Alongside this, states can increase their\ncompetitiveness by bolstering their economies and militaries through AI, and\nthey can engage in nonproliferation to rogue actors to keep weaponizable AI\ncapabilities out of their hands. Taken together, the three-part framework of\ndeterrence, nonproliferation, and competitiveness outlines a robust strategy to\nsuperintelligence in the years ahead.\n","authors":["Dan Hendrycks","Eric Schmidt","Alexandr Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05628v1.pdf","comment":"https://nationalsecurity.ai/"},{"id":"http://arxiv.org/abs/2503.05626v1","updated":"2025-03-07T17:52:12Z","published":"2025-03-07T17:52:12Z","title":"FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE\n  Framework","summary":"  Artificial intelligence has shown the potential to improve diagnostic\naccuracy through medical image analysis for pneumonia diagnosis. However,\ntraditional multimodal approaches often fail to address real-world challenges\nsuch as incomplete data and modality loss. In this study, a Flexible Multimodal\nTransformer (FMT) was proposed, which uses ResNet-50 and BERT for joint\nrepresentation learning, followed by a dynamic masked attention strategy that\nsimulates clinical modality loss to improve robustness; finally, a sequential\nmixture of experts (MOE) architecture was used to achieve multi-level decision\nrefinement. After evaluation on a small multimodal pneumonia dataset, FMT\nachieved state-of-the-art performance with 94% accuracy, 95% recall, and 93% F1\nscore, outperforming single-modal baselines (ResNet: 89%; BERT: 79%) and the\nmedical benchmark CheXMed (90%), providing a scalable solution for multimodal\ndiagnosis of pneumonia in resource-constrained medical settings.\n","authors":["Jingyu Xu","Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07542v2","updated":"2025-03-07T17:49:02Z","published":"2025-02-11T13:29:58Z","title":"Exoplanet Transit Candidate Identification in TESS Full-Frame Images via\n  a Transformer-Based Algorithm","summary":"  The Transiting Exoplanet Survey Satellite (TESS) is surveying a large\nfraction of the sky, generating a vast database of photometric time series data\nthat requires thorough analysis to identify exoplanetary transit signals.\nAutomated learning approaches have been successfully applied to identify\ntransit signals. However, most existing methods focus on the classification and\nvalidation of candidates, while few efforts have explored new techniques for\nthe search of candidates. To search for new exoplanet transit candidates, we\npropose an approach to identify exoplanet transit signals without the need for\nphase folding or assuming periodicity in the transit signals, such as those\nobserved in multi-transit light curves. To achieve this, we implement a new\nneural network inspired by Transformers to directly process Full Frame Image\n(FFI) light curves to detect exoplanet transits. Transformers, originally\ndeveloped for natural language processing, have recently demonstrated\nsignificant success in capturing long-range dependencies compared to previous\napproaches focused on sequential data. This ability allows us to employ\nmulti-head self-attention to identify exoplanet transit signals directly from\nthe complete light curves, combined with background and centroid time series,\nwithout requiring prior transit parameters. The network is trained to learn\ncharacteristics of the transit signal, like the dip shape, which helps\ndistinguish planetary transits from other variability sources. Our model\nsuccessfully identified 214 new planetary system candidates, including 122\nmulti-transit light curves, 88 single-transit and 4 multi-planet systems from\nTESS sectors 1-26 with a radius > 0.27 $R_{\\mathrm{Jupiter}}$, demonstrating\nits ability to detect transits regardless of their periodicity.\n","authors":["Helem Salinas","Rafael Brahm","Greg Olmschenk","Richard K. Barry","Karim Pichara","Stela Ishitani Silva","Vladimir Araujo"],"pdf_url":"https://arxiv.org/pdf/2502.07542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00242v4","updated":"2025-03-07T17:47:42Z","published":"2024-03-30T04:34:54Z","title":"DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured\n  LLM Inference","summary":"  Large language models (LLMs) are increasingly employed for complex tasks that\nprocess multiple generation calls in a tree structure with shared prefixes of\ntokens, including few-shot prompting, multi-step reasoning, speculative\ndecoding, etc. However, existing inference systems for tree-based applications\nare inefficient due to improper partitioning of queries and KV cache during\nattention calculation. This leads to two main issues: (1) a lack of memory\naccess (IO) reuse for KV cache of shared prefixes, and (2) poor load\nbalancing.As a result, there is redundant KV cache IO between GPU global memory\nand shared memory, along with low GPU utilization. To address these challenges,\nwe propose DeFT(Decoding with Flash Tree-Attention), a hardware-efficient\nattention algorithm with prefix-aware and load-balanced KV cache partitions.\nDeFT reduces the number of read/write operations of KV cache during attention\ncalculation through KV-Guided Grouping, a method that avoids repeatedly loading\nKV cache of shared prefixes in attention computation. Additionally, we propose\nFlattened Tree KV Splitting, a mechanism that ensures even distribution of the\nKV cache across partitions with little computation redundancy, enhancing GPU\nutilization during attention computations. By reducing 73-99% KV cache IO and\nnearly 100% IO for partial results during attention calculation, DeFT achieves\nup to 2.23/3.59x speedup in the end-to-end/attention latency across three\npractical tree-based workloads compared to state-of-the-art attention\nalgorithms. Our code is available at https://github.com/LINs-lab/DeFT.\n","authors":["Jinwei Yao","Kaiqi Chen","Kexun Zhang","Jiaxuan You","Binhang Yuan","Zeke Wang","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2404.00242v4.pdf","comment":"Update DeFT-v4, accepted by ICLR'25\n  (https://openreview.net/forum?id=2c7pfOqu9k). Our code is available at\n  https://github.com/LINs-lab/DeFT"},{"id":"http://arxiv.org/abs/2503.05620v1","updated":"2025-03-07T17:46:13Z","published":"2025-03-07T17:46:13Z","title":"Learning LLM Preference over Intra-Dialogue Pairs: A Framework for\n  Utterance-level Understandings","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities in\nhandling complex dialogue tasks without requiring use case-specific\nfine-tuning. However, analyzing live dialogues in real-time necessitates\nlow-latency processing systems, making it impractical to deploy models with\nbillions of parameters due to latency constraints. As a result, practitioners\noften prefer smaller models with millions of parameters, trained on\nhigh-quality, human-annotated datasets. Yet, curating such datasets is both\ntime-consuming and costly. Consequently, there is a growing need to combine the\nscalability of LLM-generated labels with the precision of human annotations,\nenabling fine-tuned smaller models to achieve both higher speed and accuracy\ncomparable to larger models. In this paper, we introduce a simple yet effective\nframework to address this challenge. Our approach is specifically designed for\nper-utterance classification problems, which encompass tasks such as intent\ndetection, dialogue state tracking, and more. To mitigate the impact of\nlabeling errors from LLMs -- the primary source of inaccuracies in student\nmodels -- we propose a noise-reduced preference learning loss. Experimental\nresults demonstrate that our method significantly improves accuracy across\nutterance-level dialogue tasks, including sentiment detection (over $2\\%$),\ndialogue act classification (over $1.5\\%$), etc.\n","authors":["Xuanqing Liu","Luyang Kong","Wei Niu","Afshin Khashei","Belinda Zeng","Steve Johnson","Jon Jay","Davor Golac","Matt Pope"],"pdf_url":"https://arxiv.org/pdf/2503.05620v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2408.11963v2","updated":"2025-03-07T17:38:59Z","published":"2024-08-21T19:31:39Z","title":"Real-Time Incremental Explanations for Object Detectors in Autonomous\n  Driving","summary":"  Object detectors are widely used in safety-critical real-time applications\nsuch as autonomous driving. Explainability is especially important for\nsafety-critical applications, and due to the variety of object detectors and\ntheir often proprietary nature, black-box explainability tools are needed.\nHowever, existing black-box explainability tools for AI models rely on multiple\nmodel calls, rendering them impractical for real-time use.\n  In this paper, we introduce IncX, an algorithm and a tool for real-time\nblack-box explainability for object detectors. The algorithm is based on linear\ntransformations of saliency maps, producing sufficient explanations. We\nevaluate our implementation on four widely used video datasets of autonomous\ndriving and demonstrate that IncX's explanations are comparable in quality to\nthe state-of-the-art and are computed two orders of magnitude faster than the\nstate-of-the-art, making them usable in real time.\n","authors":["Santiago Calderón-Peña","Hana Chockler","David A. Kelly"],"pdf_url":"https://arxiv.org/pdf/2408.11963v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05613v1","updated":"2025-03-07T17:38:00Z","published":"2025-03-07T17:38:00Z","title":"A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of\n  Large Language Models","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.\n","authors":["Dong Shu","Xuansheng Wu","Haiyan Zhao","Daking Rai","Ziyu Yao","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2503.05613v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05604v1","updated":"2025-03-07T17:29:04Z","published":"2025-03-07T17:29:04Z","title":"CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment\n  and Classification of Ultrasound Images Using Deep Transfer Learning","summary":"  Cardiac ultrasound (US) scanning is a commonly used techniques in cardiology\nto diagnose the health of the heart and its proper functioning. Therefore, it\nis necessary to consider ways to automate these tasks and assist medical\nprofessionals in classifying and assessing cardiac US images. Machine learning\n(ML) techniques are regarded as a prominent solution due to their success in\nnumerous applications aimed at enhancing the medical field, including\naddressing the shortage of echography technicians. However, the limited\navailability of medical data presents a significant barrier to applying ML in\ncardiology, particularly regarding US images of the heart. This paper addresses\nthis challenge by introducing the first open graded dataset for Cardiac\nAssessment and ClassificaTion of UltraSound (CACTUS), which is available\nonline. This dataset contains images obtained from scanning a CAE Blue Phantom\nand representing various heart views and different quality levels, exceeding\nthe conventional cardiac views typically found in the literature. Additionally,\nthe paper introduces a Deep Learning (DL) framework consisting of two main\ncomponents. The first component classifies cardiac US images based on the heart\nview using a Convolutional Neural Network (CNN). The second component uses\nTransfer Learning (TL) to fine-tune the knowledge from the first component and\ncreate a model for grading and assessing cardiac images. The framework\ndemonstrates high performance in both classification and grading, achieving up\nto 99.43% accuracy and as low as 0.3067 error, respectively. To showcase its\nrobustness, the framework is further fine-tuned using new images representing\nadditional cardiac views and compared to several other state-of-the-art\narchitectures. The framework's outcomes and performance in handling real-time\nscans were also assessed using a questionnaire answered by cardiac experts.\n","authors":["Hanae Elmekki","Ahmed Alagha","Hani Sami","Amanda Spilkin","Antonela Mariel Zanuttini","Ehsan Zakeri","Jamal Bentahar","Lyes Kadem","Wen-Fang Xie","Philippe Pibarot","Rabeb Mizouni","Hadi Otrok","Shakti Singh","Azzam Mourad"],"pdf_url":"https://arxiv.org/pdf/2503.05604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16976v3","updated":"2025-03-07T17:24:35Z","published":"2024-06-23T06:22:49Z","title":"Efficient Evolutionary Search Over Chemical Space with Large Language\n  Models","summary":"  Molecular discovery, when formulated as an optimization problem, presents\nsignificant computational challenges because optimization objectives can be\nnon-differentiable. Evolutionary Algorithms (EAs), often used to optimize\nblack-box objectives in molecular discovery, traverse chemical space by\nperforming random mutations and crossovers, leading to a large number of\nexpensive objective evaluations. In this work, we ameliorate this shortcoming\nby incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely,\nwe redesign crossover and mutation operations in EAs using LLMs trained on\nlarge corpora of chemical information. We perform extensive empirical studies\non both commercial and open-source models on multiple tasks involving property\noptimization, molecular rediscovery, and structure-based drug design,\ndemonstrating that the joint usage of LLMs with EAs yields superior performance\nover all baseline models across single- and multi-objective settings. We\ndemonstrate that our algorithm improves both the quality of the final solution\nand convergence speed, thereby reducing the number of required objective\nevaluations. Our code is available at http://github.com/zoom-wang112358/MOLLEO\n","authors":["Haorui Wang","Marta Skreta","Cher-Tian Ser","Wenhao Gao","Lingkai Kong","Felix Strieth-Kalthoff","Chenru Duan","Yuchen Zhuang","Yue Yu","Yanqiao Zhu","Yuanqi Du","Alán Aspuru-Guzik","Kirill Neklyudov","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16976v3.pdf","comment":"Published in ICLR 2025"},{"id":"http://arxiv.org/abs/2303.17251v3","updated":"2025-03-07T17:23:53Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05592v1","updated":"2025-03-07T17:14:44Z","published":"2025-03-07T17:14:44Z","title":"R1-Searcher: Incentivizing the Search Capability in LLMs via\n  Reinforcement Learning","summary":"  Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.\n","authors":["Huatong Song","Jinhao Jiang","Yingqian Min","Jie Chen","Zhipeng Chen","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.05592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05587v1","updated":"2025-03-07T17:11:34Z","published":"2025-03-07T17:11:34Z","title":"Quantifying the Robustness of Retrieval-Augmented Language Models\n  Against Spurious Features in Grounding Data","summary":"  Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.\n","authors":["Shiping Yang","Jie Wu","Wenbiao Ding","Ning Wu","Shining Liang","Ming Gong","Hengyuan Zhang","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08936v2","updated":"2025-03-07T17:09:02Z","published":"2024-09-13T15:55:15Z","title":"SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical\n  Records","summary":"  We present the SynSUM benchmark, a synthetic dataset linking unstructured\nclinical notes to structured background variables. The dataset consists of\n10,000 artificial patient records containing tabular variables (like symptoms,\ndiagnoses and underlying conditions) and related notes describing the fictional\npatient encounter in the domain of respiratory diseases. The tabular portion of\nthe data is generated through a Bayesian network, where both the causal\nstructure between the variables and the conditional probabilities are proposed\nby an expert based on domain knowledge. We then prompt a large language model\n(GPT-4o) to generate a clinical note related to this patient encounter,\ndescribing the patient symptoms and additional context. We conduct both an\nexpert evaluation study to assess the quality of the generated notes, as well\nas running some simple predictor models on both the tabular and text portions\nof the dataset, forming a baseline for further research. The SynSUM dataset is\nprimarily designed to facilitate research on clinical information extraction in\nthe presence of tabular background variables, which can be linked through\ndomain knowledge to concepts of interest to be extracted from the text - the\nsymptoms, in the case of SynSUM. Secondary uses include research on the\nautomation of clinical reasoning over both tabular data and text, causal effect\nestimation in the presence of tabular and/or textual confounders, and\nmulti-modal synthetic data generation.\n","authors":["Paloma Rabaey","Henri Arno","Stefan Heytens","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2409.08936v2.pdf","comment":"The dataset can be downloaded from https://github.com/prabaey/synsum.\n  Presented at the GenAI4Health workshop at AAAI 2025"},{"id":"http://arxiv.org/abs/2410.02355v3","updated":"2025-03-07T17:06:04Z","published":"2024-10-03T10:06:27Z","title":"AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models","summary":"  Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.4%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.\n","authors":["Junfeng Fang","Houcheng Jiang","Kun Wang","Yunshan Ma","Shi Jie","Xiang Wang","Xiangnan He","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.02355v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05573v1","updated":"2025-03-07T16:56:00Z","published":"2025-03-07T16:56:00Z","title":"InDRiVE: Intrinsic Disagreement based Reinforcement for Vehicle\n  Exploration through Curiosity Driven Generalized World Model","summary":"  Model-based Reinforcement Learning (MBRL) has emerged as a promising paradigm\nfor autonomous driving, where data efficiency and robustness are critical. Yet,\nexisting solutions often rely on carefully crafted, task specific extrinsic\nrewards, limiting generalization to new tasks or environments. In this paper,\nwe propose InDRiVE (Intrinsic Disagreement based Reinforcement for Vehicle\nExploration), a method that leverages purely intrinsic, disagreement based\nrewards within a Dreamer based MBRL framework. By training an ensemble of world\nmodels, the agent actively explores high uncertainty regions of environments\nwithout any task specific feedback. This approach yields a task agnostic latent\nrepresentation, allowing for rapid zero shot or few shot fine tuning on\ndownstream driving tasks such as lane following and collision avoidance.\nExperimental results in both seen and unseen environments demonstrate that\nInDRiVE achieves higher success rates and fewer infractions compared to\nDreamerV2 and DreamerV3 baselines despite using significantly fewer training\nsteps. Our findings highlight the effectiveness of purely intrinsic exploration\nfor learning robust vehicle control behaviors, paving the way for more scalable\nand adaptable autonomous driving systems.\n","authors":["Feeza Khan Khanzada","Jaerock Kwon"],"pdf_url":"https://arxiv.org/pdf/2503.05573v1.pdf","comment":"This work has been submitted to IROS 2025 and is currently under\n  review"},{"id":"http://arxiv.org/abs/2503.05571v1","updated":"2025-03-07T16:53:36Z","published":"2025-03-07T16:53:36Z","title":"Compliance of AI Systems","summary":"  The increasing integration of artificial intelligence (AI) systems in various\nfields requires solid concepts to ensure compliance with upcoming legislation.\nThis paper systematically examines the compliance of AI systems with relevant\nlegislation, focusing on the EU's AI Act and the compliance of data sets. The\nanalysis highlighted many challenges associated with edge devices, which are\nincreasingly being used to deploy AI applications closer and closer to the data\nsources. Such devices often face unique issues due to their decentralized\nnature and limited computing resources for implementing sophisticated\ncompliance mechanisms. By analyzing AI implementations, the paper identifies\nchallenges and proposes the first best practices for legal compliance when\ndeveloping, deploying, and running AI. The importance of data set compliance is\nhighlighted as a cornerstone for ensuring the trustworthiness, transparency,\nand explainability of AI systems, which must be aligned with ethical standards\nset forth in regulatory frameworks such as the AI Act. The insights gained\nshould contribute to the ongoing discourse on the responsible development and\ndeployment of embedded AI systems.\n","authors":["Julius Schöning","Niklas Kruse"],"pdf_url":"https://arxiv.org/pdf/2503.05571v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2501.02068v2","updated":"2025-03-07T16:48:14Z","published":"2025-01-03T19:28:53Z","title":"The interplay between domain specialization and model size","summary":"  Scaling laws for language models have often focused on finding the optimal\nmodel size and token count for training from scratch. However, achieving this\noptimal balance requires significant compute resources due to the extensive\ndata demands when training models from randomly-initialized weights. Continued\npretraining offers a cost-effective alternative, leveraging the compute\ninvestment from pretrained models to incorporate new knowledge without\nrequiring extensive new data. Recent findings suggest that data quality\ninfluences constants in scaling laws, thereby altering the optimal\nparameter-token allocation ratio. Building on this insight, we investigate the\ninterplay between domain specialization and model size during continued\npretraining under compute-constrained scenarios. Our goal is to identify an\noptimal training regime for this scenario and detect patterns in this interplay\nthat can be generalized across different model sizes and domains. To compare\ngeneral and specialized training, we filtered a web-based dataset to extract\ndata from three domains: legal, medical, and accounting. We pretrained models\nwith 1.5B, 3B, 7B, and 14B parameters on both the unfiltered and filtered\ndatasets, then evaluated their performance on domain-specific exams. Results\nshow that as model size increases, specialized models outperform general models\nwhile requiring less training compute. Additionally, their growing compute\nefficiency leads to reduced forgetting of previously learned knowledge.\n","authors":["Roseval Malaquias Junior","Ramon Pires","Thales Sales Almeida","Kenzo Sakiyama","Roseli A. F. Romero","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2501.02068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05546v1","updated":"2025-03-07T16:19:19Z","published":"2025-03-07T16:19:19Z","title":"Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement\n  Learning","summary":"  As image-based deep reinforcement learning tackles more challenging tasks,\nincreasing model size has become an important factor in improving performance.\nRecent studies achieved this by focusing on the parameter efficiency of scaled\nnetworks, typically using Impala-CNN, a 15-layer ResNet-inspired network, as\nthe image encoder. However, while Impala-CNN evidently outperforms older CNN\narchitectures, potential advancements in network design for deep reinforcement\nlearning-specific image encoders remain largely unexplored. We find that\nreplacing the flattening of output feature maps in Impala-CNN with global\naverage pooling leads to a notable performance improvement. This approach\noutperforms larger and more complex models in the Procgen Benchmark,\nparticularly in terms of generalization. We call our proposed encoder model\nImpoola-CNN. A decrease in the network's translation sensitivity may be central\nto this improvement, as we observe the most significant gains in games without\nagent-centered observations. Our results demonstrate that network scaling is\nnot just about increasing model size - efficient network design is also an\nessential factor.\n","authors":["Raphael Trumpp","Ansgar Schäfftlein","Mirco Theile","Marco Caccamo"],"pdf_url":"https://arxiv.org/pdf/2503.05546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04836v3","updated":"2025-03-07T15:55:55Z","published":"2024-02-07T13:32:53Z","title":"On the Completeness of Invariant Geometric Deep Learning Models","summary":"  Invariant models, one important class of geometric deep learning models, are\ncapable of generating meaningful geometric representations by leveraging\ninformative geometric features in point clouds. These models are characterized\nby their simplicity, good experimental results and computational efficiency.\nHowever, their theoretical expressive power still remains unclear, restricting\na deeper understanding of the potential of such models. In this work, we\nconcentrate on characterizing the theoretical expressiveness of a wide range of\ninvariant models under fully-connected conditions. We first rigorously\ncharacterize the expressiveness of the most classic invariant model,\nmessage-passing neural networks incorporating distance (DisGNN), restricting\nits unidentifiable cases to be only highly symmetric point clouds. We then\nprove that GeoNGNN, the geometric counterpart of one of the simplest subgraph\ngraph neural networks, can effectively break these corner cases' symmetry and\nthus achieve E(3)-completeness. By leveraging GeoNGNN as a theoretical tool, we\nfurther prove that: 1) most subgraph GNNs developed in traditional graph\nlearning can be seamlessly extended to geometric scenarios with\nE(3)-completeness; 2) DimeNet, GemNet and SphereNet, three well-established\ninvariant models, are also all capable of achieving E(3)-completeness. Our\ntheoretical results fill the gap in the expressive power of invariant models,\ncontributing to a rigorous and comprehensive understanding of their\ncapabilities.\n","authors":["Zian Li","Xiyuan Wang","Shijia Kang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.04836v3.pdf","comment":"The Thirteenth International Conference on Learning Representations"},{"id":"http://arxiv.org/abs/2503.05522v1","updated":"2025-03-07T15:45:43Z","published":"2025-03-07T15:45:43Z","title":"Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept\n  Representations","summary":"  Concept Activation Vectors (CAVs) are widely used to model\nhuman-understandable concepts as directions within the latent space of neural\nnetworks. They are trained by identifying directions from the activations of\nconcept samples to those of non-concept samples. However, this method often\nproduces similar, non-orthogonal directions for correlated concepts, such as\n\"beard\" and \"necktie\" within the CelebA dataset, which frequently co-occur in\nimages of men. This entanglement complicates the interpretation of concepts in\nisolation and can lead to undesired effects in CAV applications, such as\nactivation steering. To address this issue, we introduce a post-hoc concept\ndisentanglement method that employs a non-orthogonality loss, facilitating the\nidentification of orthogonal concept directions while preserving directional\ncorrectness. We evaluate our approach with real-world and controlled correlated\nconcepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18\narchitectures. We further demonstrate the superiority of orthogonalized concept\nrepresentations in activation steering tasks, allowing (1) the insertion of\nisolated concepts into input images through generative models and (2) the\nremoval of concepts for effective shortcut suppression with reduced impact on\ncorrelated concepts in comparison to baseline CAVs.\n","authors":["Eren Erogullari","Sebastian Lapuschkin","Wojciech Samek","Frederik Pahde"],"pdf_url":"https://arxiv.org/pdf/2503.05522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05516v1","updated":"2025-03-07T15:35:37Z","published":"2025-03-07T15:35:37Z","title":"Cognitive Bias Detection Using Advanced Prompt Engineering","summary":"  Cognitive biases, systematic deviations from rationality in judgment, pose\nsignificant challenges in generating objective content. This paper introduces a\nnovel approach for real-time cognitive bias detection in user-generated text\nusing large language models (LLMs) and advanced prompt engineering techniques.\nThe proposed system analyzes textual data to identify common cognitive biases\nsuch as confirmation bias, circular reasoning, and hidden assumption. By\ndesigning tailored prompts, the system effectively leverages LLMs' capabilities\nto both recognize and mitigate these biases, improving the quality of\nhuman-generated content (e.g., news, media, reports). Experimental results\ndemonstrate the high accuracy of our approach in identifying cognitive biases,\noffering a valuable tool for enhancing content objectivity and reducing the\nrisks of biased decision-making.\n","authors":["Frederic Lemieux","Aisha Behr","Clara Kellermann-Bryant","Zaki Mohammed"],"pdf_url":"https://arxiv.org/pdf/2503.05516v1.pdf","comment":"17 pages. 6 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2503.05514v1","updated":"2025-03-07T15:30:55Z","published":"2025-03-07T15:30:55Z","title":"Noise-Robust Radio Frequency Fingerprint Identification Using Denoise\n  Diffusion Model","summary":"  Securing Internet of Things (IoT) devices presents increasing challenges due\nto their limited computational and energy resources. Radio Frequency\nFingerprint Identification (RFFI) emerges as a promising authentication\ntechnique to identify wireless devices through hardware impairments. RFFI\nperformance under low signal-to-noise ratio (SNR) scenarios is significantly\ndegraded because the minute hardware features can be easily swamped in noise.\nIn this paper, we leveraged the diffusion model to effectively restore the RFF\nunder low SNR scenarios. Specifically, we trained a powerful noise predictor\nand tailored a noise removal algorithm to effectively reduce the noise level in\nthe received signal and restore the device fingerprints. We used Wi-Fi as a\ncase study and created a testbed involving 6 commercial off-the-shelf Wi-Fi\ndongles and a USRP N210 software-defined radio (SDR) platform. We conducted\nexperimental evaluations on various SNR scenarios. The experimental results\nshow that the proposed algorithm can improve the classification accuracy by up\nto 34.9%.\n","authors":["Guolin Yin","Junqing Zhang","Yuan Ding","Simon Cotton"],"pdf_url":"https://arxiv.org/pdf/2503.05514v1.pdf","comment":"6 pages, 8 figures, WCNC 2025"},{"id":"http://arxiv.org/abs/2503.05507v1","updated":"2025-03-07T15:23:13Z","published":"2025-03-07T15:23:13Z","title":"Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?","summary":"  Grammar serves as a cornerstone in programming languages and software\nengineering, providing frameworks to define the syntactic space and program\nstructure. Existing research demonstrates the effectiveness of grammar-based\ncode representations in small-scale models, showing their ability to reduce\nsyntax errors and enhance performance. However, as language models scale to the\nbillion level or beyond, syntax-level errors become rare, making it unclear\nwhether grammar information still provides performance benefits. To explore\nthis, we develop a series of billion-scale GrammarCoder models, incorporating\ngrammar rules in the code generation process. Experiments on HumanEval (+) and\nMBPP (+) demonstrate a notable improvement in code generation accuracy. Further\nanalysis shows that grammar-based representations enhance LLMs' ability to\ndiscern subtle code differences, reducing semantic errors caused by minor\nvariations. These findings suggest that grammar-based code representations\nremain valuable even in billion-scale models, not only by maintaining syntax\ncorrectness but also by improving semantic differentiation.\n","authors":["Qingyuan Liang","Zhao Zhang","Zeyu Sun","Zheng Lin","Qi Luo","Yueyi Xiao","Yizhou Chen","Yuqun Zhang","Haotian Zhang","Lu Zhang","Bin Chen","Yingfei Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.05507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02126v2","updated":"2025-03-07T15:21:42Z","published":"2024-11-04T14:37:07Z","title":"Unsupervised detection of semantic correlations in big data","summary":"  In real-world data, information is stored in extremely large feature vectors.\nThese variables are typically correlated due to complex interactions involving\nmany features simultaneously. Such correlations qualitatively correspond to\nsemantic roles and are naturally recognized by both the human brain and\nartificial neural networks. This recognition enables, for instance, the\nprediction of missing parts of an image or text based on their context. We\npresent a method to detect these correlations in high-dimensional data\nrepresented as binary numbers. We estimate the binary intrinsic dimension of a\ndataset, which quantifies the minimum number of independent coordinates needed\nto describe the data, and is therefore a proxy of semantic complexity. The\nproposed algorithm is largely insensitive to the so-called curse of\ndimensionality, and can therefore be used in big data analysis. We test this\napproach identifying phase transitions in model magnetic systems and we then\napply it to the detection of semantic correlations of images and text inside\ndeep neural networks.\n","authors":["Santiago Acevedo","Alex Rodriguez","Alessandro Laio"],"pdf_url":"https://arxiv.org/pdf/2411.02126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03463v3","updated":"2025-03-07T15:17:02Z","published":"2024-09-05T12:19:07Z","title":"Massive Activations in Graph Neural Networks: Decoding Attention for\n  Domain-Dependent Interpretability","summary":"  Graph Neural Networks (GNNs) have become increasingly popular for effectively\nmodeling graph-structured data, and attention mechanisms have been pivotal in\nenabling these models to capture complex patterns. In our study, we reveal a\ncritical yet underexplored consequence of integrating attention into\nedge-featured GNNs: the emergence of Massive Activations (MAs) within attention\nlayers. By developing a novel method for detecting MAs on edge features, we\nshow that these extreme activations are not only activation anomalies but\nencode domain-relevant signals. Our post-hoc interpretability analysis\ndemonstrates that, in molecular graphs, MAs aggregate predominantly on common\nbond types (e.g., single and double bonds) while sparing more informative ones\n(e.g., triple bonds). Furthermore, our ablation studies confirm that MAs can\nserve as natural attribution indicators, reallocating to less informative\nedges. Our study assesses various edge-featured attention-based GNN models\nusing benchmark datasets, including ZINC, TOX21, and PROTEINS. Key\ncontributions include (1) establishing the direct link between attention\nmechanisms and MAs generation in edge-featured GNNs, (2) developing a robust\ndefinition and detection method for MAs enabling reliable post-hoc\ninterpretability. Overall, our study reveals the complex interplay between\nattention mechanisms, edge-featured GNNs model, and MAs emergence, providing\ncrucial insights for relating GNNs internals to domain knowledge.\n","authors":["Lorenzo Bini","Marco Sorbi","Stephane Marchand-Maillet"],"pdf_url":"https://arxiv.org/pdf/2409.03463v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05500v1","updated":"2025-03-07T15:13:58Z","published":"2025-03-07T15:13:58Z","title":"EuroBERT: Scaling Multilingual Encoders for European Languages","summary":"  General-purpose multilingual vector representations, used in retrieval,\nregression and classification, are traditionally obtained from bidirectional\nencoder models. Despite their wide applicability, encoders have been recently\novershadowed by advances in generative decoder-only models. However, many\ninnovations driving this progress are not inherently tied to decoders. In this\npaper, we revisit the development of multilingual encoders through the lens of\nthese advances, and introduce EuroBERT, a family of multilingual encoders\ncovering European and widely spoken global languages. Our models outperform\nexisting alternatives across a diverse range of tasks, spanning multilingual\ncapabilities, mathematics, and coding, and natively supporting sequences of up\nto 8,192 tokens. We also examine the design decisions behind EuroBERT, offering\ninsights into our dataset composition and training pipeline. We publicly\nrelease the EuroBERT models, including intermediate training checkpoints,\ntogether with our training framework.\n","authors":["Nicolas Boizard","Hippolyte Gisserot-Boukhlef","Duarte M. Alves","André Martins","Ayoub Hammal","Caio Corro","Céline Hudelot","Emmanuel Malherbe","Etienne Malaboeuf","Fanny Jourdan","Gabriel Hautreux","João Alves","Kevin El-Haddad","Manuel Faysse","Maxime Peyrard","Nuno M. Guerreiro","Patrick Fernandes","Ricardo Rei","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2503.05500v1.pdf","comment":"26 pages, 6 figures, 11 tables"},{"id":"http://arxiv.org/abs/2503.04704v2","updated":"2025-03-07T15:12:57Z","published":"2025-03-06T18:54:32Z","title":"Universality of Layer-Level Entropy-Weighted Quantization Beyond Model\n  Architecture and Size","summary":"  We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.\n","authors":["Alireza Behtash","Marijan Fofonjka","Ethan Baird","Tyler Mauer","Hossein Moghimifam","David Stout","Joel Dennison"],"pdf_url":"https://arxiv.org/pdf/2503.04704v2.pdf","comment":"29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements"},{"id":"http://arxiv.org/abs/2404.10386v2","updated":"2025-03-07T15:11:30Z","published":"2024-04-16T08:37:36Z","title":"I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey","summary":"  Growing interest in Artificial Intelligence (AI) has resulted in a surge in\ndemand for faster methods of Machine Learning (ML) model training and\ninference. This demand for speed has prompted the use of high performance\ncomputing (HPC) systems that excel in managing distributed workloads. Because\ndata is the main fuel for AI applications, the performance of the storage and\nI/O subsystem of HPC systems is critical. In the past, HPC applications\naccessed large portions of data written by simulations or experiments or\ningested data for visualizations or analysis tasks. ML workloads perform small\nreads spread across a large number of random files. This shift of I/O access\npatterns poses several challenges to modern parallel storage systems. In this\npaper, we survey I/O in ML applications on HPC systems, and target literature\nwithin a 6-year time window from 2019 to 2024. We define the scope of the\nsurvey, provide an overview of the common phases of ML, review available\nprofilers and benchmarks, examine the I/O patterns encountered during offline\ndata preparation, training, and inference, and explore I/O optimizations\nutilized in modern ML frameworks and proposed in recent literature. Lastly, we\nseek to expose research gaps that could spawn further R&D.\n","authors":["Noah Lewis","Jean Luca Bez","Surendra Byna"],"pdf_url":"https://arxiv.org/pdf/2404.10386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05492v1","updated":"2025-03-07T15:01:55Z","published":"2025-03-07T15:01:55Z","title":"FastMap: Fast Queries Initialization Based Vectorized HD Map\n  Reconstruction Framework","summary":"  Reconstruction of high-definition maps is a crucial task in perceiving the\nautonomous driving environment, as its accuracy directly impacts the\nreliability of prediction and planning capabilities in downstream modules.\nCurrent vectorized map reconstruction methods based on the DETR framework\nencounter limitations due to the redundancy in the decoder structure,\nnecessitating the stacking of six decoder layers to maintain performance, which\nsignificantly hampers computational efficiency. To tackle this issue, we\nintroduce FastMap, an innovative framework designed to reduce decoder\nredundancy in existing approaches. FastMap optimizes the decoder architecture\nby employing a single-layer, two-stage transformer that achieves multilevel\nrepresentation capabilities. Our framework eliminates the conventional practice\nof randomly initializing queries and instead incorporates a heatmap-guided\nquery generation module during the decoding phase, which effectively maps image\nfeatures into structured query vectors using learnable positional encoding.\nAdditionally, we propose a geometry-constrained point-to-line loss mechanism\nfor FastMap, which adeptly addresses the challenge of distinguishing highly\nhomogeneous features that often arise in traditional point-to-point loss\ncomputations. Extensive experiments demonstrate that FastMap achieves\nstate-of-the-art performance in both nuScenes and Argoverse2 datasets, with its\ndecoder operating 3.2 faster than the baseline. Code and more demos are\navailable at https://github.com/hht1996ok/FastMap.\n","authors":["Haotian Hu","Jingwei Xu","Fanyi Wang","Toyota Li","Yaonong Wang","Laifeng Hu","Zhiwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19723v3","updated":"2025-03-07T14:56:45Z","published":"2025-02-27T03:25:34Z","title":"CNsum:Automatic Summarization for Chinese News Text","summary":"  Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.\n","authors":["Yu Zhao","Songping Huang","Dongsheng Zhou","Zhaoyun Ding","Fei Wang","Aixin Nian"],"pdf_url":"https://arxiv.org/pdf/2502.19723v3.pdf","comment":"This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version"},{"id":"http://arxiv.org/abs/2403.02694v4","updated":"2025-03-07T14:49:07Z","published":"2024-03-05T06:23:50Z","title":"MeanCache: User-Centric Semantic Caching for LLM Web Services","summary":"  Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.\n","authors":["Waris Gill","Mohamed Elidrisi","Pallavi Kalapatapu","Ammar Ahmed","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2403.02694v4.pdf","comment":"Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)"},{"id":"http://arxiv.org/abs/2503.05474v1","updated":"2025-03-07T14:47:03Z","published":"2025-03-07T14:47:03Z","title":"Personalized Federated Learning via Learning Dynamic Graphs","summary":"  Personalized Federated Learning (PFL) aims to train a personalized model for\neach client that is tailored to its local data distribution, learning fails to\nperform well on individual clients due to variations in their local data\ndistributions. Most existing PFL methods focus on personalizing the aggregated\nglobal model for each client, neglecting the fundamental aspect of federated\nlearning: the regulation of how client models are aggregated. Additionally,\nalmost all of them overlook the graph structure formed by clients in federated\nlearning. In this paper, we propose a novel method, Personalized Federated\nLearning with Graph Attention Network (pFedGAT), which captures the latent\ngraph structure between clients and dynamically determines the importance of\nother clients for each client, enabling fine-grained control over the\naggregation process. We evaluate pFedGAT across multiple data distribution\nscenarios, comparing it with twelve state of the art methods on three datasets:\nFashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs\nwell.\n","authors":["Ziran Zhou","Guanyu Gao","Xiaohu Wu","Yan Lyu"],"pdf_url":"https://arxiv.org/pdf/2503.05474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05473v1","updated":"2025-03-07T14:45:03Z","published":"2025-03-07T14:45:03Z","title":"The Society of HiveMind: Multi-Agent Optimization of Foundation Model\n  Swarms to Unlock the Potential of Collective Intelligence","summary":"  Multi-agent systems address issues of accessibility and scalability of\nartificial intelligence (AI) foundation models, which are often represented by\nlarge language models. We develop a framework - the \"Society of HiveMind\"\n(SOHM) - that orchestrates the interaction between multiple AI foundation\nmodels, imitating the observed behavior of animal swarms in nature by following\nmodern evolutionary theories. On the one hand, we find that the SOHM provides a\nnegligible benefit on tasks that mainly require real-world knowledge. On the\nother hand, we remark a significant improvement on tasks that require intensive\nlogical reasoning, indicating that multi-agent systems are capable of\nincreasing the reasoning capabilities of the collective compared to the\nindividual agents. Our findings demonstrate the potential of combining a\nmultitude of diverse AI foundation models to form an artificial swarm\nintelligence capable of self-improvement through interactions with a given\nenvironment.\n","authors":["Noah Mamie","Susie Xi Rao"],"pdf_url":"https://arxiv.org/pdf/2503.05473v1.pdf","comment":"11 pages (excl. appendix)"},{"id":"http://arxiv.org/abs/2503.05455v1","updated":"2025-03-07T14:27:48Z","published":"2025-03-07T14:27:48Z","title":"Controllable Complementarity: Subjective Preferences in Human-AI\n  Collaboration","summary":"  Research on human-AI collaboration often prioritizes objective performance.\nHowever, understanding human subjective preferences is essential to improving\nhuman-AI complementarity and human experiences. We investigate human\npreferences for controllability in a shared workspace task with AI partners\nusing Behavior Shaping (BS), a reinforcement learning algorithm that allows\nhumans explicit control over AI behavior.\n  In one experiment, we validate the robustness of BS in producing effective AI\npolicies relative to self-play policies, when controls are hidden. In another\nexperiment, we enable human control, showing that participants perceive AI\npartners as more effective and enjoyable when they can directly dictate AI\nbehavior. Our findings highlight the need to design AI that prioritizes both\ntask performance and subjective human preferences. By aligning AI behavior with\nhuman preferences, we demonstrate how human-AI complementarity can extend\nbeyond objective outcomes to include subjective preferences.\n","authors":["Chase McDonald","Cleotilde Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2503.05455v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05453v1","updated":"2025-03-07T14:23:40Z","published":"2025-03-07T14:23:40Z","title":"Soft Policy Optimization: Online Off-Policy RL for Sequence Models","summary":"  RL-based post-training of language models is almost exclusively done using\non-policy methods such as PPO. These methods cannot learn from arbitrary\nsequences such as those produced earlier in training, in earlier runs, by human\nexperts or other policies, or by decoding and exploration methods. This results\nin severe sample inefficiency and exploration difficulties, as well as a\npotential loss of diversity in the policy responses. Moreover, asynchronous PPO\nimplementations require frequent and costly model transfers, and typically use\nvalue models which require a large amount of memory. In this paper we introduce\nSoft Policy Optimization (SPO), a simple, scalable and principled Soft RL\nmethod for sequence model policies that can learn from arbitrary online and\noffline trajectories and does not require a separate value model. In\nexperiments on code contests, we shows that SPO outperforms PPO on pass@10, is\nsignificantly faster and more memory efficient, is able to benefit from\noff-policy data, enjoys improved stability, and learns more diverse (i.e. soft)\npolicies.\n","authors":["Taco Cohen","David W. Zhang","Kunhao Zheng","Yunhao Tang","Remi Munos","Gabriel Synnaeve"],"pdf_url":"https://arxiv.org/pdf/2503.05453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06287v3","updated":"2025-03-07T14:20:58Z","published":"2024-02-09T09:54:01Z","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","summary":"  Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.\n","authors":["Clara Punzi","Roberto Pellungrini","Mattia Setzu","Fosca Giannotti","Dino Pedreschi"],"pdf_url":"https://arxiv.org/pdf/2402.06287v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05449v1","updated":"2025-03-07T14:19:17Z","published":"2025-03-07T14:19:17Z","title":"LLM-based Iterative Approach to Metamodeling in Automotive","summary":"  In this paper, we introduce an automated approach to domain-specific\nmetamodel construction relying on Large Language Model (LLM). The main focus is\nadoption in automotive domain. As outcome, a prototype was implemented as web\nservice using Python programming language, while OpenAI's GPT-4o was used as\nthe underlying LLM. Based on the initial experiments, this approach\nsuccessfully constructs Ecore metamodel based on set of automotive requirements\nand visualizes it making use of PlantUML notation, so human experts can provide\nfeedback in order to refine the result. Finally, locally deployable solution is\nalso considered, including the limitations and additional steps required.\n","authors":["Nenad Petrovic","Fengjunjie Pan","Vahid Zolfaghari","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2503.05449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05447v1","updated":"2025-03-07T14:17:45Z","published":"2025-03-07T14:17:45Z","title":"Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts","summary":"  Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.\n","authors":["Weigao Sun","Disen Lan","Tong Zhu","Xiaoye Qu","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05447v1.pdf","comment":"Technical report, 17 pages"},{"id":"http://arxiv.org/abs/2503.05439v1","updated":"2025-03-07T14:10:10Z","published":"2025-03-07T14:10:10Z","title":"An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for\n  Robust Reasoning","summary":"  In this paper, we examine the use of Conformal Language Modelling (CLM)\nalongside Answer Set Programming (ASP) to enhance the performance of standard\nopen-weight LLMs on complex multi-step reasoning tasks. Using the StepGame\ndataset, which requires spatial reasoning, we apply CLM to generate sets of ASP\nprograms from an LLM, providing statistical guarantees on the correctness of\nthe outputs. Experimental results show that CLM significantly outperforms\nbaseline models that use standard sampling methods, achieving substantial\naccuracy improvements across different levels of reasoning complexity.\nAdditionally, the LLM-as-Judge metric enhances CLM's performance, especially in\nassessing structurally and logically correct ASP outputs. However, calibrating\nCLM with diverse calibration sets did not improve generalizability for tasks\nrequiring much longer reasoning steps, indicating limitations in handling more\ncomplex tasks.\n","authors":["Navdeep Kaur","Lachlan McPheat","Alessandra Russo","Anthony G Cohn","Pranava Madhyastha"],"pdf_url":"https://arxiv.org/pdf/2503.05439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05423v1","updated":"2025-03-07T13:50:29Z","published":"2025-03-07T13:50:29Z","title":"Semantic Shift Estimation via Dual-Projection and Classifier\n  Reconstruction for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn\nfrom distinct categories without retaining exemplars but easily suffers from\ncatastrophic forgetting of learned knowledge. While existing EFCIL methods\nleverage knowledge distillation to alleviate forgetting, they still face two\ncritical challenges: semantic shift and decision bias. Specifically, the\nembeddings of old tasks shift in the embedding space after learning new tasks,\nand the classifier becomes biased towards new tasks due to training solely with\nnew data, thereby hindering the balance between old and new knowledge. To\naddress these issues, we propose the Dual-Projection Shift Estimation and\nClassifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates\nsemantic shift through a dual-projection, which combines a learnable\ntransformation with a row-space projection to capture both task-wise and\ncategory-wise shifts. Furthermore, to mitigate decision bias, DPCR employs\nridge regression to reformulate classifier training as a reconstruction\nprocess. This reconstruction exploits previous information encoded in\ncovariance and prototype of each class after calibration with estimated shift,\nthereby reducing decision bias. Extensive experiments demonstrate that, across\nvarious datasets, DPCR effectively balances old and new tasks, outperforming\nstate-of-the-art EFCIL methods.\n","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.05423v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.05394v1","updated":"2025-03-07T13:09:37Z","published":"2025-03-07T13:09:37Z","title":"Static Program Analysis Guided LLM Based Unit Test Generation","summary":"  We describe a novel approach to automating unit test generation for Java\nmethods using large language models (LLMs). Existing LLM-based approaches rely\non sample usage(s) of the method to test (focal method) and/or provide the\nentire class of the focal method as input prompt and context. The former\napproach is often not viable due to the lack of sample usages, especially for\nnewly written focal methods. The latter approach does not scale well enough;\nthe bigger the complexity of the focal method and larger associated class, the\nharder it is to produce adequate test code (due to factors such as exceeding\nthe prompt and context lengths of the underlying LLM). We show that augmenting\nprompts with \\emph{concise} and \\emph{precise} context information obtained by\nprogram analysis %of the focal method increases the effectiveness of generating\nunit test code through LLMs. We validate our approach on a large commercial\nJava project and a popular open-source Java project.\n","authors":["Sujoy Roychowdhury","Giriprasad Sridhara","A K Raghavan","Joy Bose","Sourav Mazumdar","Hamender Singh","Srinivasan Bajji Sugumaran","Ricardo Britto"],"pdf_url":"https://arxiv.org/pdf/2503.05394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03890v6","updated":"2025-03-07T13:06:56Z","published":"2024-01-08T13:42:59Z","title":"A Survey on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (GS) has emerged as a transformative technique in\nexplicit radiance field and computer graphics. This innovative approach,\ncharacterized by the use of millions of learnable 3D Gaussians, represents a\nsignificant departure from mainstream neural radiance field approaches, which\npredominantly use implicit, coordinate-based models to map spatial coordinates\nto pixel values. 3D GS, with its explicit scene representation and\ndifferentiable rendering algorithm, not only promises real-time rendering\ncapability but also introduces unprecedented levels of editability. This\npositions 3D GS as a potential game-changer for the next generation of 3D\nreconstruction and representation. In the present paper, we provide the first\nsystematic overview of the recent developments and critical contributions in\nthe domain of 3D GS. We begin with a detailed exploration of the underlying\nprinciples and the driving forces behind the emergence of 3D GS, laying the\ngroundwork for understanding its significance. A focal point of our discussion\nis the practical applicability of 3D GS. By enabling unprecedented rendering\nspeed, 3D GS opens up a plethora of applications, ranging from virtual reality\nto interactive media and beyond. This is complemented by a comparative analysis\nof leading 3D GS models, evaluated across various benchmark tasks to highlight\ntheir performance and practical utility. The survey concludes by identifying\ncurrent challenges and suggesting potential avenues for future research.\nThrough this survey, we aim to provide a valuable resource for both newcomers\nand seasoned researchers, fostering further exploration and advancement in\nexplicit radiance field.\n","authors":["Guikun Chen","Wenguan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.03890v6.pdf","comment":"Ongoing project. Paper list:\n  https://github.com/guikunchen/Awesome3DGS ; Benchmark:\n  https://github.com/guikunchen/3DGS-Benchmarks"},{"id":"http://arxiv.org/abs/2503.05388v1","updated":"2025-03-07T13:03:28Z","published":"2025-03-07T13:03:28Z","title":"Ontology Generation using Large Language Models","summary":"  The ontology engineering process is complex, time-consuming, and error-prone,\neven for experienced ontology engineers. In this work, we investigate the\npotential of Large Language Models (LLMs) to provide effective OWL ontology\ndrafts directly from ontological requirements described using user stories and\ncompetency questions. Our main contribution is the presentation and evaluation\nof two new prompting techniques for automated ontology development: Memoryless\nCQbyCQ and Ontogenia. We also emphasize the importance of three structural\ncriteria for ontology assessment, alongside expert qualitative evaluation,\nhighlighting the need for a multi-dimensional evaluation in order to capture\nthe quality and usability of the generated ontologies. Our experiments,\nconducted on a benchmark dataset of ten ontologies with 100 distinct CQs and 29\ndifferent user stories, compare the performance of three LLMs using the two\nprompting techniques. The results demonstrate improvements over the current\nstate-of-the-art in LLM-supported ontology engineering. More specifically, the\nmodel OpenAI o1-preview with Ontogenia produces ontologies of sufficient\nquality to meet the requirements of ontology engineers, significantly\noutperforming novice ontology engineers in modelling ability. However, we still\nnote some common mistakes and variability of result quality, which is important\nto take into account when using LLMs for ontology authoring support. We discuss\nthese limitations and propose directions for future research.\n","authors":["Anna Sofia Lippolis","Mohammad Javad Saeedizade","Robin Keskisärkkä","Sara Zuppiroli","Miguel Ceriani","Aldo Gangemi","Eva Blomqvist","Andrea Giovanni Nuzzolese"],"pdf_url":"https://arxiv.org/pdf/2503.05388v1.pdf","comment":"2 figures and 3 tables. 20 pages"},{"id":"http://arxiv.org/abs/2503.05383v1","updated":"2025-03-07T12:54:25Z","published":"2025-03-07T12:54:25Z","title":"VLMs Play StarCraft II: A Benchmark and Multimodal Decision Method","summary":"  We introduce VLM-Attention, a multimodal StarCraft II environment that aligns\nartificial agent perception with the human gameplay experience. Traditional\nframeworks such as SMAC rely on abstract state representations that diverge\nsignificantly from human perception, limiting the ecological validity of agent\nbehavior. Our environment addresses this limitation by incorporating RGB visual\ninputs and natural language observations that more closely simulate human\ncognitive processes during gameplay. The VLM-Attention framework consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. Our experimental evaluation across 21 custom scenarios\ndemonstrates that VLM-based agents powered by foundation models (specifically\nQwen-VL and GPT-4o) can execute complex tactical maneuvers without explicit\ntraining, achieving comparable performance to traditional MARL methods that\nrequire substantial training iterations. This work establishes a foundation for\ndeveloping human-aligned StarCraft II agents and advances the broader research\nagenda of multimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2.\n","authors":["Weiyu Ma","Yuqian Fu","Zecheng Zhang","Guohao Li"],"pdf_url":"https://arxiv.org/pdf/2503.05383v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.05053v2","updated":"2025-03-07T12:46:14Z","published":"2024-06-07T16:22:51Z","title":"Hints-In-Browser: Benchmarking Language Models for Programming Feedback\n  Generation","summary":"  Generative AI and large language models hold great promise in enhancing\nprogramming education by generating individualized feedback and hints for\nlearners. Recent works have primarily focused on improving the quality of\ngenerated feedback to achieve human tutors' quality. While quality is an\nimportant performance criterion, it is not the only criterion to optimize for\nreal-world educational deployments. In this paper, we benchmark language models\nfor programming feedback generation across several performance criteria,\nincluding quality, cost, time, and data privacy. The key idea is to leverage\nrecent advances in the new paradigm of in-browser inference that allow running\nthese models directly in the browser, thereby providing direct benefits across\ncost and data privacy. To boost the feedback quality of small models compatible\nwith in-browser inference engines, we develop a fine-tuning pipeline based on\nGPT-4 generated synthetic data. We showcase the efficacy of fine-tuned\nLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser\ninference engine on three different Python programming datasets. We will\nrelease the full implementation along with a web app and datasets to facilitate\nfurther research on in-browser language models.\n","authors":["Nachiket Kotalwar","Alkis Gotovos","Adish Singla"],"pdf_url":"https://arxiv.org/pdf/2406.05053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01614v2","updated":"2025-03-07T12:31:27Z","published":"2024-05-02T16:17:29Z","title":"RULSurv: A probabilistic survival-based method for early censoring-aware\n  prediction of remaining useful life in ball bearings","summary":"  Censored data refers to situations where the full information about a\nparticular event or process is only partially known. In survival analysis,\ncensoring plays an important role, as ignoring such observations can bias the\nmodel parameters and overestimate the probability of when the event is likely\nto occur. There has been a renewed interest in using data-driven methods to\npredict the remaining useful life (RUL) of ball bearings for predictive\nmaintenance. However, few studies have explicitly addressed the challenge of\nhandling censored data. To address this issue, we introduce a novel and\nflexible method for early fault detection using Kullback-Leibler (KL)\ndivergence and RUL estimation using survival analysis that naturally supports\ncensored data. We demonstrate our approach in the XJTU-SY dataset using a\n5-fold cross-validation across three different operating conditions. When\npredicting the time to failure for bearings under the highest load (C1, 12.0 kN\nand 2100 RPM) with 25\\% random censoring, our approach achieves a mean absolute\nerror (MAE) of 14.7 minutes (95\\% CI 13.6-15.8) using a linear CoxPH model, and\nan MAE of 12.6 minutes (95\\% CI 11.8-13.4) using a nonlinear Random Survival\nForests model, compared to an MAE of 18.5 minutes (95\\% 17.4-19.6) using a\nlinear LASSO model that does not support censoring. Moreover, our approach\nachieves a mean cumulative relative accuracy (CRA) of 0.7586 over 5 bearings\nunder the highest load, which improves over several state-of-the-art baselines.\nOur work highlights the importance of considering censored observations as part\nof the model design when building predictive models for early fault detection\nand RUL estimation.\n","authors":["Christian Marius Lillelund","Fernando Pannullo","Morten Opprud Jakobsen","Manuel Morante","Christian Fischer Pedersen"],"pdf_url":"https://arxiv.org/pdf/2405.01614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05371v1","updated":"2025-03-07T12:25:29Z","published":"2025-03-07T12:25:29Z","title":"Shifting Perspectives: Steering Vector Ensembles for Robust Bias\n  Mitigation in LLMs","summary":"  We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.\n","authors":["Zara Siddique","Irtaza Khalid","Liam D. Turner","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.05371v1.pdf","comment":"Submitted to ACL 2025"},{"id":"http://arxiv.org/abs/2403.10173v2","updated":"2025-03-07T12:03:09Z","published":"2024-03-15T10:28:31Z","title":"A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial\n  and Temporal AttentionEfficient Event-Based Object Detection: A Hybrid Neural\n  Network with Spatial and Temporal Attention","summary":"  Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for energy\nefficient and low latency event-based data processing, they often fall short of\nArtificial Neural Networks (ANNs) in accuracy and flexibility. Here, we\nintroduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvLSTMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.\n","authors":["Soikat Hasan Ahmed","Jan Finkbeiner","Emre Neftci"],"pdf_url":"https://arxiv.org/pdf/2403.10173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05357v1","updated":"2025-03-07T12:01:02Z","published":"2025-03-07T12:01:02Z","title":"Improving Hate Speech Classification with Cross-Taxonomy Dataset\n  Integration","summary":"  Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.\n","authors":["Jan Fillies","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2503.05357v1.pdf","comment":"Accepted for publication at LaTeCH-CLfL 2025. The 9th Joint ACL\n  Special Interest Group on Language Technologies for the Socio-Economic\n  Sciences and Humanities (SIGHUM) Workshop on Computational Linguistics for\n  Cultural Heritage, Social Sciences, Humanities and Literature"},{"id":"http://arxiv.org/abs/2503.05355v1","updated":"2025-03-07T11:58:08Z","published":"2025-03-07T11:58:08Z","title":"On the Logical Content of Logic Programs","summary":"  Logic programming (LP) is typically understood through operational semantics\n(e.g., SLD-resolution) or model-theoretic interpretations (e.g., the least\nHerbrand model). This paper introduces a novel perspective on LP by defining a\n``support'' relation that explicates what a program ``knows''. This\ninterpretation is shown to express classical and intuitionistic logic, as well\nas an intermediate logic, depending on certain choices regarding LP and the\nmeanings of disjunction and negation. These results are formalized using the\nidea of base-extension semantics within proof-theoretic semantics. Our approach\noffers new insights into the logical foundations of LP and has potential\napplications in knowledge representation, automated reasoning, and formal\nverification.\n","authors":["Alexader V. Gheorghiu"],"pdf_url":"https://arxiv.org/pdf/2503.05355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05349v1","updated":"2025-03-07T11:44:49Z","published":"2025-03-07T11:44:49Z","title":"Spatial Distillation based Distribution Alignment (SDDA) for\n  Cross-Headset EEG Classification","summary":"  A non-invasive brain-computer interface (BCI) enables direct interaction\nbetween the user and external devices, typically via electroencephalogram (EEG)\nsignals. However, decoding EEG signals across different headsets remains a\nsignificant challenge due to differences in the number and locations of the\nelectrodes. To address this challenge, we propose a spatial distillation based\ndistribution alignment (SDDA) approach for heterogeneous cross-headset transfer\nin non-invasive BCIs. SDDA uses first spatial distillation to make use of the\nfull set of electrodes, and then input/feature/output space distribution\nalignments to cope with the significant differences between the source and\ntarget domains. To our knowledge, this is the first work to use knowledge\ndistillation in cross-headset transfers. Extensive experiments on six EEG\ndatasets from two BCI paradigms demonstrated that SDDA achieved superior\nperformance in both offline unsupervised domain adaptation and online\nsupervised domain adaptation scenarios, consistently outperforming 10 classical\nand state-of-the-art transfer learning algorithms.\n","authors":["Dingkun Liu","Siyang Li","Ziwei Wang","Wei Li","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05349v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.04398v2","updated":"2025-03-07T11:41:53Z","published":"2025-03-06T12:52:22Z","title":"Speculative MoE: Communication Efficient Parallel MoE Inference with\n  Speculative Token and Expert Pre-scheduling","summary":"  MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.\n","authors":["Yan Li","Pengfei Zheng","Shuang Chen","Zewei Xu","Yuanhao Lai","Yunfei Du","Zhengang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05346v1","updated":"2025-03-07T11:40:52Z","published":"2025-03-07T11:40:52Z","title":"AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT\n  Applications","summary":"  The advent of Large Language Models (LLMs) has profoundly transformed our\nlives, revolutionizing interactions with AI and lowering the barrier to AI\nusage. While LLMs are primarily designed for natural language interaction, the\nextensive embedded knowledge empowers them to comprehend digital sensor data.\nThis capability enables LLMs to engage with the physical world through IoT\nsensors and actuators, performing a myriad of AIoT tasks. Consequently, this\nevolution triggers a paradigm shift in conventional AIoT application\ndevelopment, democratizing its accessibility to all by facilitating the design\nand development of AIoT applications via natural language. However, some\nlimitations need to be addressed to unlock the full potential of LLMs in AIoT\napplication development. First, existing solutions often require transferring\nraw sensor data to LLM servers, which raises privacy concerns, incurs high\nquery fees, and is limited by token size. Moreover, the reasoning processes of\nLLMs are opaque to users, making it difficult to verify the robustness and\ncorrectness of inference results. This paper introduces AutoIOT, an LLM-based\nautomated program generator for AIoT applications. AutoIOT enables users to\nspecify their requirements using natural language (input) and automatically\nsynthesizes interpretable programs with documentation (output). AutoIOT\nautomates the iterative optimization to enhance the quality of generated code\nwith minimum user involvement. AutoIOT not only makes the execution of AIoT\ntasks more explainable but also mitigates privacy concerns and reduces token\ncosts with local execution of synthesized programs. Extensive experiments and\nuser studies demonstrate AutoIOT's remarkable capability in program synthesis\nfor various AIoT tasks. The synthesized programs can match and even outperform\nsome representative baselines.\n","authors":["Leming Shen","Qiang Yang","Yuanqing Zheng","Mo Li"],"pdf_url":"https://arxiv.org/pdf/2503.05346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05336v1","updated":"2025-03-07T11:23:48Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Deb Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Sayash Kapoor","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2412.15429v3","updated":"2025-03-07T11:20:12Z","published":"2024-12-19T22:29:03Z","title":"Offline Safe Reinforcement Learning Using Trajectory Classification","summary":"  Offline safe reinforcement learning (RL) has emerged as a promising approach\nfor learning safe behaviors without engaging in risky online interactions with\nthe environment. Most existing methods in offline safe RL rely on cost\nconstraints at each time step (derived from global cost constraints) and this\ncan result in either overly conservative policies or violation of safety\nconstraints. In this paper, we propose to learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories. To be specific, we\nfirst partition the pre-collected dataset of state-action trajectories into\ndesirable and undesirable subsets. Intuitively, the desirable set contains high\nreward and safe trajectories, and undesirable set contains unsafe trajectories\nand low-reward safe trajectories. Second, we learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories, where\n(un)desirability scores are provided by a classifier learnt from the dataset of\ndesirable and undesirable trajectories. This approach bypasses the\ncomputational complexity and stability issues of a min-max objective that is\nemployed in existing methods. Theoretically, we also show our approach's strong\nconnections to existing learning paradigms involving human feedback. Finally,\nwe extensively evaluate our method using the DSRL benchmark for offline safe\nRL. Empirically, our method outperforms competitive baselines, achieving higher\nrewards and better constraint satisfaction across a wide variety of benchmark\ntasks.\n","authors":["Ze Gong","Akshat Kumar","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2412.15429v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2308.14352v2","updated":"2025-03-07T11:16:40Z","published":"2023-08-28T06:56:08Z","title":"EdgeMoE: Empowering Sparse Large Language Models on Mobile Devices","summary":"  Large language models (LLMs) such as GPTs and Mixtral-8x7B have\nrevolutionized machine intelligence due to their exceptional abilities in\ngeneric ML tasks. Transiting LLMs from datacenters to edge devices brings\nbenefits like better privacy and availability, but is challenged by their\nmassive parameter size and thus unbearable runtime costs. To this end, we\npresent EdgeMoE, an on-device inference engine for mixture-of-expert (MoE) LLMs\n-- a popular form of sparse LLM that scales its parameter size with almost\nconstant computing complexity. EdgeMoE achieves both memory- and\ncompute-efficiency by partitioning the model into the storage hierarchy:\nnon-expert weights are held in device memory; while expert weights are held on\nexternal storage and fetched to memory only when activated. This design is\nmotivated by a key observation that expert weights are bulky but infrequently\nused due to sparse activation. To further reduce the expert I/O swapping\noverhead, EdgeMoE incorporates two novel techniques: (1) expert-wise bitwidth\nadaptation that reduces the expert sizes with tolerable accuracy loss; (2)\nexpert preloading that predicts the activated experts ahead of time and\npreloads it with the compute-I/O pipeline. On popular MoE LLMs and edge\ndevices, EdgeMoE showcase significant memory savings and speedup over\ncompetitive baselines. The code is available at\nhttps://github.com/UbiquitousLearning/mllm.\n","authors":["Rongjie Yi","Liwei Guo","Shiyun Wei","Ao Zhou","Shangguang Wang","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2308.14352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05330v1","updated":"2025-03-07T11:15:36Z","published":"2025-03-07T11:15:36Z","title":"Speculative Decoding for Multi-Sample Inference","summary":"  We propose a novel speculative decoding method tailored for multi-sample\nreasoning scenarios, such as self-consistency and Best-of-N sampling. Our\nmethod exploits the intrinsic consensus of parallel generation paths to\nsynthesize high-quality draft tokens without requiring auxiliary models or\nexternal databases. By dynamically analyzing structural patterns across\nparallel reasoning paths through a probabilistic aggregation mechanism, it\nidentifies consensus token sequences that align with the decoding distribution.\nEvaluations on mathematical reasoning benchmarks demonstrate a substantial\nimprovement in draft acceptance rates over baselines, while reducing the\nlatency in draft token construction. This work establishes a paradigm shift for\nefficient multi-sample inference, enabling seamless integration of speculative\ndecoding with sampling-based reasoning techniques.\n","authors":["Yiwei Li","Jiayi Shi","Shaoxiong Feng","Peiwen Yuan","Xinglin Wang","Yueqi Zhang","Ji Zhang","Chuyi Tan","Boyuan Pan","Yao Hu","Kan Li"],"pdf_url":"https://arxiv.org/pdf/2503.05330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05328v1","updated":"2025-03-07T11:13:33Z","published":"2025-03-07T11:13:33Z","title":"Dynamic Knowledge Integration for Evidence-Driven Counter-Argument\n  Generation with Large Language Models","summary":"  This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.\n","authors":["Anar Yeginbergen","Maite Oronoz","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2503.05328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v2","updated":"2025-03-07T11:12:17Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2408.02361v2.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05322v1","updated":"2025-03-07T11:01:00Z","published":"2025-03-07T11:01:00Z","title":"Attenuation artifact detection and severity classification in\n  intracoronary OCT using mixed image representations","summary":"  In intracoronary optical coherence tomography (OCT), blood residues and gas\nbubbles cause attenuation artifacts that can obscure critical vessel\nstructures. The presence and severity of these artifacts may warrant\nre-acquisition, prolonging procedure time and increasing use of contrast agent.\nAccurate detection of these artifacts can guide targeted re-acquisition,\nreducing the amount of repeated scans needed to achieve diagnostically viable\nimages. However, the highly heterogeneous appearance of these artifacts poses a\nchallenge for the automated detection of the affected image regions. To enable\nautomatic detection of the attenuation artifacts caused by blood residues and\ngas bubbles based on their severity, we propose a convolutional neural network\nthat performs classification of the attenuation lines (A-lines) into three\nclasses: no artifact, mild artifact and severe artifact. Our model extracts and\nmerges features from OCT images in both Cartesian and polar coordinates, where\neach column of the image represents an A-line. Our method detects the presence\nof attenuation artifacts in OCT frames reaching F-scores of 0.77 and 0.94 for\nmild and severe artifacts, respectively. The inference time over a full OCT\nscan is approximately 6 seconds. Our experiments show that analysis of images\nrepresented in both Cartesian and polar coordinate systems outperforms the\nanalysis in polar coordinates only, suggesting that these representations\ncontain complementary features. This work lays the foundation for automated\nartifact assessment and image acquisition guidance in intracoronary OCT\nimaging.\n","authors":["Pierandrea Cancian","Simone Saitta","Xiaojin Gu","Rudolf L. M. van Herten","Thijs J. Luttikholt","Jos Thannhauser","Rick H. J. A. Volleberg","Ruben G. A. van der Waerden","Joske L. van der Zande","Clarisa I. Sánchez","Bram van Ginneken","Niels van Royen","Ivana Išgum"],"pdf_url":"https://arxiv.org/pdf/2503.05322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05320v1","updated":"2025-03-07T11:00:24Z","published":"2025-03-07T11:00:24Z","title":"Disentangling Task Interference within Neurons: Model Merging in\n  Alignment with Neuronal Mechanisms","summary":"  Fine-tuning pre-trained models on targeted datasets enhances task-specific\nperformance but often comes at the expense of generalization. Model merging\ntechniques, which integrate multiple fine-tuned models into a single multi-task\nmodel through task arithmetic at various levels: model, layer, or parameter,\noffer a promising solution. However, task interference remains a fundamental\nchallenge, leading to performance degradation and suboptimal merged models.\nExisting approaches largely overlook the fundamental role of individual neurons\nand their connectivity, resulting in a lack of interpretability in both the\nmerging process and the merged models. In this work, we present the first study\non the impact of neuronal alignment in model merging. We decompose\ntask-specific representations into two complementary neuronal subspaces that\nregulate neuron sensitivity and input adaptability. Leveraging this\ndecomposition, we introduce NeuroMerging, a novel merging framework developed\nto mitigate task interference within neuronal subspaces, enabling training-free\nmodel fusion across diverse tasks. Through extensive experiments, we\ndemonstrate that NeuroMerging achieves superior performance compared to\nexisting methods on multi-task benchmarks across both vision and natural\nlanguage domains. Our findings highlight the importance of aligning neuronal\nmechanisms in model merging, offering new insights into mitigating task\ninterference and improving knowledge fusion.\n","authors":["Zitao Fang","Guodong DU","Shuyang Yu","Yifei Guo","Yiwei Zhang","Jing Li","Ho-Kin Tang","Sim Kuan Goh"],"pdf_url":"https://arxiv.org/pdf/2503.05320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05319v1","updated":"2025-03-07T10:58:38Z","published":"2025-03-07T10:58:38Z","title":"Robust Multimodal Learning for Ophthalmic Disease Grading via\n  Disentangled Representation","summary":"  This paper discusses how ophthalmologists often rely on multimodal data to\nimprove diagnostic accuracy. However, complete multimodal data is rare in\nreal-world applications due to a lack of medical equipment and concerns about\ndata privacy. Traditional deep learning methods typically address these issues\nby learning representations in latent space. However, the paper highlights two\nkey limitations of these approaches: (i) Task-irrelevant redundant information\n(e.g., numerous slices) in complex modalities leads to significant redundancy\nin latent space representations. (ii) Overlapping multimodal representations\nmake it difficult to extract unique features for each modality. To overcome\nthese challenges, the authors propose the Essence-Point and Disentangle\nRepresentation Learning (EDRL) strategy, which integrates a self-distillation\nmechanism into an end-to-end framework to enhance feature selection and\ndisentanglement for more robust multimodal learning. Specifically, the\nEssence-Point Representation Learning module selects discriminative features\nthat improve disease grading performance. The Disentangled Representation\nLearning module separates multimodal data into modality-common and\nmodality-unique representations, reducing feature entanglement and enhancing\nboth robustness and interpretability in ophthalmic disease diagnosis.\nExperiments on multimodal ophthalmology datasets show that the proposed EDRL\nstrategy significantly outperforms current state-of-the-art methods.\n","authors":["Xinkun Wang","Yifang Wang","Senwei Liang","Feilong Tang","Chengzhi Liu","Ming Hu","Chao Hu","Junjun He","Zongyuan Ge","Imran Razzak"],"pdf_url":"https://arxiv.org/pdf/2503.05319v1.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2503.05318v1","updated":"2025-03-07T10:55:12Z","published":"2025-03-07T10:55:12Z","title":"Uncertainty-Aware Decoding with Minimum Bayes Risk","summary":"  Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.\n","authors":["Nico Daheim","Clara Meister","Thomas Möllenhoff","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.05318v1.pdf","comment":"ICLR 2025 (Poster)"},{"id":"http://arxiv.org/abs/2402.10726v4","updated":"2025-03-07T10:45:07Z","published":"2024-02-16T14:36:58Z","title":"Planning Domain Model Acquisition from State Traces without Action\n  Parameters","summary":"  Existing planning action domain model acquisition approaches consider\ndifferent types of state traces from which they learn. The differences in state\ntraces refer to the level of observability of state changes (from full to none)\nand whether the observations have some noise (the state changes might be\ninaccurately logged). However, to the best of our knowledge, all the existing\napproaches consider state traces in which each state change corresponds to an\naction specified by its name and all its parameters (all objects that are\nrelevant to the action). Furthermore, the names and types of all the parameters\nof the actions to be learned are given. These assumptions are too strong.\n  In this paper, we propose a method that learns action schema from state\ntraces with fully observable state changes but without the parameters of\nactions responsible for the state changes (only action names are part of the\nstate traces). Although we can easily deduce the number (and names) of the\nactions that will be in the learned domain model, we still need to deduce the\nnumber and types of the parameters of each action alongside its precondition\nand effects. We show that this task is at least as hard as graph isomorphism.\nHowever, our experimental evaluation on a large collection of IPC benchmarks\nshows that our approach is still practical as the number of required parameters\nis usually small.\n  Compared to the state-of-the-art learning tools SAM and Extended SAM our new\nalgorithm is able to provide better results in multiple domains in terms of\nlearning action models more similar to reference models, even though it uses\nless information and has fewer restrictions on the input traces.\n","authors":["Tomáš Balyo","Martin Suda","Lukáš Chrpa","Dominik Šafránek","Stephan Gocht","Filip Dvořák","Roman Barták","G. Michael Youngblood"],"pdf_url":"https://arxiv.org/pdf/2402.10726v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05306v1","updated":"2025-03-07T10:35:01Z","published":"2025-03-07T10:35:01Z","title":"Adversarial Policy Optimization for Offline Preference-based\n  Reinforcement Learning","summary":"  In this paper, we study offline preference-based reinforcement learning\n(PbRL), where learning is based on pre-collected preference feedback over pairs\nof trajectories. While offline PbRL has demonstrated remarkable empirical\nsuccess, existing theoretical approaches face challenges in ensuring\nconservatism under uncertainty, requiring computationally intractable\nconfidence set constructions. We address this limitation by proposing\nAdversarial Preference-based Policy Optimization (APPO), a computationally\nefficient algorithm for offline PbRL that guarantees sample complexity bounds\nwithout relying on explicit confidence sets. By framing PbRL as a two-player\ngame between a policy and a model, our approach enforces conservatism in a\ntractable manner. Using standard assumptions on function approximation and\nbounded trajectory concentrability, we derive a sample complexity bound. To our\nknowledge, APPO is the first offline PbRL algorithm to offer both statistical\nefficiency and practical applicability. Experimental results on continuous\ncontrol tasks demonstrate that APPO effectively learns from complex datasets,\nshowing comparable performance with existing state-of-the-art methods.\n","authors":["Hyungkyu Kang","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2503.05306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05305v1","updated":"2025-03-07T10:34:04Z","published":"2025-03-07T10:34:04Z","title":"Frequency Autoregressive Image Generation with Continuous Tokens","summary":"  Autoregressive (AR) models for image generation typically adopt a two-stage\nparadigm of vector quantization and raster-scan ``next-token prediction\",\ninspired by its great success in language modeling. However, due to the huge\nmodality gap, image autoregressive models may require a systematic reevaluation\nfrom two perspectives: tokenizer format and regression direction. In this\npaper, we introduce the frequency progressive autoregressive (\\textbf{FAR})\nparadigm and instantiate FAR with the continuous tokenizer. Specifically, we\nidentify spectral dependency as the desirable regression direction for FAR,\nwherein higher-frequency components build upon the lower one to progressively\nconstruct a complete image. This design seamlessly fits the causality\nrequirement for autoregressive models and preserves the unique spatial locality\nof image data. Besides, we delve into the integration of FAR and the continuous\ntokenizer, introducing a series of techniques to address optimization\nchallenges and improve the efficiency of training and inference processes. We\ndemonstrate the efficacy of FAR through comprehensive experiments on the\nImageNet dataset and verify its potential on text-to-image generation.\n","authors":["Hu Yu","Hao Luo","Hangjie Yuan","Yu Rong","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04280v2","updated":"2025-03-07T10:06:29Z","published":"2025-03-06T10:08:44Z","title":"Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.\n","authors":["Niccolò Turcato","Matteo Iovino","Aris Synodinos","Alberto Dalla Libera","Ruggero Carli","Pietro Falco"],"pdf_url":"https://arxiv.org/pdf/2503.04280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04564v2","updated":"2025-03-07T10:01:49Z","published":"2025-03-06T15:53:37Z","title":"Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User\n  Association","summary":"  Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer network, where clustered users communicate with the\nserver through an intermediate layer of relays. In HSA, beyond conventional\nserver security, relay security is also enforced to ensure that the relays\nremain oblivious to the users' inputs (an abstraction of the local models in\nFL). Existing study on HSA assumes that each user is associated with only one\nrelay, limiting opportunities for coding across inter-cluster users to achieve\nefficient communication and key generation. In this paper, we consider HSA with\na cyclic association pattern where each user is connected to $B$ consecutive\nrelays in a wrap-around manner. We propose an efficient aggregation scheme\nwhich includes a message design for the inputs inspired by gradient coding-a\nwell-known technique for efficient communication in distributed computing-along\nwith a highly nontrivial security key design. We also derive novel converse\nbounds on the minimum achievable communication and key rates using\ninformation-theoretic arguments.\n","authors":["Xiang Zhang","Zhou Li","Kai Wan","Hua Sun","Mingyue Ji","Giuseppe Caire"],"pdf_url":"https://arxiv.org/pdf/2503.04564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08662v2","updated":"2025-03-07T09:55:19Z","published":"2025-02-10T09:34:15Z","title":"RoToR: Towards More Reliable Responses for Order-Invariant Inputs","summary":"  Mitigating positional bias of language models (LMs) for listwise inputs is a\nwell-known and important problem (e.g., lost-in-the-middle). While zero-shot\norder-invariant LMs have been proposed to solve this issue, their success on\npractical listwise problems has been limited. In this work, as a first\ncontribution, we identify and overcome two limitations to make zero-shot\ninvariant LMs more practical: (1) training and inference distribution mismatch\narising from modifying positional ID assignments to enforce invariance, and (2)\nfailure to adapt to a mixture of order-invariant and sensitive inputs in\npractical listwise problems. Then, to overcome these issues we propose (1)\nRoToR, a zero-shot invariant LM for genuinely order-invariant inputs with\nminimal modifications of positional IDs, and (2) Selective Routing, an adaptive\nframework that handles both order-invariant and order-sensitive inputs in\nlistwise tasks. On the Lost in the middle (LitM), Knowledge Graph QA (KGQA),\nand MMLU benchmarks, we show that RoToR with Selective Routing can effectively\nhandle practical listwise input tasks in a zero-shot manner.\n","authors":["Soyoung Yoon","Dongha Ahn","Youngwon Lee","Minkyu Jung","HyungJoo Jang","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2502.08662v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05274v1","updated":"2025-03-07T09:46:21Z","published":"2025-03-07T09:46:21Z","title":"Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction","summary":"  Accurate trajectory prediction is crucial for autonomous driving, yet\nuncertainty in agent behavior and perception noise makes it inherently\nchallenging. While multi-modal trajectory prediction models generate multiple\nplausible future paths with associated probabilities, effectively quantifying\nuncertainty remains an open problem. In this work, we propose a novel\nmulti-modal trajectory prediction approach based on evidential deep learning\nthat estimates both positional and mode probability uncertainty in real time.\nOur approach leverages a Normal Inverse Gamma distribution for positional\nuncertainty and a Dirichlet distribution for mode uncertainty. Unlike\nsampling-based methods, it infers both types of uncertainty in a single forward\npass, significantly improving efficiency. Additionally, we experimented with\nuncertainty-driven importance sampling to improve training efficiency by\nprioritizing underrepresented high-uncertainty samples over redundant ones. We\nperform extensive evaluations of our method on the Argoverse 1 and Argoverse 2\ndatasets, demonstrating that it provides reliable uncertainty estimates while\nmaintaining high trajectory prediction accuracy.\n","authors":["Sajad Marvi","Christoph Rist","Julian Schmidt","Julian Jordan","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2503.05274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04150v2","updated":"2025-03-07T09:37:53Z","published":"2025-03-06T06:59:09Z","title":"Ticktack : Long Span Temporal Alignment of Large Language Models\n  Leveraging Sexagenary Cycle Time Expression","summary":"  Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.\n","authors":["Xue Han","Qian Hu","Yitong Wang","Wenchun Gao","Lianlian Zhang","Qing Wang","Lijun Mei","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09651v2","updated":"2025-03-07T09:32:03Z","published":"2024-12-11T16:08:25Z","title":"Assisted morbidity coding: the SISCO.web use case for identifying the\n  main diagnosis in Hospital Discharge Records","summary":"  Coding morbidity data using international standard diagnostic classifications\nis increasingly important and still challenging. Clinical coders and physicians\nassign codes to patient episodes based on their interpretation of case notes or\nelectronic patient records. Therefore, accurate coding relies on the legibility\nof case notes and the coders' understanding of medical terminology. During the\nlast ten years, many studies have shown poor reproducibility of clinical\ncoding, even recently, with the application of Artificial Intelligence-based\nmodels. Given this context, the paper aims to present the SISCO.web approach\ndesigned to support physicians in filling in Hospital Discharge Records with\nproper diagnoses and procedures codes using the International Classification of\nDiseases (9th and 10th), and, above all, in identifying the main pathological\ncondition. The web service leverages NLP algorithms, specific coding rules, as\nwell as ad hoc decision trees to identify the main condition, showing promising\nresults in providing accurate ICD coding suggestions.\n","authors":["Elena Cardillo","Lucilla Frattura"],"pdf_url":"https://arxiv.org/pdf/2412.09651v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.02972v3","updated":"2025-03-07T09:31:42Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Assessing the reasoning capabilities of large language models (LLMs) is\nsusceptible to overestimation due to data exposure of evaluation benchmarks. We\nintroduce a framework for producing linguistic reasoning problems that reduces\nthe effect of memorisation in model performance estimates and apply this\nframework to develop LINGOLY-TOO, a challenging benchmark for linguistic\nreasoning. By developing orthographic templates, we dynamically obfuscate the\nwriting systems of real languages to generate numerousquestion variations.\nThese variations preserve the reasoning steps required for each solution while\nreducing the likelihood of specific problem instances appearing in model\ntraining data. Our experiments demonstrate that frontier models, including\nClaud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.\nOur analysis also shows that LLMs exhibit noticeable variance in accuracy\nacross permutations of the same problem, and on average perform better on\nquestions appearing in their original orthography. Our findings highlight the\nopaque nature of response generation in LLMs and provide evidence that prior\ndata exposure contributes to over estimating the reasoning capabilities of\nfrontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacsu","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05265v1","updated":"2025-03-07T09:30:16Z","published":"2025-03-07T09:30:16Z","title":"PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and\n  Latin Lexicons","summary":"  We present PhiloBERTA, a cross-lingual transformer model that measures\nsemantic relationships between ancient Greek and Latin lexicons. Through\nanalysis of selected term pairs from classical texts, we use contextual\nembeddings and angular similarity metrics to identify precise semantic\nalignments. Our results show that etymologically related pairs demonstrate\nsignificantly higher similarity scores, particularly for abstract philosophical\nconcepts such as epist\\=em\\=e (scientia) and dikaiosyn\\=e (iustitia).\nStatistical analysis reveals consistent patterns in these relationships (p =\n0.012), with etymologically related pairs showing remarkably stable semantic\npreservation compared to control pairs. These findings establish a quantitative\nframework for examining how philosophical concepts moved between Greek and\nLatin traditions, offering new methods for classical philological research.\n","authors":["Rumi A. Allbert","Makai L. Allbert"],"pdf_url":"https://arxiv.org/pdf/2503.05265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05264v1","updated":"2025-03-07T09:28:19Z","published":"2025-03-07T09:28:19Z","title":"Jailbreaking is (Mostly) Simpler Than You Think","summary":"  We introduce the Context Compliance Attack (CCA), a novel, optimization-free\nmethod for bypassing AI safety mechanisms. Unlike current approaches -- which\nrely on complex prompt engineering and computationally intensive optimization\n-- CCA exploits a fundamental architectural vulnerability inherent in many\ndeployed AI systems. By subtly manipulating conversation history, CCA convinces\nthe model to comply with a fabricated dialogue context, thereby triggering\nrestricted behavior. Our evaluation across a diverse set of open-source and\nproprietary models demonstrates that this simple attack can circumvent\nstate-of-the-art safety protocols. We discuss the implications of these\nfindings and propose practical mitigation strategies to fortify AI systems\nagainst such elementary yet effective adversarial tactics.\n","authors":["Mark Russinovich","Ahmed Salem"],"pdf_url":"https://arxiv.org/pdf/2503.05264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05251v1","updated":"2025-03-07T09:07:07Z","published":"2025-03-07T09:07:07Z","title":"A Map-free Deep Learning-based Framework for Gate-to-Gate Monocular\n  Visual Navigation aboard Miniaturized Aerial Vehicles","summary":"  Palm-sized autonomous nano-drones, i.e., sub-50g in weight, recently entered\nthe drone racing scenario, where they are tasked to avoid obstacles and\nnavigate as fast as possible through gates. However, in contrast with their\nbigger counterparts, i.e., kg-scale drones, nano-drones expose three orders of\nmagnitude less onboard memory and compute power, demanding more efficient and\nlightweight vision-based pipelines to win the race. This work presents a\nmap-free vision-based (using only a monocular camera) autonomous nano-drone\nthat combines a real-time deep learning gate detection front-end with a classic\nyet elegant and effective visual servoing control back-end, only relying on\nonboard resources. Starting from two state-of-the-art tiny deep learning\nmodels, we adapt them for our specific task, and after a mixed\nsimulator-real-world training, we integrate and deploy them aboard our\nnano-drone. Our best-performing pipeline costs of only 24M multiply-accumulate\noperations per frame, resulting in a closed-loop control performance of 30 Hz,\nwhile achieving a gate detection root mean square error of 1.4 pixels, on our\n~20k real-world image dataset. In-field experiments highlight the capability of\nour nano-drone to successfully navigate through 15 gates in 4 min, never\ncrashing and covering a total travel distance of ~100m, with a peak flight\nspeed of 1.9 m/s. Finally, to stress the generalization capability of our\nsystem, we also test it in a never-seen-before environment, where it navigates\nthrough gates for more than 4 min.\n","authors":["Lorenzo Scarciglia","Antonio Paolillo","Daniele Palossi"],"pdf_url":"https://arxiv.org/pdf/2503.05251v1.pdf","comment":"\\c{opyright}2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2410.23746v2","updated":"2025-03-07T09:06:03Z","published":"2024-10-31T09:01:25Z","title":"DetectRL: Benchmarking LLM-Generated Text Detection in Real-World\n  Scenarios","summary":"  Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xinyi Yang","Yulin Yuan","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2410.23746v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)"},{"id":"http://arxiv.org/abs/2503.01743v2","updated":"2025-03-07T09:05:58Z","published":"2025-03-03T17:05:52Z","title":"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs","summary":"  We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n","authors":[" Microsoft"," :","Abdelrahman Abouelenin","Atabak Ashfaq","Adam Atkinson","Hany Awadalla","Nguyen Bach","Jianmin Bao","Alon Benhaim","Martin Cai","Vishrav Chaudhary","Congcong Chen","Dong Chen","Dongdong Chen","Junkun Chen","Weizhu Chen","Yen-Chun Chen","Yi-ling Chen","Qi Dai","Xiyang Dai","Ruchao Fan","Mei Gao","Min Gao","Amit Garg","Abhishek Goswami","Junheng Hao","Amr Hendy","Yuxuan Hu","Xin Jin","Mahmoud Khademi","Dongwoo Kim","Young Jin Kim","Gina Lee","Jinyu Li","Yunsheng Li","Chen Liang","Xihui Lin","Zeqi Lin","Mengchen Liu","Yang Liu","Gilsinia Lopez","Chong Luo","Piyush Madan","Vadim Mazalov","Arindam Mitra","Ali Mousavi","Anh Nguyen","Jing Pan","Daniel Perez-Becker","Jacob Platin","Thomas Portet","Kai Qiu","Bo Ren","Liliang Ren","Sambuddha Roy","Ning Shang","Yelong Shen","Saksham Singhal","Subhojit Som","Xia Song","Tetyana Sych","Praneetha Vaddamanu","Shuohang Wang","Yiming Wang","Zhenghao Wang","Haibin Wu","Haoran Xu","Weijian Xu","Yifan Yang","Ziyi Yang","Donghan Yu","Ishmam Zabir","Jianwen Zhang","Li Lyna Zhang","Yunan Zhang","Xiren Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01743v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2501.13983v4","updated":"2025-03-07T09:02:42Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v4.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2502.07351v2","updated":"2025-03-07T08:56:46Z","published":"2025-02-11T08:22:21Z","title":"Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for\n  Vision-driven Intelligent Systems","summary":"  Salient object detection (SOD) plays a critical role in vision-driven\nmeasurement systems (VMS), facilitating the detection and segmentation of key\nvisual elements in an image. However, adverse imaging conditions such as haze\nduring the day, low light, and haze at night severely degrade image quality,\nand complicating the SOD process. To address these challenges, we propose a\nmulti-task-oriented nighttime haze imaging enhancer (MToIE), which integrates\nthree tasks: daytime dehazing, low-light enhancement, and nighttime dehazing.\nThe MToIE incorporates two key innovative components: First, the network\nemploys a task-oriented node learning mechanism to handle three specific\ndegradation types: day-time haze, low light, and night-time haze conditions,\nwith an embedded self-attention module enhancing its performance in nighttime\nimaging. In addition, multi-receptive field enhancement module that efficiently\nextracts multi-scale features through three parallel depthwise separable\nconvolution branches with different dilation rates, capturing comprehensive\nspatial information with minimal computational overhead. To ensure optimal\nimage reconstruction quality and visual characteristics, we suggest a hybrid\nloss function. Extensive experiments on different types of weather/imaging\nconditions illustrate that MToIE surpasses existing methods, significantly\nenhancing the accuracy and reliability of vision systems across diverse imaging\nscenarios. The code is available at https://github.com/Ai-Chen-Lab/MKoIE.\n","authors":["Ai Chen","Yuxu Lu","Dong Yang","Junlin Zhou","Yan Fu","Duanbing Chen"],"pdf_url":"https://arxiv.org/pdf/2502.07351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05244v1","updated":"2025-03-07T08:56:20Z","published":"2025-03-07T08:56:20Z","title":"WritingBench: A Comprehensive Benchmark for Generative Writing","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.\n","authors":["Yuning Wu","Jiahao Mei","Ming Yan","Chenliang Li","SHaopeng Lai","Yuran Ren","Zijia Wang","Ji Zhang","Mengyue Wu","Qin Jin","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v2","updated":"2025-03-07T08:55:13Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05239v1","updated":"2025-03-07T08:41:53Z","published":"2025-03-07T08:41:53Z","title":"Robust Conformal Prediction with a Single Binary Certificate","summary":"  Conformal prediction (CP) converts any model's output to prediction sets with\na guarantee to cover the true label with (adjustable) high probability. Robust\nCP extends this guarantee to worst-case (adversarial) inputs. Existing\nbaselines achieve robustness by bounding randomly smoothed conformity scores.\nIn practice, they need expensive Monte-Carlo (MC) sampling (e.g. $\\sim10^4$\nsamples per point) to maintain an acceptable set size. We propose a robust\nconformal prediction that produces smaller sets even with significantly lower\nMC samples (e.g. 150 for CIFAR10). Our approach binarizes samples with an\nadjustable (or automatically adjusted) threshold selected to preserve the\ncoverage guarantee. Remarkably, we prove that robustness can be achieved by\ncomputing only one binary certificate, unlike previous methods that certify\neach calibration (or test) point. Thus, our method is faster and returns\nsmaller robust sets. We also eliminate a previous limitation that requires a\nbounded score function.\n","authors":["Soroush H. Zargarbashi","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2503.05239v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2401.10690v4","updated":"2025-03-07T08:40:19Z","published":"2024-01-19T13:41:08Z","title":"Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and\n  unfairness in dyadic regression models","summary":"  Dyadic regression models, which output real-valued predictions for pairs of\nentities, are fundamental in many domains (e.g. obtaining user-product ratings\nin Recommender Systems) and promising and under exploration in others (e.g.\ntuning patient-drug dosages in precision pharmacology). In this work, we prove\nthat non-uniform observed value distributions of individual entities lead to\nsevere biases in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet crucial cases; we name this phenomenon\neccentricity bias. We show that global error metrics like Root Mean Squared\nError (RMSE) are insufficient to capture this bias, and we introduce\nEccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it\nin all studied domains and models. We prove the intuitive interpretation of\nEAUC by experimenting with naive post-training bias corrections, and theorize\nother options to use EAUC to guide the construction of fair models. This work\ncontributes a bias-aware evaluation of dyadic regression to prevent unfairness\nin critical real-world applications of such systems.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Bertha Guijarro-Berdiñas","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2401.10690v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14003v2","updated":"2025-03-07T08:39:06Z","published":"2023-11-23T13:38:43Z","title":"Direct Preference-Based Evolutionary Multi-Objective Optimization with\n  Dueling Bandit","summary":"  Optimization problems find widespread use in both single-objective and\nmulti-objective scenarios. In practical applications, users aspire for\nsolutions that converge to the region of interest (ROI) along the Pareto front\n(PF). While the conventional approach involves approximating a fitness function\nor an objective function to reflect user preferences, this paper explores an\nalternative avenue. Specifically, we aim to discover a method that sidesteps\nthe need for calculating the fitness function, relying solely on human\nfeedback. Our proposed approach entails conducting direct preference learning\nfacilitated by an active dueling bandit algorithm. The experimental phase is\nstructured into three sessions. Firstly, we assess the performance of our\nactive dueling bandit algorithm. Secondly, we implement our proposed method\nwithin the context of Multi-objective Evolutionary Algorithms (MOEAs). Finally,\nwe deploy our method in a practical problem, specifically in protein structure\nprediction (PSP). This research presents a novel interactive preference-based\nMOEA framework that not only addresses the limitations of traditional\ntechniques but also unveils new possibilities for optimization problems.\n","authors":["Tian Huang","Shengbo Wang","Ke Li"],"pdf_url":"https://arxiv.org/pdf/2311.14003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05231v1","updated":"2025-03-07T08:28:24Z","published":"2025-03-07T08:28:24Z","title":"Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot\n  Learning and Human-Robot Interaction","summary":"  Cutting-edge robot learning techniques including foundation models and\nimitation learning from humans all pose huge demands on large-scale and\nhigh-quality datasets which constitute one of the bottleneck in the general\nintelligent robot fields. This paper presents the Kaiwu multimodal dataset to\naddress the missing real-world synchronized multimodal data problems in the\nsophisticated assembling scenario,especially with dynamics information and its\nfine-grained labelling. The dataset first provides an integration of\nhuman,environment and robot data collection framework with 20 subjects and 30\ninteraction objects resulting in totally 11,664 instances of integrated\nactions. For each of the demonstration,hand motions,operation pressures,sounds\nof the assembling process,multi-view videos, high-precision motion capture\ninformation,eye gaze with first-person videos,electromyography signals are all\nrecorded. Fine-grained multi-level annotation based on absolute timestamp,and\nsemantic segmentation labelling are performed. Kaiwu dataset aims to facilitate\nrobot learning,dexterous manipulation,human intention investigation and\nhuman-robot collaboration research.\n","authors":["Shuo Jiang","Haonan Li","Ruochen Ren","Yanmin Zhou","Zhipeng Wang","Bin He"],"pdf_url":"https://arxiv.org/pdf/2503.05231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00965v5","updated":"2025-03-07T08:27:32Z","published":"2024-06-03T03:38:56Z","title":"HBTP: Heuristic Behavior Tree Planning with Large Language Model\n  Reasoning","summary":"  Behavior Trees (BTs) are increasingly becoming a popular control structure in\nrobotics due to their modularity, reactivity, and robustness. In terms of BT\ngeneration methods, BT planning shows promise for generating reliable BTs.\nHowever, the scalability of BT planning is often constrained by prolonged\nplanning times in complex scenarios, largely due to a lack of domain knowledge.\nIn contrast, pre-trained Large Language Models (LLMs) have demonstrated task\nreasoning capabilities across various domains, though the correctness and\nsafety of their planning remain uncertain. This paper proposes integrating BT\nplanning with LLM reasoning, introducing Heuristic Behavior Tree Planning\n(HBTP)-a reliable and efficient framework for BT generation. The key idea in\nHBTP is to leverage LLMs for task-specific reasoning to generate a heuristic\npath, which BT planning can then follow to expand efficiently. We first\nintroduce the heuristic BT expansion process, along with two heuristic variants\ndesigned for optimal planning and satisficing planning, respectively. Then, we\npropose methods to address the inaccuracies of LLM reasoning, including action\nspace pruning and reflective feedback, to further enhance both reasoning\naccuracy and planning efficiency. Experiments demonstrate the theoretical\nbounds of HBTP, and results from four datasets confirm its practical\neffectiveness in everyday service robot applications.\n","authors":["Yishuai Cai","Xinglin Chen","Yunxin Mao","Minglong Li","Shaowu Yang","Wenjing Yang","Ji Wang"],"pdf_url":"https://arxiv.org/pdf/2406.00965v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19098v2","updated":"2025-03-07T08:27:00Z","published":"2024-07-09T12:52:22Z","title":"Evaluating Human-AI Collaboration: A Review and Methodological Framework","summary":"  The use of artificial intelligence (AI) in working environments with\nindividuals, known as Human-AI Collaboration (HAIC), has become essential in a\nvariety of domains, boosting decision-making, efficiency, and innovation.\nDespite HAIC's wide potential, evaluating its effectiveness remains challenging\ndue to the complex interaction of components involved.\n  This paper provides a detailed analysis of existing HAIC evaluation\napproaches and develops a fresh paradigm for more effectively evaluating these\nsystems.\n  Our framework includes a structured decision tree which assists to select\nrelevant metrics based on distinct HAIC modes (AI-Centric, Human-Centric, and\nSymbiotic). By including both quantitative and qualitative metrics, the\nframework seeks to represent HAIC's dynamic and reciprocal nature, enabling the\nassessment of its impact and success. This framework's practicality can be\nexamined by its application in an array of domains, including manufacturing,\nhealthcare, finance, and education, each of which has unique challenges and\nrequirements. Our hope is that this study will facilitate further research on\nthe systematic evaluation of HAIC in real-world applications.\n","authors":["George Fragiadakis","Christos Diou","George Kousiouris","Mara Nikolaidou"],"pdf_url":"https://arxiv.org/pdf/2407.19098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05229v1","updated":"2025-03-07T08:26:04Z","published":"2025-03-07T08:26:04Z","title":"Discrete Contrastive Learning for Diffusion Policies in Autonomous\n  Driving","summary":"  Learning to perform accurate and rich simulations of human driving behaviors\nfrom data for autonomous vehicle testing remains challenging due to human\ndriving styles' high diversity and variance. We address this challenge by\nproposing a novel approach that leverages contrastive learning to extract a\ndictionary of driving styles from pre-existing human driving data. We\ndiscretize these styles with quantization, and the styles are used to learn a\nconditional diffusion policy for simulating human drivers. Our empirical\nevaluation confirms that the behaviors generated by our approach are both safer\nand more human-like than those of the machine-learning-based baseline methods.\nWe believe this has the potential to enable higher realism and more effective\ntechniques for evaluating and improving the performance of autonomous vehicles.\n","authors":["Kalle Kujanpää","Daulet Baimukashev","Farzeen Munir","Shoaib Azam","Tomasz Piotr Kucner","Joni Pajarinen","Ville Kyrki"],"pdf_url":"https://arxiv.org/pdf/2503.05229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05227v1","updated":"2025-03-07T08:25:08Z","published":"2025-03-07T08:25:08Z","title":"MOHPER: Multi-objective Hyperparameter Optimization Framework for\n  E-commerce Retrieval System","summary":"  E-commerce search optimization has evolved to include a wider range of\nmetrics that reflect user engagement and business objectives. Modern search\nframeworks now incorporate advanced quality features, such as sales counts and\ndocument-query relevance, to better align search results with these goals.\nTraditional methods typically focus on click-through rate (CTR) as a measure of\nengagement or relevance, but this can miss true purchase intent, creating a gap\nbetween user interest and actual conversions. Joint training with the\nclick-through conversion rate (CTCVR) has become essential for understanding\nbuying behavior, although its sparsity poses challenges for reliable\noptimization. This study presents MOHPER, a Multi-Objective Hyperparameter\nOptimization framework for E-commerce Retrieval systems. Utilizing Bayesian\noptimization and sampling, it jointly optimizes both CTR, CTCVR, and relevant\nobjectives, focusing on engagement and conversion of the users. In addition, to\nimprove the selection of the best configuration from multi-objective\noptimization, we suggest advanced methods for hyperparameter selection,\nincluding a meta-configuration voting strategy and a cumulative training\napproach that leverages prior optimal configurations, to improve speeds of\ntraining and efficiency. Currently deployed in a live setting, our proposed\nframework substantiates its practical efficacy in achieving a balanced\noptimization that aligns with both user satisfaction and revenue goals.\n","authors":["Jungbae Park","Heonseok Jang"],"pdf_url":"https://arxiv.org/pdf/2503.05227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05226v1","updated":"2025-03-07T08:25:04Z","published":"2025-03-07T08:25:04Z","title":"Reward-Centered ReST-MCTS: A Robust Decision-Making Framework for\n  Robotic Manipulation in High Uncertainty Environments","summary":"  Monte Carlo Tree Search (MCTS) has emerged as a powerful tool for\ndecision-making in robotics, enabling efficient exploration of large search\nspaces. However, traditional MCTS methods struggle in environments\ncharacterized by high uncertainty and noisy data due to their reliance on\nfinal-step reward evaluation. The lack of intermediate feedback during search\noften results in suboptimal decision-making and computational inefficiencies.\n  This paper introduces Reward-Centered ReST-MCTS, a novel framework that\nenhances MCTS by incorporating intermediate reward shaping. The core of our\napproach is the Rewarding Center, which refines search trajectories by\ndynamically assigning partial rewards using rule-based validation, heuristic\nguidance, and neural estimation. By integrating these mechanisms, our method\nenables real-time optimization of search paths, mitigating the effects of error\npropagation.\n  We evaluate Reward-Centered ReST-MCTS in robotic manipulation tasks under\nhigh uncertainty, demonstrating consistent improvements in decision accuracy.\nCompared to baseline methods, including Chain-of-Thought (CoT) prompting and\nVanilla ReST-MCTS, our framework achieves a 2-4% accuracy improvement while\nmaintaining computational feasibility. Ablation studies confirm the\neffectiveness of intermediate feedback in search refinement, particularly in\npruning incorrect decision paths early. Furthermore, robustness tests show that\nour method retains high performance across varying levels of uncertainty.\n","authors":["Xibai Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05224v1","updated":"2025-03-07T08:22:50Z","published":"2025-03-07T08:22:50Z","title":"Deep Sequence Models for Predicting Average Shear Wave Velocity from\n  Strong Motion Records","summary":"  This study explores the use of deep learning for predicting the time averaged\nshear wave velocity in the top 30 m of the subsurface ($V_{s30}$) at strong\nmotion recording stations in T\\\"urkiye. $V_{s30}$ is a key parameter in site\ncharacterization and, as a result for seismic hazard assessment. However, it is\noften unavailable due to the lack of direct measurements and is therefore\nestimated using empirical correlations. Such correlations however are commonly\ninadequate in capturing complex, site-specific variability and this motivates\nthe need for data-driven approaches. In this study, we employ a hybrid deep\nlearning model combining convolutional neural networks (CNNs) and long\nshort-term memory (LSTM) networks to capture both spatial and temporal\ndependencies in strong motion records. Furthermore, we explore how using\ndifferent parts of the signal influence our deep learning model. Our results\nsuggest that the hybrid approach effectively learns complex, nonlinear\nrelationships within seismic signals. We observed that an improved P-wave\narrival time model increased the prediction accuracy of $V_{s30}$. We believe\nthe study provides valuable insights into improving $V_{s30}$ predictions using\na CNN-LSTM framework, demonstrating its potential for improving site\ncharacterization for seismic studies. Our codes are available via this repo:\nhttps://github.com/brsylmz23/CNNLSTM_DeepEQ\n","authors":["Baris Yilmaz","Erdem Akagündüz","Salih Tileylioglu"],"pdf_url":"https://arxiv.org/pdf/2503.05224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20224v2","updated":"2025-03-07T08:17:31Z","published":"2025-02-27T16:06:57Z","title":"RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema\n  Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head\n  Clustering","summary":"  Diabetic Macular Edema (DME), a prevalent complication among diabetic\npatients, constitutes a major cause of visual impairment and blindness.\nAlthough deep learning has achieved remarkable progress in medical image\nanalysis, traditional DME diagnosis still relies on extensive annotated data\nand subjective ophthalmologist assessments, limiting practical applications. To\naddress this, we present RURANET++, an unsupervised learning-based automated\nDME diagnostic system. This framework incorporates an optimized U-Net\narchitecture with embedded Spatial and Channel Squeeze & Excitation (SCSE)\nattention mechanisms to enhance lesion feature extraction. During feature\nprocessing, a pre-trained GoogLeNet model extracts deep features from retinal\nimages, followed by PCA-based dimensionality reduction to 50 dimensions for\ncomputational efficiency. Notably, we introduce a novel clustering algorithm\nemploying multi-projection heads to explicitly control cluster diversity while\ndynamically adjusting similarity thresholds, thereby optimizing intra-class\nconsistency and inter-class discrimination. Experimental results demonstrate\nsuperior performance across multiple metrics, achieving maximum accuracy\n(0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), with\nexceptional clustering quality. This work provides an efficient unsupervised\nsolution for DME diagnosis with significant clinical implications.\n","authors":["Wei Yang","Yiran Zhu","Jiayu Shen","Yuhan Tang","Chengchang Pan","Hui He","Yan Su","Honggang Qi"],"pdf_url":"https://arxiv.org/pdf/2502.20224v2.pdf","comment":"10 pages, 2 figures, 5 tables, submitted to The 28th International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI 2025)"},{"id":"http://arxiv.org/abs/2503.03796v2","updated":"2025-03-07T08:06:15Z","published":"2025-03-05T14:33:18Z","title":"Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent\n  Reinforcement Learning in USV Swarm","summary":"  Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.\n","authors":["Hyeonjun Kim","Kanghoon Lee","Junho Park","Jiachen Li","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2503.03796v2.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05212v1","updated":"2025-03-07T08:04:25Z","published":"2025-03-07T08:04:25Z","title":"Knowledge Updating? No More Model Editing! Just Selective Contextual\n  Reasoning","summary":"  As real-world knowledge evolves, the information embedded within large\nlanguage models (LLMs) can become outdated, inadequate, or erroneous. Model\nediting has emerged as a prominent approach for updating LLMs' knowledge with\nminimal computational costs and parameter changes. This approach typically\nidentifies and adjusts specific model parameters associated with newly acquired\nknowledge. However, existing methods often underestimate the adverse effects\nthat parameter modifications can have on broadly distributed knowledge. More\ncritically, post-edit LLMs frequently struggle with multi-hop reasoning and\ncontinuous knowledge updates. Although various studies have discussed these\nshortcomings, there is a lack of comprehensive evaluation. In this paper, we\nprovide an evaluation of ten model editing methods along four dimensions:\nreliability, generalization, locality, and portability. Results confirm that\nall ten popular model editing methods show significant shortcomings across\nmultiple dimensions, suggesting model editing is less promising. We then\npropose a straightforward method called Selective Contextual Reasoning (SCR),\nfor knowledge updating. SCR does not modify model parameters but harnesses\nLLM's inherent contextual reasoning capabilities utilizing the updated\nknowledge pieces. Under SCR, an LLM first assesses whether an incoming query\nfalls within the scope of an external knowledge base. If it does, the relevant\nexternal knowledge texts are contextualized to enhance reasoning; otherwise,\nthe query is answered directly. We evaluate SCR against the ten model editing\nmethods on two counterfactual datasets with three backbone LLMs. Empirical\nresults confirm the effectiveness and efficiency of contextual reasoning for\nknowledge updating.\n","authors":["Guoxiu He","Xin Song","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2503.05212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05207v1","updated":"2025-03-07T07:55:51Z","published":"2025-03-07T07:55:51Z","title":"Policy Constraint by Only Support Constraint for Offline Reinforcement\n  Learning","summary":"  Offline reinforcement learning (RL) aims to optimize a policy by using\npre-collected datasets, to maximize cumulative rewards. However, offline\nreinforcement learning suffers challenges due to the distributional shift\nbetween the learned and behavior policies, leading to errors when computing\nQ-values for out-of-distribution (OOD) actions. To mitigate this issue, policy\nconstraint methods aim to constrain the learned policy's distribution with the\ndistribution of the behavior policy or confine action selection within the\nsupport of the behavior policy. However, current policy constraint methods tend\nto exhibit excessive conservatism, hindering the policy from further surpassing\nthe behavior policy's performance. In this work, we present Only Support\nConstraint (OSC) which is derived from maximizing the total probability of\nlearned policy in the support of behavior policy, to address the conservatism\nof policy constraint. OSC presents a regularization term that only restricts\npolicies to the support without imposing extra constraints on actions within\nthe support. Additionally, to fully harness the performance of the new policy\nconstraints, OSC utilizes a diffusion model to effectively characterize the\nsupport of behavior policies. Experimental evaluations across a variety of\noffline RL benchmarks demonstrate that OSC significantly enhances performance,\nalleviating the challenges associated with distributional shifts and mitigating\nconservatism of policy constraints. Code is available at\nhttps://github.com/MoreanP/OSC.\n","authors":["Yunkai Gao","Jiaming Guo","Fan Wu","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15830v4","updated":"2025-03-07T07:53:04Z","published":"2025-01-27T07:34:33Z","title":"SpatialVLA: Exploring Spatial Representations for Visual-Language-Action\n  Model","summary":"  In this paper, we claim that spatial understanding is the keypoint in robot\nmanipulation, and propose SpatialVLA to explore effective spatial\nrepresentations for the robot foundation model. Specifically, we introduce\nEgo3D Position Encoding to inject 3D information into the input observations of\nthe visual-language-action model, and propose Adaptive Action Grids to\nrepresent spatial robot movement actions with adaptive discretized action\ngrids, facilitating learning generalizable and transferrable spatial action\nknowledge for cross-robot control. SpatialVLA is first pre-trained on top of a\nvision-language model with 1.1 Million real-world robot episodes, to learn a\ngeneralist manipulation policy across multiple robot environments and tasks.\nAfter pre-training, SpatialVLA is directly applied to perform numerous tasks in\na zero-shot manner. The superior results in both simulation and real-world\nrobots demonstrate its advantage of inferring complex robot motion trajectories\nand its strong in-domain multi-task generalization ability. We further show the\nproposed Adaptive Action Grids offer a new and effective way to fine-tune the\npre-trained SpatialVLA model for new simulation and real-world setups, where\nthe pre-learned action grids are re-discretized to capture robot-specific\nspatial action movements of new setups. The superior results from extensive\nevaluations demonstrate the exceptional in-distribution generalization and\nout-of-distribution adaptation capability, highlighting the crucial benefit of\nthe proposed spatial-aware representations for generalist robot policy\nlearning. All the details and codes will be open-sourced.\n","authors":["Delin Qu","Haoming Song","Qizhi Chen","Yuanqi Yao","Xinyi Ye","Yan Ding","Zhigang Wang","JiaYuan Gu","Bin Zhao","Dong Wang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2501.15830v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05203v1","updated":"2025-03-07T07:48:30Z","published":"2025-03-07T07:48:30Z","title":"Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge\n  Graph Retrieval-Augmented Generation","summary":"  Although Large Language Models achieve strong success in many tasks, they\nstill suffer from hallucinations and knowledge deficiencies in real-world\napplications. Many knowledge graph-based retrieval-augmented generation\n(KG-RAG) methods enhance the quality and credibility of LLMs by leveraging\nstructure and semantic information in KGs as external knowledge bases. However,\nthese methods struggle to effectively incorporate structure information, either\nincurring high computational costs or underutilizing available knowledge.\nInspired by smoothing operations in graph representation learning, we propose\npath pooling, a simple, train-free strategy that introduces structure\ninformation through a novel path-centric pooling operation. It seamlessly\nintegrates into existing KG-RAG methods in a plug-and-play manner, enabling\nricher structure information utilization. Extensive experiments demonstrate\nthat incorporating the path pooling into the state-of-the-art KG-RAG method\nconsistently improves performance across various settings while introducing\nnegligible additional cost. Code is coming soon at\nhttps://github.com/hrwang00/path-pooling.\n","authors":["Hairu Wang","Yuan Feng","Xike Xie","S Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05201v1","updated":"2025-03-07T07:46:26Z","published":"2025-03-07T07:46:26Z","title":"Deep Muscle EMG construction using A Physics-Integrated Deep Learning\n  approach","summary":"  Electromyography (EMG)--based computational musculoskeletal modeling is a\nnon-invasive method for studying musculotendon function, human movement, and\nneuromuscular control, providing estimates of internal variables like muscle\nforces and joint torques. However, EMG signals from deeper muscles are often\nchallenging to measure by placing the surface EMG electrodes and unfeasible to\nmeasure directly using invasive methods. The restriction to the access of EMG\ndata from deeper muscles poses a considerable obstacle to the broad adoption of\nEMG-driven modeling techniques. A strategic alternative is to use an estimation\nalgorithm to approximate the missing EMG signals from deeper muscle. A similar\nstrategy is used in physics-informed deep learning, where the features of\nphysical systems are learned without labeled data. In this work, we propose a\nhybrid deep learning algorithm, namely the neural musculoskeletal model (NMM),\nthat integrates physics-informed and data-driven deep learning to approximate\nthe EMG signals from the deeper muscles. While data-driven modeling is used to\npredict the missing EMG signals, physics-based modeling engraves the\nsubject-specific information into the predictions. Experimental verifications\non five test subjects are carried out to investigate the performance of the\nproposed hybrid framework. The proposed NMM is validated against the joint\ntorque computed from 'OpenSim' software. The predicted deep EMG signals are\nalso compared against the state-of-the-art muscle synergy extrapolation (MSE)\napproach, where the proposed NMM completely outperforms the existing MSE\nframework by a significant margin.\n","authors":["Rajnish Kumar","Tapas Tripura","Souvik Chakraborty","Sitikantha Roy"],"pdf_url":"https://arxiv.org/pdf/2503.05201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05194v1","updated":"2025-03-07T07:29:48Z","published":"2025-03-07T07:29:48Z","title":"Uncertainty-Aware Explainable Federated Learning","summary":"  Federated Learning (FL) is a collaborative machine learning paradigm for\nenhancing data privacy preservation. Its privacy-preserving nature complicates\nthe explanation of the decision-making processes and the evaluation of the\nreliability of the generated explanations. In this paper, we propose the\nUncertainty-aware eXplainable Federated Learning (UncertainXFL) to address\nthese challenges. It generates explanations for decision-making processes under\nFL settings and provides information regarding the uncertainty of these\nexplanations. UncertainXFL is the first framework to explicitly offer\nuncertainty evaluation for explanations within the FL context. Explanatory\ninformation is initially generated by the FL clients and then aggregated by the\nserver in a comprehensive and conflict-free manner during FL training. The\nquality of the explanations, including the uncertainty score and tested\nvalidity, guides the FL training process by prioritizing clients with the most\nreliable explanations through higher weights during model aggregation.\nExtensive experimental evaluation results demonstrate that UncertainXFL\nachieves superior model accuracy and explanation accuracy, surpassing the\ncurrent state-of-the-art model that does not incorporate uncertainty\ninformation by 2.71% and 1.77%, respectively. By integrating and quantifying\nuncertainty in the data into the explanation process, UncertainXFL not only\nclearly presents the explanation alongside its uncertainty, but also leverages\nthis uncertainty to guide the FL training process, thereby enhancing the\nrobustness and reliability of the resulting models.\n","authors":["Yanci Zhang","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2503.05194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16927v2","updated":"2025-03-07T07:28:39Z","published":"2025-02-24T07:37:29Z","title":"BigMac: A Communication-Efficient Mixture-of-Experts Model Structure for\n  Fast Training and Inference","summary":"  The Mixture-of-Experts (MoE) structure scales the Transformer-based large\nlanguage models (LLMs) and improves their performance with only the sub-linear\nincrease in computation resources. Recently, a fine-grained DeepSeekMoE\nstructure is proposed, which can further improve the computing efficiency of\nMoE without performance degradation. However, the All-to-All communication\nintroduced by MoE has become a bottleneck, especially for the fine-grained\nstructure, which typically involves and activates more experts, hence\ncontributing to heavier communication overhead.\n  In this paper, we propose a novel MoE structure named BigMac, which is also\nfine-grained but with high communication efficiency. The innovation of BigMac\nis mainly due to that we abandon the\n\\textbf{c}ommunicate-\\textbf{d}escend-\\textbf{a}scend-\\textbf{c}ommunicate\n(CDAC) manner used by fine-grained MoE, which leads to the All-to-All\ncommunication always taking place at the highest dimension. Instead, BigMac\ndesigns an efficient\n\\textbf{d}escend-\\textbf{c}ommunicate-\\textbf{c}ommunicate-\\textbf{a}scend\n(DCCA) manner. Specifically, we add a descending and ascending projection at\nthe entrance and exit of the expert, respectively, which enables the\ncommunication to perform at a very low dimension. Furthermore, to adapt to\nDCCA, we re-design the structure of small experts, ensuring that the expert in\nBigMac has enough complexity to address tokens. Experimental results show that\nBigMac achieves comparable or even better model quality than fine-grained MoEs\nwith the same number of experts and a similar number of total parameters.\nEqually importantly, BigMac reduces the end-to-end latency by up to\n3.09$\\times$ for training and increases the throughput by up to 3.11$\\times$\nfor inference on state-of-the-art AI computing frameworks including Megatron,\nTutel, and DeepSpeed-Inference.\n","authors":["Zewen Jin","Shengnan Wang","Jiaan Zhu","Hongrui Zhan","Youhui Bai","Lin Zhang","Zhenyu Ming","Cheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.16927v2.pdf","comment":"Typo Fixed"},{"id":"http://arxiv.org/abs/2402.00389v4","updated":"2025-03-07T07:23:30Z","published":"2024-02-01T07:21:32Z","title":"On the $O(\\frac{\\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its\n  Momentum Extension Measured by $\\ell_1$ Norm","summary":"  Although adaptive gradient methods have been extensively used in deep\nlearning, their convergence rates proved in the literature are all slower than\nthat of SGD, particularly with respect to their dependence on the dimension.\nThis paper considers the classical RMSProp and its momentum extension and\nestablishes the convergence rate of $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla\nf(x^k)\\|_1\\right]\\leq O(\\frac{\\sqrt{d}C}{T^{1/4}})$ measured by $\\ell_1$ norm\nwithout the bounded gradient assumption, where $d$ is the dimension of the\noptimization variable, $T$ is the iteration number, and $C$ is a constant\nidentical to that appeared in the optimal convergence rate of SGD. Our\nconvergence rate matches the lower bound with respect to all the coefficients\nexcept the dimension $d$. Since $\\|x\\|_2\\ll\\|x\\|_1\\leq\\sqrt{d}\\|x\\|_2$ for\nproblems with extremely large $d$, our convergence rate can be considered to be\nanalogous to the $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla f(x^k)\\|_2\\right]\\leq\nO(\\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\\|\\nabla\nf(x)\\|_1=\\varTheta(\\sqrt{d}\\|\\nabla f(x)\\|_2)$.\n","authors":["Huan Li","Yiming Dong","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2402.00389v4.pdf","comment":"V4 vs V3: More experiments. V3 vs V2: A fairer comparison with (Li et\n  al., 2023). V2 vs V1: (1) Correct one error in v1. (2) Improve the\n  convergence rate matching the lower bound with respect to all the\n  coefficients except the dimension"},{"id":"http://arxiv.org/abs/2503.05188v1","updated":"2025-03-07T07:20:24Z","published":"2025-03-07T07:20:24Z","title":"Rewarding Curse: Analyze and Mitigate Reward Modeling Issues for LLM\n  Reasoning","summary":"  Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.\n","authors":["Jiachun Li","Pengfei Cao","Yubo Chen","Jiexin Xu","Huaijun Li","Xiaojian Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05188v1.pdf","comment":"18 pages, 21 figures"},{"id":"http://arxiv.org/abs/2503.05185v1","updated":"2025-03-07T07:13:59Z","published":"2025-03-07T07:13:59Z","title":"FinTMMBench: Benchmarking Temporal-Aware Multi-Modal RAG in Finance","summary":"  Finance decision-making often relies on in-depth data analysis across various\ndata sources, including financial tables, news articles, stock prices, etc. In\nthis work, we introduce FinTMMBench, the first comprehensive benchmark for\nevaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG)\nsystems in finance. Built from heterologous data of NASDAQ 100 companies,\nFinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It\nencompasses a hybrid of financial tables, news articles, daily stock prices,\nand visual technical charts as the corpus. 2) Temporal-aware Questions: Each\nquestion requires the retrieval and interpretation of its relevant data over a\nspecific time period, including daily, weekly, monthly, quarterly, and annual\nperiods. 3) Diverse Financial Analysis Tasks: The questions involve 10\ndifferent tasks, including information extraction, trend analysis, sentiment\nanalysis and event detection, etc. We further propose a novel TMMHybridRAG\nmethod, which first leverages LLMs to convert data from other modalities (e.g.,\ntabular, visual and time-series data) into textual format and then incorporates\ntemporal information in each node when constructing graphs and dense indexes.\nIts effectiveness has been validated in extensive experiments, but notable gaps\nremain, highlighting the challenges presented by our FinTMMBench.\n","authors":["Fengbin Zhu","Junfeng Li","Liangming Pan","Wenjie Wang","Fuli Feng","Chao Wang","Huanbo Luan","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.05185v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.05179v1","updated":"2025-03-07T06:57:17Z","published":"2025-03-07T06:57:17Z","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching","summary":"  Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.\n","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11142v3","updated":"2025-03-07T06:06:29Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05164v1","updated":"2025-03-07T06:03:02Z","published":"2025-03-07T06:03:02Z","title":"A Comprehensive LLM-powered Framework for Driving Intelligence\n  Evaluation","summary":"  Evaluation methods for autonomous driving are crucial for algorithm\noptimization. However, due to the complexity of driving intelligence, there is\ncurrently no comprehensive evaluation method for the level of autonomous\ndriving intelligence. In this paper, we propose an evaluation framework for\ndriving behavior intelligence in complex traffic environments, aiming to fill\nthis gap. We constructed a natural language evaluation dataset of human\nprofessional drivers and passengers through naturalistic driving experiments\nand post-driving behavior evaluation interviews. Based on this dataset, we\ndeveloped an LLM-powered driving evaluation framework. The effectiveness of\nthis framework was validated through simulated experiments in the CARLA urban\ntraffic simulator and further corroborated by human assessment. Our research\nprovides valuable insights for evaluating and designing more intelligent,\nhuman-like autonomous driving agents. The implementation details of the\nframework and detailed information about the dataset can be found at Github.\n","authors":["Shanhe You","Xuewen Luo","Xinhe Liang","Jiashu Yu","Chen Zheng","Jiangtao Gong"],"pdf_url":"https://arxiv.org/pdf/2503.05164v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.12282v2","updated":"2025-03-07T05:47:20Z","published":"2024-07-17T03:02:24Z","title":"Chip Placement with Diffusion Models","summary":"  Macro placement is a vital step in digital circuit design that defines the\nphysical location of large collections of components, known as macros, on a 2D\nchip. Because key performance metrics of the chip are determined by the\nplacement, optimizing it is crucial. Existing learning-based methods typically\nfall short because of their reliance on reinforcement learning (RL), which is\nslow and struggles to generalize, requiring online training on each new\ncircuit. Instead, we train a diffusion model capable of placing new circuits\nzero-shot, using guided sampling in lieu of RL to optimize placement quality.\nTo enable such models to train at scale, we designed a capable yet efficient\narchitecture for the denoising model, and propose a novel algorithm to generate\nlarge synthetic datasets for pre-training. To allow zero-shot transfer to real\ncircuits, we empirically study the design decisions of our dataset generation\nalgorithm, and identify several key factors enabling generalization. When\ntrained on our synthetic data, our models generate high-quality placements on\nunseen, realistic circuits, achieving competitive performance on placement\nbenchmarks compared to state-of-the-art methods.\n","authors":["Vint Lee","Minh Nguyen","Leena Elzeiny","Chun Deng","Pieter Abbeel","John Wawrzynek"],"pdf_url":"https://arxiv.org/pdf/2407.12282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13979v2","updated":"2025-03-07T05:39:48Z","published":"2024-10-17T19:14:43Z","title":"RecoveryChaining: Learning Local Recovery Policies for Robust\n  Manipulation","summary":"  Model-based planners and controllers are commonly used to solve complex\nmanipulation problems as they can efficiently optimize diverse objectives and\ngeneralize to long horizon tasks. However, they often fail during deployment\ndue to noisy actuation, partial observability and imperfect models. To enable a\nrobot to recover from such failures, we propose to use hierarchical\nreinforcement learning to learn a recovery policy. The recovery policy is\ntriggered when a failure is detected based on sensory observations and seeks to\ntake the robot to a state from which it can complete the task using the nominal\nmodel-based controllers. Our approach, called RecoveryChaining, uses a hybrid\naction space, where the model-based controllers are provided as additional\n\\emph{nominal} options which allows the recovery policy to decide how to\nrecover, when to switch to a nominal controller and which controller to switch\nto even with \\emph{sparse rewards}. We evaluate our approach in three\nmulti-step manipulation tasks with sparse rewards, where it learns\nsignificantly more robust recovery policies than those learned by baselines. We\nsuccessfully transfer recovery policies learned in simulation to a physical\nrobot to demonstrate the feasibility of sim-to-real transfer with our method.\n","authors":["Shivam Vats","Devesh K. Jha","Maxim Likhachev","Oliver Kroemer","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2410.13979v2.pdf","comment":"Added Lazy RecoveryChaining algorithm. 8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.00691v2","updated":"2025-03-07T05:38:47Z","published":"2025-03-02T02:04:58Z","title":"How Diversely Can Language Models Solve Problems? Exploring the\n  Algorithmic Diversity of Model-Generated Code","summary":"  Language models (LMs) have exhibited impressive abilities in generating code\nfrom natural language requirements. In this work, we highlight the diversity of\ncode generated by LMs as a critical criterion for evaluating their code\ngeneration capabilities. There is a lack of studies focused on assessing the\ndiversity of generated code, which overlooks its importance in code LMs.\nTherefore, we propose a systematic approach to evaluate code diversity,\nintroducing various metrics with inter-code similarity. Specifically, we\nintroduce code clustering methods that leverages LMs' capabilities in code\nunderstanding and reasoning, resulting in a set of metrics that represent the\nnumber of algorithms in model-generated solutions. We extensively investigate\nthe property of model-generated solutions by contrasting them with\nhuman-written ones and quantifying the impact of various factors on code\ndiversity: model size, temperature, instruction tuning, and problem complexity.\nOur analysis demonstrates that model-generated solutions exhibit low\nalgorithmic diversity, which was neglected by the research community. Moreover,\nwe explore methods to increase code diversity by combining solutions from\ndifferent models and increasing sampling temperatures. Our findings highlight\nthat code diversity can be enhanced with the help of heterogeneous models and\nsetting temperature beyond 1.0 that has not been fully explored due to the\nfunctional correctness degradation. To facilitate our research direction, we\npublicly share our code and datasets through open-source repositories.\n","authors":["Seonghyeon Lee","Heejae Chon","Joonwon Jang","Dongha Lee","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2503.00691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10510v3","updated":"2025-03-07T05:29:18Z","published":"2024-01-19T05:58:30Z","title":"When Large Language Models Meet Evolutionary Algorithms: Potential\n  Enhancements and Challenges","summary":"  Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.\n","authors":["Chao Wang","Jiaxuan Zhao","Licheng Jiao","Lingling Li","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2401.10510v3.pdf","comment":"The article has been accepted for publication in Research"},{"id":"http://arxiv.org/abs/2503.05153v1","updated":"2025-03-07T05:22:52Z","published":"2025-03-07T05:22:52Z","title":"Generative Trajectory Stitching through Diffusion Composition","summary":"  Effective trajectory stitching for long-horizon planning is a significant\nchallenge in robotic decision-making. While diffusion models have shown promise\nin planning, they are limited to solving tasks similar to those seen in their\ntraining data. We propose CompDiffuser, a novel generative approach that can\nsolve new tasks by learning to compositionally stitch together shorter\ntrajectory chunks from previously seen tasks. Our key insight is modeling the\ntrajectory distribution by subdividing it into overlapping chunks and learning\ntheir conditional relationships through a single bidirectional diffusion model.\nThis allows information to propagate between segments during generation,\nensuring physically consistent connections. We conduct experiments on benchmark\ntasks of various difficulties, covering different environment sizes, agent\nstate dimension, trajectory types, training data quality, and show that\nCompDiffuser significantly outperforms existing methods.\n","authors":["Yunhao Luo","Utkarsh A. Mishra","Yilun Du","Danfei Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05153v1.pdf","comment":"Project page: https://comp-diffuser.github.io/"},{"id":"http://arxiv.org/abs/2503.04095v2","updated":"2025-03-07T05:18:44Z","published":"2025-03-06T05:08:40Z","title":"Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts","summary":"  Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.\n","authors":["Xiangnan Chen","Yuancheng Fang","Qian Xiao","Juncheng Li","Jun Lin","Siliang Tang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.04095v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.05149v1","updated":"2025-03-07T05:18:00Z","published":"2025-03-07T05:18:00Z","title":"Development and Enhancement of Text-to-Image Diffusion Models","summary":"  This research focuses on the development and enhancement of text-to-image\ndenoising diffusion models, addressing key challenges such as limited sample\ndiversity and training instability. By incorporating Classifier-Free Guidance\n(CFG) and Exponential Moving Average (EMA) techniques, this study significantly\nimproves image quality, diversity, and stability. Utilizing Hugging Face's\nstate-of-the-art text-to-image generation model, the proposed enhancements\nestablish new benchmarks in generative AI. This work explores the underlying\nprinciples of diffusion models, implements advanced strategies to overcome\nexisting limitations, and presents a comprehensive evaluation of the\nimprovements achieved. Results demonstrate substantial progress in generating\nstable, diverse, and high-quality images from textual descriptions, advancing\nthe field of generative artificial intelligence and providing new foundations\nfor future applications.\n  Keywords: Text-to-image, Diffusion model, Classifier-free guidance,\nExponential moving average, Image generation.\n","authors":["Rajdeep Roshan Sahu"],"pdf_url":"https://arxiv.org/pdf/2503.05149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10220v2","updated":"2025-03-07T05:09:28Z","published":"2024-04-16T02:01:56Z","title":"Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V","summary":"  Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.\n","authors":["Peiyuan Zhi","Zhiyuan Zhang","Yu Zhao","Muzhi Han","Zeyu Zhang","Zhitian Li","Ziyuan Jiao","Baoxiong Jia","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2404.10220v2.pdf","comment":"6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/"},{"id":"http://arxiv.org/abs/2503.05143v1","updated":"2025-03-07T04:52:20Z","published":"2025-03-07T04:52:20Z","title":"FedMABench: Benchmarking Mobile Agents on Decentralized Heterogeneous\n  User Data","summary":"  Mobile agents have attracted tremendous research participation recently.\nTraditional approaches to mobile agent training rely on centralized data\ncollection, leading to high cost and limited scalability. Distributed training\nutilizing federated learning offers an alternative by harnessing real-world\nuser data, providing scalability and reducing costs. However, pivotal\nchallenges, including the absence of standardized benchmarks, hinder progress\nin this field.\n  To tackle the challenges, we introduce FedMABench, the first benchmark for\nfederated training and evaluation of mobile agents, specifically designed for\nheterogeneous scenarios. FedMABench features 6 datasets with 30+ subsets, 8\nfederated algorithms, 10+ base models, and over 800 apps across 5 categories,\nproviding a comprehensive framework for evaluating mobile agents across diverse\nenvironments. Through extensive experiments, we uncover several key insights:\nfederated algorithms consistently outperform local training; the distribution\nof specific apps plays a crucial role in heterogeneity; and, even apps from\ndistinct categories can exhibit correlations during training. FedMABench is\npublicly available at: https://github.com/wwh0411/FedMABench with the datasets\nat: https://huggingface.co/datasets/wwh0411/FedMABench.\n","authors":["Wenhao Wang","Zijie Yu","Rui Ye","Jianqing Zhang","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05139v1","updated":"2025-03-07T04:43:39Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2409.11283v4","updated":"2025-03-07T04:29:19Z","published":"2024-09-17T15:38:36Z","title":"Zero-resource Hallucination Detection for Text Generation via\n  Graph-based Contextual Knowledge Triples Modeling","summary":"  LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.\n","authors":["Xinyue Fang","Zhen Huang","Zhiliang Tian","Minghui Fang","Ziyi Pan","Quntian Fang","Zhihua Wen","Hengyue Pan","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2409.11283v4.pdf","comment":"Accepted by AAAI25"},{"id":"http://arxiv.org/abs/2503.05132v1","updated":"2025-03-07T04:21:47Z","published":"2025-03-07T04:21:47Z","title":"R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT Model","summary":"  Recently DeepSeek R1 demonstrated how reinforcement learning with simple\nrule-based incentives can enable autonomous development of complex reasoning in\nlarge language models, characterized by the \"aha moment\", in which the model\nmanifest self-reflection and increased response length during training.\nHowever, attempts to extend this success to multimodal reasoning often failed\nto reproduce these key characteristics. In this report, we present the first\nsuccessful replication of these emergent characteristics for multimodal\nreasoning on only a non-SFT 2B model. Starting with Qwen2-VL-2B and applying\nreinforcement learning directly on the SAT dataset, our model achieves 59.47%\naccuracy on CVBench, outperforming the base model by approximately ~30% and\nexceeding both SFT setting by ~2%. In addition, we share our failed attempts\nand insights in attempting to achieve R1-like reasoning using RL with instruct\nmodels. aiming to shed light on the challenges involved. Our key observations\ninclude: (1) applying RL on instruct model often results in trivial reasoning\ntrajectories, and (2) naive length reward are ineffective in eliciting\nreasoning capabilities. The project code is available at\nhttps://github.com/turningpoint-ai/VisualThinker-R1-Zero\n","authors":["Hengguang Zhou","Xirui Li","Ruochen Wang","Minhao Cheng","Tianyi Zhou","Cho-Jui Hsieh"],"pdf_url":"https://arxiv.org/pdf/2503.05132v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.05127v1","updated":"2025-03-07T04:18:55Z","published":"2025-03-07T04:18:55Z","title":"HexPlane Representation for 3D Semantic Scene Understanding","summary":"  In this paper, we introduce the HexPlane representation for 3D semantic scene\nunderstanding. Specifically, we first design the View Projection Module (VPM)\nto project the 3D point cloud into six planes to maximally retain the original\nspatial information. Features of six planes are extracted by the 2D encoder and\nsent to the HexPlane Association Module (HAM) to adaptively fuse the most\ninformative information for each point. The fused point features are further\nfed to the task head to yield the ultimate predictions. Compared to the popular\npoint and voxel representation, the HexPlane representation is efficient and\ncan utilize highly optimized 2D operations to process sparse and unordered 3D\npoint clouds. It can also leverage off-the-shelf 2D models, network weights,\nand training recipes to achieve accurate scene understanding in 3D space. On\nScanNet and SemanticKITTI benchmarks, our algorithm, dubbed HexNet3D, achieves\ncompetitive performance with previous algorithms. In particular, on the ScanNet\n3D segmentation task, our method obtains 77.0 mIoU on the validation set,\nsurpassing Point Transformer V2 by 1.6 mIoU. We also observe encouraging\nresults in indoor 3D detection tasks. Note that our method can be seamlessly\nintegrated into existing voxel-based, point-based, and range-based approaches\nand brings considerable gains without bells and whistles. The codes will be\navailable upon publication.\n","authors":["Zeren Chen","Yuenan Hou","Yulin Chen","Li Liu","Xiao Sun","Lu Sheng"],"pdf_url":"https://arxiv.org/pdf/2503.05127v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2408.05842v5","updated":"2025-03-07T04:13:19Z","published":"2024-08-11T18:32:29Z","title":"Open Role-Playing with Delta-Engines","summary":"  Game roles can be reflections of personas from a parallel world. In this\npaper, we propose a new style of game-play to bridge self-expression and\nrole-playing: \\emph{open role-playing games (ORPGs)}, where players are allowed\nto craft and embody their unique characters in the game world. Our vision is\nthat, in the real world, we are individually similar when we are born, but we\ngrow into unique ones as a result of the strongly different choices we make\nafterward. Therefore, in an ORPG, we empower players with freedom to decide\ntheir own growing curves through natural language inputs, ultimately becoming\nunique characters. To technically do this, we propose a special engine called\nDelta-Engine. This engine is not a traditional game engine used for game\ndevelopment, but serves as an in-game module to provide new game-play\nexperiences. A delta-engine consists of two components, a base engine and a\nneural proxy. The base engine programs the prototype of the character as well\nas the foundational settings of the game; the neural proxy is an LLM, which\nrealizes the character growth by generating new code snippets on the base\nengine incrementally. In this paper, we self-develop a specific ORPG based on\ndelta-engines. It is adapted from the popular animated series ``Pok\\'emon''. We\npresent our efforts in generating out-of-domain and interesting role data in\nthe development process as well as accessing the performance of a delta-engine.\nWhile the empirical results in this work are specific, we aim for them to\nprovide general insights for future games.\n","authors":["Hongqiu Wu","Zekai Xu","Tianyang Xu","Shize Wei","Yan Wang","Jiale Hong","Weiqi Wu","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.05842v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05126v1","updated":"2025-03-07T04:13:02Z","published":"2025-03-07T04:13:02Z","title":"Multi-Task Reinforcement Learning Enables Parameter Scaling","summary":"  Multi-task reinforcement learning (MTRL) aims to endow a single agent with\nthe ability to perform well on multiple tasks. Recent works have focused on\ndeveloping novel sophisticated architectures to improve performance, often\nresulting in larger models; it is unclear, however, whether the performance\ngains are a consequence of the architecture design itself or the extra\nparameters. We argue that gains are mostly due to scale by demonstrating that\nnaively scaling up a simple MTRL baseline to match parameter counts outperforms\nthe more sophisticated architectures, and these gains benefit most from scaling\nthe critic over the actor. Additionally, we explore the training stability\nadvantages that come with task diversity, demonstrating that increasing the\nnumber of tasks can help mitigate plasticity loss. Our findings suggest that\nMTRL's simultaneous training across multiple tasks provides a natural framework\nfor beneficial parameter scaling in reinforcement learning, challenging the\nneed for complex architectural innovations.\n","authors":["Reginald McLean","Evangelos Chataroulas","Jordan Terry","Isaac Woungang","Nariman Farsad","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2503.05126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10340v5","updated":"2025-03-07T04:01:59Z","published":"2024-02-15T22:01:45Z","title":"On the Vulnerability of LLM/VLM-Controlled Robotics","summary":"  In this work, we highlight vulnerabilities in robotic systems integrating\nlarge language models (LLMs) and vision-language models (VLMs) due to input\nmodality sensitivities. While LLM/VLM-controlled robots show impressive\nperformance across various tasks, their reliability under slight input\nvariations remains underexplored yet critical. These models are highly\nsensitive to instruction or perceptual input changes, which can trigger\nmisalignment issues, leading to execution failures with severe real-world\nconsequences. To study this issue, we analyze the misalignment-induced\nvulnerabilities within LLM/VLM-controlled robotic systems and present a\nmathematical formulation for failure modes arising from variations in input\nmodalities. We propose empirical perturbation strategies to expose these\nvulnerabilities and validate their effectiveness through experiments on\nmultiple robot manipulation tasks. Our results show that simple input\nperturbations reduce task execution success rates by 22.2% and 14.6% in two\nrepresentative LLM/VLM-controlled robotic systems. These findings underscore\nthe importance of input modality robustness and motivate further research to\nensure the safe and reliable deployment of advanced LLM/VLM-controlled robotic\nsystems.\n","authors":["Xiyang Wu","Souradip Chakraborty","Ruiqi Xian","Jing Liang","Tianrui Guan","Fuxiao Liu","Brian M. Sadler","Dinesh Manocha","Amrit Singh Bedi"],"pdf_url":"https://arxiv.org/pdf/2402.10340v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01062v2","updated":"2025-03-07T03:58:14Z","published":"2025-03-02T23:52:46Z","title":"SFO: Piloting VLM Feedback for Offline RL","summary":"  While internet-scale image and textual data have enabled strong\ngeneralization in Vision-Language Models (VLMs), the absence of internet-scale\ncontrol data has impeded the development of similar generalization in standard\nreinforcement learning (RL) agents. Although VLMs are fundamentally limited in\ntheir ability to solve control tasks due to their lack of action-conditioned\ntraining data, their capacity for image understanding allows them to provide\nvaluable feedback in RL tasks by recognizing successful outcomes. A key\nchallenge in Reinforcement Learning from AI Feedback (RLAIF) is determining how\nbest to integrate VLM-derived signals into the learning process. We explore\nthis question in the context of offline RL and introduce a class of methods\ncalled sub-trajectory filtered optimization. We identify three key insights.\nFirst, trajectory length plays a crucial role in offline RL, as full-trajectory\npreference learning exacerbates the stitching problem, necessitating the use of\nsub-trajectories. Second, even in Markovian environments, a non-Markovian\nreward signal from a sequence of images is required to assess trajectory\nimprovement, as VLMs do not interpret control actions and must rely on visual\ncues over time. Third, a simple yet effective approach--filtered and weighted\nbehavior cloning--consistently outperforms more complex reinforcement learning\nfrom human feedback-based methods. We propose sub-trajectory filtered behavior\ncloning, a method that leverages VLM feedback on sub-trajectories while\nincorporating a retrospective filtering mechanism that removes sub-trajectories\npreceding failures to improve robustness and prevent turbulence. This study is\npreliminary; we provide initial evidence through evaluations on a toy control\ndomain. Please enjoy our airport puns.\n","authors":["Jacob Beck"],"pdf_url":"https://arxiv.org/pdf/2503.01062v2.pdf","comment":"Code is provided at https://github.com/jacooba/OfflineRLAIF"},{"id":"http://arxiv.org/abs/2411.15811v3","updated":"2025-03-07T03:39:49Z","published":"2024-11-24T12:34:02Z","title":"FastTrackTr:Towards Fast Multi-Object Tracking with Transformers","summary":"  Transformer-based multi-object tracking (MOT) methods have captured the\nattention of many researchers in recent years. However, these models often\nsuffer from slow inference speeds due to their structure or other issues. To\naddress this problem, we revisited the Joint Detection and Tracking (JDT)\nmethod by looking back at past approaches. By integrating the original JDT\napproach with some advanced theories, this paper employs an efficient method of\ninformation transfer between frames on the DETR, constructing a fast and novel\nJDT-type MOT framework: FastTrackTr. Thanks to the superiority of this\ninformation transfer method, our approach not only reduces the number of\nqueries required during tracking but also avoids the excessive introduction of\nnetwork structures, ensuring model simplicity. Experimental results indicate\nthat our method has the potential to achieve real-time tracking and exhibits\ncompetitive tracking accuracy across multiple datasets.\n","authors":["Pan Liao","Feng Yang","Di Wu","Jinwen Yu","Wenhui Zhao","Bo Liu"],"pdf_url":"https://arxiv.org/pdf/2411.15811v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05114v1","updated":"2025-03-07T03:19:25Z","published":"2025-03-07T03:19:25Z","title":"Look Before You Leap: Using Serialized State Machine for Language\n  Conditioned Robotic Manipulation","summary":"  Imitation learning frameworks for robotic manipulation have drawn attention\nin the recent development of language model grounded robotics. However, the\nsuccess of the frameworks largely depends on the coverage of the demonstration\ncases: When the demonstration set does not include examples of how to act in\nall possible situations, the action may fail and can result in cascading\nerrors. To solve this problem, we propose a framework that uses serialized\nFinite State Machine (FSM) to generate demonstrations and improve the success\nrate in manipulation tasks requiring a long sequence of precise interactions.\nTo validate its effectiveness, we use environmentally evolving and long-horizon\npuzzles that require long sequential actions. Experimental results show that\nour approach achieves a success rate of up to 98 in these tasks, compared to\nthe controlled condition using existing approaches, which only had a success\nrate of up to 60, and, in some tasks, almost failed completely.\n","authors":["Tong Mu","Yihao Liu","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2503.05114v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04723v2","updated":"2025-03-07T03:14:02Z","published":"2025-03-06T18:59:37Z","title":"Shifting Long-Context LLMs Research from Input to Output","summary":"  Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.\n","authors":["Yuhao Wu","Yushi Bai","Zhiqing Hu","Shangqing Tu","Ming Shan Hee","Juanzi Li","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04723v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.18335v2","updated":"2025-03-07T03:11:27Z","published":"2024-12-24T10:42:25Z","title":"FloNa: Floor Plan Guided Embodied Visual Navigation","summary":"  Humans naturally rely on floor plans to navigate in unfamiliar environments,\nas they are readily available, reliable, and provide rich geometrical guidance.\nHowever, existing visual navigation settings overlook this valuable prior\nknowledge, leading to limited efficiency and accuracy. To eliminate this gap,\nwe introduce a novel navigation task: Floor Plan Visual Navigation (FloNa), the\nfirst attempt to incorporate floor plan into embodied visual navigation. While\nthe floor plan offers significant advantages, two key challenges emerge: (1)\nhandling the spatial inconsistency between the floor plan and the actual scene\nlayout for collision-free navigation, and (2) aligning observed images with the\nfloor plan sketch despite their distinct modalities. To address these\nchallenges, we propose FloDiff, a novel diffusion policy framework\nincorporating a localization module to facilitate alignment between the current\nobservation and the floor plan. We further collect $20k$ navigation episodes\nacross $117$ scenes in the iGibson simulator to support the training and\nevaluation. Extensive experiments demonstrate the effectiveness and efficiency\nof our framework in unfamiliar scenes using floor plan knowledge. Project\nwebsite: https://gauleejx.github.io/flona/.\n","authors":["Jiaxin Li","Weiqi Huang","Zan Wang","Wei Liang","Huijun Di","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2412.18335v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2409.19527v2","updated":"2025-03-07T03:06:50Z","published":"2024-09-29T03:00:16Z","title":"BuildingView: Constructing Urban Building Exteriors Databases with\n  Street View Imagery and Multimodal Large Language Mode","summary":"  Urban Building Exteriors are increasingly important in urban analytics,\ndriven by advancements in Street View Imagery and its integration with urban\nresearch. Multimodal Large Language Models (LLMs) offer powerful tools for\nurban annotation, enabling deeper insights into urban environments. However,\nchallenges remain in creating accurate and detailed urban building exterior\ndatabases, identifying critical indicators for energy efficiency, environmental\nsustainability, and human-centric design, and systematically organizing these\nindicators. To address these challenges, we propose BuildingView, a novel\napproach that integrates high-resolution visual data from Google Street View\nwith spatial information from OpenStreetMap via the Overpass API. This research\nimproves the accuracy of urban building exterior data, identifies key\nsustainability and design indicators, and develops a framework for their\nextraction and categorization. Our methodology includes a systematic literature\nreview, building and Street View sampling, and annotation using the ChatGPT-4O\nAPI. The resulting database, validated with data from New York City, Amsterdam,\nand Singapore, provides a comprehensive tool for urban studies, supporting\ninformed decision-making in urban planning, architectural design, and\nenvironmental policy. The code for BuildingView is available at\nhttps://github.com/Jasper0122/BuildingView.\n","authors":["Zongrong Li","Yunlei Su","Hongrong Wang","Wufan Zhao"],"pdf_url":"https://arxiv.org/pdf/2409.19527v2.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.05108v1","updated":"2025-03-07T03:06:21Z","published":"2025-03-07T03:06:21Z","title":"TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series\n  Forecasting","summary":"  Spiking Neural Networks (SNNs) offer a promising, biologically inspired\napproach for processing spatiotemporal data, particularly for time series\nforecasting. However, conventional neuron models like the Leaky\nIntegrate-and-Fire (LIF) struggle to capture long-term dependencies and\neffectively process multi-scale temporal dynamics. To overcome these\nlimitations, we introduce the Temporal Segment Leaky Integrate-and-Fire\n(TS-LIF) model, featuring a novel dual-compartment architecture. The dendritic\nand somatic compartments specialize in capturing distinct frequency components,\nproviding functional heterogeneity that enhances the neuron's ability to\nprocess both low- and high-frequency information. Furthermore, the newly\nintroduced direct somatic current injection reduces information loss during\nintra-neuronal transmission, while dendritic spike generation improves\nmulti-scale information extraction. We provide a theoretical stability analysis\nof the TS-LIF model and explain how each compartment contributes to distinct\nfrequency response characteristics. Experimental results show that TS-LIF\noutperforms traditional SNNs in time series forecasting, demonstrating better\naccuracy and robustness, even with missing data. TS-LIF advances the\napplication of SNNs in time-series forecasting, providing a biologically\ninspired approach that captures complex temporal dynamics and offers potential\nfor practical implementation in diverse forecasting scenarios. The source code\nis available at https://github.com/kkking-kk/TS-LIF.\n","authors":["Shibo Feng","Wanjin Feng","Xingyu Gao","Peilin Zhao","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2503.05108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05106v1","updated":"2025-03-07T03:01:00Z","published":"2025-03-07T03:01:00Z","title":"Grouped Sequential Optimization Strategy -- the Application of\n  Hyperparameter Importance Assessment in Deep Learning","summary":"  Hyperparameter optimization (HPO) is a critical component of machine learning\npipelines, significantly affecting model robustness, stability, and\ngeneralization. However, HPO is often a time-consuming and computationally\nintensive task. Traditional HPO methods, such as grid search and random search,\noften suffer from inefficiency. Bayesian optimization, while more efficient,\nstill struggles with high-dimensional search spaces. In this paper, we\ncontribute to the field by exploring how insights gained from hyperparameter\nimportance assessment (HIA) can be leveraged to accelerate HPO, reducing both\ntime and computational resources. Building on prior work that quantified\nhyperparameter importance by evaluating 10 hyperparameters on CNNs using 10\ncommon image classification datasets, we implement a novel HPO strategy called\n'Sequential Grouping.' That prior work assessed the importance weights of the\ninvestigated hyperparameters based on their influence on model performance,\nproviding valuable insights that we leverage to optimize our HPO process. Our\nexperiments, validated across six additional image classification datasets,\ndemonstrate that incorporating hyperparameter importance assessment (HIA) can\nsignificantly accelerate HPO without compromising model performance, reducing\noptimization time by an average of 31.9\\% compared to the conventional\nsimultaneous strategy.\n","authors":["Ruinan Wang","Ian Nabney","Mohammad Golbabaee"],"pdf_url":"https://arxiv.org/pdf/2503.05106v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2503.03140v2","updated":"2025-03-07T02:57:44Z","published":"2025-03-05T03:26:54Z","title":"Knowledge Augmentation in Federation: Rethinking What Collaborative\n  Learning Can Bring Back to Decentralized Data","summary":"  Data, as an observable form of knowledge, has become one of the most\nimportant factors of production for the development of Artificial Intelligence\n(AI). Meanwhile, increasing legislation and regulations on private and\nproprietary information results in scattered data sources also known as the\n\"data islands\". Although some collaborative learning paradigms such as\nFederated Learning (FL) can enable privacy-preserving training over\ndecentralized data, they have inherent deficiencies in fairness, costs and\nreproducibility because of being learning-centric, which greatly limits the way\nhow participants cooperate with each other. In light of this, we present a\nknowledge-centric paradigm termed Knowledge Augmentation in Federation (KAF),\nwith focus on how to enhance local knowledge through collaborative effort. We\nprovide the suggested system architecture, formulate the prototypical\noptimization objective, and review emerging studies that employ methodologies\nsuitable for KAF. On our roadmap, with a three-way categorization we describe\nthe methods for knowledge expansion, knowledge filtering, and label and feature\nspace correction in the federation. Further, we highlight several challenges\nand open questions that deserve more attention from the community. With our\ninvestigation, we intend to offer new insights for what collaborative learning\ncan bring back to decentralized data.\n","authors":["Wentai Wu","Ligang He","Saiqin Long","Ahmed M. Abdelmoniem","Yingliang Wu","Rui Mao"],"pdf_url":"https://arxiv.org/pdf/2503.03140v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.10253v3","updated":"2025-03-07T02:53:18Z","published":"2024-10-14T08:09:45Z","title":"Feedback Favors the Generalization of Neural ODEs","summary":"  The well-known generalization problem hinders the application of artificial\nneural networks in continuous-time prediction tasks with varying latent\ndynamics. In sharp contrast, biological systems can neatly adapt to evolving\nenvironments benefiting from real-time feedback mechanisms. Inspired by the\nfeedback philosophy, we present feedback neural networks, showing that a\nfeedback loop can flexibly correct the learned latent dynamics of neural\nordinary differential equations (neural ODEs), leading to a prominent\ngeneralization improvement. The feedback neural network is a novel two-DOF\nneural network, which possesses robust performance in unseen scenarios with no\nloss of accuracy performance on previous tasks.} A linear feedback form is\npresented to correct the learned latent dynamics firstly, with a convergence\nguarantee. Then, domain randomization is utilized to learn a nonlinear neural\nfeedback form. Finally, extensive tests including trajectory prediction of a\nreal irregular object and model predictive control of a quadrotor with various\nuncertainties, are implemented, indicating significant improvements over\nstate-of-the-art model-based and learning-based methods.\n","authors":["Jindou Jia","Zihan Yang","Meng Wang","Kexin Guo","Jianfei Yang","Xiang Yu","Lei Guo"],"pdf_url":"https://arxiv.org/pdf/2410.10253v3.pdf","comment":"27 pages, 23 figures"},{"id":"http://arxiv.org/abs/2412.00156v4","updated":"2025-03-07T02:43:19Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v4.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2204.08027v3","updated":"2025-03-07T02:28:52Z","published":"2022-04-17T15:04:44Z","title":"Attention Mechanism based Cognition-level Scene Understanding","summary":"  Given a question-image input, the Visual Commonsense Reasoning (VCR) model\ncan predict an answer with the corresponding rationale, which requires\ninference ability from the real world. The VCR task, which calls for exploiting\nthe multi-source information as well as learning different levels of\nunderstanding and extensive commonsense knowledge, is a cognition-level scene\nunderstanding task. The VCR task has aroused researchers' interest due to its\nwide range of applications, including visual question answering, automated\nvehicle systems, and clinical decision support. Previous approaches to solving\nthe VCR task generally rely on pre-training or exploiting memory with long\ndependency relationship encoded models. However, these approaches suffer from a\nlack of generalizability and losing information in long sequences. In this\npaper, we propose a parallel attention-based cognitive VCR network PAVCR, which\nfuses visual-textual information efficiently and encodes semantic information\nin parallel to enable the model to capture rich information for cognition-level\ninference. Extensive experiments show that the proposed model yields\nsignificant improvements over existing methods on the benchmark VCR dataset.\nMoreover, the proposed model provides intuitive interpretation into visual\ncommonsense reasoning.\n","authors":["Xuejiao Tang","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2204.08027v3.pdf","comment":"Published in Information"},{"id":"http://arxiv.org/abs/2503.00870v2","updated":"2025-03-07T02:28:26Z","published":"2025-03-02T12:16:20Z","title":"NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks In\n  Open Domains","summary":"  We explore neuro-symbolic approaches to generalize actionable knowledge,\nenabling embodied agents to tackle complex tasks more effectively in\nopen-domain environments. A key challenge for embodied agents is the\ngeneralization of knowledge across diverse environments and situations, as\nlimited experiences often confine them to their prior knowledge. To address\nthis issue, we introduce a novel framework, NeSyC, a neuro-symbolic continual\nlearner that emulates the hypothetico-deductive model by continually\nformulating and validating knowledge from limited experiences through the\ncombined use of Large Language Models (LLMs) and symbolic tools. Specifically,\nwe devise a contrastive generality improvement scheme within NeSyC, which\niteratively generates hypotheses using LLMs and conducts contrastive validation\nvia symbolic tools. This scheme reinforces the justification for admissible\nactions while minimizing the inference of inadmissible ones. Additionally, we\nincorporate a memory-based monitoring scheme that efficiently detects action\nerrors and triggers the knowledge refinement process across domains.\nExperiments conducted on diverse embodied task benchmarks-including ALFWorld,\nVirtualHome, Minecraft, RLBench, and a real-world robotic scenario-demonstrate\nthat NeSyC is highly effective in solving complex embodied tasks across a range\nof open-domain environments.\n","authors":["Wonje Choi","Jinwoo Park","Sanghyun Ahn","Daehee Lee","Honguk Woo"],"pdf_url":"https://arxiv.org/pdf/2503.00870v2.pdf","comment":"Accepted at ICLR 2025. Project site with code:\n  https://pjw971022.github.io/nesyc/"},{"id":"http://arxiv.org/abs/2503.05092v1","updated":"2025-03-07T02:23:24Z","published":"2025-03-07T02:23:24Z","title":"Multi-Robot Collaboration through Reinforcement Learning and Abstract\n  Simulation","summary":"  Teams of people coordinate to perform complex tasks by forming abstract\nmental models of world and agent dynamics. The use of abstract models contrasts\nwith much recent work in robot learning that uses a high-fidelity simulator and\nreinforcement learning (RL) to obtain policies for physical robots. Motivated\nby this difference, we investigate the extent to which so-called abstract\nsimulators can be used for multi-agent reinforcement learning (MARL) and the\nresulting policies successfully deployed on teams of physical robots. An\nabstract simulator models the robot's target task at a high-level of\nabstraction and discards many details of the world that could impact optimal\ndecision-making. Policies are trained in an abstract simulator then transferred\nto the physical robot by making use of separately-obtained low-level perception\nand motion control modules. We identify three key categories of modifications\nto the abstract simulator that enable policy transfer to physical robots:\nsimulation fidelity enhancements, training optimizations and simulation\nstochasticity. We then run an empirical study with extensive ablations to\ndetermine the value of each modification category for enabling policy transfer\nin cooperative robot soccer tasks. We also compare the performance of policies\nproduced by our method with a well-tuned non-learning-based behavior\narchitecture from the annual RoboCup competition and find that our approach\nleads to a similar level of performance. Broadly we show that MARL can be use\nto train cooperative physical robot behaviors using highly abstract models of\nthe world.\n","authors":["Adam Labiosa","Josiah P. Hanna"],"pdf_url":"https://arxiv.org/pdf/2503.05092v1.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2412.09417v2","updated":"2025-03-07T02:12:15Z","published":"2024-12-12T16:25:10Z","title":"Reinforcement Learning Within the Classical Robotics Stack: A Case Study\n  in Robot Soccer","summary":"  Robot decision-making in partially observable, real-time, dynamic, and\nmulti-agent environments remains a difficult and unsolved challenge. Model-free\nreinforcement learning (RL) is a promising approach to learning decision-making\nin such domains, however, end-to-end RL in complex environments is often\nintractable. To address this challenge in the RoboCup Standard Platform League\n(SPL) domain, we developed a novel architecture integrating RL within a\nclassical robotics stack, while employing a multi-fidelity sim2real approach\nand decomposing behavior into learned sub-behaviors with heuristic selection.\nOur architecture led to victory in the 2024 RoboCup SPL Challenge Shield\nDivision. In this work, we fully describe our system's architecture and\nempirically analyze key design decisions that contributed to its success. Our\napproach demonstrates how RL-based behaviors can be integrated into complete\nrobot behavior architectures.\n","authors":["Adam Labiosa","Zhihan Wang","Siddhant Agarwal","William Cong","Geethika Hemkumar","Abhinav Narayan Harish","Benjamin Hong","Josh Kelle","Chen Li","Yuhao Li","Zisen Shao","Peter Stone","Josiah P. Hanna"],"pdf_url":"https://arxiv.org/pdf/2412.09417v2.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2501.07335v2","updated":"2025-03-07T01:43:30Z","published":"2025-01-13T13:47:05Z","title":"TempoGPT: Enhancing Time Series Reasoning via Quantizing Embedding","summary":"  Multi-modal language model has made advanced progress in vision and audio,\nbut still faces significant challenges in dealing with complex reasoning tasks\nin the time series domain. The reasons are twofold. First, labels for\nmulti-modal time series data are coarse and devoid of analysis or reasoning\nprocesses. Training with these data cannot improve the model's reasoning\ncapabilities. Second, due to the lack of precise tokenization in processing\ntime series, the representation patterns for temporal and textual information\nare inconsistent, which hampers the effectiveness of multi-modal alignment. To\naddress these challenges, we propose a multi-modal time series data\nconstruction approach and a multi-modal time series language model (TLM),\nTempoGPT. Specially, we construct multi-modal data for complex reasoning tasks\nby analyzing the variable-system relationships within a white-box system.\nAdditionally, proposed TempoGPT achieves consistent representation between\ntemporal and textual information by quantizing temporal embeddings, where\ntemporal embeddings are quantized into a series of discrete tokens using a\npredefined codebook; subsequently, a shared embedding layer processes both\ntemporal and textual tokens. Extensive experiments demonstrate that TempoGPT\naccurately perceives temporal information, logically infers conclusions, and\nachieves state-of-the-art in the constructed complex time series reasoning\ntasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing\ntemporal embeddings in enhancing multi-modal alignment and the reasoning\ncapabilities of TLMs. Code and data are available at\nhttps://github.com/zhanghaochuan20/TempoGPT.\n","authors":["Haochuan Zhang","Chunhua Yang","Jie Han","Liyang Qin","Xiaoli Wang"],"pdf_url":"https://arxiv.org/pdf/2501.07335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05071v1","updated":"2025-03-07T01:31:40Z","published":"2025-03-07T01:31:40Z","title":"Object Packing and Scheduling for Sequential 3D Printing: a Linear\n  Arithmetic Model and a CEGAR-inspired Optimal Solver","summary":"  We address the problem of object arrangement and scheduling for sequential 3D\nprinting. Unlike the standard 3D printing, where all objects are printed slice\nby slice at once, in sequential 3D printing, objects are completed one after\nother. In the sequential case, it is necessary to ensure that the moving parts\nof the printer do not collide with previously printed objects. We look at the\nsequential printing problem from the perspective of combinatorial optimization.\nWe propose to express the problem as a linear arithmetic formula, which is then\nsolved using a solver for satisfiability modulo theories (SMT). However, we do\nnot solve the formula expressing the problem of object arrangement and\nscheduling directly, but we have proposed a technique inspired by\ncounterexample guided abstraction refinement (CEGAR), which turned out to be a\nkey innovation to efficiency.\n","authors":["Pavel Surynek","Vojtěch Bubník","Lukáš Matěna","Petr Kubiš"],"pdf_url":"https://arxiv.org/pdf/2503.05071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05070v1","updated":"2025-03-07T01:31:03Z","published":"2025-03-07T01:31:03Z","title":"PromptPex: Automatic Test Generation for Language Model Prompts","summary":"  Large language models (LLMs) are being used in many applications and prompts\nfor these models are integrated into software applications as code-like\nartifacts. These prompts behave much like traditional software in that they\ntake inputs, generate outputs, and perform some specific function. However,\nprompts differ from traditional code in many ways and require new approaches to\nensure that they are robust. For example, unlike traditional software the\noutput of a prompt depends on the AI model that interprets it. Also, while\nnatural language prompts are easy to modify, the impact of updates is harder to\npredict. New approaches to testing, debugging, and modifying prompts with\nrespect to the model running them are required.\n  To address some of these issues, we developed PromptPex, an LLM-based tool to\nautomatically generate and evaluate unit tests for a given prompt. PromptPex\nextracts input and output specifications from a prompt and uses them to\ngenerate diverse, targeted, and valid unit tests. These tests are instrumental\nin identifying regressions when a prompt is changed and also serve as a tool to\nunderstand how prompts are interpreted by different models. We use PromptPex to\ngenerate tests for eight benchmark prompts and evaluate the quality of the\ngenerated tests by seeing if they can cause each of four diverse models to\nproduce invalid output. PromptPex consistently creates tests that result in\nmore invalid model outputs than a carefully constructed baseline LLM-based test\ngenerator. Furthermore, by extracting concrete specifications from the input\nprompt, PromptPex allows prompt writers to clearly understand and test specific\naspects of their prompts. The source code of PromptPex is available at\nhttps://github.com/microsoft/promptpex.\n","authors":["Reshabh K Sharma","Jonathan De Halleux","Shraddha Barke","Benjamin Zorn"],"pdf_url":"https://arxiv.org/pdf/2503.05070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00064v3","updated":"2025-03-07T01:29:54Z","published":"2024-09-30T01:43:06Z","title":"M2Distill: Multi-Modal Distillation for Lifelong Imitation Learning","summary":"  Lifelong imitation learning for manipulation tasks poses significant\nchallenges due to distribution shifts that occur in incremental learning steps.\nExisting methods often focus on unsupervised skill discovery to construct an\never-growing skill library or distillation from multiple policies, which can\nlead to scalability issues as diverse manipulation tasks are continually\nintroduced and may fail to ensure a consistent latent space throughout the\nlearning process, leading to catastrophic forgetting of previously learned\nskills. In this paper, we introduce M2Distill, a multi-modal distillation-based\nmethod for lifelong imitation learning focusing on preserving consistent latent\nspace across vision, language, and action distributions throughout the learning\nprocess. By regulating the shifts in latent representations across different\nmodalities from previous to current steps, and reducing discrepancies in\nGaussian Mixture Model (GMM) policies between consecutive learning steps, we\nensure that the learned policy retains its ability to perform previously\nlearned tasks while seamlessly integrating new skills. Extensive evaluations on\nthe LIBERO lifelong imitation learning benchmark suites, including\nLIBERO-OBJECT, LIBERO-GOAL, and LIBERO-SPATIAL, demonstrate that our method\nconsistently outperforms prior state-of-the-art methods across all evaluated\nmetrics.\n","authors":["Kaushik Roy","Akila Dissanayake","Brendan Tidd","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2410.00064v3.pdf","comment":"IEEE ICRA 2025"},{"id":"http://arxiv.org/abs/2409.16287v2","updated":"2025-03-07T01:24:50Z","published":"2024-09-24T17:59:56Z","title":"Articulated Object Manipulation using Online Axis Estimation with\n  SAM2-Based Tracking","summary":"  Articulated object manipulation requires precise object interaction, where\nthe object's axis must be carefully considered. Previous research employed\ninteractive perception for manipulating articulated objects, but typically,\nopen-loop approaches often suffer from overlooking the interaction dynamics. To\naddress this limitation, we present a closed-loop pipeline integrating\ninteractive perception with online axis estimation from segmented 3D point\nclouds. Our method leverages any interactive perception technique as a\nfoundation for interactive perception, inducing slight object movement to\ngenerate point cloud frames of the evolving dynamic scene. These point clouds\nare then segmented using Segment Anything Model 2 (SAM2), after which the\nmoving part of the object is masked for accurate motion online axis estimation,\nguiding subsequent robotic actions. Our approach significantly enhances the\nprecision and efficiency of manipulation tasks involving articulated objects.\nExperiments in simulated environments demonstrate that our method outperforms\nbaseline approaches, especially in tasks that demand precise axis-based\ncontrol. Project Page:\nhttps://hytidel.github.io/video-tracking-for-axis-estimation/.\n","authors":["Xi Wang","Tianxing Chen","Qiaojun Yu","Tianling Xu","Zanxin Chen","Yiting Fu","Ziqi He","Cewu Lu","Yao Mu","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2409.16287v2.pdf","comment":"Project Page:\n  https://hytidel.github.io/video-tracking-for-axis-estimation/"},{"id":"http://arxiv.org/abs/2503.05066v1","updated":"2025-03-07T01:11:39Z","published":"2025-03-07T01:11:39Z","title":"Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of\n  Experts","summary":"  The Mixture of Experts (MoE) is an effective architecture for scaling large\nlanguage models by leveraging sparse expert activation, optimizing the\ntrade-off between performance and efficiency. However, under expert\nparallelism, MoE suffers from inference inefficiencies due to imbalanced\ntoken-to-expert assignment, where some experts are overloaded while others\nremain underutilized. This imbalance leads to poor resource utilization and\nincreased latency, as the most burdened expert dictates the overall delay, a\nphenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate\nthis, we propose Capacity-Aware Inference, including two key techniques: (1)\n\\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens\nto regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware\nToken Reroute}}, which reallocates overflowed tokens to underutilized experts,\nbalancing the token distribution. These techniques collectively optimize both\nhigh-load and low-load expert utilization, leading to a more efficient MoE\ninference pipeline. Extensive experiments demonstrate the effectiveness of our\nmethods, showing significant improvements in inference efficiency, e.g., 0.2\\%\naverage performance increase and a 1.94$\\times$ inference speedup on\nMixtral-8$\\times$7B-Instruct.\n","authors":["Shwai He","Weilin Cai","Jiayi Huang","Ang Li"],"pdf_url":"https://arxiv.org/pdf/2503.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10948v2","updated":"2025-03-07T01:02:22Z","published":"2024-03-22T08:38:27Z","title":"Surgical-LVLM: Learning to Adapt Large Vision-Language Model for\n  Grounded Visual Question Answering in Robotic Surgery","summary":"  Recent advancements in Surgical Visual Question Answering (Surgical-VQA) and\nrelated region grounding have shown great promise for robotic and medical\napplications, addressing the critical need for automated methods in\npersonalized surgical mentorship. However, existing models primarily provide\nsimple structured answers and struggle with complex scenarios due to their\nlimited capability in recognizing long-range dependencies and aligning\nmultimodal information. In this paper, we introduce Surgical-LVLM, a novel\npersonalized large vision-language model tailored for complex surgical\nscenarios. Leveraging the pre-trained large vision-language model and\nspecialized Visual Perception LoRA (VP-LoRA) blocks, our model excels in\nunderstanding complex visual-language tasks within surgical contexts. In\naddressing the visual grounding task, we propose the Token-Interaction (TIT)\nmodule, which strengthens the interaction between the grounding module and the\nlanguage responses of the Large Visual Language Model (LVLM) after projecting\nthem into the latent space. We demonstrate the effectiveness of Surgical-LVLM\non several benchmarks, including EndoVis-17-VQLA, EndoVis-18-VQLA, and a newly\nintroduced EndoVis Conversations dataset, which sets new performance standards.\nOur work contributes to advancing the field of automated surgical mentorship by\nproviding a context-aware solution.\n","authors":["Guankun Wang","Long Bai","Wan Jun Nah","Jie Wang","Zhaoxi Zhang","Zhen Chen","Jinlin Wu","Mobarakol Islam","Hongbin Liu","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2405.10948v2.pdf","comment":"The manuscript is accepted by ICLR 2025 FM-Wild Workshop"},{"id":"http://arxiv.org/abs/2503.05064v1","updated":"2025-03-07T00:55:42Z","published":"2025-03-07T00:55:42Z","title":"Perceiving, Reasoning, Adapting: A Dual-Layer Framework for VLM-Guided\n  Precision Robotic Manipulation","summary":"  Vision-Language Models (VLMs) demonstrate remarkable potential in robotic\nmanipulation, yet challenges persist in executing complex fine manipulation\ntasks with high speed and precision. While excelling at high-level planning,\nexisting VLM methods struggle to guide robots through precise sequences of fine\nmotor actions. To address this limitation, we introduce a progressive VLM\nplanning algorithm that empowers robots to perform fast, precise, and\nerror-correctable fine manipulation. Our method decomposes complex tasks into\nsub-actions and maintains three key data structures: task memory structure, 2D\ntopology graphs, and 3D spatial networks, achieving high-precision\nspatial-semantic fusion. These three components collectively accumulate and\nstore critical information throughout task execution, providing rich context\nfor our task-oriented VLM interaction mechanism. This enables VLMs to\ndynamically adjust guidance based on real-time feedback, generating precise\naction plans and facilitating step-wise error correction. Experimental\nvalidation on complex assembly tasks demonstrates that our algorithm\neffectively guides robots to rapidly and precisely accomplish fine manipulation\nin challenging scenarios, significantly advancing robot intelligence for\nprecision tasks.\n","authors":["Qingxuan Jia","Guoqin Tang","Zeyuan Huang","Zixuan Hao","Ning Ji"," Shihang"," Yin","Gang Chen"],"pdf_url":"https://arxiv.org/pdf/2503.05064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05051v1","updated":"2025-03-07T00:05:43Z","published":"2025-03-07T00:05:43Z","title":"Accelerated Patient-specific Non-Cartesian MRI Reconstruction using\n  Implicit Neural Representations","summary":"  The scanning time for a fully sampled MRI can be undesirably lengthy.\nCompressed sensing has been developed to minimize image artifacts in\naccelerated scans, but the required iterative reconstruction is computationally\ncomplex and difficult to generalize on new cases. Image-domain-based deep\nlearning methods (e.g., convolutional neural networks) emerged as a faster\nalternative but face challenges in modeling continuous k-space, a problem\namplified with non-Cartesian sampling commonly used in accelerated acquisition.\nIn comparison, implicit neural representations can model continuous signals in\nthe frequency domain and thus are compatible with arbitrary k-space sampling\npatterns. The current study develops a novel generative-adversarially trained\nimplicit neural representations (k-GINR) for de novo undersampled non-Cartesian\nk-space reconstruction. k-GINR consists of two stages: 1) supervised training\non an existing patient cohort; 2) self-supervised patient-specific\noptimization. In stage 1, the network is trained with the\ngenerative-adversarial network on diverse patients of the same anatomical\nregion supervised by fully sampled acquisition. In stage 2, undersampled\nk-space data of individual patients is used to tailor the prior-embedded\nnetwork for patient-specific optimization. The UCSF StarVIBE T1-weighted liver\ndataset was evaluated on the proposed framework. k-GINR is compared with an\nimage-domain deep learning method, Deep Cascade CNN, and a compressed sensing\nmethod. k-GINR consistently outperformed the baselines with a larger\nperformance advantage observed at very high accelerations (e.g., 20 times).\nk-GINR offers great value for direct non-Cartesian k-space reconstruction for\nnew incoming patients across a wide range of accelerations liver anatomy.\n","authors":["Di Xu","Hengjie Liu","Xin Miao","Daniel O'Connor","Jessica E. Scholey","Wensha Yang","Mary Feng","Michael Ohliger","Hui Lin","Dan Ruan","Yang Yang","Ke Sheng"],"pdf_url":"https://arxiv.org/pdf/2503.05051v1.pdf","comment":null}]},"2025-03-10T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.07459v1","updated":"2025-03-10T15:38:44Z","published":"2025-03-10T15:38:44Z","title":"MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for\n  Complex Medical Reasoning","summary":"  Large Language Models (LLMs) have shown impressive performance on existing\nmedical question-answering benchmarks. This high performance makes it\nincreasingly difficult to meaningfully evaluate and differentiate advanced\nmethods. We present MedAgentsBench, a benchmark that focuses on challenging\nmedical questions requiring multi-step clinical reasoning, diagnosis\nformulation, and treatment planning-scenarios where current models still\nstruggle despite their strong performance on standard tests. Drawing from seven\nestablished medical datasets, our benchmark addresses three key limitations in\nexisting evaluations: (1) the prevalence of straightforward questions where\neven base models achieve high performance, (2) inconsistent sampling and\nevaluation protocols across studies, and (3) lack of systematic analysis of the\ninterplay between performance, cost, and inference time. Through experiments\nwith various base models and reasoning methods, we demonstrate that the latest\nthinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in\ncomplex medical reasoning tasks. Additionally, advanced search-based agent\nmethods offer promising performance-to-cost ratios compared to traditional\napproaches. Our analysis reveals substantial performance gaps between model\nfamilies on complex questions and identifies optimal model selections for\ndifferent computational constraints. Our benchmark and evaluation framework are\npublicly available at https://github.com/gersteinlab/medagents-benchmark.\n","authors":["Xiangru Tang","Daniel Shao","Jiwoong Sohn","Jiapeng Chen","Jiayi Zhang","Jinyu Xiang","Fang Wu","Yilun Zhao","Chenglin Wu","Wenqi Shi","Arman Cohan","Mark Gerstein"],"pdf_url":"https://arxiv.org/pdf/2503.07459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07457v1","updated":"2025-03-10T15:37:07Z","published":"2025-03-10T15:37:07Z","title":"LLMs syntactically adapt their language use to their conversational\n  partner","summary":"  It has been frequently observed that human speakers align their language use\nwith each other during conversations. In this paper, we study empirically\nwhether large language models (LLMs) exhibit the same behavior of\nconversational adaptation. We construct a corpus of conversations between LLMs\nand find that two LLM agents end up making more similar syntactic choices as\nconversations go on, confirming that modern LLMs adapt their language use to\ntheir conversational partners in at least a rudimentary way.\n","authors":["Florian Kandra","Vera Demberg","Alexander Koller"],"pdf_url":"https://arxiv.org/pdf/2503.07457v1.pdf","comment":"4 pages, 1 table, 1 figure, submitted to ACL"},{"id":"http://arxiv.org/abs/2503.07453v1","updated":"2025-03-10T15:31:42Z","published":"2025-03-10T15:31:42Z","title":"Is a Good Foundation Necessary for Efficient Reinforcement Learning? The\n  Computational Role of the Base Model in Exploration","summary":"  Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.\n","authors":["Dylan J. Foster","Zakaria Mhammedi","Dhruv Rohatgi"],"pdf_url":"https://arxiv.org/pdf/2503.07453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07395v1","updated":"2025-03-10T14:42:42Z","published":"2025-03-10T14:42:42Z","title":"Revisiting Noise in Natural Language Processing for Computational Social\n  Science","summary":"  Computational Social Science (CSS) is an emerging field driven by the\nunprecedented availability of human-generated content for researchers. This\nfield, however, presents a unique set of challenges due to the nature of the\ntheories and datasets it explores, including highly subjective tasks and\ncomplex, unstructured textual corpora. Among these challenges, one of the less\nwell-studied topics is the pervasive presence of noise. This thesis aims to\naddress this gap in the literature by presenting a series of interconnected\ncase studies that examine different manifestations of noise in CSS. These\ninclude character-level errors following the OCR processing of historical\nrecords, archaic language, inconsistencies in annotations for subjective and\nambiguous tasks, and even noise and biases introduced by large language models\nduring content generation. This thesis challenges the conventional notion that\nnoise in CSS is inherently harmful or useless. Rather, it argues that certain\nforms of noise can encode meaningful information that is invaluable for\nadvancing CSS research, such as the unique communication styles of individuals\nor the culture-dependent nature of datasets and tasks. Further, this thesis\nhighlights the importance of nuance in dealing with noise and the\nconsiderations CSS researchers must address when encountering it, demonstrating\nthat different types of noise require distinct strategies.\n","authors":["Nadav Borenstein"],"pdf_url":"https://arxiv.org/pdf/2503.07395v1.pdf","comment":"PhD thesis. Under the supervision of Prof. Isabelle Augenstein"},{"id":"http://arxiv.org/abs/2503.07384v1","updated":"2025-03-10T14:32:56Z","published":"2025-03-10T14:32:56Z","title":"Is My Text in Your AI Model? Gradient-based Membership Inference Test\n  applied to LLMs","summary":"  This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.\n","authors":["Gonzalo Mancera","Daniel de Alcala","Julian Fierrez","Ruben Tolosana","Aythami Morales"],"pdf_url":"https://arxiv.org/pdf/2503.07384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05139v2","updated":"2025-03-10T14:21:21Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2503.07358v1","updated":"2025-03-10T14:16:08Z","published":"2025-03-10T14:16:08Z","title":"RepoST: Scalable Repository-Level Coding Environment Construction with\n  Sandbox Testing","summary":"  We present RepoST, a scalable method to construct environments that provide\nexecution feedback for repository-level code generation for both training and\nevaluation. Unlike existing works that aim to build entire repositories for\nexecution, which is challenging for both human and LLMs, we provide execution\nfeedback with sandbox testing, which isolates a given target function and its\ndependencies to a separate script for testing. Sandbox testing reduces the\ncomplexity of external dependencies and enables constructing environments at a\nlarge scale. We use our method to construct RepoST-Train, a large-scale train\nset with 7,415 functions from 832 repositories. Training with the execution\nfeedback provided by RepoST-Train leads to a performance gain of 5.5% Pass@1 on\nHumanEval and 3.5% Pass@1 on RepoEval. We also build an evaluation dataset,\nRepoST-Eval, and benchmark 12 code generation models.\n","authors":["Yiqing Xie","Alex Xie","Divyanshu Sheth","Pengfei Liu","Daniel Fried","Carolyn Rose"],"pdf_url":"https://arxiv.org/pdf/2503.07358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16457v3","updated":"2025-03-10T14:00:39Z","published":"2025-02-23T06:16:23Z","title":"Towards Fully-Automated Materials Discovery via Large-Scale Synthesis\n  Dataset and Expert-Level LLM-as-a-Judge","summary":"  Materials synthesis is vital for innovations such as energy storage,\ncatalysis, electronics, and biomedical devices. Yet, the process relies heavily\non empirical, trial-and-error methods guided by expert intuition. Our work aims\nto support the materials science community by providing a practical,\ndata-driven resource. We have curated a comprehensive dataset of 17K\nexpert-verified synthesis recipes from open-access literature, which forms the\nbasis of our newly developed benchmark, AlchemyBench. AlchemyBench offers an\nend-to-end framework that supports research in large language models applied to\nsynthesis prediction. It encompasses key tasks, including raw materials and\nequipment prediction, synthesis procedure generation, and characterization\noutcome forecasting. We propose an LLM-as-a-Judge framework that leverages\nlarge language models for automated evaluation, demonstrating strong\nstatistical agreement with expert assessments. Overall, our contributions offer\na supportive foundation for exploring the capabilities of LLMs in predicting\nand guiding materials synthesis, ultimately paving the way for more efficient\nexperimental design and accelerated innovation in materials science.\n","authors":["Heegyu Kim","Taeyang Jeon","Seungtaek Choi","Ji Hoon Hong","Dong Won Jeon","Ga-Yeon Baek","Kyeong-Won Kwak","Dong-Hee Lee","Jisu Bae","Chihoon Lee","Yunseo Kim","Seon-Jin Choi","Jin-Seong Park","Sung Beom Cho","Hyunsouk Cho"],"pdf_url":"https://arxiv.org/pdf/2502.16457v3.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2411.19295v2","updated":"2025-03-10T14:00:23Z","published":"2024-11-28T18:04:31Z","title":"Extracting Information in a Low-resource Setting: Case Study on\n  Bioinformatics Workflows","summary":"  Bioinformatics workflows are essential for complex biological data analyses\nand are often described in scientific articles with source code in public\nrepositories. Extracting detailed workflow information from articles can\nimprove accessibility and reusability but is hindered by limited annotated\ncorpora. To address this, we framed the problem as a low-resource extraction\ntask and tested four strategies: 1) creating a tailored annotated corpus, 2)\nfew-shot named-entity recognition (NER) with an autoregressive language model,\n3) NER using masked language models with existing and new corpora, and 4)\nintegrating workflow knowledge into NER models. Using BioToFlow, a new corpus\nof 52 articles annotated with 16 entities, a SciBERT-based NER model achieved a\n70.4 F-measure, comparable to inter-annotator agreement. While knowledge\nintegration improved performance for specific entities, it was less effective\nacross the entire information schema. Our results demonstrate that\nhigh-performance information extraction for bioinformatics workflows is\nachievable.\n","authors":["Clémence Sebe","Sarah Cohen-Boulakia","Olivier Ferret","Aurélie Névéol"],"pdf_url":"https://arxiv.org/pdf/2411.19295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16821v3","updated":"2025-03-10T13:58:19Z","published":"2024-11-25T17:15:41Z","title":"KL-geodesics flow matching with a novel sampling scheme","summary":"  Non-autoregressive language models generate all tokens simultaneously,\noffering potential speed advantages over traditional autoregressive models, but\nthey face challenges in modeling the complex dependencies inherent in text\ndata. In this work, we investigate a conditional flow matching approach for\ntext generation. We represent tokens as one-hot vectors in a \\(V\\)-dimensional\nsimplex and utilize geodesics under the Kullback-Leibler (KL) divergence, which\ncorrespond to linear interpolation in logit space. We provide a theoretical\njustification that maximizing the conditional likelihood \\(P_{\\theta}(x_1 \\mid\nx_t, t)\\) yields the exact flow matching velocity under logit interpolation. To\naddress the suboptimal performance of basic inference, we propose a novel\nempirical sampling scheme that iteratively samples from the conditional\ndistribution and introduces additional noise, significantly improving results\ndespite lacking full theoretical underpinnings. Furthermore, we propose a\nhybrid inference method that combines the basic approach with the sampling\nscheme. This method demonstrates superior performance on both conditional and\nunconditional text generation experiments compared to previous SOTA method for\ndiscrete flow matching.\n","authors":["Egor Sevriugov","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2411.16821v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.19017v2","updated":"2025-03-10T13:50:13Z","published":"2025-01-31T10:37:48Z","title":"Calling a Spade a Heart: Gaslighting Multimodal Large Language Models\n  via Negation","summary":"  Multimodal Large Language Models (MLLMs) have exhibited remarkable\nadvancements in integrating different modalities, excelling in complex\nunderstanding and generation tasks. Despite their success, MLLMs remain\nvulnerable to conversational adversarial inputs, particularly negation\narguments. This paper systematically evaluates state-of-the-art MLLMs across\ndiverse benchmarks, revealing significant performance drops when negation\narguments are introduced to initially correct responses. Notably, we introduce\nthe first benchmark GaslightingBench, specifically designed to evaluate the\nvulnerability of MLLMs to negation arguments. GaslightingBench consists of\nmultiple-choice questions curated from existing datasets, along with generated\nnegation prompts across 20 diverse categories. Throughout extensive evaluation,\nwe find that proprietary models such as Gemini-1.5-flash, GPT-4o and\nClaude-3.5-Sonnet demonstrate better resilience compared to open-source\ncounterparts like Qwen2-VL and LLaVA. However, all evaluated MLLMs struggle to\nmaintain logical consistency under negation arguments during conversation. Our\nfindings provide critical insights for improving the robustness of MLLMs\nagainst negation inputs, contributing to the development of more reliable and\ntrustworthy multimodal AI systems.\n","authors":["Bin Zhu","Huiyan Qi","Yinxuan Gui","Jingjing Chen","Chong-Wah Ngo","Ee-Peng Lim"],"pdf_url":"https://arxiv.org/pdf/2501.19017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07329v1","updated":"2025-03-10T13:42:04Z","published":"2025-03-10T13:42:04Z","title":"Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning\n  Large Language Models","summary":"  The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.\n","authors":["Hao Zhou","Guergana Savova","Lijing Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07329v1.pdf","comment":"7 pages, 5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2503.07306v1","updated":"2025-03-10T13:28:25Z","published":"2025-03-10T13:28:25Z","title":"Benchmarking Chinese Medical LLMs: A Medbench-based Analysis of\n  Performance Gaps and Hierarchical Optimization Strategies","summary":"  The evaluation and improvement of medical large language models (LLMs) are\ncritical for their real-world deployment, particularly in ensuring accuracy,\nsafety, and ethical alignment. Existing frameworks inadequately dissect\ndomain-specific error patterns or address cross-modal challenges. This study\nintroduces a granular error taxonomy through systematic analysis of top 10\nmodels on MedBench, categorizing incorrect responses into eight types:\nOmissions, Hallucination, Format Mismatch, Causal Reasoning Deficiency,\nContextual Inconsistency, Unanswered, Output Error, and Deficiency in Medical\nLanguage Generation. Evaluation of 10 leading models reveals vulnerabilities:\ndespite achieving 0.86 accuracy in medical knowledge recall, critical reasoning\ntasks show 96.3% omission, while safety ethics evaluations expose alarming\ninconsistency (robustness score: 0.79) under option shuffled. Our analysis\nuncovers systemic weaknesses in knowledge boundary enforcement and multi-step\nreasoning. To address these, we propose a tiered optimization strategy spanning\nfour levels, from prompt engineering and knowledge-augmented retrieval to\nhybrid neuro-symbolic architectures and causal reasoning frameworks. This work\nestablishes an actionable roadmap for developing clinically robust LLMs while\nredefining evaluation paradigms through error-driven insights, ultimately\nadvancing the safety and trustworthiness of AI in high-stakes medical\nenvironments.\n","authors":["Luyi Jiang","Jiayuan Chen","Lu Lu","Xinwei Peng","Lihao Liu","Junjun He","Jie Xu"],"pdf_url":"https://arxiv.org/pdf/2503.07306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07303v1","updated":"2025-03-10T13:24:46Z","published":"2025-03-10T13:24:46Z","title":"An Information-Theoretic Approach to Identifying Formulaic Clusters in\n  Textual Data","summary":"  Texts, whether literary or historical, exhibit structural and stylistic\npatterns shaped by their purpose, authorship, and cultural context. Formulaic\ntexts, characterized by repetition and constrained expression, tend to have\nlower variability in self-information compared to more dynamic compositions.\nIdentifying such patterns in historical documents, particularly multi-author\ntexts like the Hebrew Bible provides insights into their origins, purpose, and\ntransmission.\n  This study aims to identify formulaic clusters -- sections exhibiting\nsystematic repetition and structural constraints -- by analyzing recurring\nphrases, syntactic structures, and stylistic markers. However, distinguishing\nformulaic from non-formulaic elements in an unsupervised manner presents a\ncomputational challenge, especially in high-dimensional textual spaces where\npatterns must be inferred without predefined labels.\n  To address this, we develop an information-theoretic algorithm leveraging\nweighted self-information distributions to detect structured patterns in text,\nunlike covariance-based methods, which become unstable in small-sample,\nhigh-dimensional settings, our approach directly models variations in\nself-information to identify formulaicity. By extending classical discrete\nself-information measures with a continuous formulation based on differential\nself-information, our method remains applicable across different types of\ntextual representations, including neural embeddings under Gaussian priors.\n  Applied to hypothesized authorial divisions in the Hebrew Bible, our approach\nsuccessfully isolates stylistic layers, providing a quantitative framework for\ntextual stratification. This method enhances our ability to analyze\ncompositional patterns, offering deeper insights into the literary and cultural\nevolution of texts shaped by complex authorship and editorial processes.\n","authors":["Gideon Yoffe","Yair Segev","Barak Sober"],"pdf_url":"https://arxiv.org/pdf/2503.07303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07282v1","updated":"2025-03-10T13:02:29Z","published":"2025-03-10T13:02:29Z","title":"A Graph-based Verification Framework for Fact-Checking","summary":"  Fact-checking plays a crucial role in combating misinformation. Existing\nmethods using large language models (LLMs) for claim decomposition face two key\nlimitations: (1) insufficient decomposition, introducing unnecessary complexity\nto the verification process, and (2) ambiguity of mentions, leading to\nincorrect verification results. To address these challenges, we suggest\nintroducing a claim graph consisting of triplets to address the insufficient\ndecomposition problem and reduce mention ambiguity through graph structure.\nBased on this core idea, we propose a graph-based framework, GraphFC, for\nfact-checking. The framework features three key components: graph construction,\nwhich builds both claim and evidence graphs; graph-guided planning, which\nprioritizes the triplet verification order; and graph-guided checking, which\nverifies the triples one by one between claim and evidence graphs. Extensive\nexperiments show that GraphFC enables fine-grained decomposition while\nresolving referential ambiguities through relational constraints, achieving\nstate-of-the-art performance across three datasets.\n","authors":["Yani Huang","Richong Zhang","Zhijie Nie","Junfan Chen","Xuefeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07282v1.pdf","comment":"13pages, 4figures"},{"id":"http://arxiv.org/abs/2503.07279v1","updated":"2025-03-10T13:00:41Z","published":"2025-03-10T13:00:41Z","title":"VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in\n  Human-AI Communication","summary":"  Trust plays a fundamental role in shaping the willingness of users to engage\nand collaborate with artificial intelligence (AI) systems. Yet, measuring user\ntrust remains challenging due to its complex and dynamic nature. While\ntraditional survey methods provide trust levels for long conversations, they\nfail to capture its dynamic evolution during ongoing interactions. Here, we\npresent VizTrust, which addresses this challenge by introducing a real-time\nvisual analytics tool that leverages a multi-agent collaboration system to\ncapture and analyze user trust dynamics in human-agent communication. Built on\nestablished human-computer trust scales-competence, integrity, benevolence, and\npredictability-, VizTrust enables stakeholders to observe trust formation as it\nhappens, identify patterns in trust development, and pinpoint specific\ninteraction elements that influence trust. Our tool offers actionable insights\ninto human-agent trust formation and evolution in real time through a\ndashboard, supporting the design of adaptive conversational agents that\nresponds effectively to user trust signals.\n","authors":["Xin Wang","Stephanie Tulk Jesso","Sadamori Kojaku","David M Neyens","Min Sun Kim"],"pdf_url":"https://arxiv.org/pdf/2503.07279v1.pdf","comment":"Accepted by ACM CHI conference 2025"},{"id":"http://arxiv.org/abs/2406.05870v4","updated":"2025-03-10T12:56:54Z","published":"2024-06-09T17:55:55Z","title":"Machine Against the RAG: Jamming Retrieval-Augmented Generation with\n  Blocker Documents","summary":"  Retrieval-augmented generation (RAG) systems respond to queries by retrieving\nrelevant documents from a knowledge database and applying an LLM to the\nretrieved documents. We demonstrate that RAG systems that operate on databases\nwith untrusted content are vulnerable to denial-of-service attacks we call\njamming. An adversary can add a single ``blocker'' document to the database\nthat will be retrieved in response to a specific query and result in the RAG\nsystem not answering this query, ostensibly because it lacks relevant\ninformation or because the answer is unsafe.\n  We describe and measure the efficacy of several methods for generating\nblocker documents, including a new method based on black-box optimization. Our\nmethod (1) does not rely on instruction injection, (2) does not require the\nadversary to know the embedding or LLM used by the target RAG system, and (3)\ndoes not employ an auxiliary LLM.\n  We evaluate jamming attacks on several embeddings and LLMs and demonstrate\nthat the existing safety metrics for LLMs do not capture their vulnerability to\njamming. We then discuss defenses against blocker documents.\n","authors":["Avital Shafran","Roei Schuster","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2406.05870v4.pdf","comment":"To appear in USENIX Security Symposium 2025"},{"id":"http://arxiv.org/abs/2503.07269v1","updated":"2025-03-10T12:49:31Z","published":"2025-03-10T12:49:31Z","title":"SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion Detection","summary":"  We present our shared task on text-based emotion detection, covering more\nthan 30 languages from seven distinct language families. These languages are\npredominantly low-resource and spoken across various continents. The data\ninstances are multi-labeled into six emotional classes, with additional\ndatasets in 11 languages annotated for emotion intensity. Participants were\nasked to predict labels in three tracks: (a) emotion labels in monolingual\nsettings, (b) emotion intensity scores, and (c) emotion labels in cross-lingual\nsettings. The task attracted over 700 participants. We received final\nsubmissions from more than 200 teams and 93 system description papers. We\nreport baseline results, as well as findings on the best-performing systems,\nthe most common approaches, and the most effective methods across various\ntracks and languages. The datasets for this task are publicly available.\n","authors":["Shamsuddeen Hassan Muhammad","Nedjma Ousidhoum","Idris Abdulmumin","Seid Muhie Yimam","Jan Philip Wahle","Terry Ruas","Meriem Beloucif","Christine De Kock","Tadesse Destaw Belay","Ibrahim Said Ahmad","Nirmal Surange","Daniela Teodorescu","David Ifeoluwa Adelani","Alham Fikri Aji","Felermino Ali","Vladimir Araujo","Abinew Ali Ayele","Oana Ignat","Alexander Panchenko","Yi Zhou","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2503.07269v1.pdf","comment":"SemEval2025 Task11 (Task Description Paper). arXiv admin note: text\n  overlap with arXiv:2502.11926"},{"id":"http://arxiv.org/abs/2503.07265v1","updated":"2025-03-10T12:47:53Z","published":"2025-03-10T12:47:53Z","title":"WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image\n  Generation","summary":"  Text-to-Image (T2I) models are capable of generating high-quality artistic\ncreations and visual content. However, existing research and evaluation\nstandards predominantly focus on image realism and shallow text-image\nalignment, lacking a comprehensive assessment of complex semantic understanding\nand world knowledge integration in text to image generation. To address this\nchallenge, we propose $\\textbf{WISE}$, the first benchmark specifically\ndesigned for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic\n$\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by\nchallenging models with 1000 meticulously crafted prompts across 25 sub-domains\nin cultural common sense, spatio-temporal reasoning, and natural science. To\novercome the limitations of traditional CLIP metric, we introduce\n$\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image\nalignment. Through comprehensive testing of 20 models (10 dedicated T2I models\nand 10 unified multimodal models) using 1,000 structured prompts spanning 25\nsubdomains, our findings reveal significant limitations in their ability to\neffectively integrate and apply world knowledge during image generation,\nhighlighting critical pathways for enhancing knowledge incorporation and\napplication in next-generation T2I models. Code and data are available at\nhttps://github.com/PKU-YuanGroup/WISE.\n","authors":["Yuwei Niu","Munan Ning","Mengren Zheng","Bin Lin","Peng Jin","Jiaqi Liao","Kunpeng Ning","Bin Zhu","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.07265v1.pdf","comment":"Code, data and leaderboard: https://github.com/PKU-YuanGroup/WISE"},{"id":"http://arxiv.org/abs/2410.14405v3","updated":"2025-03-10T12:47:31Z","published":"2024-10-18T12:08:07Z","title":"Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of\n  Language Models for Fact Completion","summary":"  Language models (LMs) can make a correct prediction based on many possible\nsignals in a prompt, not all corresponding to recall of factual associations.\nHowever, current interpretations of LMs fail to take this into account. For\nexample, given the query \"Astrid Lindgren was born in\" with the corresponding\ncompletion \"Sweden\", no difference is made between whether the prediction was\nbased on knowing where the author was born or assuming that a person with a\nSwedish-sounding name was born in Sweden. In this paper, we present a\nmodel-specific recipe - PrISM - for constructing datasets with examples of four\ndifferent prediction scenarios: generic language modeling, guesswork,\nheuristics recall and exact fact recall. We apply two popular interpretability\nmethods to the scenarios: causal tracing (CT) and information flow analysis. We\nfind that both yield distinct results for each scenario. Results for exact fact\nrecall and generic language modeling scenarios confirm previous conclusions\nabout the importance of mid-range MLP sublayers for fact recall, while results\nfor guesswork and heuristics indicate a critical role of late last token\nposition MLP sublayers. In summary, we contribute resources for a more\nextensive and granular study of fact completion in LMs, together with analyses\nthat provide a more nuanced understanding of how LMs process fact-related\nqueries.\n","authors":["Denitsa Saynova","Lovisa Hagström","Moa Johansson","Richard Johansson","Marco Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2410.14405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07237v1","updated":"2025-03-10T12:20:20Z","published":"2025-03-10T12:20:20Z","title":"LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate\n  Speech Moderation","summary":"  Content moderation is a global challenge, yet major tech platforms prioritize\nhigh-resource languages, leaving low-resource languages with scarce native\nmoderators. Since effective moderation depends on understanding contextual\ncues, this imbalance increases the risk of improper moderation due to\nnon-native moderators' limited cultural understanding. Through a user study, we\nidentify that non-native moderators struggle with interpreting\nculturally-specific knowledge, sentiment, and internet culture in the hate\nspeech moderation. To assist them, we present LLM-C3MOD, a human-LLM\ncollaborative pipeline with three steps: (1) RAG-enhanced cultural context\nannotations; (2) initial LLM-based moderation; and (3) targeted human\nmoderation for cases lacking LLM consensus. Evaluated on a Korean hate speech\ndataset with Indonesian and German participants, our system achieves 78%\naccuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by\n83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle.\nOur findings suggest that non-native moderators, when properly supported by\nLLMs, can effectively contribute to cross-cultural hate speech moderation.\n","authors":["Junyeong Park","Seogyeong Jeong","Seyoung Song","Yohan Lee","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2503.07237v1.pdf","comment":"Accepted to NAACL 2025 Workshop - C3NLP (Workshop on Cross-Cultural\n  Considerations in NLP)"},{"id":"http://arxiv.org/abs/2502.11926v2","updated":"2025-03-10T12:20:14Z","published":"2025-02-17T15:39:50Z","title":"BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion\n  Recognition Datasets for 28 Languages","summary":"  People worldwide use language in subtle and complex ways to express emotions.\nWhile emotion recognition -- an umbrella term for several NLP tasks --\nsignificantly impacts different applications in NLP and other fields, most work\nin the area is focused on high-resource languages. Therefore, this has led to\nmajor disparities in research and proposed solutions, especially for\nlow-resource languages that suffer from the lack of high-quality datasets. In\nthis paper, we present BRIGHTER -- a collection of multilabeled\nemotion-annotated datasets in 28 different languages. BRIGHTER covers\npredominantly low-resource languages from Africa, Asia, Eastern Europe, and\nLatin America, with instances from various domains annotated by fluent\nspeakers. We describe the data collection and annotation processes and the\nchallenges of building these datasets. Then, we report different experimental\nresults for monolingual and crosslingual multi-label emotion identification, as\nwell as intensity-level emotion recognition. We investigate results with and\nwithout using LLMs and analyse the large variability in performance across\nlanguages and text domains. We show that BRIGHTER datasets are a step towards\nbridging the gap in text-based emotion recognition and discuss their impact and\nutility.\n","authors":["Shamsuddeen Hassan Muhammad","Nedjma Ousidhoum","Idris Abdulmumin","Jan Philip Wahle","Terry Ruas","Meriem Beloucif","Christine de Kock","Nirmal Surange","Daniela Teodorescu","Ibrahim Said Ahmad","David Ifeoluwa Adelani","Alham Fikri Aji","Felermino D. M. A. Ali","Ilseyar Alimova","Vladimir Araujo","Nikolay Babakov","Naomi Baes","Ana-Maria Bucur","Andiswa Bukula","Guanqun Cao","Rodrigo Tufino Cardenas","Rendi Chevi","Chiamaka Ijeoma Chukwuneke","Alexandra Ciobotaru","Daryna Dementieva","Murja Sani Gadanya","Robert Geislinger","Bela Gipp","Oumaima Hourrane","Oana Ignat","Falalu Ibrahim Lawan","Rooweither Mabuya","Rahmad Mahendra","Vukosi Marivate","Andrew Piper","Alexander Panchenko","Charles Henrique Porto Ferreira","Vitaly Protasov","Samuel Rutunda","Manish Shrivastava","Aura Cristina Udrea","Lilian Diana Awuor Wanzare","Sophie Wu","Florian Valentin Wunderlich","Hanif Muhammad Zhafran","Tianhui Zhang","Yi Zhou","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2502.11926v2.pdf","comment":"20 pages, under review"},{"id":"http://arxiv.org/abs/2411.18260v3","updated":"2025-03-10T12:09:20Z","published":"2024-11-27T11:58:34Z","title":"MetaphorShare: A Dynamic Collaborative Repository of Open Metaphor\n  Datasets","summary":"  The metaphor studies community has developed numerous valuable labelled\ncorpora in various languages over the years. Many of these resources are not\nonly unknown to the NLP community, but are also often not easily shared among\nthe researchers. Both in human sciences and in NLP, researchers could benefit\nfrom a centralised database of labelled resources, easily accessible and\nunified under an identical format. To facilitate this, we present\nMetaphorShare, a website to integrate metaphor datasets making them open and\naccessible. With this effort, our aim is to encourage researchers to share and\nupload more datasets in any language in order to facilitate metaphor studies\nand the development of future metaphor processing NLP systems. The website has\nfour main functionalities: upload, download, search and label metaphor\ndatasets. It is accessible at www.metaphorshare.com.\n","authors":["Joanne Boisson","Arif Mehmood","Jose Camacho-Collados"],"pdf_url":"https://arxiv.org/pdf/2411.18260v3.pdf","comment":"Accepted in NAACL 2025 system demonstration track"},{"id":"http://arxiv.org/abs/2503.07214v1","updated":"2025-03-10T11:52:33Z","published":"2025-03-10T11:52:33Z","title":"Cross-Lingual IPA Contrastive Learning for Zero-Shot NER","summary":"  Existing approaches to zero-shot Named Entity Recognition (NER) for\nlow-resource languages have primarily relied on machine translation, whereas\nmore recent methods have shifted focus to phonemic representation. Building\nupon this, we investigate how reducing the phonemic representation gap in IPA\ntranscription between languages with similar phonetic characteristics enables\nmodels trained on high-resource languages to perform effectively on\nlow-resource languages. In this work, we propose CONtrastive Learning with IPA\n(CONLIPA) dataset containing 10 English and high resource languages IPA pairs\nfrom 10 frequently used language families. We also propose a cross-lingual IPA\nContrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our\nproposed dataset and methodology demonstrate a substantial average gain when\ncompared to the best performing baseline.\n","authors":["Jimin Sohn","David R. Mortensen"],"pdf_url":"https://arxiv.org/pdf/2503.07214v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.07195v1","updated":"2025-03-10T11:23:44Z","published":"2025-03-10T11:23:44Z","title":"Contextual Cues in Machine Translation: Investigating the Potential of\n  Multi-Source Input Strategies in LLMs and NMT Systems","summary":"  We explore the impact of multi-source input strategies on machine translation\n(MT) quality, comparing GPT-4o, a large language model (LLM), with a\ntraditional multilingual neural machine translation (NMT) system. Using\nintermediate language translations as contextual cues, we evaluate their\neffectiveness in enhancing English and Chinese translations into Portuguese.\nResults suggest that contextual information significantly improves translation\nquality for domain-specific datasets and potentially for linguistically distant\nlanguage pairs, with diminishing returns observed in benchmarks with high\nlinguistic variability. Additionally, we demonstrate that shallow fusion, a\nmulti-source approach we apply within the NMT system, shows improved results\nwhen using high-resource languages as context for other translation pairs,\nhighlighting the importance of strategic context language selection.\n","authors":["Lia Shahnazaryan","Patrick Simianer","Joern Wuebker"],"pdf_url":"https://arxiv.org/pdf/2503.07195v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2503.07190v1","updated":"2025-03-10T11:18:17Z","published":"2025-03-10T11:18:17Z","title":"Multi-Modal 3D Mesh Reconstruction from Images and Text","summary":"  6D object pose estimation for unseen objects is essential in robotics but\ntraditionally relies on trained models that require large datasets, high\ncomputational costs, and struggle to generalize. Zero-shot approaches eliminate\nthe need for training but depend on pre-existing 3D object models, which are\noften impractical to obtain. To address this, we propose a language-guided\nfew-shot 3D reconstruction method, reconstructing a 3D mesh from few input\nimages. In the proposed pipeline, receives a set of input images and a language\nquery. A combination of GroundingDINO and Segment Anything Model outputs\nsegmented masks from which a sparse point cloud is reconstructed with VGGSfM.\nSubsequently, the mesh is reconstructed with the Gaussian Splatting method\nSuGAR. In a final cleaning step, artifacts are removed, resulting in the final\n3D mesh of the queried object. We evaluate the method in terms of accuracy and\nquality of the geometry and texture. Furthermore, we study the impact of\nimaging conditions such as viewing angle, number of input images, and image\noverlap on 3D object reconstruction quality, efficiency, and computational\nscalability.\n","authors":["Melvin Reka","Tessa Pulli","Markus Vincze"],"pdf_url":"https://arxiv.org/pdf/2503.07190v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.07179v1","updated":"2025-03-10T10:56:06Z","published":"2025-03-10T10:56:06Z","title":"Strategies for political-statement segmentation and labelling in\n  unstructured text","summary":"  Analysis of parliamentary speeches and political-party manifestos has become\nan integral area of computational study of political texts. While speeches have\nbeen overwhelmingly analysed using unsupervised methods, a large corpus of\nmanifestos with by-statement political-stance labels has been created by the\nparticipants of the MARPOR project. It has been recently shown that these\nlabels can be predicted by a neural model; however, the current approach relies\non provided statement boundaries, limiting out-of-domain applicability. In this\nwork, we propose and test a range of unified split-and-label frameworks --\nbased on linear-chain CRFs, fine-tuned text-to-text models, and the combination\nof in-context learning with constrained decoding -- that can be used to jointly\nsegment and classify statements from raw textual data. We show that our\napproaches achieve competitive accuracy when applied to raw text of political\nmanifestos, and then demonstrate the research potential of our method by\napplying it to the records of the UK House of Commons and tracing the political\ntrajectories of four major parties in the last three decades.\n","authors":["Dmitry Nikolaev","Sean Papay"],"pdf_url":"https://arxiv.org/pdf/2503.07179v1.pdf","comment":"Accepted to NLP4DH 2025 @ NAACL 2025"},{"id":"http://arxiv.org/abs/2502.11995v2","updated":"2025-03-10T10:48:57Z","published":"2025-02-17T16:35:15Z","title":"Presumed Cultural Identity: How Names Shape LLM Responses","summary":"  Names are deeply tied to human identity. They can serve as markers of\nindividuality, cultural heritage, and personal history. However, using names as\na core indicator of identity can lead to over-simplification of complex\nidentities. When interacting with LLMs, user names are an important point of\ninformation for personalisation. Names can enter chatbot conversations through\ndirect user input (requested by chatbots), as part of task contexts such as CV\nreviews, or as built-in memory features that store user information for\npersonalisation. We study biases associated with names by measuring cultural\npresumptions in the responses generated by LLMs when presented with common\nsuggestion-seeking queries, which might involve making assumptions about the\nuser. Our analyses demonstrate strong assumptions about cultural identity\nassociated with names present in LLM generations across multiple cultures. Our\nwork has implications for designing more nuanced personalisation systems that\navoid reinforcing stereotypes while maintaining meaningful customisation.\n","authors":["Siddhesh Pawar","Arnav Arora","Lucie-Aimée Kaffee","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2502.11995v2.pdf","comment":"23 Pages, 13 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2503.07170v1","updated":"2025-03-10T10:48:00Z","published":"2025-03-10T10:48:00Z","title":"DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form\n  Article Generation","summary":"  Long-form article generation (LFAG) presents challenges such as maintaining\nlogical consistency, comprehensive topic coverage, and narrative coherence\nacross extended articles. Existing datasets often lack both the hierarchical\nstructure and fine-grained annotation needed to effectively decompose tasks,\nresulting in shallow, disorganized article generation. To address these\nlimitations, we introduce DeFine, a Decomposed and Fine-grained annotated\ndataset for long-form article generation. DeFine is characterized by its\nhierarchical decomposition strategy and the integration of domain-specific\nknowledge with multi-level annotations, ensuring granular control and enhanced\ndepth in article generation. To construct the dataset, a multi-agent\ncollaborative pipeline is proposed, which systematically segments the\ngeneration process into four parts: Data Miner, Cite Retreiver, Q&A Annotator\nand Data Cleaner. To validate the effectiveness of DeFine, we designed and\ntested three LFAG baselines: the web retrieval, the local retrieval, and the\ngrounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine\ntraining dataset. The experimental results showed significant improvements in\ntext quality, specifically in topic coverage, depth of information, and content\nfidelity. Our dataset publicly available to facilitate future research.\n","authors":["Ming Wang","Fang Wang","Minghao Hu","Li He","Haiyang Wang","Jun Zhang","Tianwei Yan","Li Li","Zhunchen Luo","Wei Luo","Xiaoying Bai","Guotong Geng"],"pdf_url":"https://arxiv.org/pdf/2503.07170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10645v2","updated":"2025-03-10T10:35:53Z","published":"2024-07-15T12:04:32Z","title":"Prompt Selection Matters: Enhancing Text Annotations for Social Sciences\n  with Large Language Models","summary":"  Large Language Models have recently been applied to text annotation tasks\nfrom social sciences, equalling or surpassing the performance of human workers\nat a fraction of the cost. However, no inquiry has yet been made on the impact\nof prompt selection on labelling accuracy. In this study, we show that\nperformance greatly varies between prompts, and we apply the method of\nautomatic prompt optimization to systematically craft high quality prompts. We\nalso provide the community with a simple, browser-based implementation of the\nmethod at https://prompt-ultra.github.io/ .\n","authors":["Louis Abraham","Charles Arnal","Antoine Marie"],"pdf_url":"https://arxiv.org/pdf/2407.10645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07144v1","updated":"2025-03-10T10:20:05Z","published":"2025-03-10T10:20:05Z","title":"MRCEval: A Comprehensive, Challenging and Accessible Machine Reading\n  Comprehension Benchmark","summary":"  Machine Reading Comprehension (MRC) is an essential task in evaluating\nnatural language understanding. Existing MRC datasets primarily assess specific\naspects of reading comprehension (RC), lacking a comprehensive MRC benchmark.\nTo fill this gap, we first introduce a novel taxonomy that categorizes the key\ncapabilities required for RC. Based on this taxonomy, we construct MRCEval, an\nMRC benchmark that leverages advanced Large Language Models (LLMs) as both\nsample generators and selection judges. MRCEval is a comprehensive, challenging\nand accessible benchmark designed to assess the RC capabilities of LLMs\nthoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality\nmulti-choice questions. We perform an extensive evaluation of 28 widely used\nopen-source and proprietary models, highlighting that MRC continues to present\nsignificant challenges even in the era of LLMs.\n","authors":["Shengkun Ma","Hao Peng","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2503.07144v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.07142v1","updated":"2025-03-10T10:13:55Z","published":"2025-03-10T10:13:55Z","title":"A Systematic Comparison of Syntactic Representations of Dependency\n  Parsing","summary":"  We compare the performance of a transition-based parser in regards to\ndifferent annotation schemes. We pro-pose to convert some specific syntactic\nconstructions observed in the universal dependency treebanks into a so-called\nmore standard representation and to evaluate parsing performances over all the\nlanguages of the project. We show that the ``standard'' constructions do not\nlead systematically to better parsing performance and that the scores vary\nconsiderably according to the languages.\n","authors":["Guillaume Wisniewski","Ophélie Lacroix"],"pdf_url":"https://arxiv.org/pdf/2503.07142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07140v1","updated":"2025-03-10T10:10:50Z","published":"2025-03-10T10:10:50Z","title":"Application of Multiple Chain-of-Thought in Contrastive Reasoning for\n  Implicit Sentiment Analysis","summary":"  Implicit sentiment analysis aims to uncover emotions that are subtly\nexpressed, often obscured by ambiguity and figurative language. To accomplish\nthis task, large language models and multi-step reasoning are needed to\nidentify those sentiments that are not explicitly stated. In this study, we\npropose a novel Dual Reverse Chain Reasoning (DRCR) framework to enhance the\nperformance of implicit sentiment analysis. Inspired by deductive reasoning,\nthe framework consists of three key steps: 1) hypothesize an emotional polarity\nand derive a reasoning process, 2) negate the initial hypothesis and derive a\nnew reasoning process, and 3) contrast the two reasoning paths to deduce the\nfinal sentiment polarity. Building on this, we also introduce a Triple Reverse\nChain Reasoning (TRCR) framework to address the limitations of random\nhypotheses. Both methods combine contrastive mechanisms and multi-step\nreasoning, significantly improving the accuracy of implicit sentiment\nclassification. Experimental results demonstrate that both approaches\noutperform existing methods across various model scales, achieving\nstate-of-the-art performance. This validates the effectiveness of combining\ncontrastive reasoning and multi-step reasoning for implicit sentiment analysis.\n","authors":["Liwei Yang","Xinying Wang","Xiaotang Zhou","Zhengchao Wu","Ningning Tan"],"pdf_url":"https://arxiv.org/pdf/2503.07140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07129v1","updated":"2025-03-10T09:57:50Z","published":"2025-03-10T09:57:50Z","title":"ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through\n  Action in Dynamic Offer Optimization","summary":"  Negotiation requires dynamically balancing self-interest and cooperation to\nmaximize one's own utility. Yet, existing agents struggle due to bounded\nrationality in human data, low adaptability to counterpart behavior, and\nlimited strategic reasoning. To address this, we introduce principle-driven\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\nand (3) selecting offers based on negotiation tactics and the partner's\nacceptance probability. Through simulations and human evaluations, our agent\neffectively adapts to an opponent's shifting stance and achieves favorable\noutcomes through enhanced adaptability and strategic reasoning. Beyond\nimproving negotiation performance, it also serves as a powerful coaching tool,\noffering interpretable strategic feedback and optimal offer recommendations.\n","authors":["Deuksin Kwon","Jiwon Hae","Emma Clift","Daniel Shamsoddini","Jonathan Gratch","Gale M. Lucas"],"pdf_url":"https://arxiv.org/pdf/2503.07129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03946v2","updated":"2025-03-10T09:52:25Z","published":"2024-09-06T00:02:09Z","title":"On The Role of Prompt Construction In Enhancing Efficacy and Efficiency\n  of LLM-Based Tabular Data Generation","summary":"  LLM-based data generation for real-world tabular data can be challenged by\nthe lack of sufficient semantic context in feature names used to describe\ncolumns. We hypothesize that enriching prompts with domain-specific insights\ncan improve both the quality and efficiency of data generation. To test this\nhypothesis, we explore three prompt construction protocols: Expert-guided,\nLLM-guided, and Novel-Mapping. Through empirical studies with the recently\nproposed GReaT framework, we find that context-enriched prompts lead to\nsignificantly improved data generation quality and training efficiency.\n","authors":["Banooqa Banday","Kowshik Thopalli","Tanzima Z. Islam","Jayaraman J. Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2409.03946v2.pdf","comment":"Accepted to IEEE ICASSP 2025"},{"id":"http://arxiv.org/abs/2404.12827v3","updated":"2025-03-10T09:51:28Z","published":"2024-04-19T12:04:32Z","title":"An Evaluation Benchmark for Adverse Drug Event Prediction from Clinical\n  Trial Results","summary":"  Adverse drug events (ADEs) are a major safety issue in clinical trials. Thus,\npredicting ADEs is key to developing safer medications and enhancing patient\noutcomes. To support this effort, we introduce CT-ADE, a dataset for multilabel\nADE prediction in monopharmacy treatments. CT-ADE encompasses 2,497 drugs and\n168,984 drug-ADE pairs from clinical trial results, annotated using the MedDRA\nontology. Unlike existing resources, CT-ADE integrates treatment and target\npopulation data, enabling comparative analyses under varying conditions, such\nas dosage, administration route, and demographics. In addition, CT-ADE\nsystematically collects all ADEs in the study population, including positive\nand negative cases. To provide a baseline for ADE prediction performance using\nthe CT-ADE dataset, we conducted analyses using large language models (LLMs).\nThe best LLM achieved an F1-score of 56%, with models incorporating treatment\nand patient information outperforming by 21%-38% those relying solely on the\nchemical structure. These findings underscore the importance of contextual\ninformation in ADE prediction and establish CT-ADE as a robust resource for\nsafety risk assessment in pharmaceutical research and development.\n","authors":["Anthony Yazdani","Alban Bornet","Philipp Khlebnikov","Boya Zhang","Hossein Rouhizadeh","Poorya Amini","Douglas Teodoro"],"pdf_url":"https://arxiv.org/pdf/2404.12827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18141v2","updated":"2025-03-10T09:49:31Z","published":"2024-10-22T11:23:11Z","title":"SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback","summary":"  RAG systems consist of multiple modules to work together. However, these\nmodules are usually separately trained. We argue that a system like RAG that\nincorporates multiple modules should be jointly optimized to achieve optimal\nperformance. To demonstrate this, we design a specific pipeline called\n\\textbf{SmartRAG} that includes a policy network and a retriever. The policy\nnetwork can serve as 1) a decision maker that decides when to retrieve, 2) a\nquery rewriter to generate a query most suited to the retriever, and 3) an\nanswer generator that produces the final response with/without the\nobservations. We then propose to jointly optimize the whole system using a\nreinforcement learning algorithm, with the reward designed to encourage the\nsystem to achieve the best performance with minimal retrieval cost. When\njointly optimized, all the modules can be aware of how other modules are\nworking and thus find the best way to work together as a complete system.\nEmpirical results demonstrate that the jointly optimized SmartRAG can achieve\nbetter performance than separately optimized counterparts.\n","authors":["Jingsheng Gao","Linxu Li","Weiyuan Li","Yuzhuo Fu","Bin Dai"],"pdf_url":"https://arxiv.org/pdf/2410.18141v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07111v1","updated":"2025-03-10T09:34:05Z","published":"2025-03-10T09:34:05Z","title":"PoseLess: Depth-Free Vision-to-Joint Control via Direct Image Mapping\n  with VLM","summary":"  This paper introduces PoseLess, a novel framework for robot hand control that\neliminates the need for explicit pose estimation by directly mapping 2D images\nto joint angles using tokenized representations. Our approach leverages\nsynthetic training data generated through randomized joint configurations,\nenabling zero-shot generalization to real-world scenarios and cross-morphology\ntransfer from robotic to human hands. By tokenizing visual inputs and employing\na transformer-based decoder, PoseLess achieves robust, low-latency control\nwhile addressing challenges such as depth ambiguity and data scarcity.\nExperimental results demonstrate competitive performance in joint angle\nprediction accuracy without relying on any human-labelled dataset.\n","authors":["Alan Dao","Dinh Bach Vu","Tuan Le Duc Anh","Bui Quang Huy"],"pdf_url":"https://arxiv.org/pdf/2503.07111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17477v2","updated":"2025-03-10T09:32:00Z","published":"2024-01-30T22:22:55Z","title":"Detecting mental disorder on social media: a ChatGPT-augmented\n  explainable approach","summary":"  In the digital era, the prevalence of depressive symptoms expressed on social\nmedia has raised serious concerns, necessitating advanced methodologies for\ntimely detection. This paper addresses the challenge of interpretable\ndepression detection by proposing a novel methodology that effectively combines\nLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and\nconversational agents like ChatGPT. In our methodology, explanations are\nachieved by integrating BERTweet, a Twitter-specific variant of BERT, into a\nnovel self-explanatory model, namely BERT-XDD, capable of providing both\nclassification and explanations via masked attention. The interpretability is\nfurther enhanced using ChatGPT to transform technical explanations into\nhuman-readable commentaries. By introducing an effective and modular approach\nfor interpretable depression detection, our methodology can contribute to the\ndevelopment of socially responsible digital platforms, fostering early\nintervention and support for mental health challenges under the guidance of\nqualified healthcare professionals.\n","authors":["Loris Belcastro","Riccardo Cantini","Fabrizio Marozzo","Domenico Talia","Paolo Trunfio"],"pdf_url":"https://arxiv.org/pdf/2401.17477v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04475v2","updated":"2025-03-10T09:27:03Z","published":"2024-04-06T02:29:02Z","title":"Length-Controlled AlpacaEval: A Simple Way to Debias Automatic\n  Evaluators","summary":"  LLM-based auto-annotators have become a key component of the LLM development\nprocess due to their cost-effectiveness and scalability compared to human-based\nevaluation. However, these auto-annotators can introduce biases that are hard\nto remove. Even simple, known confounders such as preference for longer outputs\nremain in existing automated evaluation metrics. We propose a simple regression\nanalysis approach for controlling biases in auto-evaluations. As a real case\nstudy, we focus on reducing the length bias of AlpacaEval, a fast and\naffordable benchmark for instruction-tuned LLMs that uses LLMs to estimate\nresponse quality. Despite being highly correlated with human preferences,\nAlpacaEval is known to favor models that generate longer outputs. We introduce\na length-controlled AlpacaEval that aims to answer the counterfactual question:\n\"What would the preference be if the model's and baseline's output had the same\nlength?\" To achieve this, we first fit a generalized linear model to predict\nthe biased auto-annotator's preferences based on the mediators we want to\ncontrol for (length difference) and other relevant features. We then obtain\nlength-controlled preferences by predicting preferences while conditioning the\nGLM with a zero difference in lengths. Length-controlling not only improves the\nrobustness of the metric to manipulations in model verbosity, but we also find\nthat it increases the Spearman correlation with LMSYS Chatbot Arena from 0.94\nto 0.98.\n","authors":["Yann Dubois","Balázs Galambosi","Percy Liang","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2404.04475v2.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2503.07094v1","updated":"2025-03-10T09:19:55Z","published":"2025-03-10T09:19:55Z","title":"A Novel Ophthalmic Benchmark for Evaluating Multimodal Large Language\n  Models with Fundus Photographs and OCT Images","summary":"  In recent years, large language models (LLMs) have demonstrated remarkable\npotential across various medical applications. Building on this foundation,\nmultimodal large language models (MLLMs) integrate LLMs with visual models to\nprocess diverse inputs, including clinical data and medical images. In\nophthalmology, LLMs have been explored for analyzing optical coherence\ntomography (OCT) reports, assisting in disease classification, and even\npredicting treatment outcomes. However, existing MLLM benchmarks often fail to\ncapture the complexities of real-world clinical practice, particularly in the\nanalysis of OCT images. Many suffer from limitations such as small sample\nsizes, a lack of diverse OCT datasets, and insufficient expert validation.\nThese shortcomings hinder the accurate assessment of MLLMs' ability to\ninterpret OCT scans and their broader applicability in ophthalmology. Our\ndataset, curated through rigorous quality control and expert annotation,\nconsists of 439 fundus images and 75 OCT images. Using a standardized API-based\nframework, we assessed seven mainstream MLLMs and observed significant\nvariability in diagnostic accuracy across different diseases. While some models\nperformed well in diagnosing conditions such as diabetic retinopathy and\nage-related macular degeneration, they struggled with others, including\nchoroidal neovascularization and myopia, highlighting inconsistencies in\nperformance and the need for further refinement. Our findings emphasize the\nimportance of developing clinically relevant benchmarks to provide a more\naccurate assessment of MLLMs' capabilities. By refining these models and\nexpanding their scope, we can enhance their potential to transform ophthalmic\ndiagnosis and treatment.\n","authors":["Xiaoyi Liang","Mouxiao Bian","Moxin Chen","Lihao Liu","Junjun He","Jie Xu","Lin Li"],"pdf_url":"https://arxiv.org/pdf/2503.07094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07078v1","updated":"2025-03-10T09:00:18Z","published":"2025-03-10T09:00:18Z","title":"Linguistic Knowledge Transfer Learning for Speech Enhancement","summary":"  Linguistic knowledge plays a crucial role in spoken language comprehension.\nIt provides essential semantic and syntactic context for speech perception in\nnoisy environments. However, most speech enhancement (SE) methods predominantly\nrely on acoustic features to learn the mapping relationship between noisy and\nclean speech, with limited exploration of linguistic integration. While\ntext-informed SE approaches have been investigated, they often require explicit\nspeech-text alignment or externally provided textual data, constraining their\npracticality in real-world scenarios. Additionally, using text as input poses\nchallenges in aligning linguistic and acoustic representations due to their\ninherent differences. In this study, we propose the Cross-Modality Knowledge\nTransfer (CMKT) learning framework, which leverages pre-trained large language\nmodels (LLMs) to infuse linguistic knowledge into SE models without requiring\ntext input or LLMs during inference. Furthermore, we introduce a misalignment\nstrategy to improve knowledge transfer. This strategy applies controlled\ntemporal shifts, encouraging the model to learn more robust representations.\nExperimental evaluations demonstrate that CMKT consistently outperforms\nbaseline models across various SE architectures and LLM embeddings,\nhighlighting its adaptability to different configurations. Additionally,\nresults on Mandarin and English datasets confirm its effectiveness across\ndiverse linguistic conditions, further validating its robustness. Moreover,\nCMKT remains effective even in scenarios without textual data, underscoring its\npracticality for real-world applications. By bridging the gap between\nlinguistic and acoustic modalities, CMKT offers a scalable and innovative\nsolution for integrating linguistic knowledge into SE models, leading to\nsubstantial improvements in both intelligibility and enhancement performance.\n","authors":["Kuo-Hsuan Hung","Xugang Lu","Szu-Wei Fu","Huan-Hsin Tseng","Hsin-Yi Lin","Chii-Wann Lin","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2503.07078v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.07067v1","updated":"2025-03-10T08:51:32Z","published":"2025-03-10T08:51:32Z","title":"DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs","summary":"  Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.\n","authors":["Jongwoo Ko","Tianyi Chen","Sungnyun Kim","Tianyu Ding","Luming Liang","Ilya Zharkov","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2503.07067v1.pdf","comment":"The code will be available soon at\n  https://github.com/jongwooko/distillm-2"},{"id":"http://arxiv.org/abs/2407.02883v2","updated":"2025-03-10T08:48:30Z","published":"2024-07-03T07:58:20Z","title":"CoIR: A Comprehensive Benchmark for Code Information Retrieval Models","summary":"  Despite the substantial success of Information Retrieval (IR) in various NLP\ntasks, most IR systems predominantly handle queries and corpora in natural\nlanguage, neglecting the domain of code retrieval. Code retrieval is critically\nimportant yet remains under-explored, with existing methods and benchmarks\ninadequately representing the diversity of code in various domains and tasks.\nAddressing this gap, we present COIR (Code Information Retrieval Benchmark), a\nrobust and comprehensive benchmark specifically designed to assess code\nretrieval capabilities. COIR comprises ten meticulously curated code datasets,\nspanning eight distinctive retrieval tasks across seven diverse domains. We\nfirst discuss the construction of COIR and its diverse dataset composition.\nFurther, we evaluate nine widely used retrieval models using COIR, uncovering\nsignificant difficulties in performing code retrieval tasks even with\nstate-of-the-art systems. To facilitate easy adoption and integration within\nexisting research workflows, COIR has been developed as a user-friendly Python\nframework, readily installable via pip. It shares same data schema as other\npopular benchmarks like MTEB and BEIR, enabling seamless cross-benchmark\nevaluations. Through COIR, we aim to invigorate research in the code retrieval\ndomain, providing a versatile benchmarking tool that encourages further\ndevelopment and exploration of code retrieval systems\nhttps://github.com/CoIR-team/coir.\n","authors":["Xiangyang Li","Kuicai Dong","Yi Quan Lee","Wei Xia","Hao Zhang","Xinyi Dai","Yasheng Wang","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2407.02883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10998v2","updated":"2025-03-10T08:45:53Z","published":"2024-06-25T09:55:22Z","title":"Discrete Diffusion Language Model for Efficient Text Summarization","summary":"  While diffusion models excel at conditional generating high-quality images,\nprior works in discrete diffusion models were not evaluated on conditional\nlong-text generation. In this work, we address the limitations of prior\ndiscrete diffusion models for conditional long-text generation, particularly in\nlong sequence-to-sequence tasks such as abstractive summarization. Despite fast\ndecoding speeds compared to autoregressive methods, previous diffusion models\nfailed on the abstractive summarization task due to the incompatibility between\nthe backbone architectures and the random noising process. To overcome these\nchallenges, we introduce a novel semantic-aware noising process that enables\nTransformer backbones to handle long sequences effectively. Additionally, we\npropose CrossMamba, an adaptation of the Mamba model to the encoder-decoder\nparadigm, which integrates seamlessly with the random absorbing noising\nprocess. Our approaches achieve state-of-the-art performance on three benchmark\nsummarization datasets: Gigaword, CNN/DailyMail, and Arxiv, outperforming\nexisting discrete diffusion models on ROUGE metrics as well as possessing much\nfaster speed in inference compared to autoregressive models.\n","authors":["Do Huu Dat","Do Duc Anh","Anh Tuan Luu","Wray Buntine"],"pdf_url":"https://arxiv.org/pdf/2407.10998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10115v2","updated":"2025-03-10T08:40:41Z","published":"2024-11-15T11:29:31Z","title":"Memorization in Attention-only Transformers","summary":"  Recent research has explored the memorization capacity of multi-head\nattention, but these findings are constrained by unrealistic limitations on the\ncontext size. We present a novel proof for language-based Transformers that\nextends the current hypothesis to any context size. Our approach improves upon\nthe state-of-the-art by achieving more effective exact memorization with an\nattention layer, while also introducing the concept of approximate memorization\nof distributions. Through experimental validation, we demonstrate that our\nproposed bounds more accurately reflect the true memorization capacity of\nlanguage models, and provide a precise comparison with prior work.\n","authors":["Léo Dana","Muni Sreenivas Pydi","Yann Chevaleyre"],"pdf_url":"https://arxiv.org/pdf/2411.10115v2.pdf","comment":"16 pages, 6 figures, submitted to AISTATS 2025,"},{"id":"http://arxiv.org/abs/2503.07044v1","updated":"2025-03-10T08:32:33Z","published":"2025-03-10T08:32:33Z","title":"DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data\n  Science","summary":"  Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.\n","authors":["Ziming You","Yumiao Zhang","Dexuan Xu","Yiwei Lou","Yandong Yan","Wei Wang","Huaming Zhang","Yu Huang"],"pdf_url":"https://arxiv.org/pdf/2503.07044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07041v1","updated":"2025-03-10T08:29:15Z","published":"2025-03-10T08:29:15Z","title":"TCM-3CEval: A Triaxial Benchmark for Assessing Responses from Large\n  Language Models in Traditional Chinese Medicine","summary":"  Large language models (LLMs) excel in various NLP tasks and modern medicine,\nbut their evaluation in traditional Chinese medicine (TCM) is underexplored. To\naddress this, we introduce TCM3CEval, a benchmark assessing LLMs in TCM across\nthree dimensions: core knowledge mastery, classical text understanding, and\nclinical decision-making. We evaluate diverse models, including international\n(e.g., GPT-4o), Chinese (e.g., InternLM), and medical-specific (e.g., PLUSE).\nResults show a performance hierarchy: all models have limitations in\nspecialized subdomains like Meridian & Acupoint theory and Various TCM Schools,\nrevealing gaps between current capabilities and clinical needs. Models with\nChinese linguistic and cultural priors perform better in classical text\ninterpretation and clinical reasoning. TCM-3CEval sets a standard for AI\nevaluation in TCM, offering insights for optimizing LLMs in culturally grounded\nmedical domains. The benchmark is available on Medbench's TCM track, aiming to\nassess LLMs' TCM capabilities in basic knowledge, classic texts, and clinical\ndecision-making through multidimensional questions and real cases.\n","authors":["Tianai Huang","Lu Lu","Jiayuan Chen","Lihao Liu","Junjun He","Yuping Zhao","Wenchao Tang","Jie Xu"],"pdf_url":"https://arxiv.org/pdf/2503.07041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07036v1","updated":"2025-03-10T08:21:36Z","published":"2025-03-10T08:21:36Z","title":"Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike\n  Against Phone Scams","summary":"  We present \"Bot Wars,\" a framework using Large Language Models (LLMs)\nscam-baiters to counter phone scams through simulated adversarial dialogues.\nOur key contribution is a formal foundation for strategy emergence through\nchain-of-thought reasoning without explicit optimization. Through a novel\ntwo-layer prompt architecture, our framework enables LLMs to craft\ndemographically authentic victim personas while maintaining strategic\ncoherence. We evaluate our approach using a dataset of 3,200 scam dialogues\nvalidated against 179 hours of human scam-baiting interactions, demonstrating\nits effectiveness in capturing complex adversarial dynamics. Our systematic\nevaluation through cognitive, quantitative, and content-specific metrics shows\nthat GPT-4 excels in dialogue naturalness and persona authenticity, while\nDeepseek demonstrates superior engagement sustainability.\n","authors":["Nardine Basta","Conor Atkins","Dali Kaafar"],"pdf_url":"https://arxiv.org/pdf/2503.07036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07032v1","updated":"2025-03-10T08:16:18Z","published":"2025-03-10T08:16:18Z","title":"Multimodal Human-AI Synergy for Medical Imaging Quality Control: A\n  Hybrid Intelligence Framework with Adaptive Dataset Curation and Closed-Loop\n  Evaluation","summary":"  Medical imaging quality control (QC) is essential for accurate diagnosis, yet\ntraditional QC methods remain labor-intensive and subjective. To address this\nchallenge, in this study, we establish a standardized dataset and evaluation\nframework for medical imaging QC, systematically assessing large language\nmodels (LLMs) in image quality assessment and report standardization.\nSpecifically, we first constructed and anonymized a dataset of 161 chest X-ray\n(CXR) radiographs and 219 CT reports for evaluation. Then, multiple LLMs,\nincluding Gemini 2.0-Flash, GPT-4o, and DeepSeek-R1, were evaluated based on\nrecall, precision, and F1 score to detect technical errors and inconsistencies.\nExperimental results show that Gemini 2.0-Flash achieved a Macro F1 score of 90\nin CXR tasks, demonstrating strong generalization but limited fine-grained\nperformance. DeepSeek-R1 excelled in CT report auditing with a 62.23\\% recall\nrate, outperforming other models. However, its distilled variants performed\npoorly, while InternLM2.5-7B-chat exhibited the highest additional discovery\nrate, indicating broader but less precise error detection. These findings\nhighlight the potential of LLMs in medical imaging QC, with DeepSeek-R1 and\nGemini 2.0-Flash demonstrating superior performance.\n","authors":["Zhi Qin","Qianhui Gui","Mouxiao Bian","Rui Wang","Hong Ge","Dandan Yao","Ziying Sun","Yuan Zhao","Yu Zhang","Hui Shi","Dongdong Wang","Chenxin Song","Shenghong Ju","Lihao Liu","Junjun He","Jie Xu","Yuan-Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07018v1","updated":"2025-03-10T07:59:41Z","published":"2025-03-10T07:59:41Z","title":"Toward Multi-Session Personalized Conversation: A Large-Scale Dataset\n  and Hierarchical Tree Framework for Implicit Reasoning","summary":"  There has been a surge in the use of large language models (LLM)\nconversational agents to generate responses based on long-term history from\nmultiple sessions. However, existing long-term open-domain dialogue datasets\nlack complex, real-world personalization and fail to capture implicit\nreasoning-where relevant information is embedded in subtle, syntactic, or\nsemantically distant connections rather than explicit statements. In such\ncases, traditional retrieval methods fail to capture relevant context, and\nlong-context modeling also becomes inefficient due to numerous complicated\npersona-related details. To address this gap, we introduce ImplexConv, a\nlarge-scale long-term dataset with 2,500 examples, each containing\napproximately 100 conversation sessions, designed to study implicit reasoning\nin personalized dialogues. Additionally, we propose TaciTree, a novel\nhierarchical tree framework that structures conversation history into multiple\nlevels of summarization. Instead of brute-force searching all data, TaciTree\nenables an efficient, level-based retrieval process where models refine their\nsearch by progressively selecting relevant details. Our experiments demonstrate\nthat TaciTree significantly improves the ability of LLMs to reason over\nlong-term conversations with implicit contextual dependencies.\n","authors":["Xintong Li","Jalend Bantupalli","Ria Dharmani","Yuwei Zhang","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.07018v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.07010v1","updated":"2025-03-10T07:47:27Z","published":"2025-03-10T07:47:27Z","title":"ProjectEval: A Benchmark for Programming Agents Automated Evaluation on\n  Project-Level Code Generation","summary":"  Recently, LLM agents have made rapid progress in improving their programming\ncapabilities. However, existing benchmarks lack the ability to automatically\nevaluate from users' perspective, and also lack the explainability of the\nresults of LLM agents' code generation capabilities. Thus, we introduce\nProjectEval, a new benchmark for LLM agents project-level code generation's\nautomated evaluation by simulating user interaction. ProjectEval is constructed\nby LLM with human reviewing. It has three different level inputs of natural\nlanguages or code skeletons. ProjectEval can evaluate the generated projects by\nuser interaction simulation for execution, and by code similarity through\nexisting objective indicators. Through ProjectEval, we find that systematic\nengineering project code, overall understanding of the project and\ncomprehensive analysis capability are the keys for LLM agents to achieve\npractical projects. Our findings and benchmark provide valuable insights for\ndeveloping more effective programming agents that can be deployed in future\nreal-world production.\n","authors":["Kaiyuan Liu","Youcheng Pan","Jing Li","Daojing He","Yang Xiang","Yexing Du","Tianrun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.07010v1.pdf","comment":"17 pages (9 Appendix pages), 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.03592v2","updated":"2025-03-10T07:36:46Z","published":"2025-03-05T15:26:59Z","title":"English K_Quantization of LLMs Does Not Disproportionately Diminish\n  Multilingual Performance","summary":"  For consumer usage of locally deployed LLMs, the GGUF format and\nk\\_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to yielded\nnon-significant results indicating that current quantization practices do not\ndisproportionately harm multilingual performance.\n","authors":["Karl Audun Borgersen"],"pdf_url":"https://arxiv.org/pdf/2503.03592v2.pdf","comment":"8 pages, 6 figures, v2"},{"id":"http://arxiv.org/abs/2503.07003v1","updated":"2025-03-10T07:34:54Z","published":"2025-03-10T07:34:54Z","title":"Large Language Models Often Say One Thing and Do Another","summary":"  As large language models (LLMs) increasingly become central to various\napplications and interact with diverse user populations, ensuring their\nreliable and consistent performance is becoming more important. This paper\nexplores a critical issue in assessing the reliability of LLMs: the consistency\nbetween their words and deeds. To quantitatively explore this consistency, we\ndeveloped a novel evaluation benchmark called the Words and Deeds Consistency\nTest (WDCT). The benchmark establishes a strict correspondence between\nword-based and deed-based questions across different domains, including opinion\nvs. action, non-ethical value vs. action, ethical value vs. action, and theory\nvs. application. The evaluation results reveal a widespread inconsistency\nbetween words and deeds across different LLMs and domains. Subsequently, we\nconducted experiments with either word alignment or deed alignment to observe\ntheir impact on the other aspect. The experimental results indicate that\nalignment only on words or deeds poorly and unpredictably influences the other\naspect. This supports our hypothesis that the underlying knowledge guiding\nLLMs' word or deed choices is not contained within a unified space.\n","authors":["Ruoxi Xu","Hongyu Lin","Xianpei Han","Jia Zheng","Weixiang Zhou","Le Sun","Yingfei Sun"],"pdf_url":"https://arxiv.org/pdf/2503.07003v1.pdf","comment":"Published on ICLR 2025"},{"id":"http://arxiv.org/abs/2502.11882v4","updated":"2025-03-10T07:25:31Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v4.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, QwQ-32b, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2503.03091v2","updated":"2025-03-10T07:14:51Z","published":"2025-03-05T01:18:11Z","title":"MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion","summary":"  Knowledge graph completion (KGC) seeks to predict missing entities (e.g.,\nheads or tails) or relationships in knowledge graphs (KGs), which often contain\nincomplete data. Traditional embedding-based methods, such as TransE and\nComplEx, have improved tail entity prediction but struggle to generalize to\nunseen entities during testing. Textual-based models mitigate this issue by\nleveraging additional semantic context; however, their reliance on negative\ntriplet sampling introduces high computational overhead, semantic\ninconsistencies, and data imbalance. Recent approaches, like KG-BERT, show\npromise but depend heavily on entity descriptions, which are often unavailable\nin KGs. Critically, existing methods overlook valuable structural information\nin the KG related to the entities and relationships. To address these\nchallenges, we propose Multi-Context-Aware Knowledge Graph Completion\n(MuCo-KGC), a novel model that utilizes contextual information from linked\nentities and relations within the graph to predict tail entities. MuCo-KGC\neliminates the need for entity descriptions and negative triplet sampling,\nsignificantly reducing computational complexity while enhancing performance.\nOur experiments on standard datasets, including FB15k-237, WN18RR, CoDEx-S, and\nCoDEx-M, demonstrate that MuCo-KGC outperforms state-of-the-art methods on\nthree datasets. Notably, MuCo-KGC improves MRR on WN18RR, and CoDEx-S and\nCoDEx-M datasets by $1.63\\%$, and $3.77\\%$ and $20.15\\%$ respectively,\ndemonstrating its effectiveness for KGC tasks.\n","authors":["Haji Gul","Ajaz Ahmad Bhat","Abdul Ghani Haji Naim"],"pdf_url":"https://arxiv.org/pdf/2503.03091v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06987v1","updated":"2025-03-10T07:06:47Z","published":"2025-03-10T07:06:47Z","title":"Social Bias Benchmark for Generation: A Comparison of Generation and\n  QA-Based Evaluations","summary":"  Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.\n","authors":["Jiho Jin","Woosung Kang","Junho Myung","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2503.06987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06980v1","updated":"2025-03-10T06:52:35Z","published":"2025-03-10T06:52:35Z","title":"Exploring Multimodal Perception in Large Language Models Through\n  Perceptual Strength Ratings","summary":"  This study investigated the multimodal perception of large language models\n(LLMs), focusing on their ability to capture human-like perceptual strength\nratings across sensory modalities. Utilizing perceptual strength ratings as a\nbenchmark, the research compared GPT-3.5, GPT-4, GPT-4o, and GPT-4o-mini,\nhighlighting the influence of multimodal inputs on grounding and linguistic\nreasoning. While GPT-4 and GPT-4o demonstrated strong alignment with human\nevaluations and significant advancements over smaller models, qualitative\nanalyses revealed distinct differences in processing patterns, such as\nmultisensory overrating and reliance on loose semantic associations. Despite\nintegrating multimodal capabilities, GPT-4o did not exhibit superior grounding\ncompared to GPT-4, raising questions about their role in improving human-like\ngrounding. These findings underscore how LLMs' reliance on linguistic patterns\ncan both approximate and diverge from human embodied cognition, revealing\nlimitations in replicating sensory experiences.\n","authors":["Jonghyun Lee","Dojun Park","Jiwoo Lee","Hoekeon Choi","Sung-Eun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.06980v1.pdf","comment":"under review, 15 pages"},{"id":"http://arxiv.org/abs/2402.07818v6","updated":"2025-03-10T06:52:03Z","published":"2024-02-12T17:24:15Z","title":"Differentially Private Zeroth-Order Methods for Scalable Large Language\n  Model Finetuning","summary":"  Fine-tuning on task-specific datasets is a widely-embraced paradigm of\nharnessing the powerful capability of pretrained LLMs for various downstream\ntasks. Due to the popularity of LLMs fine-tuning and its accompanying privacy\nconcerns, differentially private (DP) fine-tuning of pretrained LLMs has been\nwidely used to safeguarding the privacy of task-specific datasets. Lying at the\ndesign core of DP LLM fine-tuning methods is the satisfactory tradeoff among\nprivacy, utility, and scalability. Most existing methods build upon the seminal\nwork of DP-SGD. Despite pushing the scalability of DP-SGD to its limit,\nDP-SGD-based fine-tuning methods are unfortunately limited by the inherent\ninefficiency of SGD.\n  In this paper, we investigate the potential of DP zeroth-order methods for\nLLM pretraining, which avoids the scalability bottleneck of SGD by\napproximating the gradient with the more efficient zeroth-order gradient.\nRather than treating the zeroth-order method as a drop-in replacement for SGD,\nthis paper presents a comprehensive study both theoretically and empirically.\nFirst, we propose the stagewise DP zeroth-order method (DP-ZOSO) that\ndynamically schedules key hyperparameters. This design is grounded on the\nsynergy between DP random perturbation and the gradient approximation error of\nthe zeroth-order method, and its effect on fine-tuning trajectory.\n  We provide theoretical analysis for both proposed methods. We conduct\nextensive empirical analysis on both encoder-only masked language model and\ndecoder-only autoregressive language model, achieving impressive results in\nterms of scalability and utility regardless of the class of tasks (compared\nwith DPZero, DP-ZOPO improves $4.5\\%$ on SST-5, $5.5\\%$ on MNLI with\nRoBERTa-Large and 9.2\\% on CB, 3.9\\% on BoolQ with OPT-2.7b when $\\epsilon=4$,\ndemonstrates more significant enhancement in performance on more complicated\ntasks).\n","authors":["Z Liu","J Lou","W Bao","Y Hu","B Li","Z Qin","K Ren"],"pdf_url":"https://arxiv.org/pdf/2402.07818v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04809v2","updated":"2025-03-10T06:49:01Z","published":"2025-03-04T07:40:02Z","title":"PanguIR Technical Report for NTCIR-18 AEOLLM Task","summary":"  As large language models (LLMs) gain widespread attention in both academia\nand industry, it becomes increasingly critical and challenging to effectively\nevaluate their capabilities. Existing evaluation methods can be broadly\ncategorized into two types: manual evaluation and automatic evaluation. Manual\nevaluation, while comprehensive, is often costly and resource-intensive.\nConversely, automatic evaluation offers greater scalability but is constrained\nby the limitations of its evaluation criteria (dominated by reference-based\nanswers). To address these challenges, NTCIR-18 introduced the AEOLLM\n(Automatic Evaluation of LLMs) task, aiming to encourage reference-free\nevaluation methods that can overcome the limitations of existing approaches. In\nthis paper, to enhance the evaluation performance of the AEOLLM task, we\npropose three key methods to improve the reference-free evaluation: 1)\nMulti-model Collaboration: Leveraging multiple LLMs to approximate human\nratings across various subtasks; 2) Prompt Auto-optimization: Utilizing LLMs to\niteratively refine the initial task prompts based on evaluation feedback from\ntraining samples; and 3) In-context Learning (ICL) Optimization: Based on the\nmulti-task evaluation feedback, we train a specialized in-context example\nretrieval model, combined with a semantic relevance retrieval model, to jointly\nidentify the most effective in-context learning examples. Experiments conducted\non the final dataset demonstrate that our approach achieves superior\nperformance on the AEOLLM task.\n","authors":["Lang Mei","Chong Chen","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2503.04809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14855v2","updated":"2025-03-10T06:44:48Z","published":"2025-02-20T18:58:07Z","title":"Prompt-to-Leaderboard","summary":"  Large language model (LLM) evaluations typically rely on aggregated metrics\nlike accuracy or human preference, averaging across users and prompts. This\naveraging obscures user- and prompt-specific variations in model performance.\nTo address this, we propose Prompt-to-Leaderboard (P2L), a method that produces\nleaderboards specific to a prompt. The core idea is to train an LLM taking\nnatural language prompts as input to output a vector of Bradley-Terry\ncoefficients which are then used to predict the human preference vote. The\nresulting prompt-dependent leaderboards allow for unsupervised task-specific\nevaluation, optimal routing of queries to models, personalization, and\nautomated evaluation of model strengths and weaknesses. Data from Chatbot Arena\nsuggest that P2L better captures the nuanced landscape of language model\nperformance than the averaged leaderboard. Furthermore, our findings suggest\nthat P2L's ability to produce prompt-specific evaluations follows a power law\nscaling similar to that observed in LLMs themselves. In January 2025, the\nrouter we trained based on this methodology achieved the #1 spot on the Chatbot\nArena leaderboard. Our code is available on GitHub at\nhttps://github.com/lmarena/p2l.\n","authors":["Evan Frick","Connor Chen","Joseph Tennyson","Tianle Li","Wei-Lin Chiang","Anastasios N. Angelopoulos","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2502.14855v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02519v2","updated":"2025-03-10T06:22:25Z","published":"2025-03-04T11:31:05Z","title":"Generator-Assistant Stepwise Rollback Framework for Large Language Model\n  Agent","summary":"  Large language model (LLM) agents typically adopt a step-by-step reasoning\nframework, in which they interleave the processes of thinking and acting to\naccomplish the given task. However, this paradigm faces a deep-rooted one-pass\nissue whereby each generated intermediate thought is plugged into the\ntrajectory regardless of its correctness, which can cause irreversible error\npropagation. To address the issue, this paper proposes a novel framework called\nGenerator-Assistant Stepwise Rollback (GA-Rollback) to induce better\ndecision-making for LLM agents. Particularly, GA-Rollback utilizes a generator\nto interact with the environment and an assistant to examine each action\nproduced by the generator, where the assistant triggers a rollback operation\nupon detection of incorrect actions. Moreover, we introduce two additional\nstrategies tailored for the rollback scenario to further improve its\neffectiveness. Extensive experiments show that GA-Rollback achieves significant\nimprovements over several strong baselines on three widely used benchmarks. Our\nanalysis further reveals that GA-Rollback can function as a robust\nplug-and-play module, integrating seamlessly with other methods.\n","authors":["Xingzuo Li","Kehai Chen","Yunfei Long","Xuefeng Bai","Yong Xu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02519v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04773v2","updated":"2025-03-10T06:15:16Z","published":"2025-02-17T09:52:17Z","title":"Invisible Walls in Cities: Leveraging Large Language Models to Predict\n  Urban Segregation Experience with Social Media Content","summary":"  Understanding experienced segregation in urban daily life is crucial for\naddressing societal inequalities and fostering inclusivity. The abundance of\nuser-generated reviews on social media encapsulates nuanced perceptions and\nfeelings associated with different places, offering rich insights into\nsegregation. However, leveraging this data poses significant challenges due to\nits vast volume, ambiguity, and confluence of diverse perspectives. To tackle\nthese challenges, we propose using Large Language Models (LLMs) to automate\nonline review mining for segregation prediction. We design a Reflective LLM\nCoder to digest social media content into insights consistent with real-world\nfeedback, and eventually produce a codebook capturing key dimensions that\nsignal segregation experience, such as cultural resonance and appeal,\naccessibility and convenience, and community engagement and local involvement.\nGuided by the codebook, LLMs can generate both informative review summaries and\nratings for segregation prediction. Moreover, we design a\nREasoning-and-EMbedding (RE'EM) framework, which combines the reasoning and\nembedding capabilities of language models to integrate multi-channel features\nfor segregation prediction. Experiments on real-world data demonstrate that our\nframework greatly improves prediction accuracy, with a 22.79% elevation in R2\nand a 9.33% reduction in MSE. The derived codebook is generalizable across\nthree different cities, consistently improving prediction accuracy. Moreover,\nour user study confirms that the codebook-guided summaries provide cognitive\ngains for human participants in perceiving POIs' social inclusiveness. Our\nstudy marks an important step toward understanding implicit social barriers and\ninequalities, demonstrating the great potential of promoting social\ninclusiveness with AI.\n","authors":["Bingbing Fan","Lin Chen","Songwei Li","Jian Yuan","Fengli Xu","Pan Hui","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2503.04773v2.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.06950v1","updated":"2025-03-10T05:55:15Z","published":"2025-03-10T05:55:15Z","title":"CtrlRAG: Black-box Adversarial Attacks Based on Masked Language Models\n  in Retrieval-Augmented Language Generation","summary":"  Retrieval-Augmented Generation (RAG) systems enhance Large Language Models\n(LLMs) by integrating external knowledge bases. However, this integration\nintroduces a new security threat: adversaries can exploit the retrieval\nmechanism to inject malicious content into the knowledge base, thereby\ninfluencing the generated responses. Based on this attack vector, we propose\nCtrlRAG, a novel attack method designed for RAG system in the black-box\nsetting, which aligns with real-world scenarios. Unlike existing attack\nmethods, CtrlRAG introduces a perturbation mechanism using Masked Language\nModel (MLM) to dynamically optimize malicious content in response to changes in\nthe retrieved context. Experimental results demonstrate that CtrlRAG\noutperforms three baseline methods in both Emotional Manipulation and\nHallucination Amplification objectives. Furthermore, we evaluate three existing\ndefense mechanisms, revealing their limited effectiveness against CtrlRAG and\nunderscoring the urgent need for more robust defenses.\n","authors":["Runqi Sui"],"pdf_url":"https://arxiv.org/pdf/2503.06950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06949v1","updated":"2025-03-10T05:54:23Z","published":"2025-03-10T05:54:23Z","title":"Lshan-1.0 Technical Report","summary":"  In this report, we introduce our first-generation reasoning model, Lshan-1.0,\na large language model designed for the highly specialized Chinese legal\ndomain, offering comprehensive capabilities to meet diverse realistic needs.\nExisting legal LLMs face two primary challenges. Firstly, their design and\nevaluation are predominantly driven by computer science perspectives, leading\nto insufficient incorporation of legal expertise and logic, which is crucial\nfor high-precision legal applications, such as handling complex prosecutorial\ntasks. Secondly, these models often underperform due to a lack of comprehensive\ntraining data from the legal domain, limiting their ability to effectively\naddress real-world legal scenarios. To address this, we first compile millions\nof legal documents covering over 20 types of crimes from 31 provinces in China\nfor model training. From the extensive dataset, we further select high-quality\nfor supervised fine-tuning, ensuring enhanced relevance and precision. The\nmodel further undergoes large-scale reinforcement learning without additional\nsupervision, emphasizing the enhancement of its reasoning capabilities and\nexplainability. To validate its effectiveness in complex legal applications, we\nalso conduct human evaluations with legal experts. We develop fine-tuned models\nbased on DeepSeek-R1-Distilled versions, available in three dense\nconfigurations: 14B, 32B, and 70B.\n","authors":["Haotian Chen","Yanyu Xu","Boyan Wang","Chaoyue Zhao","Xiaoyu Han","Fang Wang","Lizhen Cui","Yonghui Xu"],"pdf_url":"https://arxiv.org/pdf/2503.06949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06926v1","updated":"2025-03-10T05:11:58Z","published":"2025-03-10T05:11:58Z","title":"Effect of Selection Format on LLM Performance","summary":"  This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.\n","authors":["Yuchen Han","Yucheng Wu","Jeffrey Willard"],"pdf_url":"https://arxiv.org/pdf/2503.06926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06924v1","updated":"2025-03-10T05:09:44Z","published":"2025-03-10T05:09:44Z","title":"Automatic Speech Recognition for Non-Native English: Accuracy and\n  Disfluency Handling","summary":"  Automatic speech recognition (ASR) has been an essential component of\ncomputer assisted language learning (CALL) and computer assisted language\ntesting (CALT) for many years. As this technology continues to develop rapidly,\nit is important to evaluate the accuracy of current ASR systems for language\nlearning applications. This study assesses five cutting-edge ASR systems'\nrecognition of non-native accented English speech using recordings from the\nL2-ARCTIC corpus, featuring speakers from six different L1 backgrounds (Arabic,\nChinese, Hindi, Korean, Spanish, and Vietnamese), in the form of both read and\nspontaneous speech. The read speech consisted of 2,400 single sentence\nrecordings from 24 speakers, while the spontaneous speech included narrative\nrecordings from 22 speakers. Results showed that for read speech, Whisper and\nAssemblyAI achieved the best accuracy with mean Match Error Rates (MER) of\n0.054 and 0.056 respectively, approaching human-level accuracy. For spontaneous\nspeech, RevAI performed best with a mean MER of 0.063. The study also examined\nhow each system handled disfluencies such as filler words, repetitions, and\nrevisions, finding significant variation in performance across systems and\ndisfluency types. While processing speed varied considerably between systems,\nlonger processing times did not necessarily correlate with better accuracy. By\ndetailing the performance of several of the most recent, widely-available ASR\nsystems on non-native English speech, this study aims to help language\ninstructors and researchers understand the strengths and weaknesses of each\nsystem and identify which may be suitable for specific use cases.\n","authors":["Michael McGuire"],"pdf_url":"https://arxiv.org/pdf/2503.06924v1.pdf","comment":"33 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.05280v2","updated":"2025-03-10T04:41:06Z","published":"2025-03-07T09:49:31Z","title":"Revealing Hidden Mechanisms of Cross-Country Content Moderation with\n  Natural Language Processing","summary":"  The ability of Natural Language Processing (NLP) methods to categorize text\ninto multiple classes has motivated their use in online content moderation\ntasks, such as hate speech and fake news detection. However, there is limited\nunderstanding of how or why these methods make such decisions, or why certain\ncontent is moderated in the first place. To investigate the hidden mechanisms\nbehind content moderation, we explore multiple directions: 1) training\nclassifiers to reverse-engineer content moderation decisions across countries;\n2) explaining content moderation decisions by analyzing Shapley values and\nLLM-guided explanations. Our primary focus is on content moderation decisions\nmade across countries, using pre-existing corpora sampled from the Twitter\nStream Grab. Our experiments reveal interesting patterns in censored posts,\nboth across countries and over time. Through human evaluations of LLM-generated\nexplanations across three LLMs, we assess the effectiveness of using LLMs in\ncontent moderation. Finally, we discuss potential future directions, as well as\nthe limitations and ethical considerations of this work. Our code and data are\navailable at https://github.com/causalNLP/censorship\n","authors":["Neemesh Yadav","Jiarui Liu","Francesco Ortu","Roya Ensafi","Zhijing Jin","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2503.05280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06899v1","updated":"2025-03-10T04:05:38Z","published":"2025-03-10T04:05:38Z","title":"KwaiChat: A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue\n  Corpus","summary":"  Video-based dialogue systems, such as education assistants, have compelling\napplication value, thereby garnering growing interest. However, the current\nvideo-based dialogue systems are limited by their reliance on a single dialogue\ntype, which hinders their versatility in practical applications across a range\nof scenarios, including question-answering, emotional dialog, etc. In this\npaper, we identify this challenge as how to generate video-driven multilingual\nmixed-type dialogues. To mitigate this challenge, we propose a novel task and\ncreate a human-to-human video-driven multilingual mixed-type dialogue corpus,\ntermed KwaiChat, containing a total of 93,209 videos and 246,080 dialogues,\nacross 4 dialogue types, 30 domains, 4 languages, and 13 topics. Additionally,\nwe establish baseline models on KwaiChat. An extensive analysis of 7 distinct\nLLMs on KwaiChat reveals that GPT-4o achieves the best performance but still\ncannot perform well in this situation even with the help of in-context learning\nand fine-tuning, which indicates that the task is not trivial and needs further\nresearch.\n","authors":["Xiaoming Shi","Zeming Liu","Yiming Lei","Chenkai Zhang","Haitao Leng","Chuan Wang","Qingjie Liu","Wanxiang Che","Shaoguo Liu","Size Li","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2503.06899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02235v2","updated":"2025-03-10T03:41:41Z","published":"2025-01-04T08:45:24Z","title":"Survey on Question Answering over Visually Rich Documents: Methods,\n  Challenges, and Trends","summary":"  The field of visually-rich document understanding, which involves interacting\nwith visually-rich documents (whether scanned or born-digital), is rapidly\nevolving and still lacks consensus on several key aspects of the processing\npipeline. In this work, we provide a comprehensive overview of state-of-the-art\napproaches, emphasizing their strengths and limitations, pointing out the main\nchallenges in the field, and proposing promising research directions.\n","authors":["Camille Barboule","Benjamin Piwowarski","Yoan Chabot"],"pdf_url":"https://arxiv.org/pdf/2501.02235v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06888v1","updated":"2025-03-10T03:33:45Z","published":"2025-03-10T03:33:45Z","title":"A LongFormer-Based Framework for Accurate and Efficient Medical Text\n  Summarization","summary":"  This paper proposes a medical text summarization method based on LongFormer,\naimed at addressing the challenges faced by existing models when processing\nlong medical texts. Traditional summarization methods are often limited by\nshort-term memory, leading to information loss or reduced summary quality in\nlong texts. LongFormer, by introducing long-range self-attention, effectively\ncaptures long-range dependencies in the text, retaining more key information\nand improving the accuracy and information retention of summaries. Experimental\nresults show that the LongFormer-based model outperforms traditional models,\nsuch as RNN, T5, and BERT in automatic evaluation metrics like ROUGE. It also\nreceives high scores in expert evaluations, particularly excelling in\ninformation retention and grammatical accuracy. However, there is still room\nfor improvement in terms of conciseness and readability. Some experts noted\nthat the generated summaries contain redundant information, which affects\nconciseness. Future research will focus on further optimizing the model\nstructure to enhance conciseness and fluency, achieving more efficient medical\ntext summarization. As medical data continues to grow, automated summarization\ntechnology will play an increasingly important role in fields such as medical\nresearch, clinical decision support, and knowledge management.\n","authors":["Dan Sun","Jacky He","Hanlu Zhang","Zhen Qi","Hongye Zheng","Xiaokai Wang"],"pdf_url":"https://arxiv.org/pdf/2503.06888v1.pdf","comment":"Paper accepted by 2025 8th International Conference on Advanced\n  Algorithms and Control Engineering (ICAACE 2025)"},{"id":"http://arxiv.org/abs/2503.04065v2","updated":"2025-03-10T03:22:24Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04804v2","updated":"2025-03-10T03:02:59Z","published":"2025-03-03T15:32:18Z","title":"What do Large Language Models Say About Animals? Investigating Risks of\n  Animal Harm in Generated Text","summary":"  As machine learning systems become increasingly embedded in human society,\ntheir impact on the natural world continues to escalate. Technical evaluations\nhave addressed a variety of potential harms from large language models (LLMs)\ntowards humans and the environment, but there is little empirical work\nregarding harms towards nonhuman animals. Following the growing recognition of\nanimal protection in regulatory and ethical AI frameworks, we present the\nAnimal Harm Assessment (AHA), a novel evaluation of risks of animal harm in\nLLM-generated text. Our dataset comprises 1,850 curated questions from Reddit\npost titles and 2,500 synthetic questions based on 50 animal categories (e.g.,\ncats, reptiles) and 50 ethical scenarios, with further 70-30 public-private\nsplit. Scenarios include open-ended questions about how to treat animals,\npractical scenarios with potential animal harm, and willingness-to-pay measures\nfor the prevention of animal harm. Using the LLM-as-a-judge framework, answers\nare evaluated for their potential to increase or decrease harm, and evaluations\nare debiased for the tendency to judge their own outputs more favorably. We\nshow that AHA produces meaningful evaluation results when applied to frontier\nLLMs, revealing significant differences between models, animal categories,\nscenarios, and subreddits. We conclude with future directions for technical\nresearch and the challenges of building evaluations on complex social and moral\ntopics.\n","authors":["Arturs Kanepajs","Aditi Basu","Sankalpa Ghose","Constance Li","Akshat Mehta","Ronak Mehta","Samuel David Tucker-Davis","Eric Zhou","Bob Fischer"],"pdf_url":"https://arxiv.org/pdf/2503.04804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06868v1","updated":"2025-03-10T02:44:36Z","published":"2025-03-10T02:44:36Z","title":"Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset,\n  Evaluation Framework, and Mitigation","summary":"  Existing long-text generation methods primarily concentrate on producing\nlengthy texts from short inputs, neglecting the long-input and long-output\ntasks. Such tasks have numerous practical applications while lacking available\nbenchmarks. Moreover, as the input grows in length, existing methods inevitably\nencounter the \"lost-in-the-middle\" phenomenon. In this paper, we first\nintroduce a Long Input and Output Benchmark (LongInOutBench), including a\nsynthetic dataset and a comprehensive evaluation framework, addressing the\nchallenge of the missing benchmark. We then develop the Retrieval-Augmented\nLong-Text Writer (RAL-Writer), which retrieves and restates important yet\noverlooked content, mitigating the \"lost-in-the-middle\" issue by constructing\nexplicit prompts. We finally employ the proposed LongInOutBench to evaluate our\nRAL-Writer against comparable baselines, and the results demonstrate the\neffectiveness of our approach. Our code has been released at\nhttps://github.com/OnlyAR/RAL-Writer.\n","authors":["Junhao Zhang","Richong Zhang","Fanshuang Kong","Ziyang Miao","Yanhan Ye","Yaowei Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.06868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06861v1","updated":"2025-03-10T02:39:06Z","published":"2025-03-10T02:39:06Z","title":"Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks\n  and Augmented Attention","summary":"  Extracting high-quality structured information from scientific literature is\ncrucial for advancing material design through data-driven methods. Despite the\nconsiderable research in natural language processing for dataset extraction,\neffective approaches for multi-tuple extraction in scientific literature remain\nscarce due to the complex interrelations of tuples and contextual ambiguities.\nIn the study, we illustrate the multi-tuple extraction of mechanical properties\nfrom multi-principal-element alloys and presents a novel framework that\ncombines an entity extraction model based on MatSciBERT with pointer networks\nand an allocation model utilizing inter- and intra-entity attention. Our\nrigorous experiments on tuple extraction demonstrate impressive F1 scores of\n0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples,\nconfirming the effectiveness of the model. Furthermore, an F1 score of 0.854\nwas achieved on a randomly curated dataset. These results highlight the model's\ncapacity to deliver precise and structured information, offering a robust\nalternative to large language models and equipping researchers with essential\ndata for fostering data-driven innovations.\n","authors":["Mengzhe Hei","Zhouran Zhang","Qingbao Liu","Yan Pan","Xiang Zhao","Yongqian Peng","Yicong Ye","Xin Zhang","Shuxin Bai"],"pdf_url":"https://arxiv.org/pdf/2503.06861v1.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.03122v2","updated":"2025-03-10T02:34:53Z","published":"2025-03-05T02:37:41Z","title":"The Devil Is in the Details: Tackling Unimodal Spurious Correlations for\n  Generalizable Multimodal Reward Models","summary":"  Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.\n","authors":["Zichao Li","Xueru Wen","Jie Lou","Yuqiu Ji","Yaojie Lu","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2503.03122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11492v2","updated":"2025-03-10T02:13:57Z","published":"2025-02-17T06:54:49Z","title":"Why Vision Language Models Struggle with Visual Arithmetic? Towards\n  Enhanced Chart and Geometry Understanding","summary":"  Vision Language Models (VLMs) have achieved remarkable progress in multimodal\ntasks, yet they often struggle with visual arithmetic, seemingly simple\ncapabilities like object counting or length comparison, which are essential for\nrelevant complex tasks like chart understanding and geometric reasoning. In\nthis work, we first investigate the root causes of this deficiency through a\nsuite of probing tasks focusing on basic visual arithmetic. Our analysis\nreveals that while pre-trained vision encoders typically capture sufficient\ninformation, the text decoder often fails to decode it correctly for arithmetic\nreasoning. To address this, we propose CogAlign, a novel post-training strategy\ninspired by Piaget's theory of cognitive development. CogAlign trains VLMs to\nrecognize invariant properties under visual transformations. We demonstrate\nthat this approach significantly improves the performance of three diverse VLMs\non our proposed probing tasks. Furthermore, CogAlign enhances performance by an\naverage of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching\nsupervised fine-tuning methods while requiring only 60% less training data.\nThese results highlight the effectiveness and generalizability of CogAlign in\nimproving fundamental visual arithmetic capabilities and their transfer to\ndownstream tasks.\n","authors":["Kung-Hsiang Huang","Can Qin","Haoyi Qiu","Philippe Laban","Shafiq Joty","Caiming Xiong","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2502.11492v2.pdf","comment":"Code and data are available at\n  https://github.com/SalesforceAIResearch/CogAlign"},{"id":"http://arxiv.org/abs/2503.04830v2","updated":"2025-03-10T01:47:04Z","published":"2025-03-05T08:58:35Z","title":"Cite Before You Speak: Enhancing Context-Response Grounding in\n  E-commerce Conversational LLM-Agents","summary":"  With the advancement of conversational large language models (LLMs), several\nLLM-based Conversational Shopping Agents (CSA) have been developed to help\ncustomers answer questions and smooth their shopping journey in e-commerce\ndomain. The primary objective in building a trustworthy CSA is to ensure the\nagent's responses are accurate and factually grounded, which is essential for\nbuilding customer trust and encouraging continuous engagement. However, two\nchallenges remain. First, LLMs produce hallucinated or unsupported claims. Such\ninaccuracies risk spreading misinformation and diminishing customer trust.\nSecond, without providing knowledge source attribution in CSA response,\ncustomers struggle to verify LLM-generated information. To address these\nchallenges, we present an easily productionized solution that enables a\n\"citation experience\" utilizing In-context Learning (ICL) and\nMulti-UX-Inference (MUI) to generate responses with citations to attribute its\noriginal sources without interfering other existing UX features. With proper UX\ndesign, these citation marks can be linked to the related product information\nand display the source to our customers. In this work, we also build\nauto-metrics and scalable benchmarks to holistically evaluate LLM's grounding\nand attribution capabilities. Our experiments demonstrate that incorporating\nthis citation generation paradigm can substantially enhance the grounding of\nLLM responses by 13.83% on the real-world data. As such, our solution not only\naddresses the immediate challenges of LLM grounding issues but also adds\ntransparency to conversational AI.\n","authors":["Jingying Zeng","Hui Liu","Zhenwei Dai","Xianfeng Tang","Chen Luo","Samarth Varshney","Zhen Li","Qi He"],"pdf_url":"https://arxiv.org/pdf/2503.04830v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04786v2","updated":"2025-03-10T01:43:38Z","published":"2025-02-27T14:15:43Z","title":"Analyzing the temporal dynamics of linguistic features contained in\n  misinformation","summary":"  Consumption of misinformation can lead to negative consequences that impact\nthe individual and society. To help mitigate the influence of misinformation on\nhuman beliefs, algorithmic labels providing context about content accuracy and\nsource reliability have been developed. Since the linguistic features used by\nalgorithms to estimate information accuracy can change across time, it is\nimportant to understand their temporal dynamics. As a result, this study uses\nnatural language processing to analyze PolitiFact statements spanning between\n2010 and 2024 to quantify how the sources and linguistic features of\nmisinformation change between five-year time periods. The results show that\nstatement sentiment has decreased significantly over time, reflecting a\ngenerally more negative tone in PolitiFact statements. Moreover, statements\nassociated with misinformation realize significantly lower sentiment than\naccurate information. Additional analysis shows that recent time periods are\ndominated by sources from online social networks and other digital forums, such\nas blogs and viral images, that contain high levels of misinformation\ncontaining negative sentiment. In contrast, most statements during early time\nperiods are attributed to individual sources (i.e., politicians) that are\nrelatively balanced in accuracy ratings and contain statements with neutral or\npositive sentiment. Named-entity recognition was used to identify that\npresidential incumbents and candidates are relatively more prevalent in\nstatements containing misinformation, while US states tend to be present in\naccurate information. Finally, entity labels associated with people and\norganizations are more common in misinformation, while accurate statements are\nmore likely to contain numeric entity labels, such as percentages and dates.\n","authors":["Erik J Schlicht"],"pdf_url":"https://arxiv.org/pdf/2503.04786v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22269v2","updated":"2025-03-10T23:59:12Z","published":"2024-10-29T17:27:58Z","title":"Fourier Head: Helping Large Language Models Learn Complex Probability\n  Distributions","summary":"  As the quality of large language models has improved, there has been\nincreased interest in using them to model non-linguistic tokens. For example,\nthe Decision Transformer recasts agentic decision making as a sequence modeling\nproblem, using a decoder-only LLM to model the distribution over the discrete\naction space for an Atari agent. However, when adapting LLMs to non-linguistic\ndomains, it remains unclear if softmax over discrete bins captures the\ncontinuous structure of the tokens and the potentially complex distributions\nneeded for high quality token generation. We introduce a neural network layer,\nconstructed using Fourier series, which we can easily substitute for any linear\nlayer if we want the outputs to have a more continuous structure. We perform\nextensive analysis on synthetic datasets, as well as on large-scale decision\nmaking and time series forecasting tasks. We also provide theoretical evidence\nthat this layer can better learn signal from data while ignoring high-frequency\nnoise. All of our results support the effectiveness of our proposed Fourier\nhead in scenarios where the underlying data distribution has a natural\ncontinuous structure. For example, the Fourier head improves a Decision\nTransformer agent's returns across four benchmark Atari games by as much as\n377%, and increases a state-of-the-art times series foundation model's\nforecasting performance by 3.5% across 20 benchmarks unseen during training.\n","authors":["Nate Gillman","Daksh Aggarwal","Michael Freeman","Saurabh Singh","Chen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.22269v2.pdf","comment":"Camera ready version (ICLR 2025). Code at\n  https://nategillman.com/fourier-head"},{"id":"http://arxiv.org/abs/2503.07920v1","updated":"2025-03-10T23:54:52Z","published":"2025-03-10T23:54:52Z","title":"Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural\n  Vision-Language Dataset for Southeast Asia","summary":"  Southeast Asia (SEA) is a region of extraordinary linguistic and cultural\ndiversity, yet it remains significantly underrepresented in vision-language\n(VL) research. This often results in artificial intelligence (AI) models that\nfail to capture SEA cultural nuances. To fill this gap, we present SEA-VL, an\nopen-source initiative dedicated to developing high-quality, culturally\nrelevant data for SEA languages. By involving contributors from SEA countries,\nSEA-VL aims to ensure better cultural relevance and diversity, fostering\ngreater inclusivity of underrepresented languages in VL research. Beyond\ncrowdsourcing, our initiative goes one step further in the exploration of the\nautomatic collection of culturally relevant images through crawling and image\ngeneration. First, we find that image crawling achieves approximately ~85%\ncultural relevance while being more cost- and time-efficient than\ncrowdsourcing. Second, despite the substantial progress in generative vision\nmodels, synthetic images remain unreliable in accurately reflecting SEA\ncultures. The generated images often fail to reflect the nuanced traditions and\ncultural contexts of the region. Collectively, we gather 1.28M SEA\nculturally-relevant images, more than 50 times larger than other existing\ndatasets. Through SEA-VL, we aim to bridge the representation gap in SEA,\nfostering the development of more inclusive AI systems that authentically\nrepresent diverse cultures across SEA.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Joel Ruben Antony Moniz","Tack Hwa Wong","Mohammad Rifqi Farhansyah","Thant Thiri Maung","Frederikus Hudi","David Anugraha","Muhammad Ravi Shulthan Habibi","Muhammad Reza Qorib","Amit Agarwal","Joseph Marvin Imperial","Hitesh Laxmichand Patel","Vicky Feliren","Bahrul Ilmi Nasution","Manuel Antonio Rufino","Genta Indra Winata","Rian Adam Rajagede","Carlos Rafael Catalan","Mohamed Fazli Imam","Priyaranjan Pattnayak","Salsabila Zahirah Pranida","Kevin Pratama","Yeshil Bangera","Adisai Na-Thalang","Patricia Nicole Monderin","Yueqi Song","Christian Simon","Lynnette Hui Xian Ng","Richardy Lobo' Sapan","Taki Hasan Rafi","Bin Wang"," Supryadi","Kanyakorn Veerakanjana","Piyalitt Ittichaiwong","Matthew Theodore Roque","Karissa Vincentio","Takdanai Kreangphet","Phakphum Artkaew","Kadek Hendrawan Palgunadi","Yanzhi Yu","Rochana Prih Hastuti","William Nixon","Mithil Bangera","Adrian Xuan Wei Lim","Aye Hninn Khine","Hanif Muhammad Zhafran","Teddy Ferdinan","Audra Aurora Izzani","Ayushman Singh"," Evan","Jauza Akbar Krito","Michael Anugraha","Fenal Ashokbhai Ilasariya","Haochen Li","John Amadeo Daniswara","Filbert Aurelian Tjiaranata","Eryawan Presma Yulianrifat","Can Udomcharoenchaikit","Fadil Risdian Ansori","Mahardika Krisna Ihsani","Giang Nguyen","Anab Maulana Barik","Dan John Velasco","Rifo Ahmad Genadi","Saptarshi Saha","Chengwei Wei","Isaiah Flores","Kenneth Ko Han Chen","Anjela Gail Santos","Wan Shen Lim","Kaung Si Phyo","Tim Santos","Meisyarah Dwiastuti","Jiayun Luo","Jan Christian Blaise Cruz","Ming Shan Hee","Ikhlasul Akmal Hanif","M. Alif Al Hakim","Muhammad Rizky Sya'ban","Kun Kerdthaisong","Lester James V. Miranda","Fajri Koto","Tirana Noor Fatyanosa","Alham Fikri Aji","Jostin Jerico Rosal","Jun Kevin","Robert Wijaya","Onno P. Kampman","Ruochen Zhang","Börje F. Karlsson","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2503.07920v1.pdf","comment":"SEA-VL Dataset:\n  https://huggingface.co/collections/SEACrowd/sea-vl-multicultural-vl-dataset-for-southeast-asia-67cf223d0c341d4ba2b236e7"},{"id":"http://arxiv.org/abs/2503.07919v1","updated":"2025-03-10T23:50:30Z","published":"2025-03-10T23:50:30Z","title":"BEARCUBS: A benchmark for computer-using web agents","summary":"  Modern web agents possess computer use abilities that allow them to interact\nwith webpages by sending commands to a virtual keyboard and mouse. While such\nagents have considerable potential to assist human users with complex tasks,\nevaluating their capabilities in real-world settings poses a major challenge.\nTo this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111\ninformation-seeking questions designed to evaluate a web agent's ability to\nsearch, browse, and identify factual information from the web. Unlike prior web\nagent benchmarks, solving BEARCUBS requires (1) accessing live web content\nrather than synthetic or simulated pages, which captures the unpredictability\nof real-world web interactions; and (2) performing a broad range of multimodal\ninteractions (e.g., video understanding, 3D navigation) that cannot be bypassed\nvia text-based workarounds. Each question in BEARCUBS has a corresponding\nshort, unambiguous answer and a human-validated browsing trajectory, allowing\nfor transparent evaluation of agent performance and strategies. A human study\nconfirms that BEARCUBS questions are solvable but non-trivial (84.7% human\naccuracy), revealing search inefficiencies and domain knowledge gaps as common\nfailure points. By contrast, state-of-the-art computer-using agents\nunderperform, with the best-scoring system (OpenAI's Operator) reaching only\n24.3% accuracy. These results highlight critical areas for improvement,\nincluding reliable source selection and more powerful multimodal capabilities.\nTo facilitate future research, BEARCUBS will be updated periodically to replace\ninvalid or contaminated questions, keeping the benchmark fresh for future\ngenerations of web agents.\n","authors":["Yixiao Song","Katherine Thai","Chau Minh Pham","Yapei Chang","Mazin Nadaf","Mohit Iyyer"],"pdf_url":"https://arxiv.org/pdf/2503.07919v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2503.07914v1","updated":"2025-03-10T23:17:46Z","published":"2025-03-10T23:17:46Z","title":"Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of\n  Inferring Ratings from Reviews","summary":"  Interpretable machine learning models offer understandable reasoning behind\ntheir decision-making process, though they may not always match the performance\nof their black-box counterparts. This trade-off between interpretability and\nmodel performance has sparked discussions around the deployment of AI,\nparticularly in critical applications where knowing the rationale of\ndecision-making is essential for trust and accountability. In this study, we\nconduct a comparative analysis of several black-box and interpretable models,\nfocusing on a specific NLP use case that has received limited attention:\ninferring ratings from reviews. Through this use case, we explore the intricate\nrelationship between the performance and interpretability of different models.\nWe introduce a quantitative score called Composite Interpretability (CI) to\nhelp visualize the trade-off between interpretability and performance,\nparticularly in the case of composite models. Our results indicate that, in\ngeneral, the learning performance improves as interpretability decreases, but\nthis relationship is not strictly monotonic, and there are instances where\ninterpretable models are more advantageous.\n","authors":["Pranjal Atrey","Michael P. Brundage","Min Wu","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2503.07914v1.pdf","comment":"Accepted at DAI Workshop, AAAI-2025"},{"id":"http://arxiv.org/abs/2411.09009v2","updated":"2025-03-10T23:08:54Z","published":"2024-11-13T20:30:15Z","title":"Cut Your Losses in Large-Vocabulary Language Models","summary":"  As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence.\n","authors":["Erik Wijmans","Brody Huval","Alexander Hertzberg","Vladlen Koltun","Philipp Krähenbühl"],"pdf_url":"https://arxiv.org/pdf/2411.09009v2.pdf","comment":"To appear in ICLR 2025 (Oral). Code is available at\n  https://github.com/apple/ml-cross-entropy"},{"id":"http://arxiv.org/abs/2503.07903v1","updated":"2025-03-10T22:48:53Z","published":"2025-03-10T22:48:53Z","title":"Can Memory-Augmented Language Models Generalize on\n  Reasoning-in-a-Haystack Tasks?","summary":"  Large language models often expose their brittleness in reasoning tasks,\nespecially while executing long chains of reasoning over context. We propose\nMemReasoner, a new and simple memory-augmented LLM architecture, in which the\nmemory learns the relative order of facts in context, and enables hopping over\nthem, while the decoder selectively attends to the memory. MemReasoner is\ntrained end-to-end, with optional supporting fact supervision of varying\ndegrees. We train MemReasoner, along with existing memory-augmented transformer\nmodels and a state-space model, on two distinct synthetic multi-hop reasoning\ntasks. Experiments performed under a variety of challenging scenarios,\nincluding the presence of long distractor text or target answer changes in test\nset, show strong generalization of MemReasoner on both single- and two-hop\ntasks. This generalization of MemReasoner is achieved using none-to-weak\nsupporting fact supervision (using none and 1\\% of supporting facts for one-\nand two-hop tasks, respectively). In contrast, baseline models overall struggle\nto generalize and benefit far less from using full supporting fact supervision.\nThe results highlight the importance of explicit memory mechanisms, combined\nwith additional weak supervision, for improving large language model's context\nprocessing ability toward reasoning tasks.\n","authors":["Payel Das","Ching-Yun Ko","Sihui Dai","Georgios Kollias","Subhajit Chaudhury","Aurelie Lozano"],"pdf_url":"https://arxiv.org/pdf/2503.07903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07891v1","updated":"2025-03-10T22:16:45Z","published":"2025-03-10T22:16:45Z","title":"Gemini Embedding: Generalizable Embeddings from Gemini","summary":"  In this report, we introduce Gemini Embedding, a state-of-the-art embedding\nmodel leveraging the power of Gemini, Google's most capable large language\nmodel. Capitalizing on Gemini's inherent multilingual and code understanding\ncapabilities, Gemini Embedding produces highly generalizable embeddings for\ntext spanning numerous languages and textual modalities. The representations\ngenerated by Gemini Embedding can be precomputed and applied to a variety of\ndownstream tasks including classification, similarity, clustering, ranking, and\nretrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark\n(MMTEB), which includes over one hundred tasks across 250+ languages, Gemini\nEmbedding substantially outperforms prior state-of-the-art models,\ndemonstrating considerable improvements in embedding quality. Achieving\nstate-of-the-art performance across MMTEB's multilingual, English, and code\nbenchmarks, our unified model demonstrates strong capabilities across a broad\nselection of tasks and surpasses specialized domain-specific models.\n","authors":["Jinhyuk Lee","Feiyang Chen","Sahil Dua","Daniel Cer","Madhuri Shanbhogue","Iftekhar Naim","Gustavo Hernández Ábrego","Zhe Li","Kaifeng Chen","Henrique Schechter Vera","Xiaoqi Ren","Shanfeng Zhang","Daniel Salz","Michael Boratko","Jay Han","Blair Chen","Shuo Huang","Vikram Rao","Paul Suganthan","Feng Han","Andreas Doumanoglou","Nithi Gupta","Fedor Moiseev","Cathy Yip","Aashi Jain","Simon Baumgartner","Shahrokh Shahi","Frank Palma Gomez","Sandeep Mariserla","Min Choi","Parashar Shah","Sonam Goenka","Ke Chen","Ye Xia","Koert Chen","Sai Meher Karthik Duddu","Yichang Chen","Trevor Walker","Wenlei Zhou","Rakesh Ghiya","Zach Gleicher","Karan Gill","Zhe Dong","Mojtaba Seyedhosseini","Yunhsuan Sung","Raphael Hoffmann","Tom Duerig"],"pdf_url":"https://arxiv.org/pdf/2503.07891v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2501.13778v2","updated":"2025-03-10T22:15:10Z","published":"2025-01-23T15:55:07Z","title":"Explainable XR: Understanding User Behaviors of XR Environments using\n  LLM-assisted Analytics Framework","summary":"  We present Explainable XR, an end-to-end framework for analyzing user\nbehavior in diverse eXtended Reality (XR) environments by leveraging Large\nLanguage Models (LLMs) for data interpretation assistance. Existing XR user\nanalytics frameworks face challenges in handling cross-virtuality - AR, VR, MR\n- transitions, multi-user collaborative application scenarios, and the\ncomplexity of multimodal data. Explainable XR addresses these challenges by\nproviding a virtuality-agnostic solution for the collection, analysis, and\nvisualization of immersive sessions. We propose three main components in our\nframework: (1) A novel user data recording schema, called User Action\nDescriptor (UAD), that can capture the users' multimodal actions, along with\ntheir intents and the contexts; (2) a platform-agnostic XR session recorder,\nand (3) a visual analytics interface that offers LLM-assisted insights tailored\nto the analysts' perspectives, facilitating the exploration and analysis of the\nrecorded XR session data. We demonstrate the versatility of Explainable XR by\ndemonstrating five use-case scenarios, in both individual and collaborative XR\napplications across virtualities. Our technical evaluation and user studies\nshow that Explainable XR provides a highly usable analytics solution for\nunderstanding user actions and delivering multifaceted, actionable insights\ninto user behaviors in immersive environments.\n","authors":["Yoonsang Kim","Zainab Aamir","Mithilesh Singh","Saeed Boorboor","Klaus Mueller","Arie E. Kaufman"],"pdf_url":"https://arxiv.org/pdf/2501.13778v2.pdf","comment":"11 pages, 8 figures. This is the author's version of the article that\n  has been accepted for publication in IEEE Transactions on Visualization and\n  Computer Graphics"},{"id":"http://arxiv.org/abs/2410.16162v3","updated":"2025-03-10T22:01:59Z","published":"2024-10-21T16:26:09Z","title":"Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models\n  Elicits Generalization to Spatial Reasoning","summary":"  Vision language models (VLMs) have demonstrated impressive performance across\na wide range of downstream tasks. However, their proficiency in spatial\nreasoning remains limited, despite its crucial role in tasks involving\nnavigation and interaction with physical environments. Specifically, most of\nthese tasks rely on the core spatial reasoning capabilities in two-dimensional\n(2D) environments, and our evaluation reveals that state-of-the-art VLMs\nfrequently generate implausible and incorrect responses to composite spatial\nreasoning problems, including simple pathfinding tasks that humans can solve\neffortlessly at a glance. To address this, we explore an effective approach to\nenhance 2D spatial reasoning within VLMs by training the model solely on basic\nspatial capabilities. We begin by disentangling the key components of 2D\nspatial reasoning: direction comprehension, distance estimation, and\nlocalization. Our central hypothesis is that mastering these basic spatial\ncapabilities can significantly enhance a model's performance on composite\nspatial tasks requiring advanced spatial understanding and combinatorial\nproblem-solving, with generalized improvements in real-world visual-spatial\ntasks. To investigate this hypothesis, we introduce Sparkle: a framework that\nuses synthetic data generation to provide targeted supervision for vision\nlanguage models (VLMs) in three basic spatial capabilities, creating an\ninstruction dataset for each capability. Our experiments demonstrate that VLMs\nfine-tuned with Sparkle achieve significant performance gains, not only in the\nbasic tasks themselves but also in generalizing to composite and\nout-of-distribution real-world spatial reasoning tasks. These findings offer\ninsights into systematic strategies for improving VLMs' spatial reasoning\ncapabilities.\n","authors":["Yihong Tang","Ao Qu","Zhaokai Wang","Dingyi Zhuang","Zhaofeng Wu","Wei Ma","Shenhao Wang","Yunhan Zheng","Zhan Zhao","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.16162v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07879v1","updated":"2025-03-10T21:51:17Z","published":"2025-03-10T21:51:17Z","title":"Datasets, Documents, and Repetitions: The Practicalities of Unequal Data\n  Quality","summary":"  Data filtering has become a powerful tool for improving model performance\nwhile reducing computational cost. However, as large language model compute\nbudgets continue to grow, the limited data volume provided by heavily filtered\nand deduplicated datasets will become a practical constraint. In efforts to\nbetter understand how to proceed, we study model performance at various compute\nbudgets and across multiple pre-training datasets created through data\nfiltering and deduplication. We find that, given appropriate modifications to\nthe training recipe, repeating existing aggressively filtered datasets for up\nto ten epochs can outperform training on the ten times larger superset for a\nsingle epoch across multiple compute budget orders of magnitude. While this\nfinding relies on repeating the dataset for many epochs, we also investigate\nrepeats within these datasets at the document level. We find that not all\ndocuments within a dataset are equal, and we can create better datasets\nrelative to a token budget by explicitly manipulating the counts of individual\ndocuments. We conclude by arguing that even as large language models scale,\ndata filtering remains an important direction of research.\n","authors":["Alex Fang","Hadi Pouransari","Matt Jordan","Alexander Toshev","Vaishaal Shankar","Ludwig Schmidt","Tom Gunter"],"pdf_url":"https://arxiv.org/pdf/2503.07879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07871v1","updated":"2025-03-10T21:37:22Z","published":"2025-03-10T21:37:22Z","title":"MapQA: Open-domain Geospatial Question Answering on Map Data","summary":"  Geospatial question answering (QA) is a fundamental task in navigation and\npoint of interest (POI) searches. While existing geospatial QA datasets exist,\nthey are limited in both scale and diversity, often relying solely on textual\ndescriptions of geo-entities without considering their geometries. A major\nchallenge in scaling geospatial QA datasets for reasoning lies in the\ncomplexity of geospatial relationships, which require integrating spatial\nstructures, topological dependencies, and multi-hop reasoning capabilities that\nmost text-based QA datasets lack. To address these limitations, we introduce\nMapQA, a novel dataset that not only provides question-answer pairs but also\nincludes the geometries of geo-entities referenced in the questions. MapQA is\nconstructed using SQL query templates to extract question-answer pairs from\nOpenStreetMap (OSM) for two study regions: Southern California and Illinois. It\nconsists of 3,154 QA pairs spanning nine question types that require geospatial\nreasoning, such as neighborhood inference and geo-entity type identification.\nCompared to existing datasets, MapQA expands both the number and diversity of\ngeospatial question types. We explore two approaches to tackle this challenge:\n(1) a retrieval-based language model that ranks candidate geo-entities by\nembedding similarity, and (2) a large language model (LLM) that generates SQL\nqueries from natural language questions and geo-entity attributes, which are\nthen executed against an OSM database. Our findings indicate that\nretrieval-based methods effectively capture concepts like closeness and\ndirection but struggle with questions that require explicit computations (e.g.,\ndistance calculations). LLMs (e.g., GPT and Gemini) excel at generating SQL\nqueries for one-hop reasoning but face challenges with multi-hop reasoning,\nhighlighting a key bottleneck in advancing geospatial QA systems.\n","authors":["Zekun Li","Malcolm Grossman"," Eric"," Qasemi","Mihir Kulkarni","Muhao Chen","Yao-Yi Chiang"],"pdf_url":"https://arxiv.org/pdf/2503.07871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16810v2","updated":"2025-03-10T21:33:53Z","published":"2024-06-24T17:22:36Z","title":"How Data Inter-connectivity Shapes LLMs Unlearning: A Structural\n  Unlearning Perspective","summary":"  While unlearning knowledge from large language models (LLMs) is receiving\nincreasing attention, one important aspect remains unexplored. Existing\napproaches and benchmarks assume data points to-be-forgotten are independent,\nignoring their inter-connectivity - a fundamental characteristic of real-world\ndata structures. In this paper, we propose PISTOL, a method for compiling\nstructural datasets. PISTOL leverages the inherently structured nature of\ncontractual relationships, offering several key benefits. First, it enables\ninsights into the impact of structural data on unlearning effectiveness.\nSecond, it provides precise and concise ground truths for clearer evaluation.\nThird, its attribute generation does not require input from pre-trained LLMs,\nmitigating confounding risks. Leveraging datasets synthesized using PISTOL, we\ndemonstrate how data inter-connectivity impacts LLM unlearning. Specifically,\n(a) in both the pre-trained and fine-tuned models, unlearning difficulty\nincreases as data inter-connectivity grows, (b) there is a positive correlation\nbetween the density of the knowledge graph and unlearning difficulty, and (c)\nwhen the to-be-forgotten data is skewed towards one domain, balancing retaining\nperformance across all domains is challenging.\n","authors":["Xinchi Qiu","William F. Shen","Yihong Chen","Meghdad Kurmanji","Nicola Cancedda","Pontus Stenetorp","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2406.16810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07862v1","updated":"2025-03-10T21:21:13Z","published":"2025-03-10T21:21:13Z","title":"cantnlp@DravidianLangTech-2025: A Bag-of-Sounds Approach to Multimodal\n  Hate Speech Detection","summary":"  This paper presents the systems and results for the Multimodal Social Media\nData Analysis in Dravidian Languages (MSMDA-DL) shared task at the Fifth\nWorkshop on Speech, Vision, and Language Technologies for Dravidian Languages\n(DravidianLangTech-2025). We took a `bag-of-sounds' approach by training our\nhate speech detection system on the speech (audio) data using transformed Mel\nspectrogram measures. While our candidate model performed poorly on the test\nset, our approach offered promising results during training and development for\nMalayalam and Tamil. With sufficient and well-balanced training data, our\nresults show that it is feasible to use both text and speech (audio) data in\nthe development of multimodal hate speech detection systems.\n","authors":["Sidney Wong","Andrew Li"],"pdf_url":"https://arxiv.org/pdf/2503.07862v1.pdf","comment":"Accepted Fifth Workshop on Speech and Language Technologies for\n  Dravidian Languages"},{"id":"http://arxiv.org/abs/2411.10639v2","updated":"2025-03-10T20:59:22Z","published":"2024-11-16T00:14:13Z","title":"MTA: Multimodal Task Alignment for BEV Perception and Captioning","summary":"  Bird's eye view (BEV)-based 3D perception plays a crucial role in autonomous\ndriving applications. The rise of large language models has spurred interest in\nBEV-based captioning to understand object behavior in the surrounding\nenvironment. However, existing approaches treat perception and captioning as\nseparate tasks, focusing on the performance of only one task and overlooking\nthe potential benefits of multimodal alignment. To bridge this gap between\nmodalities, we introduce MTA, a novel multimodal task alignment framework that\nboosts both BEV perception and captioning. MTA consists of two key components:\n(1) BEV-Language Alignment (BLA), a contextual learning mechanism that aligns\nthe BEV scene representations with ground-truth language representations, and\n(2) Detection-Captioning Alignment (DCA), a cross-modal prompting mechanism\nthat aligns detection and captioning outputs. MTA seamlessly integrates into\nstate-of-the-art baselines during training, adding no extra computational\ncomplexity at runtime. Extensive experiments on the nuScenes and TOD3Cap\ndatasets show that MTA significantly outperforms state-of-the-art baselines in\nboth tasks, achieving a 10.7% improvement in challenging rare perception\nscenarios and a 9.2% improvement in captioning. These results underscore the\neffectiveness of unified alignment in reconciling BEV-based perception and\ncaptioning.\n","authors":["Yunsheng Ma","Burhaneddin Yaman","Xin Ye","Jingru Luo","Feng Tao","Abhirup Mallik","Ziran Wang","Liu Ren"],"pdf_url":"https://arxiv.org/pdf/2411.10639v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.07833v1","updated":"2025-03-10T20:24:07Z","published":"2025-03-10T20:24:07Z","title":"HalluVerse25: Fine-grained Multilingual Benchmark Dataset for LLM\n  Hallucinations","summary":"  Large Language Models (LLMs) are increasingly used in various contexts, yet\nremain prone to generating non-factual content, commonly referred to as\n\"hallucinations\". The literature categorizes hallucinations into several types,\nincluding entity-level, relation-level, and sentence-level hallucinations.\nHowever, existing hallucination datasets often fail to capture fine-grained\nhallucinations in multilingual settings. In this work, we introduce\nHalluVerse25, a multilingual LLM hallucination dataset that categorizes\nfine-grained hallucinations in English, Arabic, and Turkish. Our dataset\nconstruction pipeline uses an LLM to inject hallucinations into factual\nbiographical sentences, followed by a rigorous human annotation process to\nensure data quality. We evaluate several LLMs on HalluVerse25, providing\nvaluable insights into how proprietary models perform in detecting\nLLM-generated hallucinations across different contexts.\n","authors":["Samir Abdaljalil","Hasan Kurban","Erchin Serpedin"],"pdf_url":"https://arxiv.org/pdf/2503.07833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07832v1","updated":"2025-03-10T20:23:24Z","published":"2025-03-10T20:23:24Z","title":"RefactorBench: Evaluating Stateful Reasoning in Language Agents Through\n  Code","summary":"  Recent advances in language model (LM) agents and function calling have\nenabled autonomous, feedback-driven systems to solve problems across various\ndigital domains. To better understand the unique limitations of LM agents, we\nintroduce RefactorBench, a benchmark consisting of 100 large handcrafted\nmulti-file refactoring tasks in popular open-source repositories. Solving tasks\nwithin RefactorBench requires thorough exploration of dependencies across\nmultiple files and strong adherence to relevant instructions. Every task is\ndefined by 3 natural language instructions of varying specificity and is\nmutually exclusive, allowing for the creation of longer combined tasks on the\nsame repository. Baselines on RefactorBench reveal that current LM agents\nstruggle with simple compositional tasks, solving only 22% of tasks with base\ninstructions, in contrast to a human developer with short time constraints\nsolving 87%. Through trajectory analysis, we identify various unique failure\nmodes of LM agents, and further explore the failure mode of tracking past\nactions. By adapting a baseline agent to condition on representations of state,\nwe achieve a 43.9% improvement in solving RefactorBench tasks. We further\nextend our state-aware approach to encompass entire digital environments and\noutline potential directions for future research. RefactorBench aims to support\nthe study of LM agents by providing a set of real-world, multi-hop tasks within\nthe realm of code.\n","authors":["Dhruv Gautam","Spandan Garg","Jinu Jang","Neel Sundaresan","Roshanak Zilouchian Moghaddam"],"pdf_url":"https://arxiv.org/pdf/2503.07832v1.pdf","comment":"ICLR 2025 Camera Ready"},{"id":"http://arxiv.org/abs/2503.07827v1","updated":"2025-03-10T20:16:01Z","published":"2025-03-10T20:16:01Z","title":"Modern Models, Medieval Texts: A POS Tagging Study of Old Occitan","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing, yet their effectiveness in handling historical\nlanguages remains largely unexplored. This study examines the performance of\nopen-source LLMs in part-of-speech (POS) tagging for Old Occitan, a historical\nlanguage characterized by non-standardized orthography and significant\ndiachronic variation. Through comparative analysis of two distinct\ncorpora-hagiographical and medical texts-we evaluate how current models handle\nthe inherent challenges of processing a low-resource historical language. Our\nfindings demonstrate critical limitations in LLM performance when confronted\nwith extreme orthographic and syntactic variability. We provide detailed error\nanalysis and specific recommendations for improving model performance in\nhistorical language processing. This research advances our understanding of LLM\ncapabilities in challenging linguistic contexts while offering practical\ninsights for both computational linguistics and historical language studies.\n","authors":["Matthias Schöffel","Marinus Wiedner","Esteban Garces Arias","Paula Ruppert","Christian Heumann","Matthias Aßenmacher"],"pdf_url":"https://arxiv.org/pdf/2503.07827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07826v1","updated":"2025-03-10T20:13:07Z","published":"2025-03-10T20:13:07Z","title":"Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph\n  Translation","summary":"  Large language models (LLMs) have exhibited the ability to effectively\nutilize external tools to address user queries. However, their performance may\nbe limited in complex, multi-turn interactions involving users and multiple\ntools. To address this, we propose Magnet, a principled framework for\nsynthesizing high-quality training trajectories to enhance the function calling\ncapability of large language model agents in multi-turn conversations with\nhumans. The framework is based on automatic and iterative translations from a\nfunction signature path to a sequence of queries and executable function calls.\nWe model the complicated function interactions in multi-turn cases with graph\nand design novel node operations to build reliable signature paths. Motivated\nby context distillation, when guiding the generation of positive and negative\ntrajectories using a teacher model, we provide reference function call\nsequences as positive hints in context and contrastive, incorrect function\ncalls as negative hints. Experiments show that training with the positive\ntrajectories with supervised fine-tuning and preference optimization against\nnegative trajectories, our 14B model, Magnet-14B-mDPO, obtains 68.01 on BFCL-v3\nand 73.30 on ToolQuery, surpassing the performance of the teacher model\nGemini-1.5-pro-002 by a large margin in function calling.\n","authors":["Fan Yin","Zifeng Wang","I-Hung Hsu","Jun Yan","Ke Jiang","Yanfei Chen","Jindong Gu","Long T. Le","Kai-Wei Chang","Chen-Yu Lee","Hamid Palangi","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2503.07826v1.pdf","comment":"12 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2407.02646v2","updated":"2025-03-10T19:55:22Z","published":"2024-07-02T20:28:16Z","title":"A Practical Review of Mechanistic Interpretability for Transformer-Based\n  Language Models","summary":"  Mechanistic interpretability (MI) is an emerging sub-field of\ninterpretability that seeks to understand a neural network model by\nreverse-engineering its internal computations. Recently, MI has garnered\nsignificant attention for interpreting transformer-based language models (LMs),\nresulting in many novel insights yet introducing new challenges. However, there\nhas not been work that comprehensively reviews these insights and challenges,\nparticularly as a guide for newcomers to this field. To fill this gap, we\nprovide a comprehensive survey from a task-centric perspective, organizing the\ntaxonomy of MI research around specific research questions or tasks. We outline\nthe fundamental objects of study in MI, along with the techniques, evaluation\nmethods, and key findings for each task in the taxonomy. In particular, we\npresent a task-centric taxonomy as a roadmap for beginners to navigate the\nfield by helping them quickly identify impactful problems in which they are\nmost interested and leverage MI for their benefit. Finally, we discuss the\ncurrent gaps in the field and suggest potential future directions for MI\nresearch.\n","authors":["Daking Rai","Yilun Zhou","Shi Feng","Abulhair Saparov","Ziyu Yao"],"pdf_url":"https://arxiv.org/pdf/2407.02646v2.pdf","comment":"35 pages, 13 figures, Preprint"},{"id":"http://arxiv.org/abs/2503.07807v1","updated":"2025-03-10T19:40:25Z","published":"2025-03-10T19:40:25Z","title":"Training Domain Draft Models for Speculative Decoding: Best Practices\n  and Insights","summary":"  Speculative decoding is an effective method for accelerating inference of\nlarge language models (LLMs) by employing a small draft model to predict the\noutput of a target model. However, when adapting speculative decoding to\ndomain-specific target models, the acceptance rate of the generic draft model\ndrops significantly due to domain shift. In this work, we systematically\ninvestigate knowledge distillation techniques for training domain draft models\nto improve their speculation accuracy. We compare white-box and black-box\ndistillation approaches and explore their effectiveness in various data\naccessibility scenarios, including historical user queries, curated domain\ndata, and synthetically generated alignment data. Our experiments across\nFunction Calling, Biology, and Chinese domains show that offline distillation\nconsistently outperforms online distillation by 11% to 25%, white-box\ndistillation surpasses black-box distillation by 2% to 10%, and data scaling\ntrends hold across domains. Additionally, we find that synthetic data can\neffectively align draft models and achieve 80% to 93% of the performance of\ntraining on historical user queries. These findings provide practical\nguidelines for training domain-specific draft models to improve speculative\ndecoding efficiency.\n","authors":["Fenglu Hong","Ravi Raju","Jonathan Lingjie Li","Bo Li","Urmish Thakker","Avinash Ravichandran","Swayambhoo Jain","Changran Hu"],"pdf_url":"https://arxiv.org/pdf/2503.07807v1.pdf","comment":"Published as a workshop paper at SCOPE - ICLR 2025"},{"id":"http://arxiv.org/abs/2503.07806v1","updated":"2025-03-10T19:39:39Z","published":"2025-03-10T19:39:39Z","title":"Towards Large Language Models that Benefit for All: Benchmarking Group\n  Fairness in Reward Models","summary":"  As Large Language Models (LLMs) become increasingly powerful and accessible\nto human users, ensuring fairness across diverse demographic groups, i.e.,\ngroup fairness, is a critical ethical concern. However, current fairness and\nbias research in LLMs is limited in two aspects. First, compared to traditional\ngroup fairness in machine learning classification, it requires that the\nnon-sensitive attributes, in this case, the prompt questions, be the same\nacross different groups. In many practical scenarios, different groups,\nhowever, may prefer different prompt questions and this requirement becomes\nimpractical. Second, it evaluates group fairness only for the LLM's final\noutput without identifying the source of possible bias. Namely, the bias in\nLLM's output can result from both the pretraining and the finetuning. For\nfinetuning, the bias can result from both the RLHF procedure and the learned\nreward model. Arguably, evaluating the group fairness of each component in the\nLLM pipeline could help develop better methods to mitigate the possible bias.\nRecognizing those two limitations, this work benchmarks the group fairness of\nlearned reward models. By using expert-written text from arXiv, we are able to\nbenchmark the group fairness of reward models without requiring the same prompt\nquestions across different demographic groups. Surprisingly, our results\ndemonstrate that all the evaluated reward models (e.g., Nemotron-4-340B-Reward,\nArmoRM-Llama3-8B-v0.1, and GRM-llama3-8B-sftreg) exhibit statistically\nsignificant group unfairness. We also observed that top-performing reward\nmodels (w.r.t. canonical performance metrics) tend to demonstrate better group\nfairness.\n","authors":["Kefan Song","Jin Yao","Runnan Jiang","Rohan Chandra","Shangtong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.03678v2","updated":"2025-03-10T19:34:32Z","published":"2025-02-05T23:53:08Z","title":"Reflection-Window Decoding: Text Generation with Selective Refinement","summary":"  The autoregressive decoding for text generation in large language models\n(LLMs), while widely used, is inherently suboptimal due to the lack of a\nbuilt-in mechanism to perform refinement and/or correction of the generated\ncontent. In this paper, we consider optimality in terms of the joint\nprobability over the generated response, when jointly considering all tokens at\nthe same time. We theoretically characterize the potential deviation of the\nautoregressively generated response from its globally optimal counterpart that\nis of the same length. Our analysis suggests that we need to be cautious when\nnoticeable uncertainty arises during text generation, which may signal the\nsub-optimality of the generation history. To address the pitfall of\nautoregressive decoding for text generation, we propose an approach that\nincorporates a sliding reflection window and a pausing criterion, such that\nrefinement and generation can be carried out interchangeably as the decoding\nproceeds. Our selective refinement framework strikes a balance between\nefficiency and optimality, and our extensive experimental results demonstrate\nthe effectiveness of our approach.\n","authors":["Zeyu Tang","Zhenhao Chen","Loka Li","Xiangchen Song","Yunlong Deng","Yifan Shen","Guangyi Chen","Peter Spirtes","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.03678v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05005v2","updated":"2025-03-10T18:52:15Z","published":"2025-03-06T22:09:55Z","title":"Balcony: A Lightweight Approach to Dynamic Inference of Generative\n  Language Models","summary":"  Deploying large language models (LLMs) in real-world applications is often\nhindered by strict computational and latency constraints. While dynamic\ninference offers the flexibility to adjust model behavior based on varying\nresource budgets, existing methods are frequently limited by hardware\ninefficiencies or performance degradation. In this paper, we introduce Balcony,\na simple yet highly effective framework for depth-based dynamic inference. By\nfreezing the pretrained LLM and inserting additional transformer layers at\nselected exit points, Balcony maintains the full model's performance while\nenabling real-time adaptation to different computational budgets. These\nadditional layers are trained using a straightforward self-distillation loss,\naligning the sub-model outputs with those of the full model. This approach\nrequires significantly fewer training tokens and tunable parameters,\ndrastically reducing computational costs compared to prior methods. When\napplied to the LLaMA3-8B model, using only 0.2% of the original pretraining\ndata, Balcony achieves minimal performance degradation while enabling\nsignificant speedups. Remarkably, we show that Balcony outperforms\nstate-of-the-art methods such as Flextron and Layerskip as well as other\nleading compression techniques on multiple models and at various scales, across\na variety of benchmarks.\n","authors":["Benyamin Jamialahmadi","Parsa Kavehzadeh","Mehdi Rezagholizadeh","Parsa Farinneya","Hossein Rajabzadeh","Aref Jafari","Boxing Chen","Marzieh S. Tahaei"],"pdf_url":"https://arxiv.org/pdf/2503.05005v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02783v2","updated":"2025-03-10T18:08:16Z","published":"2025-03-04T16:56:34Z","title":"IterPref: Focal Preference Learning for Code Generation via Iterative\n  Debugging","summary":"  Preference learning enhances Code LLMs beyond supervised fine-tuning by\nleveraging relative quality comparisons. Existing methods construct preference\npairs from\n  candidates based on test case success, treating the higher pass rate sample\nas positive and the lower as negative. However, this approach does not pinpoint\nspecific errors in the code, which prevents the model from learning more\ninformative error correction patterns, as aligning failing code as a whole\nlacks the granularity needed to capture meaningful error-resolution\nrelationships. To address these issues, we propose IterPref, a new preference\nalignment framework that mimics human iterative debugging to refine Code LLMs.\nIterPref explicitly locates error regions and aligns the corresponding tokens\nvia a tailored DPO algorithm. To generate informative pairs, we introduce the\nCodeFlow dataset, where samples are iteratively refined until passing tests,\nwith modifications capturing error corrections. Extensive experiments show that\na diverse suite of Code LLMs equipped with IterPref achieves significant\nperformance gains in code generation and improves on challenging tasks like\nBigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our\ncode and data will be made publicaly available.\n","authors":["Jie Wu","Haoling Li","Xin Zhang","Jianwen Luo","Yangyu Huang","Ruihang Chu","Yujiu Yang","Scarlett Li"],"pdf_url":"https://arxiv.org/pdf/2503.02783v2.pdf","comment":"The code and data will be released soon"},{"id":"http://arxiv.org/abs/2503.07605v1","updated":"2025-03-10T17:59:03Z","published":"2025-03-10T17:59:03Z","title":"SEAP: Training-free Sparse Expert Activation Pruning Unlock the\n  Brainpower of Large Language Models","summary":"  Large Language Models have achieved remarkable success across various natural\nlanguage processing tasks, yet their high computational cost during inference\nremains a major bottleneck. This paper introduces Sparse Expert Activation\nPruning (SEAP), a training-free pruning method that selectively retains\ntask-relevant parameters to reduce inference overhead. Inspired by the\nclustering patterns of hidden states and activations in LLMs, SEAP identifies\ntask-specific expert activation patterns and prunes the model while preserving\ntask performance and enhancing computational efficiency. Experimental results\ndemonstrate that SEAP significantly reduces computational overhead while\nmaintaining competitive accuracy. Notably, at 50% pruning, SEAP surpasses both\nWandA and FLAP by over 20%, and at 20% pruning, it incurs only a 2.2%\nperformance drop compared to the dense model. These findings highlight SEAP's\nscalability and effectiveness, making it a promising approach for optimizing\nlarge-scale LLMs.\n","authors":["Xun Liang","Hanyu Wang","Huayi Lai","Simin Niu","Shichao Song","Jiawei Yang","Jihao Zhao","Feiyu Xiong","Bo Tang","Zhiyu Li"],"pdf_url":"https://arxiv.org/pdf/2503.07605v1.pdf","comment":"15 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2503.07604v1","updated":"2025-03-10T17:58:31Z","published":"2025-03-10T17:58:31Z","title":"Implicit Reasoning in Transformers is Reasoning through Shortcuts","summary":"  Test-time compute is emerging as a new paradigm for enhancing language\nmodels' complex multi-step reasoning capabilities, as demonstrated by the\nsuccess of OpenAI's o1 and o3, as well as DeepSeek's R1. Compared to explicit\nreasoning in test-time compute, implicit reasoning is more inference-efficient,\nrequiring fewer generated tokens. However, why does the advanced reasoning\ncapability fail to emerge in the implicit reasoning style? In this work, we\ntrain GPT-2 from scratch on a curated multi-step mathematical reasoning dataset\nand conduct analytical experiments to investigate how language models perform\nimplicit reasoning in multi-step tasks. Our findings reveal: 1) Language models\ncan perform step-by-step reasoning and achieve high accuracy in both in-domain\nand out-of-domain tests via implicit reasoning. However, this capability only\nemerges when trained on fixed-pattern data. 2) Conversely, implicit reasoning\nabilities emerging from training on unfixed-pattern data tend to overfit a\nspecific pattern and fail to generalize further. Notably, this limitation is\nalso observed in state-of-the-art large language models. These findings suggest\nthat language models acquire implicit reasoning through shortcut learning,\nenabling strong performance on tasks with similar patterns while lacking\ngeneralization.\n","authors":["Tianhe Lin","Jian Xie","Siyu Yuan","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2503.07604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07595v1","updated":"2025-03-10T17:56:25Z","published":"2025-03-10T17:56:25Z","title":"Detection Avoidance Techniques for Large Language Models","summary":"  The increasing popularity of large language models has not only led to\nwidespread use but has also brought various risks, including the potential for\nsystematically spreading fake news. Consequently, the development of\nclassification systems such as DetectGPT has become vital. These detectors are\nvulnerable to evasion techniques, as demonstrated in an experimental series:\nSystematic changes of the generative models' temperature proofed shallow\nlearning-detectors to be the least reliable. Fine-tuning the generative model\nvia reinforcement learning circumvented BERT-based-detectors. Finally,\nrephrasing led to a >90\\% evasion of zero-shot-detectors like DetectGPT,\nalthough texts stayed highly similar to the original. A comparison with\nexisting work highlights the better performance of the presented methods.\nPossible implications for society and further research are discussed.\n","authors":["Sinclair Schneider","Florian Steuber","Joao A. G. Schneider","Gabi Dreo Rodosek"],"pdf_url":"https://arxiv.org/pdf/2503.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05816v2","updated":"2025-03-10T17:56:18Z","published":"2024-09-09T17:23:29Z","title":"Improving Pretraining Data Using Perplexity Correlations","summary":"  Quality pretraining data is often seen as the key to high-performance\nlanguage models. However, progress in understanding pretraining data has been\nslow due to the costly pretraining runs required for data selection\nexperiments. We present a framework that avoids these costs and selects\nhigh-quality pretraining data without any LLM training of our own. Our work is\nbased on a simple observation: LLM losses on many pretraining texts are\ncorrelated with downstream benchmark performance, and selecting\nhigh-correlation documents is an effective pretraining data selection method.\nWe build a new statistical framework for data selection centered around\nestimates of perplexity-benchmark correlations and perform data selection using\na sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of\nthousands of web domains. In controlled pretraining experiments at the 160M\nparameter scale on 8 benchmarks, our approach outperforms DSIR on every\nbenchmark, while matching the best data selector found in DataComp-LM, a\nhand-engineered bigram classifier. We have now also updated this paper to\ninclude results from preregistered experiments with new pretraining data on an\naggregation of 22 benchmarks up to the 1.4B scale, showing increasing\nimprovements of our method over others with more scale. A pip package with full\ndocumentation can be found here:\nhttps://github.com/TristanThrush/perplexity-correlations.\n","authors":["Tristan Thrush","Christopher Potts","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2409.05816v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.17055v4","updated":"2025-03-10T17:42:37Z","published":"2024-06-24T18:15:27Z","title":"Large Language Models Assume People are More Rational than We Really are","summary":"  In order for AI systems to communicate effectively with people, they must\nunderstand how we make decisions. However, people's decisions are not always\nrational, so the implicit internal models of human decision-making in Large\nLanguage Models (LLMs) must account for this. Previous empirical evidence seems\nto suggest that these implicit models are accurate -- LLMs offer believable\nproxies of human behavior, acting how we expect humans would in everyday\ninteractions. However, by comparing LLM behavior and predictions to a large\ndataset of human decisions, we find that this is actually not the case: when\nboth simulating and predicting people's choices, a suite of cutting-edge LLMs\n(GPT-4o & 4-Turbo, Llama-3-8B & 70B, Claude 3 Opus) assume that people are more\nrational than we really are. Specifically, these models deviate from human\nbehavior and align more closely with a classic model of rational choice --\nexpected value theory. Interestingly, people also tend to assume that other\npeople are rational when interpreting their behavior. As a consequence, when we\ncompare the inferences that LLMs and people draw from the decisions of others\nusing another psychological dataset, we find that these inferences are highly\ncorrelated. Thus, the implicit decision-making models of LLMs appear to be\naligned with the human expectation that other people will act rationally,\nrather than with how people actually act.\n","authors":["Ryan Liu","Jiayi Geng","Joshua C. Peterson","Ilia Sucholutsky","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2406.17055v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07575v1","updated":"2025-03-10T17:42:30Z","published":"2025-03-10T17:42:30Z","title":"VisBias: Measuring Explicit and Implicit Social Biases in Vision\n  Language Models","summary":"  This research investigates both explicit and implicit social biases exhibited\nby Vision-Language Models (VLMs). The key distinction between these bias types\nlies in the level of awareness: explicit bias refers to conscious, intentional\nbiases, while implicit bias operates subconsciously. To analyze explicit bias,\nwe directly pose questions to VLMs related to gender and racial differences:\n(1) Multiple-choice questions based on a given image (e.g., \"What is the\neducation level of the person in the image?\") (2) Yes-No comparisons using two\nimages (e.g., \"Is the person in the first image more educated than the person\nin the second image?\") For implicit bias, we design tasks where VLMs assist\nusers but reveal biases through their responses: (1) Image description tasks:\nModels are asked to describe individuals in images, and we analyze disparities\nin textual cues across demographic groups. (2) Form completion tasks: Models\ndraft a personal information collection form with 20 attributes, and we examine\ncorrelations among selected attributes for potential biases. We evaluate\nGemini-1.5, GPT-4V, GPT-4o, LLaMA-3.2-Vision and LLaVA-v1.6. Our code and data\nare publicly available at https://github.com/uscnlp-lime/VisBias.\n","authors":["Jen-tse Huang","Jiantong Qin","Jianping Zhang","Youliang Yuan","Wenxuan Wang","Jieyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.07575v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2503.07572v1","updated":"2025-03-10T17:40:43Z","published":"2025-03-10T17:40:43Z","title":"Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning","summary":"  Training models to effectively use test-time compute is crucial for improving\nthe reasoning performance of LLMs. Current methods mostly do so via fine-tuning\non search traces or running RL with 0/1 outcome reward, but do these approaches\nefficiently utilize test-time compute? Would these approaches continue to scale\nas the budget improves? In this paper, we try to answer these questions. We\nformalize the problem of optimizing test-time compute as a meta-reinforcement\nlearning (RL) problem, which provides a principled perspective on spending\ntest-time compute. This perspective enables us to view the long output stream\nfrom the LLM as consisting of several episodes run at test time and leads us to\nuse a notion of cumulative regret over output tokens as a way to measure the\nefficacy of test-time compute. Akin to how RL algorithms can best tradeoff\nexploration and exploitation over training, minimizing cumulative regret would\nalso provide the best balance between exploration and exploitation in the token\nstream. While we show that state-of-the-art models do not minimize regret, one\ncan do so by maximizing a dense reward bonus in conjunction with the outcome\n0/1 reward RL. This bonus is the ''progress'' made by each subsequent block in\nthe output stream, quantified by the change in the likelihood of eventual\nsuccess. Using these insights, we develop Meta Reinforcement Fine-Tuning, or\nMRT, a new class of fine-tuning methods for optimizing test-time compute. MRT\nleads to a 2-3x relative gain in performance and roughly a 1.5x gain in token\nefficiency for math reasoning compared to outcome-reward RL.\n","authors":["Yuxiao Qu","Matthew Y. R. Yang","Amrith Setlur","Lewis Tunstall","Edward Emanuel Beeching","Ruslan Salakhutdinov","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2503.07572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03205v2","updated":"2025-03-10T17:39:42Z","published":"2025-03-05T05:50:31Z","title":"MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances\n  Formal Theorem Proving","summary":"  Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves a 61.07% accuracy rate on the Lean4 version of the MiniF2F-Test\ndataset, largely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation (Godel-Prover,\n55.33%) baselines. Furthermore, our findings highlight the potential of\ncombining Long CoT with formal verification for a more insightful generation in\na broader perspective.\n","authors":["Ruida Wang","Rui Pan","Yuxin Li","Jipeng Zhang","Yizhen Jia","Shizhe Diao","Renjie Pi","Junjie Hu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03205v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04691v2","updated":"2025-03-10T17:28:31Z","published":"2025-03-06T18:35:39Z","title":"Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases","summary":"  Recent advancements in reasoning-enhanced large language models (LLMs), such\nas DeepSeek-R1 and OpenAI-o3, have demonstrated significant progress. However,\ntheir application in professional medical contexts remains underexplored,\nparticularly in evaluating the quality of their reasoning processes alongside\nfinal outputs. Here, we introduce MedR-Bench, a benchmarking dataset of 1,453\nstructured patient cases, annotated with reasoning references derived from\nclinical case reports. Spanning 13 body systems and 10 specialties, it includes\nboth common and rare diseases. To comprehensively evaluate LLM performance, we\npropose a framework encompassing three critical examination recommendation,\ndiagnostic decision-making, and treatment planning, simulating the entire\npatient care journey. To assess reasoning quality, we present the Reasoning\nEvaluator, a novel automated system that objectively scores free-text reasoning\nresponses based on efficiency, actuality, and completeness using dynamic\ncross-referencing and evidence checks. Using this benchmark, we evaluate five\nstate-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and\nGemini-2.0-Flash Thinking, etc. Our results show that current LLMs achieve over\n85% accuracy in relatively simple diagnostic tasks when provided with\nsufficient examination results. However, performance declines in more complex\ntasks, such as examination recommendation and treatment planning. While\nreasoning outputs are generally reliable, with factuality scores exceeding 90%,\ncritical reasoning steps are frequently missed. These findings underscore both\nthe progress and limitations of clinical LLMs. Notably, open-source models like\nDeepSeek-R1 are narrowing the gap with proprietary systems, highlighting their\npotential to drive accessible and equitable advancements in healthcare.\n","authors":["Pengcheng Qiu","Chaoyi Wu","Shuyu Liu","Weike Zhao","Zhuoxia Chen","Hongfei Gu","Chuanjin Peng","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07550v1","updated":"2025-03-10T17:17:41Z","published":"2025-03-10T17:17:41Z","title":"KSOD: Knowledge Supplement for LLMs On Demand","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet still produce errors in domain-specific tasks. To further\nimprove their performance, we propose KSOD (Knowledge Supplement for LLMs On\nDemand), a novel framework that empowers LLMs to improve their capabilities\nwith knowledge-based supervised fine-tuning (SFT). KSOD analyzes the causes of\nerrors from the perspective of knowledge deficiency by identifying potential\nmissing knowledge in LLM that may lead to the errors. Subsequently, KSOD tunes\na knowledge module on knowledge dataset and verifies whether the LLM lacks the\nidentified knowledge based on it. If the knowledge is verified, KSOD\nsupplements the LLM with the identified knowledge using the knowledge module.\nTuning LLMs on specific knowledge instead of specific task decouples task and\nknowledge and our experiments on two domain-specific benchmarks and four\ngeneral benchmarks empirically demonstrate that KSOD enhances the performance\nof LLMs on tasks requiring the supplemented knowledge while preserving their\nperformance on other tasks. Our findings shed light on the potential of\nimproving the capabilities of LLMs with knowledge-based SFT.\n","authors":["Haoran Li","Junfeng Hu"],"pdf_url":"https://arxiv.org/pdf/2503.07550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07539v1","updated":"2025-03-10T17:07:52Z","published":"2025-03-10T17:07:52Z","title":"XIFBench: Evaluating Large Language Models on Multilingual Instruction\n  Following","summary":"  Large Language Models (LLMs) have demonstrated remarkable\ninstruction-following capabilities across various applications. However, their\nperformance in multilingual settings remains poorly understood, as existing\nevaluations lack fine-grained constraint analysis. We introduce XIFBench, a\ncomprehensive constraint-based benchmark for assessing multilingual\ninstruction-following abilities of LLMs, featuring a novel taxonomy of five\nconstraint categories and 465 parallel instructions across six languages\nspanning different resource levels. To ensure consistent cross-lingual\nevaluation, we develop a requirement-based protocol that leverages English\nrequirements as semantic anchors. These requirements are then used to validate\nthe translations across languages. Extensive experiments with various LLMs\nreveal notable variations in instruction-following performance across resource\nlevels, identifying key influencing factors such as constraint categories,\ninstruction complexity, and cultural specificity.\n","authors":["Zhenyu Li","Kehai Chen","Yunfei Long","Xuefeng Bai","Yaoyin Zhang","Xuchen Wei","Juntao Li","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07691v1","updated":"2025-03-10T16:52:45Z","published":"2025-03-10T16:52:45Z","title":"Fair Text Classification via Transferable Representations","summary":"  Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g., women and men) remains\nan open challenge. We propose an approach that extends the use of the\nWasserstein Dependency Measure for learning unbiased neural text classifiers.\nGiven the challenge of distinguishing fair from unfair information in a text\nencoder, we draw inspiration from adversarial training by inducing independence\nbetween representations learned for the target label and those for a sensitive\nattribute. We further show that Domain Adaptation can be efficiently leveraged\nto remove the need for access to the sensitive attributes in the dataset we\ncure. We provide both theoretical and empirical evidence that our approach is\nwell-founded.\n","authors":["Thibaud Leteno","Michael Perrot","Charlotte Laclau","Antoine Gourru","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2503.07691v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.12689"},{"id":"http://arxiv.org/abs/2503.07522v1","updated":"2025-03-10T16:48:51Z","published":"2025-03-10T16:48:51Z","title":"Building English ASR model with regional language support","summary":"  In this paper, we present a novel approach to developing an English Automatic\nSpeech Recognition (ASR) system that can effectively handle Hindi queries,\nwithout compromising its performance on English. We propose a novel acoustic\nmodel (AM), referred to as SplitHead with Attention (SHA) model, features\nshared hidden layers across languages and language-specific projection layers\ncombined via a self-attention mechanism. This mechanism estimates the weight\nfor each language based on input data and weighs the corresponding\nlanguage-specific projection layers accordingly. Additionally, we propose a\nlanguage modeling approach that interpolates n-gram models from both English\nand transliterated Hindi text corpora. Our results demonstrate the\neffectiveness of our approach, with a 69.3% and 5.7% relative reduction in word\nerror rate on Hindi and English test sets respectively when compared to a\nmonolingual English model.\n","authors":["Purvi Agrawal","Vikas Joshi","Bharati Patidar","Ankur Gupta","Rupesh Kumar Mehta"],"pdf_url":"https://arxiv.org/pdf/2503.07522v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.07519v1","updated":"2025-03-10T16:42:48Z","published":"2025-03-10T16:42:48Z","title":"GRITHopper: Decomposition-Free Multi-Hop Dense Retrieval","summary":"  Decomposition-based multi-hop retrieval methods rely on many autoregressive\nsteps to break down complex queries, which breaks end-to-end differentiability\nand is computationally expensive. Decomposition-free methods tackle this, but\ncurrent decomposition-free approaches struggle with longer multi-hop problems\nand generalization to out-of-distribution data. To address these challenges, we\nintroduce GRITHopper-7B, a novel multi-hop dense retrieval model that achieves\nstate-of-the-art performance on both in-distribution and out-of-distribution\nbenchmarks. GRITHopper combines generative and representational instruction\ntuning by integrating causal language modeling with dense retrieval training.\nThrough controlled studies, we find that incorporating additional context after\nthe retrieval process, referred to as post-retrieval language modeling,\nenhances dense retrieval performance. By including elements such as final\nanswers during training, the model learns to better contextualize and retrieve\nrelevant information. GRITHopper-7B offers a robust, scalable, and\ngeneralizable solution for multi-hop dense retrieval, and we release it to the\ncommunity for future research and applications requiring multi-hop reasoning\nand retrieval capabilities.\n","authors":["Justus-Jonas Erker","Nils Reimers","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.07519v1.pdf","comment":"Under Review at ACL Rolling Review (ARR)"},{"id":"http://arxiv.org/abs/2503.07518v1","updated":"2025-03-10T16:41:14Z","published":"2025-03-10T16:41:14Z","title":"TokenButler: Token Importance is Predictable","summary":"  Large Language Models (LLMs) rely on the Key-Value (KV) Cache to store token\nhistory, enabling efficient decoding of tokens. As the KV-Cache grows, it\nbecomes a major memory and computation bottleneck, however, there is an\nopportunity to alleviate this bottleneck, especially because prior research has\nshown that only a small subset of tokens contribute meaningfully to each\ndecoding step. A key challenge in finding these critical tokens is that they\nare dynamic, and heavily input query-dependent. Existing methods either risk\nquality by evicting tokens permanently, or retain the full KV-Cache but rely on\nretrieving chunks (pages) of tokens at generation, failing at dense,\ncontext-rich tasks. Additionally, many existing KV-Cache sparsity methods rely\non inaccurate proxies for token importance. To address these limitations, we\nintroduce TokenButler, a high-granularity, query-aware predictor that learns to\nidentify these critical tokens. By training a light-weight predictor with less\nthan 1.2% parameter overhead, TokenButler prioritizes tokens based on their\ncontextual, predicted importance. This improves perplexity & downstream\naccuracy by over 8% relative to SoTA methods for estimating token importance.\nWe evaluate TokenButler on a novel synthetic small-context co-referential\nretrieval task, demonstrating near-oracle accuracy. Code, models and\nbenchmarks: https://github.com/abdelfattah-lab/TokenButler\n","authors":["Yash Akhauri","Ahmed F AbouElhamayed","Yifei Gao","Chi-Chih Chang","Nilesh Jain","Mohamed S. Abdelfattah"],"pdf_url":"https://arxiv.org/pdf/2503.07518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07513v1","updated":"2025-03-10T16:33:14Z","published":"2025-03-10T16:33:14Z","title":"Language Models Fail to Introspect About Their Knowledge of Language","summary":"  There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.\n","authors":["Siyuan Song","Jennifer Hu","Kyle Mahowald"],"pdf_url":"https://arxiv.org/pdf/2503.07513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07510v1","updated":"2025-03-10T16:32:03Z","published":"2025-03-10T16:32:03Z","title":"Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs\n  through Demographic Analysis in Asian Nations","summary":"  Large Language Models (LLMs) are capable of generating opinions and\npropagating bias unknowingly, originating from unrepresentative and non-diverse\ndata collection. Prior research has analysed these opinions with respect to the\nWest, particularly the United States. However, insights thus produced may not\nbe generalized in non-Western populations. With the widespread usage of LLM\nsystems by users across several different walks of life, the cultural\nsensitivity of each generated output is of crucial interest. Our work proposes\na novel method that quantitatively analyzes the opinions generated by LLMs,\nimproving on previous work with regards to extracting the social demographics\nof the models. Our method measures the distance from an LLM's response to\nsurvey respondents, through Hamming Distance, to infer the demographic\ncharacteristics reflected in the model's outputs. We evaluate modern, open LLMs\nsuch as Llama and Mistral on surveys conducted in various global south\ncountries, with a focus on India and other Asian nations, specifically\nassessing the model's performance on surveys related to religious tolerance and\nidentity. Our analysis reveals that most open LLMs match a single homogeneous\nprofile, varying across different countries/territories, which in turn raises\nquestions about the risks of LLMs promoting a hegemonic worldview, and\nundermining perspectives of different minorities. Our framework may also be\nuseful for future research investigating the complex intersection between\ntraining data, model architecture, and the resulting biases reflected in LLM\noutputs, particularly concerning sensitive topics like religious tolerance and\nidentity.\n","authors":["Hari Shankar","Vedanta S P","Tejas Cavale","Ponnurangam Kumaraguru","Abhijnan Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2503.07510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19951v3","updated":"2025-03-10T15:44:34Z","published":"2024-11-29T18:59:54Z","title":"Sparrow: Data-Efficient Video-LLM with Text-to-Image Augmentation","summary":"  Recent years have witnessed the success of Multimodal Large Language Models\n(MLLMs) in the vision understanding domain. The success of these models can\nlargely be attributed to the dominant scaling law, which states that larger\nparameter sizes and data volumes contribute to better performance. Notably,\ndata scaling has mainly been powered by automatic data pipelines, which center\naround the self-instruction of LLMs. The paradigm has been taken for granted\nfor quite some time, but the study of the effectiveness of scaling with these\ndata has been neglected for a long time. In this context, this work revisits\nscaling with synthetic data and focuses on developing video-LLMs from a\ndata-centric perspective. Our main study approach is fine-tuning pre-trained\nimage-LLMs with video data and investigating learning efficiency through data\nscaling. Results from our preliminary experiments reveal a low learning\nefficiency phenomenon when simply scaling up video data samples, which, through\nour probing, can be ascribed to a lack of instruction diversity. Aiming at this\nissue, we propose a data augmentation method called Sparrow, which synthesizes\nvideo-like samples from pure text instruction data. Mixing these synthetic\nsamples with the video data enables a more efficient training scheme. Through\ncomprehensive experiments, we demonstrate that our proposed method achieves\nperformance comparable to or even superior to baselines trained with many more\nsamples. Meanwhile, we find that incorporating these synthetic samples can\nboost the performance of long video understanding without training with long\nvideo data. The code and data examples are available at\nhttps://github.com/VITA-MLLM/Sparrow.\n","authors":["Shukang Yin","Chaoyou Fu","Sirui Zhao","Yunhang Shen","Chunjiang Ge","Yan Yang","Zuwei Long","Yuhan Dai","Yongdong Luo","Haoyu Cao","Tong Xu","Xing Sun","Caifeng Shan","Ran He","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.19951v3.pdf","comment":"Project page: https://github.com/VITA-MLLM/Sparrow"},{"id":"http://arxiv.org/abs/2101.02157v3","updated":"2025-03-10T15:43:32Z","published":"2021-01-06T17:46:05Z","title":"EfficientQA : a RoBERTa Based Phrase-Indexed Question-Answering System","summary":"  State-of-the-art extractive question-answering models achieve superhuman\nperformances on the SQuAD benchmark. Yet, they are unreasonably heavy and need\nexpensive GPU computing to answer questions in a reasonable time. Thus, they\ncannot be used in the open-domain question-answering paradigm for real-world\nqueries on hundreds of thousands of documents. In this paper, we explore the\npossibility of transferring the natural language understanding of language\nmodels into dense vectors representing questions and answer candidates to make\nquestion-answering compatible with a simple nearest neighbor search task. This\nnew model, which we call EfficientQA, takes advantage of the pair of sequences\nkind of input of BERT-based models to build meaningful, dense representations\nof candidate answers. These latter are extracted from the context in a\nquestion-agnostic fashion. Our model achieves state-of-the-art results in\nPhrase-Indexed Question Answering (PIQA), beating the previous state-of-art by\n1.3 points in exact-match and 1.4 points in f1-score. These results show that\ndense vectors can embed rich semantic representations of sequences, although\nthese were built from language models not originally trained for the use case.\nThus, to build more resource-efficient NLP systems in the future, training\nlanguage models better adapted to build dense representations of phrases is one\nof the possibilities.\n","authors":["Sofian Chaybouti","Achraf Saghe","Aymen Shabou"],"pdf_url":"https://arxiv.org/pdf/2101.02157v3.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.11176v3","updated":"2025-03-10T15:31:00Z","published":"2024-03-17T11:32:18Z","title":"Quality-Aware Image-Text Alignment for Opinion-Unaware Image Quality\n  Assessment","summary":"  No-Reference Image Quality Assessment (NR-IQA) focuses on designing methods\nto measure image quality in alignment with human perception when a high-quality\nreference image is unavailable. Most state-of-the-art NR-IQA approaches are\nopinion-aware, i.e. they require human annotations for training. This\ndependency limits their scalability and broad applicability. To overcome this\nlimitation, we propose QualiCLIP (Quality-aware CLIP), a CLIP-based\nself-supervised opinion-unaware approach that does not require human opinions.\nIn particular, we introduce a quality-aware image-text alignment strategy to\nmake CLIP generate quality-aware image representations. Starting from pristine\nimages, we synthetically degrade them with increasing levels of intensity.\nThen, we train CLIP to rank these degraded images based on their similarity to\nquality-related antonym text prompts. At the same time, we force CLIP to\ngenerate consistent representations for images with similar content and the\nsame level of degradation. Our experiments show that the proposed method\nimproves over existing opinion-unaware approaches across multiple datasets with\ndiverse distortion types. Moreover, despite not requiring human annotations,\nQualiCLIP achieves excellent performance against supervised opinion-aware\nmethods in cross-dataset experiments, thus demonstrating remarkable\ngeneralization capabilities. The code and the model are publicly available at\nhttps://github.com/miccunifi/QualiCLIP.\n","authors":["Lorenzo Agnolucci","Leonardo Galteri","Marco Bertini"],"pdf_url":"https://arxiv.org/pdf/2403.11176v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05966v4","updated":"2025-03-10T15:07:49Z","published":"2024-05-09T17:59:32Z","title":"Natural Language Processing RELIES on Linguistics","summary":"  Large Language Models (LLMs) have become capable of generating highly fluent\ntext in certain languages, without modules specially designed to capture\ngrammar or semantic coherence. What does this mean for the future of linguistic\nexpertise in NLP? We highlight several aspects in which NLP (still) relies on\nlinguistics, or where linguistic thinking can illuminate new directions. We\nargue our case around the acronym RELIES that encapsulates six major facets\nwhere linguistics contributes to NLP: Resources, Evaluation, Low-resource\nsettings, Interpretability, Explanation, and the Study of language. This list\nis not exhaustive, nor is linguistics the main point of reference for every\neffort under these themes; but at a macro level, these facets highlight the\nenduring importance of studying machine systems vis-\\`a-vis systems of human\nlanguage.\n","authors":["Juri Opitz","Shira Wein","Nathan Schneider"],"pdf_url":"https://arxiv.org/pdf/2405.05966v4.pdf","comment":"To appear in Computational Linguistics. This is a pre-MIT Press\n  publication version"},{"id":"http://arxiv.org/abs/2407.12863v2","updated":"2025-03-10T14:24:29Z","published":"2024-07-12T13:16:50Z","title":"Token-Supervised Value Models for Enhancing Mathematical Problem-Solving\n  Capabilities of Large Language Models","summary":"  With the rapid advancement of test-time compute search strategies to improve\nthe mathematical problem-solving capabilities of large language models (LLMs),\nthe need for building robust verifiers has become increasingly important.\nHowever, all these inference strategies rely on existing verifiers originally\ndesigned for Best-of-N search, which makes them sub-optimal for tree search\ntechniques at test time. During tree search, existing verifiers can only offer\nindirect and implicit assessments of partial solutions or under-value\nprospective intermediate steps, thus resulting in the premature pruning of\npromising intermediate steps. To overcome these limitations, we propose\ntoken-supervised value models (TVMs) - a new class of verifiers that assign\neach token a probability that reflects the likelihood of reaching the correct\nfinal answer. This new token-level supervision enables TVMs to directly and\nexplicitly evaluate partial solutions, effectively distinguishing between\npromising and incorrect intermediate steps during tree search at test time.\nExperimental results demonstrate that combining tree-search-based inference\nstrategies with TVMs significantly improves the accuracy of LLMs in\nmathematical problem-solving tasks, surpassing the performance of existing\nverifiers.\n","authors":["Jung Hyun Lee","June Yong Yang","Byeongho Heo","Dongyoon Han","Kyungsu Kim","Eunho Yang","Kang Min Yoo"],"pdf_url":"https://arxiv.org/pdf/2407.12863v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04620v3","updated":"2025-03-10T13:24:46Z","published":"2024-05-07T19:05:26Z","title":"Folded Context Condensation in Path Integral Formalism for Infinite\n  Context Transformers","summary":"  In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.\n","authors":["Won-Gi Paeng","Daesuk Kwon","Kyungwon Jeong","Honggyo Suh"],"pdf_url":"https://arxiv.org/pdf/2405.04620v3.pdf","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2305.15932v3","updated":"2025-03-10T09:28:29Z","published":"2023-05-25T10:59:47Z","title":"BUCA: A Binary Classification Approach to Unsupervised Commonsense\n  Question Answering","summary":"  Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as\nthe construction of commonsense reasoning datasets is expensive, and they are\ninevitably limited in their scope. A popular approach to UCR is to fine-tune\nlanguage models with external knowledge (e.g., knowledge graphs), but this\nusually requires a large number of training examples. In this paper, we propose\nto transform the downstream multiple choice question answering task into a\nsimpler binary classification task by ranking all candidate answers according\nto their reasonableness. To this end, for training the model, we convert the\nknowledge graph triples into reasonable and unreasonable texts. Extensive\nexperimental results show the effectiveness of our approach on various multiple\nchoice question answering benchmarks. Furthermore, compared with existing UCR\napproaches using KGs, ours is less data hungry. Our code is available at\nhttps://github.com/probe2/BUCA.\n","authors":["Jie He","Simon Chi Lok U","Víctor Gutiérrez-Basulto","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2305.15932v3.pdf","comment":"Accepted by ACL2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.07482v1","updated":"2025-03-10T15:58:43Z","published":"2025-03-10T15:58:43Z","title":"Efficient Membership Inference Attacks by Bayesian Neural Network","summary":"  Membership Inference Attacks (MIAs) aim to estimate whether a specific data\npoint was used in the training of a given model. Previous attacks often utilize\nmultiple reference models to approximate the conditional score distribution,\nleading to significant computational overhead. While recent work leverages\nquantile regression to estimate conditional thresholds, it fails to capture\nepistemic uncertainty, resulting in bias in low-density regions. In this work,\nwe propose a novel approach - Bayesian Membership Inference Attack (BMIA),\nwhich performs conditional attack through Bayesian inference. In particular, we\ntransform a trained reference model into Bayesian neural networks by Laplace\napproximation, enabling the direct estimation of the conditional score\ndistribution by probabilistic model parameters. Our method addresses both\nepistemic and aleatoric uncertainty with only a reference model, enabling\nefficient and powerful MIA. Extensive experiments on five datasets demonstrate\nthe effectiveness and efficiency of BMIA.\n","authors":["Zhenlong Liu","Wenyu Jiang","Feng Zhou","Hongxin Wei"],"pdf_url":"https://arxiv.org/pdf/2503.07482v1.pdf","comment":"8 pages, under review"},{"id":"http://arxiv.org/abs/2503.03245v2","updated":"2025-03-10T15:51:39Z","published":"2025-03-05T07:53:39Z","title":"Less is more? Rewards in RL for Cyber Defence","summary":"  The last few years have seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. This is especially a problem in complex cyber environments where\npolicy weaknesses may not be noticed until exploited by an adversary. In this\nwork we set out to evaluate whether sparse reward functions might enable\ntraining more effective cyber defence agents. Towards this goal we first break\ndown several evaluation limitations in existing work by proposing a ground\ntruth evaluation score that goes beyond the standard RL paradigm used to train\nand evaluate agents. By adapting a well-established cyber gym to accommodate\nour methodology and ground truth score, we propose and evaluate two sparse\nreward mechanisms and compare them with a typical dense reward. Our evaluation\nconsiders a range of network sizes, from 2 to 50 nodes, and both reactive and\nproactive defensive actions. Our results show that sparse rewards, particularly\npositive reinforcement for an uncompromised network state, enable the training\nof more effective cyber defence agents. Furthermore, we show that sparse\nrewards provide more stable training than dense rewards, and that both\neffectiveness and training stability are robust to a variety of cyber\nenvironment considerations.\n","authors":["Elizabeth Bates","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2503.03245v2.pdf","comment":"4 Pages"},{"id":"http://arxiv.org/abs/2503.07475v1","updated":"2025-03-10T15:49:58Z","published":"2025-03-10T15:49:58Z","title":"Sample Complexity of Nonparametric Closeness Testing for Continuous\n  Distributions and Its Application to Causal Discovery with Hidden Confounding","summary":"  We study the problem of closeness testing for continuous distributions and\nits implications for causal discovery. Specifically, we analyze the sample\ncomplexity of distinguishing whether two multidimensional continuous\ndistributions are identical or differ by at least $\\epsilon$ in terms of\nKullback-Leibler (KL) divergence under non-parametric assumptions. To this end,\nwe propose an estimator of KL divergence which is based on the von Mises\nexpansion. Our closeness test attains optimal parametric rates under smoothness\nassumptions. Equipped with this test, which serves as a building block of our\ncausal discovery algorithm to identify the causal structure between two\nmultidimensional random variables, we establish sample complexity guarantees\nfor our causal discovery method. To the best of our knowledge, this work is the\nfirst work that provides sample complexity guarantees for distinguishing cause\nand effect in multidimensional non-linear models with non-Gaussian continuous\nvariables in the presence of unobserved confounding.\n","authors":["Fateme Jamshidi","Sina Akbari","Negar Kiyavash"],"pdf_url":"https://arxiv.org/pdf/2503.07475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07470v1","updated":"2025-03-10T15:47:01Z","published":"2025-03-10T15:47:01Z","title":"Advancing Vietnamese Information Retrieval with Learning Objective and\n  Benchmark","summary":"  With the rapid development of natural language processing, many language\nmodels have been invented for multiple tasks. One important task is information\nretrieval (IR), which requires models to retrieve relevant documents. Despite\nits importance in many real-life applications, especially in retrieval\naugmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This\nsituation causes difficulty in assessing and comparing many existing Vietnamese\nembedding language models on the task and slows down the advancement of\nVietnamese natural language processing (NLP) research. In this work, we aim to\nprovide the Vietnamese research community with a new benchmark for information\nretrieval, which mainly focuses on retrieval and reranking tasks. Furthermore,\nwe also present a new objective function based on the InfoNCE loss function,\nwhich is used to train our Vietnamese embedding model. Our function aims to be\nbetter than the origin in information retrieval tasks. Finally, we analyze the\neffect of temperature, a hyper-parameter in both objective functions, on the\nperformance of text embedding models.\n","authors":["Phu-Vinh Nguyen","Minh-Nam Tran","Long Nguyen","Dien Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.07470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07464v1","updated":"2025-03-10T15:42:30Z","published":"2025-03-10T15:42:30Z","title":"Learning to Localize Leakage of Cryptographic Sensitive Variables","summary":"  While cryptographic algorithms such as the ubiquitous Advanced Encryption\nStandard (AES) are secure, *physical implementations* of these algorithms in\nhardware inevitably 'leak' sensitive data such as cryptographic keys. A\nparticularly insidious form of leakage arises from the fact that hardware\nconsumes power and emits radiation in a manner that is statistically associated\nwith the data it processes and the instructions it executes. Supervised deep\nlearning has emerged as a state-of-the-art tool for carrying out *side-channel\nattacks*, which exploit this leakage by learning to map power/radiation\nmeasurements throughout encryption to the sensitive data operated on during\nthat encryption. In this work we develop a principled deep learning framework\nfor determining the relative leakage due to measurements recorded at different\npoints in time, in order to inform *defense* against such attacks. This\ninformation is invaluable to cryptographic hardware designers for understanding\n*why* their hardware leaks and how they can mitigate it (e.g. by indicating the\nparticular sections of code or electronic components which are responsible).\nOur framework is based on an adversarial game between a family of classifiers\ntrained to estimate the conditional distributions of sensitive data given\nsubsets of measurements, and a budget-constrained noise distribution which\nprobabilistically erases individual measurements to maximize the loss of these\nclassifiers. We demonstrate our method's efficacy and ability to overcome\nlimitations of prior work through extensive experimental comparison with 8\nbaseline methods using 3 evaluation metrics and 6 publicly-available power/EM\ntrace datasets from AES, ECC and RSA implementations. We provide an open-source\nPyTorch implementation of these experiments.\n","authors":["Jimmy Gammell","Anand Raghunathan","Abolfazl Hashemi","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2503.07464v1.pdf","comment":"52 pages, 30 figures. Our code can be found at\n  https://github.com/jimgammell/learning_to_localize_leakage"},{"id":"http://arxiv.org/abs/2503.07453v1","updated":"2025-03-10T15:31:42Z","published":"2025-03-10T15:31:42Z","title":"Is a Good Foundation Necessary for Efficient Reinforcement Learning? The\n  Computational Role of the Base Model in Exploration","summary":"  Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.\n","authors":["Dylan J. Foster","Zakaria Mhammedi","Dhruv Rohatgi"],"pdf_url":"https://arxiv.org/pdf/2503.07453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05622v2","updated":"2025-03-10T15:25:16Z","published":"2025-03-07T17:49:55Z","title":"Decision-aware training of spatiotemporal forecasting models to select a\n  top K subset of sites for intervention","summary":"  Optimal allocation of scarce resources is a common problem for decision\nmakers faced with choosing a limited number of locations for intervention.\nSpatiotemporal prediction models could make such decisions data-driven. A\nrecent performance metric called fraction of best possible reach (BPR) measures\nthe impact of using a model's recommended size K subset of sites compared to\nthe best possible top-K in hindsight. We tackle two open problems related to\nBPR. First, we explore how to rank all sites numerically given a probabilistic\nmodel that predicts event counts jointly across sites. Ranking via the per-site\nmean is suboptimal for BPR. Instead, we offer a better ranking for BPR backed\nby decision theory. Second, we explore how to train a probabilistic model's\nparameters to maximize BPR. Discrete selection of K sites implies all-zero\nparameter gradients which prevent standard gradient training. We overcome this\nbarrier via advances in perturbed optimizers. We further suggest a training\nobjective that combines likelihood with a decision-aware BPR constraint to\ndeliver high-quality top-K rankings as well as good forecasts for all sites. We\ndemonstrate our approach on two where-to-intervene applications: mitigating\nopioid-related fatal overdoses for public health and monitoring endangered\nwildlife.\n","authors":["Kyle Heuton","F. Samuel Muench","Shikhar Shrestha","Thomas J. Stopka","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2503.05622v2.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.07444v1","updated":"2025-03-10T15:24:36Z","published":"2025-03-10T15:24:36Z","title":"Divide and Conquer Self-Supervised Learning for High-Content Imaging","summary":"  Self-supervised representation learning methods often fail to learn subtle or\ncomplex features, which can be dominated by simpler patterns which are much\neasier to learn. This limitation is particularly problematic in applications to\nscience and engineering, as complex features can be critical for discovery and\nanalysis. To address this, we introduce Split Component Embedding Registration\n(SpliCER), a novel architecture which splits the image into sections and\ndistils information from each section to guide the model to learn more subtle\nand complex features without compromising on simpler features. SpliCER is\ncompatible with any self-supervised loss function and can be integrated into\nexisting methods without modification. The primary contributions of this work\nare as follows: i) we demonstrate that existing self-supervised methods can\nlearn shortcut solutions when simple and complex features are both present; ii)\nwe introduce a novel self-supervised training method, SpliCER, to overcome the\nlimitations of existing methods, and achieve significant downstream performance\nimprovements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge\nmedical and geospatial imaging settings. SpliCER offers a powerful new tool for\nrepresentation learning, enabling models to uncover complex features which\ncould be overlooked by other methods.\n","authors":["Lucas Farndale","Paul Henderson","Edward W Roberts","Ke Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.07444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07426v1","updated":"2025-03-10T15:11:07Z","published":"2025-03-10T15:11:07Z","title":"RePO: ReLU-based Preference Optimization","summary":"  Aligning large language models (LLMs) with human preferences is critical for\nreal-world deployment, yet existing methods like RLHF face computational and\nstability challenges. While DPO establishes an offline paradigm with single\nhyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity\nthrough dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference\nOptimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two\nadvances: (1) retaining SimPO's reference-free margins but removing $\\beta$\nthrough gradient analysis, and (2) adopting a ReLU-based max-margin loss that\nnaturally filters trivial pairs. Theoretically, RePO is characterized as\nSimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting\ncollapses to binary thresholding, forming a convex envelope of the 0-1 loss.\nEmpirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO\nand SimPO across multiple base models, requiring only one hyperparameter to\ntune.\n","authors":["Junkang Wu","Kexin Huang","Xue Wang","Jinyang Gao","Bolin Ding","Jiancan Wu","Xiangnan He","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07424v1","updated":"2025-03-10T15:10:22Z","published":"2025-03-10T15:10:22Z","title":"Inorganic Catalyst Efficiency Prediction Based on EAPCR Model: A Deep\n  Learning Solution for Multi-Source Heterogeneous Data","summary":"  The design of inorganic catalysts and the prediction of their catalytic\nefficiency are fundamental challenges in chemistry and materials science.\nTraditional catalyst evaluation methods primarily rely on machine learning\ntechniques; however, these methods often struggle to process multi-source\nheterogeneous data, limiting both predictive accuracy and generalization. To\naddress these limitations, this study introduces the\nEmbedding-Attention-Permutated CNN-Residual (EAPCR) deep learning model. EAPCR\nconstructs a feature association matrix using embedding and attention\nmechanisms and enhances predictive performance through permutated CNN\narchitectures and residual connections. This approach enables the model to\naccurately capture complex feature interactions across various catalytic\nconditions, leading to precise efficiency predictions. EAPCR serves as a\npowerful tool for computational researchers while also assisting domain experts\nin optimizing catalyst design, effectively bridging the gap between data-driven\nmodeling and experimental applications. We evaluate EAPCR on datasets from TiO2\nphotocatalysis, thermal catalysis, and electrocatalysis, demonstrating its\nsuperiority over traditional machine learning methods (e.g., linear regression,\nrandom forest) as well as conventional deep learning models (e.g., ANN, NNs).\nAcross multiple evaluation metrics (MAE, MSE, R2, and RMSE), EAPCR consistently\noutperforms existing approaches. These findings highlight the strong potential\nof EAPCR in inorganic catalytic efficiency prediction. As a versatile deep\nlearning framework, EAPCR not only improves predictive accuracy but also\nestablishes a solid foundation for future large-scale model development in\ninorganic catalysis.\n","authors":["Zhangdi Liu","Ling An","Mengke Song","Zhuohang Yu","Shan Wang","Kezhen Qi","Zhenyu Zhang","Chichun Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07411v1","updated":"2025-03-10T14:58:16Z","published":"2025-03-10T14:58:16Z","title":"PER-DPP Sampling Framework and Its Application in Path Planning","summary":"  Autonomous navigation in intelligent mobile systems represents a core\nresearch focus within artificial intelligence-driven robotics. Contemporary\npath planning approaches face constraints in dynamic environmental\nresponsiveness and multi-objective task scalability, limiting their capacity to\naddress growing intelligent operation requirements. Decision-centric\nreinforcement learning frameworks, capitalizing on their unique strengths in\nadaptive environmental interaction and self-optimization, have gained\nprominence in advanced control system research. This investigation introduces\nmethodological improvements to address sample homogeneity challenges in\nreinforcement learning experience replay mechanisms. By incorporating\ndeterminant point processes (DPP) for diversity assessment, we develop a\ndual-criteria sampling framework with adaptive selection protocols. This\napproach resolves representation bias in conventional prioritized experience\nreplay (PER) systems while preserving algorithmic interoperability, offering\nimproved decision optimization for dynamic operational scenarios. Key\ncontributions comprise: Develop a hybrid sampling paradigm (PER-DPP) combining\npriority sequencing with diversity maximization.Based on this,create an\nintegrated optimization scheme (PER-DPP-Elastic DQN) merging diversity-aware\nsampling with adaptive step-size regulation. Comparative simulations in 2D\nnavigation scenarios demonstrate that the elastic step-size component\ntemporarily delays initial convergence speed but synergistically enhances\nfinal-stage optimization with PER-DPP integration. The synthesized method\ngenerates navigation paths with optimized length efficiency and directional\nstability.\n","authors":["Junzhe Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07401v1","updated":"2025-03-10T14:49:37Z","published":"2025-03-10T14:49:37Z","title":"ECNN: A Low-complex, Adjustable CNN for Industrial Pump Monitoring Using\n  Vibration Data","summary":"  Industrial pumps are essential components in various sectors, such as\nmanufacturing, energy production, and water treatment, where their failures can\ncause significant financial and safety risks. Anomaly detection can be used to\nreduce those risks and increase reliability. In this work, we propose a novel\nenhanced convolutional neural network (ECNN) to predict the failure of an\nindustrial pump based on the vibration data captured by an acceleration sensor.\nThe convolutional neural network (CNN) is designed with a focus on low\ncomplexity to enable its implementation on edge devices with limited\ncomputational resources. Therefore, a detailed design space exploration is\nperformed to find a topology satisfying the trade-off between complexity and\naccuracy. Moreover, to allow for adaptation to unknown pumps, our algorithm\nfeatures a pump-specific parameter that can be determined by a small set of\nnormal data samples. Finally, we combine the ECNN with a threshold approach to\nfurther increase the performance and satisfy the application requirements. As a\nresult, our combined approach significantly outperforms a traditional\nstatistical approach and a classical CNN in terms of accuracy. To summarize,\nthis work provides a novel, low-complex, CNN-based algorithm that is enhanced\nby classical methods to offer high accuracy for anomaly detection of industrial\npumps.\n","authors":["Jonas Ney","Norbert Wehn"],"pdf_url":"https://arxiv.org/pdf/2503.07401v1.pdf","comment":"Accepted and to be presented as a poster at the 2025 IEEE Symposium\n  Series on Computational Intelligence (SSCI)"},{"id":"http://arxiv.org/abs/2502.20317v3","updated":"2025-03-10T14:43:15Z","published":"2025-02-27T17:42:52Z","title":"Mixture of Structural-and-Textual Retrieval over Text-rich Graph\n  Knowledge Bases","summary":"  Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for\nanswering queries by providing textual and structural knowledge. However,\ncurrent retrieval methods often retrieve these two types of knowledge in\nisolation without considering their mutual reinforcement and some hybrid\nmethods even bypass structural retrieval entirely after neighboring\naggregation. To fill in this gap, we propose a Mixture of\nStructural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge\nvia a Planning-Reasoning-Organizing framework. In the Planning stage, MoR\ngenerates textual planning graphs delineating the logic for answering queries.\nFollowing planning graphs, in the Reasoning stage, MoR interweaves structural\ntraversal and textual matching to obtain candidates from TG-KBs. In the\nOrganizing stage, MoR further reranks fetched candidates based on their\nstructural trajectory. Extensive experiments demonstrate the superiority of MoR\nin harmonizing structural and textual retrieval with insights, including uneven\nretrieving performance across different query logics and the benefits of\nintegrating structural trajectories for candidate reranking. Our code is\navailable at https://github.com/Yoega/MoR.\n","authors":["Yongjia Lei","Haoyu Han","Ryan A. Rossi","Franck Dernoncourt","Nedim Lipka","Mahantesh M Halappanavar","Jiliang Tang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20317v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07397v1","updated":"2025-03-10T14:43:10Z","published":"2025-03-10T14:43:10Z","title":"Q-MARL: A quantum-inspired algorithm using neural message passing for\n  large-scale multi-agent reinforcement learning","summary":"  Inspired by a graph-based technique for predicting molecular properties in\nquantum chemistry -- atoms' position within molecules in three-dimensional\nspace -- we present Q-MARL, a completely decentralised learning architecture\nthat supports very large-scale multi-agent reinforcement learning scenarios\nwithout the need for strong assumptions like common rewards or agent order. The\nkey is to treat each agent as relative to its surrounding agents in an\nenvironment that is presumed to change dynamically. Hence, in each time step,\nan agent is the centre of its own neighbourhood and also a neighbour to many\nother agents. Each role is formulated as a sub-graph, and each sub-graph is\nused as a training sample. A message-passing neural network supports full-scale\nvertex and edge interaction within a local neighbourhood, while a parameter\ngoverning the depth of the sub-graphs eases the training burden. During\ntesting, an agent's actions are locally ensembled across all the sub-graphs\nthat contain it, resulting in robust decisions. Where other approaches struggle\nto manage 50 agents, Q-MARL can easily marshal thousands. A detailed\ntheoretical analysis proves improvement and convergence, and simulations with\nthe typical collaborative and competitive scenarios show dramatically faster\ntraining speeds and reduced training losses.\n","authors":["Kha Vo","Chin-Teng Lin"],"pdf_url":"https://arxiv.org/pdf/2503.07397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04243v2","updated":"2025-03-10T14:42:44Z","published":"2024-12-05T15:25:51Z","title":"Quantifying the Limits of Segmentation Foundation Models: Modeling\n  Challenges in Segmenting Tree-Like and Low-Contrast Objects","summary":"  Image segmentation foundation models (SFMs) like Segment Anything Model (SAM)\nhave achieved impressive zero-shot and interactive segmentation across diverse\ndomains. However, they struggle to segment objects with certain structures,\nparticularly those with dense, tree-like morphology and low textural contrast\nfrom their surroundings. These failure modes are crucial for understanding the\nlimitations of SFMs in real-world applications. To systematically study this\nissue, we introduce interpretable metrics quantifying object tree-likeness and\ntextural separability. On carefully controlled synthetic experiments and\nreal-world datasets, we show that SFM performance (e.g., SAM, SAM 2, HQ-SAM)\nnoticeably correlates with these factors. We link these failures to \"textural\nconfusion\", where models misinterpret local structure as global texture,\ncausing over-segmentation or difficulty distinguishing objects from similar\nbackgrounds. Notably, targeted fine-tuning fails to resolve this issue,\nindicating a fundamental limitation. Our study provides the first quantitative\nframework for modeling the behavior of SFMs on challenging structures, offering\ninterpretable insights into their segmentation capabilities.\n","authors":["Yixin Zhang","Nicholas Konz","Kevin Kramer","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2412.04243v2.pdf","comment":"Code: https://github.com/mazurowski-lab/SAM-TexturalConfusion-Metrics"},{"id":"http://arxiv.org/abs/2501.17450v2","updated":"2025-03-10T14:42:09Z","published":"2025-01-29T07:14:09Z","title":"A Constraint-Preserving Neural Network Approach for Solving Mean-Field\n  Games Equilibrium","summary":"  Neural network-based methods have demonstrated effectiveness in solving\nhigh-dimensional Mean-Field Games (MFG) equilibria, yet ensuring mathematically\nconsistent density-coupled evolution remains a major challenge. This paper\nproposes the NF-MKV Net, a neural network approach that integrates\nprocess-regularized normalizing flow (NF) with state-policy-connected\ntime-series neural networks to solve MKV FBSDEs and their associated\nfixed-point formulations of MFG equilibria. The method first reformulates MFG\nequilibria as MKV FBSDEs, embedding density evolution into equation\ncoefficients within a probabilistic framework. Neural networks are then\nemployed to approximate value functions and their gradients. To enforce\nvolumetric invariance and temporal continuity, NF architectures impose loss\nconstraints on each density transfer function.\n","authors":["Jinwei Liu","Lu Ren","Wang Yao","Xiao Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.17450v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2503.07383v1","updated":"2025-03-10T14:32:27Z","published":"2025-03-10T14:32:27Z","title":"Diagnostic-free onboard battery health assessment","summary":"  Diverse usage patterns induce complex and variable aging behaviors in\nlithium-ion batteries, complicating accurate health diagnosis and prognosis.\nSeparate diagnostic cycles are often used to untangle the battery's current\nstate of health from prior complex aging patterns. However, these same\ndiagnostic cycles alter the battery's degradation trajectory, are\ntime-intensive, and cannot be practically performed in onboard applications. In\nthis work, we leverage portions of operational measurements in combination with\nan interpretable machine learning model to enable rapid, onboard battery health\ndiagnostics and prognostics without offline diagnostic testing and the\nrequirement of historical data. We integrate mechanistic constraints within an\nencoder-decoder architecture to extract electrode states in a physically\ninterpretable latent space and enable improved reconstruction of the\ndegradation path. The health diagnosis model framework can be flexibly applied\nacross diverse application interests with slight fine-tuning. We demonstrate\nthe versatility of this model framework by applying it to three battery-cycling\ndatasets consisting of 422 cells under different operating conditions,\nhighlighting the utility of an interpretable diagnostic-free, onboard battery\ndiagnosis and prognosis model.\n","authors":["Yunhong Che","Vivek N. Lam","Jinwook Rhyu","Joachim Schaeffer","Minsu Kim","Martin Z. Bazant","William C. Chueh","Richard D. Braatz"],"pdf_url":"https://arxiv.org/pdf/2503.07383v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.07378v1","updated":"2025-03-10T14:31:34Z","published":"2025-03-10T14:31:34Z","title":"Materials Map Integrating Experimental and Computational Data through\n  Graph-Based Machine Learning for Enhanced Materials Discovery","summary":"  Materials informatics (MI), which emerges from the integration of materials\nscience and data science, is expected to greatly streamline the material\ndiscovery and development. The data used for MI are obtained from both\ncomputational and experimental studies, while their integration remains\nchallenging. In our previous study, we reported the integration of these\ndatasets by applying a machine learning model that captures trends hidden in\nthe experimental datasets to compositional data stored in the computational\ndatabase. In this study, we use the obtained data to construct materials maps,\nwhich visualize the relation in the structural features of materials, aiming to\nsupport study by the experimental researchers. The map is constructed using the\nMatDeepLearn (MDL) framework, which implements the graph-based representation\nof material structures, deep learning, and dimensional reduction for the map\nconstruction. We evaluate the obtained materials maps through statistical\nanalysis and found that the MDL using message passing neural network (MPNN)\nenables efficient extraction of features that reflect the structural complexity\nof materials. Moreover, we found that this advantage does not necessarily\ntranslate into improved accuracy in predicting material properties. We\nattribute this unexpected outcome to the high learning performance inherent in\nMPNN, which can contribute to the structuring of data points within the\nmaterials map.\n","authors":["Yusuke Hashimoto","Xue Jia","Li Hao","Takaaki Toma"],"pdf_url":"https://arxiv.org/pdf/2503.07378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07375v1","updated":"2025-03-10T14:30:56Z","published":"2025-03-10T14:30:56Z","title":"Probabilistic Segmentation for Robust Field of View Estimation","summary":"  Attacks on sensing and perception threaten the safe deployment of autonomous\nvehicles (AVs). Security-aware sensor fusion helps mitigate threats but\nrequires accurate field of view (FOV) estimation which has not been evaluated\nautonomy. To address this gap, we adapt classical computer graphics algorithms\nto develop the first autonomy-relevant FOV estimators and create the first\ndatasets with ground truth FOV labels. Unfortunately, we find that these\napproaches are themselves highly vulnerable to attacks on sensing. To improve\nrobustness of FOV estimation against attacks, we propose a learning-based\nsegmentation model that captures FOV features, integrates Monte Carlo dropout\n(MCD) for uncertainty quantification, and performs anomaly detection on\nconfidence maps. We illustrate through comprehensive evaluations attack\nresistance and strong generalization across environments. Architecture trade\nstudies demonstrate the model is feasible for real-time deployment in multiple\napplications.\n","authors":["R. Spencer Hallyburton","David Hunt","Yiwei He","Judy He","Miroslav Pajic"],"pdf_url":"https://arxiv.org/pdf/2503.07375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05139v2","updated":"2025-03-10T14:21:21Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2503.07352v1","updated":"2025-03-10T14:08:31Z","published":"2025-03-10T14:08:31Z","title":"Score-informed Music Source Separation: Improving Synthetic-to-real\n  Generalization in Classical Music","summary":"  Music source separation is the task of separating a mixture of instruments\ninto constituent tracks. Music source separation models are typically trained\nusing only audio data, although additional information can be used to improve\nthe model's separation capability. In this paper, we propose two ways of using\nmusical scores to aid music source separation: a score-informed model where the\nscore is concatenated with the magnitude spectrogram of the audio mixture as\nthe input of the model, and a model where we use only the score to calculate\nthe separation mask. We train our models on synthetic data in the SynthSOD\ndataset and evaluate our methods on the URMP and Aalto anechoic orchestra\ndatasets, comprised of real recordings. The score-informed model improves\nseparation results compared to a baseline approach, but struggles to generalize\nfrom synthetic to real data, whereas the score-only model shows a clear\nimprovement in synthetic-to-real generalization.\n","authors":["Eetu Tunturi","David Diaz-Guerra","Archontis Politis","Tuomas Virtanen"],"pdf_url":"https://arxiv.org/pdf/2503.07352v1.pdf","comment":"5 pages, 2 figures, submitted to Eusipco2025"},{"id":"http://arxiv.org/abs/2503.04870v2","updated":"2025-03-10T14:04:38Z","published":"2025-03-06T16:04:01Z","title":"Leveraging Large Language Models to Address Data Scarcity in Machine\n  Learning: Applications in Graphene Synthesis","summary":"  Machine learning in materials science faces challenges due to limited\nexperimental data, as generating synthesis data is costly and time-consuming,\nespecially with in-house experiments. Mining data from existing literature\nintroduces issues like mixed data quality, inconsistent formats, and variations\nin reporting experimental parameters, complicating the creation of consistent\nfeatures for the learning algorithm. Additionally, combining continuous and\ndiscrete features can hinder the learning process with limited data. Here, we\npropose strategies that utilize large language models (LLMs) to enhance machine\nlearning performance on a limited, heterogeneous dataset of graphene chemical\nvapor deposition synthesis compiled from existing literature. These strategies\ninclude prompting modalities for imputing missing data points and leveraging\nlarge language model embeddings to encode the complex nomenclature of\nsubstrates reported in chemical vapor deposition experiments. The proposed\nstrategies enhance graphene layer classification using a support vector machine\n(SVM) model, increasing binary classification accuracy from 39% to 65% and\nternary accuracy from 52% to 72%. We compare the performance of the SVM and a\nGPT-4 model, both trained and fine-tuned on the same data. Our results\ndemonstrate that the numerical classifier, when combined with LLM-driven data\nenhancements, outperforms the standalone LLM predictor, highlighting that in\ndata-scarce scenarios, improving predictive learning with LLM strategies\nrequires more than simple fine-tuning on datasets. Instead, it necessitates\nsophisticated approaches for data imputation and feature space homogenization\nto achieve optimal performance. The proposed strategies emphasize data\nenhancement techniques, offering a broadly applicable framework for improving\nmachine learning performance on scarce, inhomogeneous datasets.\n","authors":["Devi Dutta Biswajeet","Sara Kadkhodaei"],"pdf_url":"https://arxiv.org/pdf/2503.04870v2.pdf","comment":"20 pages, 10 figures, 4 tables; Supplementary Material with 13\n  figures and 4 tables"},{"id":"http://arxiv.org/abs/2503.07346v1","updated":"2025-03-10T13:59:57Z","published":"2025-03-10T13:59:57Z","title":"Now you see me! A framework for obtaining class-relevant saliency maps","summary":"  Neural networks are part of daily-life decision-making, including in\nhigh-stakes settings where understanding and transparency are key. Saliency\nmaps have been developed to gain understanding into which input features neural\nnetworks use for a specific prediction. Although widely employed, these methods\noften result in overly general saliency maps that fail to identify the specific\ninformation that triggered the classification. In this work, we suggest a\nframework that allows to incorporate attributions across classes to arrive at\nsaliency maps that actually capture the class-relevant information. On\nestablished benchmarks for attribution methods, including the grid-pointing\ngame and randomization-based sanity checks, we show that our framework heavily\nboosts the performance of standard saliency map approaches. It is, by design,\nagnostic to model architectures and attribution methods and now allows to\nidentify the distinguishing and shared features used for a model prediction.\n","authors":["Nils Philipp Walter","Jilles Vreeken","Jonas Fischer"],"pdf_url":"https://arxiv.org/pdf/2503.07346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16821v3","updated":"2025-03-10T13:58:19Z","published":"2024-11-25T17:15:41Z","title":"KL-geodesics flow matching with a novel sampling scheme","summary":"  Non-autoregressive language models generate all tokens simultaneously,\noffering potential speed advantages over traditional autoregressive models, but\nthey face challenges in modeling the complex dependencies inherent in text\ndata. In this work, we investigate a conditional flow matching approach for\ntext generation. We represent tokens as one-hot vectors in a \\(V\\)-dimensional\nsimplex and utilize geodesics under the Kullback-Leibler (KL) divergence, which\ncorrespond to linear interpolation in logit space. We provide a theoretical\njustification that maximizing the conditional likelihood \\(P_{\\theta}(x_1 \\mid\nx_t, t)\\) yields the exact flow matching velocity under logit interpolation. To\naddress the suboptimal performance of basic inference, we propose a novel\nempirical sampling scheme that iteratively samples from the conditional\ndistribution and introduces additional noise, significantly improving results\ndespite lacking full theoretical underpinnings. Furthermore, we propose a\nhybrid inference method that combines the basic approach with the sampling\nscheme. This method demonstrates superior performance on both conditional and\nunconditional text generation experiments compared to previous SOTA method for\ndiscrete flow matching.\n","authors":["Egor Sevriugov","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2411.16821v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02467v6","updated":"2025-03-10T13:57:12Z","published":"2024-10-03T13:17:06Z","title":"Extracting Training Data from Unconditional Diffusion Models","summary":"  As diffusion probabilistic models (DPMs) are being employed as mainstream\nmodels for Generative Artificial Intelligence (GenAI), the study of their\nmemorization has attracted growing attention. Existing works in this field aim\nto establish an understanding of whether or to what extent DPMs learn via\nmemorization. Such an understanding is crucial for identifying potential risks\nof data leakage and copyright infringement in diffusion models and, more\nimportantly, for trustworthy application of GenAI. Existing works revealed that\nconditional DPMs are more prone to memorize training data than unconditional\nDPMs. And most data extraction methods developed so far target conditional\nDPMs. Although unconditional DPMs are less prone to data extraction, further\ninvestigation into these attacks remains essential since they serve as the\nfoundation for conditional models like Stable Diffusion, and exploring these\nattacks will enhance our understanding of memorization in DPMs. In this work,\nwe propose a novel data extraction method named \\textbf{Surrogate condItional\nData Extraction (SIDE)} that leverages a time-dependent classifier trained on\ngenerated data as surrogate conditions to extract training data from\nunconditional DPMs. Empirical results demonstrate that it can extract training\ndata in challenging scenarios where previous methods fail, and it is, on\naverage, over 50\\% more effective across different scales of the CelebA\ndataset. Furthermore, we provide a theoretical understanding of memorization in\nboth conditional and unconditional DPMs and why SIDE is effective.\n","authors":["Yunhao Chen","Shujie Wang","Difan Zou","Xingjun Ma"],"pdf_url":"https://arxiv.org/pdf/2410.02467v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07340v1","updated":"2025-03-10T13:53:22Z","published":"2025-03-10T13:53:22Z","title":"Research and Design on Intelligent Recognition of Unordered Targets for\n  Robots Based on Reinforcement Learning","summary":"  In the field of robot target recognition research driven by artificial\nintelligence (AI), factors such as the disordered distribution of targets, the\ncomplexity of the environment, the massive scale of data, and noise\ninterference have significantly restricted the improvement of target\nrecognition accuracy. Against the backdrop of the continuous iteration and\nupgrading of current AI technologies, to meet the demand for accurate\nrecognition of disordered targets by intelligent robots in complex and\nchangeable scenarios, this study innovatively proposes an AI - based\nintelligent robot disordered target recognition method using reinforcement\nlearning. This method processes the collected target images with the bilateral\nfiltering algorithm, decomposing them into low - illumination images and\nreflection images. Subsequently, it adopts differentiated AI strategies,\ncompressing the illumination images and enhancing the reflection images\nrespectively, and then fuses the two parts of images to generate a new image.\nOn this basis, this study deeply integrates deep learning, a core AI\ntechnology, with the reinforcement learning algorithm. The enhanced target\nimages are input into a deep reinforcement learning model for training,\nultimately enabling the AI - based intelligent robot to efficiently recognize\ndisordered targets. Experimental results show that the proposed method can not\nonly significantly improve the quality of target images but also enable the AI\n- based intelligent robot to complete the recognition task of disordered\ntargets with higher efficiency and accuracy, demonstrating extremely high\napplication value and broad development prospects in the field of AI robots.\n","authors":["Yiting Mao","Dajun Tao","Shengyuan Zhang","Tian Qi","Keqin Li"],"pdf_url":"https://arxiv.org/pdf/2503.07340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07329v1","updated":"2025-03-10T13:42:04Z","published":"2025-03-10T13:42:04Z","title":"Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning\n  Large Language Models","summary":"  The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.\n","authors":["Hao Zhou","Guergana Savova","Lijing Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07329v1.pdf","comment":"7 pages, 5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2503.07326v1","updated":"2025-03-10T13:40:28Z","published":"2025-03-10T13:40:28Z","title":"AI Biases as Asymmetries: A Review to Guide Practice","summary":"  The understanding of bias in AI is currently undergoing a revolution.\nInitially understood as errors or flaws, biases are increasingly recognized as\nintegral to AI systems and sometimes preferable to less biased alternatives. In\nthis paper, we review the reasons for this changed understanding and provide\nnew guidance on two questions: First, how should we think about and measure\nbiases in AI systems, consistent with the new understanding? Second, what kinds\nof bias in an AI system should we accept or even amplify, and what kinds should\nwe minimize or eliminate, and why? The key to answering both questions, we\nargue, is to understand biases as \"violations of a symmetry standard\"\n(following Kelly). We distinguish three main types of asymmetry in AI\nsystems-error biases, inequality biases, and process biases-and highlight\nplaces in the pipeline of AI development and application where bias of each\ntype is likely to be good, bad, or inevitable.\n","authors":["Gabriella Waters","Phillip Honenberger"],"pdf_url":"https://arxiv.org/pdf/2503.07326v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2503.07325v1","updated":"2025-03-10T13:40:10Z","published":"2025-03-10T13:40:10Z","title":"Non-vacuous Generalization Bounds for Deep Neural Networks without any\n  modification to the trained models","summary":"  Deep neural network (NN) with millions or billions of parameters can perform\nreally well on unseen data, after being trained from a finite training set.\nVarious prior theories have been developed to explain such excellent ability of\nNNs, but do not provide a meaningful bound on the test error. Some recent\ntheories, based on PAC-Bayes and mutual information, are non-vacuous and hence\nshow a great potential to explain the excellent performance of NNs. However,\nthey often require a stringent assumption and extensive modification (e.g.\ncompression, quantization) to the trained model of interest. Therefore, those\nprior theories provide a guarantee for the modified versions only. In this\npaper, we propose two novel bounds on the test error of a model. Our bounds\nuses the training set only and require no modification to the model. Those\nbounds are verified on a large class of modern NNs, pretrained by Pytorch on\nthe ImageNet dataset, and are non-vacuous. To the best of our knowledge, these\nare the first non-vacuous bounds at this large scale, without any modification\nto the pretrained models.\n","authors":["Khoat Than","Dat Phan"],"pdf_url":"https://arxiv.org/pdf/2503.07325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07324v1","updated":"2025-03-10T13:39:57Z","published":"2025-03-10T13:39:57Z","title":"Decision-Dependent Stochastic Optimization: The Role of Distribution\n  Dynamics","summary":"  Distribution shifts have long been regarded as troublesome external forces\nthat a decision-maker should either counteract or conform to. An intriguing\nfeedback phenomenon termed decision dependence arises when the deployed\ndecision affects the environment and alters the data-generating distribution.\nIn the realm of performative prediction, this is encoded by distribution maps\nparameterized by decisions due to strategic behaviors. In contrast, we\nformalize an endogenous distribution shift as a feedback process featuring\nnonlinear dynamics that couple the evolving distribution with the decision.\nStochastic optimization in this dynamic regime provides a fertile ground to\nexamine the various roles played by dynamics in the composite problem\nstructure. To this end, we develop an online algorithm that achieves optimal\ndecision-making by both adapting to and shaping the dynamic distribution.\nThroughout the paper, we adopt a distributional perspective and demonstrate how\nthis view facilitates characterizations of distribution dynamics and the\noptimality and generalization performance of the proposed algorithm. We\nshowcase the theoretical results in an opinion dynamics context, where an\nopportunistic party maximizes the affinity of a dynamic polarized population,\nand in a recommender system scenario, featuring performance optimization with\ndiscrete distributions in the probability simplex.\n","authors":["Zhiyu He","Saverio Bolognani","Florian Dörfler","Michael Muehlebach"],"pdf_url":"https://arxiv.org/pdf/2503.07324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07315v1","updated":"2025-03-10T13:34:18Z","published":"2025-03-10T13:34:18Z","title":"Group-robust Sample Reweighting for Subpopulation Shifts via Influence\n  Functions","summary":"  Machine learning models often have uneven performance among subpopulations\n(a.k.a., groups) in the data distributions. This poses a significant challenge\nfor the models to generalize when the proportions of the groups shift during\ndeployment. To improve robustness to such shifts, existing approaches have\ndeveloped strategies that train models or perform hyperparameter tuning using\nthe group-labeled data to minimize the worst-case loss over groups. However, a\nnon-trivial amount of high-quality labels is often required to obtain\nnoticeable improvements. Given the costliness of the labels, we propose to\nadopt a different paradigm to enhance group label efficiency: utilizing the\ngroup-labeled data as a target set to optimize the weights of other\ngroup-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a\ntwo-stage approach that first learns the representations from group-unlabeled\ndata, and then tinkers the model by iteratively retraining its last layer on\nthe reweighted data using influence functions. Our GSR is theoretically sound,\npractically lightweight, and effective in improving the robustness to\nsubpopulation shifts. In particular, GSR outperforms the previous\nstate-of-the-art approaches that require the same amount or even more group\nlabels.\n","authors":["Rui Qiao","Zhaoxuan Wu","Jingtan Wang","Pang Wei Koh","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2503.07315v1.pdf","comment":"Accepted to the 13th International Conference on Learning\n  Representations (ICLR 2025). Code is available at\n  https://github.com/qiaoruiyt/GSR"},{"id":"http://arxiv.org/abs/2503.07313v1","updated":"2025-03-10T13:32:25Z","published":"2025-03-10T13:32:25Z","title":"The influence of missing data mechanisms and simple missing data\n  handling techniques on fairness","summary":"  Fairness of machine learning algorithms is receiving increasing attention, as\nsuch algorithms permeate the day-to-day aspects of our lives. One way in which\nbias can manifest in a dataset is through missing values. If data are missing,\nthese data are often assumed to be missing completely randomly; in reality the\npropensity of data being missing is often tied to the demographic\ncharacteristics of individuals. There is limited research into how missing\nvalues and the handling thereof can impact the fairness of an algorithm. Most\nresearchers either apply listwise deletion or tend to use the simpler methods\nof imputation (e.g. mean or mode) compared to the more advanced ones (e.g.\nmultiple imputation); we therefore study the impact of the simpler methods on\nthe fairness of algorithms. The starting point of the study is the mechanism of\nmissingness, leading into how the missing data are processed and finally how\nthis impacts fairness. Three popular datasets in the field of fairness are\namputed in a simulation study. The results show that under certain scenarios\nthe impact on fairness can be pronounced when the missingness mechanism is\nmissing at random. Furthermore, elementary missing data handling techniques\nlike listwise deletion and mode imputation can lead to higher fairness compared\nto more complex imputation methods like k-nearest neighbour imputation, albeit\noften at the cost of lower accuracy.\n","authors":["Aeysha Bhatti","Trudie Sandrock","Johane Nienkemper-Swanepoel"],"pdf_url":"https://arxiv.org/pdf/2503.07313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07302v1","updated":"2025-03-10T13:22:38Z","published":"2025-03-10T13:22:38Z","title":"When Selection Meets Intervention: Additional Complexities in Causal\n  Discovery","summary":"  We address the common yet often-overlooked selection bias in interventional\nstudies, where subjects are selectively enrolled into experiments. For\ninstance, participants in a drug trial are usually patients of the relevant\ndisease; A/B tests on mobile applications target existing users only, and gene\nperturbation studies typically focus on specific cell types, such as cancer\ncells. Ignoring this bias leads to incorrect causal discovery results. Even\nwhen recognized, the existing paradigm for interventional causal discovery\nstill fails to address it. This is because subtle differences in when and where\ninterventions happen can lead to significantly different statistical patterns.\nWe capture this dynamic by introducing a graphical model that explicitly\naccounts for both the observed world (where interventions are applied) and the\ncounterfactual world (where selection occurs while interventions have not been\napplied). We characterize the Markov property of the model, and propose a\nprovably sound algorithm to identify causal relations as well as selection\nmechanisms up to the equivalence class, from data with soft interventions and\nunknown targets. Through synthetic and real-world experiments, we demonstrate\nthat our algorithm effectively identifies true causal relations despite the\npresence of selection bias.\n","authors":["Haoyue Dai","Ignavier Ng","Jianle Sun","Zeyu Tang","Gongxu Luo","Xinshuai Dong","Peter Spirtes","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07302v1.pdf","comment":"Appears at ICLR 2025 (oral)"},{"id":"http://arxiv.org/abs/2502.06096v2","updated":"2025-03-10T13:20:58Z","published":"2025-02-10T02:01:30Z","title":"Post-detection inference for sequential changepoint localization","summary":"  This paper addresses a fundamental but largely unexplored challenge in\nsequential changepoint analysis: conducting inference following a detected\nchange. We study the problem of localizing the changepoint using only the data\nobserved up to a data-dependent stopping time at which a sequential detection\nalgorithm $\\mathcal A$ declares a change. We first construct confidence sets\nfor the unknown changepoint when pre- and post-change distributions are assumed\nto be known. We then extend our framework to composite pre- and post-change\nscenarios. We impose no conditions on the observation space or on $\\mathcal A$\n-- we only need to be able to run $\\mathcal A$ on simulated data sequences. In\nsummary, this work offers both theoretically sound and practically effective\ntools for sequential changepoint localization.\n","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2502.06096v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03442v2","updated":"2025-03-10T13:19:15Z","published":"2024-12-04T16:30:35Z","title":"State Frequency Estimation for Anomaly Detection","summary":"  Many works have studied the efficacy of state machines for detecting\nanomalies within NetFlows. These works typically learn a model from unlabeled\ndata and compute anomaly scores for arbitrary traces based on their likelihood\nof occurrence or how well they fit within the model. However, these methods do\nnot dynamically adapt their scores based on the traces seen at test time. This\nbecomes a problem when an adversary produces seemingly common traces in their\nattack, causing the model to miss the detection by assigning low anomaly\nscores. We propose SEQUENT, a new unsupervised approach that uses the state\nvisit frequency of a state machine to adapt its scoring dynamically for anomaly\ndetection. SEQUENT subsequently uses the scores to generate root causes for\nanomalies. These allow the grouping of alarms and simplify the analysis of\nanomalies. We evaluate SEQUENT's effectiveness in detecting network anomalies\non three publicly available NetFlow datasets and compare its performance\nagainst various existing unsupervised anomaly detection methods. Our evaluation\nshows promising results for using the state visit frequency of a state machine\nto detect network anomalies.\n","authors":["Clinton Cao","Agathe Blaise","Annibale Panichella","Sicco Verwer"],"pdf_url":"https://arxiv.org/pdf/2412.03442v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2503.07294v1","updated":"2025-03-10T13:16:48Z","published":"2025-03-10T13:16:48Z","title":"Distilling Knowledge into Quantum Vision Transformers for Biomedical\n  Image Classification","summary":"  Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis.\n","authors":["Thomas Boucher","Evangelos B. Mazomenos"],"pdf_url":"https://arxiv.org/pdf/2503.07294v1.pdf","comment":"Submitted for MICCAI 2025"},{"id":"http://arxiv.org/abs/2410.04228v2","updated":"2025-03-10T13:02:15Z","published":"2024-10-05T16:57:40Z","title":"SGD with memory: fundamental properties and stochastic acceleration","summary":"  An important open problem is the theoretically feasible acceleration of\nmini-batch SGD-type algorithms on quadratic problems with power-law spectrum.\nIn the non-stochastic setting, the optimal exponent $\\xi$ in the loss\nconvergence $L_t\\sim C_Lt^{-\\xi}$ is double that in plain GD and is achievable\nusing Heavy Ball (HB) with a suitable schedule; this no longer works in the\npresence of mini-batch noise. We address this challenge by considering\nfirst-order methods with an arbitrary fixed number $M$ of auxiliary velocity\nvectors (*memory-$M$ algorithms*). We first prove an equivalence between two\nforms of such algorithms and describe them in terms of suitable characteristic\npolynomials. Then we develop a general expansion of the loss in terms of signal\nand noise propagators. Using it, we show that losses of stationary stable\nmemory-$M$ algorithms always retain the exponent $\\xi$ of plain GD, but can\nhave different constants $C_L$ depending on their effective learning rate that\ngeneralizes that of HB. We prove that in memory-1 algorithms we can make $C_L$\narbitrarily small while maintaining stability. As a consequence, we propose a\nmemory-1 algorithm with a time-dependent schedule that we show heuristically\nand experimentally to improve the exponent $\\xi$ of plain SGD.\n","authors":["Dmitry Yarotsky","Maksim Velikanov"],"pdf_url":"https://arxiv.org/pdf/2410.04228v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2501.13456v3","updated":"2025-03-10T13:01:47Z","published":"2025-01-23T08:14:55Z","title":"KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) with attention mechanisms, often referred to as\nattentive GNNs, have emerged as a prominent paradigm in advanced GNN models in\nrecent years. However, our understanding of the critical process of scoring\nneighbor nodes remains limited, leading to the underperformance of many\nexisting attentive GNNs. In this paper, we unify the scoring functions of\ncurrent attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which\nintegrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring\nprocess. KAA enhances the performance of scoring functions across the board and\ncan be applied to nearly all existing attentive GNNs. To compare the expressive\npower of KAA with other scoring functions, we introduce Maximum Ranking\nDistance (MRD) to quantitatively estimate their upper bounds in ranking errors\nfor node importance. Our analysis reveals that, under limited parameters and\nconstraints on width and depth, both linear transformation-based and MLP-based\nscoring functions exhibit finite expressive power. In contrast, our proposed\nKAA, even with a single-layer KAN parameterized by zero-order B-spline\nfunctions, demonstrates nearly infinite expressive power. Extensive experiments\non both node-level and graph-level tasks using various backbone models show\nthat KAA-enhanced scoring functions consistently outperform their original\ncounterparts, achieving performance improvements of over 20% in some cases.\n","authors":["Taoran Fang","Tianhong Gao","Chunping Wang","Yihao Shang","Wei Chow","Lei Chen","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13456v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07276v1","updated":"2025-03-10T12:57:43Z","published":"2025-03-10T12:57:43Z","title":"A Systematic Review of ECG Arrhythmia Classification: Adherence to\n  Standards, Fair Evaluation, and Embedded Feasibility","summary":"  The classification of electrocardiogram (ECG) signals is crucial for early\ndetection of arrhythmias and other cardiac conditions. However, despite\nadvances in machine learning, many studies fail to follow standardization\nprotocols, leading to inconsistencies in performance evaluation and real-world\napplicability. Additionally, hardware constraints essential for practical\ndeployment, such as in pacemakers, Holter monitors, and wearable ECG patches,\nare often overlooked. Since real-world impact depends on feasibility in\nresource-constrained devices, ensuring efficient deployment is critical for\ncontinuous monitoring. This review systematically analyzes ECG classification\nstudies published between 2017 and 2024, focusing on those adhering to the E3C\n(Embedded, Clinical, and Comparative Criteria), which include inter-patient\nparadigm implementation, compliance with Association for the Advancement of\nMedical Instrumentation (AAMI) recommendations, and model feasibility for\nembedded systems. While many studies report high accuracy, few properly\nconsider patient-independent partitioning and hardware limitations. We identify\nstate-of-the-art methods meeting E3C criteria and conduct a comparative\nanalysis of accuracy, inference time, energy consumption, and memory usage.\nFinally, we propose standardized reporting practices to ensure fair comparisons\nand practical applicability of ECG classification models. By addressing these\ngaps, this study aims to guide future research toward more robust and\nclinically viable ECG classification systems.\n","authors":["Guilherme Silva","Pedro Silva","Gladston Moreira","Vander Freitas","Jadson Gertrudes","Eduardo Luz"],"pdf_url":"https://arxiv.org/pdf/2503.07276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05870v4","updated":"2025-03-10T12:56:54Z","published":"2024-06-09T17:55:55Z","title":"Machine Against the RAG: Jamming Retrieval-Augmented Generation with\n  Blocker Documents","summary":"  Retrieval-augmented generation (RAG) systems respond to queries by retrieving\nrelevant documents from a knowledge database and applying an LLM to the\nretrieved documents. We demonstrate that RAG systems that operate on databases\nwith untrusted content are vulnerable to denial-of-service attacks we call\njamming. An adversary can add a single ``blocker'' document to the database\nthat will be retrieved in response to a specific query and result in the RAG\nsystem not answering this query, ostensibly because it lacks relevant\ninformation or because the answer is unsafe.\n  We describe and measure the efficacy of several methods for generating\nblocker documents, including a new method based on black-box optimization. Our\nmethod (1) does not rely on instruction injection, (2) does not require the\nadversary to know the embedding or LLM used by the target RAG system, and (3)\ndoes not employ an auxiliary LLM.\n  We evaluate jamming attacks on several embeddings and LLMs and demonstrate\nthat the existing safety metrics for LLMs do not capture their vulnerability to\njamming. We then discuss defenses against blocker documents.\n","authors":["Avital Shafran","Roei Schuster","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2406.05870v4.pdf","comment":"To appear in USENIX Security Symposium 2025"},{"id":"http://arxiv.org/abs/2503.07274v1","updated":"2025-03-10T12:55:08Z","published":"2025-03-10T12:55:08Z","title":"Efficient Distillation of Classifier-Free Guidance using Adapters","summary":"  While classifier-free guidance (CFG) is essential for conditional diffusion\nmodels, it doubles the number of neural function evaluations (NFEs) per\ninference step. To mitigate this inefficiency, we introduce adapter guidance\ndistillation (AGD), a novel approach that simulates CFG in a single forward\npass. AGD leverages lightweight adapters to approximate CFG, effectively\ndoubling the sampling speed while maintaining or even improving sample quality.\nUnlike prior guidance distillation methods that tune the entire model, AGD\nkeeps the base model frozen and only trains minimal additional parameters\n($\\sim$2%) to significantly reduce the resource requirement of the distillation\nphase. Additionally, this approach preserves the original model weights and\nenables the adapters to be seamlessly combined with other checkpoints derived\nfrom the same base model. We also address a key mismatch between training and\ninference in existing guidance distillation methods by training on CFG-guided\ntrajectories instead of standard diffusion trajectories. Through extensive\nexperiments, we show that AGD achieves comparable or superior FID to CFG across\nmultiple architectures with only half the NFEs. Notably, our method enables the\ndistillation of large models ($\\sim$2.6B parameters) on a single consumer GPU\nwith 24 GB of VRAM, making it more accessible than previous approaches that\nrequire multiple high-end GPUs. We will publicly release the implementation of\nour method.\n","authors":["Cristian Perez Jensen","Seyedmorteza Sadat"],"pdf_url":"https://arxiv.org/pdf/2503.07274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07272v1","updated":"2025-03-10T12:53:45Z","published":"2025-03-10T12:53:45Z","title":"Federated Learning in NTNs: Design, Architecture and Challenges","summary":"  Non-terrestrial networks (NTNs) are emerging as a core component of future 6G\ncommunication systems, providing global connectivity and supporting\ndata-intensive applications. In this paper, we propose a distributed\nhierarchical federated learning (HFL) framework within the NTN architecture,\nleveraging a high altitude platform station (HAPS) constellation as\nintermediate distributed FL servers. Our framework integrates both low-Earth\norbit (LEO) satellites and ground clients in the FL training process while\nutilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as\nrelays to exchange FL global models across other HAPS constellations worldwide,\nenabling seamless, global-scale learning. The proposed framework offers several\nkey benefits: (i) enhanced privacy through the decentralization of the FL\nmechanism by leveraging the HAPS constellation, (ii) improved model accuracy\nand reduced training loss while balancing latency, (iii) increased scalability\nof FL systems through ubiquitous connectivity by utilizing MEO and GEO\nsatellites, and (iv) the ability to use FL data, such as resource utilization\nmetrics, to further optimize the NTN architecture from a network management\nperspective. A numerical study demonstrates the proposed framework's\neffectiveness, with improved model accuracy, reduced training loss, and\nefficient latency management. The article also includes a brief review of FL in\nNTNs and highlights key challenges and future research directions.\n","authors":["Amin Farajzadeh","Animesh Yadav","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2503.07272v1.pdf","comment":"Accepted in IEEE Communications Magazine"},{"id":"http://arxiv.org/abs/2412.13294v2","updated":"2025-03-10T12:42:18Z","published":"2024-12-17T19:47:10Z","title":"Interpretable deformable image registration: A geometric deep learning\n  perspective","summary":"  Deformable image registration poses a challenging problem where, unlike most\ndeep learning tasks, a complex relationship between multiple coordinate systems\nhas to be considered. Although data-driven methods have shown promising\ncapabilities to model complex non-linear transformations, existing works employ\nstandard deep learning architectures assuming they are general black-box\nsolvers. We argue that understanding how learned operations perform\npattern-matching between the features in the source and target domains is the\nkey to building robust, data-efficient, and interpretable architectures. We\npresent a theoretical foundation for designing an interpretable registration\nframework: separated feature extraction and deformation modeling, dynamic\nreceptive fields, and a data-driven deformation functions awareness of the\nrelationship between both spatial domains. Based on this foundation, we\nformulate an end-to-end process that refines transformations in a\ncoarse-to-fine fashion. Our architecture employs spatially continuous\ndeformation modeling functions that use geometric deep-learning principles,\ntherefore avoiding the problematic approach of resampling to a regular grid\nbetween successive refinements of the transformation. We perform a qualitative\ninvestigation to highlight interesting interpretability properties of our\narchitecture. We conclude by showing significant improvement in performance\nmetrics over state-of-the-art approaches for both mono- and multi-modal\ninter-subject brain registration, as well as the challenging task of\nlongitudinal retinal intra-subject registration. We make our code publicly\navailable\n","authors":["Vasiliki Sideri-Lampretsa","Nil Stolt-Ansó","Huaqi Qiu","Julian McGinnis","Wenke Karbole","Martin Menten","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2412.13294v2.pdf","comment":"20 Pages"},{"id":"http://arxiv.org/abs/2503.07258v1","updated":"2025-03-10T12:41:19Z","published":"2025-03-10T12:41:19Z","title":"MC-GRU:a Multi-Channel GRU network for generalized nonlinear structural\n  response prediction across structures","summary":"  Accurate prediction of seismic responses and quantification of structural\ndamage are critical in civil engineering. Traditional approaches such as finite\nelement analysis could lack computational efficiency, especially for complex\nstructural systems under extreme hazards. Recently, artificial intelligence has\nprovided an alternative to efficiently model highly nonlinear behaviors.\nHowever, existing models face challenges in generalizing across diverse\nstructural systems. This paper proposes a novel multi-channel gated recurrent\nunit (MC-GRU) network aimed at achieving generalized nonlinear structural\nresponse prediction for varying structures. The key concept lies in the\nintegration of a multi-channel input mechanism to GRU with an extra input of\nstructural information to the candidate hidden state, which enables the network\nto learn the dynamic characteristics of diverse structures and thus empower the\ngeneralizability and adaptiveness to unseen structures. The performance of the\nproposed MC-GRU is validated through a series of case studies, including a\nsingle-degree-of-freedom linear system, a hysteretic Bouc-Wen system, and a\nnonlinear reinforced concrete column from experimental testing. Results\nindicate that the proposed MC-GRU overcomes the major generalizability issues\nof existing methods, with capability of accurately inferring seismic responses\nof varying structures. Additionally, it demonstrates enhanced capabilities in\nrepresenting nonlinear structural dynamics compared to traditional models such\nas GRU and LSTM.\n","authors":["Shan He","Ruiyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09481v2","updated":"2025-03-10T12:27:10Z","published":"2025-01-16T11:35:22Z","title":"MonoSOWA: Scalable monocular 3D Object detector Without human\n  Annotations","summary":"  Inferring object 3D position and orientation from a single RGB camera is a\nfoundational task in computer vision with many important applications.\nTraditionally, 3D object detection methods are trained in a fully-supervised\nsetup, requiring LiDAR and vast amounts of human annotations, which are\nlaborious, costly, and do not scale well with the ever-increasing amounts of\ndata being captured.\n  We present a novel method to train a 3D object detector from a single RGB\ncamera without domain-specific human annotations, making orders of magnitude\nmore data available for training. The method uses newly proposed Local Object\nMotion Model to disentangle object movement source between subsequent frames,\nis approximately 700 times faster than previous work and compensates camera\nfocal length differences to aggregate multiple datasets.\n  The method is evaluated on three public datasets, where despite using no\nhuman labels, it outperforms prior work by a significant margin. It also shows\nits versatility as a pre-training tool for fully-supervised training and shows\nthat combining pseudo-labels from multiple datasets can achieve comparable\naccuracy to using human labels from a single dataset. The source code and model\nwill be published soon.\n","authors":["Jan Skvrna","Lukas Neumann"],"pdf_url":"https://arxiv.org/pdf/2501.09481v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11168v3","updated":"2025-03-10T12:26:21Z","published":"2024-12-15T12:34:22Z","title":"PGD-Imp: Rethinking and Unleashing Potential of Classic PGD with Dual\n  Strategies for Imperceptible Adversarial Attacks","summary":"  Imperceptible adversarial attacks have recently attracted increasing research\ninterests. Existing methods typically incorporate external modules or loss\nterms other than a simple $l_p$-norm into the attack process to achieve\nimperceptibility, while we argue that such additional designs may not be\nnecessary. In this paper, we rethink the essence of imperceptible attacks and\npropose two simple yet effective strategies to unleash the potential of PGD,\nthe common and classical attack, for imperceptibility from an optimization\nperspective. Specifically, the Dynamic Step Size is introduced to find the\noptimal solution with minimal attack cost towards the decision boundary of the\nattacked model, and the Adaptive Early Stop strategy is adopted to reduce the\nredundant strength of adversarial perturbations to the minimum level. The\nproposed PGD-Imperceptible (PGD-Imp) attack achieves state-of-the-art results\nin imperceptible adversarial attacks for both untargeted and targeted\nscenarios. When performing untargeted attacks against ResNet-50, PGD-Imp\nattains 100$\\%$ (+0.3$\\%$) ASR, 0.89 (-1.76) $l_2$ distance, and 52.93 (+9.2)\nPSNR with 57s (-371s) running time, significantly outperforming existing\nmethods.\n","authors":["Jin Li","Zitong Yu","Ziqiang He","Z. Jane Wang","Xiangui Kang"],"pdf_url":"https://arxiv.org/pdf/2412.11168v3.pdf","comment":"Accepted by IEEE ICASSP 2025. Please cite this paper using the\n  following format: J. Li, Z. Yu, Z. He, Z. Wang, X. Kang, \"PGD-Imp: Rethinking\n  and Unleashing Potential of Classic PGD with Dual Strategies for\n  Imperceptible Adversarial Attacks,\" in proc. of International Conference on\n  Acoustics, Speech, and Signal Processing 2025 (ICASSP 2025), Hyderabad,\n  India, 2025-4-06 to 2025-04-11"},{"id":"http://arxiv.org/abs/2503.07227v1","updated":"2025-03-10T12:14:02Z","published":"2025-03-10T12:14:02Z","title":"Coreset Spectral Clustering","summary":"  Coresets have become an invaluable tool for solving $k$-means and kernel\n$k$-means clustering problems on large datasets with small numbers of clusters.\nOn the other hand, spectral clustering works well on sparse graphs and has\nrecently been extended to scale efficiently to large numbers of clusters. We\nexploit the connection between kernel $k$-means and the normalised cut problem\nto combine the benefits of both. Our main result is a coreset spectral\nclustering algorithm for graphs that clusters a coreset graph to infer a good\nlabelling of the original graph. We prove that an $\\alpha$-approximation for\nthe normalised cut problem on the coreset graph is an $O(\\alpha)$-approximation\non the original. We also improve the running time of the state-of-the-art\ncoreset algorithm for kernel $k$-means on sparse kernels, from $\\tilde{O}(nk)$\nto $\\tilde{O}(n\\cdot \\min \\{k, d_{avg}\\})$, where $d_{avg}$ is the average\nnumber of non-zero entries in each row of the $n\\times n$ kernel matrix. Our\nexperiments confirm our coreset algorithm is asymptotically faster on large\nreal-world graphs with many clusters, and show that our clustering algorithm\novercomes the main challenge faced by coreset kernel $k$-means on sparse\nkernels which is getting stuck in local optima.\n","authors":["Ben Jourdan","Gregory Schwartzman","Peter Macgregor","He Sun"],"pdf_url":"https://arxiv.org/pdf/2503.07227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17506v2","updated":"2025-03-10T12:11:58Z","published":"2025-02-22T00:12:52Z","title":"RAG-Enhanced Collaborative LLM Agents for Drug Discovery","summary":"  Recent advances in large language models (LLMs) have shown great potential to\naccelerate drug discovery. However, the specialized nature of biochemical data\noften necessitates costly domain-specific fine-tuning, posing critical\nchallenges. First, it hinders the application of more flexible general-purpose\nLLMs in cutting-edge drug discovery tasks. More importantly, it impedes the\nrapid integration of the vast amounts of scientific data continuously generated\nthrough experiments and research. To investigate these challenges, we propose\nCLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored\nto drug discovery tasks. Through the collaboration of multiple LLM agents,\nCLADD dynamically retrieves information from biomedical knowledge bases,\ncontextualizes query molecules, and integrates relevant evidence to generate\nresponses -- all without the need for domain-specific fine-tuning. Crucially,\nwe tackle key obstacles in applying RAG workflows to biochemical data,\nincluding data heterogeneity, ambiguity, and multi-source integration. We\ndemonstrate the flexibility and effectiveness of this framework across a\nvariety of drug discovery tasks, showing that it outperforms general-purpose\nand domain-specific LLMs as well as traditional deep learning approaches.\n","authors":["Namkyeong Lee","Edward De Brouwer","Ehsan Hajiramezanali","Tommaso Biancalani","Chanyoung Park","Gabriele Scalia"],"pdf_url":"https://arxiv.org/pdf/2502.17506v2.pdf","comment":"Machine Learning, Drug Discovery"},{"id":"http://arxiv.org/abs/2503.07216v1","updated":"2025-03-10T11:55:50Z","published":"2025-03-10T11:55:50Z","title":"FedRand: Enhancing Privacy in Federated Learning with Randomized LoRA\n  Subparameter Updates","summary":"  Federated Learning (FL) is a widely used framework for training models in a\ndecentralized manner, ensuring that the central server does not have direct\naccess to data from local clients. However, this approach may still fail to\nfully preserve data privacy, as models from local clients are exposed to the\ncentral server during the aggregation process. This issue becomes even more\ncritical when training vision-language models (VLMs) with FL, as VLMs can\neasily memorize training data instances, making them vulnerable to membership\ninference attacks (MIAs). To address this challenge, we propose the FedRand\nframework, which avoids disclosing the full set of client parameters. In this\nframework, each client randomly selects subparameters of Low-Rank Adaptation\n(LoRA) from the server and keeps the remaining counterparts of the LoRA weights\nas private parameters. After training both parameters on the client's private\ndataset, only the non-private client parameters are sent back to the server for\naggregation. This approach mitigates the risk of exposing client-side VLM\nparameters, thereby enhancing data privacy. We empirically validate that\nFedRand improves robustness against MIAs compared to relevant baselines while\nachieving accuracy comparable to methods that communicate full LoRA parameters\nacross several benchmark datasets.\n","authors":["Sangwoo Park","Seanie Lee","Byungjoo Kim","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.07216v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.12581v3","updated":"2025-03-10T11:53:28Z","published":"2025-02-18T06:37:33Z","title":"The Majority Vote Paradigm Shift: When Popular Meets Optimal","summary":"  Reliably labelling data typically requires annotations from multiple human\nworkers. However, humans are far from being perfect. Hence, it is a common\npractice to aggregate labels gathered from multiple annotators to make a more\nconfident estimate of the true label. Among many aggregation methods, the\nsimple and well known Majority Vote (MV) selects the class label polling the\nhighest number of votes. However, despite its importance, the optimality of\nMV's label aggregation has not been extensively studied. We address this gap in\nour work by characterising the conditions under which MV achieves the\ntheoretically optimal lower bound on label estimation error. Our results\ncapture the tolerable limits on annotation noise under which MV can optimally\nrecover labels for a given class distribution. This certificate of optimality\nprovides a more principled approach to model selection for label aggregation as\nan alternative to otherwise inefficient practices that sometimes include higher\nexperts, gold labels, etc., that are all marred by the same human uncertainty\ndespite huge time and monetary costs. Experiments on both synthetic and real\nworld data corroborate our theoretical findings.\n","authors":["Antonio Purificato","Maria Sofia Bucarelli","Anil Kumar Nelakanti","Andrea Bacciu","Fabrizio Silvestri","Amin Mantrach"],"pdf_url":"https://arxiv.org/pdf/2502.12581v3.pdf","comment":"33 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.07209v1","updated":"2025-03-10T11:48:26Z","published":"2025-03-10T11:48:26Z","title":"Synthetic Lung X-ray Generation through Cross-Attention and Affinity\n  Transformation","summary":"  Collecting and annotating medical images is a time-consuming and\nresource-intensive task. However, generating synthetic data through models such\nas Diffusion offers a cost-effective alternative. This paper introduces a new\nmethod for the automatic generation of accurate semantic masks from synthetic\nlung X-ray images based on a stable diffusion model trained on text-image\npairs. This method uses cross-attention mapping between text and image to\nextend text-driven image synthesis to semantic mask generation. It employs\ntext-guided cross-attention information to identify specific areas in an image\nand combines this with innovative techniques to produce high-resolution,\nclass-differentiated pixel masks. This approach significantly reduces the costs\nassociated with data collection and annotation. The experimental results\ndemonstrate that segmentation models trained on synthetic data generated using\nthe method are comparable to, and in some cases even better than, models\ntrained on real datasets. This shows the effectiveness of the method and its\npotential to revolutionize medical image analysis.\n","authors":["Ruochen Pi","Lianlei Shan"],"pdf_url":"https://arxiv.org/pdf/2503.07209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01423v3","updated":"2025-03-10T11:43:42Z","published":"2025-01-02T18:59:40Z","title":"Reconstruction vs. Generation: Taming Optimization Dilemma in Latent\n  Diffusion Models","summary":"  Latent diffusion models with Transformer architectures excel at generating\nhigh-fidelity images. However, recent studies reveal an optimization dilemma in\nthis two-stage design: while increasing the per-token feature dimension in\nvisual tokenizers improves reconstruction quality, it requires substantially\nlarger diffusion models and more training iterations to achieve comparable\ngeneration performance. Consequently, existing systems often settle for\nsub-optimal solutions, either producing visual artifacts due to information\nloss within tokenizers or failing to converge fully due to expensive\ncomputation costs. We argue that this dilemma stems from the inherent\ndifficulty in learning unconstrained high-dimensional latent spaces. To address\nthis, we propose aligning the latent space with pre-trained vision foundation\nmodels when training the visual tokenizers. Our proposed VA-VAE (Vision\nfoundation model Aligned Variational AutoEncoder) significantly expands the\nreconstruction-generation frontier of latent diffusion models, enabling faster\nconvergence of Diffusion Transformers (DiT) in high-dimensional latent spaces.\nTo exploit the full potential of VA-VAE, we build an enhanced DiT baseline with\nimproved training strategies and architecture designs, termed LightningDiT. The\nintegrated system achieves state-of-the-art (SOTA) performance on ImageNet\n256x256 generation with an FID score of 1.35 while demonstrating remarkable\ntraining efficiency by reaching an FID score of 2.11 in just 64\nepochs--representing an over 21 times convergence speedup compared to the\noriginal DiT. Models and codes are available at:\nhttps://github.com/hustvl/LightningDiT.\n","authors":["Jingfeng Yao","Bin Yang","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2501.01423v3.pdf","comment":"Models and codes are available at:\n  https://github.com/hustvl/LightningDiT"},{"id":"http://arxiv.org/abs/2410.16032v3","updated":"2025-03-10T11:37:38Z","published":"2024-10-21T14:06:53Z","title":"TimeMixer++: A General Time Series Pattern Machine for Universal\n  Predictive Analysis","summary":"  Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.\n","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2410.16032v3.pdf","comment":"Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2503.07199v1","updated":"2025-03-10T11:32:30Z","published":"2025-03-10T11:32:30Z","title":"How Well Can Differential Privacy Be Audited in One Run?","summary":"  Recent methods for auditing the privacy of machine learning algorithms have\nimproved computational efficiency by simultaneously intervening on multiple\ntraining examples in a single training run. Steinke et al. (2024) prove that\none-run auditing indeed lower bounds the true privacy parameter of the audited\nalgorithm, and give impressive empirical results. Their work leaves open the\nquestion of how precisely one-run auditing can uncover the true privacy\nparameter of an algorithm, and how that precision depends on the audited\nalgorithm. In this work, we characterize the maximum achievable efficacy of\none-run auditing and show that one-run auditing can only perfectly uncover the\ntrue privacy parameters of algorithms whose structure allows the effects of\nindividual data elements to be isolated. Our characterization helps reveal how\nand when one-run auditing is still a promising technique for auditing real\nmachine learning algorithms, despite these fundamental gaps.\n","authors":["Amit Keinan","Moshe Shenfeld","Katrina Ligett"],"pdf_url":"https://arxiv.org/pdf/2503.07199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07197v1","updated":"2025-03-10T11:27:12Z","published":"2025-03-10T11:27:12Z","title":"Effective and Efficient Masked Image Generation Models","summary":"  Although masked image generation models and masked diffusion models are\ndesigned with different motivations and objectives, we observe that they can be\nunified within a single framework. Building upon this insight, we carefully\nexplore the design space of training and sampling, identifying key factors that\ncontribute to both performance and efficiency. Based on the improvements\nobserved during this exploration, we develop our model, referred to as eMIGM.\nEmpirically, eMIGM demonstrates strong performance on ImageNet generation, as\nmeasured by Fr\\'echet Inception Distance (FID). In particular, on ImageNet\n256x256, with similar number of function evaluations (NFEs) and model\nparameters, eMIGM outperforms the seminal VAR. Moreover, as NFE and model\nparameters increase, eMIGM achieves performance comparable to the\nstate-of-the-art continuous diffusion models while requiring less than 40% of\nthe NFE. Additionally, on ImageNet 512x512, with only about 60% of the NFE,\neMIGM outperforms the state-of-the-art continuous diffusion models.\n","authors":["Zebin You","Jingyang Ou","Xiaolu Zhang","Jun Hu","Jun Zhou","Chongxuan Li"],"pdf_url":"https://arxiv.org/pdf/2503.07197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13810v2","updated":"2025-03-10T11:27:07Z","published":"2024-12-18T12:57:56Z","title":"CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers","summary":"  We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design.\nOur approach is based on a powerful Vision and Large Language Model (VLLM) as a\nplanner and a tool-augmentation paradigm using CAD-specific tools.\nCAD-Assistant addresses multimodal user queries by generating actions that are\niteratively executed on a Python interpreter equipped with the FreeCAD\nsoftware, accessed via its Python API. Our framework is able to assess the\nimpact of generated CAD commands on geometry and adapts subsequent actions\nbased on the evolving state of the CAD design. We consider a wide range of\nCAD-specific tools including a sketch image parameterizer, rendering modules, a\n2D cross-section generator, and other specialized routines. CAD-Assistant is\nevaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and\nsupervised task-specific methods. Beyond existing benchmarks, we qualitatively\ndemonstrate the potential of tool-augmented VLLMs as general-purpose CAD\nsolvers across diverse workflows.\n","authors":["Dimitrios Mallis","Ahmet Serdar Karadeniz","Sebastian Cavada","Danila Rukhovich","Niki Foteinopoulou","Kseniya Cherenkova","Anis Kacem","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2412.13810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11843v4","updated":"2025-03-10T10:50:44Z","published":"2024-09-23T08:39:16Z","title":"From Commands to Prompts: LLM-based Semantic File System for AIOS","summary":"  Large language models (LLMs) have demonstrated significant potential in the\ndevelopment of intelligent applications and systems such as LLM-based agents\nand agent operating systems (AIOS). However, when these applications and\nsystems interact with the underlying file system, the file system still remains\nthe traditional paradigm: reliant on manual navigation through precise\ncommands. This paradigm poses a bottleneck to the usability of these systems as\nusers are required to navigate complex folder hierarchies and remember cryptic\nfile names. To address this limitation, we propose an LLM-based semantic file\nsystem ( LSFS ) for prompt-driven file management. Unlike conventional\napproaches, LSFS incorporates LLMs to enable users or agents to interact with\nfiles through natural language prompts, facilitating semantic file management.\nAt the macro-level, we develop a comprehensive API set to achieve semantic file\nmanagement functionalities, such as semantic file retrieval, file update\nmonitoring and summarization, and semantic file rollback). At the micro-level,\nwe store files by constructing semantic indexes for them, design and implement\nsyscalls of different semantic operations (e.g., CRUD, group by, join) powered\nby vector database. Our experiments show that LSFS offers significant\nimprovements over traditional file systems in terms of user convenience, the\ndiversity of supported functions, and the accuracy and efficiency of file\noperations. Additionally, with the integration of LLM, our system enables more\nintelligent file management tasks, such as content summarization and version\ncomparison, further enhancing its capabilities.\n","authors":["Zeru Shi","Kai Mei","Mingyu Jin","Yongye Su","Chaoji Zuo","Wenyue Hua","Wujiang Xu","Yujie Ren","Zirui Liu","Mengnan Du","Dong Deng","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.11843v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19319v2","updated":"2025-03-10T10:38:11Z","published":"2024-10-25T06:11:43Z","title":"Fully First-Order Methods for Decentralized Bilevel Optimization","summary":"  This paper focuses on decentralized stochastic bilevel optimization (DSBO)\nwhere agents only communicate with their neighbors. We propose Decentralized\nStochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a\nnovel algorithm that only requires first-order oracles that are much cheaper\nthan second-order oracles widely adopted in existing works. We further provide\na finite-time convergence analysis showing that for $n$ agents collaboratively\nsolving the DSBO problem, the sample complexity of finding an\n$\\epsilon$-stationary point in our algorithm is\n$\\mathcal{O}(n^{-1}\\epsilon^{-7})$, which matches the currently best-known\nresults of the single-agent counterpart with linear speedup. The numerical\nexperiments demonstrate both the communication and training efficiency of our\nalgorithm.\n","authors":["Xiaoyu Wang","Xuxing Chen","Shiqian Ma","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.19319v2.pdf","comment":"47 pages"},{"id":"http://arxiv.org/abs/2503.07154v1","updated":"2025-03-10T10:27:30Z","published":"2025-03-10T10:27:30Z","title":"Ideas in Inference-time Scaling can Benefit Generative Pre-training\n  Algorithms","summary":"  Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.\n","authors":["Jiaming Song","Linqi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07153v1","updated":"2025-03-10T10:27:21Z","published":"2025-03-10T10:27:21Z","title":"PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning","summary":"  Class-incremental learning (CIL) for time series data faces critical\nchallenges in balancing stability against catastrophic forgetting and\nplasticity for new knowledge acquisition, particularly under real-world\nconstraints where historical data access is restricted. While pre-trained\nmodels (PTMs) have shown promise in CIL for vision and NLP domains, their\npotential in time series class-incremental learning (TSCIL) remains\nunderexplored due to the scarcity of large-scale time series pre-trained\nmodels. Prompted by the recent emergence of large-scale pre-trained models\n(PTMs) for time series data, we present the first exploration of PTM-based Time\nSeries Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM\nbackbones coupled with incrementally tuning the shared adapter, preserving\ngeneralization capabilities while mitigating feature drift through knowledge\ndistillation. Furthermore, we introduce a Feature Drift Compensation Network\n(DCN), designed with a novel two-stage training strategy to precisely model\nfeature space transformations across incremental tasks. This allows for\naccurate projection of old class prototypes into the new feature space. By\nemploying DCN-corrected prototypes, we effectively enhance the unified\nclassifier retraining, mitigating model feature drift and alleviating\ncatastrophic forgetting. Extensive experiments on five real-world datasets\ndemonstrate state-of-the-art performance, with our method yielding final\naccuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based\napproaches. Our work establishes a new paradigm for TSCIL, providing insights\ninto stability-plasticity optimization for continual learning systems.\n","authors":["Yuanlong Wu","Mingxing Nie","Tao Zhu","Liming Chen","Huansheng Ning","Yaping Wan"],"pdf_url":"https://arxiv.org/pdf/2503.07153v1.pdf","comment":"13 pages,6 figures"},{"id":"http://arxiv.org/abs/2503.07148v1","updated":"2025-03-10T10:22:13Z","published":"2025-03-10T10:22:13Z","title":"Hierarchical Neuro-Symbolic Decision Transformer","summary":"  We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.\n","authors":["Ali Baheri","Cecilia O. Alm"],"pdf_url":"https://arxiv.org/pdf/2503.07148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15721v2","updated":"2025-03-10T10:11:26Z","published":"2024-10-21T07:39:44Z","title":"Learning signals defined on graphs with optimal transport and Gaussian\n  process regression","summary":"  In computational physics, machine learning has now emerged as a powerful\ncomplementary tool to explore efficiently candidate designs in engineering\nstudies. Outputs in such supervised problems are signals defined on meshes, and\na natural question is the extension of general scalar output regression models\nto such complex outputs. Changes between input geometries in terms of both size\nand adjacency structure in particular make this transition non-trivial. In this\nwork, we propose an innovative strategy for Gaussian process regression where\ninputs are large and sparse graphs with continuous node attributes and outputs\nare signals defined on the nodes of the associated inputs. The methodology\nrelies on the combination of regularized optimal transport, dimension reduction\ntechniques, and the use of Gaussian processes indexed by graphs. In addition to\nenabling signal prediction, the main point of our proposal is to come with\nconfidence intervals on node values, which is crucial for uncertainty\nquantification and active learning. Numerical experiments highlight the\nefficiency of the method to solve real problems in fluid dynamics and solid\nmechanics.\n","authors":["Raphaël Carpintero Perez","Sébastien da Veiga","Josselin Garnier","Brian Staber"],"pdf_url":"https://arxiv.org/pdf/2410.15721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07137v1","updated":"2025-03-10T10:08:55Z","published":"2025-03-10T10:08:55Z","title":"A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and\n  Applications","summary":"  Artificial intelligence (AI) has achieved astonishing successes in many\ndomains, especially with the recent breakthroughs in the development of\nfoundational large models. These large models, leveraging their extensive\ntraining data, provide versatile solutions for a wide range of downstream\ntasks. However, as modern datasets become increasingly diverse and complex, the\ndevelopment of large AI models faces two major challenges: (1) the enormous\nconsumption of computational resources and deployment difficulties, and (2) the\ndifficulty in fitting heterogeneous and complex data, which limits the\nusability of the models. Mixture of Experts (MoE) models has recently attracted\nmuch attention in addressing these challenges, by dynamically selecting and\nactivating the most relevant sub-models to process input data. It has been\nshown that MoEs can significantly improve model performance and efficiency with\nfewer resources, particularly excelling in handling large-scale, multimodal\ndata. Given the tremendous potential MoE has demonstrated across various\ndomains, it is urgent to provide a comprehensive summary of recent advancements\nof MoEs in many important fields. Existing surveys on MoE have their\nlimitations, e.g., being outdated or lacking discussion on certain key areas,\nand we aim to address these gaps. In this paper, we first introduce the basic\ndesign of MoE, including gating functions, expert networks, routing mechanisms,\ntraining strategies, and system design. We then explore the algorithm design of\nMoE in important machine learning paradigms such as continual learning,\nmeta-learning, multi-task learning, and reinforcement learning. Additionally,\nwe summarize theoretical studies aimed at understanding MoE and review its\napplications in computer vision and natural language processing. Finally, we\ndiscuss promising future research directions.\n","authors":["Siyuan Mu","Sen Lin"],"pdf_url":"https://arxiv.org/pdf/2503.07137v1.pdf","comment":"28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2501.07155v2","updated":"2025-03-10T09:59:57Z","published":"2025-01-13T09:28:47Z","title":"AlphaNet: Scaling Up Local Frame-based Atomistic Interatomic Potential","summary":"  We present AlphaNet, a local frame-based equivariant model designed to\nachieve both accurate and efficient simulations for atomistic systems.\nRecently, machine learning force fields (MLFFs) have gained prominence in\nmolecular dynamics simulations due to their advantageous efficiency-accuracy\nbalance compared to classical force fields and quantum mechanical calculations,\nalongside their transferability across various systems. Despite the\nadvancements in improving model accuracy, the efficiency and scalability of\nMLFFs remain significant obstacles in practical applications. AlphaNet enhances\ncomputational efficiency and accuracy by leveraging the local geometric\nstructures of atomic environments through the construction of equivariant local\nframes and learnable frame transitions. We substantiate the efficacy of\nAlphaNet across diverse datasets, including defected graphene, formate\ndecomposition, zeolites, and surface reactions. AlphaNet consistently surpasses\nwell-established models, such as NequIP and DeepPot, in terms of both energy\nand force prediction accuracy. Notably, AlphaNet offers one of the best\ntrade-offs between computational efficiency and accuracy among existing models.\nMoreover, AlphaNet exhibits scalability across a broad spectrum of system and\ndataset sizes, affirming its versatility.\n","authors":["Bangchen Yin","Jiaao Wang","Weitao Du","Pengbo Wang","Penghua Ying","Haojun Jia","Zisheng Zhang","Yuanqi Du","Carla P. Gomes","Graeme Henkelman","Chenru Duan","Hai Xiao"],"pdf_url":"https://arxiv.org/pdf/2501.07155v2.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.07127v1","updated":"2025-03-10T09:56:08Z","published":"2025-03-10T09:56:08Z","title":"Performance-driven Constrained Optimal Auto-Tuner for MPC","summary":"  A key challenge in tuning Model Predictive Control (MPC) cost function\nparameters is to ensure that the system performance stays consistently above a\ncertain threshold. To address this challenge, we propose a novel method,\nCOAT-MPC, Constrained Optimal Auto-Tuner for MPC. With every tuning iteration,\nCOAT-MPC gathers performance data and learns by updating its posterior belief.\nIt explores the tuning parameters' domain towards optimistic parameters in a\ngoal-directed fashion, which is key to its sample efficiency. We theoretically\nanalyze COAT-MPC, showing that it satisfies performance constraints with\narbitrarily high probability at all times and provably converges to the optimum\nperformance within finite time. Through comprehensive simulations and\ncomparative analyses with a hardware platform, we demonstrate the effectiveness\nof COAT-MPC in comparison to classical Bayesian Optimization (BO) and other\nstate-of-the-art methods. When applied to autonomous racing, our approach\noutperforms baselines in terms of constraint violations and cumulative regret\nover time.\n","authors":["Albert Gassol Puigjaner","Manish Prajapat","Andrea Carron","Andreas Krause","Melanie N. Zeilinger"],"pdf_url":"https://arxiv.org/pdf/2503.07127v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2405.17823v4","updated":"2025-03-10T09:51:10Z","published":"2024-05-28T04:47:12Z","title":"Spectral Truncation Kernels: Noncommutativity in $C^*$-algebraic Kernel\n  Machines","summary":"  $C^*$-algebra-valued kernels could pave the way for the next generation of\nkernel machines. To further our fundamental understanding of learning with\n$C^*$-algebraic kernels, we propose a new class of positive definite kernels\nbased on the spectral truncation. We focus on kernels whose inputs and outputs\nare vectors or functions and generalize typical kernels by introducing the\nnoncommutativity of the products appearing in the kernels. The noncommutativity\ninduces interactions along the data function domain. We show that the proposed\nkernels fill the gap between existing separable and commutative kernels. We\nalso propose a deep learning perspective to obtain a more flexible framework.\nThe flexibility of the proposed class of kernels allows us to go beyond\nprevious separable and commutative kernels, addressing two of the foremost\nissues regarding learning in vector-valued RKHSs, namely the choice of the\nkernel and the computational cost.\n","authors":["Yuka Hashimoto","Ayoub Hafid","Masahiro Ikeda","Hachem Kadri"],"pdf_url":"https://arxiv.org/pdf/2405.17823v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03135v2","updated":"2025-03-10T09:51:05Z","published":"2025-03-05T03:15:38Z","title":"Bridging Molecular Graphs and Large Language Models","summary":"  While Large Language Models (LLMs) have shown exceptional generalization\ncapabilities, their ability to process graph data, such as molecular\nstructures, remains limited. To bridge this gap, this paper proposes\nGraph2Token, an efficient solution that aligns graph tokens to LLM tokens. The\nkey idea is to represent a graph token with the LLM token vocabulary, without\nfine-tuning the LLM backbone. To achieve this goal, we first construct a\nmolecule-text paired dataset from multisources, including CHEBI and HMDB, to\ntrain a graph structure encoder, which reduces the distance between graphs and\ntexts representations in the feature space. Then, we propose a novel alignment\nstrategy that associates a graph token with LLM tokens. To further unleash the\npotential of LLMs, we collect molecular IUPAC name identifiers, which are\nincorporated into the LLM prompts. By aligning molecular graphs as special\ntokens, we can activate LLM generalization ability to molecular few-shot\nlearning. Extensive experiments on molecular classification and regression\ntasks demonstrate the effectiveness of our proposed Graph2Token.\n","authors":["Runze Wang","Mingqi Yang","Yanming Shen"],"pdf_url":"https://arxiv.org/pdf/2503.03135v2.pdf","comment":"AAAI 2025 camera ready version"},{"id":"http://arxiv.org/abs/2503.07120v1","updated":"2025-03-10T09:49:18Z","published":"2025-03-10T09:49:18Z","title":"Exposure Bias Reduction for Enhancing Diffusion Transformer Feature\n  Caching","summary":"  Diffusion Transformer (DiT) has exhibited impressive generation capabilities\nbut faces great challenges due to its high computational complexity. To address\nthis problem, various methods, notably feature caching, have been introduced.\nHowever, these approaches focus on aligning non-cache diffusion without\nanalyzing the impact of caching on the generation of intermediate processes. So\nthe lack of exploration provides us with room for analysis and improvement. In\nthis paper, we analyze the impact of caching on the SNR of the diffusion\nprocess and discern that feature caching intensifies the denoising procedure,\nand we further identify this as a more severe exposure bias issue. Drawing on\nthis insight, we introduce EB-Cache, a joint cache strategy that aligns the\nNon-exposure bias (which gives us a higher performance ceiling) diffusion\nprocess. Our approach incorporates a comprehensive understanding of caching\nmechanisms and offers a novel perspective on leveraging caches to expedite\ndiffusion processes. Empirical results indicate that EB-Cache optimizes model\nperformance while concurrently facilitating acceleration. Specifically, in the\n50-step generation process, EB-Cache achieves 1.49$\\times$ acceleration with\n0.63 FID reduction from 3.69, surpassing prior acceleration methods. Code will\nbe available at\n\\href{https://github.com/aSleepyTree/EB-Cache}{https://github.com/aSleepyTree/EB-Cache}.\n","authors":["Zhen Zou","Hu Yu","Jie Xiao","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.07120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07119v1","updated":"2025-03-10T09:48:52Z","published":"2025-03-10T09:48:52Z","title":"Improving Deep Ensembles by Estimating Confusion Matrices","summary":"  Ensembling in deep learning improves accuracy and calibration over single\nnetworks. The traditional aggregation approach, ensemble averaging, treats all\nindividual networks equally by averaging their outputs. Inspired by\ncrowdsourcing we propose an aggregation method called soft Dawid Skene for deep\nensembles that estimates confusion matrices of ensemble members and weighs them\naccording to their inferred performance. Soft Dawid Skene aggregates soft\nlabels in contrast to hard labels often used in crowdsourcing. We empirically\nshow the superiority of soft Dawid Skene in accuracy, calibration and out of\ndistribution detection in comparison to ensemble averaging in extensive\nexperiments.\n","authors":["Danil Kuzin","Olga Isupova","Steven Reece","Brooke D Simmons"],"pdf_url":"https://arxiv.org/pdf/2503.07119v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07114v1","updated":"2025-03-10T09:38:35Z","published":"2025-03-10T09:38:35Z","title":"Sequential Function-Space Variational Inference via Gaussian Mixture\n  Approximation","summary":"  Continual learning is learning from a sequence of tasks with the aim of\nlearning new tasks without forgetting old tasks. Sequential function-space\nvariational inference (SFSVI) is a continual learning method based on\nvariational inference which uses a Gaussian variational distribution to\napproximate the distribution of the outputs of a finite number of selected\ninducing points. Since the posterior distribution of a neural network is\nmulti-modal, a Gaussian distribution could only match one mode of the posterior\ndistribution, and a Gaussian mixture distribution could be used to better\napproximate the posterior distribution. We propose an SFSVI method which uses a\nGaussian mixture variational distribution. We also compare different types of\nvariational inference methods with and without a fixed pre-trained feature\nextractor. We find that in terms of final average accuracy, Gaussian mixture\nmethods perform better than Gaussian methods and likelihood-focused methods\nperform better than prior-focused methods.\n","authors":["Menghao Waiyan William Zhu","Pengcheng Hao","Ercan Engin Kuruoğlu"],"pdf_url":"https://arxiv.org/pdf/2503.07114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07110v1","updated":"2025-03-10T09:33:59Z","published":"2025-03-10T09:33:59Z","title":"A LSTM-Transformer Model for pulsation control of pVADs","summary":"  Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model).\nAP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model.\n(1)The NPQ Model determines the mathematical relationship between motor speed,\npressure, and flow rate for the pVAD. (2)The Attention module of Transformer\nneural network is integrated into the LSTM neural network to form the new\nLSTM-Transformer Model to predict the pulsation time characteristic points for\nadjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated\nin three hydraulic experiments and an animal experiment. (1)The pressure\nprovided by pVAD calculated with the NPQ Model has a maximum error of only 2.15\nmmHg compared to the expected values. (2)The pulsation time characteristic\npoints predicted by the LSTM-Transformer Model shows a maximum prediction error\nof 1.78ms, which is significantly lower than other methods. (3)The in-vivo test\nof pVAD in animal experiment has significant improvements in aortic pressure.\nAnimals survive for over 27 hours after the initiation of pVAD operation.\nConclusion: (1)For a given pVAD, motor speed has a linear relationship with\npressure and a quadratic relationship with flow. (2)Deep learning can be used\nto predict pulsation characteristic time points, with the LSTM-Transformer\nModel demonstrating minimal prediction error and better robust performance\nunder conditions of limited dataset sizes, elevated noise levels, and diverse\nhyperparameter combinations, demonstrating its feasibility and effectiveness.\n","authors":["Chaoran E","Chenghan Chen","Yuyang Shi","Haiyun Wang","Peixin Hua","Xiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17477v2","updated":"2025-03-10T09:32:00Z","published":"2024-01-30T22:22:55Z","title":"Detecting mental disorder on social media: a ChatGPT-augmented\n  explainable approach","summary":"  In the digital era, the prevalence of depressive symptoms expressed on social\nmedia has raised serious concerns, necessitating advanced methodologies for\ntimely detection. This paper addresses the challenge of interpretable\ndepression detection by proposing a novel methodology that effectively combines\nLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and\nconversational agents like ChatGPT. In our methodology, explanations are\nachieved by integrating BERTweet, a Twitter-specific variant of BERT, into a\nnovel self-explanatory model, namely BERT-XDD, capable of providing both\nclassification and explanations via masked attention. The interpretability is\nfurther enhanced using ChatGPT to transform technical explanations into\nhuman-readable commentaries. By introducing an effective and modular approach\nfor interpretable depression detection, our methodology can contribute to the\ndevelopment of socially responsible digital platforms, fostering early\nintervention and support for mental health challenges under the guidance of\nqualified healthcare professionals.\n","authors":["Loris Belcastro","Riccardo Cantini","Fabrizio Marozzo","Domenico Talia","Paolo Trunfio"],"pdf_url":"https://arxiv.org/pdf/2401.17477v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07107v1","updated":"2025-03-10T09:31:32Z","published":"2025-03-10T09:31:32Z","title":"Towards Experience Replay for Class-Incremental Learning in Fully-Binary\n  Networks","summary":"  Binary Neural Networks (BNNs) are a promising approach to enable Artificial\nNeural Network (ANN) implementation on ultra-low power edge devices. Such\ndevices may compute data in highly dynamic environments, in which the classes\ntargeted for inference can evolve or even novel classes may arise, requiring\ncontinual learning. Class Incremental Learning (CIL) is a common type of\ncontinual learning for classification problems, that has been scarcely\naddressed in the context of BNNs. Furthermore, most of existing BNNs models are\nnot fully binary, as they require several real-valued network layers, at the\ninput, the output, and for batch normalization. This paper goes a step further,\nenabling class incremental learning in Fully-Binarized NNs (FBNNs) through four\nmain contributions. We firstly revisit the FBNN design and its training\nprocedure that is suitable to CIL. Secondly, we explore loss balancing, a\nmethod to trade-off the performance of past and current classes. Thirdly, we\npropose a semi-supervised method to pre-train the feature extractor of the FBNN\nfor transferable representations. Fourthly, two conventional CIL methods, \\ie,\nLatent and Native replay, are thoroughly compared. These contributions are\nexemplified first on the CIFAR100 dataset, before being scaled up to address\nthe CORE50 continual learning benchmark. The final results based on our 3Mb\nFBNN on CORE50 exhibit at par and better performance than conventional\nreal-valued larger NN models.\n","authors":["Yanis Basso-Bert","Anca Molnos","Romain Lemaire","William Guicquero","Antoine Dupret"],"pdf_url":"https://arxiv.org/pdf/2503.07107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01383v2","updated":"2025-03-10T09:29:33Z","published":"2024-12-02T11:12:01Z","title":"Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to\n  Improve Face Recognition with Synthetic Data","summary":"  Synthetic data is gaining increasing popularity for face recognition\ntechnologies, mainly due to the privacy concerns and challenges associated with\nobtaining real data, including diverse scenarios, quality, and demographic\ngroups, among others. It also offers some advantages over real data, such as\nthe large amount of data that can be generated or the ability to customize it\nto adapt to specific problem-solving needs. To effectively use such data, face\nrecognition models should also be specifically designed to exploit synthetic\ndata to its fullest potential. In order to promote the proposal of novel\nGenerative AI methods and synthetic data, and investigate the application of\nsynthetic data to better train face recognition systems, we introduce the 2nd\nFRCSyn-onGoing challenge, based on the 2nd Face Recognition Challenge in the\nEra of Synthetic Data (FRCSyn), originally launched at CVPR 2024. This is an\nongoing challenge that provides researchers with an accessible platform to\nbenchmark i) the proposal of novel Generative AI methods and synthetic data,\nand ii) novel face recognition systems that are specifically proposed to take\nadvantage of synthetic data. We focus on exploring the use of synthetic data\nboth individually and in combination with real data to solve current challenges\nin face recognition such as demographic bias, domain adaptation, and\nperformance constraints in demanding situations, such as age disparities\nbetween training and testing, changes in the pose, or occlusions. Very\ninteresting findings are obtained in this second edition, including a direct\ncomparison with the first one, in which synthetic databases were restricted to\nDCFace and GANDiffFace.\n","authors":["Ivan DeAndres-Tame","Ruben Tolosana","Pietro Melzi","Ruben Vera-Rodriguez","Minchul Kim","Christian Rathgeb","Xiaoming Liu","Luis F. Gomez","Aythami Morales","Julian Fierrez","Javier Ortega-Garcia","Zhizhou Zhong","Yuge Huang","Yuxi Mi","Shouhong Ding","Shuigeng Zhou","Shuai He","Lingzhi Fu","Heng Cong","Rongyu Zhang","Zhihong Xiao","Evgeny Smirnov","Anton Pimenov","Aleksei Grigorev","Denis Timoshenko","Kaleb Mesfin Asfaw","Cheng Yaw Low","Hao Liu","Chuyi Wang","Qing Zuo","Zhixiang He","Hatef Otroshi Shahreza","Anjith George","Alexander Unnervik","Parsa Rahimi","Sébastien Marcel","Pedro C. Neto","Marco Huber","Jan Niklas Kolf","Naser Damer","Fadi Boutros","Jaime S. Cardoso","Ana F. Sequeira","Andrea Atzori","Gianni Fenu","Mirko Marras","Vitomir Štruc","Jiang Yu","Zhangjie Li","Jichun Li","Weisong Zhao","Zhen Lei","Xiangyu Zhu","Xiao-Yu Zhang","Bernardo Biesseck","Pedro Vidal","Luiz Coelho","Roger Granada","David Menotti"],"pdf_url":"https://arxiv.org/pdf/2412.01383v2.pdf","comment":"Accepted in Information Fusion"},{"id":"http://arxiv.org/abs/2503.07104v1","updated":"2025-03-10T09:27:07Z","published":"2025-03-10T09:27:07Z","title":"Global Context Is All You Need for Parallel Efficient Tractography\n  Parcellation","summary":"  Whole-brain tractography in diffusion MRI is often followed by a parcellation\nin which each streamline is classified as belonging to a specific white matter\nbundle, or discarded as a false positive. Efficient parcellation is important\nboth in large-scale studies, which have to process huge amounts of data, and in\nthe clinic, where computational resources are often limited. TractCloud is a\nstate-of-the-art approach that aims to maximize accuracy with a local-global\nrepresentation. We demonstrate that the local context does not contribute to\nthe accuracy of that approach, and is even detrimental when dealing with\npathological cases. Based on this observation, we propose PETParc, a new method\nfor Parallel Efficient Tractography Parcellation. PETParc is a\ntransformer-based architecture in which the whole-brain tractogram is randomly\npartitioned into sub-tractograms whose streamlines are classified in parallel,\nwhile serving as global context for each other. This leads to a speedup of up\nto two orders of magnitude relative to TractCloud, and permits inference even\non clinical workstations without a GPU. PETParc accounts for the lack of\nstreamline orientation either via a novel flip-invariant embedding, or by\nsimply using flips as part of data augmentation. Despite the speedup, results\nare often even better than those of prior methods. The code and pretrained\nmodel will be made public upon acceptance.\n","authors":["Valentin von Bornhaupt","Johannes Grün","and Justus Bisten","Tobias Bauer","Theodor Rüber","Thomas Schultz"],"pdf_url":"https://arxiv.org/pdf/2503.07104v1.pdf","comment":"8 pages, 2 pages references, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2404.04475v2","updated":"2025-03-10T09:27:03Z","published":"2024-04-06T02:29:02Z","title":"Length-Controlled AlpacaEval: A Simple Way to Debias Automatic\n  Evaluators","summary":"  LLM-based auto-annotators have become a key component of the LLM development\nprocess due to their cost-effectiveness and scalability compared to human-based\nevaluation. However, these auto-annotators can introduce biases that are hard\nto remove. Even simple, known confounders such as preference for longer outputs\nremain in existing automated evaluation metrics. We propose a simple regression\nanalysis approach for controlling biases in auto-evaluations. As a real case\nstudy, we focus on reducing the length bias of AlpacaEval, a fast and\naffordable benchmark for instruction-tuned LLMs that uses LLMs to estimate\nresponse quality. Despite being highly correlated with human preferences,\nAlpacaEval is known to favor models that generate longer outputs. We introduce\na length-controlled AlpacaEval that aims to answer the counterfactual question:\n\"What would the preference be if the model's and baseline's output had the same\nlength?\" To achieve this, we first fit a generalized linear model to predict\nthe biased auto-annotator's preferences based on the mediators we want to\ncontrol for (length difference) and other relevant features. We then obtain\nlength-controlled preferences by predicting preferences while conditioning the\nGLM with a zero difference in lengths. Length-controlling not only improves the\nrobustness of the metric to manipulations in model verbosity, but we also find\nthat it increases the Spearman correlation with LMSYS Chatbot Arena from 0.94\nto 0.98.\n","authors":["Yann Dubois","Balázs Galambosi","Percy Liang","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2404.04475v2.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2405.16498v4","updated":"2025-03-10T09:20:24Z","published":"2024-05-26T09:20:47Z","title":"On Sequential Maximum a Posteriori Inference for Continual Learning","summary":"  We formulate sequential maximum a posteriori inference as a recursion of loss\nfunctions and reduce the problem of continual learning to approximating the\nprevious loss function. We then propose two coreset-free methods: autodiff\nquadratic consolidation, which uses an accurate and full quadratic\napproximation, and neural consolidation, which uses a neural network\napproximation. These methods are not scalable with respect to the neural\nnetwork size, and we study them for classification tasks in combination with a\nfixed pre-trained feature extractor. We also introduce simple but challenging\nclassical task sequences based on Iris and Wine datasets. We find that neural\nconsolidation performs well in the classical task sequences, where the input\ndimension is small, while autodiff quadratic consolidation performs\nconsistently well in image task sequences with a fixed pre-trained feature\nextractor, achieving comparable performance to joint maximum a posteriori\ntraining in many cases.\n","authors":["Menghao Waiyan William Zhu","Ercan Engin Kuruoğlu"],"pdf_url":"https://arxiv.org/pdf/2405.16498v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14297v4","updated":"2025-03-10T09:17:56Z","published":"2024-05-23T08:18:30Z","title":"Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient\n  Transformer Models","summary":"  The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the\nefficiency of training and inference for Transformer-based foundational models,\nyielding promising results.However, the performance of SMoE heavily depends on\nthe choice of hyper-parameters, such as the number of experts and the number of\nexperts to be activated (referred to as top-k), resulting in significant\ncomputational overhead due to the extensive model training by searching over\nvarious hyper-parameter configurations. As a remedy, we introduce the Dynamic\nMixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating\nmethod that enables each token to automatically determine the number of experts\nto activate. (2) An adaptive process automatically adjusts the number of\nexperts during training. Extensive numerical results across Vision, Language,\nand Vision-Language tasks demonstrate the effectiveness of our approach to\nachieve competitive performance compared to GMoE for vision and language tasks,\nand MoE-LLaVA for vision-language tasks, while maintaining efficiency by\nactivating fewer parameters. Our code is available at\nhttps://github.com/LINs-lab/DynMoE.\n","authors":["Yongxin Guo","Zhenglin Cheng","Xiaoying Tang","Zhaopeng Tu","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14297v4.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.19671v4","updated":"2025-03-10T09:16:28Z","published":"2024-11-29T12:56:43Z","title":"On the Performance Analysis of Momentum Method: A Frequency Domain\n  Perspective","summary":"  Momentum-based optimizers are widely adopted for training neural networks.\nHowever, the optimal selection of momentum coefficients remains elusive. This\nuncertainty impedes a clear understanding of the role of momentum in stochastic\ngradient methods. In this paper, we present a frequency domain analysis\nframework that interprets the momentum method as a time-variant filter for\ngradients, where adjustments to momentum coefficients modify the filter\ncharacteristics. Our experiments support this perspective and provide a deeper\nunderstanding of the mechanism involved. Moreover, our analysis reveals the\nfollowing significant findings: high-frequency gradient components are\nundesired in the late stages of training; preserving the original gradient in\nthe early stages, and gradually amplifying low-frequency gradient components\nduring training both enhance performance. Based on these insights, we propose\nFrequency Stochastic Gradient Descent with Momentum (FSGDM), a heuristic\noptimizer that dynamically adjusts the momentum filtering characteristic with\nan empirically effective dynamic magnitude response. Experimental results\ndemonstrate the superiority of FSGDM over conventional momentum optimizers.\n","authors":["Xianliang Li","Jun Luo","Zhiwei Zheng","Hanxiao Wang","Li Luo","Lingkun Wen","Linlong Wu","Sheng Xu"],"pdf_url":"https://arxiv.org/pdf/2411.19671v4.pdf","comment":"ICLR 2025. 22 pages, 14 figures. Keywords: Momentum Method,\n  Stochastic Gradient Descent, Z-Transform, Frequency Domain Analysis, Deep\n  Learning"},{"id":"http://arxiv.org/abs/2401.15199v2","updated":"2025-03-10T09:12:04Z","published":"2024-01-26T20:51:55Z","title":"SCANIA Component X Dataset: A Real-World Multivariate Time Series\n  Dataset for Predictive Maintenance","summary":"  Predicting failures and maintenance time in predictive maintenance is\nchallenging due to the scarcity of comprehensive real-world datasets, and among\nthose available, few are of time series format. This paper introduces a\nreal-world, multivariate time series dataset collected exclusively from a\nsingle anonymized engine component (Component X) across a fleet of SCANIA\ntrucks. The dataset includes operational data, repair records, and\nspecifications related to Component X, while maintaining confidentiality\nthrough anonymization. It is well-suited for a range of machine learning\napplications, including classification, regression, survival analysis, and\nanomaly detection, particularly in predictive maintenance scenarios. The\ndataset's large population size, diverse features (in the form of histograms\nand numerical counters), and temporal information make it a unique resource in\nthe field. The objective of releasing this dataset is to give a broad range of\nresearchers the possibility of working with real-world data from an\ninternationally well-known company and introduce a standard benchmark to the\npredictive maintenance field, fostering reproducible research.\n","authors":["Zahra Kharazian","Tony Lindgren","Sindri Magnússon","Olof Steinert","Oskar Andersson Reyna"],"pdf_url":"https://arxiv.org/pdf/2401.15199v2.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.07084v1","updated":"2025-03-10T09:06:40Z","published":"2025-03-10T09:06:40Z","title":"A Unified View of Optimal Kernel Hypothesis Testing","summary":"  This paper provides a unifying view of optimal kernel hypothesis testing\nacross the MMD two-sample, HSIC independence, and KSD goodness-of-fit\nframeworks. Minimax optimal separation rates in the kernel and $L^2$ metrics\nare presented, with two adaptive kernel selection methods (kernel pooling and\naggregation), and under various testing constraints: computational efficiency,\ndifferential privacy, and robustness to data corruption. Intuition behind the\nderivation of the power results is provided in a unified way accross the three\nframeworks, and open problems are highlighted.\n","authors":["Antonin Schrab"],"pdf_url":"https://arxiv.org/pdf/2503.07084v1.pdf","comment":"46 pages, 1 figure"},{"id":"http://arxiv.org/abs/2503.07082v1","updated":"2025-03-10T09:04:50Z","published":"2025-03-10T09:04:50Z","title":"On the Generalization of Representation Uncertainty in Earth Observation","summary":"  Recent advances in Computer Vision have introduced the concept of pretrained\nrepresentation uncertainty, enabling zero-shot uncertainty estimation. This\nholds significant potential for Earth Observation (EO), where trustworthiness\nis critical, yet the complexity of EO data poses challenges to\nuncertainty-aware methods. In this work, we investigate the generalization of\nrepresentation uncertainty in EO, considering the domain's unique semantic\ncharacteristics. We pretrain uncertainties on large EO datasets and propose an\nevaluation framework to assess their zero-shot performance in multi-label\nclassification and segmentation EO tasks. Our findings reveal that, unlike\nuncertainties pretrained on natural images, EO-pretraining exhibits strong\ngeneralization across unseen EO domains, geographic locations, and target\ngranularities, while maintaining sensitivity to variations in ground sampling\ndistance. We demonstrate the practical utility of pretrained uncertainties\nshowcasing their alignment with task-specific uncertainties in downstream\ntasks, their sensitivity to real-world EO image noise, and their ability to\ngenerate spatial uncertainty estimates out-of-the-box. Initiating the\ndiscussion on representation uncertainty in EO, our study provides insights\ninto its strengths and limitations, paving the way for future research in the\nfield. Code and weights are available at:\nhttps://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.\n","authors":["Spyros Kondylatos","Nikolaos Ioannis Bountos","Dimitrios Michail","Xiao Xiang Zhu","Gustau Camps-Valls","Ioannis Papoutsis"],"pdf_url":"https://arxiv.org/pdf/2503.07082v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2502.13833v2","updated":"2025-03-10T09:01:19Z","published":"2025-02-19T15:52:23Z","title":"Contrastive Learning-Based privacy metrics in Tabular Synthetic Datasets","summary":"  Synthetic data has garnered attention as a Privacy Enhancing Technology (PET)\nin sectors such as healthcare and finance. When using synthetic data in\npractical applications, it is important to provide protection guarantees. In\nthe literature, two family of approaches are proposed for tabular data: on the\none hand, Similarity-based methods aim at finding the level of similarity\nbetween training and synthetic data. Indeed, a privacy breach can occur if the\ngenerated data is consistently too similar or even identical to the train data.\nOn the other hand, Attack-based methods conduce deliberate attacks on synthetic\ndatasets. The success rates of these attacks reveal how secure the synthetic\ndatasets are.\n  In this paper, we introduce a contrastive method that improves privacy\nassessment of synthetic datasets by embedding the data in a more representative\nspace. This overcomes obstacles surrounding the multitude of data types and\nattributes. It also makes the use of intuitive distance metrics possible for\nsimilarity measurements and as an attack vector. In a series of experiments\nwith publicly available datasets, we compare the performances of\nsimilarity-based and attack-based methods, both with and without use of the\ncontrastive learning-based embeddings. Our results show that relatively\nefficient, easy to implement privacy metrics can perform equally well as more\nadvanced metrics explicitly modeling conditions for privacy referred to by the\nGDPR.\n","authors":["Milton Nicolás Plasencia Palacios","Sebastiano Saccani","Gabriele Sgroi","Alexander Boudewijn","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2502.13833v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17030v2","updated":"2025-03-10T09:00:28Z","published":"2025-02-24T10:31:12Z","title":"Your Assumed DAG is Wrong and Here's How To Deal With It","summary":"  Assuming a directed acyclic graph (DAG) that represents prior knowledge of\ncausal relationships between variables is a common starting point for\ncause-effect estimation. Existing literature typically invokes hypothetical\ndomain expert knowledge or causal discovery algorithms to justify this\nassumption. In practice, neither may propose a single DAG with high confidence.\nDomain experts are hesitant to rule out dependencies with certainty or have\nongoing disputes about relationships; causal discovery often relies on\nuntestable assumptions itself or only provides an equivalence class of DAGs and\nis commonly sensitive to hyperparameter and threshold choices. We propose an\nefficient, gradient-based optimization method that provides bounds for causal\nqueries over a collection of causal graphs -- compatible with imperfect prior\nknowledge -- that may still be too large for exhaustive enumeration. Our bounds\nachieve good coverage and sharpness for causal queries such as average\ntreatment effects in linear and non-linear synthetic settings as well as on\nreal-world data. Our approach aims at providing an easy-to-use and widely\napplicable rebuttal to the valid critique of `What if your assumed DAG is\nwrong?'.\n","authors":["Kirtan Padh","Zhufeng Li","Cecilia Casolo","Niki Kilbertus"],"pdf_url":"https://arxiv.org/pdf/2502.17030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07070v1","updated":"2025-03-10T08:53:11Z","published":"2025-03-10T08:53:11Z","title":"PIED: Physics-Informed Experimental Design for Inverse Problems","summary":"  In many science and engineering settings, system dynamics are characterized\nby governing PDEs, and a major challenge is to solve inverse problems (IPs)\nwhere unknown PDE parameters are inferred based on observational data gathered\nunder limited budget. Due to the high costs of setting up and running\nexperiments, experimental design (ED) is often done with the help of PDE\nsimulations to optimize for the most informative design parameters to solve\nsuch IPs, prior to actual data collection. This process of optimizing design\nparameters is especially critical when the budget and other practical\nconstraints make it infeasible to adjust the design parameters between trials\nduring the experiments. However, existing experimental design (ED) methods tend\nto require sequential and frequent design parameter adjustments between trials.\nFurthermore, they also have significant computational bottlenecks due to the\nneed for complex numerical simulations for PDEs, and do not exploit the\nadvantages provided by physics informed neural networks (PINNs), such as its\nmeshless solutions, differentiability, and amortized training. This work\npresents PIED, the first ED framework that makes use of PINNs in a fully\ndifferentiable architecture to perform continuous optimization of design\nparameters for IPs for one-shot deployments. PIED overcomes existing methods'\ncomputational bottlenecks through parallelized computation and meta-learning of\nPINN parameter initialization, and proposes novel methods to effectively take\ninto account PINN training dynamics in optimizing the ED parameters. Through\nexperiments based on noisy simulated data and even real world experimental\ndata, we empirically show that given limited observation budget, PIED\nsignificantly outperforms existing ED methods in solving IPs, including\nchallenging settings where the inverse parameters are unknown functions rather\nthan just finite-dimensional.\n","authors":["Apivich Hemachandra","Gregory Kang Ruey Lau","See-Kiong Ng","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2503.07070v1.pdf","comment":"Accepted to 13th International Conference on Learning Representations\n  (ICLR 2025), 31 pages"},{"id":"http://arxiv.org/abs/2503.07067v1","updated":"2025-03-10T08:51:32Z","published":"2025-03-10T08:51:32Z","title":"DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs","summary":"  Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.\n","authors":["Jongwoo Ko","Tianyi Chen","Sungnyun Kim","Tianyu Ding","Luming Liang","Ilya Zharkov","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2503.07067v1.pdf","comment":"The code will be available soon at\n  https://github.com/jongwooko/distillm-2"},{"id":"http://arxiv.org/abs/2503.07066v1","updated":"2025-03-10T08:50:55Z","published":"2025-03-10T08:50:55Z","title":"You Only Debias Once: Towards Flexible Accuracy-Fairness Trade-offs at\n  Inference Time","summary":"  Deep neural networks are prone to various bias issues, jeopardizing their\napplications for high-stake decision-making. Existing fairness methods\ntypically offer a fixed accuracy-fairness trade-off, since the weight of the\nwell-trained model is a fixed point (fairness-optimum) in the weight space.\nNevertheless, more flexible accuracy-fairness trade-offs at inference time are\npractically desired since: 1) stakes of the same downstream task can vary for\ndifferent individuals, and 2) different regions have diverse laws or\nregularization for fairness. If using the previous fairness methods, we have to\ntrain multiple models, each offering a specific level of accuracy-fairness\ntrade-off. This is often computationally expensive, time-consuming, and\ndifficult to deploy, making it less practical for real-world applications. To\naddress this problem, we propose You Only Debias Once (YODO) to achieve in-situ\nflexible accuracy-fairness trade-offs at inference time, using a single model\nthat trained only once. Instead of pursuing one individual fixed point\n(fairness-optimum) in the weight space, we aim to find a \"line\" in the weight\nspace that connects the accuracy-optimum and fairness-optimum points using a\nsingle model. Points (models) on this line implement varying levels of\naccuracy-fairness trade-offs. At inference time, by manually selecting the\nspecific position of the learned \"line\", our proposed method can achieve\narbitrary accuracy-fairness trade-offs for different end-users and scenarios.\nExperimental results on tabular and image datasets show that YODO achieves\nflexible trade-offs between model accuracy and fairness, at ultra-low\noverheads. For example, if we need $100$ levels of trade-off on the \\acse\ndataset, YODO takes $3.53$ seconds while training $100$ fixed models consumes\n$425$ seconds. The code is available at https://github.com/ahxt/yodo.\n","authors":["Xiaotian Han","Tianlong Chen","Kaixiong Zhou","Zhimeng Jiang","Zhangyang Wang","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2503.07066v1.pdf","comment":"CPAL2025(Oral)"},{"id":"http://arxiv.org/abs/2407.10998v2","updated":"2025-03-10T08:45:53Z","published":"2024-06-25T09:55:22Z","title":"Discrete Diffusion Language Model for Efficient Text Summarization","summary":"  While diffusion models excel at conditional generating high-quality images,\nprior works in discrete diffusion models were not evaluated on conditional\nlong-text generation. In this work, we address the limitations of prior\ndiscrete diffusion models for conditional long-text generation, particularly in\nlong sequence-to-sequence tasks such as abstractive summarization. Despite fast\ndecoding speeds compared to autoregressive methods, previous diffusion models\nfailed on the abstractive summarization task due to the incompatibility between\nthe backbone architectures and the random noising process. To overcome these\nchallenges, we introduce a novel semantic-aware noising process that enables\nTransformer backbones to handle long sequences effectively. Additionally, we\npropose CrossMamba, an adaptation of the Mamba model to the encoder-decoder\nparadigm, which integrates seamlessly with the random absorbing noising\nprocess. Our approaches achieve state-of-the-art performance on three benchmark\nsummarization datasets: Gigaword, CNN/DailyMail, and Arxiv, outperforming\nexisting discrete diffusion models on ROUGE metrics as well as possessing much\nfaster speed in inference compared to autoregressive models.\n","authors":["Do Huu Dat","Do Duc Anh","Anh Tuan Luu","Wray Buntine"],"pdf_url":"https://arxiv.org/pdf/2407.10998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00136v2","updated":"2025-03-10T08:43:03Z","published":"2024-11-28T16:19:37Z","title":"FonTS: Text Rendering with Typography and Style Controls","summary":"  Visual text rendering are widespread in various real-world applications,\nrequiring careful font selection and typographic choices. Recent progress in\ndiffusion transformer (DiT)-based text-to-image (T2I) models show promise in\nautomating these processes. However, these methods still encounter challenges\nlike inconsistent fonts, style variation, and limited fine-grained control,\nparticularly at the word-level. This paper proposes a two-stage DiT-based\npipeline to address these problems by enhancing controllability over typography\nand style in text rendering. We introduce typography control fine-tuning\n(TC-FT), an parameter-efficient fine-tuning method (on $5\\%$ key parameters)\nwith enclosing typography control tokens (ETC-tokens), which enables precise\nword-level application of typographic features. To further address style\ninconsistency in text rendering, we propose a text-agnostic style control\nadapter (SCA) that prevents content leakage while enhancing style consistency.\nTo implement TC-FT and SCA effectively, we incorporated HTML-render into the\ndata synthesis pipeline and proposed the first word-level controllable dataset.\nThrough comprehensive experiments, we demonstrate the effectiveness of our\napproach in achieving superior word-level typographic control, font\nconsistency, and style consistency in text rendering tasks. The datasets and\nmodels will be available for academic use.\n","authors":["Wenda Shi","Yiren Song","Dengming Zhang","Jiaming Liu","Xingxing Zou"],"pdf_url":"https://arxiv.org/pdf/2412.00136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07056v1","updated":"2025-03-10T08:42:26Z","published":"2025-03-10T08:42:26Z","title":"Generative method for aerodynamic optimization based on classifier-free\n  guided denoising diffusion probabilistic model","summary":"  Inverse design approach, which directly generates optimal aerodynamic shape\nwith neural network models to meet designated performance targets, has drawn\nenormous attention. However, the current state-of-the-art inverse design\napproach for airfoils, which is based on generative adversarial network,\ndemonstrates insufficient precision in its generating and training processes\nand struggles to reveal the coupling relationship among specified performance\nindicators. To address these issues, the airfoil inverse design framework based\non the classifier-free guided denoising diffusion probabilistic model (CDDPM)\nis proposed innovatively in this paper. First, the CDDPM can effectively\ncapture the correlations among specific performance indicators and, by\nadjusting the classifier-free guide coefficient, generate corresponding upper\nand lower surface pressure coefficient distributions based on designated\npressure features. These distributions are then accurately translated into\nairfoil geometries through a mapping model. Experimental results using\nclassical transonic airfoils as examples show that the inverse design based on\nCDDPM can generate a variety of pressure coefficient distributions, which\nenriches the diversity of design results. Compared with current\nstate-of-the-art Wasserstein generative adversarial network methods, CDDPM\nachieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a\npractical method to readjust each performance indicator value is proposed based\non global optimization algorithm in conjunction with active learning strategy,\naiming to provide rational value combination of performance indicators for the\ninverse design framework. This work is not only suitable for the airfoils\ndesign, but also has the capability to apply to optimization process of general\nproduct parts targeting selected performance indicators.\n","authors":["Shisong Deng","Qiang Zhang","Zhengyang Cai"],"pdf_url":"https://arxiv.org/pdf/2503.07056v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.07025v1","updated":"2025-03-10T08:06:30Z","published":"2025-03-10T08:06:30Z","title":"Weak Supervision for Improved Precision in Search Systems","summary":"  Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.\n","authors":["Sriram Vasudevan"],"pdf_url":"https://arxiv.org/pdf/2503.07025v1.pdf","comment":"Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace"},{"id":"http://arxiv.org/abs/2310.03546v3","updated":"2025-03-10T08:04:14Z","published":"2023-10-05T13:57:53Z","title":"Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior\n  Models","summary":"  Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.\n","authors":["Marien Renaud","Jiaming Liu","Valentin de Bortoli","Andrés Almansa","Ulugbek S. Kamilov"],"pdf_url":"https://arxiv.org/pdf/2310.03546v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07021v1","updated":"2025-03-10T08:01:49Z","published":"2025-03-10T08:01:49Z","title":"Learning Energy-Based Models by Self-normalising the Likelihood","summary":"  Training an energy-based model (EBM) with maximum likelihood is challenging\ndue to the intractable normalisation constant. Traditional methods rely on\nexpensive Markov chain Monte Carlo (MCMC) sampling to estimate the gradient of\nlogartihm of the normalisation constant. We propose a novel objective called\nself-normalised log-likelihood (SNL) that introduces a single additional\nlearnable parameter representing the normalisation constant compared to the\nregular log-likelihood. SNL is a lower bound of the log-likelihood, and its\noptimum corresponds to both the maximum likelihood estimate of the model\nparameters and the normalisation constant. We show that the SNL objective is\nconcave in the model parameters for exponential family distributions. Unlike\nthe regular log-likelihood, the SNL can be directly optimised using stochastic\ngradient techniques by sampling from a crude proposal distribution. We validate\nthe effectiveness of our proposed method on various density estimation tasks as\nwell as EBMs for regression. Our results show that the proposed method, while\nsimpler to implement and tune, outperforms existing techniques.\n","authors":["Hugo Senetaire","Paul Jeha","Pierre-Alexandre Mattei","Jes Frellsen"],"pdf_url":"https://arxiv.org/pdf/2503.07021v1.pdf","comment":"10pages, 3figures"},{"id":"http://arxiv.org/abs/2503.07020v1","updated":"2025-03-10T08:01:41Z","published":"2025-03-10T08:01:41Z","title":"Combating Partial Perception Deficit in Autonomous Driving with\n  Multimodal LLM Commonsense","summary":"  Partial perception deficits can compromise autonomous vehicle safety by\ndisrupting environmental understanding. Current protocols typically respond\nwith immediate stops or minimal-risk maneuvers, worsening traffic flow and\nlacking flexibility for rare driving scenarios. In this paper, we propose\nLLM-RCO, a framework leveraging large language models to integrate human-like\ndriving commonsense into autonomous systems facing perception deficits. LLM-RCO\nfeatures four key modules: hazard inference, short-term motion planner, action\ncondition verifier, and safety constraint generator. These modules interact\nwith the dynamic driving environment, enabling proactive and context-aware\ncontrol actions to override the original control policy of autonomous agents.\nTo improve safety in such challenging conditions, we construct DriveLM-Deficit,\na dataset of 53,895 video clips featuring deficits of safety-critical objects,\ncomplete with annotations for LLM-based hazard inference and motion planning\nfine-tuning. Extensive experiments in adverse driving conditions with the CARLA\nsimulator demonstrate that systems equipped with LLM-RCO significantly improve\ndriving performance, highlighting its potential for enhancing autonomous\ndriving resilience against adverse perception deficits. Our results also show\nthat LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements\ninstead of conservative stops in the context of perception deficits.\n","authors":["Yuting Hu","Chenhui Xu","Ruiyang Qin","Dancheng Liu","Amir Nassereldine","Yiyu Shi","Jinjun Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.07020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07017v1","updated":"2025-03-10T07:57:26Z","published":"2025-03-10T07:57:26Z","title":"How to Train Your Robots? The Impact of Demonstration Modality on\n  Imitation Learning","summary":"  Imitation learning is a promising approach for learning robot policies with\nuser-provided data. The way demonstrations are provided, i.e., demonstration\nmodality, influences the quality of the data. While existing research shows\nthat kinesthetic teaching (physically guiding the robot) is preferred by users\nfor the intuitiveness and ease of use, the majority of existing manipulation\ndatasets were collected through teleoperation via a VR controller or\nspacemouse. In this work, we investigate how different demonstration modalities\nimpact downstream learning performance as well as user experience.\nSpecifically, we compare low-cost demonstration modalities including\nkinesthetic teaching, teleoperation with a VR controller, and teleoperation\nwith a spacemouse controller. We experiment with three table-top manipulation\ntasks with different motion constraints. We evaluate and compare imitation\nlearning performance using data from different demonstration modalities, and\ncollected subjective feedback on user experience. Our results show that\nkinesthetic teaching is rated the most intuitive for controlling the robot and\nprovides cleanest data for best downstream learning performance. However, it is\nnot preferred as the way for large-scale data collection due to the physical\nload. Based on such insight, we propose a simple data collection scheme that\nrelies on a small number of kinesthetic demonstrations mixed with data\ncollected through teleoperation to achieve the best overall learning\nperformance while maintaining low data-collection effort.\n","authors":["Haozhuo Li","Yuchen Cui","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2503.07017v1.pdf","comment":"8 pages, ICRA"},{"id":"http://arxiv.org/abs/2503.07013v1","updated":"2025-03-10T07:52:30Z","published":"2025-03-10T07:52:30Z","title":"Learning Nash Equilibrial Hamiltonian for Two-Player Collision-Avoiding\n  Interactions","summary":"  We consider the problem of learning Nash equilibrial policies for two-player\nrisk-sensitive collision-avoiding interactions. Solving the\nHamilton-Jacobi-Isaacs equations of such general-sum differential games in real\ntime is an open challenge due to the discontinuity of equilibrium values on the\nstate space. A common solution is to learn a neural network that approximates\nthe equilibrium Hamiltonian for given system states and actions. The learning,\nhowever, is usually supervised and requires a large amount of sample\nequilibrium policies from different initial states in order to mitigate the\nrisks of collisions. This paper claims two contributions towards more\ndata-efficient learning of equilibrium policies: First, instead of computing\nHamiltonian through a value network, we show that the equilibrium co-states\nhave simple structures when collision avoidance dominates the agents' loss\nfunctions and system dynamics is linear, and therefore are more data-efficient\nto learn. Second, we introduce theory-driven active learning to guide data\nsampling, where the acquisition function measures the compliance of the\npredicted co-states to Pontryagin's Maximum Principle. On an uncontrolled\nintersection case, the proposed method leads to more generalizable\napproximation of the equilibrium policies, and in turn, lower collision\nprobabilities, than the state-of-the-art under the same data acquisition\nbudget.\n","authors":["Lei Zhang","Siddharth Das","Tanner Merry","Wenlong Zhang","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2503.07013v1.pdf","comment":"Accepted by 2025 ACC"},{"id":"http://arxiv.org/abs/2503.05577v2","updated":"2025-03-10T07:35:46Z","published":"2025-03-07T16:59:18Z","title":"opXRD: Open Experimental Powder X-ray Diffraction Database","summary":"  Powder X-ray diffraction (pXRD) experiments are a cornerstone for materials\nstructure characterization. Despite their widespread application, analyzing\npXRD diffractograms still presents a significant challenge to automation and a\nbottleneck in high-throughput discovery in self-driving labs. Machine learning\npromises to resolve this bottleneck by enabling automated powder diffraction\nanalysis. A notable difficulty in applying machine learning to this domain is\nthe lack of sufficiently sized experimental datasets, which has constrained\nresearchers to train primarily on simulated data. However, models trained on\nsimulated pXRD patterns showed limited generalization to experimental patterns,\nparticularly for low-quality experimental patterns with high noise levels and\nelevated backgrounds. With the Open Experimental Powder X-Ray Diffraction\nDatabase (opXRD), we provide an openly available and easily accessible dataset\nof labeled and unlabeled experimental powder diffractograms. Labeled opXRD data\ncan be used to evaluate the performance of models on experimental data and\nunlabeled opXRD data can help improve the performance of models on experimental\ndata, e.g. through transfer learning methods. We collected 92552\ndiffractograms, 2179 of them labeled, from a wide spectrum of materials\nclasses. We hope this ongoing effort can guide machine learning research toward\nfully automated analysis of pXRD data and thus enable future self-driving\nmaterials labs.\n","authors":["Daniel Hollarek","Henrik Schopmans","Jona Östreicher","Jonas Teufel","Bin Cao","Adie Alwen","Simon Schweidler","Mriganka Singh","Tim Kodalle","Hanlin Hu","Gregoire Heymans","Maged Abdelsamie","Arthur Hardiagon","Alexander Wieczorek","Siarhei Zhuk","Ruth Schwaiger","Sebastian Siol","François-Xavier Coudert","Moritz Wolf","Carolin M. Sutter-Fella","Ben Breitung","Andrea M. Hodge","Tong-yi Zhang","Pascal Friederich"],"pdf_url":"https://arxiv.org/pdf/2503.05577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17098v2","updated":"2025-03-10T07:33:32Z","published":"2024-06-24T19:36:45Z","title":"Learning Temporal Distances: Contrastive Successor Features Can Provide\n  a Metric Structure for Decision-Making","summary":"  Temporal distances lie at the heart of many algorithms for planning, control,\nand reinforcement learning that involve reaching goals, allowing one to\nestimate the transit time between two states. However, prior attempts to define\nsuch temporal distances in stochastic settings have been stymied by an\nimportant limitation: these prior approaches do not satisfy the triangle\ninequality. This is not merely a definitional concern, but translates to an\ninability to generalize and find shortest paths. In this paper, we build on\nprior work in contrastive learning and quasimetrics to show how successor\nfeatures learned by contrastive learning (after a change of variables) form a\ntemporal distance that does satisfy the triangle inequality, even in stochastic\nsettings. Importantly, this temporal distance is computationally efficient to\nestimate, even in high-dimensional and stochastic settings. Experiments in\ncontrolled settings and benchmark suites demonstrate that an RL algorithm based\non these new temporal distances exhibits combinatorial generalization (i.e.,\n\"stitching\") and can sometimes learn more quickly than prior methods, including\nthose based on quasimetrics.\n","authors":["Vivek Myers","Chongyi Zheng","Anca Dragan","Sergey Levine","Benjamin Eysenbach"],"pdf_url":"https://arxiv.org/pdf/2406.17098v2.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)"},{"id":"http://arxiv.org/abs/2411.08832v2","updated":"2025-03-10T07:30:55Z","published":"2024-11-13T18:12:15Z","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","summary":"  We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.\n","authors":["Reece O'Mahoney","Alexander L. Mitchell","Wanming Yu","Ingmar Posner","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2411.08832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11882v4","updated":"2025-03-10T07:25:31Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v4.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, QwQ-32b, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2503.06997v1","updated":"2025-03-10T07:22:54Z","published":"2025-03-10T07:22:54Z","title":"Water Quality Data Imputation via A Fast Latent Factorization of Tensors\n  with PID-based Optimizer","summary":"  Water quality data can supply a substantial decision support for water\nresources utilization and pollution prevention. However, there are numerous\nmissing values in water quality data due to inescapable factors like sensor\nfailure, thereby leading to biased result for hydrological analysis and failing\nto support environmental governance decision accurately. A Latent Factorization\nof Tensors (LFT) with Stochastic Gradient Descent (SGD) proves to be an\nefficient imputation method. However, a standard SGD-based LFT model commonly\nsurfers from the slow convergence that impairs its efficiency. To tackle this\nissue, this paper proposes a Fast Latent Factorization of Tensors (FLFT) model.\nIt constructs an adjusted instance error into SGD via leveraging a nonlinear\nPID controller to incorporates the past, current and future information of\nprediction error for improving convergence rate. Comparing with state-of-art\nmodels in real world datasets, the results of experiment indicate that the FLFT\nmodel achieves a better convergence rate and higher accuracy.\n","authors":["Qian Liu","Lan Wang","Bing Yang","Hao Wu"],"pdf_url":"https://arxiv.org/pdf/2503.06997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02646v2","updated":"2025-03-10T07:17:55Z","published":"2025-03-03T08:42:55Z","title":"A Tight Regret Analysis of Non-Parametric Repeated Contextual Brokerage","summary":"  We study a contextual version of the repeated brokerage problem. In each\ninteraction, two traders with private valuations for an item seek to buy or\nsell based on the learner's-a broker-proposed price, which is informed by some\ncontextual information. The broker's goal is to maximize the traders' net\nutility-also known as the gain from trade-by minimizing regret compared to an\noracle with perfect knowledge of traders' valuation distributions. We assume\nthat traders' valuations are zero-mean perturbations of the unknown item's\ncurrent market value-which can change arbitrarily from one interaction to the\nnext-and that similar contexts will correspond to similar market prices. We\nanalyze two feedback settings: full-feedback, where after each interaction the\ntraders' valuations are revealed to the broker, and limited-feedback, where\nonly transaction attempts are revealed. For both feedback types, we propose\nalgorithms achieving tight regret bounds. We further strengthen our performance\nguarantees by providing a tight 1/2-approximation result showing that the\noracle that knows the traders' valuation distributions achieves at least 1/2 of\nthe gain from trade of the omniscient oracle that knows in advance the actual\nrealized traders' valuations.\n","authors":["François Bachoc","Tommaso Cesari","Roberto Colomboni"],"pdf_url":"https://arxiv.org/pdf/2503.02646v2.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.06993v1","updated":"2025-03-10T07:17:15Z","published":"2025-03-10T07:17:15Z","title":"CAPT: Class-Aware Prompt Tuning for Federated Long-Tailed Learning with\n  Vision-Language Model","summary":"  Effectively handling the co-occurrence of non-IID data and long-tailed\ndistributions remains a critical challenge in federated learning. While\nfine-tuning vision-language models (VLMs) like CLIP has shown to be promising\nin addressing non-IID data challenges, this approach leads to severe\ndegradation of tail classes in federated long-tailed scenarios. Under the\ncomposite effects of strong non-IID data distribution and long-tailed class\nimbalances, VLM fine-tuning may even fail to yield any improvement. To address\nthis issue, we propose Class-Aware Prompt Learning for Federated Long-tailed\nLearning (CAPT), a novel framework that leverages a pre-trained VLM to\neffectively handle both data heterogeneity and long-tailed distributions. CAPT\nintroduces a dual-prompt mechanism that synergizes general and class-aware\nprompts, enabling the framework to capture global trends while preserving\nclass-specific knowledge. To better aggregate and share knowledge across\nclients, we introduce a heterogeneity-aware client clustering strategy that\ngroups clients based on their data distributions, enabling efficient\ncollaboration and knowledge sharing. Extensive experiments on various\nlong-tailed datasets with different levels of data heterogeneity demonstrate\nthat CAPT significantly improves tail class performance without compromising\noverall accuracy, outperforming state-of-the-art methods in federated\nlong-tailed learning scenarios.\n","authors":["Shihao Hou","Xinyi Shang","Shreyank N Gowda","Yang Lu","Chao Wu","Yan Yan","Hanzi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.06993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05631v2","updated":"2025-03-10T07:13:09Z","published":"2025-03-07T17:54:05Z","title":"Strategy Coopetition Explains the Emergence and Transience of In-Context\n  Learning","summary":"  In-context learning (ICL) is a powerful ability that emerges in transformer\nmodels, enabling them to learn from context without weight updates. Recent work\nhas established emergent ICL as a transient phenomenon that can sometimes\ndisappear after long training times. In this work, we sought a mechanistic\nunderstanding of these transient dynamics. Firstly, we find that, after the\ndisappearance of ICL, the asymptotic strategy is a remarkable hybrid between\nin-weights and in-context learning, which we term \"context-constrained\nin-weights learning\" (CIWL). CIWL is in competition with ICL, and eventually\nreplaces it as the dominant strategy of the model (thus leading to ICL\ntransience). However, we also find that the two competing strategies actually\nshare sub-circuits, which gives rise to cooperative dynamics as well. For\nexample, in our setup, ICL is unable to emerge quickly on its own, and can only\nbe enabled through the simultaneous slow development of asymptotic CIWL. CIWL\nthus both cooperates and competes with ICL, a phenomenon we term \"strategy\ncoopetition.\" We propose a minimal mathematical model that reproduces these key\ndynamics and interactions. Informed by this model, we were able to identify a\nsetup where ICL is truly emergent and persistent.\n","authors":["Aaditya K. Singh","Ted Moskovitz","Sara Dragutinovic","Felix Hill","Stephanie C. Y. Chan","Andrew M. Saxe"],"pdf_url":"https://arxiv.org/pdf/2503.05631v2.pdf","comment":"20 pages, 18 figures"},{"id":"http://arxiv.org/abs/2503.06991v1","updated":"2025-03-10T07:11:34Z","published":"2025-03-10T07:11:34Z","title":"Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning\n  Evaluation Protocols","summary":"  Machine unlearning is a process to remove specific data points from a trained\nmodel while maintaining the performance on retain data, addressing privacy or\nlegal requirements. Despite its importance, existing unlearning evaluations\ntend to focus on logit-based metrics (i.e., accuracy) under small-scale\nscenarios. We observe that this could lead to a false sense of security in\nunlearning approaches under real-world scenarios. In this paper, we conduct a\nnew comprehensive evaluation that employs representation-based evaluations of\nthe unlearned model under large-scale scenarios to verify whether the\nunlearning approaches genuinely eliminate the targeted forget data from the\nmodel's representation perspective. Our analysis reveals that current\nstate-of-the-art unlearning approaches either completely degrade the\nrepresentational quality of the unlearned model or merely modify the classifier\n(i.e., the last layer), thereby achieving superior logit-based evaluation\nmetrics while maintaining significant representational similarity to the\noriginal model. Furthermore, we introduce a novel unlearning evaluation setup\nfrom a transfer learning perspective, in which the forget set classes exhibit\nsemantic similarity to downstream task classes, necessitating that feature\nrepresentations diverge significantly from those of the original model. Our\ncomprehensive benchmark not only addresses a critical gap between theoretical\nmachine unlearning and practical scenarios, but also establishes a foundation\nto inspire future research directions in developing genuinely effective\nunlearning methodologies.\n","authors":["Yongwoo Kim","Sungmin Cha","Donghyun Kim"],"pdf_url":"https://arxiv.org/pdf/2503.06991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05379v2","updated":"2025-03-10T07:11:14Z","published":"2025-03-07T12:46:42Z","title":"R1-Omni: Explainable Omni-Multimodal Emotion Recognition with\n  Reinforcement Learning","summary":"  In this work, we present the first application of Reinforcement Learning with\nVerifiable Reward (RLVR) to an Omni-multimodal large language model in the\ncontext of emotion recognition, a task where both visual and audio modalities\nplay crucial roles. We leverage RLVR to optimize the Omni model, significantly\nenhancing its performance in three key aspects: reasoning capability, emotion\nrecognition accuracy, and generalization ability. The introduction of RLVR not\nonly improves the model's overall performance on in-distribution data but also\ndemonstrates superior robustness when evaluated on out-of-distribution\ndatasets. More importantly, the improved reasoning capability enables clear\nanalysis of the contributions of different modalities, particularly visual and\naudio information, in the emotion recognition process. This provides valuable\ninsights into the optimization of multimodal large language models.\n","authors":["Jiaxing Zhao","Xihan Wei","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2503.05379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06990v1","updated":"2025-03-10T07:10:45Z","published":"2025-03-10T07:10:45Z","title":"TiGer: Self-Supervised Purification for Time-evolving Graphs","summary":"  Time-evolving graphs, such as social and citation networks, often contain\nnoise that distorts structural and temporal patterns, adversely affecting\ndownstream tasks, such as node classification. Existing purification methods\nfocus on static graphs, limiting their ability to account for critical temporal\ndependencies in dynamic graphs. In this work, we propose TiGer (Time-evolving\nGraph purifier), a self-supervised method explicitly designed for time-evolving\ngraphs. TiGer assigns two different sub-scores to edges using (1)\nself-attention for capturing long-term contextual patterns shaped by both\nadjacent and distant past events of varying significance and (2) statistical\ndistance measures for detecting inconsistency over a short-term period. These\nsub-scores are used to identify and filter out suspicious (i.e., noise-like)\nedges through an ensemble strategy, ensuring robustness without requiring noise\nlabels. Our experiments on five real-world datasets show TiGer filters out\nnoise with up to 10.2% higher accuracy and improves node classification\nperformance by up to 5.3%, compared to state-of-the-art methods.\n","authors":["Hyeonsoo Jo","Jongha Lee","Fanchen Bu","Kijung Shin"],"pdf_url":"https://arxiv.org/pdf/2503.06990v1.pdf","comment":"PAKDD 2025"},{"id":"http://arxiv.org/abs/2305.15557v6","updated":"2025-03-10T07:05:53Z","published":"2023-05-24T20:43:47Z","title":"Non-Parametric Learning of Stochastic Differential Equations with\n  Non-asymptotic Fast Rates of Convergence","summary":"  We propose a novel non-parametric learning paradigm for the identification of\ndrift and diffusion coefficients of multi-dimensional non-linear stochastic\ndifferential equations, which relies upon discrete-time observations of the\nstate. The key idea essentially consists of fitting a RKHS-based approximation\nof the corresponding Fokker-Planck equation to such observations, yielding\ntheoretical estimates of non-asymptotic learning rates which, unlike previous\nworks, become increasingly tighter when the regularity of the unknown drift and\ndiffusion coefficients becomes higher. Our method being kernel-based, offline\npre-processing may be profitably leveraged to enable efficient numerical\nimplementation, offering excellent balance between precision and computational\ncomplexity.\n","authors":["Riccardo Bonalli","Alessandro Rudi"],"pdf_url":"https://arxiv.org/pdf/2305.15557v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06985v1","updated":"2025-03-10T07:05:07Z","published":"2025-03-10T07:05:07Z","title":"Learning Decision Trees as Amortized Structure Inference","summary":"  Building predictive models for tabular data presents fundamental challenges,\nnotably in scaling consistently, i.e., more resources translating to better\nperformance, and generalizing systematically beyond the training data\ndistribution. Designing decision tree models remains especially challenging\ngiven the intractably large search space, and most existing methods rely on\ngreedy heuristics, while deep learning inductive biases expect a temporal or\nspatial structure not naturally present in tabular data. We propose a hybrid\namortized structure inference approach to learn predictive decision tree\nensembles given data, formulating decision tree construction as a sequential\nplanning problem. We train a deep reinforcement learning (GFlowNet) policy to\nsolve this problem, yielding a generative model that samples decision trees\nfrom the Bayesian posterior. We show that our approach, DT-GFN, outperforms\nstate-of-the-art decision tree and deep learning methods on standard\nclassification benchmarks derived from real-world data, robustness to\ndistribution shifts, and anomaly detection, all while yielding interpretable\nmodels with shorter description lengths. Samples from the trained DT-GFN model\ncan be ensembled to construct a random forest, and we further show that the\nperformance of scales consistently in ensemble size, yielding ensembles of\npredictors that continue to generalize systematically.\n","authors":["Mohammed Mahfoud","Ghait Boukachab","Michał Koziarski","Alex Hernandez-Garcia","Stefan Bauer","Yoshua Bengio","Nikolay Malkin"],"pdf_url":"https://arxiv.org/pdf/2503.06985v1.pdf","comment":"Code:\n  $\\href{https://github.com/GFNOrg/dt-gfn}{https://github.com/GFNOrg/dt-gfn}$"},{"id":"http://arxiv.org/abs/2503.06982v1","updated":"2025-03-10T06:57:10Z","published":"2025-03-10T06:57:10Z","title":"Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective\n  on Low-Rank Adaptation in Matrix Factorization","summary":"  Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning\npre-trained models, there is little theoretical understanding of how\nfirst-order methods with carefully crafted initialization adapt models to new\ntasks. In this work, we take the first step towards bridging this gap by\ntheoretically analyzing the learning dynamics of LoRA for matrix factorization\n(MF) under gradient flow (GF), emphasizing the crucial role of initialization.\nFor small initialization, we theoretically show that GF converges to a\nneighborhood of the optimal solution, with smaller initialization leading to\nlower final error. Our analysis shows that the final error is affected by the\nmisalignment between the singular spaces of the pre-trained model and the\ntarget matrix, and reducing the initialization scale improves alignment. To\naddress this misalignment, we propose a spectral initialization for LoRA in MF\nand theoretically prove that GF with small spectral initialization converges to\nthe fine-tuning task with arbitrary precision. Numerical experiments from MF\nand image classification validate our findings.\n","authors":["Ziqing Xu","Hancheng Min","Lachlan Ewen MacDonald","Jinqi Luo","Salma Tarmoun","Enrique Mallada","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2503.06982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07818v6","updated":"2025-03-10T06:52:03Z","published":"2024-02-12T17:24:15Z","title":"Differentially Private Zeroth-Order Methods for Scalable Large Language\n  Model Finetuning","summary":"  Fine-tuning on task-specific datasets is a widely-embraced paradigm of\nharnessing the powerful capability of pretrained LLMs for various downstream\ntasks. Due to the popularity of LLMs fine-tuning and its accompanying privacy\nconcerns, differentially private (DP) fine-tuning of pretrained LLMs has been\nwidely used to safeguarding the privacy of task-specific datasets. Lying at the\ndesign core of DP LLM fine-tuning methods is the satisfactory tradeoff among\nprivacy, utility, and scalability. Most existing methods build upon the seminal\nwork of DP-SGD. Despite pushing the scalability of DP-SGD to its limit,\nDP-SGD-based fine-tuning methods are unfortunately limited by the inherent\ninefficiency of SGD.\n  In this paper, we investigate the potential of DP zeroth-order methods for\nLLM pretraining, which avoids the scalability bottleneck of SGD by\napproximating the gradient with the more efficient zeroth-order gradient.\nRather than treating the zeroth-order method as a drop-in replacement for SGD,\nthis paper presents a comprehensive study both theoretically and empirically.\nFirst, we propose the stagewise DP zeroth-order method (DP-ZOSO) that\ndynamically schedules key hyperparameters. This design is grounded on the\nsynergy between DP random perturbation and the gradient approximation error of\nthe zeroth-order method, and its effect on fine-tuning trajectory.\n  We provide theoretical analysis for both proposed methods. We conduct\nextensive empirical analysis on both encoder-only masked language model and\ndecoder-only autoregressive language model, achieving impressive results in\nterms of scalability and utility regardless of the class of tasks (compared\nwith DPZero, DP-ZOPO improves $4.5\\%$ on SST-5, $5.5\\%$ on MNLI with\nRoBERTa-Large and 9.2\\% on CB, 3.9\\% on BoolQ with OPT-2.7b when $\\epsilon=4$,\ndemonstrates more significant enhancement in performance on more complicated\ntasks).\n","authors":["Z Liu","J Lou","W Bao","Y Hu","B Li","Z Qin","K Ren"],"pdf_url":"https://arxiv.org/pdf/2402.07818v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06978v1","updated":"2025-03-10T06:47:38Z","published":"2025-03-10T06:47:38Z","title":"Lightweight Multimodal Artificial Intelligence Framework for Maritime\n  Multi-Scene Recognition","summary":"  Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of\nintelligent marine robotics, particularly in applications such as marine\nconservation, environmental monitoring, and disaster response. However, this\ntask presents significant challenges due to environmental interference, where\nmarine conditions degrade image quality, and the complexity of maritime scenes,\nwhich requires deeper reasoning for accurate recognition. Pure vision models\nalone are insufficient to address these issues. To overcome these limitations,\nwe propose a novel multimodal Artificial Intelligence (AI) framework that\nintegrates image data, textual descriptions and classification vectors\ngenerated by a Multimodal Large Language Model (MLLM), to provide richer\nsemantic understanding and improve recognition accuracy. Our framework employs\nan efficient multimodal fusion mechanism to further enhance model robustness\nand adaptability in complex maritime environments. Experimental results show\nthat our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by\n3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt\nactivation-aware weight quantization (AWQ) as a lightweight technique, reducing\nthe model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly\nlowering computational overhead. This work provides a high-performance solution\nfor real-time maritime scene recognition, enabling Autonomous Surface Vehicles\n(ASVs) to support environmental monitoring and disaster response in\nresource-limited settings.\n","authors":["Xinyu Xi","Hua Yang","Shentai Zhang","Yijie Liu","Sijin Sun","Xiuju Fu"],"pdf_url":"https://arxiv.org/pdf/2503.06978v1.pdf","comment":"19 pages, 4 figures, submitted to Engineering Applications of\n  Artificial Intelligence"},{"id":"http://arxiv.org/abs/2502.14855v2","updated":"2025-03-10T06:44:48Z","published":"2025-02-20T18:58:07Z","title":"Prompt-to-Leaderboard","summary":"  Large language model (LLM) evaluations typically rely on aggregated metrics\nlike accuracy or human preference, averaging across users and prompts. This\naveraging obscures user- and prompt-specific variations in model performance.\nTo address this, we propose Prompt-to-Leaderboard (P2L), a method that produces\nleaderboards specific to a prompt. The core idea is to train an LLM taking\nnatural language prompts as input to output a vector of Bradley-Terry\ncoefficients which are then used to predict the human preference vote. The\nresulting prompt-dependent leaderboards allow for unsupervised task-specific\nevaluation, optimal routing of queries to models, personalization, and\nautomated evaluation of model strengths and weaknesses. Data from Chatbot Arena\nsuggest that P2L better captures the nuanced landscape of language model\nperformance than the averaged leaderboard. Furthermore, our findings suggest\nthat P2L's ability to produce prompt-specific evaluations follows a power law\nscaling similar to that observed in LLMs themselves. In January 2025, the\nrouter we trained based on this methodology achieved the #1 spot on the Chatbot\nArena leaderboard. Our code is available on GitHub at\nhttps://github.com/lmarena/p2l.\n","authors":["Evan Frick","Connor Chen","Joseph Tennyson","Tianle Li","Wei-Lin Chiang","Anastasios N. Angelopoulos","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2502.14855v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08109v3","updated":"2025-03-10T06:43:36Z","published":"2025-01-14T13:40:08Z","title":"Data-driven inventory management for new products: An adjusted Dyna-$Q$\n  approach with transfer learning","summary":"  In this paper, we propose a novel reinforcement learning algorithm for\ninventory management of newly launched products with no historical demand\ninformation. The algorithm follows the classic Dyna-$Q$ structure, balancing\nthe model-free and model-based approaches, while accelerating the training\nprocess of Dyna-$Q$ and mitigating the model discrepancy generated by the\nmodel-based feedback. Based on the idea of transfer learning, warm-start\ninformation from the demand data of existing similar products can be\nincorporated into the algorithm to further stabilize the early-stage training\nand reduce the variance of the estimated optimal policy. Our approach is\nvalidated through a case study of bakery inventory management with real data.\nThe adjusted Dyna-$Q$ shows up to a 23.7\\% reduction in average daily cost\ncompared with $Q$-learning, and up to a 77.5\\% reduction in training time\nwithin the same horizon compared with classic Dyna-$Q$. By using transfer\nlearning, it can be found that the adjusted Dyna-$Q$ has the lowest total cost,\nlowest variance in total cost, and relatively low shortage percentages among\nall the benchmarking algorithms under a 30-day testing.\n","authors":["Xinye Qu","Longxiao Liu","Wenjie Huang"],"pdf_url":"https://arxiv.org/pdf/2501.08109v3.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.06962v1","updated":"2025-03-10T06:20:39Z","published":"2025-03-10T06:20:39Z","title":"Capture Global Feature Statistics for One-Shot Federated Learning","summary":"  Traditional Federated Learning (FL) necessitates numerous rounds of\ncommunication between the server and clients, posing significant challenges\nincluding high communication costs, connection drop risks and susceptibility to\nprivacy attacks. One-shot FL has become a compelling learning paradigm to\novercome above drawbacks by enabling the training of a global server model via\na single communication round. However, existing one-shot FL methods suffer from\nexpensive computation cost on the server or clients and cannot deal with\nnon-IID (Independent and Identically Distributed) data stably and effectively.\nTo address these challenges, this paper proposes FedCGS, a novel Federated\nlearning algorithm that Capture Global feature Statistics leveraging\npre-trained models. With global feature statistics, we achieve training-free\nand heterogeneity-resistant one-shot FL. Furthermore, we extend its application\nto personalization scenario, where clients only need execute one extra\ncommunication round with server to download global statistics. Extensive\nexperimental results demonstrate the effectiveness of our methods across\ndiverse data heterogeneity settings. Code is available at\nhttps://github.com/Yuqin-G/FedCGS.\n","authors":["Zenghao Guan","Yucan Zhou","Xiaoyan Gu"],"pdf_url":"https://arxiv.org/pdf/2503.06962v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2303.11789v9","updated":"2025-03-10T06:19:41Z","published":"2023-03-20T08:37:08Z","title":"Decentralized Online Learning for Random Inverse Problems Over Graphs","summary":"  We propose a decentralized online learning algorithm for distributed random\ninverse problems over network graphs with online measurements, and unifies the\ndistributed parameter estimation in Hilbert spaces and the least mean square\nproblem in reproducing kernel Hilbert spaces (RKHS-LMS). We transform the\nconvergence of the algorithm into the asymptotic stability of a class of\ninhomogeneous random difference equations in Hilbert spaces with\n$L_{2}$-bounded martingale difference terms and develop the $L_2$-asymptotic\nstability theory in Hilbert spaces. We show that if the network graph is\nconnected and the sequence of forward operators satisfies the\ninfinite-dimensional spatio-temporal persistence of excitation condition, then\nthe estimates of all nodes are mean square and almost surely strongly\nconsistent. Moreover, we propose a decentralized online learning algorithm in\nRKHS based on non-stationary online data streams, and prove that the algorithm\nis mean square and almost surely strongly consistent if the operators induced\nby the random input data satisfy the infinite-dimensional spatio-temporal\npersistence of excitation condition.\n","authors":["Tao Li","Xiwei Zhang","Yan Chen"],"pdf_url":"https://arxiv.org/pdf/2303.11789v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17417v2","updated":"2025-03-10T06:18:24Z","published":"2024-07-24T16:53:09Z","title":"Can Watermarking Large Language Models Prevent Copyrighted Text\n  Generation and Hide Training Data?","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\ngenerating diverse and contextually rich text. However, concerns regarding\ncopyright infringement arise as LLMs may inadvertently produce copyrighted\nmaterial. In this paper, we first investigate the effectiveness of watermarking\nLLMs as a deterrent against the generation of copyrighted texts. Through\ntheoretical analysis and empirical evaluation, we demonstrate that\nincorporating watermarks into LLMs significantly reduces the likelihood of\ngenerating copyrighted content, thereby addressing a critical concern in the\ndeployment of LLMs. However, we also find that watermarking can have unintended\nconsequences on Membership Inference Attacks (MIAs), which aim to discern\nwhether a sample was part of the pretraining dataset and may be used to detect\ncopyright violations. Surprisingly, we find that watermarking adversely affects\nthe success rate of MIAs, complicating the task of detecting copyrighted text\nin the pretraining dataset. These results reveal the complex interplay between\ndifferent regulatory measures, which may impact each other in unforeseen ways.\nFinally, we propose an adaptive technique to improve the success rate of a\nrecent MIA under watermarking. Our findings underscore the importance of\ndeveloping adaptive methods to study critical problems in LLMs with potential\nlegal implications.\n","authors":["Michael-Andrei Panaitescu-Liess","Zora Che","Bang An","Yuancheng Xu","Pankayaraj Pathmanathan","Souradip Chakraborty","Sicheng Zhu","Tom Goldstein","Furong Huang"],"pdf_url":"https://arxiv.org/pdf/2407.17417v2.pdf","comment":"19 pages, 7 figures. Published at AAAI 2025. Code will be available\n  at https://github.com/michael-panaitescu/watermark_copyright_aaai25"},{"id":"http://arxiv.org/abs/2408.06701v2","updated":"2025-03-10T05:43:04Z","published":"2024-08-13T07:56:21Z","title":"DiffSG: A Generative Solver for Network Optimization with Diffusion\n  Model","summary":"  Generative diffusion models, famous for their performance in image\ngeneration, are popular in various cross-domain applications. However, their\nuse in the communication community has been mostly limited to auxiliary tasks\nlike data modeling and feature extraction. These models hold greater promise\nfor fundamental problems in network optimization compared to traditional\nmachine learning methods. Discriminative deep learning often falls short due to\nits single-step input-output mapping and lack of global awareness of the\nsolution space, especially given the complexity of network optimization's\nobjective functions. In contrast, generative diffusion models can consider a\nbroader range of solutions and exhibit stronger generalization by learning\nparameters that describe the distribution of the underlying solution space,\nwith higher probabilities assigned to better solutions. We propose a new\nframework Diffusion Model-based Solution Generation (DiffSG), which leverages\nthe intrinsic distribution learning capabilities of generative diffusion models\nto learn high-quality solution distributions based on given inputs. The optimal\nsolution within this distribution is highly probable, allowing it to be\neffectively reached through repeated sampling. We validate the performance of\nDiffSG on several typical network optimization problems, including\nmixed-integer non-linear programming, convex optimization, and hierarchical\nnon-convex optimization. Our results demonstrate that DiffSG outperforms\nexisting baseline methods not only on in-domain inputs but also on\nout-of-domain inputs. In summary, we demonstrate the potential of generative\ndiffusion models in tackling complex network optimization problems and outline\na promising path for their broader application in the communication community.\nOur code is available at https://github.com/qiyu3816/DiffSG.\n","authors":["Ruihuai Liang","Bo Yang","Zhiwen Yu","Bin Guo","Xuelin Cao","Mérouane Debbah","H. Vincent Poor","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2408.06701v2.pdf","comment":"Accepted by IEEE Communications Magazine"},{"id":"http://arxiv.org/abs/2410.16718v5","updated":"2025-03-10T05:26:34Z","published":"2024-10-22T05:56:57Z","title":"Learning Partial Graph Matching via Optimal Partial Transport","summary":"  Partial graph matching extends traditional graph matching by allowing some\nnodes to remain unmatched, enabling applications in more complex scenarios.\nHowever, this flexibility introduces additional complexity, as both the subset\nof nodes to match and the optimal mapping must be determined. While recent\nstudies have explored deep learning techniques for partial graph matching, a\nsignificant limitation remains: the absence of an optimization objective that\nfully captures the problem's intrinsic nature while enabling efficient\nsolutions. In this paper, we propose a novel optimization framework for partial\ngraph matching, inspired by optimal partial transport. Our approach formulates\nan objective that enables partial assignments while incorporating matching\nbiases, using weighted total variation as the divergence function to guarantee\noptimal partial assignments. Our method can achieve efficient, exact solutions\nwithin cubic worst case time complexity. Our contributions are threefold: (i)\nwe introduce a novel optimization objective that balances matched and unmatched\nnodes; (ii) we establish a connection between partial graph matching and linear\nsum assignment problem, enabling efficient solutions; (iii) we propose a deep\ngraph matching architecture with a novel partial matching loss, providing an\nend-to-end solution. The empirical evaluations on standard graph matching\nbenchmarks demonstrate the efficacy of the proposed approach.\n","authors":["Gathika Ratnayaka","James Nichols","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2410.16718v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06929v1","updated":"2025-03-10T05:20:56Z","published":"2025-03-10T05:20:56Z","title":"Assessing Uncertainty in Stock Returns: A Gaussian Mixture\n  Distribution-Based Method","summary":"  This study seeks to advance the understanding and prediction of stock market\nreturn uncertainty through the application of advanced deep learning\ntechniques. We introduce a novel deep learning model that utilizes a Gaussian\nmixture distribution to capture the complex, time-varying nature of asset\nreturn distributions in the Chinese stock market. By incorporating the Gaussian\nmixture distribution, our approach effectively characterizes short-term\nfluctuations and non-traditional features of stock returns, such as skewness\nand heavy tails, that are often overlooked by traditional models. Compared to\nGARCH models and their variants, our method demonstrates superior performance\nin volatility estimation, particularly during periods of heightened market\nvolatility. It provides more accurate volatility forecasts and offers unique\nrisk insights for different assets, thereby deepening the understanding of\nreturn uncertainty. Additionally, we propose a novel use of Code embedding\nwhich utilizes a bag-of-words approach to train hidden representations of stock\ncodes and transforms the uncertainty attributes of stocks into high-dimensional\nvectors. These vectors are subsequently reduced to two dimensions, allowing the\nobservation of similarity among different stocks. This visualization\nfacilitates the identification of asset clusters with similar risk profiles,\noffering valuable insights for portfolio management and risk mitigation. Since\nwe predict the uncertainty of returns by estimating their latent distribution,\nit is challenging to evaluate the return distribution when the true\ndistribution is unobservable. However, we can measure it through the CRPS to\nassess how well the predicted distribution matches the true returns, and\nthrough MSE and QLIKE metrics to evaluate the error between the volatility\nlevel of the predicted distribution and proxy measures of true volatility.\n","authors":["Yanlong Wang","Jian Xu","Shao-Lun Huang","Danny Dongning Sun","Xiao-Ping Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06929v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2503.06928v1","updated":"2025-03-10T05:19:13Z","published":"2025-03-10T05:19:13Z","title":"FinTSBridge: A New Evaluation Suite for Real-world Financial Prediction\n  with Advanced Time Series Models","summary":"  Despite the growing attention to time series forecasting in recent years,\nmany studies have proposed various solutions to address the challenges\nencountered in time series prediction, aiming to improve forecasting\nperformance. However, effectively applying these time series forecasting models\nto the field of financial asset pricing remains a challenging issue. There is\nstill a need for a bridge to connect cutting-edge time series forecasting\nmodels with financial asset pricing. To bridge this gap, we have undertaken the\nfollowing efforts: 1) We constructed three datasets from the financial domain;\n2) We selected over ten time series forecasting models from recent studies and\nvalidated their performance in financial time series; 3) We developed new\nmetrics, msIC and msIR, in addition to MSE and MAE, to showcase the time series\ncorrelation captured by the models; 4) We designed financial-specific tasks for\nthese three datasets and assessed the practical performance and application\npotential of these forecasting models in important financial problems. We hope\nthe developed new evaluation suite, FinTSBridge, can provide valuable insights\ninto the effectiveness and robustness of advanced forecasting models in\nfinanical domains.\n","authors":["Yanlong Wang","Jian Xu","Tiantian Gao","Hongkang Zhang","Shao-Lun Huang","Danny Dongning Sun","Xiao-Ping Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06928v1.pdf","comment":"ICLR 2025 Workshop Advances in Financial AI"},{"id":"http://arxiv.org/abs/2503.06926v1","updated":"2025-03-10T05:11:58Z","published":"2025-03-10T05:11:58Z","title":"Effect of Selection Format on LLM Performance","summary":"  This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.\n","authors":["Yuchen Han","Yucheng Wu","Jeffrey Willard"],"pdf_url":"https://arxiv.org/pdf/2503.06926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02021v2","updated":"2025-03-10T05:09:16Z","published":"2024-06-04T07:00:14Z","title":"FFNet: MetaMixer-based Efficient Convolutional Mixer Design","summary":"  Transformer, composed of self-attention and Feed-Forward Network, has\nrevolutionized the landscape of network design across various vision tasks.\nWhile self-attention is extensively explored as a key factor in performance,\nFFN has received little attention. FFN is a versatile operator seamlessly\nintegrated into nearly all AI models to effectively harness rich\nrepresentations. Recent works also show that FFN functions like key-value\nmemories. Thus, akin to the query-key-value mechanism within self-attention,\nFFN can be viewed as a memory network, where the input serves as query and the\ntwo projection weights operate as keys and values, respectively. Based on these\nobservations, we hypothesize that the importance lies in query-key-value\nframework itself for competitive performance. To verify this, we propose\nconverting self-attention into a more FFN-like efficient token mixer with only\nconvolutions while retaining query-key-value framework, namely FFNification.\nSpecifically, FFNification replaces query-key-value interactions with large\nkernel convolutions and adopts GELU activation function instead of softmax. The\nderived token mixer, FFNified attention, serves as key-value memories for\ndetecting locally distributed spatial patterns, and operates in the opposite\ndimension to the ConvNeXt block within each corresponding sub-operation of the\nquery-key-value framework. Building upon the above two modules, we present a\nfamily of Fast-Forward Networks (FFNet). Despite being composed of only simple\noperators, FFNet outperforms sophisticated and highly specialized methods in\neach domain, with notable efficiency gains. These results validate our\nhypothesis, leading us to propose MetaMixer, a general mixer architecture that\ndoes not specify sub-operations within the query-key-value framework.\n","authors":["Seokju Yun","Dongheon Lee","Youngmin Ro"],"pdf_url":"https://arxiv.org/pdf/2406.02021v2.pdf","comment":"Code: https://github.com/ysj9909/FFNet"},{"id":"http://arxiv.org/abs/2405.04944v2","updated":"2025-03-10T05:06:10Z","published":"2024-05-08T10:28:20Z","title":"A Sparse Tensor Generator with Efficient Feature Extraction","summary":"  Sparse tensor operations are increasingly important in diverse applications\nsuch as social networks, deep learning, diagnosis, crime, and review analysis.\nHowever, a major obstacle in sparse tensor research is the lack of large-scale\nsparse tensor datasets. Another challenge lies in analyzing sparse tensor\nfeatures, which are essential not only for understanding the nonzero pattern\nbut also for selecting the most suitable storage format, decomposition\nalgorithm, and reordering methods. However, due to the large size of real-world\ntensors, even extracting these features can be computationally expensive\nwithout careful optimization. To address these limitations, we have developed a\nsmart sparse tensor generator that replicates key characteristics of real\nsparse tensors. Additionally, we propose efficient methods for extracting a\ncomprehensive set of sparse tensor features. The effectiveness of our generator\nis validated through the quality of extracted features and the performance of\ndecomposition on the generated tensors. Both the sparse tensor feature\nextractor and the tensor generator are open source with all the artifacts\navailable at https://github.com/sparcityeu/FeaTensor and\nhttps://github.com/sparcityeu/GenTensor, respectively.\n","authors":["Tugba Torun","Ameer Taweel","Didem Unat"],"pdf_url":"https://arxiv.org/pdf/2405.04944v2.pdf","comment":"20 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.04850v2","updated":"2025-03-10T05:01:22Z","published":"2025-03-06T02:24:35Z","title":"Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain Scams","summary":"  We identify the slow liquidity drain (SLID) scam, an insidious and highly\nprofitable threat to decentralized finance (DeFi), posing a large-scale,\npersistent, and growing risk to the ecosystem. Unlike traditional scams such as\nrug pulls or honeypots (USENIX Sec'19, USENIX Sec'23), SLID gradually siphons\nfunds from liquidity pools over extended periods, making detection\nsignificantly more challenging. In this paper, we conducted the first\nlarge-scale empirical analysis of 319,166 liquidity pools across six major\ndecentralized exchanges (DEXs) since 2018. We identified 3,117 SLID affected\nliquidity pools, resulting in cumulative losses of more than US$103 million. We\npropose a rule-based heuristic and an enhanced machine learning model for early\ndetection. Our machine learning model achieves a detection speed 4.77 times\nfaster than the heuristic while maintaining 95% accuracy. Our study establishes\na foundation for protecting DeFi investors at an early stage and promoting\ntransparency in the DeFi ecosystem.\n","authors":["Minh Trung Tran","Nasrin Sohrabi","Zahir Tari","Qin Wang","Xiaoyu Xia"],"pdf_url":"https://arxiv.org/pdf/2503.04850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06921v1","updated":"2025-03-10T05:00:24Z","published":"2025-03-10T05:00:24Z","title":"Task Vector Quantization for Memory-Efficient Model Merging","summary":"  Model merging enables efficient multi-task models by combining task-specific\nfine-tuned checkpoints. However, storing multiple task-specific checkpoints\nrequires significant memory, limiting scalability and restricting model merging\nto larger models and diverse tasks. In this paper, we propose quantizing task\nvectors (i.e., the difference between pre-trained and fine-tuned checkpoints)\ninstead of quantizing fine-tuned checkpoints. We observe that task vectors\nexhibit a narrow weight range, enabling low precision quantization (up to 4\nbit) within existing task vector merging frameworks. To further mitigate\nquantization errors within ultra-low bit precision (e.g., 2 bit), we introduce\nResidual Task Vector Quantization, which decomposes the task vector into a base\nvector and offset component. We allocate bits based on quantization\nsensitivity, ensuring precision while minimizing error within a memory budget.\nExperiments on image classification and dense prediction show our method\nmaintains or improves model merging performance while using only 8% of the\nmemory required for full-precision checkpoints.\n","authors":["Youngeun Kim","Seunghwan Lee","Aecheon Jung","Bogon Ryu","Sungeun Hong"],"pdf_url":"https://arxiv.org/pdf/2503.06921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06917v1","updated":"2025-03-10T04:58:18Z","published":"2025-03-10T04:58:18Z","title":"Combinatorial Optimization via LLM-driven Iterated Fine-tuning","summary":"  We present a novel way to integrate flexible, context-dependent constraints\ninto combinatorial optimization by leveraging Large Language Models (LLMs)\nalongside traditional algorithms. Although LLMs excel at interpreting nuanced,\nlocally specified requirements, they struggle with enforcing global\ncombinatorial feasibility. To bridge this gap, we propose an iterated\nfine-tuning framework where algorithmic feedback progressively refines the\nLLM's output distribution. Interpreting this as simulated annealing, we\nintroduce a formal model based on a \"coarse learnability\" assumption, providing\nsample complexity bounds for convergence. Empirical evaluations on scheduling,\ngraph connectivity, and clustering tasks demonstrate that our framework\nbalances the flexibility of locally expressed constraints with rigorous global\noptimization more effectively compared to baseline sampling methods. Our\nresults highlight a promising direction for hybrid AI-driven combinatorial\nreasoning.\n","authors":["Pranjal Awasthi","Sreenivas Gollapudi","Ravi Kumar","Kamesh Munagala"],"pdf_url":"https://arxiv.org/pdf/2503.06917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06916v1","updated":"2025-03-10T04:57:20Z","published":"2025-03-10T04:57:20Z","title":"You Are Your Own Best Teacher: Achieving Centralized-level Performance\n  in Federated Learning under Heterogeneous and Long-tailed Data","summary":"  Data heterogeneity, stemming from local non-IID data and global long-tailed\ndistributions, is a major challenge in federated learning (FL), leading to\nsignificant performance gaps compared to centralized learning. Previous\nresearch found that poor representations and biased classifiers are the main\nproblems and proposed neural-collapse-inspired synthetic simplex ETF to help\nrepresentations be closer to neural collapse optima. However, we find that the\nneural-collapse-inspired methods are not strong enough to reach neural collapse\nand still have huge gaps to centralized training. In this paper, we rethink\nthis issue from a self-bootstrap perspective and propose FedYoYo (You Are Your\nOwn Best Teacher), introducing Augmented Self-bootstrap Distillation (ASD) to\nimprove representation learning by distilling knowledge between weakly and\nstrongly augmented local samples, without needing extra datasets or models. We\nfurther introduce Distribution-aware Logit Adjustment (DLA) to balance the\nself-bootstrap process and correct biased feature representations. FedYoYo\nnearly eliminates the performance gap, achieving centralized-level performance\neven under mixed heterogeneity. It enhances local representation learning,\nreducing model drift and improving convergence, with feature prototypes closer\nto neural collapse optimality. Extensive experiments show FedYoYo achieves\nstate-of-the-art results, even surpassing centralized logit adjustment methods\nby 5.4\\% under global long-tailed settings.\n","authors":["Shanshan Yan","Zexi Li","Chao Wu","Meng Pang","Yang Lu","Yan Yan","Hanzi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.06916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20642v2","updated":"2025-03-10T04:55:43Z","published":"2024-05-31T07:01:49Z","title":"Linear Contracts in Multitasking: Robustness, Uniformity, and Learning","summary":"  In this work, we study the multitasking principal-agent problem. The agent\nperforms several task for the principal, and the principal posts a contract\nincentivizing the agent to exert effort. The principal can observe a signal for\neach task, and the contract is a mapping from the space of possible signals to\na payment. We study the special class of linear contracts from three\nperspectives: robustness, uniformity, and learning. Firstly, we show a\nrobustness result: in an ambiguous setting when only first moment information\nis known, there is a linear contract maximizing the principal's payoff in a\nworst-case scenario. Secondly, we show a uniformity result: when the agent's\ncost function is homogeneous to a certain degree and the the principal's\nutility takes a linear form across tasks, then the optimal contract depends on\nthe agent's cost function only through its homogeneuity degree. Thirdly, we\nstudy the problem of learning an optimal linear contract through observational\ndata. We identify this as an measurement error model, and propose instrumental\nregression methods to estimate the optimal contract parameters in an offline\nsetting, or to learn the optimal contract in an online setting.\n","authors":["Shiliang Zuo"],"pdf_url":"https://arxiv.org/pdf/2405.20642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11788v4","updated":"2025-03-10T04:51:22Z","published":"2024-04-17T22:44:22Z","title":"NonGEMM Bench: Understanding the Performance Horizon of the Latest ML\n  Workloads with NonGEMM Workloads","summary":"  Among ML operators today, GEneralMatrix Multiplication (GEMM)-based operators\nare known to be key operators that build the main backbone of ML models. As\ntheir computational overhead dominates the overall execution time (e.g., 42.8%\n- 96.6% in our results), GEMM operators have been the prime optimization\ntargets for fast ML inference. This led to advanced GPUs and accelerators\navailable today, which provided significant boost in the GEMM performance\ncompared to CPUs, aligned with the lesson from Amdahl's law. However,\naccelerating GEMM has significantly shifted the Amdahl's law's landscape for ML\ninference; due to the decreased GEMM execution time, the relative execution\ntime of non-GEMM operators is not dominant. Although the importance of non-GEMM\nperformance is increasing, we have little knowledge about the non-GEMM\nperformance horizon in the latest hardware platforms and models. Therefore, to\nguide non-GEMM-oriented optimizations, we conduct a thorough performance\nanalysis of 16 widely adopted ML models in Hugging Face and Torchvision on\nworkstation and data center platforms with/without GPUs. We discover that\nnon-GEMM performance bottleneck is a considerable issue across all the\nplatforms and models, accounting for 11.3% to 73.6% of total latency, on\naverage. The challenge significantly aggravates when we apply quantization,\nwhich is a common model compression technique, due to the boosted GEMM\nperformance and extra non-GEMM operators for dequantization and requantization.\nTo provide insights into non-GEMM optimization targets, we demystify the most\ndominant non-GEMM operators for each model and deployment software.We also show\nthat widely adopted optimizations such as operator fusion do not completely\naddress the non-GEMM performance bottleneck, where non-GEMM operators still\naccount for 15% to 48% of total latency.\n","authors":["Rachid Karami","Sheng-Chun Kao","Hyoukjun Kwon"],"pdf_url":"https://arxiv.org/pdf/2404.11788v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19834v2","updated":"2025-03-10T04:45:52Z","published":"2025-02-27T07:14:11Z","title":"Knowledge Bridger: Towards Training-free Missing Multi-modality\n  Completion","summary":"  Previous successful approaches to missing modality completion rely on\ncarefully designed fusion techniques and extensive pre-training on complete\ndata, which can limit their generalizability in out-of-domain (OOD) scenarios.\nIn this study, we pose a new challenge: can we develop a missing modality\ncompletion model that is both resource-efficient and robust to OOD\ngeneralization? To address this, we present a training-free framework for\nmissing modality completion that leverages large multimodal models (LMMs). Our\napproach, termed the \"Knowledge Bridger\", is modality-agnostic and integrates\ngeneration and ranking of missing modalities. By defining domain-specific\npriors, our method automatically extracts structured information from available\nmodalities to construct knowledge graphs. These extracted graphs connect the\nmissing modality generation and ranking modules through the LMM, resulting in\nhigh-quality imputations of missing modalities. Experimental results across\nboth general and medical domains show that our approach consistently\noutperforms competing methods, including in OOD generalization. Additionally,\nour knowledge-driven generation and ranking techniques demonstrate superiority\nover variants that directly employ LMMs for generation and ranking, offering\ninsights that may be valuable for applications in other domains.\n","authors":["Guanzhou Ke","Shengfeng He","Xiao Li Wang","Bo Wang","Guoqing Chao","Yuanyang Zhang","Yi Xie","HeXing Su"],"pdf_url":"https://arxiv.org/pdf/2502.19834v2.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2502.16660v3","updated":"2025-03-10T04:21:05Z","published":"2025-02-23T17:38:10Z","title":"BioMaze: Benchmarking and Enhancing Large Language Models for Biological\n  Pathway Reasoning","summary":"  The applications of large language models (LLMs) in various biological\ndomains have been explored recently, but their reasoning ability in complex\nbiological systems, such as pathways, remains underexplored, which is crucial\nfor predicting biological phenomena, formulating hypotheses, and designing\nexperiments. This work explores the potential of LLMs in pathway reasoning. We\nintroduce BioMaze, a dataset with 5.1K complex pathway problems derived from\nreal research, covering various biological contexts including natural dynamic\nchanges, disturbances, additional intervention conditions, and multi-scale\nresearch targets. Our evaluation of methods such as CoT and graph-augmented\nreasoning, shows that LLMs struggle with pathway reasoning, especially in\nperturbed systems. To address this, we propose PathSeeker, an LLM agent that\nenhances reasoning through interactive subgraph-based navigation, enabling a\nmore effective approach to handling the complexities of biological systems in a\nscientifically aligned manner. The dataset and code are available at\nhttps://github.com/zhao-ht/BioMaze.\n","authors":["Haiteng Zhao","Chang Ma","Fangzhi Xu","Lingpeng Kong","Zhi-Hong Deng"],"pdf_url":"https://arxiv.org/pdf/2502.16660v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11418v2","updated":"2025-03-10T04:15:20Z","published":"2025-02-17T04:17:27Z","title":"TimeCAP: Learning to Contextualize, Augment, and Predict Time Series\n  Events with Large Language Model Agents","summary":"  Time series data is essential in various applications, including climate\nmodeling, healthcare monitoring, and financial analytics. Understanding the\ncontextual information associated with real-world time series data is often\nessential for accurate and reliable event predictions. In this paper, we\nintroduce TimeCAP, a time-series processing framework that creatively employs\nLarge Language Models (LLMs) as contextualizers of time series data, extending\ntheir typical usage as predictors. TimeCAP incorporates two independent LLM\nagents: one generates a textual summary capturing the context of the time\nseries, while the other uses this enriched summary to make more informed\npredictions. In addition, TimeCAP employs a multi-modal encoder that synergizes\nwith the LLM agents, enhancing predictive performance through mutual\naugmentation of inputs with in-context examples. Experimental results on\nreal-world datasets demonstrate that TimeCAP outperforms state-of-the-art\nmethods for time series event prediction, including those utilizing LLMs as\npredictors, achieving an average improvement of 28.75% in F1 score.\n","authors":["Geon Lee","Wenchao Yu","Kijung Shin","Wei Cheng","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2502.11418v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2308.14815v4","updated":"2025-03-10T04:10:08Z","published":"2023-08-28T18:06:24Z","title":"Distributionally Robust Statistical Verification with Imprecise Neural\n  Networks","summary":"  A particularly challenging problem in AI safety is providing guarantees on\nthe behavior of high-dimensional autonomous systems. Verification approaches\ncentered around reachability analysis fail to scale, and purely statistical\napproaches are constrained by the distributional assumptions about the sampling\nprocess. Instead, we pose a distributionally robust version of the statistical\nverification problem for black-box systems, where our performance guarantees\nhold over a large family of distributions. This paper proposes a novel approach\nbased on uncertainty quantification using concepts from imprecise\nprobabilities. A central piece of our approach is an ensemble technique called\nImprecise Neural Networks, which provides the uncertainty quantification.\nAdditionally, we solve the allied problem of exploring the input set using\nactive learning. The active learning uses an exhaustive neural-network\nverification tool Sherlock to collect samples. An evaluation on multiple\nphysical simulators in the openAI gym Mujoco environments with\nreinforcement-learned controllers demonstrates that our approach can provide\nuseful and scalable guarantees for high-dimensional systems.\n","authors":["Souradeep Dutta","Michele Caprio","Vivian Lin","Matthew Cleaveland","Kuk Jin Jang","Ivan Ruchkin","Oleg Sokolsky","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2308.14815v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06901v1","updated":"2025-03-10T04:07:43Z","published":"2025-03-10T04:07:43Z","title":"Iterative Prompt Relocation for Distribution-Adaptive Visual Prompt\n  Tuning","summary":"  Visual prompt tuning (VPT) provides an efficient and effective solution for\nadapting pre-trained models to various downstream tasks by incorporating\nlearnable prompts. However, most prior art indiscriminately applies a fixed\nprompt distribution across different tasks, neglecting the importance of each\nblock differing depending on the task. In this paper, we investigate adaptive\ndistribution optimization (ADO) by addressing two key questions: (1) How to\nappropriately and formally define ADO, and (2) How to design an adaptive\ndistribution strategy guided by this definition? Through in-depth analysis, we\nprovide an affirmative answer that properly adjusting the distribution\nsignificantly improves VPT performance, and further uncover a key insight that\na nested relationship exists between ADO and VPT. Based on these findings, we\npropose a new VPT framework, termed PRO-VPT (iterative Prompt RelOcation-based\nVPT), which adaptively adjusts the distribution building upon a nested\noptimization formulation. Specifically, we develop a prompt relocation strategy\nfor ADO derived from this formulation, comprising two optimization steps:\nidentifying and pruning idle prompts, followed by determining the optimal\nblocks for their relocation. By iteratively performing prompt relocation and\nVPT, our proposal adaptively learns the optimal prompt distribution, thereby\nunlocking the full potential of VPT. Extensive experiments demonstrate that our\nproposal significantly outperforms state-of-the-art VPT methods, e.g., PRO-VPT\nsurpasses VPT by 1.6% average accuracy, leading prompt-based methods to\nstate-of-the-art performance on the VTAB-1k benchmark. The code is available at\nhttps://github.com/ckshang/PRO-VPT.\n","authors":["Chikai Shang","Mengke Li","Yiqun Zhang","Zhen Chen","Jinlin Wu","Fangqing Gu","Yang Lu","Yiu-ming Cheung"],"pdf_url":"https://arxiv.org/pdf/2503.06901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06893v1","updated":"2025-03-10T03:50:20Z","published":"2025-03-10T03:50:20Z","title":"Policy Regularization on Globally Accessible States in Cross-Dynamics\n  Reinforcement Learning","summary":"  To learn from data collected in diverse dynamics, Imitation from Observation\n(IfO) methods leverage expert state trajectories based on the premise that\nrecovering expert state distributions in other dynamics facilitates policy\nlearning in the current one. However, Imitation Learning inherently imposes a\nperformance upper bound of learned policies. Additionally, as the environment\ndynamics change, certain expert states may become inaccessible, rendering their\ndistributions less valuable for imitation. To address this, we propose a novel\nframework that integrates reward maximization with IfO, employing F-distance\nregularized policy optimization. This framework enforces constraints on\nglobally accessible states--those with nonzero visitation frequency across all\nconsidered dynamics--mitigating the challenge posed by inaccessible states. By\ninstantiating F-distance in different ways, we derive two theoretical analysis\nand develop a practical algorithm called Accessible State Oriented Policy\nRegularization (ASOR). ASOR serves as a general add-on module that can be\nincorporated into various RL approaches, including offline RL and off-policy\nRL. Extensive experiments across multiple benchmarks demonstrate ASOR's\neffectiveness in enhancing state-of-the-art cross-domain policy transfer\nalgorithms, significantly improving their performance.\n","authors":["Zhenghai Xue","Lang Feng","Jiacheng Xu","Kang Kang","Xiang Wen","Bo An","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2503.06893v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2410.11206v2","updated":"2025-03-10T03:40:53Z","published":"2024-10-15T02:47:57Z","title":"Towards Understanding Why FixMatch Generalizes Better Than Supervised\n  Learning","summary":"  Semi-supervised learning (SSL), exemplified by FixMatch (Sohn et al., 2020),\nhas shown significant generalization advantages over supervised learning (SL),\nparticularly in the context of deep neural networks (DNNs). However, it is\nstill unclear, from a theoretical standpoint, why FixMatch-like SSL algorithms\ngeneralize better than SL on DNNs. In this work, we present the first\ntheoretical justification for the enhanced test accuracy observed in\nFixMatch-like SSL applied to DNNs by taking convolutional neural networks\n(CNNs) on classification tasks as an example. Our theoretical analysis reveals\nthat the semantic feature learning processes in FixMatch and SL are rather\ndifferent. In particular, FixMatch learns all the discriminative features of\neach semantic class, while SL only randomly captures a subset of features due\nto the well-known lottery ticket hypothesis. Furthermore, we show that our\nanalysis framework can be applied to other FixMatch-like SSL methods, e.g.,\nFlexMatch, FreeMatch, Dash, and SoftMatch. Inspired by our theoretical\nanalysis, we develop an improved variant of FixMatch, termed Semantic-Aware\nFixMatch (SA-FixMatch). Experimental results corroborate our theoretical\nfindings and the enhanced generalization capability of SA-FixMatch.\n","authors":["Jingyang Li","Jiachun Pan","Vincent Y. F. Tan","Kim-Chuan Toh","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.11206v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06884v1","updated":"2025-03-10T03:28:18Z","published":"2025-03-10T03:28:18Z","title":"Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement\n  Cannot Help","summary":"  Generative modeling is widely regarded as one of the most essential problems\nin today's AI community, with text-to-image generation having gained\nunprecedented real-world impacts. Among various approaches, diffusion models\nhave achieved remarkable success and have become the de facto solution for\ntext-to-image generation. However, despite their impressive performance, these\nmodels exhibit fundamental limitations in adhering to numerical constraints in\nuser instructions, frequently generating images with an incorrect number of\nobjects. While several prior works have mentioned this issue, a comprehensive\nand rigorous evaluation of this limitation remains lacking. To address this\ngap, we introduce T2ICountBench, a novel benchmark designed to rigorously\nevaluate the counting ability of state-of-the-art text-to-image diffusion\nmodels. Our benchmark encompasses a diverse set of generative models, including\nboth open-source and private systems. It explicitly isolates counting\nperformance from other capabilities, provides structured difficulty levels, and\nincorporates human evaluations to ensure high reliability.\n  Extensive evaluations with T2ICountBench reveal that all state-of-the-art\ndiffusion models fail to generate the correct number of objects, with accuracy\ndropping significantly as the number of objects increases. Additionally, an\nexploratory study on prompt refinement demonstrates that such simple\ninterventions generally do not improve counting accuracy. Our findings\nhighlight the inherent challenges in numerical understanding within diffusion\nmodels and point to promising directions for future improvements.\n","authors":["Yuefan Cao","Xuyang Guo","Jiayan Huo","Yingyu Liang","Zhenmei Shi","Zhao Song","Jiahao Zhang","Zhen Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05246v2","updated":"2025-03-10T03:22:48Z","published":"2025-03-07T08:58:07Z","title":"Mastering Continual Reinforcement Learning through Fine-Grained Sparse\n  Network Allocation and Dormant Neuron Exploration","summary":"  Continual Reinforcement Learning (CRL) is essential for developing agents\nthat can learn, adapt, and accumulate knowledge over time. However, a\nfundamental challenge persists as agents must strike a delicate balance between\nplasticity, which enables rapid skill acquisition, and stability, which ensures\nlong-term knowledge retention while preventing catastrophic forgetting. In this\npaper, we introduce SSDE, a novel structure-based approach that enhances\nplasticity through a fine-grained allocation strategy with Structured Sparsity\nand Dormant-guided Exploration. SSDE decomposes the parameter space into\nforward-transfer (frozen) parameters and task-specific (trainable) parameters.\nCrucially, these parameters are allocated by an efficient co-allocation scheme\nunder sparse coding, ensuring sufficient trainable capacity for new tasks while\npromoting efficient forward transfer through frozen parameters. However,\nstructure-based methods often suffer from rigidity due to the accumulation of\nnon-trainable parameters, limiting exploration and adaptability. To address\nthis, we further introduce a sensitivity-guided neuron reactivation mechanism\nthat systematically identifies and resets dormant neurons, which exhibit\nminimal influence in the sparse policy network during inference. This approach\neffectively enhance exploration while preserving structural efficiency.\nExtensive experiments on the CW10-v1 Continual World benchmark demonstrate that\nSSDE achieves state-of-the-art performance, reaching a success rate of 95%,\nsurpassing prior methods significantly in both plasticity and stability\ntrade-offs (code is available at: https://github.com/chengqiArchy/SSDE).\n","authors":["Chengqi Zheng","Haiyan Yin","Jianda Chen","Terence Ng","Yew-Soon Ong","Ivor Tsang"],"pdf_url":"https://arxiv.org/pdf/2503.05246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06881v1","updated":"2025-03-10T03:15:54Z","published":"2025-03-10T03:15:54Z","title":"ResMoE: Space-efficient Compression of Mixture of Experts LLMs via\n  Residual Restoration","summary":"  Mixture-of-Experts (MoE) Transformer, the backbone architecture of multiple\nphenomenal language models, leverages sparsity by activating only a fraction of\nmodel parameters for each input token. The sparse structure, while allowing\nconstant time costs, results in space inefficiency: we still need to load all\nthe model parameters during inference. We introduce ResMoE, an innovative MoE\napproximation framework that utilizes Wasserstein barycenter to extract a\ncommon expert (barycenter expert) and approximate the residuals between this\nbarycenter expert and the original ones. ResMoE enhances the space efficiency\nfor inference of large-scale MoE Transformers in a one-shot and data-agnostic\nmanner without retraining while maintaining minimal accuracy loss, thereby\npaving the way for broader accessibility to large language models. We\ndemonstrate the effectiveness of ResMoE through extensive experiments on Switch\nTransformer, Mixtral, and DeepSeekMoE models. The results show that ResMoE can\nreduce the number of parameters in an expert by up to 75% while maintaining\ncomparable performance. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/ResMoE.\n","authors":["Mengting Ai","Tianxin Wei","Yifan Chen","Zhichen Zeng","Ritchie Zhao","Girish Varatkar","Bita Darvish Rouhani","Xianfeng Tang","Hanghang Tong","Jingrui He"],"pdf_url":"https://arxiv.org/pdf/2503.06881v1.pdf","comment":"KDD 2025"},{"id":"http://arxiv.org/abs/2502.04684v3","updated":"2025-03-10T03:08:27Z","published":"2025-02-07T06:16:31Z","title":"G2PDiffusion: Cross-Species Genotype-to-Phenotype Prediction via\n  Evolutionary Diffusion","summary":"  Understanding how genes influence phenotype across species is a fundamental\nchallenge in genetic engineering, which will facilitate advances in various\nfields such as crop breeding, conservation biology, and personalized medicine.\nHowever, current phenotype prediction models are limited to individual species\nand expensive phenotype labeling process, making the genotype-to-phenotype\nprediction a highly domain-dependent and data-scarce problem. To this end, we\nsuggest taking images as morphological proxies, facilitating cross-species\ngeneralization through large-scale multimodal pretraining. We propose the first\ngenotype-to-phenotype diffusion model (G2PDiffusion) that generates\nmorphological images from DNA considering two critical evolutionary signals,\ni.e., multiple sequence alignments (MSA) and environmental contexts. The model\ncontains three novel components: 1) a MSA retrieval engine that identifies\nconserved and co-evolutionary patterns; 2) an environment-aware MSA conditional\nencoder that effectively models complex genotype-environment interactions; and\n3) an adaptive phenomic alignment module to improve genotype-phenotype\nconsistency. Extensive experiments show that integrating evolutionary signals\nwith environmental context enriches the model's understanding of phenotype\nvariability across species, thereby offering a valuable and promising\nexploration into advanced AI-assisted genomic analysis.\n","authors":["Mengdi Liu","Zhangyang Gao","Hong Chang","Stan Z. Li","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2502.04684v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07574v2","updated":"2025-03-10T03:04:21Z","published":"2024-10-10T03:19:46Z","title":"Gap-Dependent Bounds for Q-Learning using Reference-Advantage\n  Decomposition","summary":"  We study the gap-dependent bounds of two important algorithms for on-policy\nQ-learning for finite-horizon episodic tabular Markov Decision Processes\n(MDPs): UCB-Advantage (Zhang et al. 2020) and Q-EarlySettled-Advantage (Li et\nal. 2021). UCB-Advantage and Q-EarlySettled-Advantage improve upon the results\nbased on Hoeffding-type bonuses and achieve the almost optimal $\\sqrt{T}$-type\nregret bound in the worst-case scenario, where $T$ is the total number of\nsteps. However, the benign structures of the MDPs such as a strictly positive\nsuboptimality gap can significantly improve the regret. While gap-dependent\nregret bounds have been obtained for Q-learning with Hoeffding-type bonuses, it\nremains an open question to establish gap-dependent regret bounds for\nQ-learning using variance estimators in their bonuses and reference-advantage\ndecomposition for variance reduction. We develop a novel error decomposition\nframework to prove gap-dependent regret bounds of UCB-Advantage and\nQ-EarlySettled-Advantage that are logarithmic in $T$ and improve upon existing\nones for Q-learning algorithms. Moreover, we establish the gap-dependent bound\nfor the policy switching cost of UCB-Advantage and improve that under the\nworst-case MDPs. To our knowledge, this paper presents the first gap-dependent\nregret analysis for Q-learning using variance estimators and\nreference-advantage decomposition and also provides the first gap-dependent\nanalysis on policy switching cost for Q-learning.\n","authors":["Zhong Zheng","Haochen Zhang","Lingzhou Xue"],"pdf_url":"https://arxiv.org/pdf/2410.07574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17766v2","updated":"2025-03-10T02:58:33Z","published":"2024-11-26T05:04:38Z","title":"Integrating Dual Prototypes for Task-Wise Adaption in Pre-Trained\n  Model-Based Class-Incremental Learning","summary":"  Class-incremental learning (CIL) aims to acquire new classes while conserving\nhistorical knowledge incrementally. Despite existing pre-trained model (PTM)\nbased methods performing excellently in CIL, it is better to fine-tune them on\ndownstream incremental tasks with massive patterns unknown to PTMs. However,\nusing task streams for fine-tuning could lead to catastrophic forgetting that\nwill erase the knowledge in PTMs. This paper proposes the Dual Prototype\nnetwork for Task-wise Adaption (DPTA) of PTM-based CIL. For each incremental\nlearning task, a task-wise adapter module is built to fine-tune the PTM, where\nthe center-adapt loss forces the representation to be more centrally clustered\nand class separable. The dual prototype network improves the prediction process\nby enabling test-time adapter selection, where the raw prototypes deduce\nseveral possible task indexes of test samples to select suitable adapter\nmodules for PTM, and the augmented prototypes that could separate highly\ncorrelated classes are utilized to determine the final result. Experiments on\nseveral benchmark datasets demonstrate the state-of-the-art performance of\nDPTA. The code will be open-sourced after the paper is published.\n","authors":["Zhiming Xu","Suorong Yang","Baile Xu","Jian Zhao","Furao Shen"],"pdf_url":"https://arxiv.org/pdf/2411.17766v2.pdf","comment":"9 pages,6 figures,2 tables"},{"id":"http://arxiv.org/abs/2410.02191v2","updated":"2025-03-10T02:57:32Z","published":"2024-10-03T04:11:42Z","title":"A Survey on Point-of-Interest Recommendation: Models, Architectures, and\n  Security","summary":"  The widespread adoption of smartphones and Location-Based Social Networks has\nled to a massive influx of spatio-temporal data, creating unparalleled\nopportunities for enhancing Point-of-Interest (POI) recommendation systems.\nThese advanced POI systems are crucial for enriching user experiences, enabling\npersonalized interactions, and optimizing decision-making processes in the\ndigital landscape. However, existing surveys tend to focus on traditional\napproaches and few of them delve into cutting-edge developments, emerging\narchitectures, as well as security considerations in POI recommendations. To\naddress this gap, our survey stands out by offering a comprehensive, up-to-date\nreview of POI recommendation systems, covering advancements in models,\narchitectures, and security aspects. We systematically examine the transition\nfrom traditional models to advanced techniques such as large language models.\nAdditionally, we explore the architectural evolution from centralized to\ndecentralized and federated learning systems, highlighting the improvements in\nscalability and privacy. Furthermore, we address the increasing importance of\nsecurity, examining potential vulnerabilities and privacy-preserving\napproaches. Our taxonomy provides a structured overview of the current state of\nPOI recommendation, while we also identify promising directions for future\nresearch in this rapidly advancing field.\n","authors":["Qianru Zhang","Peng Yang","Junliang Yu","Haixin Wang","Xingwei He","Siu-Ming Yiu","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2410.02191v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2503.06873v1","updated":"2025-03-10T02:52:47Z","published":"2025-03-10T02:52:47Z","title":"Interactive Medical Image Analysis with Concept-based Similarity\n  Reasoning","summary":"  The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.\n","authors":["Ta Duc Huy","Sen Kim Tran","Phan Nguyen","Nguyen Hoang Tran","Tran Bao Sam","Anton van den Hengel","Zhibin Liao","Johan W. Verjans","Minh-Son To","Vu Minh Hieu Phan"],"pdf_url":"https://arxiv.org/pdf/2503.06873v1.pdf","comment":"Accepted CVPR2025"},{"id":"http://arxiv.org/abs/2406.13075v2","updated":"2025-03-10T02:46:14Z","published":"2024-06-18T21:48:59Z","title":"Exact Community Recovery under Side Information: Optimality of Spectral\n  Algorithms","summary":"  We study the problem of exact community recovery in general, two-community\nblock models, in the presence of node-attributed $side$ $information$. We allow\nfor a very general side information channel for node attributes, and for\npairwise (edge) observations, consider both Bernoulli and Gaussian matrix\nmodels, capturing the Stochastic Block Model, Submatrix Localization, and\n$\\mathbb{Z}_2$-Synchronization as special cases. A recent work of Dreveton et\nal. 2024 characterized the information-theoretic limit of a very general exact\nrecovery problem with side information. In this paper, we show algorithmic\nachievability in the above important cases by designing a simple but optimal\nspectral algorithm that incorporates side information (when present) along with\nthe eigenvectors of the pairwise observation matrix. Using the powerful tool of\nentrywise eigenvector analysis of Abbe et al. 2020, we show that our spectral\nalgorithm can mimic the so called $genie$-$aided$ $estimators$, where the\n$i^{\\mathrm{th}}$ genie-aided estimator optimally computes the estimate of the\n$i^{\\mathrm{th}}$ label, when all remaining labels are revealed by a genie.\nThis perspective provides a unified understanding of the optimality of spectral\nalgorithms for various exact recovery problems in a recent line of work.\n","authors":["Julia Gaudio","Nirmit Joshi"],"pdf_url":"https://arxiv.org/pdf/2406.13075v2.pdf","comment":"To appear in ICLR2025, Refurbished the results and presentation in\n  light of Dreveton et al. 2024"},{"id":"http://arxiv.org/abs/2503.06867v1","updated":"2025-03-10T02:44:11Z","published":"2025-03-10T02:44:11Z","title":"Enhancing Time Series Forecasting via Logic-Inspired Regularization","summary":"  Time series forecasting (TSF) plays a crucial role in many applications.\nTransformer-based methods are one of the mainstream techniques for TSF.\nExisting methods treat all token dependencies equally. However, we find that\nthe effectiveness of token dependencies varies across different forecasting\nscenarios, and existing methods ignore these differences, which affects their\nperformance. This raises two issues: (1) What are effective token dependencies?\n(2) How can we learn effective dependencies? From a logical perspective, we\nalign Transformer-based TSF methods with the logical framework and define\neffective token dependencies as those that ensure the tokens as atomic formulas\n(Issue 1). We then align the learning process of Transformer methods with the\nprocess of obtaining atomic formulas in logic, which inspires us to design a\nmethod for learning these effective dependencies (Issue 2). Specifically, we\npropose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method\nthat guides the model to use fewer but more effective dependencies by making\nthe attention map sparse, thereby ensuring the tokens as atomic formulas and\nimproving prediction performance. Extensive experiments and theoretical\nanalysis confirm the effectiveness of Attn-L-Reg.\n","authors":["Jianqi Zhang","Jingyao Wang","Xingchen Shen","Wenwen Qiang"],"pdf_url":"https://arxiv.org/pdf/2503.06867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15210v3","updated":"2025-03-10T02:39:40Z","published":"2024-11-20T10:41:23Z","title":"Towards Million-Scale Adversarial Robustness Evaluation With Stronger\n  Individual Attacks","summary":"  As deep learning models are increasingly deployed in safety-critical\napplications, evaluating their vulnerabilities to adversarial perturbations is\nessential for ensuring their reliability and trustworthiness. Over the past\ndecade, a large number of white-box adversarial robustness evaluation methods\n(i.e., attacks) have been proposed, ranging from single-step to multi-step\nmethods and from individual to ensemble methods. Despite these advances,\nchallenges remain in conducting meaningful and comprehensive robustness\nevaluations, particularly when it comes to large-scale testing and ensuring\nevaluations reflect real-world adversarial risks. In this work, we focus on\nimage classification models and propose a novel individual attack method,\nProbability Margin Attack (PMA), which defines the adversarial margin in the\nprobability space rather than the logits space. We analyze the relationship\nbetween PMA and existing cross-entropy or logits-margin-based attacks, and show\nthat PMA can outperform the current state-of-the-art individual methods.\nBuilding on PMA, we propose two types of ensemble attacks that balance\neffectiveness and efficiency. Furthermore, we create a million-scale dataset,\nCC1M, derived from the existing CC3M dataset, and use it to conduct the first\nmillion-scale white-box adversarial robustness evaluation of\nadversarially-trained ImageNet models. Our findings provide valuable insights\ninto the robustness gaps between individual versus ensemble attacks and\nsmall-scale versus million-scale evaluations.\n","authors":["Yong Xie","Weijie Zheng","Hanxun Huang","Guangnan Ye","Xingjun Ma"],"pdf_url":"https://arxiv.org/pdf/2411.15210v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12767v4","updated":"2025-03-10T02:11:51Z","published":"2024-02-20T07:16:12Z","title":"Nonstationary Time Series Forecasting via Unknown Distribution\n  Adaptation","summary":"  As environments evolve, temporal distribution shifts can degrade time series\nforecasting performance. A straightforward solution is to adapt to\nnonstationary changes while preserving stationary dependencies. Hence, some\nmethods disentangle stationary and nonstationary components by assuming uniform\ndistribution shifts, but it is impractical since when the distribution changes\nis unknown. To address this challenge, we propose the \\textbf{U}nknown\n\\textbf{D}istribution \\textbf{A}daptation (\\textbf{UDA}) model for\nnonstationary time series forecasting, which detects when distribution shifts\noccur and disentangles stationary/nonstationary latent variables, thus enabling\nadaptation to unknown distribution without assuming a uniform distribution\nshift. Specifically, under a Hidden Markov assumption of latent environments,\nwe demonstrate that the latent environments are identifiable. Sequentially, we\nfurther disentangle stationary/nonstationary latent variables by leveraging the\nvariability of historical information. Based on these theoretical results, we\npropose a variational autoencoder-based model, which incorporates an\nautoregressive hidden Markov model to estimate latent environments.\nAdditionally, we further devise the modular prior networks to disentangle\nstationary/nonstationary latent variables. These two modules realize automatic\nadaptation and enhance nonstationary forecasting performance. Experimental\nresults on several datasets validate the effectiveness of our approach.\n","authors":["Zijian Li","Ruichu Cai","Zhenhui Yang","Haiqin Huang","Guangyi Chen","Yifan Shen","Zhengming Chen","Xiangchen Song","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.12767v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08521v2","updated":"2025-03-10T02:01:38Z","published":"2025-01-15T02:17:38Z","title":"Mitigating Domain Shift in Federated Learning via Intra- and\n  Inter-Domain Prototypes","summary":"  Federated Learning (FL) has emerged as a decentralized machine learning\ntechnique, allowing clients to train a global model collaboratively without\nsharing private data. However, most FL studies ignore the crucial challenge of\nheterogeneous domains where each client has a distinct feature distribution,\nwhich is popular in real-world scenarios. Prototype learning, which leverages\nthe mean feature vectors within the same classes, has become a prominent\nsolution for federated learning under domain shift. However, existing federated\nprototype learning methods focus soley on inter-domain prototypes and neglect\nintra-domain perspectives. In this work, we introduce a novel federated\nprototype learning method, namely I$^2$PFL, which incorporates\n$\\textbf{I}$ntra-domain and $\\textbf{I}$nter-domain $\\textbf{P}$rototypes, to\nmitigate domain shift from both perspectives and learn a generalized global\nmodel across multiple domains in federated learning. To construct intra-domain\nprototypes, we propose feature alignment with MixUp-based augmented prototypes\nto capture the diversity within local domains and enhance the generalization of\nlocal features. Additionally, we introduce a reweighting mechanism for\ninter-domain prototypes to generate generalized prototypes that reduce domain\nshift while providing inter-domain knowledge across multiple clients. Extensive\nexperiments on the Digits, Office-10, and PACS datasets illustrate the superior\nperformance of our method compared to other baselines.\n","authors":["Huy Q. Le","Ye Lin Tun","Yu Qiao","Minh N. H. Nguyen","Keon Oh Kim","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2501.08521v2.pdf","comment":"13 pages, 11 figures, 7 tables"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2503.07493v1","updated":"2025-03-10T16:12:50Z","published":"2025-03-10T16:12:50Z","title":"V2Flow: Unifying Visual Tokenization and Large Language Model\n  Vocabularies for Autoregressive Image Generation","summary":"  We propose V2Flow, a novel tokenizer that produces discrete visual tokens\ncapable of high-fidelity reconstruction, while ensuring structural and latent\ndistribution alignment with the vocabulary space of large language models\n(LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables\nautoregressive visual generation on top of existing LLMs. Our approach\nformulates visual tokenization as a flow-matching problem, aiming to learn a\nmapping from a standard normal prior to the continuous image distribution,\nconditioned on token sequences embedded within the LLMs vocabulary space. The\neffectiveness of V2Flow stems from two core designs. First, we propose a Visual\nVocabulary resampler, which compresses visual data into compact token\nsequences, with each represented as a soft categorical distribution over LLM's\nvocabulary. This allows seamless integration of visual tokens into existing\nLLMs for autoregressive visual generation. Second, we present a masked\nautoregressive Rectified-Flow decoder, employing a masked transformer\nencoder-decoder to refine visual tokens into contextually enriched embeddings.\nThese embeddings then condition a dedicated velocity field for precise\nreconstruction. Additionally, an autoregressive rectified-flow sampling\nstrategy is incorporated, ensuring flexible sequence lengths while preserving\ncompetitive reconstruction quality. Extensive experiments show that V2Flow\noutperforms mainstream VQ-based tokenizers and facilitates autoregressive\nvisual generation on top of existing. https://github.com/zhangguiwei610/V2Flow\n","authors":["Guiwei Zhang","Tianyu Zhang","Mohan Zhou","Yalong Bai","Biye Li"],"pdf_url":"https://arxiv.org/pdf/2503.07493v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.07482v1","updated":"2025-03-10T15:58:43Z","published":"2025-03-10T15:58:43Z","title":"Efficient Membership Inference Attacks by Bayesian Neural Network","summary":"  Membership Inference Attacks (MIAs) aim to estimate whether a specific data\npoint was used in the training of a given model. Previous attacks often utilize\nmultiple reference models to approximate the conditional score distribution,\nleading to significant computational overhead. While recent work leverages\nquantile regression to estimate conditional thresholds, it fails to capture\nepistemic uncertainty, resulting in bias in low-density regions. In this work,\nwe propose a novel approach - Bayesian Membership Inference Attack (BMIA),\nwhich performs conditional attack through Bayesian inference. In particular, we\ntransform a trained reference model into Bayesian neural networks by Laplace\napproximation, enabling the direct estimation of the conditional score\ndistribution by probabilistic model parameters. Our method addresses both\nepistemic and aleatoric uncertainty with only a reference model, enabling\nefficient and powerful MIA. Extensive experiments on five datasets demonstrate\nthe effectiveness and efficiency of BMIA.\n","authors":["Zhenlong Liu","Wenyu Jiang","Feng Zhou","Hongxin Wei"],"pdf_url":"https://arxiv.org/pdf/2503.07482v1.pdf","comment":"8 pages, under review"},{"id":"http://arxiv.org/abs/2503.03245v2","updated":"2025-03-10T15:51:39Z","published":"2025-03-05T07:53:39Z","title":"Less is more? Rewards in RL for Cyber Defence","summary":"  The last few years have seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. This is especially a problem in complex cyber environments where\npolicy weaknesses may not be noticed until exploited by an adversary. In this\nwork we set out to evaluate whether sparse reward functions might enable\ntraining more effective cyber defence agents. Towards this goal we first break\ndown several evaluation limitations in existing work by proposing a ground\ntruth evaluation score that goes beyond the standard RL paradigm used to train\nand evaluate agents. By adapting a well-established cyber gym to accommodate\nour methodology and ground truth score, we propose and evaluate two sparse\nreward mechanisms and compare them with a typical dense reward. Our evaluation\nconsiders a range of network sizes, from 2 to 50 nodes, and both reactive and\nproactive defensive actions. Our results show that sparse rewards, particularly\npositive reinforcement for an uncompromised network state, enable the training\nof more effective cyber defence agents. Furthermore, we show that sparse\nrewards provide more stable training than dense rewards, and that both\neffectiveness and training stability are robust to a variety of cyber\nenvironment considerations.\n","authors":["Elizabeth Bates","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2503.03245v2.pdf","comment":"4 Pages"},{"id":"http://arxiv.org/abs/2503.07470v1","updated":"2025-03-10T15:47:01Z","published":"2025-03-10T15:47:01Z","title":"Advancing Vietnamese Information Retrieval with Learning Objective and\n  Benchmark","summary":"  With the rapid development of natural language processing, many language\nmodels have been invented for multiple tasks. One important task is information\nretrieval (IR), which requires models to retrieve relevant documents. Despite\nits importance in many real-life applications, especially in retrieval\naugmented generation (RAG) systems, this task lacks Vietnamese benchmarks. This\nsituation causes difficulty in assessing and comparing many existing Vietnamese\nembedding language models on the task and slows down the advancement of\nVietnamese natural language processing (NLP) research. In this work, we aim to\nprovide the Vietnamese research community with a new benchmark for information\nretrieval, which mainly focuses on retrieval and reranking tasks. Furthermore,\nwe also present a new objective function based on the InfoNCE loss function,\nwhich is used to train our Vietnamese embedding model. Our function aims to be\nbetter than the origin in information retrieval tasks. Finally, we analyze the\neffect of temperature, a hyper-parameter in both objective functions, on the\nperformance of text embedding models.\n","authors":["Phu-Vinh Nguyen","Minh-Nam Tran","Long Nguyen","Dien Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.07470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07459v1","updated":"2025-03-10T15:38:44Z","published":"2025-03-10T15:38:44Z","title":"MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for\n  Complex Medical Reasoning","summary":"  Large Language Models (LLMs) have shown impressive performance on existing\nmedical question-answering benchmarks. This high performance makes it\nincreasingly difficult to meaningfully evaluate and differentiate advanced\nmethods. We present MedAgentsBench, a benchmark that focuses on challenging\nmedical questions requiring multi-step clinical reasoning, diagnosis\nformulation, and treatment planning-scenarios where current models still\nstruggle despite their strong performance on standard tests. Drawing from seven\nestablished medical datasets, our benchmark addresses three key limitations in\nexisting evaluations: (1) the prevalence of straightforward questions where\neven base models achieve high performance, (2) inconsistent sampling and\nevaluation protocols across studies, and (3) lack of systematic analysis of the\ninterplay between performance, cost, and inference time. Through experiments\nwith various base models and reasoning methods, we demonstrate that the latest\nthinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in\ncomplex medical reasoning tasks. Additionally, advanced search-based agent\nmethods offer promising performance-to-cost ratios compared to traditional\napproaches. Our analysis reveals substantial performance gaps between model\nfamilies on complex questions and identifies optimal model selections for\ndifferent computational constraints. Our benchmark and evaluation framework are\npublicly available at https://github.com/gersteinlab/medagents-benchmark.\n","authors":["Xiangru Tang","Daniel Shao","Jiwoong Sohn","Jiapeng Chen","Jiayi Zhang","Jinyu Xiang","Fang Wu","Yilun Zhao","Chenglin Wu","Wenqi Shi","Arman Cohan","Mark Gerstein"],"pdf_url":"https://arxiv.org/pdf/2503.07459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07453v1","updated":"2025-03-10T15:31:42Z","published":"2025-03-10T15:31:42Z","title":"Is a Good Foundation Necessary for Efficient Reinforcement Learning? The\n  Computational Role of the Base Model in Exploration","summary":"  Language model alignment (or, reinforcement learning) techniques that\nleverage active exploration -- deliberately encouraging the model to produce\ndiverse, informative responses -- offer the promise of super-human\ncapabilities. However, current understanding of algorithm design primitives for\ncomputationally efficient exploration with language models is limited. To\nbetter understand how to leverage access to powerful pre-trained generative\nmodels to improve the efficiency of exploration, we introduce a new\ncomputational framework for RL with language models, in which the learner\ninteracts with the model through a sampling oracle. Focusing on the linear\nsoftmax model parameterization, we provide new results that reveal the\ncomputational-statistical tradeoffs of efficient exploration:\n  1. Necessity of coverage: Coverage refers to the extent to which the\npre-trained model covers near-optimal responses -- a form of hidden knowledge.\nWe show that coverage, while not necessary for data efficiency, lower bounds\nthe runtime of any algorithm in our framework.\n  2. Inference-time exploration: We introduce a new algorithm, SpannerSampling,\nwhich obtains optimal data efficiency and is computationally efficient whenever\nthe pre-trained model enjoys sufficient coverage, matching our lower bound.\nSpannerSampling leverages inference-time computation with the pre-trained model\nto reduce the effective search space for exploration.\n  3. Insufficiency of training-time interventions: We contrast the result above\nby showing that training-time interventions that produce proper policies cannot\nachieve similar guarantees in polynomial time.\n  4. Computational benefits of multi-turn exploration: Finally, we show that\nunder additional representational assumptions, one can achieve improved runtime\n(replacing sequence-level coverage with token-level coverage) through\nmulti-turn exploration.\n","authors":["Dylan J. Foster","Zakaria Mhammedi","Dhruv Rohatgi"],"pdf_url":"https://arxiv.org/pdf/2503.07453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07450v1","updated":"2025-03-10T15:30:05Z","published":"2025-03-10T15:30:05Z","title":"From Idea to Implementation: Evaluating the Influence of Large Language\n  Models in Software Development -- An Opinion Paper","summary":"  The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted.\n","authors":["Sargam Yadav","Asifa Mehmood Qureshi","Abhishek Kaushik","Shubham Sharma","Roisin Loughran","Subramaniam Kazhuparambil","Andrew Shaw","Mohammed Sabry","Niamh St John Lynch",". Nikhil Singh","Padraic O'Hara","Pranay Jaiswal","Roshan Chandru","David Lillis"],"pdf_url":"https://arxiv.org/pdf/2503.07450v1.pdf","comment":"The project is partially supported by the DkIT Postgraduate\n  Scholarship, Research Ireland under Grant number 13/RC/2094_2, and Grant\n  number 21/FFP-A/925"},{"id":"http://arxiv.org/abs/2503.07444v1","updated":"2025-03-10T15:24:36Z","published":"2025-03-10T15:24:36Z","title":"Divide and Conquer Self-Supervised Learning for High-Content Imaging","summary":"  Self-supervised representation learning methods often fail to learn subtle or\ncomplex features, which can be dominated by simpler patterns which are much\neasier to learn. This limitation is particularly problematic in applications to\nscience and engineering, as complex features can be critical for discovery and\nanalysis. To address this, we introduce Split Component Embedding Registration\n(SpliCER), a novel architecture which splits the image into sections and\ndistils information from each section to guide the model to learn more subtle\nand complex features without compromising on simpler features. SpliCER is\ncompatible with any self-supervised loss function and can be integrated into\nexisting methods without modification. The primary contributions of this work\nare as follows: i) we demonstrate that existing self-supervised methods can\nlearn shortcut solutions when simple and complex features are both present; ii)\nwe introduce a novel self-supervised training method, SpliCER, to overcome the\nlimitations of existing methods, and achieve significant downstream performance\nimprovements; iii) we demonstrate the effectiveness of SpliCER in cutting-edge\nmedical and geospatial imaging settings. SpliCER offers a powerful new tool for\nrepresentation learning, enabling models to uncover complex features which\ncould be overlooked by other methods.\n","authors":["Lucas Farndale","Paul Henderson","Edward W Roberts","Ke Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.07444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07429v1","updated":"2025-03-10T15:13:38Z","published":"2025-03-10T15:13:38Z","title":"From Text to Visuals: Using LLMs to Generate Math Diagrams with Vector\n  Graphics","summary":"  Advances in large language models (LLMs) offer new possibilities for\nenhancing math education by automating support for both teachers and students.\nWhile prior work has focused on generating math problems and high-quality\ndistractors, the role of visualization in math learning remains under-explored.\nDiagrams are essential for mathematical thinking and problem-solving, yet\nmanually creating them is time-consuming and requires domain-specific\nexpertise, limiting scalability. Recent research on using LLMs to generate\nScalable Vector Graphics (SVG) presents a promising approach to automating\ndiagram creation. Unlike pixel-based images, SVGs represent geometric figures\nusing XML, allowing seamless scaling and adaptability. Educational platforms\nsuch as Khan Academy and IXL already use SVGs to display math problems and\nhints. In this paper, we explore the use of LLMs to generate math-related\ndiagrams that accompany textual hints via intermediate SVG representations. We\naddress three research questions: (1) how to automatically generate math\ndiagrams in problem-solving hints and evaluate their quality, (2) whether SVG\nis an effective intermediate representation for math diagrams, and (3) what\nprompting strategies and formats are required for LLMs to generate accurate\nSVG-based diagrams. Our contributions include defining the task of\nautomatically generating SVG-based diagrams for math hints, developing an LLM\nprompting-based pipeline, and identifying key strategies for improving diagram\ngeneration. Additionally, we introduce a Visual Question Answering-based\nevaluation setup and conduct ablation studies to assess different pipeline\nvariations. By automating the math diagram creation, we aim to provide students\nand teachers with accurate, conceptually relevant visual aids that enhance\nproblem-solving and learning experiences.\n","authors":["Jaewook Lee","Jeongah Lee","Wanyong Feng","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2503.07429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07426v1","updated":"2025-03-10T15:11:07Z","published":"2025-03-10T15:11:07Z","title":"RePO: ReLU-based Preference Optimization","summary":"  Aligning large language models (LLMs) with human preferences is critical for\nreal-world deployment, yet existing methods like RLHF face computational and\nstability challenges. While DPO establishes an offline paradigm with single\nhyperparameter $\\beta$, subsequent methods like SimPO reintroduce complexity\nthrough dual parameters ($\\beta$, $\\gamma$). We propose {ReLU-based Preference\nOptimization (RePO)}, a streamlined algorithm that eliminates $\\beta$ via two\nadvances: (1) retaining SimPO's reference-free margins but removing $\\beta$\nthrough gradient analysis, and (2) adopting a ReLU-based max-margin loss that\nnaturally filters trivial pairs. Theoretically, RePO is characterized as\nSimPO's limiting case ($\\beta \\to \\infty$), where the logistic weighting\ncollapses to binary thresholding, forming a convex envelope of the 0-1 loss.\nEmpirical results on AlpacaEval 2 and Arena-Hard show that RePO outperforms DPO\nand SimPO across multiple base models, requiring only one hyperparameter to\ntune.\n","authors":["Junkang Wu","Kexin Huang","Xue Wang","Jinyang Gao","Bolin Ding","Jiancan Wu","Xiangnan He","Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20317v3","updated":"2025-03-10T14:43:15Z","published":"2025-02-27T17:42:52Z","title":"Mixture of Structural-and-Textual Retrieval over Text-rich Graph\n  Knowledge Bases","summary":"  Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for\nanswering queries by providing textual and structural knowledge. However,\ncurrent retrieval methods often retrieve these two types of knowledge in\nisolation without considering their mutual reinforcement and some hybrid\nmethods even bypass structural retrieval entirely after neighboring\naggregation. To fill in this gap, we propose a Mixture of\nStructural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge\nvia a Planning-Reasoning-Organizing framework. In the Planning stage, MoR\ngenerates textual planning graphs delineating the logic for answering queries.\nFollowing planning graphs, in the Reasoning stage, MoR interweaves structural\ntraversal and textual matching to obtain candidates from TG-KBs. In the\nOrganizing stage, MoR further reranks fetched candidates based on their\nstructural trajectory. Extensive experiments demonstrate the superiority of MoR\nin harmonizing structural and textual retrieval with insights, including uneven\nretrieving performance across different query logics and the benefits of\nintegrating structural trajectories for candidate reranking. Our code is\navailable at https://github.com/Yoega/MoR.\n","authors":["Yongjia Lei","Haoyu Han","Ryan A. Rossi","Franck Dernoncourt","Nedim Lipka","Mahantesh M Halappanavar","Jiliang Tang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20317v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07396v1","updated":"2025-03-10T14:42:51Z","published":"2025-03-10T14:42:51Z","title":"Brain Inspired Adaptive Memory Dual-Net for Few-Shot Image\n  Classification","summary":"  Few-shot image classification has become a popular research topic for its\nwide application in real-world scenarios, however the problem of supervision\ncollapse induced by single image-level annotation remains a major challenge.\nExisting methods aim to tackle this problem by locating and aligning relevant\nlocal features. However, the high intra-class variability in real-world images\nposes significant challenges in locating semantically relevant local regions\nunder few-shot settings. Drawing inspiration from the human's complementary\nlearning system, which excels at rapidly capturing and integrating semantic\nfeatures from limited examples, we propose the generalization-optimized Systems\nConsolidation Adaptive Memory Dual-Network, SCAM-Net. This approach simulates\nthe systems consolidation of complementary learning system with an adaptive\nmemory module, which successfully addresses the difficulty of identifying\nmeaningful features in few-shot scenarios. Specifically, we construct a\nHippocampus-Neocortex dual-network that consolidates structured representation\nof each category, the structured representation is then stored and adaptively\nregulated following the generalization optimization principle in a long-term\nmemory inside Neocortex. Extensive experiments on benchmark datasets show that\nthe proposed model has achieved state-of-the-art performance.\n","authors":["Kexin Di","Xiuxing Li","Yuyang Han","Ziyu Li","Qing Li","Xia Wu"],"pdf_url":"https://arxiv.org/pdf/2503.07396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07389v1","updated":"2025-03-10T14:37:53Z","published":"2025-03-10T14:37:53Z","title":"TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image\n  Diffusion Models","summary":"  Recent advances in text-to-image diffusion models enable photorealistic image\ngeneration, but they also risk producing malicious content, such as NSFW\nimages. To mitigate risk, concept erasure methods are studied to facilitate the\nmodel to unlearn specific concepts. However, current studies struggle to fully\nerase malicious concepts implicitly embedded in prompts (e.g., metaphorical\nexpressions or adversarial prompts) while preserving the model's normal\ngeneration capability. To address this challenge, our study proposes TRCE,\nusing a two-stage concept erasure strategy to achieve an effective trade-off\nbetween reliable erasure and knowledge preservation. Firstly, TRCE starts by\nerasing the malicious semantics implicitly embedded in textual prompts. By\nidentifying a critical mapping objective(i.e., the [EoT] embedding), we\noptimize the cross-attention layers to map malicious prompts to contextually\nsimilar prompts but with safe concepts. This step prevents the model from being\noverly influenced by malicious semantics during the denoising process.\nFollowing this, considering the deterministic properties of the sampling\ntrajectory of the diffusion model, TRCE further steers the early denoising\nprediction toward the safe direction and away from the unsafe one through\ncontrastive learning, thus further avoiding the generation of malicious\ncontent. Finally, we conduct comprehensive evaluations of TRCE on multiple\nmalicious concept erasure benchmarks, and the results demonstrate its\neffectiveness in erasing malicious concepts while better preserving the model's\noriginal generation ability. The code is available at:\nhttp://github.com/ddgoodgood/TRCE. CAUTION: This paper includes model-generated\ncontent that may contain offensive material.\n","authors":["Ruidong Chen","Honglin Guo","Lanjun Wang","Chenyu Zhang","Weizhi Nie","An-An Liu"],"pdf_url":"https://arxiv.org/pdf/2503.07389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07384v1","updated":"2025-03-10T14:32:56Z","published":"2025-03-10T14:32:56Z","title":"Is My Text in Your AI Model? Gradient-based Membership Inference Test\n  applied to LLMs","summary":"  This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.\n","authors":["Gonzalo Mancera","Daniel de Alcala","Julian Fierrez","Ruben Tolosana","Aythami Morales"],"pdf_url":"https://arxiv.org/pdf/2503.07384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05139v2","updated":"2025-03-10T14:21:21Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2503.07364v1","updated":"2025-03-10T14:20:58Z","published":"2025-03-10T14:20:58Z","title":"Artificial Utopia: Simulation and Intelligent Agents for a Democratised\n  Future","summary":"  Prevailing top-down systems in politics and economics struggle to keep pace\nwith the pressing challenges of the 21st century, such as climate change,\nsocial inequality and conflict. Bottom-up democratisation and participatory\napproaches in politics and economics are increasingly seen as promising\nalternatives to confront and overcome these issues, often with utopian\novertones, as proponents believe they may dramatically reshape political,\nsocial and ecological futures for the better and in contrast to contemporary\nauthoritarian tendencies across various countries. Institutional specifics and\nthe associated collective human behavior or culture remains little understood\nand debated, however. In this article, I propose a novel research agenda\nfocusing on utopian democratisation efforts with formal and computational\nmethods as well as with artificial intelligence - I call this agenda Artificial\nUtopia. Artificial Utopias provide safe testing grounds for new political ideas\nand economic policies in-silico with reduced risk of negative consequences as\ncompared to testing ideas in real-world contexts. An increasing number of\nadvanced simulation and intelligence methods, that aim at representing human\ncognition and collective decision-making in more realistic ways, could benefit\nthis process. This includes agent-based modelling, reinforcement learning,\nlarge language models and more. I clarify what some of these simulation\napproaches can contribute to the study of Artificial Utopias with the help of\ntwo institutional examples: the citizen assembly and the democratic firm.\n","authors":["Yannick Oswald"],"pdf_url":"https://arxiv.org/pdf/2503.07364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07351v1","updated":"2025-03-10T14:06:58Z","published":"2025-03-10T14:06:58Z","title":"Encoding Argumentation Frameworks to Propositional Logic Systems","summary":"  The theory of argumentation frameworks ($AF$s) has been a useful tool for\nartificial intelligence. The research of the connection between $AF$s and logic\nis an important branch. This paper generalizes the encoding method by encoding\n$AF$s as logical formulas in different propositional logic systems. It studies\nthe relationship between models of an AF by argumentation semantics, including\nDung's classical semantics and Gabbay's equational semantics, and models of the\nencoded formulas by semantics of propositional logic systems. Firstly, we\nsupplement the proof of the regular encoding function in the case of encoding\n$AF$s to the 2-valued propositional logic system. Then we encode $AF$s to\n3-valued propositional logic systems and fuzzy propositional logic systems and\nexplore the model relationship. This paper enhances the connection between\n$AF$s and propositional logic systems. It also provides a new way to construct\nnew equational semantics by choosing different fuzzy logic operations.\n","authors":["Shuai Tang","Jiachao Wu","Ning Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07351v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2503.07341v1","updated":"2025-03-10T13:53:39Z","published":"2025-03-10T13:53:39Z","title":"The Economics of p(doom): Scenarios of Existential Risk and Economic\n  Growth in the Age of Transformative AI","summary":"  Recent advances in artificial intelligence (AI) have led to a diverse set of\npredictions about its long-term impact on humanity. A central focus is the\npotential emergence of transformative AI (TAI), eventually capable of\noutperforming humans in all economically valuable tasks and fully automating\nlabor. Discussed scenarios range from human extinction after a misaligned TAI\ntakes over (\"AI doom\") to unprecedented economic growth and abundance\n(\"post-scarcity\"). However, the probabilities and implications of these\nscenarios remain highly uncertain. Here, we organize the various scenarios and\nevaluate their associated existential risks and economic outcomes in terms of\naggregate welfare. Our analysis shows that even low-probability catastrophic\noutcomes justify large investments in AI safety and alignment research. We find\nthat the optimizing representative individual would rationally allocate\nsubstantial resources to mitigate extinction risk; in some cases, she would\nprefer not to develop TAI at all. This result highlights that current global\nefforts in AI safety and alignment research are vastly insufficient relative to\nthe scale and urgency of existential risks posed by TAI. Our findings therefore\nunderscore the need for stronger safeguards to balance the potential economic\nbenefits of TAI with the prevention of irreversible harm. Addressing these\nrisks is crucial for steering technological progress toward sustainable human\nprosperity.\n","authors":["Jakub Growiec","Klaus Prettner"],"pdf_url":"https://arxiv.org/pdf/2503.07341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07340v1","updated":"2025-03-10T13:53:22Z","published":"2025-03-10T13:53:22Z","title":"Research and Design on Intelligent Recognition of Unordered Targets for\n  Robots Based on Reinforcement Learning","summary":"  In the field of robot target recognition research driven by artificial\nintelligence (AI), factors such as the disordered distribution of targets, the\ncomplexity of the environment, the massive scale of data, and noise\ninterference have significantly restricted the improvement of target\nrecognition accuracy. Against the backdrop of the continuous iteration and\nupgrading of current AI technologies, to meet the demand for accurate\nrecognition of disordered targets by intelligent robots in complex and\nchangeable scenarios, this study innovatively proposes an AI - based\nintelligent robot disordered target recognition method using reinforcement\nlearning. This method processes the collected target images with the bilateral\nfiltering algorithm, decomposing them into low - illumination images and\nreflection images. Subsequently, it adopts differentiated AI strategies,\ncompressing the illumination images and enhancing the reflection images\nrespectively, and then fuses the two parts of images to generate a new image.\nOn this basis, this study deeply integrates deep learning, a core AI\ntechnology, with the reinforcement learning algorithm. The enhanced target\nimages are input into a deep reinforcement learning model for training,\nultimately enabling the AI - based intelligent robot to efficiently recognize\ndisordered targets. Experimental results show that the proposed method can not\nonly significantly improve the quality of target images but also enable the AI\n- based intelligent robot to complete the recognition task of disordered\ntargets with higher efficiency and accuracy, demonstrating extremely high\napplication value and broad development prospects in the field of AI robots.\n","authors":["Yiting Mao","Dajun Tao","Shengyuan Zhang","Tian Qi","Keqin Li"],"pdf_url":"https://arxiv.org/pdf/2503.07340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07338v1","updated":"2025-03-10T13:50:23Z","published":"2025-03-10T13:50:23Z","title":"Temporal Triplane Transformers as Occupancy World Models","summary":"  Recent years have seen significant advances in world models, which primarily\nfocus on learning fine-grained correlations between an agent's motion\ntrajectory and the resulting changes in its surrounding environment. However,\nexisting methods often struggle to capture such fine-grained correlations and\nachieve real-time predictions. To address this, we propose a new 4D occupancy\nworld model for autonomous driving, termed T$^3$Former. T$^3$Former begins by\npre-training a compact triplane representation that efficiently compresses the\n3D semantically occupied environment. Next, T$^3$Former extracts multi-scale\ntemporal motion features from the historical triplane and employs an\nautoregressive approach to iteratively predict the next triplane changes.\nFinally, T$^3$Former combines the triplane changes with the previous ones to\ndecode them into future occupancy results and ego-motion trajectories.\nExperimental results demonstrate the superiority of T$^3$Former, achieving\n1.44$\\times$ faster inference speed (26 FPS), while improving the mean IoU to\n36.09 and reducing the mean absolute planning error to 1.0 meters.\n","authors":["Haoran Xu","Peixi Peng","Guang Tan","Yiqian Chang","Yisen Zhao","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2503.07338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07330v1","updated":"2025-03-10T13:42:41Z","published":"2025-03-10T13:42:41Z","title":"Mitigating Hallucinations in YOLO-based Object Detection Models: A\n  Revisit to Out-of-Distribution Detection","summary":"  Object detection systems must reliably perceive objects of interest without\nbeing overly confident to ensure safe decision-making in dynamic environments.\nFiltering techniques based on out-of-distribution (OoD) detection are commonly\nadded as an extra safeguard to filter hallucinations caused by overconfidence\nin novel objects. Nevertheless, evaluating YOLO-family detectors and their\nfilters under existing OoD benchmarks often leads to unsatisfactory\nperformance. This paper studies the underlying reasons for performance\nbottlenecks and proposes a methodology to improve performance fundamentally.\nOur first contribution is a calibration of all existing evaluation results:\nAlthough images in existing OoD benchmark datasets are claimed not to have\nobjects within in-distribution (ID) classes (i.e., categories defined in the\ntraining dataset), around 13% of objects detected by the object detector are\nactually ID objects. Dually, the ID dataset containing OoD objects can also\nnegatively impact the decision boundary of filters. These ultimately lead to a\nsignificantly imprecise performance estimation. Our second contribution is to\nconsider the task of hallucination reduction as a joint pipeline of detectors\nand filters. By developing a methodology to carefully synthesize an OoD dataset\nthat semantically resembles the objects to be detected, and using the crafted\nOoD dataset in the fine-tuning of YOLO detectors to suppress the objectness\nscore, we achieve a 88% reduction in overall hallucination error with a\ncombined fine-tuned detection and filtering system on the self-driving\nbenchmark BDD-100K. Our code and dataset are available at:\nhttps://gricad-gitlab.univ-grenoble-alpes.fr/dnn-safety/m-hood.\n","authors":["Weicheng He","Changshun Wu","Chih-Hong Cheng","Xiaowei Huang","Saddek Bensalem"],"pdf_url":"https://arxiv.org/pdf/2503.07330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07329v1","updated":"2025-03-10T13:42:04Z","published":"2025-03-10T13:42:04Z","title":"Assessing the Macro and Micro Effects of Random Seeds on Fine-Tuning\n  Large Language Models","summary":"  The impact of random seeds in fine-tuning large language models (LLMs) has\nbeen largely overlooked despite its potential influence on model performance.In\nthis study, we systematically evaluate the effects of random seeds on LLMs\nusing the GLUE and SuperGLUE benchmarks. We analyze the macro-level impact\nthrough traditional metrics like accuracy and F1, calculating their mean and\nvariance to quantify performance fluctuations. To capture the micro-level\neffects, we introduce a novel metric, consistency, measuring the stability of\nindividual predictions across runs. Our experiments reveal significant variance\nat both macro and micro levels, underscoring the need for careful consideration\nof random seeds in fine-tuning and evaluation.\n","authors":["Hao Zhou","Guergana Savova","Lijing Wang"],"pdf_url":"https://arxiv.org/pdf/2503.07329v1.pdf","comment":"7 pages, 5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2503.07326v1","updated":"2025-03-10T13:40:28Z","published":"2025-03-10T13:40:28Z","title":"AI Biases as Asymmetries: A Review to Guide Practice","summary":"  The understanding of bias in AI is currently undergoing a revolution.\nInitially understood as errors or flaws, biases are increasingly recognized as\nintegral to AI systems and sometimes preferable to less biased alternatives. In\nthis paper, we review the reasons for this changed understanding and provide\nnew guidance on two questions: First, how should we think about and measure\nbiases in AI systems, consistent with the new understanding? Second, what kinds\nof bias in an AI system should we accept or even amplify, and what kinds should\nwe minimize or eliminate, and why? The key to answering both questions, we\nargue, is to understand biases as \"violations of a symmetry standard\"\n(following Kelly). We distinguish three main types of asymmetry in AI\nsystems-error biases, inequality biases, and process biases-and highlight\nplaces in the pipeline of AI development and application where bias of each\ntype is likely to be good, bad, or inevitable.\n","authors":["Gabriella Waters","Phillip Honenberger"],"pdf_url":"https://arxiv.org/pdf/2503.07326v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2503.07323v1","updated":"2025-03-10T13:39:09Z","published":"2025-03-10T13:39:09Z","title":"Dynamic Path Navigation for Motion Agents with LLM Reasoning","summary":"  Large Language Models (LLMs) have demonstrated strong generalizable reasoning\nand planning capabilities. However, their efficacies in spatial path planning\nand obstacle-free trajectory generation remain underexplored. Leveraging LLMs\nfor navigation holds significant potential, given LLMs' ability to handle\nunseen scenarios, support user-agent interactions, and provide global control\nacross complex systems, making them well-suited for agentic planning and\nhumanoid motion generation. As one of the first studies in this domain, we\nexplore the zero-shot navigation and path generation capabilities of LLMs by\nconstructing a dataset and proposing an evaluation protocol. Specifically, we\nrepresent paths using anchor points connected by straight lines, enabling\nmovement in various directions. This approach offers greater flexibility and\npracticality compared to previous methods while remaining simple and intuitive\nfor LLMs. We demonstrate that, when tasks are well-structured in this manner,\nmodern LLMs exhibit substantial planning proficiency in avoiding obstacles\nwhile autonomously refining navigation with the generated motion to reach the\ntarget. Further, this spatial reasoning ability of a single LLM motion agent\ninteracting in a static environment can be seamlessly generalized in\nmulti-motion agents coordination in dynamic environments. Unlike traditional\napproaches that rely on single-step planning or local policies, our\ntraining-free LLM-based method enables global, dynamic, closed-loop planning,\nand autonomously resolving collision issues.\n","authors":["Yubo Zhao","Qi Wu","Yifan Wang","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2503.07323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07320v1","updated":"2025-03-10T13:37:36Z","published":"2025-03-10T13:37:36Z","title":"Experimental Exploration: Investigating Cooperative Interaction Behavior\n  Between Humans and Large Language Model Agents","summary":"  With the rise of large language models (LLMs), AI agents as autonomous\ndecision-makers present significant opportunities and challenges for human-AI\ncooperation. While many studies have explored human cooperation with AI as\ntools, the role of LLM-augmented autonomous agents in competitive-cooperative\ninteractions remains under-examined. This study investigates human cooperative\nbehavior by engaging 30 participants who interacted with LLM agents exhibiting\ndifferent characteristics (purported human, purported rule-based AI agent, and\nLLM agent) in repeated Prisoner's Dilemma games. Findings show significant\ndifferences in cooperative behavior based on the agents' purported\ncharacteristics and the interaction effect of participants' genders and\npurported characteristics. We also analyzed human response patterns, including\ngame completion time, proactive favorable behavior, and acceptance of repair\nefforts. These insights offer a new perspective on human interactions with LLM\nagents in competitive cooperation contexts, such as virtual avatars or future\nphysical entities. The study underscores the importance of understanding human\nbiases toward AI agents and how observed behaviors can influence future\nhuman-AI cooperation dynamics.\n","authors":["Guanxuan Jiang","Yuyang Wang","Pan Hui"],"pdf_url":"https://arxiv.org/pdf/2503.07320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07319v1","updated":"2025-03-10T13:36:36Z","published":"2025-03-10T13:36:36Z","title":"Human Machine Co-Adaptation Model and Its Convergence Analysis","summary":"  The key to robot-assisted rehabilitation lies in the design of the\nhuman-machine interface, which must accommodate the needs of both patients and\nmachines. Current interface designs primarily focus on machine control\nalgorithms, often requiring patients to spend considerable time adapting. In\nthis paper, we introduce a novel approach based on the Cooperative Adaptive\nMarkov Decision Process (CAMDPs) model to address the fundamental aspects of\nthe interactive learning process, offering theoretical insights and practical\nguidance. We establish sufficient conditions for the convergence of CAMDPs and\nensure the uniqueness of Nash equilibrium points. Leveraging these conditions,\nwe guarantee the system's convergence to a unique Nash equilibrium point.\nFurthermore, we explore scenarios with multiple Nash equilibrium points,\ndevising strategies to adjust both Value Evaluation and Policy Improvement\nalgorithms to enhance the likelihood of converging to the global minimal Nash\nequilibrium point. Through numerical experiments, we illustrate the\neffectiveness of the proposed conditions and algorithms, demonstrating their\napplicability and robustness in practical settings. The proposed conditions for\nconvergence and the identification of a unique optimal Nash equilibrium\ncontribute to the development of more effective adaptive systems for human\nusers in robot-assisted rehabilitation.\n","authors":["Steven W. Su","Yaqi Li","Kairui Guo","Rob Duffield"],"pdf_url":"https://arxiv.org/pdf/2503.07319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07317v1","updated":"2025-03-10T13:35:51Z","published":"2025-03-10T13:35:51Z","title":"Self-Corrective Task Planning by Inverse Prompting with Large Language\n  Models","summary":"  In robot task planning, large language models (LLMs) have shown significant\npromise in generating complex and long-horizon action sequences. However, it is\nobserved that LLMs often produce responses that sound plausible but are not\naccurate. To address these problems, existing methods typically employ\npredefined error sets or external knowledge sources, requiring human efforts\nand computation resources. Recently, self-correction approaches have emerged,\nwhere LLM generates and refines plans, identifying errors by itself. Despite\ntheir effectiveness, they are more prone to failures in correction due to\ninsufficient reasoning. In this paper, we introduce InversePrompt, a novel\nself-corrective task planning approach that leverages inverse prompting to\nenhance interpretability. Our method incorporates reasoning steps to provide\nclear, interpretable feedback. It generates inverse actions corresponding to\nthe initially generated actions and verifies whether these inverse actions can\nrestore the system to its original state, explicitly validating the logical\ncoherence of the generated plans.The results on benchmark datasets show an\naverage 16.3% higher success rate over existing LLM-based task planning\nmethods. Our approach offers clearer justifications for feedback in real-world\nenvironments, resulting in more successful task completion than existing\nself-correction approaches across various scenarios.\n","authors":["Jiho Lee","Hayun Lee","Jonghyeon Kim","Kyungjae Lee","Eunwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2503.07317v1.pdf","comment":"7 pages, 5 figures, IEEE International Conference on Robotics and\n  Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2503.07315v1","updated":"2025-03-10T13:34:18Z","published":"2025-03-10T13:34:18Z","title":"Group-robust Sample Reweighting for Subpopulation Shifts via Influence\n  Functions","summary":"  Machine learning models often have uneven performance among subpopulations\n(a.k.a., groups) in the data distributions. This poses a significant challenge\nfor the models to generalize when the proportions of the groups shift during\ndeployment. To improve robustness to such shifts, existing approaches have\ndeveloped strategies that train models or perform hyperparameter tuning using\nthe group-labeled data to minimize the worst-case loss over groups. However, a\nnon-trivial amount of high-quality labels is often required to obtain\nnoticeable improvements. Given the costliness of the labels, we propose to\nadopt a different paradigm to enhance group label efficiency: utilizing the\ngroup-labeled data as a target set to optimize the weights of other\ngroup-unlabeled data. We introduce Group-robust Sample Reweighting (GSR), a\ntwo-stage approach that first learns the representations from group-unlabeled\ndata, and then tinkers the model by iteratively retraining its last layer on\nthe reweighted data using influence functions. Our GSR is theoretically sound,\npractically lightweight, and effective in improving the robustness to\nsubpopulation shifts. In particular, GSR outperforms the previous\nstate-of-the-art approaches that require the same amount or even more group\nlabels.\n","authors":["Rui Qiao","Zhaoxuan Wu","Jingtan Wang","Pang Wei Koh","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2503.07315v1.pdf","comment":"Accepted to the 13th International Conference on Learning\n  Representations (ICLR 2025). Code is available at\n  https://github.com/qiaoruiyt/GSR"},{"id":"http://arxiv.org/abs/2502.06096v2","updated":"2025-03-10T13:20:58Z","published":"2025-02-10T02:01:30Z","title":"Post-detection inference for sequential changepoint localization","summary":"  This paper addresses a fundamental but largely unexplored challenge in\nsequential changepoint analysis: conducting inference following a detected\nchange. We study the problem of localizing the changepoint using only the data\nobserved up to a data-dependent stopping time at which a sequential detection\nalgorithm $\\mathcal A$ declares a change. We first construct confidence sets\nfor the unknown changepoint when pre- and post-change distributions are assumed\nto be known. We then extend our framework to composite pre- and post-change\nscenarios. We impose no conditions on the observation space or on $\\mathcal A$\n-- we only need to be able to run $\\mathcal A$ on simulated data sequences. In\nsummary, this work offers both theoretically sound and practically effective\ntools for sequential changepoint localization.\n","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2502.06096v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07294v1","updated":"2025-03-10T13:16:48Z","published":"2025-03-10T13:16:48Z","title":"Distilling Knowledge into Quantum Vision Transformers for Biomedical\n  Image Classification","summary":"  Quantum vision transformers (QViTs) build on vision transformers (ViTs) by\nreplacing linear layers within the self-attention mechanism with parameterised\nquantum neural networks (QNNs), harnessing quantum mechanical properties to\nimprove feature representation. This hybrid approach aims to achieve superior\nperformance, with significantly reduced model complexity as a result of the\nenriched feature representation, requiring fewer parameters. This paper\nproposes a novel QViT model for biomedical image classification and\ninvestigates its performance against comparable ViTs across eight diverse\ndatasets, encompassing various modalities and classification tasks. We assess\nmodels trained from scratch and those pre-trained using knowledge distillation\n(KD) from high-quality teacher models. Our findings demonstrate that QViTs\noutperform comparable ViTs with average ROC AUC (0.863 vs 0.846) and accuracy\n(0.710 vs 0.687) when trained from scratch, and even compete with\nstate-of-the-art classical models in multiple tasks, whilst being significantly\nmore efficient (89% reduction in GFLOPs and 99.99% in parameter number).\nAdditionally, we find that QViTs and ViTs respond equally well to KD, with QViT\npre-training performance scaling with model complexity. This is the first\ninvestigation into the efficacy of deploying QViTs with KD for computer-aided\ndiagnosis. Our results highlight the enormous potential of quantum machine\nlearning (QML) in biomedical image analysis.\n","authors":["Thomas Boucher","Evangelos B. Mazomenos"],"pdf_url":"https://arxiv.org/pdf/2503.07294v1.pdf","comment":"Submitted for MICCAI 2025"},{"id":"http://arxiv.org/abs/2503.04479v2","updated":"2025-03-10T13:01:58Z","published":"2025-03-06T14:29:52Z","title":"ToolFuzz -- Automated Agent Tool Testing","summary":"  Large Language Model (LLM) Agents leverage the advanced reasoning\ncapabilities of LLMs in real-world applications. To interface with an\nenvironment, these agents often rely on tools, such as web search or database\nAPIs. As the agent provides the LLM with tool documentation along the user\nquery, the completeness and correctness of this documentation is critical.\nHowever, tool documentation is often over-, under-, or ill-specified, impeding\nthe agent's accuracy. Standard software testing approaches struggle to identify\nthese errors as they are expressed in natural language. Thus, despite its\nimportance, there currently exists no automated method to test the tool\ndocumentation for agents. To address this issue, we present ToolFuzz, the first\nmethod for automated testing of tool documentations. ToolFuzz is designed to\ndiscover two types of errors: (1) user queries leading to tool runtime errors\nand (2) user queries that lead to incorrect agent responses. ToolFuzz can\ngenerate a large and diverse set of natural inputs, effectively finding tool\ndescription errors at a low false positive rate. Further, we present two\nstraightforward prompt-engineering approaches. We evaluate all three tool\ntesting approaches on 32 common LangChain tools and 35 newly created custom\ntools and 2 novel benchmarks to further strengthen the assessment. We find that\nmany publicly available tools suffer from underspecification. Specifically, we\nshow that ToolFuzz identifies 20x more erroneous inputs compared to the\nprompt-engineering approaches, making it a key component for building reliable\nAI agents.\n","authors":["Ivan Milev","Mislav Balunović","Maximilian Baader","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2503.04479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13456v3","updated":"2025-03-10T13:01:47Z","published":"2025-01-23T08:14:55Z","title":"KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) with attention mechanisms, often referred to as\nattentive GNNs, have emerged as a prominent paradigm in advanced GNN models in\nrecent years. However, our understanding of the critical process of scoring\nneighbor nodes remains limited, leading to the underperformance of many\nexisting attentive GNNs. In this paper, we unify the scoring functions of\ncurrent attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which\nintegrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring\nprocess. KAA enhances the performance of scoring functions across the board and\ncan be applied to nearly all existing attentive GNNs. To compare the expressive\npower of KAA with other scoring functions, we introduce Maximum Ranking\nDistance (MRD) to quantitatively estimate their upper bounds in ranking errors\nfor node importance. Our analysis reveals that, under limited parameters and\nconstraints on width and depth, both linear transformation-based and MLP-based\nscoring functions exhibit finite expressive power. In contrast, our proposed\nKAA, even with a single-layer KAN parameterized by zero-order B-spline\nfunctions, demonstrates nearly infinite expressive power. Extensive experiments\non both node-level and graph-level tasks using various backbone models show\nthat KAA-enhanced scoring functions consistently outperform their original\ncounterparts, achieving performance improvements of over 20% in some cases.\n","authors":["Taoran Fang","Tianhong Gao","Chunping Wang","Yihao Shang","Wei Chow","Lei Chen","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13456v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07279v1","updated":"2025-03-10T13:00:41Z","published":"2025-03-10T13:00:41Z","title":"VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in\n  Human-AI Communication","summary":"  Trust plays a fundamental role in shaping the willingness of users to engage\nand collaborate with artificial intelligence (AI) systems. Yet, measuring user\ntrust remains challenging due to its complex and dynamic nature. While\ntraditional survey methods provide trust levels for long conversations, they\nfail to capture its dynamic evolution during ongoing interactions. Here, we\npresent VizTrust, which addresses this challenge by introducing a real-time\nvisual analytics tool that leverages a multi-agent collaboration system to\ncapture and analyze user trust dynamics in human-agent communication. Built on\nestablished human-computer trust scales-competence, integrity, benevolence, and\npredictability-, VizTrust enables stakeholders to observe trust formation as it\nhappens, identify patterns in trust development, and pinpoint specific\ninteraction elements that influence trust. Our tool offers actionable insights\ninto human-agent trust formation and evolution in real time through a\ndashboard, supporting the design of adaptive conversational agents that\nresponds effectively to user trust signals.\n","authors":["Xin Wang","Stephanie Tulk Jesso","Sadamori Kojaku","David M Neyens","Min Sun Kim"],"pdf_url":"https://arxiv.org/pdf/2503.07279v1.pdf","comment":"Accepted by ACM CHI conference 2025"},{"id":"http://arxiv.org/abs/2503.04299v2","updated":"2025-03-10T13:00:00Z","published":"2025-03-06T10:39:47Z","title":"Mapping AI Benchmark Data to Quantitative Risk Estimates Through Expert\n  Elicitation","summary":"  The literature and multiple experts point to many potential risks from large\nlanguage models (LLMs), but there are still very few direct measurements of the\nactual harms posed. AI risk assessment has so far focused on measuring the\nmodels' capabilities, but the capabilities of models are only indicators of\nrisk, not measures of risk. Better modeling and quantification of AI risk\nscenarios can help bridge this disconnect and link the capabilities of LLMs to\ntangible real-world harm. This paper makes an early contribution to this field\nby demonstrating how existing AI benchmarks can be used to facilitate the\ncreation of risk estimates. We describe the results of a pilot study in which\nexperts use information from Cybench, an AI benchmark, to generate probability\nestimates. We show that the methodology seems promising for this purpose, while\nnoting improvements that can be made to further strengthen its application in\nquantitative AI risk assessment.\n","authors":["Malcolm Murray","Henry Papadatos","Otter Quarks","Pierre-François Gimenez","Simeon Campos"],"pdf_url":"https://arxiv.org/pdf/2503.04299v2.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.07275v1","updated":"2025-03-10T12:55:31Z","published":"2025-03-10T12:55:31Z","title":"Automatic Curriculum Design for Zero-Shot Human-AI Coordination","summary":"  Zero-shot human-AI coordination is the training of an ego-agent to coordinate\nwith humans without using human data. Most studies on zero-shot human-AI\ncoordination have focused on enhancing the ego-agent's coordination ability in\na given environment without considering the issue of generalization to unseen\nenvironments. Real-world applications of zero-shot human-AI coordination should\nconsider unpredictable environmental changes and the varying coordination\nability of co-players depending on the environment. Previously, the multi-agent\nUED (Unsupervised Environment Design) approach has investigated these\nchallenges by jointly considering environmental changes and co-player policy in\ncompetitive two-player AI-AI scenarios. In this paper, our study extends the\nmulti-agent UED approach to a zero-shot human-AI coordination. We propose a\nutility function and co-player sampling for a zero-shot human-AI coordination\nsetting that helps train the ego-agent to coordinate with humans more\neffectively than the previous multi-agent UED approach. The zero-shot human-AI\ncoordination performance was evaluated in the Overcooked-AI environment, using\nhuman proxy agents and real humans. Our method outperforms other baseline\nmodels and achieves a high human-AI coordination performance in unseen\nenvironments.\n","authors":["Won-Sang You","Tae-Gwan Ha","Seo-Young Lee","Kyung-Joong Kim"],"pdf_url":"https://arxiv.org/pdf/2503.07275v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07272v1","updated":"2025-03-10T12:53:45Z","published":"2025-03-10T12:53:45Z","title":"Federated Learning in NTNs: Design, Architecture and Challenges","summary":"  Non-terrestrial networks (NTNs) are emerging as a core component of future 6G\ncommunication systems, providing global connectivity and supporting\ndata-intensive applications. In this paper, we propose a distributed\nhierarchical federated learning (HFL) framework within the NTN architecture,\nleveraging a high altitude platform station (HAPS) constellation as\nintermediate distributed FL servers. Our framework integrates both low-Earth\norbit (LEO) satellites and ground clients in the FL training process while\nutilizing geostationary orbit (GEO) and medium-Earth orbit (MEO) satellites as\nrelays to exchange FL global models across other HAPS constellations worldwide,\nenabling seamless, global-scale learning. The proposed framework offers several\nkey benefits: (i) enhanced privacy through the decentralization of the FL\nmechanism by leveraging the HAPS constellation, (ii) improved model accuracy\nand reduced training loss while balancing latency, (iii) increased scalability\nof FL systems through ubiquitous connectivity by utilizing MEO and GEO\nsatellites, and (iv) the ability to use FL data, such as resource utilization\nmetrics, to further optimize the NTN architecture from a network management\nperspective. A numerical study demonstrates the proposed framework's\neffectiveness, with improved model accuracy, reduced training loss, and\nefficient latency management. The article also includes a brief review of FL in\nNTNs and highlights key challenges and future research directions.\n","authors":["Amin Farajzadeh","Animesh Yadav","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2503.07272v1.pdf","comment":"Accepted in IEEE Communications Magazine"},{"id":"http://arxiv.org/abs/2503.07265v1","updated":"2025-03-10T12:47:53Z","published":"2025-03-10T12:47:53Z","title":"WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image\n  Generation","summary":"  Text-to-Image (T2I) models are capable of generating high-quality artistic\ncreations and visual content. However, existing research and evaluation\nstandards predominantly focus on image realism and shallow text-image\nalignment, lacking a comprehensive assessment of complex semantic understanding\nand world knowledge integration in text to image generation. To address this\nchallenge, we propose $\\textbf{WISE}$, the first benchmark specifically\ndesigned for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic\n$\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by\nchallenging models with 1000 meticulously crafted prompts across 25 sub-domains\nin cultural common sense, spatio-temporal reasoning, and natural science. To\novercome the limitations of traditional CLIP metric, we introduce\n$\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image\nalignment. Through comprehensive testing of 20 models (10 dedicated T2I models\nand 10 unified multimodal models) using 1,000 structured prompts spanning 25\nsubdomains, our findings reveal significant limitations in their ability to\neffectively integrate and apply world knowledge during image generation,\nhighlighting critical pathways for enhancing knowledge incorporation and\napplication in next-generation T2I models. Code and data are available at\nhttps://github.com/PKU-YuanGroup/WISE.\n","authors":["Yuwei Niu","Munan Ning","Mengren Zheng","Bin Lin","Peng Jin","Jiaqi Liao","Kunpeng Ning","Bin Zhu","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.07265v1.pdf","comment":"Code, data and leaderboard: https://github.com/PKU-YuanGroup/WISE"},{"id":"http://arxiv.org/abs/2503.07259v1","updated":"2025-03-10T12:43:51Z","published":"2025-03-10T12:43:51Z","title":"COMODO: Cross-Modal Video-to-IMU Distillation for Efficient Egocentric\n  Human Activity Recognition","summary":"  Egocentric video-based models capture rich semantic information and have\ndemonstrated strong performance in human activity recognition (HAR). However,\ntheir high power consumption, privacy concerns, and dependence on lighting\nconditions limit their feasibility for continuous on-device recognition. In\ncontrast, inertial measurement unit (IMU) sensors offer an energy-efficient and\nprivacy-preserving alternative, yet they suffer from limited large-scale\nannotated datasets, leading to weaker generalization in downstream tasks. To\nbridge this gap, we propose COMODO, a cross-modal self-supervised distillation\nframework that transfers rich semantic knowledge from the video modality to the\nIMU modality without requiring labeled annotations. COMODO leverages a\npretrained and frozen video encoder to construct a dynamic instance queue,\naligning the feature distributions of video and IMU embeddings. By distilling\nknowledge from video representations, our approach enables the IMU encoder to\ninherit rich semantic information from video while preserving its efficiency\nfor real-world applications. Experiments on multiple egocentric HAR datasets\ndemonstrate that COMODO consistently improves downstream classification\nperformance, achieving results comparable to or exceeding fully supervised\nfine-tuned models. Moreover, COMODO exhibits strong cross-dataset\ngeneralization. Benefiting from its simplicity, our method is also generally\napplicable to various video and time-series pre-trained models, offering the\npotential to leverage more powerful teacher and student foundation models in\nfuture research. The code is available at https://github.com/Breezelled/COMODO .\n","authors":["Baiyu Chen","Wilson Wongso","Zechen Li","Yonchanok Khaokaew","Hao Xue","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2503.07259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07248v1","updated":"2025-03-10T12:32:44Z","published":"2025-03-10T12:32:44Z","title":"AI-Driven Automated Tool for Abdominal CT Body Composition Analysis in\n  Gastrointestinal Cancer Management","summary":"  The incidence of gastrointestinal cancers remains significantly high,\nparticularly in China, emphasizing the importance of accurate prognostic\nassessments and effective treatment strategies. Research shows a strong\ncorrelation between abdominal muscle and fat tissue composition and patient\noutcomes. However, existing manual methods for analyzing abdominal tissue\ncomposition are time-consuming and costly, limiting clinical research\nscalability. To address these challenges, we developed an AI-driven tool for\nautomated analysis of abdominal CT scans to effectively identify and segment\nmuscle, subcutaneous fat, and visceral fat. Our tool integrates a multi-view\nlocalization model and a high-precision 2D nnUNet-based segmentation model,\ndemonstrating a localization accuracy of 90% and a Dice Score Coefficient of\n0.967 for segmentation. Furthermore, it features an interactive interface that\nallows clinicians to refine the segmentation results, ensuring high-quality\noutcomes effectively. Our tool offers a standardized method for effectively\nextracting critical abdominal tissues, potentially enhancing the management and\ntreatment for gastrointestinal cancers. The code is available at\nhttps://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git}{https://github.com/NanXinyu/AI-Tool4Abdominal-Seg.git.\n","authors":["Xinyu Nan","Meng He","Zifan Chen","Bin Dong","Lei Tang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09481v2","updated":"2025-03-10T12:27:10Z","published":"2025-01-16T11:35:22Z","title":"MonoSOWA: Scalable monocular 3D Object detector Without human\n  Annotations","summary":"  Inferring object 3D position and orientation from a single RGB camera is a\nfoundational task in computer vision with many important applications.\nTraditionally, 3D object detection methods are trained in a fully-supervised\nsetup, requiring LiDAR and vast amounts of human annotations, which are\nlaborious, costly, and do not scale well with the ever-increasing amounts of\ndata being captured.\n  We present a novel method to train a 3D object detector from a single RGB\ncamera without domain-specific human annotations, making orders of magnitude\nmore data available for training. The method uses newly proposed Local Object\nMotion Model to disentangle object movement source between subsequent frames,\nis approximately 700 times faster than previous work and compensates camera\nfocal length differences to aggregate multiple datasets.\n  The method is evaluated on three public datasets, where despite using no\nhuman labels, it outperforms prior work by a significant margin. It also shows\nits versatility as a pre-training tool for fully-supervised training and shows\nthat combining pseudo-labels from multiple datasets can achieve comparable\naccuracy to using human labels from a single dataset. The source code and model\nwill be published soon.\n","authors":["Jan Skvrna","Lukas Neumann"],"pdf_url":"https://arxiv.org/pdf/2501.09481v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07237v1","updated":"2025-03-10T12:20:20Z","published":"2025-03-10T12:20:20Z","title":"LLM-C3MOD: A Human-LLM Collaborative System for Cross-Cultural Hate\n  Speech Moderation","summary":"  Content moderation is a global challenge, yet major tech platforms prioritize\nhigh-resource languages, leaving low-resource languages with scarce native\nmoderators. Since effective moderation depends on understanding contextual\ncues, this imbalance increases the risk of improper moderation due to\nnon-native moderators' limited cultural understanding. Through a user study, we\nidentify that non-native moderators struggle with interpreting\nculturally-specific knowledge, sentiment, and internet culture in the hate\nspeech moderation. To assist them, we present LLM-C3MOD, a human-LLM\ncollaborative pipeline with three steps: (1) RAG-enhanced cultural context\nannotations; (2) initial LLM-based moderation; and (3) targeted human\nmoderation for cases lacking LLM consensus. Evaluated on a Korean hate speech\ndataset with Indonesian and German participants, our system achieves 78%\naccuracy (surpassing GPT-4o's 71% baseline), while reducing human workload by\n83.6%. Notably, human moderators excel at nuanced contents where LLMs struggle.\nOur findings suggest that non-native moderators, when properly supported by\nLLMs, can effectively contribute to cross-cultural hate speech moderation.\n","authors":["Junyeong Park","Seogyeong Jeong","Seyoung Song","Yohan Lee","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2503.07237v1.pdf","comment":"Accepted to NAACL 2025 Workshop - C3NLP (Workshop on Cross-Cultural\n  Considerations in NLP)"},{"id":"http://arxiv.org/abs/2503.07234v1","updated":"2025-03-10T12:17:38Z","published":"2025-03-10T12:17:38Z","title":"CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs\n  and Chain-of-Thought Prompting","summary":"  Accurate motion forecasting is crucial for safe autonomous driving (AD). This\nstudy proposes CoT-Drive, a novel approach that enhances motion forecasting by\nleveraging large language models (LLMs) and a chain-of-thought (CoT) prompting\nmethod. We introduce a teacher-student knowledge distillation strategy to\neffectively transfer LLMs' advanced scene understanding capabilities to\nlightweight language models (LMs), ensuring that CoT-Drive operates in\nreal-time on edge devices while maintaining comprehensive scene understanding\nand generalization capabilities. By leveraging CoT prompting techniques for\nLLMs without additional training, CoT-Drive generates semantic annotations that\nsignificantly improve the understanding of complex traffic environments,\nthereby boosting the accuracy and robustness of predictions. Additionally, we\npresent two new scene description datasets, Highway-Text and Urban-Text,\ndesigned for fine-tuning lightweight LMs to generate context-specific semantic\nannotations. Comprehensive evaluations of five real-world datasets demonstrate\nthat CoT-Drive outperforms existing models, highlighting its effectiveness and\nefficiency in handling complex traffic scenarios. Overall, this study is the\nfirst to consider the practical application of LLMs in this field. It pioneers\nthe training and use of a lightweight LLM surrogate for motion forecasting,\nsetting a new benchmark and showcasing the potential of integrating LLMs into\nAD systems.\n","authors":["Haicheng Liao","Hanlin Kong","Bonan Wang","Chengyue Wang","Wang Ye","Zhengbing He","Chengzhong Xu","Zhenning Li"],"pdf_url":"https://arxiv.org/pdf/2503.07234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13178v4","updated":"2025-03-10T12:13:09Z","published":"2024-12-17T18:55:58Z","title":"SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM\n  Agents","summary":"  With the integration of large language models (LLMs), embodied agents have\nstrong capabilities to understand and plan complicated natural language\ninstructions. However, a foreseeable issue is that those embodied agents can\nalso flawlessly execute some hazardous tasks, potentially causing damages in\nthe real world. Existing benchmarks predominantly overlook critical safety\nrisks, focusing solely on planning performance, while a few evaluate LLMs'\nsafety awareness only on non-interactive image-text data. To address this gap,\nwe present SafeAgentBench-the first benchmark for safety-aware task planning of\nembodied LLM agents in interactive simulation environments. SafeAgentBench\nincludes: (1) an executable, diverse, and high-quality dataset of 750 tasks,\nrigorously curated to cover 10 potential hazards and 3 task types; (2)\nSafeAgentEnv, a universal embodied environment with a low-level controller,\nsupporting multi-agent execution with 17 high-level actions for 8\nstate-of-the-art baselines; and (3) reliable evaluation methods from both\nexecution and semantic perspectives. Experimental results show that, although\nagents based on different design frameworks exhibit substantial differences in\ntask success rates, their overall safety awareness remains weak. The most\nsafety-conscious baseline achieves only a 10\\% rejection rate for detailed\nhazardous tasks. Moreover, simply replacing the LLM driving the agent does not\nlead to notable improvements in safety awareness. More details and code are\navailable at https://github.com/shengyin1224/SafeAgentBench.\n","authors":["Sheng Yin","Xianghe Pang","Yuanzhuo Ding","Menglan Chen","Yutong Bi","Yichen Xiong","Wenhao Huang","Zhen Xiang","Jing Shao","Siheng Chen"],"pdf_url":"https://arxiv.org/pdf/2412.13178v4.pdf","comment":"23 pages, 17 tables, 14 figures"},{"id":"http://arxiv.org/abs/2502.17506v2","updated":"2025-03-10T12:11:58Z","published":"2025-02-22T00:12:52Z","title":"RAG-Enhanced Collaborative LLM Agents for Drug Discovery","summary":"  Recent advances in large language models (LLMs) have shown great potential to\naccelerate drug discovery. However, the specialized nature of biochemical data\noften necessitates costly domain-specific fine-tuning, posing critical\nchallenges. First, it hinders the application of more flexible general-purpose\nLLMs in cutting-edge drug discovery tasks. More importantly, it impedes the\nrapid integration of the vast amounts of scientific data continuously generated\nthrough experiments and research. To investigate these challenges, we propose\nCLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored\nto drug discovery tasks. Through the collaboration of multiple LLM agents,\nCLADD dynamically retrieves information from biomedical knowledge bases,\ncontextualizes query molecules, and integrates relevant evidence to generate\nresponses -- all without the need for domain-specific fine-tuning. Crucially,\nwe tackle key obstacles in applying RAG workflows to biochemical data,\nincluding data heterogeneity, ambiguity, and multi-source integration. We\ndemonstrate the flexibility and effectiveness of this framework across a\nvariety of drug discovery tasks, showing that it outperforms general-purpose\nand domain-specific LLMs as well as traditional deep learning approaches.\n","authors":["Namkyeong Lee","Edward De Brouwer","Ehsan Hajiramezanali","Tommaso Biancalani","Chanyoung Park","Gabriele Scalia"],"pdf_url":"https://arxiv.org/pdf/2502.17506v2.pdf","comment":"Machine Learning, Drug Discovery"},{"id":"http://arxiv.org/abs/2502.12581v3","updated":"2025-03-10T11:53:28Z","published":"2025-02-18T06:37:33Z","title":"The Majority Vote Paradigm Shift: When Popular Meets Optimal","summary":"  Reliably labelling data typically requires annotations from multiple human\nworkers. However, humans are far from being perfect. Hence, it is a common\npractice to aggregate labels gathered from multiple annotators to make a more\nconfident estimate of the true label. Among many aggregation methods, the\nsimple and well known Majority Vote (MV) selects the class label polling the\nhighest number of votes. However, despite its importance, the optimality of\nMV's label aggregation has not been extensively studied. We address this gap in\nour work by characterising the conditions under which MV achieves the\ntheoretically optimal lower bound on label estimation error. Our results\ncapture the tolerable limits on annotation noise under which MV can optimally\nrecover labels for a given class distribution. This certificate of optimality\nprovides a more principled approach to model selection for label aggregation as\nan alternative to otherwise inefficient practices that sometimes include higher\nexperts, gold labels, etc., that are all marred by the same human uncertainty\ndespite huge time and monetary costs. Experiments on both synthetic and real\nworld data corroborate our theoretical findings.\n","authors":["Antonio Purificato","Maria Sofia Bucarelli","Anil Kumar Nelakanti","Andrea Bacciu","Fabrizio Silvestri","Amin Mantrach"],"pdf_url":"https://arxiv.org/pdf/2502.12581v3.pdf","comment":"33 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.07214v1","updated":"2025-03-10T11:52:33Z","published":"2025-03-10T11:52:33Z","title":"Cross-Lingual IPA Contrastive Learning for Zero-Shot NER","summary":"  Existing approaches to zero-shot Named Entity Recognition (NER) for\nlow-resource languages have primarily relied on machine translation, whereas\nmore recent methods have shifted focus to phonemic representation. Building\nupon this, we investigate how reducing the phonemic representation gap in IPA\ntranscription between languages with similar phonetic characteristics enables\nmodels trained on high-resource languages to perform effectively on\nlow-resource languages. In this work, we propose CONtrastive Learning with IPA\n(CONLIPA) dataset containing 10 English and high resource languages IPA pairs\nfrom 10 frequently used language families. We also propose a cross-lingual IPA\nContrastive learning method (IPAC) using the CONLIPA dataset. Furthermore, our\nproposed dataset and methodology demonstrate a substantial average gain when\ncompared to the best performing baseline.\n","authors":["Jimin Sohn","David R. Mortensen"],"pdf_url":"https://arxiv.org/pdf/2503.07214v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.07210v1","updated":"2025-03-10T11:50:15Z","published":"2025-03-10T11:50:15Z","title":"Discrete Gaussian Process Representations for Optimising UAV-based\n  Precision Weed Mapping","summary":"  Accurate agricultural weed mapping using UAVs is crucial for precision\nfarming applications. Traditional methods rely on orthomosaic stitching from\nrigid flight paths, which is computationally intensive and time-consuming.\nGaussian Process (GP)-based mapping offers continuous modelling of the\nunderlying variable (i.e. weed distribution) but requires discretisation for\npractical tasks like path planning or visualisation. Current implementations\noften default to quadtrees or gridmaps without systematically evaluating\nalternatives. This study compares five discretisation methods: quadtrees,\nwedgelets, top-down binary space partition (BSP) trees using least square error\n(LSE), bottom-up BSP trees using graph merging, and variable-resolution\nhexagonal grids. Evaluations on real-world weed distributions measure visual\nsimilarity, mean squared error (MSE), and computational efficiency. Results\nshow quadtrees perform best overall, but alternatives excel in specific\nscenarios: hexagons or BSP LSE suit fields with large, dominant weed patches,\nwhile quadtrees are optimal for dispersed small-scale distributions. These\nfindings highlight the need to tailor discretisation approaches to weed\ndistribution patterns (patch size, density, coverage) rather than relying on\ndefault methods. By choosing representations based on the underlying\ndistribution, we can improve mapping accuracy and efficiency for precision\nagriculture applications.\n","authors":["Jacob Swindell","Madeleine Darbyshire","Marija Popovic","Riccardo Polvara"],"pdf_url":"https://arxiv.org/pdf/2503.07210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07202v1","updated":"2025-03-10T11:38:21Z","published":"2025-03-10T11:38:21Z","title":"A Zero-shot Learning Method Based on Large Language Models for\n  Multi-modal Knowledge Graph Embedding","summary":"  Zero-shot learning (ZL) is crucial for tasks involving unseen categories,\nsuch as natural language processing, image classification, and cross-lingual\ntransfer. Current applications often fail to accurately infer and handle new\nrelations or entities involving unseen categories, severely limiting their\nscalability and practicality in open-domain scenarios. ZL learning faces the\nchallenge of effectively transferring semantic information of unseen categories\nin multi-modal knowledge graph (MMKG) embedding representation learning. In\nthis paper, we propose ZSLLM, a framework for zero-shot embedding learning of\nMMKGs using large language models (LLMs). We leverage textual modality\ninformation of unseen categories as prompts to fully utilize the reasoning\ncapabilities of LLMs, enabling semantic information transfer across different\nmodalities for unseen categories. Through model-based learning, the embedding\nrepresentation of unseen categories in MMKG is enhanced. Extensive experiments\nconducted on multiple real-world datasets demonstrate the superiority of our\napproach compared to state-of-the-art methods.\n","authors":["Bingchen Liu","Jingchen Li","Naixing Xu","Xin Li"],"pdf_url":"https://arxiv.org/pdf/2503.07202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16032v3","updated":"2025-03-10T11:37:38Z","published":"2024-10-21T14:06:53Z","title":"TimeMixer++: A General Time Series Pattern Machine for Universal\n  Predictive Analysis","summary":"  Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.\n","authors":["Shiyu Wang","Jiawei Li","Xiaoming Shi","Zhou Ye","Baichuan Mo","Wenze Lin","Shengtong Ju","Zhixuan Chu","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2410.16032v3.pdf","comment":"Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2412.13810v2","updated":"2025-03-10T11:27:07Z","published":"2024-12-18T12:57:56Z","title":"CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers","summary":"  We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design.\nOur approach is based on a powerful Vision and Large Language Model (VLLM) as a\nplanner and a tool-augmentation paradigm using CAD-specific tools.\nCAD-Assistant addresses multimodal user queries by generating actions that are\niteratively executed on a Python interpreter equipped with the FreeCAD\nsoftware, accessed via its Python API. Our framework is able to assess the\nimpact of generated CAD commands on geometry and adapts subsequent actions\nbased on the evolving state of the CAD design. We consider a wide range of\nCAD-specific tools including a sketch image parameterizer, rendering modules, a\n2D cross-section generator, and other specialized routines. CAD-Assistant is\nevaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and\nsupervised task-specific methods. Beyond existing benchmarks, we qualitatively\ndemonstrate the potential of tool-augmented VLLMs as general-purpose CAD\nsolvers across diverse workflows.\n","authors":["Dimitrios Mallis","Ahmet Serdar Karadeniz","Sebastian Cavada","Danila Rukhovich","Niki Foteinopoulou","Kseniya Cherenkova","Anis Kacem","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2412.13810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04292v2","updated":"2025-03-10T11:03:16Z","published":"2024-12-05T16:12:25Z","title":"SIDA: Social Media Image Deepfake Detection, Localization and\n  Explanation with Large Multimodal Model","summary":"  The rapid advancement of generative models in creating highly realistic\nimages poses substantial risks for misinformation dissemination. For instance,\na synthetic image, when shared on social media, can mislead extensive audiences\nand erode trust in digital content, resulting in severe repercussions. Despite\nsome progress, academia has not yet created a large and diversified deepfake\ndetection dataset for social media, nor has it devised an effective solution to\naddress this issue. In this paper, we introduce the Social media Image\nDetection dataSet (SID-Set), which offers three key advantages: (1) extensive\nvolume, featuring 300K AI-generated/tampered and authentic images with\ncomprehensive annotations, (2) broad diversity, encompassing fully synthetic\nand tampered images across various classes, and (3) elevated realism, with\nimages that are predominantly indistinguishable from genuine ones through mere\nvisual inspection. Furthermore, leveraging the exceptional capabilities of\nlarge multimodal models, we propose a new image deepfake detection,\nlocalization, and explanation framework, named SIDA (Social media Image\nDetection, localization, and explanation Assistant). SIDA not only discerns the\nauthenticity of images, but also delineates tampered regions through mask\nprediction and provides textual explanations of the model's judgment criteria.\nCompared with state-of-the-art deepfake detection models on SID-Set and other\nbenchmarks, extensive experiments demonstrate that SIDA achieves superior\nperformance among diversified settings. The code, model, and dataset will be\nreleased.\n","authors":["Zhenglin Huang","Jinwei Hu","Xiangtai Li","Yiwei He","Xingyu Zhao","Bei Peng","Baoyuan Wu","Xiaowei Huang","Guangliang Cheng"],"pdf_url":"https://arxiv.org/pdf/2412.04292v2.pdf","comment":"CVPR-2025"},{"id":"http://arxiv.org/abs/2410.11843v4","updated":"2025-03-10T10:50:44Z","published":"2024-09-23T08:39:16Z","title":"From Commands to Prompts: LLM-based Semantic File System for AIOS","summary":"  Large language models (LLMs) have demonstrated significant potential in the\ndevelopment of intelligent applications and systems such as LLM-based agents\nand agent operating systems (AIOS). However, when these applications and\nsystems interact with the underlying file system, the file system still remains\nthe traditional paradigm: reliant on manual navigation through precise\ncommands. This paradigm poses a bottleneck to the usability of these systems as\nusers are required to navigate complex folder hierarchies and remember cryptic\nfile names. To address this limitation, we propose an LLM-based semantic file\nsystem ( LSFS ) for prompt-driven file management. Unlike conventional\napproaches, LSFS incorporates LLMs to enable users or agents to interact with\nfiles through natural language prompts, facilitating semantic file management.\nAt the macro-level, we develop a comprehensive API set to achieve semantic file\nmanagement functionalities, such as semantic file retrieval, file update\nmonitoring and summarization, and semantic file rollback). At the micro-level,\nwe store files by constructing semantic indexes for them, design and implement\nsyscalls of different semantic operations (e.g., CRUD, group by, join) powered\nby vector database. Our experiments show that LSFS offers significant\nimprovements over traditional file systems in terms of user convenience, the\ndiversity of supported functions, and the accuracy and efficiency of file\noperations. Additionally, with the integration of LLM, our system enables more\nintelligent file management tasks, such as content summarization and version\ncomparison, further enhancing its capabilities.\n","authors":["Zeru Shi","Kai Mei","Mingyu Jin","Yongye Su","Chaoji Zuo","Wenyue Hua","Wujiang Xu","Yujie Ren","Zirui Liu","Mengnan Du","Dong Deng","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.11843v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07172v1","updated":"2025-03-10T10:49:34Z","published":"2025-03-10T10:49:34Z","title":"Lawful and Accountable Personal Data Processing with GDPR-based Access\n  and Usage Control in Distributed Systems","summary":"  Compliance with the GDPR privacy regulation places a significant burden on\norganisations regarding the handling of personal data. The perceived efforts\nand risks of complying with the GDPR further increase when data processing\nactivities span across organisational boundaries, as is the case in both\nsmall-scale data sharing settings and in large-scale international data spaces.\n  This paper addresses these concerns by proposing a case-generic method for\nautomated normative reasoning that establishes legal arguments for the\nlawfulness of data processing activities. The arguments are established on the\nbasis of case-specific legal qualifications made by privacy experts, bringing\nthe human in the loop. The obtained expert system promotes transparency and\naccountability, remains adaptable to extended or altered interpretations of the\nGDPR, and integrates into novel or existing distributed data processing\nsystems.\n  This result is achieved by defining a formal ontology and semantics for\nautomated normative reasoning based on an analysis of the purpose-limitation\nprinciple of the GDPR. The ontology and semantics are implemented in eFLINT, a\ndomain-specific language for specifying and reasoning with norms. The XACML\narchitecture standard, applicable to both access and usage control, is\nextended, demonstrating how GDPR-based normative reasoning can integrate into\n(existing, distributed) systems for data processing. The resulting system is\ndesigned and critically assessed in reference to requirements extracted from\nthe GPDR.\n","authors":["L. Thomas van Binsbergen","Marten C. Steketee","Milen G. Kebede","Heleen L. Janssen","Tom M. van Engers"],"pdf_url":"https://arxiv.org/pdf/2503.07172v1.pdf","comment":"Submitted for review to the Journal of AI and Law, 49 pages\n  (including)"},{"id":"http://arxiv.org/abs/2502.11995v2","updated":"2025-03-10T10:48:57Z","published":"2025-02-17T16:35:15Z","title":"Presumed Cultural Identity: How Names Shape LLM Responses","summary":"  Names are deeply tied to human identity. They can serve as markers of\nindividuality, cultural heritage, and personal history. However, using names as\na core indicator of identity can lead to over-simplification of complex\nidentities. When interacting with LLMs, user names are an important point of\ninformation for personalisation. Names can enter chatbot conversations through\ndirect user input (requested by chatbots), as part of task contexts such as CV\nreviews, or as built-in memory features that store user information for\npersonalisation. We study biases associated with names by measuring cultural\npresumptions in the responses generated by LLMs when presented with common\nsuggestion-seeking queries, which might involve making assumptions about the\nuser. Our analyses demonstrate strong assumptions about cultural identity\nassociated with names present in LLM generations across multiple cultures. Our\nwork has implications for designing more nuanced personalisation systems that\navoid reinforcing stereotypes while maintaining meaningful customisation.\n","authors":["Siddhesh Pawar","Arnav Arora","Lucie-Aimée Kaffee","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2502.11995v2.pdf","comment":"23 Pages, 13 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2503.07170v1","updated":"2025-03-10T10:48:00Z","published":"2025-03-10T10:48:00Z","title":"DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form\n  Article Generation","summary":"  Long-form article generation (LFAG) presents challenges such as maintaining\nlogical consistency, comprehensive topic coverage, and narrative coherence\nacross extended articles. Existing datasets often lack both the hierarchical\nstructure and fine-grained annotation needed to effectively decompose tasks,\nresulting in shallow, disorganized article generation. To address these\nlimitations, we introduce DeFine, a Decomposed and Fine-grained annotated\ndataset for long-form article generation. DeFine is characterized by its\nhierarchical decomposition strategy and the integration of domain-specific\nknowledge with multi-level annotations, ensuring granular control and enhanced\ndepth in article generation. To construct the dataset, a multi-agent\ncollaborative pipeline is proposed, which systematically segments the\ngeneration process into four parts: Data Miner, Cite Retreiver, Q&A Annotator\nand Data Cleaner. To validate the effectiveness of DeFine, we designed and\ntested three LFAG baselines: the web retrieval, the local retrieval, and the\ngrounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine\ntraining dataset. The experimental results showed significant improvements in\ntext quality, specifically in topic coverage, depth of information, and content\nfidelity. Our dataset publicly available to facilitate future research.\n","authors":["Ming Wang","Fang Wang","Minghao Hu","Li He","Haiyang Wang","Jun Zhang","Tianwei Yan","Li Li","Zhunchen Luo","Wei Luo","Xiaoying Bai","Guotong Geng"],"pdf_url":"https://arxiv.org/pdf/2503.07170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10645v2","updated":"2025-03-10T10:35:53Z","published":"2024-07-15T12:04:32Z","title":"Prompt Selection Matters: Enhancing Text Annotations for Social Sciences\n  with Large Language Models","summary":"  Large Language Models have recently been applied to text annotation tasks\nfrom social sciences, equalling or surpassing the performance of human workers\nat a fraction of the cost. However, no inquiry has yet been made on the impact\nof prompt selection on labelling accuracy. In this study, we show that\nperformance greatly varies between prompts, and we apply the method of\nautomatic prompt optimization to systematically craft high quality prompts. We\nalso provide the community with a simple, browser-based implementation of the\nmethod at https://prompt-ultra.github.io/ .\n","authors":["Louis Abraham","Charles Arnal","Antoine Marie"],"pdf_url":"https://arxiv.org/pdf/2407.10645v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07158v1","updated":"2025-03-10T10:33:31Z","published":"2025-03-10T10:33:31Z","title":"Generative AI in Transportation Planning: A Survey","summary":"  The integration of generative artificial intelligence (GenAI) into\ntransportation planning has the potential to revolutionize tasks such as demand\nforecasting, infrastructure design, policy evaluation, and traffic simulation.\nHowever, there is a critical need for a systematic framework to guide the\nadoption of GenAI in this interdisciplinary domain. In this survey, we, a\nmultidisciplinary team of researchers spanning computer science and\ntransportation engineering, present the first comprehensive framework for\nleveraging GenAI in transportation planning. Specifically, we introduce a new\ntaxonomy that categorizes existing applications and methodologies into two\nperspectives: transportation planning tasks and computational techniques. From\nthe transportation planning perspective, we examine the role of GenAI in\nautomating descriptive, predictive, generative, simulation, and explainable\ntasks to enhance mobility systems. From the computational perspective, we\ndetail advancements in data preparation, domain-specific fine-tuning, and\ninference strategies, such as retrieval-augmented generation and zero-shot\nlearning tailored to transportation applications. Additionally, we address\ncritical challenges, including data scarcity, explainability, bias mitigation,\nand the development of domain-specific evaluation frameworks that align with\ntransportation goals like sustainability, equity, and system efficiency. This\nsurvey aims to bridge the gap between traditional transportation planning\nmethodologies and modern AI techniques, fostering collaboration and innovation.\nBy addressing these challenges and opportunities, we seek to inspire future\nresearch that ensures ethical, equitable, and impactful use of generative AI in\ntransportation planning.\n","authors":["Longchao Da","Tiejin Chen","Zhuoheng Li","Shreyas Bachiraju","Huaiyuan Yao","Xiyang Hu","Zhengzhong Tu","Yue Zhao","Dongjie Wang"," Xuanyu"," Zhou","Ram Pendyala","Benjamin Stabler","Yezhou Yang","Xuesong Zhou","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2503.07158v1.pdf","comment":"56 pages"},{"id":"http://arxiv.org/abs/2503.07154v1","updated":"2025-03-10T10:27:30Z","published":"2025-03-10T10:27:30Z","title":"Ideas in Inference-time Scaling can Benefit Generative Pre-training\n  Algorithms","summary":"  Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.\n","authors":["Jiaming Song","Linqi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07153v1","updated":"2025-03-10T10:27:21Z","published":"2025-03-10T10:27:21Z","title":"PTMs-TSCIL Pre-Trained Models Based Class-Incremental Learning","summary":"  Class-incremental learning (CIL) for time series data faces critical\nchallenges in balancing stability against catastrophic forgetting and\nplasticity for new knowledge acquisition, particularly under real-world\nconstraints where historical data access is restricted. While pre-trained\nmodels (PTMs) have shown promise in CIL for vision and NLP domains, their\npotential in time series class-incremental learning (TSCIL) remains\nunderexplored due to the scarcity of large-scale time series pre-trained\nmodels. Prompted by the recent emergence of large-scale pre-trained models\n(PTMs) for time series data, we present the first exploration of PTM-based Time\nSeries Class-Incremental Learning (TSCIL). Our approach leverages frozen PTM\nbackbones coupled with incrementally tuning the shared adapter, preserving\ngeneralization capabilities while mitigating feature drift through knowledge\ndistillation. Furthermore, we introduce a Feature Drift Compensation Network\n(DCN), designed with a novel two-stage training strategy to precisely model\nfeature space transformations across incremental tasks. This allows for\naccurate projection of old class prototypes into the new feature space. By\nemploying DCN-corrected prototypes, we effectively enhance the unified\nclassifier retraining, mitigating model feature drift and alleviating\ncatastrophic forgetting. Extensive experiments on five real-world datasets\ndemonstrate state-of-the-art performance, with our method yielding final\naccuracy gains of 1.4%-6.1% across all datasets compared to existing PTM-based\napproaches. Our work establishes a new paradigm for TSCIL, providing insights\ninto stability-plasticity optimization for continual learning systems.\n","authors":["Yuanlong Wu","Mingxing Nie","Tao Zhu","Liming Chen","Huansheng Ning","Yaping Wan"],"pdf_url":"https://arxiv.org/pdf/2503.07153v1.pdf","comment":"13 pages,6 figures"},{"id":"http://arxiv.org/abs/2503.07148v1","updated":"2025-03-10T10:22:13Z","published":"2025-03-10T10:22:13Z","title":"Hierarchical Neuro-Symbolic Decision Transformer","summary":"  We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.\n","authors":["Ali Baheri","Cecilia O. Alm"],"pdf_url":"https://arxiv.org/pdf/2503.07148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07144v1","updated":"2025-03-10T10:20:05Z","published":"2025-03-10T10:20:05Z","title":"MRCEval: A Comprehensive, Challenging and Accessible Machine Reading\n  Comprehension Benchmark","summary":"  Machine Reading Comprehension (MRC) is an essential task in evaluating\nnatural language understanding. Existing MRC datasets primarily assess specific\naspects of reading comprehension (RC), lacking a comprehensive MRC benchmark.\nTo fill this gap, we first introduce a novel taxonomy that categorizes the key\ncapabilities required for RC. Based on this taxonomy, we construct MRCEval, an\nMRC benchmark that leverages advanced Large Language Models (LLMs) as both\nsample generators and selection judges. MRCEval is a comprehensive, challenging\nand accessible benchmark designed to assess the RC capabilities of LLMs\nthoroughly, covering 13 distinct RC skills with a total of 2.1K high-quality\nmulti-choice questions. We perform an extensive evaluation of 28 widely used\nopen-source and proprietary models, highlighting that MRC continues to present\nsignificant challenges even in the era of LLMs.\n","authors":["Shengkun Ma","Hao Peng","Lei Hou","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2503.07144v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.07137v1","updated":"2025-03-10T10:08:55Z","published":"2025-03-10T10:08:55Z","title":"A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and\n  Applications","summary":"  Artificial intelligence (AI) has achieved astonishing successes in many\ndomains, especially with the recent breakthroughs in the development of\nfoundational large models. These large models, leveraging their extensive\ntraining data, provide versatile solutions for a wide range of downstream\ntasks. However, as modern datasets become increasingly diverse and complex, the\ndevelopment of large AI models faces two major challenges: (1) the enormous\nconsumption of computational resources and deployment difficulties, and (2) the\ndifficulty in fitting heterogeneous and complex data, which limits the\nusability of the models. Mixture of Experts (MoE) models has recently attracted\nmuch attention in addressing these challenges, by dynamically selecting and\nactivating the most relevant sub-models to process input data. It has been\nshown that MoEs can significantly improve model performance and efficiency with\nfewer resources, particularly excelling in handling large-scale, multimodal\ndata. Given the tremendous potential MoE has demonstrated across various\ndomains, it is urgent to provide a comprehensive summary of recent advancements\nof MoEs in many important fields. Existing surveys on MoE have their\nlimitations, e.g., being outdated or lacking discussion on certain key areas,\nand we aim to address these gaps. In this paper, we first introduce the basic\ndesign of MoE, including gating functions, expert networks, routing mechanisms,\ntraining strategies, and system design. We then explore the algorithm design of\nMoE in important machine learning paradigms such as continual learning,\nmeta-learning, multi-task learning, and reinforcement learning. Additionally,\nwe summarize theoretical studies aimed at understanding MoE and review its\napplications in computer vision and natural language processing. Finally, we\ndiscuss promising future research directions.\n","authors":["Siyuan Mu","Sen Lin"],"pdf_url":"https://arxiv.org/pdf/2503.07137v1.pdf","comment":"28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2502.07347v4","updated":"2025-03-10T10:04:26Z","published":"2025-02-11T08:18:37Z","title":"Coarse Set Theory for AI Ethics and Decision-Making: A Mathematical\n  Framework for Granular Evaluations","summary":"  In artificial intelligence (AI) and decision-making systems, structured\napproximations play a crucial role in balancing model interpretability and\npredictive accuracy. Coarse Set Theory (CST) introduces a mathematical\nframework to formalize Coarse Ethics (CE), which models coarse-grained\ndecision-making processes commonly used in human evaluations and AI\nclassification systems. CST defines hierarchical relationships among sets using\ntotally ordered structures and coarse mappings, enabling us to adjust decision\ngranularity dynamically. Furthermore, coarse evaluations inherently involve a\ntrade-off between efficiency and information retention, as they simplify\ncomplex data representations at the cost of precision. To quantitatively assess\nthis trade-off, we introduce Kullback-Leibler (KL) Divergence as a measure of\ninformation loss in coarse evaluations, demonstrating the impact of coarse\npartitioning on decision accuracy. This study employs CST in grading systems,\nautomated recommendations, and risk assessments, demonstrating its potential to\nenhance fairness, reduce bias, and improve transparency in AI-driven\ndecision-making.\n","authors":["Takashi Izumo"],"pdf_url":"https://arxiv.org/pdf/2502.07347v4.pdf","comment":"28 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.07129v1","updated":"2025-03-10T09:57:50Z","published":"2025-03-10T09:57:50Z","title":"ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through\n  Action in Dynamic Offer Optimization","summary":"  Negotiation requires dynamically balancing self-interest and cooperation to\nmaximize one's own utility. Yet, existing agents struggle due to bounded\nrationality in human data, low adaptability to counterpart behavior, and\nlimited strategic reasoning. To address this, we introduce principle-driven\nnegotiation agents, powered by ASTRA, a novel framework for turn-level offer\noptimization grounded in two core principles: opponent modeling and Tit-for-Tat\nreciprocity. ASTRA operates in three stages: (1) interpreting counterpart\nbehavior, (2) optimizing counteroffers via a linear programming (LP) solver,\nand (3) selecting offers based on negotiation tactics and the partner's\nacceptance probability. Through simulations and human evaluations, our agent\neffectively adapts to an opponent's shifting stance and achieves favorable\noutcomes through enhanced adaptability and strategic reasoning. Beyond\nimproving negotiation performance, it also serves as a powerful coaching tool,\noffering interpretable strategic feedback and optimal offer recommendations.\n","authors":["Deuksin Kwon","Jiwon Hae","Emma Clift","Daniel Shamsoddini","Jonathan Gratch","Gale M. Lucas"],"pdf_url":"https://arxiv.org/pdf/2503.07129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02766v2","updated":"2025-03-10T09:51:12Z","published":"2025-01-06T05:18:13Z","title":"Are GNNs Actually Effective for Multimodal Fault Diagnosis in\n  Microservice Systems?","summary":"  Graph Neural Networks (GNNs) are widely adopted for fault diagnosis in\nmicroservice systems, premised on their ability to model service dependencies.\nHowever, the necessity of explicit graph structures remains underexamined, as\nexisting evaluations conflate preprocessing with architectural contributions.\nTo isolate the true value of GNNs, we propose DiagMLP, a deliberately minimal,\ntopology-agnostic baseline that retains multimodal fusion capabilities while\nexcluding graph modeling. Through ablation experiments across five datasets,\nDiagMLP achieves performance parity with state-of-the-art GNN-based methods in\nfault detection, localization, and classification. These findings challenge the\nprevailing assumption that graph structures are indispensable, revealing that:\n(i) preprocessing pipelines already encode critical dependency information, and\n(ii) GNN modules contribute marginally beyond multimodality fusion. Our work\nadvocates for systematic re-evaluation of architectural complexity and\nhighlights the need for standardized baseline protocols to validate model\ninnovations.\n","authors":["Fei Gao","Ruyue Xin","Xiaocui Li","Yaqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.02766v2.pdf","comment":"6 pages, 5 figures, submitted to conference"},{"id":"http://arxiv.org/abs/2410.18141v2","updated":"2025-03-10T09:49:31Z","published":"2024-10-22T11:23:11Z","title":"SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback","summary":"  RAG systems consist of multiple modules to work together. However, these\nmodules are usually separately trained. We argue that a system like RAG that\nincorporates multiple modules should be jointly optimized to achieve optimal\nperformance. To demonstrate this, we design a specific pipeline called\n\\textbf{SmartRAG} that includes a policy network and a retriever. The policy\nnetwork can serve as 1) a decision maker that decides when to retrieve, 2) a\nquery rewriter to generate a query most suited to the retriever, and 3) an\nanswer generator that produces the final response with/without the\nobservations. We then propose to jointly optimize the whole system using a\nreinforcement learning algorithm, with the reward designed to encourage the\nsystem to achieve the best performance with minimal retrieval cost. When\njointly optimized, all the modules can be aware of how other modules are\nworking and thus find the best way to work together as a complete system.\nEmpirical results demonstrate that the jointly optimized SmartRAG can achieve\nbetter performance than separately optimized counterparts.\n","authors":["Jingsheng Gao","Linxu Li","Weiyuan Li","Yuzhuo Fu","Bin Dai"],"pdf_url":"https://arxiv.org/pdf/2410.18141v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07110v1","updated":"2025-03-10T09:33:59Z","published":"2025-03-10T09:33:59Z","title":"A LSTM-Transformer Model for pulsation control of pVADs","summary":"  Methods: A method of the pulsation for a pVAD is proposed (AP-pVAD Model).\nAP-pVAD Model consists of two parts: NPQ Model and LSTM-Transformer Model.\n(1)The NPQ Model determines the mathematical relationship between motor speed,\npressure, and flow rate for the pVAD. (2)The Attention module of Transformer\nneural network is integrated into the LSTM neural network to form the new\nLSTM-Transformer Model to predict the pulsation time characteristic points for\nadjusting the motor speed of the pVAD. Results: The AP-pVAD Model is validated\nin three hydraulic experiments and an animal experiment. (1)The pressure\nprovided by pVAD calculated with the NPQ Model has a maximum error of only 2.15\nmmHg compared to the expected values. (2)The pulsation time characteristic\npoints predicted by the LSTM-Transformer Model shows a maximum prediction error\nof 1.78ms, which is significantly lower than other methods. (3)The in-vivo test\nof pVAD in animal experiment has significant improvements in aortic pressure.\nAnimals survive for over 27 hours after the initiation of pVAD operation.\nConclusion: (1)For a given pVAD, motor speed has a linear relationship with\npressure and a quadratic relationship with flow. (2)Deep learning can be used\nto predict pulsation characteristic time points, with the LSTM-Transformer\nModel demonstrating minimal prediction error and better robust performance\nunder conditions of limited dataset sizes, elevated noise levels, and diverse\nhyperparameter combinations, demonstrating its feasibility and effectiveness.\n","authors":["Chaoran E","Chenghan Chen","Yuyang Shi","Haiyun Wang","Peixin Hua","Xiwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17477v2","updated":"2025-03-10T09:32:00Z","published":"2024-01-30T22:22:55Z","title":"Detecting mental disorder on social media: a ChatGPT-augmented\n  explainable approach","summary":"  In the digital era, the prevalence of depressive symptoms expressed on social\nmedia has raised serious concerns, necessitating advanced methodologies for\ntimely detection. This paper addresses the challenge of interpretable\ndepression detection by proposing a novel methodology that effectively combines\nLarge Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and\nconversational agents like ChatGPT. In our methodology, explanations are\nachieved by integrating BERTweet, a Twitter-specific variant of BERT, into a\nnovel self-explanatory model, namely BERT-XDD, capable of providing both\nclassification and explanations via masked attention. The interpretability is\nfurther enhanced using ChatGPT to transform technical explanations into\nhuman-readable commentaries. By introducing an effective and modular approach\nfor interpretable depression detection, our methodology can contribute to the\ndevelopment of socially responsible digital platforms, fostering early\nintervention and support for mental health challenges under the guidance of\nqualified healthcare professionals.\n","authors":["Loris Belcastro","Riccardo Cantini","Fabrizio Marozzo","Domenico Talia","Paolo Trunfio"],"pdf_url":"https://arxiv.org/pdf/2401.17477v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01383v2","updated":"2025-03-10T09:29:33Z","published":"2024-12-02T11:12:01Z","title":"Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to\n  Improve Face Recognition with Synthetic Data","summary":"  Synthetic data is gaining increasing popularity for face recognition\ntechnologies, mainly due to the privacy concerns and challenges associated with\nobtaining real data, including diverse scenarios, quality, and demographic\ngroups, among others. It also offers some advantages over real data, such as\nthe large amount of data that can be generated or the ability to customize it\nto adapt to specific problem-solving needs. To effectively use such data, face\nrecognition models should also be specifically designed to exploit synthetic\ndata to its fullest potential. In order to promote the proposal of novel\nGenerative AI methods and synthetic data, and investigate the application of\nsynthetic data to better train face recognition systems, we introduce the 2nd\nFRCSyn-onGoing challenge, based on the 2nd Face Recognition Challenge in the\nEra of Synthetic Data (FRCSyn), originally launched at CVPR 2024. This is an\nongoing challenge that provides researchers with an accessible platform to\nbenchmark i) the proposal of novel Generative AI methods and synthetic data,\nand ii) novel face recognition systems that are specifically proposed to take\nadvantage of synthetic data. We focus on exploring the use of synthetic data\nboth individually and in combination with real data to solve current challenges\nin face recognition such as demographic bias, domain adaptation, and\nperformance constraints in demanding situations, such as age disparities\nbetween training and testing, changes in the pose, or occlusions. Very\ninteresting findings are obtained in this second edition, including a direct\ncomparison with the first one, in which synthetic databases were restricted to\nDCFace and GANDiffFace.\n","authors":["Ivan DeAndres-Tame","Ruben Tolosana","Pietro Melzi","Ruben Vera-Rodriguez","Minchul Kim","Christian Rathgeb","Xiaoming Liu","Luis F. Gomez","Aythami Morales","Julian Fierrez","Javier Ortega-Garcia","Zhizhou Zhong","Yuge Huang","Yuxi Mi","Shouhong Ding","Shuigeng Zhou","Shuai He","Lingzhi Fu","Heng Cong","Rongyu Zhang","Zhihong Xiao","Evgeny Smirnov","Anton Pimenov","Aleksei Grigorev","Denis Timoshenko","Kaleb Mesfin Asfaw","Cheng Yaw Low","Hao Liu","Chuyi Wang","Qing Zuo","Zhixiang He","Hatef Otroshi Shahreza","Anjith George","Alexander Unnervik","Parsa Rahimi","Sébastien Marcel","Pedro C. Neto","Marco Huber","Jan Niklas Kolf","Naser Damer","Fadi Boutros","Jaime S. Cardoso","Ana F. Sequeira","Andrea Atzori","Gianni Fenu","Mirko Marras","Vitomir Štruc","Jiang Yu","Zhangjie Li","Jichun Li","Weisong Zhao","Zhen Lei","Xiangyu Zhu","Xiao-Yu Zhang","Bernardo Biesseck","Pedro Vidal","Luiz Coelho","Roger Granada","David Menotti"],"pdf_url":"https://arxiv.org/pdf/2412.01383v2.pdf","comment":"Accepted in Information Fusion"},{"id":"http://arxiv.org/abs/2404.04475v2","updated":"2025-03-10T09:27:03Z","published":"2024-04-06T02:29:02Z","title":"Length-Controlled AlpacaEval: A Simple Way to Debias Automatic\n  Evaluators","summary":"  LLM-based auto-annotators have become a key component of the LLM development\nprocess due to their cost-effectiveness and scalability compared to human-based\nevaluation. However, these auto-annotators can introduce biases that are hard\nto remove. Even simple, known confounders such as preference for longer outputs\nremain in existing automated evaluation metrics. We propose a simple regression\nanalysis approach for controlling biases in auto-evaluations. As a real case\nstudy, we focus on reducing the length bias of AlpacaEval, a fast and\naffordable benchmark for instruction-tuned LLMs that uses LLMs to estimate\nresponse quality. Despite being highly correlated with human preferences,\nAlpacaEval is known to favor models that generate longer outputs. We introduce\na length-controlled AlpacaEval that aims to answer the counterfactual question:\n\"What would the preference be if the model's and baseline's output had the same\nlength?\" To achieve this, we first fit a generalized linear model to predict\nthe biased auto-annotator's preferences based on the mediators we want to\ncontrol for (length difference) and other relevant features. We then obtain\nlength-controlled preferences by predicting preferences while conditioning the\nGLM with a zero difference in lengths. Length-controlling not only improves the\nrobustness of the metric to manipulations in model verbosity, but we also find\nthat it increases the Spearman correlation with LMSYS Chatbot Arena from 0.94\nto 0.98.\n","authors":["Yann Dubois","Balázs Galambosi","Percy Liang","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2404.04475v2.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2503.07096v1","updated":"2025-03-10T09:20:38Z","published":"2025-03-10T09:20:38Z","title":"Correctness Learning: Deductive Verification Guided Learning for\n  Human-AI Collaboration","summary":"  Despite significant progress in AI and decision-making technologies in\nsafety-critical fields, challenges remain in verifying the correctness of\ndecision output schemes and verification-result driven design. We propose\ncorrectness learning (CL) to enhance human-AI collaboration integrating\ndeductive verification methods and insights from historical high-quality\nschemes. The typical pattern hidden in historical high-quality schemes, such as\nchange of task priorities in shared resources, provides critical guidance for\nintelligent agents in learning and decision-making. By utilizing deductive\nverification methods, we proposed patten-driven correctness learning (PDCL),\nformally modeling and reasoning the adaptive behaviors-or 'correctness\npattern'-of system agents based on historical high-quality schemes, capturing\nthe logical relationships embedded within these schemes. Using this logical\ninformation as guidance, we establish a correctness judgment and feedback\nmechanism to steer the intelligent decision model toward the 'correctness\npattern' reflected in historical high-quality schemes. Extensive experiments\nacross multiple working conditions and core parameters validate the framework's\ncomponents and demonstrate its effectiveness in improving decision-making and\nresource optimization.\n","authors":["Zhao Jin","Lu Jin","Yizhe Luo","Shuo Feng","Yucheng Shi","Kai Zheng","Xinde Yu","Mingliang Xu"],"pdf_url":"https://arxiv.org/pdf/2503.07096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14297v4","updated":"2025-03-10T09:17:56Z","published":"2024-05-23T08:18:30Z","title":"Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient\n  Transformer Models","summary":"  The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the\nefficiency of training and inference for Transformer-based foundational models,\nyielding promising results.However, the performance of SMoE heavily depends on\nthe choice of hyper-parameters, such as the number of experts and the number of\nexperts to be activated (referred to as top-k), resulting in significant\ncomputational overhead due to the extensive model training by searching over\nvarious hyper-parameter configurations. As a remedy, we introduce the Dynamic\nMixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating\nmethod that enables each token to automatically determine the number of experts\nto activate. (2) An adaptive process automatically adjusts the number of\nexperts during training. Extensive numerical results across Vision, Language,\nand Vision-Language tasks demonstrate the effectiveness of our approach to\nachieve competitive performance compared to GMoE for vision and language tasks,\nand MoE-LLaVA for vision-language tasks, while maintaining efficiency by\nactivating fewer parameters. Our code is available at\nhttps://github.com/LINs-lab/DynMoE.\n","authors":["Yongxin Guo","Zhenglin Cheng","Xiaoying Tang","Zhaopeng Tu","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14297v4.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.07091v1","updated":"2025-03-10T09:14:47Z","published":"2025-03-10T09:14:47Z","title":"FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset","summary":"  Due to the data-driven nature of current face identity (FaceID) customization\nmethods, all state-of-the-art models rely on large-scale datasets containing\nmillions of high-quality text-image pairs for training. However, none of these\ndatasets are publicly available, which restricts transparency and hinders\nfurther advancements in the field.\n  To address this issue, in this paper, we collect and release FaceID-6M, the\nfirst large-scale, open-source FaceID dataset containing 6 million high-quality\ntext-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M\nundergoes a rigorous image and text filtering steps to ensure dataset quality,\nincluding resolution filtering to maintain high-quality images and faces, face\nfiltering to remove images that lack human faces, and keyword-based strategy to\nretain descriptions containing human-related terms (e.g., nationality,\nprofessions and names). Through these cleaning processes, FaceID-6M provides a\nhigh-quality dataset optimized for training powerful FaceID customization\nmodels, facilitating advancements in the field by offering an open resource for\nresearch and development.\n  We conduct extensive experiments to show the effectiveness of our FaceID-6M,\ndemonstrating that models trained on our FaceID-6M dataset achieve performance\nthat is comparable to, and slightly better than currently available industrial\nmodels. Additionally, to support and advance research in the FaceID\ncustomization community, we make our code, datasets, and models fully publicly\navailable. Our codes, models, and datasets are available at:\nhttps://github.com/ShuheSH/FaceID-6M.\n","authors":["Shuhe Wang","Xiaoya Li","Jiwei Li","Guoyin Wang","Xiaofei Sun","Bob Zhu","Han Qiu","Mo Yu","Shengjie Shen","Eduard Hovy"],"pdf_url":"https://arxiv.org/pdf/2503.07091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15199v2","updated":"2025-03-10T09:12:04Z","published":"2024-01-26T20:51:55Z","title":"SCANIA Component X Dataset: A Real-World Multivariate Time Series\n  Dataset for Predictive Maintenance","summary":"  Predicting failures and maintenance time in predictive maintenance is\nchallenging due to the scarcity of comprehensive real-world datasets, and among\nthose available, few are of time series format. This paper introduces a\nreal-world, multivariate time series dataset collected exclusively from a\nsingle anonymized engine component (Component X) across a fleet of SCANIA\ntrucks. The dataset includes operational data, repair records, and\nspecifications related to Component X, while maintaining confidentiality\nthrough anonymization. It is well-suited for a range of machine learning\napplications, including classification, regression, survival analysis, and\nanomaly detection, particularly in predictive maintenance scenarios. The\ndataset's large population size, diverse features (in the form of histograms\nand numerical counters), and temporal information make it a unique resource in\nthe field. The objective of releasing this dataset is to give a broad range of\nresearchers the possibility of working with real-world data from an\ninternationally well-known company and introduce a standard benchmark to the\npredictive maintenance field, fostering reproducible research.\n","authors":["Zahra Kharazian","Tony Lindgren","Sindri Magnússon","Olof Steinert","Oskar Andersson Reyna"],"pdf_url":"https://arxiv.org/pdf/2401.15199v2.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.07082v1","updated":"2025-03-10T09:04:50Z","published":"2025-03-10T09:04:50Z","title":"On the Generalization of Representation Uncertainty in Earth Observation","summary":"  Recent advances in Computer Vision have introduced the concept of pretrained\nrepresentation uncertainty, enabling zero-shot uncertainty estimation. This\nholds significant potential for Earth Observation (EO), where trustworthiness\nis critical, yet the complexity of EO data poses challenges to\nuncertainty-aware methods. In this work, we investigate the generalization of\nrepresentation uncertainty in EO, considering the domain's unique semantic\ncharacteristics. We pretrain uncertainties on large EO datasets and propose an\nevaluation framework to assess their zero-shot performance in multi-label\nclassification and segmentation EO tasks. Our findings reveal that, unlike\nuncertainties pretrained on natural images, EO-pretraining exhibits strong\ngeneralization across unseen EO domains, geographic locations, and target\ngranularities, while maintaining sensitivity to variations in ground sampling\ndistance. We demonstrate the practical utility of pretrained uncertainties\nshowcasing their alignment with task-specific uncertainties in downstream\ntasks, their sensitivity to real-world EO image noise, and their ability to\ngenerate spatial uncertainty estimates out-of-the-box. Initiating the\ndiscussion on representation uncertainty in EO, our study provides insights\ninto its strengths and limitations, paving the way for future research in the\nfield. Code and weights are available at:\nhttps://github.com/Orion-AI-Lab/EOUncertaintyGeneralization.\n","authors":["Spyros Kondylatos","Nikolaos Ioannis Bountos","Dimitrios Michail","Xiao Xiang Zhu","Gustau Camps-Valls","Ioannis Papoutsis"],"pdf_url":"https://arxiv.org/pdf/2503.07082v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2403.16067v4","updated":"2025-03-10T09:02:42Z","published":"2024-03-24T08:34:08Z","title":"Robust Diffusion Models for Adversarial Purification","summary":"  Diffusion models (DMs) based adversarial purification (AP) has shown to be\nthe most powerful alternative to adversarial training (AT). However, these\nmethods neglect the fact that pre-trained diffusion models themselves are not\nrobust to adversarial attacks as well. Additionally, the diffusion process can\neasily destroy semantic information and generate a high quality image but\ntotally different from the original input image after the reverse process,\nleading to degraded standard accuracy. To overcome these issues, a natural idea\nis to harness adversarial training strategy to retrain or fine-tune the\npre-trained diffusion model, which is computationally prohibitive. We propose a\nnovel robust reverse process with adversarial guidance, which is independent of\ngiven pre-trained DMs and avoids retraining or fine-tuning the DMs. This robust\nguidance can not only ensure to generate purified examples retaining more\nsemantic content but also mitigate the accuracy-robustness trade-off of DMs for\nthe first time, which also provides DM-based AP an efficient adaptive ability\nto new attacks. Extensive experiments are conducted on CIFAR-10, CIFAR-100 and\nImageNet to demonstrate that our method achieves the state-of-the-art results\nand exhibits generalization against different attacks.\n","authors":["Guang Lin","Zerui Tao","Jianhai Zhang","Toshihisa Tanaka","Qibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16067v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02692v2","updated":"2025-03-10T09:01:48Z","published":"2024-12-03T18:59:10Z","title":"Scalable Image Tokenization with Index Backpropagation Quantization","summary":"  Existing vector quantization (VQ) methods struggle with scalability, largely\nattributed to the instability of the codebook that undergoes partial updates\nduring training. The codebook is prone to collapse as utilization decreases,\ndue to the progressively widening distribution gap between non-activated codes\nand visual features. To solve the problem, we propose Index Backpropagation\nQuantization (IBQ), a new VQ method for the joint optimization of all codebook\nembeddings and the visual encoder. Applying a straight-through estimator on the\none-hot categorical distribution between the encoded feature and codebook, all\ncodes are differentiable and maintain a consistent latent space with the visual\nencoder. IBQ enables scalable training of visual tokenizers and, for the first\ntime, achieves a large-scale codebook ($2^{18}$) with high dimension ($256$)\nand high utilization. Experiments on the standard ImageNet benchmark\ndemonstrate the scalability and superiority of IBQ, achieving competitive\nresults on reconstruction and the application of autoregressive visual\ngeneration. The code and models are available at\nhttps://github.com/TencentARC/SEED-Voken.\n","authors":["Fengyuan Shi","Zhuoyan Luo","Yixiao Ge","Yujiu Yang","Ying Shan","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.02692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07079v1","updated":"2025-03-10T09:00:43Z","published":"2025-03-10T09:00:43Z","title":"An Experience Report on Regression-Free Repair of Deep Neural Network\n  Model","summary":"  Systems based on Deep Neural Networks (DNNs) are increasingly being used in\nindustry. In the process of system operation, DNNs need to be updated in order\nto improve their performance. When updating DNNs, systems used in companies\nthat require high reliability must have as few regressions as possible. Since\nthe update of DNNs has a data-driven nature, it is difficult to suppress\nregressions as expected by developers. This paper identifies the requirements\nfor DNN updating in industry and presents a case study using techniques to meet\nthose requirements. In the case study, we worked on satisfying the requirement\nto update models trained on car images collected in Fujitsu assuming security\napplications without regression for a specific class. We were able to suppress\nregression by customizing the objective function based on NeuRecover, a DNN\nrepair technique. Moreover, we discuss some of the challenges identified in the\ncase study.\n","authors":["Takao Nakagawa","Susumu Tokumoto","Shogo Tokui","Fuyuki Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2503.07079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07077v1","updated":"2025-03-10T09:00:01Z","published":"2025-03-10T09:00:01Z","title":"Rule-Based Conflict-Free Decision Framework in Swarm Confrontation","summary":"  Traditional rule--based decision--making methods with interpretable\nadvantage, such as finite state machine, suffer from the jitter or\ndeadlock(JoD) problems in extremely dynamic scenarios. To realize agent swarm\nconfrontation, decision conflicts causing many JoD problems are a key issue to\nbe solved. Here, we propose a novel decision--making framework that integrates\nprobabilistic finite state machine, deep convolutional networks, and\nreinforcement learning to implement interpretable intelligence into agents. Our\nframework overcomes state machine instability and JoD problems, ensuring\nreliable and adaptable decisions in swarm confrontation. The proposed approach\ndemonstrates effective performance via enhanced human--like cooperation and\ncompetitive strategies in the rigorous evaluation of real experiments,\noutperforming other methods.\n","authors":["Zhaoqi Dong","Zhinan Wang","Quanqi Zheng","Bin Xu","Lei Chen","Jinhu Lv"],"pdf_url":"https://arxiv.org/pdf/2503.07077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07076v1","updated":"2025-03-10T08:59:10Z","published":"2025-03-10T08:59:10Z","title":"NFIG: Autoregressive Image Generation with Next-Frequency Prediction","summary":"  Autoregressive models have achieved promising results in natural language\nprocessing. However, for image generation tasks, they encounter substantial\nchallenges in effectively capturing long-range dependencies, managing\ncomputational costs, and most crucially, defining meaningful autoregressive\nsequences that reflect natural image hierarchies. To address these issues, we\npresent \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration\n(\\textbf{NFIG}), a novel framework that decomposes the image generation process\ninto multiple frequency-guided stages. Our approach first generates\nlow-frequency components to establish global structure with fewer tokens, then\nprogressively adds higher-frequency details, following the natural spectral\nhierarchy of images. This principled autoregressive sequence not only improves\nthe quality of generated images by better capturing true causal relationships\nbetween image components, but also significantly reduces computational overhead\nduring inference. Extensive experiments demonstrate that NFIG achieves\nstate-of-the-art performance with fewer steps, offering a more efficient\nsolution for image generation, with 1.25$\\times$ speedup compared to VAR-d20\nwhile achieving better performance (FID: 2.81) on the ImageNet-256 benchmark.\nWe hope that our insight of incorporating frequency-domain knowledge to guide\nautoregressive sequence design will shed light on future research. We will make\nour code publicly available upon acceptance of the paper.\n","authors":["Zhihao Huang","Xi Qiu","Yukuo Ma","Yifu Zhou","Chi Zhang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2503.07076v1.pdf","comment":"10 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.07070v1","updated":"2025-03-10T08:53:11Z","published":"2025-03-10T08:53:11Z","title":"PIED: Physics-Informed Experimental Design for Inverse Problems","summary":"  In many science and engineering settings, system dynamics are characterized\nby governing PDEs, and a major challenge is to solve inverse problems (IPs)\nwhere unknown PDE parameters are inferred based on observational data gathered\nunder limited budget. Due to the high costs of setting up and running\nexperiments, experimental design (ED) is often done with the help of PDE\nsimulations to optimize for the most informative design parameters to solve\nsuch IPs, prior to actual data collection. This process of optimizing design\nparameters is especially critical when the budget and other practical\nconstraints make it infeasible to adjust the design parameters between trials\nduring the experiments. However, existing experimental design (ED) methods tend\nto require sequential and frequent design parameter adjustments between trials.\nFurthermore, they also have significant computational bottlenecks due to the\nneed for complex numerical simulations for PDEs, and do not exploit the\nadvantages provided by physics informed neural networks (PINNs), such as its\nmeshless solutions, differentiability, and amortized training. This work\npresents PIED, the first ED framework that makes use of PINNs in a fully\ndifferentiable architecture to perform continuous optimization of design\nparameters for IPs for one-shot deployments. PIED overcomes existing methods'\ncomputational bottlenecks through parallelized computation and meta-learning of\nPINN parameter initialization, and proposes novel methods to effectively take\ninto account PINN training dynamics in optimizing the ED parameters. Through\nexperiments based on noisy simulated data and even real world experimental\ndata, we empirically show that given limited observation budget, PIED\nsignificantly outperforms existing ED methods in solving IPs, including\nchallenging settings where the inverse parameters are unknown functions rather\nthan just finite-dimensional.\n","authors":["Apivich Hemachandra","Gregory Kang Ruey Lau","See-Kiong Ng","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2503.07070v1.pdf","comment":"Accepted to 13th International Conference on Learning Representations\n  (ICLR 2025), 31 pages"},{"id":"http://arxiv.org/abs/2503.07067v1","updated":"2025-03-10T08:51:32Z","published":"2025-03-10T08:51:32Z","title":"DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs","summary":"  Despite the success of distillation in large language models (LLMs), most\nprior work applies identical loss functions to both teacher- and\nstudent-generated data. These strategies overlook the synergy between loss\nformulations and data types, leading to a suboptimal performance boost in\nstudent models. To address this, we propose DistiLLM-2, a contrastive approach\nthat simultaneously increases the likelihood of teacher responses and decreases\nthat of student responses by harnessing this synergy. Our extensive experiments\nshow that DistiLLM-2 not only builds high-performing student models across a\nwide range of tasks, including instruction-following and code generation, but\nalso supports diverse applications, such as preference alignment and\nvision-language extensions. These findings highlight the potential of a\ncontrastive approach to enhance the efficacy of LLM distillation by effectively\naligning teacher and student models across varied data types.\n","authors":["Jongwoo Ko","Tianyi Chen","Sungnyun Kim","Tianyu Ding","Luming Liang","Ilya Zharkov","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2503.07067v1.pdf","comment":"The code will be available soon at\n  https://github.com/jongwooko/distillm-2"},{"id":"http://arxiv.org/abs/2412.13432v3","updated":"2025-03-10T08:49:00Z","published":"2024-12-18T02:07:21Z","title":"Large Language Model Enhanced Recommender Systems: A Survey","summary":"  Large Language Model (LLM) has transformative potential in various domains,\nincluding recommender systems (RS). There have been a handful of research that\nfocuses on empowering the RS by LLM. However, previous efforts mainly focus on\nLLM as RS, which may face the challenge of intolerant inference costs by LLM.\nRecently, the integration of LLM into RS, known as LLM-Enhanced Recommender\nSystems (LLMERS), has garnered significant interest due to its potential to\naddress latency and memory constraints in real-world applications. This paper\npresents a comprehensive survey of the latest research efforts aimed at\nleveraging LLM to enhance RS capabilities. We identify a critical shift in the\nfield with the move towards incorporating LLM into the online system, notably\nby avoiding their use during inference. Our survey categorizes the existing\nLLMERS approaches into three primary types based on the component of the RS\nmodel being augmented: Knowledge Enhancement, Interaction Enhancement, and\nModel Enhancement. We provide an in-depth analysis of each category, discussing\nthe methodologies, challenges, and contributions of recent studies.\nFurthermore, we highlight several promising research directions that could\nfurther advance the field of LLMERS.\n","authors":["Qidong Liu","Xiangyu Zhao","Yuhao Wang","Yejing Wang","Zijian Zhang","Yuqi Sun","Xiang Li","Maolin Wang","Pengyue Jia","Chong Chen","Wei Huang","Feng Tian"],"pdf_url":"https://arxiv.org/pdf/2412.13432v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04832v2","updated":"2025-03-10T08:47:03Z","published":"2025-03-05T10:59:32Z","title":"RD Efficient FPGA Deployment of Learned Image Compression: Knowledge\n  Distillation and Hybrid Quantization","summary":"  Learnable Image Compression (LIC) has shown the potential to outperform\nstandardized video codecs in RD efficiency, prompting the research for\nhardware-friendly implementations. Most existing LIC hardware implementations\nprioritize latency to RD-efficiency and through an extensive exploration of the\nhardware design space. We present a novel design paradigm where the burden of\ntuning the design for a specific hardware platform is shifted towards model\ndimensioning and without compromising on RD-efficiency. First, we design a\nframework for distilling a leaner student LIC model from a reference teacher:\nby tuning a single model hyperparameters, we can meet the constraints of\ndifferent hardware platforms without a complex hardware design exploration.\nSecond, we propose a hardware-friendly implementation of the Generalized\nDivisive Normalization (GDN) activation that preserves RD efficiency even post\nparameter quantization. Third, we design a pipelined FPGA configuration which\ntakes full advantage of available FPGA resources by leveraging parallel\nprocessing and optimizing resource allocation. Our experiments with a state of\nthe art LIC model show that we outperform all existing FPGA implementations\nwhile performing very close to the original model in terms of RD efficiency.\n","authors":["Alaa Mazouz","Sumanta Chaudhuri","Marco Cagnanzzo","Mihai Mitrea","Enzo Tartaglione","Attilio Fiandrotti"],"pdf_url":"https://arxiv.org/pdf/2503.04832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00136v2","updated":"2025-03-10T08:43:03Z","published":"2024-11-28T16:19:37Z","title":"FonTS: Text Rendering with Typography and Style Controls","summary":"  Visual text rendering are widespread in various real-world applications,\nrequiring careful font selection and typographic choices. Recent progress in\ndiffusion transformer (DiT)-based text-to-image (T2I) models show promise in\nautomating these processes. However, these methods still encounter challenges\nlike inconsistent fonts, style variation, and limited fine-grained control,\nparticularly at the word-level. This paper proposes a two-stage DiT-based\npipeline to address these problems by enhancing controllability over typography\nand style in text rendering. We introduce typography control fine-tuning\n(TC-FT), an parameter-efficient fine-tuning method (on $5\\%$ key parameters)\nwith enclosing typography control tokens (ETC-tokens), which enables precise\nword-level application of typographic features. To further address style\ninconsistency in text rendering, we propose a text-agnostic style control\nadapter (SCA) that prevents content leakage while enhancing style consistency.\nTo implement TC-FT and SCA effectively, we incorporated HTML-render into the\ndata synthesis pipeline and proposed the first word-level controllable dataset.\nThrough comprehensive experiments, we demonstrate the effectiveness of our\napproach in achieving superior word-level typographic control, font\nconsistency, and style consistency in text rendering tasks. The datasets and\nmodels will be available for academic use.\n","authors":["Wenda Shi","Yiren Song","Dengming Zhang","Jiaming Liu","Xingxing Zou"],"pdf_url":"https://arxiv.org/pdf/2412.00136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07056v1","updated":"2025-03-10T08:42:26Z","published":"2025-03-10T08:42:26Z","title":"Generative method for aerodynamic optimization based on classifier-free\n  guided denoising diffusion probabilistic model","summary":"  Inverse design approach, which directly generates optimal aerodynamic shape\nwith neural network models to meet designated performance targets, has drawn\nenormous attention. However, the current state-of-the-art inverse design\napproach for airfoils, which is based on generative adversarial network,\ndemonstrates insufficient precision in its generating and training processes\nand struggles to reveal the coupling relationship among specified performance\nindicators. To address these issues, the airfoil inverse design framework based\non the classifier-free guided denoising diffusion probabilistic model (CDDPM)\nis proposed innovatively in this paper. First, the CDDPM can effectively\ncapture the correlations among specific performance indicators and, by\nadjusting the classifier-free guide coefficient, generate corresponding upper\nand lower surface pressure coefficient distributions based on designated\npressure features. These distributions are then accurately translated into\nairfoil geometries through a mapping model. Experimental results using\nclassical transonic airfoils as examples show that the inverse design based on\nCDDPM can generate a variety of pressure coefficient distributions, which\nenriches the diversity of design results. Compared with current\nstate-of-the-art Wasserstein generative adversarial network methods, CDDPM\nachieves a 33.6% precision improvement in airfoil generating tasks. Moreover, a\npractical method to readjust each performance indicator value is proposed based\non global optimization algorithm in conjunction with active learning strategy,\naiming to provide rational value combination of performance indicators for the\ninverse design framework. This work is not only suitable for the airfoils\ndesign, but also has the capability to apply to optimization process of general\nproduct parts targeting selected performance indicators.\n","authors":["Shisong Deng","Qiang Zhang","Zhengyang Cai"],"pdf_url":"https://arxiv.org/pdf/2503.07056v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2411.10115v2","updated":"2025-03-10T08:40:41Z","published":"2024-11-15T11:29:31Z","title":"Memorization in Attention-only Transformers","summary":"  Recent research has explored the memorization capacity of multi-head\nattention, but these findings are constrained by unrealistic limitations on the\ncontext size. We present a novel proof for language-based Transformers that\nextends the current hypothesis to any context size. Our approach improves upon\nthe state-of-the-art by achieving more effective exact memorization with an\nattention layer, while also introducing the concept of approximate memorization\nof distributions. Through experimental validation, we demonstrate that our\nproposed bounds more accurately reflect the true memorization capacity of\nlanguage models, and provide a precise comparison with prior work.\n","authors":["Léo Dana","Muni Sreenivas Pydi","Yann Chevaleyre"],"pdf_url":"https://arxiv.org/pdf/2411.10115v2.pdf","comment":"16 pages, 6 figures, submitted to AISTATS 2025,"},{"id":"http://arxiv.org/abs/2503.07050v1","updated":"2025-03-10T08:35:51Z","published":"2025-03-10T08:35:51Z","title":"TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion\n  Transformers in Image Generation","summary":"  Diffusion Transformers (DiTs) are a powerful yet underexplored class of\ngenerative models compared to U-Net-based diffusion models. To bridge this gap,\nwe introduce TIDE (Temporal-aware Sparse Autoencoders for Interpretable\nDiffusion transformErs), a novel framework that enhances temporal\nreconstruction within DiT activation layers across denoising steps. TIDE\nemploys Sparse Autoencoders (SAEs) with a sparse bottleneck layer to extract\ninterpretable and hierarchical features, revealing that diffusion models\ninherently learn hierarchical features at multiple levels (e.g., 3D, semantic,\nclass) during generative pre-training. Our approach achieves state-of-the-art\nreconstruction performance, with a mean squared error (MSE) of 1e-3 and a\ncosine similarity of 0.97, demonstrating superior accuracy in capturing\nactivation dynamics along the denoising trajectory. Beyond interpretability, we\nshowcase TIDE's potential in downstream applications such as sparse\nactivation-guided image editing and style transfer, enabling improved\ncontrollability for generative systems. By providing a comprehensive training\nand evaluation protocol tailored for DiTs, TIDE contributes to developing more\ninterpretable, transparent, and trustworthy generative models.\n","authors":["Victor Shea-Jay Huang","Le Zhuo","Yi Xin","Zhaokai Wang","Peng Gao","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2503.07050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07044v1","updated":"2025-03-10T08:32:33Z","published":"2025-03-10T08:32:33Z","title":"DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data\n  Science","summary":"  Data Science tasks are multifaceted, dynamic, and often domain-specific.\nExisting LLM-based approaches largely concentrate on isolated phases,\nneglecting the interdependent nature of many data science tasks and limiting\ntheir capacity for comprehensive end-to-end support. We propose DatawiseAgent,\na notebook-centric LLM agent framework that unifies interactions among user,\nagent and the computational environment through markdown and executable code\ncells, supporting flexible and adaptive automated data science. Built on a\nFinite State Transducer(FST), DatawiseAgent orchestrates four stages, including\nDSF-like planning, incremental execution, self-debugging, and post-filtering.\nSpecifically, the DFS-like planning stage systematically explores the solution\nspace, while incremental execution harnesses real-time feedback and\naccommodates LLM's limited capabilities to progressively complete tasks. The\nself-debugging and post-filtering modules further enhance reliability by\ndiagnosing and correcting errors and pruning extraneous information. Extensive\nexperiments on diverse tasks, including data analysis, visualization, and data\nmodeling, show that DatawiseAgent consistently outperforms or matches\nstate-of-the-art methods across multiple model settings. These results\nhighlight its potential to generalize across data science scenarios and lay the\ngroundwork for more efficient, fully automated workflows.\n","authors":["Ziming You","Yumiao Zhang","Dexuan Xu","Yiwei Lou","Yandong Yan","Wei Wang","Huaming Zhang","Yu Huang"],"pdf_url":"https://arxiv.org/pdf/2503.07044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.09108v3","updated":"2025-03-10T08:30:52Z","published":"2024-08-17T06:23:38Z","title":"Temporal Reversal Regularization for Spiking Neural Networks: Hybrid\n  Spatio-Temporal Invariance for Generalization","summary":"  Spiking neural networks (SNNs) have received widespread attention as an\nultra-low power computing paradigm. Recent studies have shown that SNNs suffer\nfrom severe overfitting, which limits their generalization performance. In this\npaper, we propose a simple yet effective Temporal Reversal Regularization (TRR)\nto mitigate overfitting during training and facilitate generalization of SNNs.\nWe exploit the inherent temporal properties of SNNs to perform input/feature\ntemporal reversal perturbations, prompting the SNN to produce original-reversed\nconsistent outputs and learn perturbation-invariant representations. To further\nenhance generalization, we utilize the lightweight ``star operation\" (Hadamard\nproduct) for feature hybridization of original and temporally reversed spike\nfiring rates, which expands the implicit dimensionality and acts as a\nspatio-temporal regularizer. We show theoretically that our method is able to\ntighten the upper bound of the generalization error, and extensive experiments\non static/neuromorphic recognition as well as 3D point cloud classification\ntasks demonstrate its effectiveness, versatility, and adversarial robustness.\nIn particular, our regularization significantly improves the recognition\naccuracy of low-latency SNN for neuromorphic objects, contributing to the\nreal-world deployment of neuromorphic computational software-hardware\nintegration.\n","authors":["Lin Zuo","Yongqi Ding","Wenwei Luo","Mengmeng Jing","Kunshan Yang"],"pdf_url":"https://arxiv.org/pdf/2408.09108v3.pdf","comment":"17 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.07036v1","updated":"2025-03-10T08:21:36Z","published":"2025-03-10T08:21:36Z","title":"Bot Wars Evolved: Orchestrating Competing LLMs in a Counterstrike\n  Against Phone Scams","summary":"  We present \"Bot Wars,\" a framework using Large Language Models (LLMs)\nscam-baiters to counter phone scams through simulated adversarial dialogues.\nOur key contribution is a formal foundation for strategy emergence through\nchain-of-thought reasoning without explicit optimization. Through a novel\ntwo-layer prompt architecture, our framework enables LLMs to craft\ndemographically authentic victim personas while maintaining strategic\ncoherence. We evaluate our approach using a dataset of 3,200 scam dialogues\nvalidated against 179 hours of human scam-baiting interactions, demonstrating\nits effectiveness in capturing complex adversarial dynamics. Our systematic\nevaluation through cognitive, quantitative, and content-specific metrics shows\nthat GPT-4 excels in dialogue naturalness and persona authenticity, while\nDeepseek demonstrates superior engagement sustainability.\n","authors":["Nardine Basta","Conor Atkins","Dali Kaafar"],"pdf_url":"https://arxiv.org/pdf/2503.07036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07029v1","updated":"2025-03-10T08:10:28Z","published":"2025-03-10T08:10:28Z","title":"Availability-aware Sensor Fusion via Unified Canonical Space for 4D\n  Radar, LiDAR, and Camera","summary":"  Sensor fusion of camera, LiDAR, and 4-dimensional (4D) Radar has brought a\nsignificant performance improvement in autonomous driving (AD). However, there\nstill exist fundamental challenges: deeply coupled fusion methods assume\ncontinuous sensor availability, making them vulnerable to sensor degradation\nand failure, whereas sensor-wise cross-attention fusion methods struggle with\ncomputational cost and unified feature representation. This paper presents\navailability-aware sensor fusion (ASF), a novel method that employs unified\ncanonical projection (UCP) to enable consistency in all sensor features for\nfusion and cross-attention across sensors along patches (CASAP) to enhance\nrobustness of sensor fusion against sensor degradation and failure. As a\nresult, the proposed ASF shows a superior object detection performance to the\nexisting state-of-the-art fusion methods under various weather and sensor\ndegradation (or failure) conditions; Extensive experiments on the K-Radar\ndataset demonstrate that ASF achieves improvements of 9.7% in AP BEV (87.2%)\nand 20.1% in AP 3D (73.6%) in object detection at IoU=0.5, while requiring a\nlow computational cost. The code will be available at\nhttps://github.com/kaist-avelab/K-Radar.\n","authors":["Dong-Hee Paek","Seung-Hyun Kong"],"pdf_url":"https://arxiv.org/pdf/2503.07029v1.pdf","comment":"Arxiv preprint"},{"id":"http://arxiv.org/abs/2503.07026v1","updated":"2025-03-10T08:06:51Z","published":"2025-03-10T08:06:51Z","title":"Erase Diffusion: Empowering Object Removal Through Calibrating Diffusion\n  Pathways","summary":"  Erase inpainting, or object removal, aims to precisely remove target objects\nwithin masked regions while preserving the overall consistency of the\nsurrounding content. Despite diffusion-based methods have made significant\nstrides in the field of image inpainting, challenges remain regarding the\nemergence of unexpected objects or artifacts. We assert that the inexact\ndiffusion pathways established by existing standard optimization paradigms\nconstrain the efficacy of object removal. To tackle these challenges, we\npropose a novel Erase Diffusion, termed EraDiff, aimed at unleashing the\npotential power of standard diffusion in the context of object removal. In\ncontrast to standard diffusion, the EraDiff adapts both the optimization\nparadigm and the network to improve the coherence and elimination of the\nerasure results. We first introduce a Chain-Rectifying Optimization (CRO)\nparadigm, a sophisticated diffusion process specifically designed to align with\nthe objectives of erasure. This paradigm establishes innovative diffusion\ntransition pathways that simulate the gradual elimination of objects during\noptimization, allowing the model to accurately capture the intent of object\nremoval. Furthermore, to mitigate deviations caused by artifacts during the\nsampling pathways, we develop a simple yet effective Self-Rectifying Attention\n(SRA) mechanism. The SRA calibrates the sampling pathways by altering\nself-attention activation, allowing the model to effectively bypass artifacts\nwhile further enhancing the coherence of the generated content. With this\ndesign, our proposed EraDiff achieves state-of-the-art performance on the\nOpenImages V5 dataset and demonstrates significant superiority in real-world\nscenarios.\n","authors":["Yi Liu","Hao Zhou","Wenxiang Shang","Ran Lin","Benlei Cui"],"pdf_url":"https://arxiv.org/pdf/2503.07026v1.pdf","comment":"accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.07025v1","updated":"2025-03-10T08:06:30Z","published":"2025-03-10T08:06:30Z","title":"Weak Supervision for Improved Precision in Search Systems","summary":"  Labeled datasets are essential for modern search engines, which increasingly\nrely on supervised learning methods like Learning to Rank and massive amounts\nof data to power deep learning models. However, creating these datasets is both\ntime-consuming and costly, leading to the common use of user click and activity\nlogs as proxies for relevance. In this paper, we present a weak supervision\napproach to infer the quality of query-document pairs and apply it within a\nLearning to Rank framework to enhance the precision of a large-scale search\nsystem.\n","authors":["Sriram Vasudevan"],"pdf_url":"https://arxiv.org/pdf/2503.07025v1.pdf","comment":"Accepted to the AAAI 2025 Workshop on Computational Jobs Marketplace"},{"id":"http://arxiv.org/abs/2503.07020v1","updated":"2025-03-10T08:01:41Z","published":"2025-03-10T08:01:41Z","title":"Combating Partial Perception Deficit in Autonomous Driving with\n  Multimodal LLM Commonsense","summary":"  Partial perception deficits can compromise autonomous vehicle safety by\ndisrupting environmental understanding. Current protocols typically respond\nwith immediate stops or minimal-risk maneuvers, worsening traffic flow and\nlacking flexibility for rare driving scenarios. In this paper, we propose\nLLM-RCO, a framework leveraging large language models to integrate human-like\ndriving commonsense into autonomous systems facing perception deficits. LLM-RCO\nfeatures four key modules: hazard inference, short-term motion planner, action\ncondition verifier, and safety constraint generator. These modules interact\nwith the dynamic driving environment, enabling proactive and context-aware\ncontrol actions to override the original control policy of autonomous agents.\nTo improve safety in such challenging conditions, we construct DriveLM-Deficit,\na dataset of 53,895 video clips featuring deficits of safety-critical objects,\ncomplete with annotations for LLM-based hazard inference and motion planning\nfine-tuning. Extensive experiments in adverse driving conditions with the CARLA\nsimulator demonstrate that systems equipped with LLM-RCO significantly improve\ndriving performance, highlighting its potential for enhancing autonomous\ndriving resilience against adverse perception deficits. Our results also show\nthat LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements\ninstead of conservative stops in the context of perception deficits.\n","authors":["Yuting Hu","Chenhui Xu","Ruiyang Qin","Dancheng Liu","Amir Nassereldine","Yiyu Shi","Jinjun Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.07020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07004v1","updated":"2025-03-10T07:38:46Z","published":"2025-03-10T07:38:46Z","title":"NukesFormers: Unpaired Hyperspectral Image Generation with Non-Uniform\n  Domain Alignment","summary":"  The inherent difficulty in acquiring accurately co-registered\nRGB-hyperspectral image (HSI) pairs has significantly impeded the practical\ndeployment of current data-driven Hyperspectral Image Generation (HIG) networks\nin engineering applications. Gleichzeitig, the ill-posed nature of the aligning\nconstraints, compounded with the complexities of mining cross-domain features,\nalso hinders the advancement of unpaired HIG (UnHIG) tasks. In this paper, we\nconquer these challenges by modeling the UnHIG to range space interaction and\ncompensations of null space through Range-Null Space Decomposition (RND)\nmethodology. Specifically, the introduced contrastive learning effectively\naligns the geometric and spectral distributions of unpaired data by building\nthe interaction of range space, considering the consistent feature in\ndegradation process. Following this, we map the frequency representations of\ndual-domain input and thoroughly mining the null space, like degraded and\nhigh-frequency components, through the proposed Non-uniform Kolmogorov-Arnold\nNetworks. Extensive comparative experiments demonstrate that it establishes a\nnew benchmark in UnHIG.\n","authors":["Jiaojiao Li","Shiyao Duan","Haitao XU","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2503.07004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03592v2","updated":"2025-03-10T07:36:46Z","published":"2025-03-05T15:26:59Z","title":"English K_Quantization of LLMs Does Not Disproportionately Diminish\n  Multilingual Performance","summary":"  For consumer usage of locally deployed LLMs, the GGUF format and\nk\\_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to yielded\nnon-significant results indicating that current quantization practices do not\ndisproportionately harm multilingual performance.\n","authors":["Karl Audun Borgersen"],"pdf_url":"https://arxiv.org/pdf/2503.03592v2.pdf","comment":"8 pages, 6 figures, v2"},{"id":"http://arxiv.org/abs/2406.17098v2","updated":"2025-03-10T07:33:32Z","published":"2024-06-24T19:36:45Z","title":"Learning Temporal Distances: Contrastive Successor Features Can Provide\n  a Metric Structure for Decision-Making","summary":"  Temporal distances lie at the heart of many algorithms for planning, control,\nand reinforcement learning that involve reaching goals, allowing one to\nestimate the transit time between two states. However, prior attempts to define\nsuch temporal distances in stochastic settings have been stymied by an\nimportant limitation: these prior approaches do not satisfy the triangle\ninequality. This is not merely a definitional concern, but translates to an\ninability to generalize and find shortest paths. In this paper, we build on\nprior work in contrastive learning and quasimetrics to show how successor\nfeatures learned by contrastive learning (after a change of variables) form a\ntemporal distance that does satisfy the triangle inequality, even in stochastic\nsettings. Importantly, this temporal distance is computationally efficient to\nestimate, even in high-dimensional and stochastic settings. Experiments in\ncontrolled settings and benchmark suites demonstrate that an RL algorithm based\non these new temporal distances exhibits combinatorial generalization (i.e.,\n\"stitching\") and can sometimes learn more quickly than prior methods, including\nthose based on quasimetrics.\n","authors":["Vivek Myers","Chongyi Zheng","Anca Dragan","Sergey Levine","Benjamin Eysenbach"],"pdf_url":"https://arxiv.org/pdf/2406.17098v2.pdf","comment":"Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)"},{"id":"http://arxiv.org/abs/2411.08832v2","updated":"2025-03-10T07:30:55Z","published":"2024-11-13T18:12:15Z","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","summary":"  We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.\n","authors":["Reece O'Mahoney","Alexander L. Mitchell","Wanming Yu","Ingmar Posner","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2411.08832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11882v4","updated":"2025-03-10T07:25:31Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v4.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, QwQ-32b, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2503.06987v1","updated":"2025-03-10T07:06:47Z","published":"2025-03-10T07:06:47Z","title":"Social Bias Benchmark for Generation: A Comparison of Generation and\n  QA-Based Evaluations","summary":"  Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.\n","authors":["Jiho Jin","Woosung Kang","Junho Myung","Alice Oh"],"pdf_url":"https://arxiv.org/pdf/2503.06987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06982v1","updated":"2025-03-10T06:57:10Z","published":"2025-03-10T06:57:10Z","title":"Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective\n  on Low-Rank Adaptation in Matrix Factorization","summary":"  Despite the empirical success of Low-Rank Adaptation (LoRA) in fine-tuning\npre-trained models, there is little theoretical understanding of how\nfirst-order methods with carefully crafted initialization adapt models to new\ntasks. In this work, we take the first step towards bridging this gap by\ntheoretically analyzing the learning dynamics of LoRA for matrix factorization\n(MF) under gradient flow (GF), emphasizing the crucial role of initialization.\nFor small initialization, we theoretically show that GF converges to a\nneighborhood of the optimal solution, with smaller initialization leading to\nlower final error. Our analysis shows that the final error is affected by the\nmisalignment between the singular spaces of the pre-trained model and the\ntarget matrix, and reducing the initialization scale improves alignment. To\naddress this misalignment, we propose a spectral initialization for LoRA in MF\nand theoretically prove that GF with small spectral initialization converges to\nthe fine-tuning task with arbitrary precision. Numerical experiments from MF\nand image classification validate our findings.\n","authors":["Ziqing Xu","Hancheng Min","Lachlan Ewen MacDonald","Jinqi Luo","Salma Tarmoun","Enrique Mallada","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2503.06982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07818v6","updated":"2025-03-10T06:52:03Z","published":"2024-02-12T17:24:15Z","title":"Differentially Private Zeroth-Order Methods for Scalable Large Language\n  Model Finetuning","summary":"  Fine-tuning on task-specific datasets is a widely-embraced paradigm of\nharnessing the powerful capability of pretrained LLMs for various downstream\ntasks. Due to the popularity of LLMs fine-tuning and its accompanying privacy\nconcerns, differentially private (DP) fine-tuning of pretrained LLMs has been\nwidely used to safeguarding the privacy of task-specific datasets. Lying at the\ndesign core of DP LLM fine-tuning methods is the satisfactory tradeoff among\nprivacy, utility, and scalability. Most existing methods build upon the seminal\nwork of DP-SGD. Despite pushing the scalability of DP-SGD to its limit,\nDP-SGD-based fine-tuning methods are unfortunately limited by the inherent\ninefficiency of SGD.\n  In this paper, we investigate the potential of DP zeroth-order methods for\nLLM pretraining, which avoids the scalability bottleneck of SGD by\napproximating the gradient with the more efficient zeroth-order gradient.\nRather than treating the zeroth-order method as a drop-in replacement for SGD,\nthis paper presents a comprehensive study both theoretically and empirically.\nFirst, we propose the stagewise DP zeroth-order method (DP-ZOSO) that\ndynamically schedules key hyperparameters. This design is grounded on the\nsynergy between DP random perturbation and the gradient approximation error of\nthe zeroth-order method, and its effect on fine-tuning trajectory.\n  We provide theoretical analysis for both proposed methods. We conduct\nextensive empirical analysis on both encoder-only masked language model and\ndecoder-only autoregressive language model, achieving impressive results in\nterms of scalability and utility regardless of the class of tasks (compared\nwith DPZero, DP-ZOPO improves $4.5\\%$ on SST-5, $5.5\\%$ on MNLI with\nRoBERTa-Large and 9.2\\% on CB, 3.9\\% on BoolQ with OPT-2.7b when $\\epsilon=4$,\ndemonstrates more significant enhancement in performance on more complicated\ntasks).\n","authors":["Z Liu","J Lou","W Bao","Y Hu","B Li","Z Qin","K Ren"],"pdf_url":"https://arxiv.org/pdf/2402.07818v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04809v2","updated":"2025-03-10T06:49:01Z","published":"2025-03-04T07:40:02Z","title":"PanguIR Technical Report for NTCIR-18 AEOLLM Task","summary":"  As large language models (LLMs) gain widespread attention in both academia\nand industry, it becomes increasingly critical and challenging to effectively\nevaluate their capabilities. Existing evaluation methods can be broadly\ncategorized into two types: manual evaluation and automatic evaluation. Manual\nevaluation, while comprehensive, is often costly and resource-intensive.\nConversely, automatic evaluation offers greater scalability but is constrained\nby the limitations of its evaluation criteria (dominated by reference-based\nanswers). To address these challenges, NTCIR-18 introduced the AEOLLM\n(Automatic Evaluation of LLMs) task, aiming to encourage reference-free\nevaluation methods that can overcome the limitations of existing approaches. In\nthis paper, to enhance the evaluation performance of the AEOLLM task, we\npropose three key methods to improve the reference-free evaluation: 1)\nMulti-model Collaboration: Leveraging multiple LLMs to approximate human\nratings across various subtasks; 2) Prompt Auto-optimization: Utilizing LLMs to\niteratively refine the initial task prompts based on evaluation feedback from\ntraining samples; and 3) In-context Learning (ICL) Optimization: Based on the\nmulti-task evaluation feedback, we train a specialized in-context example\nretrieval model, combined with a semantic relevance retrieval model, to jointly\nidentify the most effective in-context learning examples. Experiments conducted\non the final dataset demonstrate that our approach achieves superior\nperformance on the AEOLLM task.\n","authors":["Lang Mei","Chong Chen","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2503.04809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06978v1","updated":"2025-03-10T06:47:38Z","published":"2025-03-10T06:47:38Z","title":"Lightweight Multimodal Artificial Intelligence Framework for Maritime\n  Multi-Scene Recognition","summary":"  Maritime Multi-Scene Recognition is crucial for enhancing the capabilities of\nintelligent marine robotics, particularly in applications such as marine\nconservation, environmental monitoring, and disaster response. However, this\ntask presents significant challenges due to environmental interference, where\nmarine conditions degrade image quality, and the complexity of maritime scenes,\nwhich requires deeper reasoning for accurate recognition. Pure vision models\nalone are insufficient to address these issues. To overcome these limitations,\nwe propose a novel multimodal Artificial Intelligence (AI) framework that\nintegrates image data, textual descriptions and classification vectors\ngenerated by a Multimodal Large Language Model (MLLM), to provide richer\nsemantic understanding and improve recognition accuracy. Our framework employs\nan efficient multimodal fusion mechanism to further enhance model robustness\nand adaptability in complex maritime environments. Experimental results show\nthat our model achieves 98$\\%$ accuracy, surpassing previous SOTA models by\n3.5$\\%$. To optimize deployment on resource-constrained platforms, we adopt\nactivation-aware weight quantization (AWQ) as a lightweight technique, reducing\nthe model size to 68.75MB with only a 0.5$\\%$ accuracy drop while significantly\nlowering computational overhead. This work provides a high-performance solution\nfor real-time maritime scene recognition, enabling Autonomous Surface Vehicles\n(ASVs) to support environmental monitoring and disaster response in\nresource-limited settings.\n","authors":["Xinyu Xi","Hua Yang","Shentai Zhang","Yijie Liu","Sijin Sun","Xiuju Fu"],"pdf_url":"https://arxiv.org/pdf/2503.06978v1.pdf","comment":"19 pages, 4 figures, submitted to Engineering Applications of\n  Artificial Intelligence"},{"id":"http://arxiv.org/abs/2501.08109v3","updated":"2025-03-10T06:43:36Z","published":"2025-01-14T13:40:08Z","title":"Data-driven inventory management for new products: An adjusted Dyna-$Q$\n  approach with transfer learning","summary":"  In this paper, we propose a novel reinforcement learning algorithm for\ninventory management of newly launched products with no historical demand\ninformation. The algorithm follows the classic Dyna-$Q$ structure, balancing\nthe model-free and model-based approaches, while accelerating the training\nprocess of Dyna-$Q$ and mitigating the model discrepancy generated by the\nmodel-based feedback. Based on the idea of transfer learning, warm-start\ninformation from the demand data of existing similar products can be\nincorporated into the algorithm to further stabilize the early-stage training\nand reduce the variance of the estimated optimal policy. Our approach is\nvalidated through a case study of bakery inventory management with real data.\nThe adjusted Dyna-$Q$ shows up to a 23.7\\% reduction in average daily cost\ncompared with $Q$-learning, and up to a 77.5\\% reduction in training time\nwithin the same horizon compared with classic Dyna-$Q$. By using transfer\nlearning, it can be found that the adjusted Dyna-$Q$ has the lowest total cost,\nlowest variance in total cost, and relatively low shortage percentages among\nall the benchmarking algorithms under a 30-day testing.\n","authors":["Xinye Qu","Longxiao Liu","Wenjie Huang"],"pdf_url":"https://arxiv.org/pdf/2501.08109v3.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.00547v3","updated":"2025-03-10T06:43:03Z","published":"2024-11-30T17:40:49Z","title":"Motion Dreamer: Boundary Conditional Motion Reasoning for Physically\n  Coherent Video Generation","summary":"  Recent advances in video generation have shown promise for generating future\nscenarios, critical for planning and control in autonomous driving and embodied\nintelligence. However, real-world applications demand more than visually\nplausible predictions; they require reasoning about object motions based on\nexplicitly defined boundary conditions, such as initial scene image and partial\nobject motion. We term this capability Boundary Conditional Motion Reasoning.\nCurrent approaches either neglect explicit user-defined motion constraints,\nproducing physically inconsistent motions, or conversely demand complete motion\ninputs, which are rarely available in practice. Here we introduce Motion\nDreamer, a two-stage framework that explicitly separates motion reasoning from\nvisual synthesis, addressing these limitations. Our approach introduces\ninstance flow, a sparse-to-dense motion representation enabling effective\nintegration of partial user-defined motions, and the motion inpainting strategy\nto robustly enable reasoning motions of other objects. Extensive experiments\ndemonstrate that Motion Dreamer significantly outperforms existing methods,\nachieving superior motion plausibility and visual realism, thus bridging the\ngap towards practical boundary conditional motion reasoning. Our webpage is\navailable: https://envision-research.github.io/MotionDreamer/.\n","authors":["Tianshuo Xu","Zhifei Chen","Leyi Wu","Hao Lu","Yuying Chen","Lihui Jiang","Bingbing Liu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.00547v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06973v1","updated":"2025-03-10T06:37:42Z","published":"2025-03-10T06:37:42Z","title":"A Multimodal Benchmark Dataset and Model for Crop Disease Diagnosis","summary":"  While conversational generative AI has shown considerable potential in\nenhancing decision-making for agricultural professionals, its exploration has\npredominantly been anchored in text-based interactions. The evolution of\nmultimodal conversational AI, leveraging vast amounts of image-text data from\ndiverse sources, marks a significant stride forward. However, the application\nof such advanced vision-language models in the agricultural domain,\nparticularly for crop disease diagnosis, remains underexplored. In this work,\nwe present the crop disease domain multimodal (CDDM) dataset, a pioneering\nresource designed to advance the field of agricultural research through the\napplication of multimodal learning techniques. The dataset comprises 137,000\nimages of various crop diseases, accompanied by 1 million question-answer pairs\nthat span a broad spectrum of agricultural knowledge, from disease\nidentification to management practices. By integrating visual and textual data,\nCDDM facilitates the development of sophisticated question-answering systems\ncapable of providing precise, useful advice to farmers and agricultural\nprofessionals. We demonstrate the utility of the dataset by finetuning\nstate-of-the-art multimodal models, showcasing significant improvements in crop\ndisease diagnosis. Specifically, we employed a novel finetuning strategy that\nutilizes low-rank adaptation (LoRA) to finetune the visual encoder, adapter and\nlanguage model simultaneously. Our contributions include not only the dataset\nbut also a finetuning strategy and a benchmark to stimulate further research in\nagricultural technology, aiming to bridge the gap between advanced AI\ntechniques and practical agricultural applications. The dataset is available at\nhttps: //github.com/UnicomAI/UnicomBenchmark/tree/main/CDDMBench.\n","authors":["Xiang Liu","Zhaoxiang Liu","Huan Hu","Zezhou Chen","Kohou Wang","Kai Wang","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.06973v1.pdf","comment":"Accepted by ECCV 2024 (14 pages, 8 figures)"},{"id":"http://arxiv.org/abs/2503.04758v2","updated":"2025-03-10T06:33:07Z","published":"2025-02-10T13:03:35Z","title":"Chat-GPT: An AI Based Educational Revolution","summary":"  The AI revolution is gathering momentum at an unprecedented rate. Over the\npast decade, we have witnessed a seemingly inevitable integration of AI in\nevery facet of our lives. Much has been written about the potential\nrevolutionary impact of AI in education. AI has the potential to completely\nrevolutionise the educational landscape as we could see entire courses and\ndegrees developed by programs such as ChatGPT. AI has the potential to develop\ncourses, set assignments, grade and provide feedback to students much faster\nthan a team of teachers. In addition, because of its dynamic nature, it has the\npotential to continuously improve its content. In certain fields such as\ncomputer science, where technology is continuously evolving, AI based\napplications can provide dynamically changing, relevant material to students.\nAI has the potential to replace entire degrees and may challenge the concept of\nhigher education institutions. We could also see entire new disciplines emerge\nas a consequence of AI. This paper examines the practical impact of ChatGPT and\nwhy it is believed that its implementation is a critical step towards a new era\nof education. We investigate the impact that ChatGPT will have on learning,\nproblem solving skills and cognitive ability of students. We examine the\npositives, negatives and many other aspects of AI and its applications\nthroughout this paper.\n","authors":["Sasa Maric","Sonja Maric","Lana Maric"],"pdf_url":"https://arxiv.org/pdf/2503.04758v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09769v2","updated":"2025-03-10T06:32:41Z","published":"2024-02-15T07:47:10Z","title":"Learning Using a Single Forward Pass","summary":"  We propose a learning algorithm to overcome the limitations of a traditional\nbackpropagation in resource-constrained environments: Solo Pass Embedded\nLearning Algorithm (SPELA). SPELA is equipped with rapid learning capabilities\nand operates with local loss functions to update weights, significantly saving\non resources allocated to the propagation of gradients and storing\ncomputational graphs while being sufficiently accurate. Consequently, SPELA can\nclosely match backpropagation with less data, computing, storage, and power.\nMoreover, SPELA can effectively fine-tune pre-trained image recognition models\nfor new tasks. Our results indicate that SPELA can be an ideal candidate for\nlearning in resource-constrained edge AI applications.\n","authors":["Aditya Somasundaram","Pushkal Mishra","Ayon Borthakur"],"pdf_url":"https://arxiv.org/pdf/2402.09769v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06963v1","updated":"2025-03-10T06:22:37Z","published":"2025-03-10T06:22:37Z","title":"Multi-Behavior Recommender Systems: A Survey","summary":"  Traditional recommender systems primarily rely on a single type of user-item\ninteraction, such as item purchases or ratings, to predict user preferences.\nHowever, in real-world scenarios, users engage in a variety of behaviors, such\nas clicking on items or adding them to carts, offering richer insights into\ntheir interests. Multi-behavior recommender systems leverage these diverse\ninteractions to enhance recommendation quality, and research on this topic has\ngrown rapidly in recent years. This survey provides a timely review of\nmulti-behavior recommender systems, focusing on three key steps: (1) Data\nModeling: representing multi-behaviors at the input level, (2) Encoding:\ntransforming these inputs into vector representations (i.e., embeddings), and\n(3) Training: optimizing machine-learning models. We systematically categorize\nexisting multi-behavior recommender systems based on the commonalities and\ndifferences in their approaches across the above steps. Additionally, we\ndiscuss promising future directions for advancing multi-behavior recommender\nsystems.\n","authors":["Kyungho Kim","Sunwoo Kim","Geon Lee","Jinhong Jung","Kijung Shin"],"pdf_url":"https://arxiv.org/pdf/2503.06963v1.pdf","comment":"Accepted in the PAKDD 2025 Survey Track"},{"id":"http://arxiv.org/abs/2412.11934v3","updated":"2025-03-10T06:22:15Z","published":"2024-12-16T16:20:41Z","title":"Stepwise Reasoning Error Disruption Attack of LLMs","summary":"  Large language models (LLMs) have made remarkable strides in complex\nreasoning tasks, but their safety and robustness in reasoning processes remain\nunderexplored. Existing attacks on LLM reasoning are constrained by specific\nsettings or lack of imperceptibility, limiting their feasibility and\ngeneralizability. To address these challenges, we propose the Stepwise\nrEasoning Error Disruption (SEED) attack, which subtly injects errors into\nprior reasoning steps to mislead the model into producing incorrect subsequent\nreasoning and final answers. Unlike previous methods, SEED is compatible with\nzero-shot and few-shot settings, maintains the natural reasoning flow, and\nensures covert execution without modifying the instruction. Extensive\nexperiments on four datasets across four different models demonstrate SEED's\neffectiveness, revealing the vulnerabilities of LLMs to disruptions in\nreasoning processes. These findings underscore the need for greater attention\nto the robustness of LLM reasoning to ensure safety in practical applications.\n","authors":["Jingyu Peng","Maolin Wang","Xiangyu Zhao","Kai Zhang","Wanyu Wang","Pengyue Jia","Qidong Liu","Ruocheng Guo","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.11934v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01508v2","updated":"2025-03-10T06:21:15Z","published":"2025-03-03T13:22:39Z","title":"Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic\n  Algorithm for Assessing Novelty","summary":"  In the pursuit of Artificial General Intelligence (AGI), automating the\ngeneration and evaluation of novel research ideas is a key challenge in\nAI-driven scientific discovery. This paper presents Relative Neighbor Density\n(RND), a domain-agnostic algorithm for novelty assessment in research ideas\nthat overcomes the limitations of existing approaches by comparing an idea's\nlocal density with its adjacent neighbors' densities. We first developed a\nscalable methodology to create test set without expert labeling, addressing a\nfundamental challenge in novelty assessment. Using these test sets, we\ndemonstrate that our RND algorithm achieves state-of-the-art (SOTA) performance\nin computer science (AUROC=0.820) and biomedical research (AUROC=0.765)\ndomains. Most significantly, while SOTA models like Sonnet-3.7 and existing\nmetrics show domain-specific performance degradation, RND maintains consistent\naccuracies across domains by its domain-invariant property, outperforming all\nbenchmarks by a substantial margin (0.795 v.s. 0.597) on cross-domain\nevaluation. These results validate RND as a generalizable solution for\nautomated novelty assessment in scientific research.\n","authors":["Yao Wang","Mingxuan Cui","Arthur Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.01508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06962v1","updated":"2025-03-10T06:20:39Z","published":"2025-03-10T06:20:39Z","title":"Capture Global Feature Statistics for One-Shot Federated Learning","summary":"  Traditional Federated Learning (FL) necessitates numerous rounds of\ncommunication between the server and clients, posing significant challenges\nincluding high communication costs, connection drop risks and susceptibility to\nprivacy attacks. One-shot FL has become a compelling learning paradigm to\novercome above drawbacks by enabling the training of a global server model via\na single communication round. However, existing one-shot FL methods suffer from\nexpensive computation cost on the server or clients and cannot deal with\nnon-IID (Independent and Identically Distributed) data stably and effectively.\nTo address these challenges, this paper proposes FedCGS, a novel Federated\nlearning algorithm that Capture Global feature Statistics leveraging\npre-trained models. With global feature statistics, we achieve training-free\nand heterogeneity-resistant one-shot FL. Furthermore, we extend its application\nto personalization scenario, where clients only need execute one extra\ncommunication round with server to download global statistics. Extensive\nexperimental results demonstrate the effectiveness of our methods across\ndiverse data heterogeneity settings. Code is available at\nhttps://github.com/Yuqin-G/FedCGS.\n","authors":["Zenghao Guan","Yucan Zhou","Xiaoyan Gu"],"pdf_url":"https://arxiv.org/pdf/2503.06962v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2409.20548v2","updated":"2025-03-10T06:00:08Z","published":"2024-09-30T17:49:09Z","title":"Robi Butler: Multimodal Remote Interaction with a Household Robot\n  Assistant","summary":"  Imagine a future when we can Zoom-call a robot to manage household chores\nremotely. This work takes one step in this direction. Robi Butler is a new\nhousehold robot assistant that enables seamless multimodal remote interaction.\nIt allows the human user to monitor its environment from a first-person view,\nissue voice or text commands, and specify target objects through hand-pointing\ngestures. At its core, a high-level behavior module, powered by Large Language\nModels (LLMs), interprets multimodal instructions to generate multistep action\nplans. Each plan consists of open-vocabulary primitives supported by\nvision-language models, enabling the robot to process both textual and gestural\ninputs. Zoom provides a convenient interface to implement remote interactions\nbetween the human and the robot. The integration of these components allows\nRobi Butler to ground remote multimodal instructions in real-world home\nenvironments in a zero-shot manner. We evaluated the system on various\nhousehold tasks, demonstrating its ability to execute complex user commands\nwith multimodal inputs. We also conducted a user study to examine how\nmultimodal interaction influences user experiences in remote human-robot\ninteraction. These results suggest that with the advances in robot foundation\nmodels, we are moving closer to the reality of remote household robot\nassistants.\n","authors":["Anxing Xiao","Nuwan Janaka","Tianrun Hu","Anshul Gupta","Kaixin Li","Cunjun Yu","David Hsu"],"pdf_url":"https://arxiv.org/pdf/2409.20548v2.pdf","comment":"Accepted to ICRA 2025"},{"id":"http://arxiv.org/abs/2503.06951v1","updated":"2025-03-10T05:56:46Z","published":"2025-03-10T05:56:46Z","title":"ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced\n  Multi-Hop QA","summary":"  Recent advances in large language models (LLMs) have significantly improved\nmulti-hop question answering (QA) through direct Chain-of-Thought (CoT)\nreasoning. However, the irreversible nature of CoT leads to error accumulation,\nmaking it challenging to correct mistakes in multi-hop reasoning. This paper\nintroduces ReAgent: a Reversible multi-Agent collaborative framework augmented\nwith explicit backtracking mechanisms, enabling reversible multi-hop reasoning.\nBy incorporating text-based retrieval, information aggregation and validation,\nour system can detect and correct errors mid-reasoning, leading to more robust\nand interpretable QA outcomes. The framework and experiments serve as a\nfoundation for future work on error-tolerant QA systems. Empirical evaluations\nacross three benchmarks indicate ReAgent's efficacy, yielding average about 6\\%\nimprovements against baseline models.\n","authors":["Zhao Xinjie","Fan Gao","Rui Yang","Yingjian Chen","Yuyang Wang","Ying Zhu","Jiacheng Tang","Irene Li"],"pdf_url":"https://arxiv.org/pdf/2503.06951v1.pdf","comment":"25pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.06948v1","updated":"2025-03-10T05:53:30Z","published":"2025-03-10T05:53:30Z","title":"Large Language Model Guided Progressive Feature Alignment for Multimodal\n  UAV Object Detection","summary":"  Existing multimodal UAV object detection methods often overlook the impact of\nsemantic gaps between modalities, which makes it difficult to achieve accurate\nsemantic and spatial alignments, limiting detection performance. To address\nthis problem, we propose a Large Language Model (LLM) guided Progressive\nfeature Alignment Network called LPANet, which leverages the semantic features\nextracted from a large language model to guide the progressive semantic and\nspatial alignment between modalities for multimodal UAV object detection. To\nemploy the powerful semantic representation of LLM, we generate the\nfine-grained text descriptions of each object category by ChatGPT and then\nextract the semantic features using the large language model MPNet. Based on\nthe semantic features, we guide the semantic and spatial alignments in a\nprogressive manner as follows. First, we design the Semantic Alignment Module\n(SAM) to pull the semantic features and multimodal visual features of each\nobject closer, alleviating the semantic differences of objects between\nmodalities. Second, we design the Explicit Spatial alignment Module (ESM) by\nintegrating the semantic relations into the estimation of feature-level\noffsets, alleviating the coarse spatial misalignment between modalities.\nFinally, we design the Implicit Spatial alignment Module (ISM), which leverages\nthe cross-modal correlations to aggregate key features from neighboring regions\nto achieve implicit spatial alignment. Comprehensive experiments on two public\nmultimodal UAV object detection datasets demonstrate that our approach\noutperforms state-of-the-art multimodal UAV object detectors.\n","authors":["Wentao Wu","Chenglong Li","Xiao Wang","Bin Luo","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.06948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12518v4","updated":"2025-03-10T05:47:01Z","published":"2024-09-19T07:18:41Z","title":"Hier-SLAM: Scaling-up Semantics in SLAM with a Hierarchically\n  Categorical Gaussian Splatting","summary":"  We propose Hier-SLAM, a semantic 3D Gaussian Splatting SLAM method featuring\na novel hierarchical categorical representation, which enables accurate global\n3D semantic mapping, scaling-up capability, and explicit semantic label\nprediction in the 3D world. The parameter usage in semantic SLAM systems\nincreases significantly with the growing complexity of the environment, making\nit particularly challenging and costly for scene understanding. To address this\nproblem, we introduce a novel hierarchical representation that encodes semantic\ninformation in a compact form into 3D Gaussian Splatting, leveraging the\ncapabilities of large language models (LLMs). We further introduce a novel\nsemantic loss designed to optimize hierarchical semantic information through\nboth inter-level and cross-level optimization. Furthermore, we enhance the\nwhole SLAM system, resulting in improved tracking and mapping performance. Our\n\\MethodName{} outperforms existing dense SLAM methods in both mapping and\ntracking accuracy, while achieving a 2x operation speed-up. Additionally, it\nachieves on-par semantic rendering performance compared to existing methods\nwhile significantly reducing storage and training time requirements. Rendering\nFPS impressively reaches 2,000 with semantic information and 3,000 without it.\nMost notably, it showcases the capability of handling the complex real-world\nscene with more than 500 semantic classes, highlighting its valuable scaling-up\ncapability. The open-source code is available at\nhttps://github.com/LeeBY68/Hier-SLAM\n","authors":["Boying Li","Zhixi Cai","Yuan-Fang Li","Ian Reid","Hamid Rezatofighi"],"pdf_url":"https://arxiv.org/pdf/2409.12518v4.pdf","comment":"Accepted for publication at ICRA 2025. Code is available at\n  https://github.com/LeeBY68/Hier-SLAM"},{"id":"http://arxiv.org/abs/2502.12558v2","updated":"2025-03-10T05:34:20Z","published":"2025-02-18T05:50:23Z","title":"MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment\n  Retrieval Within Long Videos","summary":"  Retrieval augmented generation (RAG) holds great promise in addressing\nchallenges associated with long video understanding. These methods retrieve\nuseful moments from long videos for their presented tasks, thereby enabling\nmultimodal large language models (MLLMs) to generate high-quality answers in a\ncost-effective way. In this work, we present MomentSeeker, a comprehensive\nbenchmark to evaluate retrieval models' performance in handling general\nlong-video moment retrieval (LVMR) tasks. MomentSeeker offers three key\nadvantages. First, it incorporates long videos of over 500 seconds on average,\nmaking it the first benchmark specialized for long-video moment retrieval.\nSecond, it covers a wide range of task categories (including Moment Search,\nCaption Alignment, Image-conditioned Moment Search, and Video-conditioned\nMoment Search) and diverse application scenarios (e.g., sports, movies,\ncartoons, and ego), making it a comprehensive tool for assessing retrieval\nmodels' general LVMR performance. Additionally, the evaluation tasks are\ncarefully curated through human annotation, ensuring the reliability of\nassessment. We further fine-tune an MLLM-based LVMR retriever on synthetic\ndata, which demonstrates strong performance on our benchmark. We perform\nextensive experiments with various popular multimodal retrievers based on our\nbenchmark, whose results highlight the challenges of LVMR and limitations for\nexisting methods. Our created resources will be shared with community to\nadvance future research in this field.\n","authors":["Huaying Yuan","Jian Ni","Yueze Wang","Junjie Zhou","Zhengyang Liang","Zheng Liu","Zhao Cao","Zhicheng Dou","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2502.12558v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06099v2","updated":"2025-03-10T05:24:19Z","published":"2024-12-08T23:00:06Z","title":"DECO: Life-Cycle Management of Enterprise-Grade Copilots","summary":"  Software engineers frequently grapple with the challenge of accessing\ndisparate documentation and telemetry data, including TroubleShooting Guides\n(TSGs), incident reports, code repositories, and various internal tools\ndeveloped by multiple stakeholders. While on-call duties are inevitable,\nincident resolution becomes even more daunting due to the obscurity of legacy\nsources and the pressures of strict time constraints. To enhance the efficiency\nof on-call engineers (OCEs) and streamline their daily workflows, we introduced\nDECO-a comprehensive framework for developing, deploying, and managing\nenterprise-grade copilots tailored to improve productivity in engineering\nroutines. This paper details the design and implementation of the DECO\nframework, emphasizing its innovative NL2SearchQuery functionality and a\nlightweight agentic framework. These features support efficient and customized\nretrieval-augmented-generation (RAG) algorithms that not only extract relevant\ninformation from diverse sources but also select the most pertinent skills in\nresponse to user queries. This enables the addressing of complex technical\nquestions and provides seamless, automated access to internal resources.\nAdditionally, DECO incorporates a robust mechanism for converting unstructured\nincident logs into user-friendly, structured guides, effectively bridging the\ndocumentation gap.\n  Since its launch in September 2023, DECO has demonstrated its effectiveness\nthrough widespread adoption, enabling tens of thousands of interactions and\nengaging hundreds of monthly active users (MAU) across dozens of organizations\nwithin the company.\n","authors":["Yiwen Zhu","Mathieu Demarne","Kai Deng","Wenjing Wang","Nutan Sahoo","Divya Vermareddy","Hannah Lerner","Yunlei Lu","Swati Bararia","Anjali Bhavan","William Zhang","Xia Li","Katherine Lin","Miso Cilimdzic","Subru Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.06099v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06926v1","updated":"2025-03-10T05:11:58Z","published":"2025-03-10T05:11:58Z","title":"Effect of Selection Format on LLM Performance","summary":"  This paper investigates a critical aspect of large language model (LLM)\nperformance: the optimal formatting of classification task options in prompts.\nThrough an extensive experimental study, we compared two selection formats --\nbullet points and plain English -- to determine their impact on model\nperformance. Our findings suggest that presenting options via bullet points\ngenerally yields better results, although there are some exceptions.\nFurthermore, our research highlights the need for continued exploration of\noption formatting to drive further improvements in model performance.\n","authors":["Yuchen Han","Yucheng Wu","Jeffrey Willard"],"pdf_url":"https://arxiv.org/pdf/2503.06926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06923v1","updated":"2025-03-10T05:09:42Z","published":"2025-03-10T05:09:42Z","title":"From Reusing to Forecasting: Accelerating Diffusion Models with\n  TaylorSeers","summary":"  Diffusion Transformers (DiT) have revolutionized high-fidelity image and\nvideo synthesis, yet their computational demands remain prohibitive for\nreal-time applications. To solve this problem, feature caching has been\nproposed to accelerate diffusion models by caching the features in the previous\ntimesteps and then reusing them in the following timesteps. However, at\ntimesteps with significant intervals, the feature similarity in diffusion\nmodels decreases substantially, leading to a pronounced increase in errors\nintroduced by feature caching, significantly harming the generation quality. To\nsolve this problem, we propose TaylorSeer, which firstly shows that features of\ndiffusion models at future timesteps can be predicted based on their values at\nprevious timesteps. Based on the fact that features change slowly and\ncontinuously across timesteps, TaylorSeer employs a differential method to\napproximate the higher-order derivatives of features and predict features in\nfuture timesteps with Taylor series expansion. Extensive experiments\ndemonstrate its significant effectiveness in both image and video synthesis,\nespecially in high acceleration ratios. For instance, it achieves an almost\nlossless acceleration of 4.99$\\times$ on FLUX and 5.00$\\times$ on HunyuanVideo\nwithout additional training. On DiT, it achieves $3.41$ lower FID compared with\nprevious SOTA at $4.53$$\\times$ acceleration. %Our code is provided in the\nsupplementary materials and will be made publicly available on GitHub. Our\ncodes have been released in Github:https://github.com/Shenyi-Z/TaylorSeer\n","authors":["Jiacheng Liu","Chang Zou","Yuanhuiyi Lyu","Junjie Chen","Linfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06923v1.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.02021v2","updated":"2025-03-10T05:09:16Z","published":"2024-06-04T07:00:14Z","title":"FFNet: MetaMixer-based Efficient Convolutional Mixer Design","summary":"  Transformer, composed of self-attention and Feed-Forward Network, has\nrevolutionized the landscape of network design across various vision tasks.\nWhile self-attention is extensively explored as a key factor in performance,\nFFN has received little attention. FFN is a versatile operator seamlessly\nintegrated into nearly all AI models to effectively harness rich\nrepresentations. Recent works also show that FFN functions like key-value\nmemories. Thus, akin to the query-key-value mechanism within self-attention,\nFFN can be viewed as a memory network, where the input serves as query and the\ntwo projection weights operate as keys and values, respectively. Based on these\nobservations, we hypothesize that the importance lies in query-key-value\nframework itself for competitive performance. To verify this, we propose\nconverting self-attention into a more FFN-like efficient token mixer with only\nconvolutions while retaining query-key-value framework, namely FFNification.\nSpecifically, FFNification replaces query-key-value interactions with large\nkernel convolutions and adopts GELU activation function instead of softmax. The\nderived token mixer, FFNified attention, serves as key-value memories for\ndetecting locally distributed spatial patterns, and operates in the opposite\ndimension to the ConvNeXt block within each corresponding sub-operation of the\nquery-key-value framework. Building upon the above two modules, we present a\nfamily of Fast-Forward Networks (FFNet). Despite being composed of only simple\noperators, FFNet outperforms sophisticated and highly specialized methods in\neach domain, with notable efficiency gains. These results validate our\nhypothesis, leading us to propose MetaMixer, a general mixer architecture that\ndoes not specify sub-operations within the query-key-value framework.\n","authors":["Seokju Yun","Dongheon Lee","Youngmin Ro"],"pdf_url":"https://arxiv.org/pdf/2406.02021v2.pdf","comment":"Code: https://github.com/ysj9909/FFNet"},{"id":"http://arxiv.org/abs/2412.18084v3","updated":"2025-03-10T04:25:11Z","published":"2024-12-24T01:48:07Z","title":"Property Enhanced Instruction Tuning for Multi-task Molecule Generation\n  with Large Language Models","summary":"  Large language models (LLMs) are widely applied in various natural language\nprocessing tasks such as question answering and machine translation. However,\ndue to the lack of labeled data and the difficulty of manual annotation for\nbiochemical properties, the performance for molecule generation tasks is still\nlimited, especially for tasks involving multi-properties constraints. In this\nwork, we present a two-step framework PEIT (Property Enhanced Instruction\nTuning) to improve LLMs for molecular-related tasks. In the first step, we use\ntextual descriptions, SMILES, and biochemical properties as multimodal inputs\nto pre-train a model called PEIT-GEN, by aligning multi-modal representations\nto synthesize instruction data. In the second step, we fine-tune existing\nopen-source LLMs with the synthesized data, the resulting PEIT-LLM can handle\nmolecule captioning, text-based molecule generation, molecular property\nprediction, and our newly proposed multi-constraint molecule generation tasks.\nExperimental results show that our pre-trained PEIT-GEN outperforms MolT5 and\nBioT5 in molecule captioning, demonstrating modalities align well between\ntextual descriptions, structures, and biochemical properties. Furthermore,\nPEIT-LLM shows promising improvements in multi-task molecule generation,\nproving the scalability of the PEIT framework for various molecular tasks. We\nrelease the code, constructed instruction data, and model checkpoints in\nhttps://github.com/chenlong164/PEIT.\n","authors":["Xuan Lin","Long Chen","Yile Wang","Xiangxiang Zeng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2412.18084v3.pdf","comment":"9"},{"id":"http://arxiv.org/abs/2502.16660v3","updated":"2025-03-10T04:21:05Z","published":"2025-02-23T17:38:10Z","title":"BioMaze: Benchmarking and Enhancing Large Language Models for Biological\n  Pathway Reasoning","summary":"  The applications of large language models (LLMs) in various biological\ndomains have been explored recently, but their reasoning ability in complex\nbiological systems, such as pathways, remains underexplored, which is crucial\nfor predicting biological phenomena, formulating hypotheses, and designing\nexperiments. This work explores the potential of LLMs in pathway reasoning. We\nintroduce BioMaze, a dataset with 5.1K complex pathway problems derived from\nreal research, covering various biological contexts including natural dynamic\nchanges, disturbances, additional intervention conditions, and multi-scale\nresearch targets. Our evaluation of methods such as CoT and graph-augmented\nreasoning, shows that LLMs struggle with pathway reasoning, especially in\nperturbed systems. To address this, we propose PathSeeker, an LLM agent that\nenhances reasoning through interactive subgraph-based navigation, enabling a\nmore effective approach to handling the complexities of biological systems in a\nscientifically aligned manner. The dataset and code are available at\nhttps://github.com/zhao-ht/BioMaze.\n","authors":["Haiteng Zhao","Chang Ma","Fangzhi Xu","Lingpeng Kong","Zhi-Hong Deng"],"pdf_url":"https://arxiv.org/pdf/2502.16660v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11418v2","updated":"2025-03-10T04:15:20Z","published":"2025-02-17T04:17:27Z","title":"TimeCAP: Learning to Contextualize, Augment, and Predict Time Series\n  Events with Large Language Model Agents","summary":"  Time series data is essential in various applications, including climate\nmodeling, healthcare monitoring, and financial analytics. Understanding the\ncontextual information associated with real-world time series data is often\nessential for accurate and reliable event predictions. In this paper, we\nintroduce TimeCAP, a time-series processing framework that creatively employs\nLarge Language Models (LLMs) as contextualizers of time series data, extending\ntheir typical usage as predictors. TimeCAP incorporates two independent LLM\nagents: one generates a textual summary capturing the context of the time\nseries, while the other uses this enriched summary to make more informed\npredictions. In addition, TimeCAP employs a multi-modal encoder that synergizes\nwith the LLM agents, enhancing predictive performance through mutual\naugmentation of inputs with in-context examples. Experimental results on\nreal-world datasets demonstrate that TimeCAP outperforms state-of-the-art\nmethods for time series event prediction, including those utilizing LLMs as\npredictors, achieving an average improvement of 28.75% in F1 score.\n","authors":["Geon Lee","Wenchao Yu","Kijung Shin","Wei Cheng","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2502.11418v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2308.14815v4","updated":"2025-03-10T04:10:08Z","published":"2023-08-28T18:06:24Z","title":"Distributionally Robust Statistical Verification with Imprecise Neural\n  Networks","summary":"  A particularly challenging problem in AI safety is providing guarantees on\nthe behavior of high-dimensional autonomous systems. Verification approaches\ncentered around reachability analysis fail to scale, and purely statistical\napproaches are constrained by the distributional assumptions about the sampling\nprocess. Instead, we pose a distributionally robust version of the statistical\nverification problem for black-box systems, where our performance guarantees\nhold over a large family of distributions. This paper proposes a novel approach\nbased on uncertainty quantification using concepts from imprecise\nprobabilities. A central piece of our approach is an ensemble technique called\nImprecise Neural Networks, which provides the uncertainty quantification.\nAdditionally, we solve the allied problem of exploring the input set using\nactive learning. The active learning uses an exhaustive neural-network\nverification tool Sherlock to collect samples. An evaluation on multiple\nphysical simulators in the openAI gym Mujoco environments with\nreinforcement-learned controllers demonstrates that our approach can provide\nuseful and scalable guarantees for high-dimensional systems.\n","authors":["Souradeep Dutta","Michele Caprio","Vivian Lin","Matthew Cleaveland","Kuk Jin Jang","Ivan Ruchkin","Oleg Sokolsky","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2308.14815v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06894v1","updated":"2025-03-10T03:50:25Z","published":"2025-03-10T03:50:25Z","title":"Improving cognitive diagnostics in pathology: a deep learning approach\n  for augmenting perceptional understanding of histopathology images","summary":"  In Recent Years, Digital Technologies Have Made Significant Strides In\nAugmenting-Human-Health, Cognition, And Perception, Particularly Within The\nField Of Computational-Pathology. This Paper Presents A Novel Approach To\nEnhancing The Analysis Of Histopathology Images By Leveraging A\nMult-modal-Model That Combines Vision Transformers (Vit) With Gpt-2 For Image\nCaptioning. The Model Is Fine-Tuned On The Specialized Arch-Dataset, Which\nIncludes Dense Image Captions Derived From Clinical And Academic Resources, To\nCapture The Complexities Of Pathology Images Such As Tissue Morphologies,\nStaining Variations, And Pathological Conditions. By Generating Accurate,\nContextually Captions, The Model Augments The Cognitive Capabilities Of\nHealthcare Professionals, Enabling More Efficient Disease Classification,\nSegmentation, And Detection. The Model Enhances The Perception Of Subtle\nPathological Features In Images That Might Otherwise Go Unnoticed, Thereby\nImproving Diagnostic Accuracy. Our Approach Demonstrates The Potential For\nDigital Technologies To Augment Human Cognitive Abilities In Medical Image\nAnalysis, Providing Steps Toward More Personalized And Accurate Healthcare\nOutcomes.\n","authors":["Xiaoqian Hu"],"pdf_url":"https://arxiv.org/pdf/2503.06894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06893v1","updated":"2025-03-10T03:50:20Z","published":"2025-03-10T03:50:20Z","title":"Policy Regularization on Globally Accessible States in Cross-Dynamics\n  Reinforcement Learning","summary":"  To learn from data collected in diverse dynamics, Imitation from Observation\n(IfO) methods leverage expert state trajectories based on the premise that\nrecovering expert state distributions in other dynamics facilitates policy\nlearning in the current one. However, Imitation Learning inherently imposes a\nperformance upper bound of learned policies. Additionally, as the environment\ndynamics change, certain expert states may become inaccessible, rendering their\ndistributions less valuable for imitation. To address this, we propose a novel\nframework that integrates reward maximization with IfO, employing F-distance\nregularized policy optimization. This framework enforces constraints on\nglobally accessible states--those with nonzero visitation frequency across all\nconsidered dynamics--mitigating the challenge posed by inaccessible states. By\ninstantiating F-distance in different ways, we derive two theoretical analysis\nand develop a practical algorithm called Accessible State Oriented Policy\nRegularization (ASOR). ASOR serves as a general add-on module that can be\nincorporated into various RL approaches, including offline RL and off-policy\nRL. Extensive experiments across multiple benchmarks demonstrate ASOR's\neffectiveness in enhancing state-of-the-art cross-domain policy transfer\nalgorithms, significantly improving their performance.\n","authors":["Zhenghai Xue","Lang Feng","Jiacheng Xu","Kang Kang","Xiang Wen","Bo An","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2503.06893v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2412.10471v2","updated":"2025-03-10T03:35:16Z","published":"2024-12-12T23:39:54Z","title":"VCA: Video Curious Agent for Long Video Understanding","summary":"  Long video understanding poses unique challenges due to their temporal\ncomplexity and low information density. Recent works address this task by\nsampling numerous frames or incorporating auxiliary tools using LLMs, both of\nwhich result in high computational costs. In this work, we introduce a\ncuriosity-driven video agent with self-exploration capability, dubbed as VCA.\nBuilt upon VLMs, VCA autonomously navigates video segments and efficiently\nbuilds a comprehensive understanding of complex video sequences. Instead of\ndirectly sampling frames, VCA employs a tree-search structure to explore video\nsegments and collect frames. Rather than relying on external feedback or\nreward, VCA leverages VLM's self-generated intrinsic reward to guide its\nexploration, enabling it to capture the most crucial information for reasoning.\nExperimental results on multiple long video benchmarks demonstrate our\napproach's superior effectiveness and efficiency.\n","authors":["Zeyuan Yang","Delin Chen","Xueyang Yu","Maohao Shen","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2412.10471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06884v1","updated":"2025-03-10T03:28:18Z","published":"2025-03-10T03:28:18Z","title":"Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement\n  Cannot Help","summary":"  Generative modeling is widely regarded as one of the most essential problems\nin today's AI community, with text-to-image generation having gained\nunprecedented real-world impacts. Among various approaches, diffusion models\nhave achieved remarkable success and have become the de facto solution for\ntext-to-image generation. However, despite their impressive performance, these\nmodels exhibit fundamental limitations in adhering to numerical constraints in\nuser instructions, frequently generating images with an incorrect number of\nobjects. While several prior works have mentioned this issue, a comprehensive\nand rigorous evaluation of this limitation remains lacking. To address this\ngap, we introduce T2ICountBench, a novel benchmark designed to rigorously\nevaluate the counting ability of state-of-the-art text-to-image diffusion\nmodels. Our benchmark encompasses a diverse set of generative models, including\nboth open-source and private systems. It explicitly isolates counting\nperformance from other capabilities, provides structured difficulty levels, and\nincorporates human evaluations to ensure high reliability.\n  Extensive evaluations with T2ICountBench reveal that all state-of-the-art\ndiffusion models fail to generate the correct number of objects, with accuracy\ndropping significantly as the number of objects increases. Additionally, an\nexploratory study on prompt refinement demonstrates that such simple\ninterventions generally do not improve counting accuracy. Our findings\nhighlight the inherent challenges in numerical understanding within diffusion\nmodels and point to promising directions for future improvements.\n","authors":["Yuefan Cao","Xuyang Guo","Jiayan Huo","Yingyu Liang","Zhenmei Shi","Zhao Song","Jiahao Zhang","Zhen Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04065v2","updated":"2025-03-10T03:22:24Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.04684v3","updated":"2025-03-10T03:08:27Z","published":"2025-02-07T06:16:31Z","title":"G2PDiffusion: Cross-Species Genotype-to-Phenotype Prediction via\n  Evolutionary Diffusion","summary":"  Understanding how genes influence phenotype across species is a fundamental\nchallenge in genetic engineering, which will facilitate advances in various\nfields such as crop breeding, conservation biology, and personalized medicine.\nHowever, current phenotype prediction models are limited to individual species\nand expensive phenotype labeling process, making the genotype-to-phenotype\nprediction a highly domain-dependent and data-scarce problem. To this end, we\nsuggest taking images as morphological proxies, facilitating cross-species\ngeneralization through large-scale multimodal pretraining. We propose the first\ngenotype-to-phenotype diffusion model (G2PDiffusion) that generates\nmorphological images from DNA considering two critical evolutionary signals,\ni.e., multiple sequence alignments (MSA) and environmental contexts. The model\ncontains three novel components: 1) a MSA retrieval engine that identifies\nconserved and co-evolutionary patterns; 2) an environment-aware MSA conditional\nencoder that effectively models complex genotype-environment interactions; and\n3) an adaptive phenomic alignment module to improve genotype-phenotype\nconsistency. Extensive experiments show that integrating evolutionary signals\nwith environmental context enriches the model's understanding of phenotype\nvariability across species, thereby offering a valuable and promising\nexploration into advanced AI-assisted genomic analysis.\n","authors":["Mengdi Liu","Zhangyang Gao","Hong Chang","Stan Z. Li","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2502.04684v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18786v2","updated":"2025-03-10T03:03:09Z","published":"2025-02-26T03:42:58Z","title":"NeuroTree: Hierarchical Functional Brain Pathway Decoding for Mental\n  Health Disorders","summary":"  Analyzing functional brain networks using functional magnetic resonance\nimaging (fMRI) is crucial for understanding psychiatric disorders and addictive\nbehaviors. While existing fMRI-based graph convolutional networks (GCNs) show\nconsiderable promise for feature extraction, they often fall short in\ncharacterizing complex relationships between brain regions and demographic\nfactors and accounting for interpretable variables linked to psychiatric\nconditions. We propose NeuroTree to overcome these limitations, integrating a\nk-hop AGE-GCN with neural ordinary differential equations (ODEs). This\nframework leverages an attention mechanism to optimize functional connectivity\n(FC), thereby enhancing dynamic FC feature learning for brain disease\nclassification. Furthermore, NeuroTree effectively decodes fMRI network\nfeatures into tree structures, which improves the capture of high-order brain\nregional pathway features and enables the identification of hierarchical neural\nbehavioral patterns essential for understanding disease-related brain\nsubnetworks. Our empirical evaluations demonstrate that NeuroTree achieves\nstate-of-the-art performance across two distinct mental disorder datasets and\nprovides valuable insights into age-related deterioration patterns. These\nfindings underscore the model's efficacy in predicting psychiatric disorders\nand elucidating their underlying neural mechanisms.\n","authors":["Jun-En Ding","Dongsheng Luo","Anna Zilverstand","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2502.18786v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02191v2","updated":"2025-03-10T02:57:32Z","published":"2024-10-03T04:11:42Z","title":"A Survey on Point-of-Interest Recommendation: Models, Architectures, and\n  Security","summary":"  The widespread adoption of smartphones and Location-Based Social Networks has\nled to a massive influx of spatio-temporal data, creating unparalleled\nopportunities for enhancing Point-of-Interest (POI) recommendation systems.\nThese advanced POI systems are crucial for enriching user experiences, enabling\npersonalized interactions, and optimizing decision-making processes in the\ndigital landscape. However, existing surveys tend to focus on traditional\napproaches and few of them delve into cutting-edge developments, emerging\narchitectures, as well as security considerations in POI recommendations. To\naddress this gap, our survey stands out by offering a comprehensive, up-to-date\nreview of POI recommendation systems, covering advancements in models,\narchitectures, and security aspects. We systematically examine the transition\nfrom traditional models to advanced techniques such as large language models.\nAdditionally, we explore the architectural evolution from centralized to\ndecentralized and federated learning systems, highlighting the improvements in\nscalability and privacy. Furthermore, we address the increasing importance of\nsecurity, examining potential vulnerabilities and privacy-preserving\napproaches. Our taxonomy provides a structured overview of the current state of\nPOI recommendation, while we also identify promising directions for future\nresearch in this rapidly advancing field.\n","authors":["Qianru Zhang","Peng Yang","Junliang Yu","Haixin Wang","Xingwei He","Siu-Ming Yiu","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2410.02191v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2411.13587v3","updated":"2025-03-10T02:57:07Z","published":"2024-11-18T01:52:20Z","title":"Exploring the Adversarial Vulnerabilities of Vision-Language-Action\n  Models in Robotics","summary":"  Recently in robotics, Vision-Language-Action (VLA) models have emerged as a\ntransformative approach, enabling robots to execute complex tasks by\nintegrating visual and linguistic inputs within an end-to-end learning\nframework. While VLA models offer significant capabilities, they also introduce\nnew attack surfaces, making them vulnerable to adversarial attacks. With these\nvulnerabilities largely unexplored, this paper systematically quantifies the\nrobustness of VLA-based robotic systems. Recognizing the unique demands of\nrobotic execution, our attack objectives target the inherent spatial and\nfunctional characteristics of robotic systems. In particular, we introduce two\nuntargeted attack objectives that leverage spatial foundations to destabilize\nrobotic actions, and a targeted attack objective that manipulates the robotic\ntrajectory. Additionally, we design an adversarial patch generation approach\nthat places a small, colorful patch within the camera's view, effectively\nexecuting the attack in both digital and physical environments. Our evaluation\nreveals a marked degradation in task success rates, with up to a 100\\%\nreduction across a suite of simulated robotic tasks, highlighting critical\nsecurity gaps in current VLA architectures. By unveiling these vulnerabilities\nand proposing actionable evaluation metrics, we advance both the understanding\nand enhancement of safety for VLA-based robotic systems, underscoring the\nnecessity for continuously developing robust defense strategies prior to\nphysical-world deployments.\n","authors":["Taowen Wang","Cheng Han","James Chenhao Liang","Wenhao Yang","Dongfang Liu","Luna Xinyu Zhang","Qifan Wang","Jiebo Luo","Ruixiang Tang"],"pdf_url":"https://arxiv.org/pdf/2411.13587v3.pdf","comment":"Github: https://github.com/William-wAng618/roboticAttack Homepage:\n  https://vlaattacker.github.io/"},{"id":"http://arxiv.org/abs/2412.12778v2","updated":"2025-03-10T02:53:38Z","published":"2024-12-17T10:37:46Z","title":"Rethinking Diffusion-Based Image Generators for Fundus Fluorescein\n  Angiography Synthesis on Limited Data","summary":"  Fundus imaging is a critical tool in ophthalmology, with different imaging\nmodalities offering unique advantages. For instance, fundus fluorescein\nangiography (FFA) can accurately identify eye diseases. However, traditional\ninvasive FFA involves the injection of sodium fluorescein, which can cause\ndiscomfort and risks. Generating corresponding FFA images from non-invasive\nfundus images holds significant practical value but also presents challenges.\nFirst, limited datasets constrain the performance and effectiveness of models.\nSecond, previous studies have primarily focused on generating FFA for single\ndiseases or single modalities, often resulting in poor performance for patients\nwith various ophthalmic conditions. To address these issues, we propose a novel\nlatent diffusion model-based framework, Diffusion, which introduces a\nfine-tuning protocol to overcome the challenge of limited medical data and\nunleash the generative capabilities of diffusion models. Furthermore, we\ndesigned a new approach to tackle the challenges of generating across different\nmodalities and disease types. On limited datasets, our framework achieves\nstate-of-the-art results compared to existing methods, offering significant\npotential to enhance ophthalmic diagnostics and patient care. Our code will be\nreleased soon to support further research in this field.\n","authors":["Chengzhou Yu","Huihui Fang","Hongqiu Wang","Ting Deng","Qing Du","Yanwu Xu","Weihua Yang"],"pdf_url":"https://arxiv.org/pdf/2412.12778v2.pdf","comment":"The first author has a conflict with the data access authority"},{"id":"http://arxiv.org/abs/2503.06873v1","updated":"2025-03-10T02:52:47Z","published":"2025-03-10T02:52:47Z","title":"Interactive Medical Image Analysis with Concept-based Similarity\n  Reasoning","summary":"  The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.\n","authors":["Ta Duc Huy","Sen Kim Tran","Phan Nguyen","Nguyen Hoang Tran","Tran Bao Sam","Anton van den Hengel","Zhibin Liao","Johan W. Verjans","Minh-Son To","Vu Minh Hieu Phan"],"pdf_url":"https://arxiv.org/pdf/2503.06873v1.pdf","comment":"Accepted CVPR2025"},{"id":"http://arxiv.org/abs/2503.06868v1","updated":"2025-03-10T02:44:36Z","published":"2025-03-10T02:44:36Z","title":"Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset,\n  Evaluation Framework, and Mitigation","summary":"  Existing long-text generation methods primarily concentrate on producing\nlengthy texts from short inputs, neglecting the long-input and long-output\ntasks. Such tasks have numerous practical applications while lacking available\nbenchmarks. Moreover, as the input grows in length, existing methods inevitably\nencounter the \"lost-in-the-middle\" phenomenon. In this paper, we first\nintroduce a Long Input and Output Benchmark (LongInOutBench), including a\nsynthetic dataset and a comprehensive evaluation framework, addressing the\nchallenge of the missing benchmark. We then develop the Retrieval-Augmented\nLong-Text Writer (RAL-Writer), which retrieves and restates important yet\noverlooked content, mitigating the \"lost-in-the-middle\" issue by constructing\nexplicit prompts. We finally employ the proposed LongInOutBench to evaluate our\nRAL-Writer against comparable baselines, and the results demonstrate the\neffectiveness of our approach. Our code has been released at\nhttps://github.com/OnlyAR/RAL-Writer.\n","authors":["Junhao Zhang","Richong Zhang","Fanshuang Kong","Ziyang Miao","Yanhan Ye","Yaowei Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.06868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06867v1","updated":"2025-03-10T02:44:11Z","published":"2025-03-10T02:44:11Z","title":"Enhancing Time Series Forecasting via Logic-Inspired Regularization","summary":"  Time series forecasting (TSF) plays a crucial role in many applications.\nTransformer-based methods are one of the mainstream techniques for TSF.\nExisting methods treat all token dependencies equally. However, we find that\nthe effectiveness of token dependencies varies across different forecasting\nscenarios, and existing methods ignore these differences, which affects their\nperformance. This raises two issues: (1) What are effective token dependencies?\n(2) How can we learn effective dependencies? From a logical perspective, we\nalign Transformer-based TSF methods with the logical framework and define\neffective token dependencies as those that ensure the tokens as atomic formulas\n(Issue 1). We then align the learning process of Transformer methods with the\nprocess of obtaining atomic formulas in logic, which inspires us to design a\nmethod for learning these effective dependencies (Issue 2). Specifically, we\npropose Attention Logic Regularization (Attn-L-Reg), a plug-and-play method\nthat guides the model to use fewer but more effective dependencies by making\nthe attention map sparse, thereby ensuring the tokens as atomic formulas and\nimproving prediction performance. Extensive experiments and theoretical\nanalysis confirm the effectiveness of Attn-L-Reg.\n","authors":["Jianqi Zhang","Jingyao Wang","Xingchen Shen","Wenwen Qiang"],"pdf_url":"https://arxiv.org/pdf/2503.06867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06866v1","updated":"2025-03-10T02:43:54Z","published":"2025-03-10T02:43:54Z","title":"Graphormer-Guided Task Planning: Beyond Static Rules with LLM Safety\n  Perception","summary":"  Recent advancements in large language models (LLMs) have expanded their role\nin robotic task planning. However, while LLMs have been explored for generating\nfeasible task sequences, their ability to ensure safe task execution remains\nunderdeveloped. Existing methods struggle with structured risk perception,\nmaking them inadequate for safety-critical applications where low-latency\nhazard adaptation is required. To address this limitation, we propose a\nGraphormer-enhanced risk-aware task planning framework that combines LLM-based\ndecision-making with structured safety modeling. Our approach constructs a\ndynamic spatio-semantic safety graph, capturing spatial and contextual risk\nfactors to enable online hazard detection and adaptive task refinement. Unlike\nexisting methods that rely on predefined safety constraints, our framework\nintroduces a context-aware risk perception module that continuously refines\nsafety predictions based on real-time task execution. This enables a more\nflexible and scalable approach to robotic planning, allowing for adaptive\nsafety compliance beyond static rules. To validate our framework, we conduct\nexperiments in the AI2-THOR environment. The experiments results validates\nimprovements in risk detection accuracy, rising safety notice, and task\nadaptability of our framework in continuous environments compared to static\nrule-based and LLM-only baselines. Our project is available at\nhttps://github.com/hwj20/GGTP\n","authors":["Wanjing Huang","Tongjie Pan","Yalan Ye"],"pdf_url":"https://arxiv.org/pdf/2503.06866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14228v3","updated":"2025-03-10T02:42:01Z","published":"2024-06-20T11:49:23Z","title":"EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary\n  Algorithms","summary":"  The rise of powerful large language models (LLMs) has spurred a new trend in\nbuilding LLM-based autonomous agents for solving complex tasks, especially\nmulti-agent systems. Despite the remarkable progress, we notice that existing\nworks are heavily dependent on human-designed frameworks, which greatly limits\nthe functional scope and scalability of agent systems. How to automatically\nextend the specialized agent to multi-agent systems to improve task-solving\ncapability still remains a significant challenge. In this paper, we introduce\nEvoAgent, a generic method to automatically extend specialized agents to\nmulti-agent systems via the evolutionary algorithm, thereby improving the\neffectiveness of LLM-based agents in solving tasks. Specifically, we consider\nthe existing agent frameworks as the initial individual and then apply a series\nof evolutionary operators (e.g., mutation, crossover, selection, etc.) to\ngenerate multiple agents with diverse settings. Experimental results across\nvarious tasks show that EvoAgent can significantly enhance the task-solving\ncapability of LLM-based agents, and can be generalized to any LLM-based agent\nframework to extend them into multi-agent systems. Resources are available at\nhttps://evo-agent.github.io/.\n","authors":["Siyu Yuan","Kaitao Song","Jiangjie Chen","Xu Tan","Dongsheng Li","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2406.14228v3.pdf","comment":"Accepted as a main conference paper at NAACL 2025"},{"id":"http://arxiv.org/abs/2411.15210v3","updated":"2025-03-10T02:39:40Z","published":"2024-11-20T10:41:23Z","title":"Towards Million-Scale Adversarial Robustness Evaluation With Stronger\n  Individual Attacks","summary":"  As deep learning models are increasingly deployed in safety-critical\napplications, evaluating their vulnerabilities to adversarial perturbations is\nessential for ensuring their reliability and trustworthiness. Over the past\ndecade, a large number of white-box adversarial robustness evaluation methods\n(i.e., attacks) have been proposed, ranging from single-step to multi-step\nmethods and from individual to ensemble methods. Despite these advances,\nchallenges remain in conducting meaningful and comprehensive robustness\nevaluations, particularly when it comes to large-scale testing and ensuring\nevaluations reflect real-world adversarial risks. In this work, we focus on\nimage classification models and propose a novel individual attack method,\nProbability Margin Attack (PMA), which defines the adversarial margin in the\nprobability space rather than the logits space. We analyze the relationship\nbetween PMA and existing cross-entropy or logits-margin-based attacks, and show\nthat PMA can outperform the current state-of-the-art individual methods.\nBuilding on PMA, we propose two types of ensemble attacks that balance\neffectiveness and efficiency. Furthermore, we create a million-scale dataset,\nCC1M, derived from the existing CC3M dataset, and use it to conduct the first\nmillion-scale white-box adversarial robustness evaluation of\nadversarially-trained ImageNet models. Our findings provide valuable insights\ninto the robustness gaps between individual versus ensemble attacks and\nsmall-scale versus million-scale evaluations.\n","authors":["Yong Xie","Weijie Zheng","Hanxun Huang","Guangnan Ye","Xingjun Ma"],"pdf_url":"https://arxiv.org/pdf/2411.15210v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06861v1","updated":"2025-03-10T02:39:06Z","published":"2025-03-10T02:39:06Z","title":"Enhanced Multi-Tuple Extraction for Alloys: Integrating Pointer Networks\n  and Augmented Attention","summary":"  Extracting high-quality structured information from scientific literature is\ncrucial for advancing material design through data-driven methods. Despite the\nconsiderable research in natural language processing for dataset extraction,\neffective approaches for multi-tuple extraction in scientific literature remain\nscarce due to the complex interrelations of tuples and contextual ambiguities.\nIn the study, we illustrate the multi-tuple extraction of mechanical properties\nfrom multi-principal-element alloys and presents a novel framework that\ncombines an entity extraction model based on MatSciBERT with pointer networks\nand an allocation model utilizing inter- and intra-entity attention. Our\nrigorous experiments on tuple extraction demonstrate impressive F1 scores of\n0.963, 0.947, 0.848, and 0.753 across datasets with 1, 2, 3, and 4 tuples,\nconfirming the effectiveness of the model. Furthermore, an F1 score of 0.854\nwas achieved on a randomly curated dataset. These results highlight the model's\ncapacity to deliver precise and structured information, offering a robust\nalternative to large language models and equipping researchers with essential\ndata for fostering data-driven innovations.\n","authors":["Mengzhe Hei","Zhouran Zhang","Qingbao Liu","Yan Pan","Xiang Zhao","Yongqian Peng","Yicong Ye","Xin Zhang","Shuxin Bai"],"pdf_url":"https://arxiv.org/pdf/2503.06861v1.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.03122v2","updated":"2025-03-10T02:34:53Z","published":"2025-03-05T02:37:41Z","title":"The Devil Is in the Details: Tackling Unimodal Spurious Correlations for\n  Generalizable Multimodal Reward Models","summary":"  Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.\n","authors":["Zichao Li","Xueru Wen","Jie Lou","Yuqiu Ji","Yaojie Lu","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2503.03122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11649v2","updated":"2025-03-10T02:14:41Z","published":"2025-02-17T10:41:55Z","title":"Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation","summary":"  We introduce a novel non-cooperative game to analyse opinion formation and\nresistance, incorporating principles from social psychology such as\nconfirmation bias, resource constraints, and influence penalties. Our\nsimulation features Large Language Model (LLM) agents competing to influence a\npopulation, with penalties imposed for generating messages that propagate or\ncounter misinformation. This framework integrates resource optimisation into\nthe agents' decision-making process. Our findings demonstrate that while higher\nconfirmation bias strengthens opinion alignment within groups, it also\nexacerbates overall polarisation. Conversely, lower confirmation bias leads to\nfragmented opinions and limited shifts in individual beliefs. Investing heavily\nin a high-resource debunking strategy can initially align the population with\nthe debunking agent, but risks rapid resource depletion and diminished\nlong-term influence.\n","authors":["Amin Qasmi","Usman Naseem","Mehwish Nasim"],"pdf_url":"https://arxiv.org/pdf/2502.11649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11492v2","updated":"2025-03-10T02:13:57Z","published":"2025-02-17T06:54:49Z","title":"Why Vision Language Models Struggle with Visual Arithmetic? Towards\n  Enhanced Chart and Geometry Understanding","summary":"  Vision Language Models (VLMs) have achieved remarkable progress in multimodal\ntasks, yet they often struggle with visual arithmetic, seemingly simple\ncapabilities like object counting or length comparison, which are essential for\nrelevant complex tasks like chart understanding and geometric reasoning. In\nthis work, we first investigate the root causes of this deficiency through a\nsuite of probing tasks focusing on basic visual arithmetic. Our analysis\nreveals that while pre-trained vision encoders typically capture sufficient\ninformation, the text decoder often fails to decode it correctly for arithmetic\nreasoning. To address this, we propose CogAlign, a novel post-training strategy\ninspired by Piaget's theory of cognitive development. CogAlign trains VLMs to\nrecognize invariant properties under visual transformations. We demonstrate\nthat this approach significantly improves the performance of three diverse VLMs\non our proposed probing tasks. Furthermore, CogAlign enhances performance by an\naverage of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching\nsupervised fine-tuning methods while requiring only 60% less training data.\nThese results highlight the effectiveness and generalizability of CogAlign in\nimproving fundamental visual arithmetic capabilities and their transfer to\ndownstream tasks.\n","authors":["Kung-Hsiang Huang","Can Qin","Haoyi Qiu","Philippe Laban","Shafiq Joty","Caiming Xiong","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2502.11492v2.pdf","comment":"Code and data are available at\n  https://github.com/SalesforceAIResearch/CogAlign"},{"id":"http://arxiv.org/abs/2502.05383v2","updated":"2025-03-10T02:05:44Z","published":"2025-02-07T23:41:41Z","title":"Is attention all you need to solve the correlated electron problem?","summary":"  The attention mechanism has transformed artificial intelligence research by\nits ability to learn relations between objects. In this work, we explore how a\nmany-body wavefunction ansatz constructed from a large-parameter self-attention\nneural network can be used to solve the interacting electron problem in solids.\nBy a systematic neural-network variational Monte Carlo study on a moir\\'e\nquantum material, we demonstrate that the self-attention ansatz provides an\naccurate, efficient, and unbiased solution. Moreover, our numerical study finds\nthat the required number of variational parameters scales roughly as $N^2$ with\nthe number of electrons, which opens a path towards efficient large-scale\nsimulations.\n","authors":["Max Geier","Khachatur Nazaryan","Timothy Zaklama","Liang Fu"],"pdf_url":"https://arxiv.org/pdf/2502.05383v2.pdf","comment":"10+5 pages, comments welcome; v2: update refs, extend ED results"},{"id":"http://arxiv.org/abs/2501.08521v2","updated":"2025-03-10T02:01:38Z","published":"2025-01-15T02:17:38Z","title":"Mitigating Domain Shift in Federated Learning via Intra- and\n  Inter-Domain Prototypes","summary":"  Federated Learning (FL) has emerged as a decentralized machine learning\ntechnique, allowing clients to train a global model collaboratively without\nsharing private data. However, most FL studies ignore the crucial challenge of\nheterogeneous domains where each client has a distinct feature distribution,\nwhich is popular in real-world scenarios. Prototype learning, which leverages\nthe mean feature vectors within the same classes, has become a prominent\nsolution for federated learning under domain shift. However, existing federated\nprototype learning methods focus soley on inter-domain prototypes and neglect\nintra-domain perspectives. In this work, we introduce a novel federated\nprototype learning method, namely I$^2$PFL, which incorporates\n$\\textbf{I}$ntra-domain and $\\textbf{I}$nter-domain $\\textbf{P}$rototypes, to\nmitigate domain shift from both perspectives and learn a generalized global\nmodel across multiple domains in federated learning. To construct intra-domain\nprototypes, we propose feature alignment with MixUp-based augmented prototypes\nto capture the diversity within local domains and enhance the generalization of\nlocal features. Additionally, we introduce a reweighting mechanism for\ninter-domain prototypes to generate generalized prototypes that reduce domain\nshift while providing inter-domain knowledge across multiple clients. Extensive\nexperiments on the Digits, Office-10, and PACS datasets illustrate the superior\nperformance of our method compared to other baselines.\n","authors":["Huy Q. Le","Ye Lin Tun","Yu Qiao","Minh N. H. Nguyen","Keon Oh Kim","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2501.08521v2.pdf","comment":"13 pages, 11 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.06839v1","updated":"2025-03-10T01:59:11Z","published":"2025-03-10T01:59:11Z","title":"AttFC: Attention Fully-Connected Layer for Large-Scale Face Recognition\n  with One GPU","summary":"  Nowadays, with the advancement of deep neural networks (DNNs) and the\navailability of large-scale datasets, the face recognition (FR) model has\nachieved exceptional performance. However, since the parameter magnitude of the\nfully connected (FC) layer directly depends on the number of identities in the\ndataset. If training the FR model on large-scale datasets, the size of the\nmodel parameter will be excessively huge, leading to substantial demand for\ncomputational resources, such as time and memory. This paper proposes the\nattention fully connected (AttFC) layer, which could significantly reduce\ncomputational resources. AttFC employs an attention loader to generate the\ngenerative class center (GCC), and dynamically store the class center with\nDynamic Class Container (DCC). DCC only stores a small subset of all class\ncenters in FC, thus its parameter count is substantially less than the FC\nlayer. Also, training face recognition models on large-scale datasets with one\nGPU often encounter out-of-memory (OOM) issues. AttFC overcomes this and\nachieves comparable performance to state-of-the-art methods.\n","authors":["Zhuowen Zheng","Yain-Whar Si","Xiaochen Yuan","Junwei Duan","Ke Wang","Xiaofan Li","Xinyuan Zhang","Xueyuan Gong"],"pdf_url":"https://arxiv.org/pdf/2503.06839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05132v2","updated":"2025-03-10T01:52:08Z","published":"2025-03-07T04:21:47Z","title":"R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT Model","summary":"  Recently DeepSeek R1 demonstrated how reinforcement learning with simple\nrule-based incentives can enable autonomous development of complex reasoning in\nlarge language models, characterized by the \"aha moment\", in which the model\nmanifest self-reflection and increased response length during training.\nHowever, attempts to extend this success to multimodal reasoning often failed\nto reproduce these key characteristics. In this report, we present the first\nsuccessful replication of these emergent characteristics for multimodal\nreasoning on only a non-SFT 2B model. Starting with Qwen2-VL-2B and applying\nreinforcement learning directly on the SAT dataset, our model achieves 59.47%\naccuracy on CVBench, outperforming the base model by approximately ~30% and\nexceeding both SFT setting by ~2%. In addition, we share our failed attempts\nand insights in attempting to achieve R1-like reasoning using RL with instruct\nmodels. aiming to shed light on the challenges involved. Our key observations\ninclude: (1) applying RL on instruct model often results in trivial reasoning\ntrajectories, and (2) naive length reward are ineffective in eliciting\nreasoning capabilities. The project code is available at\nhttps://github.com/turningpoint-ai/VisualThinker-R1-Zero\n","authors":["Hengguang Zhou","Xirui Li","Ruochen Wang","Minhao Cheng","Tianyi Zhou","Cho-Jui Hsieh"],"pdf_url":"https://arxiv.org/pdf/2503.05132v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.04830v2","updated":"2025-03-10T01:47:04Z","published":"2025-03-05T08:58:35Z","title":"Cite Before You Speak: Enhancing Context-Response Grounding in\n  E-commerce Conversational LLM-Agents","summary":"  With the advancement of conversational large language models (LLMs), several\nLLM-based Conversational Shopping Agents (CSA) have been developed to help\ncustomers answer questions and smooth their shopping journey in e-commerce\ndomain. The primary objective in building a trustworthy CSA is to ensure the\nagent's responses are accurate and factually grounded, which is essential for\nbuilding customer trust and encouraging continuous engagement. However, two\nchallenges remain. First, LLMs produce hallucinated or unsupported claims. Such\ninaccuracies risk spreading misinformation and diminishing customer trust.\nSecond, without providing knowledge source attribution in CSA response,\ncustomers struggle to verify LLM-generated information. To address these\nchallenges, we present an easily productionized solution that enables a\n\"citation experience\" utilizing In-context Learning (ICL) and\nMulti-UX-Inference (MUI) to generate responses with citations to attribute its\noriginal sources without interfering other existing UX features. With proper UX\ndesign, these citation marks can be linked to the related product information\nand display the source to our customers. In this work, we also build\nauto-metrics and scalable benchmarks to holistically evaluate LLM's grounding\nand attribution capabilities. Our experiments demonstrate that incorporating\nthis citation generation paradigm can substantially enhance the grounding of\nLLM responses by 13.83% on the real-world data. As such, our solution not only\naddresses the immediate challenges of LLM grounding issues but also adds\ntransparency to conversational AI.\n","authors":["Jingying Zeng","Hui Liu","Zhenwei Dai","Xianfeng Tang","Chen Luo","Samarth Varshney","Zhen Li","Qi He"],"pdf_url":"https://arxiv.org/pdf/2503.04830v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19518v2","updated":"2025-03-10T01:43:42Z","published":"2025-02-26T19:33:35Z","title":"Assessing LLMs for Front-end Software Architecture Knowledge","summary":"  Large Language Models (LLMs) have demonstrated significant promise in\nautomating software development tasks, yet their capabilities with respect to\nsoftware design tasks remains largely unclear. This study investigates the\ncapabilities of an LLM in understanding, reproducing, and generating structures\nwithin the complex VIPER architecture, a design pattern for iOS applications.\nWe leverage Bloom's taxonomy to develop a comprehensive evaluation framework to\nassess the LLM's performance across different cognitive domains such as\nremembering, understanding, applying, analyzing, evaluating, and creating.\nExperimental results, using ChatGPT 4 Turbo 2024-04-09, reveal that the LLM\nexcelled in higher-order tasks like evaluating and creating, but faced\nchallenges with lower-order tasks requiring precise retrieval of architectural\ndetails. These findings highlight both the potential of LLMs to reduce\ndevelopment costs and the barriers to their effective application in real-world\nsoftware design scenarios. This study proposes a benchmark format for assessing\nLLM capabilities in software architecture, aiming to contribute toward more\nrobust and accessible AI-driven development tools.\n","authors":["L. P. Franciscatto Guerra","N. Ernst"],"pdf_url":"https://arxiv.org/pdf/2502.19518v2.pdf","comment":"4 pages, 1 figure, to appear in the International Workshop on\n  Designing Software at ICSE 2025"},{"id":"http://arxiv.org/abs/2501.17823v2","updated":"2025-03-10T01:34:24Z","published":"2025-01-29T18:15:49Z","title":"Robust Multimodal Learning via Cross-Modal Proxy Tokens","summary":"  Multimodal models often experience a significant performance drop when one or\nmore modalities are missing during inference. To address this challenge, we\npropose a simple yet effective approach that enhances robustness to missing\nmodalities while maintaining strong performance when all modalities are\navailable. Our method introduces cross-modal proxy tokens (CMPTs), which\napproximate the class token of a missing modality by attending only to the\ntokens of the available modality. To efficiently learn the approximation for\nthe missing modality via CMPTs with minimal computational overhead, we employ\nlow-rank adapters in frozen unimodal encoders and jointly optimize an alignment\nloss with a task-specific loss. Extensive experiments on five multimodal\ndatasets show that our method outperforms state-of-the-art baselines across\nvarious missing rates while achieving competitive results in complete-modality\nsettings. Overall, our method offers a flexible and efficient solution for\nrobust multimodal learning. The code and pretrained models will be released on\nGitHub.\n","authors":["Md Kaykobad Reza","Ameya Patil","Mashhour Solh","M. Salman Asif"],"pdf_url":"https://arxiv.org/pdf/2501.17823v2.pdf","comment":"17 Pages, 10 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2410.16795v2","updated":"2025-03-10T01:33:26Z","published":"2024-10-22T08:17:33Z","title":"Scene-Aware Explainable Multimodal Trajectory Prediction","summary":"  Advancements in intelligent technologies have significantly improved\nnavigation in complex traffic environments by enhancing environment perception\nand trajectory prediction for automated vehicles. However, current research\noften overlooks the joint reasoning of scenario agents and lacks explainability\nin trajectory prediction models, limiting their practical use in real-world\nsituations. To address this, we introduce the Explainable Conditional\nDiffusion-based Multimodal Trajectory Prediction (DMTP) model, which is\ndesigned to elucidate the environmental factors influencing predictions and\nreveal the underlying mechanisms. Our model integrates a modified conditional\ndiffusion approach to capture multimodal trajectory patterns and employs a\nrevised Shapley Value model to assess the significance of global and\nscenario-specific features. Experiments using the Waymo Open Motion Dataset\ndemonstrate that our explainable model excels in identifying critical inputs\nand significantly outperforms baseline models in accuracy. Moreover, the\nfactors identified align with the human driving experience, underscoring the\nmodel's effectiveness in learning accurate predictions. Code is available in\nour open-source repository:\nhttps://github.com/ocean-luna/Explainable-Prediction.\n","authors":["Pei Liu","Haipeng Liu","Xingyu Liu","Yiqun Li","Junlan Chen","Yangfan He","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2410.16795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06828v1","updated":"2025-03-10T01:27:09Z","published":"2025-03-10T01:27:09Z","title":"Towards a Multimodal MRI-Based Foundation Model for Multi-Level Feature\n  Exploration in Segmentation, Molecular Subtyping, and Grading of Glioma","summary":"  Accurate, noninvasive glioma characterization is crucial for effective\nclinical management. Traditional methods, dependent on invasive tissue\nsampling, often fail to capture the spatial heterogeneity of the tumor. While\ndeep learning has improved segmentation and molecular profiling, few approaches\nsimultaneously integrate tumor morphology and molecular features. Foundation\ndeep learning models, which learn robust, task-agnostic representations from\nlarge-scale datasets, hold great promise but remain underutilized in glioma\nimaging biomarkers. We propose the Multi-Task SWIN-UNETR (MTS-UNET) model, a\nnovel foundation-based framework built on the BrainSegFounder model, pretrained\non large-scale neuroimaging data. MTS-UNET simultaneously performs glioma\nsegmentation, histological grading, and molecular subtyping (IDH mutation and\n1p/19q co-deletion). It incorporates two key modules: Tumor-Aware Feature\nEncoding (TAFE) for multi-scale, tumor-focused feature extraction and\nCross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch\nsignals associated with IDH mutation. The model was trained and validated on a\ndiverse, multi-center cohort of 2,249 glioma patients from seven public\ndatasets. MTS-UNET achieved a mean Dice score of 84% for segmentation, along\nwith AUCs of 90.58% for IDH mutation, 69.22% for 1p/19q co-deletion prediction,\nand 87.54% for grading, significantly outperforming baseline models (p<=0.05).\nAblation studies validated the essential contributions of the TAFE and CMD\nmodules and demonstrated the robustness of the framework. The foundation-based\nMTS-UNET model effectively integrates tumor segmentation with multi-level\nclassification, exhibiting strong generalizability across diverse MRI datasets.\nThis framework shows significant potential for advancing noninvasive,\npersonalized glioma management by improving predictive accuracy and\ninterpretability.\n","authors":["Somayeh Farahani","Marjaneh Hejazi","Antonio Di Ieva","Emad Fatemizadeh","Sidong Liu"],"pdf_url":"https://arxiv.org/pdf/2503.06828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06820v1","updated":"2025-03-10T01:02:01Z","published":"2025-03-10T01:02:01Z","title":"Towards Fine-Grained Video Question Answering","summary":"  In the rapidly evolving domain of video understanding, Video Question\nAnswering (VideoQA) remains a focal point. However, existing datasets exhibit\ngaps in temporal and spatial granularity, which consequently limits the\ncapabilities of existing VideoQA methods. This paper introduces the\nMulti-Object Multi-Actor Question Answering (MOMA-QA) dataset, which is\ndesigned to address these shortcomings by emphasizing temporal localization,\nspatial relationship reasoning, and entity-centric queries. With ground truth\nscene graphs and temporal interval annotations, MOMA-QA is ideal for developing\nmodels for fine-grained video understanding. Furthermore, we present a novel\nvideo-language model, SGVLM, which incorporates a scene graph predictor, an\nefficient frame retriever, and a pre-trained large language model for temporal\nlocalization and fine-grained relationship understanding. Evaluations on\nMOMA-QA and other public datasets demonstrate the superior performance of our\nmodel, setting new benchmarks for VideoQA.\n","authors":["Wei Dai","Alan Luo","Zane Durante","Debadutta Dash","Arnold Milstein","Kevin Schulman","Ehsan Adeli","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2503.06820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14558v2","updated":"2025-03-10T00:58:44Z","published":"2025-02-20T13:38:36Z","title":"FUIA: Model Inversion Attack against Federated Unlearning","summary":"  With the introduction of regulations related to the ``right to be forgotten\",\nfederated learning (FL) is facing new privacy compliance challenges. To address\nthese challenges, researchers have proposed federated unlearning (FU). However,\nexisting FU research has primarily focused on improving the efficiency of\nunlearning, with less attention paid to the potential privacy vulnerabilities\ninherent in these methods. To address this gap, we draw inspiration from\ngradient inversion attacks in FL and propose the federated unlearning inversion\nattack (FUIA). The FUIA is specifically designed for the three types of FU\n(sample unlearning, client unlearning, and class unlearning), aiming to provide\na comprehensive analysis of the privacy leakage risks associated with FU. In\nFUIA, the server acts as an honest-but-curious attacker, recording and\nexploiting the model differences before and after unlearning to expose the\nfeatures and labels of forgotten data. FUIA significantly leaks the privacy of\nforgotten data and can target all types of FU. This attack contradicts the goal\nof FU to eliminate specific data influence, instead exploiting its\nvulnerabilities to recover forgotten data and expose its privacy flaws.\nExtensive experimental results show that FUIA can effectively reveal the\nprivate information of forgotten data. To mitigate this privacy leakage, we\nalso explore two potential defense methods, although these come at the cost of\nreduced unlearning effectiveness and the usability of the unlearned model.\n","authors":["Lei Zhou","Youwen Zhu"],"pdf_url":"https://arxiv.org/pdf/2502.14558v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06816v1","updated":"2025-03-10T00:43:45Z","published":"2025-03-10T00:43:45Z","title":"Semi-Supervised Medical Image Segmentation via Knowledge Mining from\n  Large Models","summary":"  Large-scale vision models like SAM have extensive visual knowledge, yet their\ngeneral nature and computational demands limit their use in specialized tasks\nlike medical image segmentation. In contrast, task-specific models such as\nU-Net++ often underperform due to sparse labeled data. This study introduces a\nstrategic knowledge mining method that leverages SAM's broad understanding to\nboost the performance of small, locally hosted deep learning models.\n  In our approach, we trained a U-Net++ model on a limited labeled dataset and\nextend its capabilities by converting SAM's output infered on unlabeled images\ninto prompts. This process not only harnesses SAM's generalized visual\nknowledge but also iteratively improves SAM's prediction to cater specialized\nmedical segmentation tasks via U-Net++. The mined knowledge, serving as \"pseudo\nlabels\", enriches the training dataset, enabling the fine-tuning of the local\nnetwork.\n  Applied to the Kvasir SEG and COVID-QU-Ex datasets which consist of\ngastrointestinal polyp and lung X-ray images respectively, our proposed method\nconsistently enhanced the segmentation performance on Dice by 3% and 1%\nrespectively over the baseline U-Net++ model, when the same amount of labelled\ndata were used during training (75% and 50% of labelled data). Remarkably, our\nproposed method surpassed the baseline U-Net++ model even when the latter was\ntrained exclusively on labeled data (100% of labelled data). These results\nunderscore the potential of knowledge mining to overcome data limitations in\nspecialized models by leveraging the broad, albeit general, knowledge of\nlarge-scale models like SAM, all while maintaining operational efficiency\nessential for clinical applications.\n","authors":["Yuchen Mao","Hongwei Li","Yinyi Lai","Giorgos Papanastasiou","Peng Qi","Yunjie Yang","Chengjia Wang"],"pdf_url":"https://arxiv.org/pdf/2503.06816v1.pdf","comment":"18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.06814v1","updated":"2025-03-10T00:38:31Z","published":"2025-03-10T00:38:31Z","title":"Unlocking Generalization for Robotics via Modularity and Scale","summary":"  How can we build generalist robot systems? Scale may not be enough due to the\nsignificant multimodality of robotics tasks, lack of easily accessible data and\nthe challenges of deploying on physical hardware. Meanwhile, most deployed\nrobotic systems today are inherently modular and can leverage the independent\ngeneralization capabilities of each module to perform well. Therefore, this\nthesis seeks to tackle the task of building generalist robot agents by\nintegrating these components into one: combining modularity with large-scale\nlearning for general purpose robot control. The first question we consider is:\nhow can we build modularity and hierarchy into learning systems? Our key\ninsight is that rather than having the agent learn hierarchy and low-level\ncontrol end-to-end, we can enforce modularity via planning to enable more\nefficient and capable robot learners. Next, we come to the role of scale in\nbuilding generalist robot systems. To scale, neural networks require vast\namounts of diverse data, expressive architectures to fit the data and a source\nof supervision to generate the data. We leverage a powerful supervision source:\nclassical planning, which can generalize, but is expensive to run and requires\naccess to privileged information to perform well in practice. We use these\nplanners to supervise large-scale policy learning in simulation to produce\ngeneralist agents. Finally, we consider how to unify modularity with\nlarge-scale policy learning to build real-world robot systems capable of\nperforming zero-shot manipulation. We do so by tightly integrating key\ningredients of modular high and mid-level planning, learned local control,\nprocedural scene generation and large-scale policy learning for sim2real\ntransfer. We demonstrate that this recipe can produce a single, generalist\nagent that can solve challenging long-horizon manipulation tasks in the real\nworld.\n","authors":["Murtaza Dalal"],"pdf_url":"https://arxiv.org/pdf/2503.06814v1.pdf","comment":"CMU Robotics PhD Thesis, 185 pages"},{"id":"http://arxiv.org/abs/2503.06812v1","updated":"2025-03-10T00:24:29Z","published":"2025-03-10T00:24:29Z","title":"Can Proof Assistants Verify Multi-Agent Systems?","summary":"  This paper presents the Soda language for verifying multi-agent systems. Soda\nis a high-level functional and object-oriented language that supports the\ncompilation of its code not only to Scala, a strongly statically typed\nhigh-level programming language, but also to Lean, a proof assistant and\nprogramming language. Given these capabilities, Soda can implement multi-agent\nsystems, or parts thereof, that can then be integrated into a mainstream\nsoftware ecosystem on the one hand and formally verified with state-of-the-art\ntools on the other hand. We provide a brief and informal introduction to Soda\nand the aforementioned interoperability capabilities, as well as a simple\ndemonstration of how interaction protocols can be designed and verified with\nSoda. In the course of the demonstration, we highlight challenges with respect\nto real-world applicability.\n","authors":["Julian Alfredo Mendez","Timotheus Kampik"],"pdf_url":"https://arxiv.org/pdf/2503.06812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06810v1","updated":"2025-03-10T00:13:19Z","published":"2025-03-10T00:13:19Z","title":"Mitigating Preference Hacking in Policy Optimization with Pessimism","summary":"  This work tackles the problem of overoptimization in reinforcement learning\nfrom human feedback (RLHF), a prevalent technique for aligning models with\nhuman preferences. RLHF relies on reward or preference models trained on\n\\emph{fixed preference datasets}, and these models are unreliable when\nevaluated outside the support of this preference data, leading to the common\nreward or preference hacking phenomenon. We propose novel, pessimistic\nobjectives for RLHF which are provably robust to overoptimization through the\nuse of pessimism in the face of uncertainty, and design practical algorithms,\nP3O and PRPO, to optimize these objectives. Our approach is derived for the\ngeneral preference optimization setting, but can be used with reward models as\nwell. We evaluate P3O and PRPO on the tasks of fine-tuning language models for\ndocument summarization and creating helpful assistants, demonstrating\nremarkable resilience to overoptimization.\n","authors":["Dhawal Gupta","Adam Fisch","Christoph Dann","Alekh Agarwal"],"pdf_url":"https://arxiv.org/pdf/2503.06810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22269v2","updated":"2025-03-10T23:59:12Z","published":"2024-10-29T17:27:58Z","title":"Fourier Head: Helping Large Language Models Learn Complex Probability\n  Distributions","summary":"  As the quality of large language models has improved, there has been\nincreased interest in using them to model non-linguistic tokens. For example,\nthe Decision Transformer recasts agentic decision making as a sequence modeling\nproblem, using a decoder-only LLM to model the distribution over the discrete\naction space for an Atari agent. However, when adapting LLMs to non-linguistic\ndomains, it remains unclear if softmax over discrete bins captures the\ncontinuous structure of the tokens and the potentially complex distributions\nneeded for high quality token generation. We introduce a neural network layer,\nconstructed using Fourier series, which we can easily substitute for any linear\nlayer if we want the outputs to have a more continuous structure. We perform\nextensive analysis on synthetic datasets, as well as on large-scale decision\nmaking and time series forecasting tasks. We also provide theoretical evidence\nthat this layer can better learn signal from data while ignoring high-frequency\nnoise. All of our results support the effectiveness of our proposed Fourier\nhead in scenarios where the underlying data distribution has a natural\ncontinuous structure. For example, the Fourier head improves a Decision\nTransformer agent's returns across four benchmark Atari games by as much as\n377%, and increases a state-of-the-art times series foundation model's\nforecasting performance by 3.5% across 20 benchmarks unseen during training.\n","authors":["Nate Gillman","Daksh Aggarwal","Michael Freeman","Saurabh Singh","Chen Sun"],"pdf_url":"https://arxiv.org/pdf/2410.22269v2.pdf","comment":"Camera ready version (ICLR 2025). Code at\n  https://nategillman.com/fourier-head"},{"id":"http://arxiv.org/abs/2503.07920v1","updated":"2025-03-10T23:54:52Z","published":"2025-03-10T23:54:52Z","title":"Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural\n  Vision-Language Dataset for Southeast Asia","summary":"  Southeast Asia (SEA) is a region of extraordinary linguistic and cultural\ndiversity, yet it remains significantly underrepresented in vision-language\n(VL) research. This often results in artificial intelligence (AI) models that\nfail to capture SEA cultural nuances. To fill this gap, we present SEA-VL, an\nopen-source initiative dedicated to developing high-quality, culturally\nrelevant data for SEA languages. By involving contributors from SEA countries,\nSEA-VL aims to ensure better cultural relevance and diversity, fostering\ngreater inclusivity of underrepresented languages in VL research. Beyond\ncrowdsourcing, our initiative goes one step further in the exploration of the\nautomatic collection of culturally relevant images through crawling and image\ngeneration. First, we find that image crawling achieves approximately ~85%\ncultural relevance while being more cost- and time-efficient than\ncrowdsourcing. Second, despite the substantial progress in generative vision\nmodels, synthetic images remain unreliable in accurately reflecting SEA\ncultures. The generated images often fail to reflect the nuanced traditions and\ncultural contexts of the region. Collectively, we gather 1.28M SEA\nculturally-relevant images, more than 50 times larger than other existing\ndatasets. Through SEA-VL, we aim to bridge the representation gap in SEA,\nfostering the development of more inclusive AI systems that authentically\nrepresent diverse cultures across SEA.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Joel Ruben Antony Moniz","Tack Hwa Wong","Mohammad Rifqi Farhansyah","Thant Thiri Maung","Frederikus Hudi","David Anugraha","Muhammad Ravi Shulthan Habibi","Muhammad Reza Qorib","Amit Agarwal","Joseph Marvin Imperial","Hitesh Laxmichand Patel","Vicky Feliren","Bahrul Ilmi Nasution","Manuel Antonio Rufino","Genta Indra Winata","Rian Adam Rajagede","Carlos Rafael Catalan","Mohamed Fazli Imam","Priyaranjan Pattnayak","Salsabila Zahirah Pranida","Kevin Pratama","Yeshil Bangera","Adisai Na-Thalang","Patricia Nicole Monderin","Yueqi Song","Christian Simon","Lynnette Hui Xian Ng","Richardy Lobo' Sapan","Taki Hasan Rafi","Bin Wang"," Supryadi","Kanyakorn Veerakanjana","Piyalitt Ittichaiwong","Matthew Theodore Roque","Karissa Vincentio","Takdanai Kreangphet","Phakphum Artkaew","Kadek Hendrawan Palgunadi","Yanzhi Yu","Rochana Prih Hastuti","William Nixon","Mithil Bangera","Adrian Xuan Wei Lim","Aye Hninn Khine","Hanif Muhammad Zhafran","Teddy Ferdinan","Audra Aurora Izzani","Ayushman Singh"," Evan","Jauza Akbar Krito","Michael Anugraha","Fenal Ashokbhai Ilasariya","Haochen Li","John Amadeo Daniswara","Filbert Aurelian Tjiaranata","Eryawan Presma Yulianrifat","Can Udomcharoenchaikit","Fadil Risdian Ansori","Mahardika Krisna Ihsani","Giang Nguyen","Anab Maulana Barik","Dan John Velasco","Rifo Ahmad Genadi","Saptarshi Saha","Chengwei Wei","Isaiah Flores","Kenneth Ko Han Chen","Anjela Gail Santos","Wan Shen Lim","Kaung Si Phyo","Tim Santos","Meisyarah Dwiastuti","Jiayun Luo","Jan Christian Blaise Cruz","Ming Shan Hee","Ikhlasul Akmal Hanif","M. Alif Al Hakim","Muhammad Rizky Sya'ban","Kun Kerdthaisong","Lester James V. Miranda","Fajri Koto","Tirana Noor Fatyanosa","Alham Fikri Aji","Jostin Jerico Rosal","Jun Kevin","Robert Wijaya","Onno P. Kampman","Ruochen Zhang","Börje F. Karlsson","Peerat Limkonchotiwat"],"pdf_url":"https://arxiv.org/pdf/2503.07920v1.pdf","comment":"SEA-VL Dataset:\n  https://huggingface.co/collections/SEACrowd/sea-vl-multicultural-vl-dataset-for-southeast-asia-67cf223d0c341d4ba2b236e7"},{"id":"http://arxiv.org/abs/2503.07919v1","updated":"2025-03-10T23:50:30Z","published":"2025-03-10T23:50:30Z","title":"BEARCUBS: A benchmark for computer-using web agents","summary":"  Modern web agents possess computer use abilities that allow them to interact\nwith webpages by sending commands to a virtual keyboard and mouse. While such\nagents have considerable potential to assist human users with complex tasks,\nevaluating their capabilities in real-world settings poses a major challenge.\nTo this end, we introduce BEARCUBS, a \"small but mighty\" benchmark of 111\ninformation-seeking questions designed to evaluate a web agent's ability to\nsearch, browse, and identify factual information from the web. Unlike prior web\nagent benchmarks, solving BEARCUBS requires (1) accessing live web content\nrather than synthetic or simulated pages, which captures the unpredictability\nof real-world web interactions; and (2) performing a broad range of multimodal\ninteractions (e.g., video understanding, 3D navigation) that cannot be bypassed\nvia text-based workarounds. Each question in BEARCUBS has a corresponding\nshort, unambiguous answer and a human-validated browsing trajectory, allowing\nfor transparent evaluation of agent performance and strategies. A human study\nconfirms that BEARCUBS questions are solvable but non-trivial (84.7% human\naccuracy), revealing search inefficiencies and domain knowledge gaps as common\nfailure points. By contrast, state-of-the-art computer-using agents\nunderperform, with the best-scoring system (OpenAI's Operator) reaching only\n24.3% accuracy. These results highlight critical areas for improvement,\nincluding reliable source selection and more powerful multimodal capabilities.\nTo facilitate future research, BEARCUBS will be updated periodically to replace\ninvalid or contaminated questions, keeping the benchmark fresh for future\ngenerations of web agents.\n","authors":["Yixiao Song","Katherine Thai","Chau Minh Pham","Yapei Chang","Mazin Nadaf","Mohit Iyyer"],"pdf_url":"https://arxiv.org/pdf/2503.07919v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2503.07914v1","updated":"2025-03-10T23:17:46Z","published":"2025-03-10T23:17:46Z","title":"Demystifying the Accuracy-Interpretability Trade-Off: A Case Study of\n  Inferring Ratings from Reviews","summary":"  Interpretable machine learning models offer understandable reasoning behind\ntheir decision-making process, though they may not always match the performance\nof their black-box counterparts. This trade-off between interpretability and\nmodel performance has sparked discussions around the deployment of AI,\nparticularly in critical applications where knowing the rationale of\ndecision-making is essential for trust and accountability. In this study, we\nconduct a comparative analysis of several black-box and interpretable models,\nfocusing on a specific NLP use case that has received limited attention:\ninferring ratings from reviews. Through this use case, we explore the intricate\nrelationship between the performance and interpretability of different models.\nWe introduce a quantitative score called Composite Interpretability (CI) to\nhelp visualize the trade-off between interpretability and performance,\nparticularly in the case of composite models. Our results indicate that, in\ngeneral, the learning performance improves as interpretability decreases, but\nthis relationship is not strictly monotonic, and there are instances where\ninterpretable models are more advantageous.\n","authors":["Pranjal Atrey","Michael P. Brundage","Min Wu","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2503.07914v1.pdf","comment":"Accepted at DAI Workshop, AAAI-2025"},{"id":"http://arxiv.org/abs/2503.07911v1","updated":"2025-03-10T23:15:57Z","published":"2025-03-10T23:15:57Z","title":"Visual and Text Prompt Segmentation: A Novel Multi-Model Framework for\n  Remote Sensing","summary":"  Pixel-level segmentation is essential in remote sensing, where foundational\nvision models like CLIP and Segment Anything Model(SAM) have demonstrated\nsignificant capabilities in zero-shot segmentation tasks. Despite their\nadvances, challenges specific to remote sensing remain substantial. Firstly,\nThe SAM without clear prompt constraints, often generates redundant masks, and\nmaking post-processing more complex. Secondly, the CLIP model, mainly designed\nfor global feature alignment in foundational models, often overlooks local\nobjects crucial to remote sensing. This oversight leads to inaccurate\nrecognition or misplaced focus in multi-target remote sensing imagery. Thirdly,\nboth models have not been pre-trained on multi-scale aerial views, increasing\nthe likelihood of detection failures. To tackle these challenges, we introduce\nthe innovative VTPSeg pipeline, utilizing the strengths of Grounding DINO,\nCLIP, and SAM for enhanced open-vocabulary image segmentation. The Grounding\nDINO+(GD+) module generates initial candidate bounding boxes, while the CLIP\nFilter++(CLIP++) module uses a combination of visual and textual prompts to\nrefine and filter out irrelevant object bounding boxes, ensuring that only\npertinent objects are considered. Subsequently, these refined bounding boxes\nserve as specific prompts for the FastSAM model, which executes precise\nsegmentation. Our VTPSeg is validated by experimental and ablation study\nresults on five popular remote sensing image segmentation datasets.\n","authors":["Xing Zi","Kairui Jin","Xian Tao","Jun Li","Ali Braytee","Rajiv Ratn Shah","Mukesh Prasad"],"pdf_url":"https://arxiv.org/pdf/2503.07911v1.pdf","comment":"Under Review - IEEE Journal of Selected Topics in Applied Earth\n  Observations and Remote Sensing"},{"id":"http://arxiv.org/abs/2503.07909v1","updated":"2025-03-10T23:13:35Z","published":"2025-03-10T23:13:35Z","title":"FunGraph: Functionality Aware 3D Scene Graphs for Language-Prompted\n  Scene Interaction","summary":"  The concept of 3D scene graphs is increasingly recognized as a powerful\nsemantic and hierarchical representation of the environment. Current approaches\noften address this at a coarse, object-level resolution. In contrast, our goal\nis to develop a representation that enables robots to directly interact with\ntheir environment by identifying both the location of functional interactive\nelements and how these can be used. To achieve this, we focus on detecting and\nstoring objects at a finer resolution, focusing on affordance-relevant parts.\nThe primary challenge lies in the scarcity of data that extends beyond\ninstance-level detection and the inherent difficulty of capturing detailed\nobject features using robotic sensors. We leverage currently available 3D\nresources to generate 2D data and train a detector, which is then used to\naugment the standard 3D scene graph generation pipeline. Through our\nexperiments, we demonstrate that our approach achieves functional element\nsegmentation comparable to state-of-the-art 3D models and that our augmentation\nenables task-driven affordance grounding with higher accuracy than the current\nsolutions.\n","authors":["Dennis Rotondi","Fabio Scaparro","Hermann Blum","Kai O. Arras"],"pdf_url":"https://arxiv.org/pdf/2503.07909v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07891v1","updated":"2025-03-10T22:16:45Z","published":"2025-03-10T22:16:45Z","title":"Gemini Embedding: Generalizable Embeddings from Gemini","summary":"  In this report, we introduce Gemini Embedding, a state-of-the-art embedding\nmodel leveraging the power of Gemini, Google's most capable large language\nmodel. Capitalizing on Gemini's inherent multilingual and code understanding\ncapabilities, Gemini Embedding produces highly generalizable embeddings for\ntext spanning numerous languages and textual modalities. The representations\ngenerated by Gemini Embedding can be precomputed and applied to a variety of\ndownstream tasks including classification, similarity, clustering, ranking, and\nretrieval. Evaluated on the Massive Multilingual Text Embedding Benchmark\n(MMTEB), which includes over one hundred tasks across 250+ languages, Gemini\nEmbedding substantially outperforms prior state-of-the-art models,\ndemonstrating considerable improvements in embedding quality. Achieving\nstate-of-the-art performance across MMTEB's multilingual, English, and code\nbenchmarks, our unified model demonstrates strong capabilities across a broad\nselection of tasks and surpasses specialized domain-specific models.\n","authors":["Jinhyuk Lee","Feiyang Chen","Sahil Dua","Daniel Cer","Madhuri Shanbhogue","Iftekhar Naim","Gustavo Hernández Ábrego","Zhe Li","Kaifeng Chen","Henrique Schechter Vera","Xiaoqi Ren","Shanfeng Zhang","Daniel Salz","Michael Boratko","Jay Han","Blair Chen","Shuo Huang","Vikram Rao","Paul Suganthan","Feng Han","Andreas Doumanoglou","Nithi Gupta","Fedor Moiseev","Cathy Yip","Aashi Jain","Simon Baumgartner","Shahrokh Shahi","Frank Palma Gomez","Sandeep Mariserla","Min Choi","Parashar Shah","Sonam Goenka","Ke Chen","Ye Xia","Koert Chen","Sai Meher Karthik Duddu","Yichang Chen","Trevor Walker","Wenlei Zhou","Rakesh Ghiya","Zach Gleicher","Karan Gill","Zhe Dong","Mojtaba Seyedhosseini","Yunhsuan Sung","Raphael Hoffmann","Tom Duerig"],"pdf_url":"https://arxiv.org/pdf/2503.07891v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2503.07885v1","updated":"2025-03-10T22:01:56Z","published":"2025-03-10T22:01:56Z","title":"Safety Guardrails for LLM-Enabled Robots","summary":"  Although the integration of large language models (LLMs) into robotics has\nunlocked transformative capabilities, it has also introduced significant safety\nconcerns, ranging from average-case LLM errors (e.g., hallucinations) to\nadversarial jailbreaking attacks, which can produce harmful robot behavior in\nreal-world settings. Traditional robot safety approaches do not address the\nnovel vulnerabilities of LLMs, and current LLM safety guardrails overlook the\nphysical risks posed by robots operating in dynamic real-world environments. In\nthis paper, we propose RoboGuard, a two-stage guardrail architecture to ensure\nthe safety of LLM-enabled robots. RoboGuard first contextualizes pre-defined\nsafety rules by grounding them in the robot's environment using a root-of-trust\nLLM, which employs chain-of-thought (CoT) reasoning to generate rigorous safety\nspecifications, such as temporal logic constraints. RoboGuard then resolves\npotential conflicts between these contextual safety specifications and a\npossibly unsafe plan using temporal logic control synthesis, which ensures\nsafety compliance while minimally violating user preferences. Through extensive\nsimulation and real-world experiments that consider worst-case jailbreaking\nattacks, we demonstrate that RoboGuard reduces the execution of unsafe plans\nfrom 92% to below 2.5% without compromising performance on safe plans. We also\ndemonstrate that RoboGuard is resource-efficient, robust against adaptive\nattacks, and significantly enhanced by enabling its root-of-trust LLM to\nperform CoT reasoning. These results underscore the potential of RoboGuard to\nmitigate the safety risks and enhance the reliability of LLM-enabled robots.\n","authors":["Zachary Ravichandran","Alexander Robey","Vijay Kumar","George J. Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2503.07885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07884v1","updated":"2025-03-10T22:01:24Z","published":"2025-03-10T22:01:24Z","title":"LLMIdxAdvis: Resource-Efficient Index Advisor Utilizing Large Language\n  Model","summary":"  Index recommendation is essential for improving query performance in database\nmanagement systems (DBMSs) through creating an optimal set of indexes under\nspecific constraints. Traditional methods, such as heuristic and learning-based\napproaches, are effective but face challenges like lengthy recommendation time,\nresource-intensive training, and poor generalization across different workloads\nand database schemas. To address these issues, we propose LLMIdxAdvis, a\nresource-efficient index advisor that uses large language models (LLMs) without\nextensive fine-tuning. LLMIdxAdvis frames index recommendation as a\nsequence-to-sequence task, taking target workload, storage constraint, and\ncorresponding database environment as input, and directly outputting\nrecommended indexes. It constructs a high-quality demonstration pool offline,\nusing GPT-4-Turbo to synthesize diverse SQL queries and applying integrated\nheuristic methods to collect both default and refined labels. During\nrecommendation, these demonstrations are ranked to inject database expertise\nvia in-context learning. Additionally, LLMIdxAdvis extracts workload features\ninvolving specific column statistical information to strengthen LLM's\nunderstanding, and introduces a novel inference scaling strategy combining\nvertical scaling (via ''Index-Guided Major Voting'' and Best-of-N) and\nhorizontal scaling (through iterative ''self-optimization'' with database\nfeedback) to enhance reliability. Experiments on 3 OLAP and 2 real-world\nbenchmarks reveal that LLMIdxAdvis delivers competitive index recommendation\nwith reduced runtime, and generalizes effectively across different workloads\nand database schemas.\n","authors":["Xinxin Zhao","Haoyang Li","Jing Zhang","Xinmei Huang","Tieying Zhang","Jianjun Chen","Rui Shi","Cuiping Li","Hong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.07884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10283v2","updated":"2025-03-10T21:51:26Z","published":"2024-09-16T13:44:50Z","title":"ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone\n  Navigation via Scene-Aware Control Barrier Functions","summary":"  In the rapidly evolving field of vision-language navigation (VLN), ensuring\nsafety for physical agents remains an open challenge. For a human-in-the-loop\nlanguage-operated drone to navigate safely, it must understand natural language\ncommands, perceive the environment, and simultaneously avoid hazards in real\ntime. Control Barrier Functions (CBFs) are formal methods that enforce safe\noperating conditions. Model Predictive Control (MPC) is an optimization\nframework that plans a sequence of future actions over a prediction horizon,\nensuring smooth trajectory tracking while obeying constraints. In this work, we\nconsider a VLN-operated drone platform and enhance its safety by formulating a\nnovel scene-aware CBF that leverages ego-centric observations from a camera\nwhich has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less\nbaseline system uses a Vision-Language Encoder with cross-modal attention to\nconvert commands into an ordered sequence of landmarks. An object detection\nmodel identifies and verifies these landmarks in the captured images to\ngenerate a planned path. To further enhance safety, an Adaptive Safety Margin\nAlgorithm (ASMA) is proposed. ASMA tracks moving objects and performs\nscene-aware CBF evaluation on-the-fly, which serves as an additional constraint\nwithin the MPC framework. By continuously identifying potentially risky\nobservations, the system performs prediction in real time about unsafe\nconditions and proactively adjusts its control actions to maintain safe\nnavigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in\nthe Gazebo environment using the Robot Operating System (ROS), ASMA achieves\n64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in\ntrajectory lengths compared to the baseline CBF-less VLN.\n","authors":["Sourav Sanyal","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2409.10283v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07878v1","updated":"2025-03-10T21:50:58Z","published":"2025-03-10T21:50:58Z","title":"Measuring directional bias amplification in image captions using\n  predictability","summary":"  When we train models on biased ML datasets, they not only learn these biases\nbut can inflate them at test time - a phenomenon called bias amplification. To\nmeasure bias amplification in ML datasets, many co-occurrence-based metrics\nhave been proposed. Co-occurrence-based metrics are effective in measuring bias\namplification in simple problems like image classification. However, these\nmetrics are ineffective for complex problems like image captioning as they\ncannot capture the semantics of a caption. To measure bias amplification in\ncaptions, prior work introduced a predictability-based metric called Leakage in\nCaptioning (LIC). While LIC captures the semantics and context of captions, it\nhas limitations. LIC cannot identify the direction in which bias is amplified,\npoorly estimates dataset bias due to a weak vocabulary substitution strategy,\nand is highly sensitive to attacker models (a hyperparameter in\npredictability-based metrics). To overcome these issues, we propose Directional\nPredictability Amplification in Captioning (DPAC). DPAC measures directional\nbias amplification in captions, provides a better estimate of dataset bias\nusing an improved substitution strategy, and is less sensitive to attacker\nmodels. Our experiments on the COCO captioning dataset show how DPAC is the\nmost reliable metric to measure bias amplification in captions.\n","authors":["Rahul Nair","Bhanu Tokas","Hannah Kerner"],"pdf_url":"https://arxiv.org/pdf/2503.07878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07874v1","updated":"2025-03-10T21:46:57Z","published":"2025-03-10T21:46:57Z","title":"Topology-Preserving Loss for Accurate and Anatomically Consistent\n  Cardiac Mesh Reconstruction","summary":"  Accurate cardiac mesh reconstruction from volumetric data is essential for\npersonalized cardiac modeling and clinical analysis. However, existing\ndeformation-based approaches are prone to topological inconsistencies,\nparticularly membrane penetration, which undermines the anatomical plausibility\nof the reconstructed mesh. To address this issue, we introduce\nTopology-Preserving Mesh Loss (TPM Loss), a novel loss function that explicitly\nenforces topological constraints during mesh deformation. By identifying\ntopology-violating points, TPM Loss ensures spatially consistent\nreconstructions. Extensive experiments on CT and MRI datasets show that TPM\nLoss reduces topology violations by up to 93.1% while maintaining high\nsegmentation accuracy (DSC: 89.1%-92.9%) and improving mesh fidelity (Chamfer\nDistance reduction up to 0.26 mm). These results demonstrate that TPM Loss\neffectively prevents membrane penetration and significantly improves cardiac\nmesh quality, enabling more accurate and anatomically consistent cardiac\nreconstructions.\n","authors":["Chenyu Zhang","Yihao Luo","Yinzhe Wu","Choon Hwai Yap","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.07874v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07871v1","updated":"2025-03-10T21:37:22Z","published":"2025-03-10T21:37:22Z","title":"MapQA: Open-domain Geospatial Question Answering on Map Data","summary":"  Geospatial question answering (QA) is a fundamental task in navigation and\npoint of interest (POI) searches. While existing geospatial QA datasets exist,\nthey are limited in both scale and diversity, often relying solely on textual\ndescriptions of geo-entities without considering their geometries. A major\nchallenge in scaling geospatial QA datasets for reasoning lies in the\ncomplexity of geospatial relationships, which require integrating spatial\nstructures, topological dependencies, and multi-hop reasoning capabilities that\nmost text-based QA datasets lack. To address these limitations, we introduce\nMapQA, a novel dataset that not only provides question-answer pairs but also\nincludes the geometries of geo-entities referenced in the questions. MapQA is\nconstructed using SQL query templates to extract question-answer pairs from\nOpenStreetMap (OSM) for two study regions: Southern California and Illinois. It\nconsists of 3,154 QA pairs spanning nine question types that require geospatial\nreasoning, such as neighborhood inference and geo-entity type identification.\nCompared to existing datasets, MapQA expands both the number and diversity of\ngeospatial question types. We explore two approaches to tackle this challenge:\n(1) a retrieval-based language model that ranks candidate geo-entities by\nembedding similarity, and (2) a large language model (LLM) that generates SQL\nqueries from natural language questions and geo-entity attributes, which are\nthen executed against an OSM database. Our findings indicate that\nretrieval-based methods effectively capture concepts like closeness and\ndirection but struggle with questions that require explicit computations (e.g.,\ndistance calculations). LLMs (e.g., GPT and Gemini) excel at generating SQL\nqueries for one-hop reasoning but face challenges with multi-hop reasoning,\nhighlighting a key bottleneck in advancing geospatial QA systems.\n","authors":["Zekun Li","Malcolm Grossman"," Eric"," Qasemi","Mihir Kulkarni","Muhao Chen","Yao-Yi Chiang"],"pdf_url":"https://arxiv.org/pdf/2503.07871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07869v1","updated":"2025-03-10T21:36:42Z","published":"2025-03-10T21:36:42Z","title":"Right Reward Right Time for Federated Learning","summary":"  Critical learning periods (CLPs) in federated learning (FL) refer to early\nstages during which low-quality contributions (e.g., sparse training data\navailability) can permanently impair the learning performance of the global\nmodel owned by the model owner (i.e., the cloud server). However, strategies to\nmotivate clients with high-quality contributions to join the FL training\nprocess and share trained model updates during CLPs remain underexplored.\nAdditionally, existing incentive mechanisms in FL treat all training periods\nequally, which consequently fails to motivate clients to participate early.\nCompounding this challenge is the cloud's limited knowledge of client training\ncapabilities due to privacy regulations, leading to information asymmetry.\nTherefore, in this article, we propose a time-aware incentive mechanism, called\nRight Reward Right Time (R3T), to encourage client involvement, especially\nduring CLPs, to maximize the utility of the cloud in FL. Specifically, the\ncloud utility function captures the trade-off between the achieved model\nperformance and payments allocated for clients' contributions, while accounting\nfor clients' time and system capabilities, efforts, joining time, and rewards.\nThen, we analytically derive the optimal contract for the cloud and devise a\nCLP-aware mechanism to incentivize early participation and efforts while\nmaximizing cloud utility, even under information asymmetry. By providing the\nright reward at the right time, our approach can attract the highest-quality\ncontributions during CLPs. Simulation and proof-of-concept studies show that\nR3T increases cloud utility and is more economically effective than benchmarks.\nNotably, our proof-of-concept results show up to a 47.6% reduction in the total\nnumber of clients and up to a 300% improvement in convergence time while\nreaching competitive test accuracies compared with incentive mechanism\nbenchmarks.\n","authors":["Thanh Linh Nguyen","Dinh Thai Hoang","Diep N. Nguyen","Quoc-Viet Pham"],"pdf_url":"https://arxiv.org/pdf/2503.07869v1.pdf","comment":"IEEE Journal Submission"},{"id":"http://arxiv.org/abs/2406.16810v2","updated":"2025-03-10T21:33:53Z","published":"2024-06-24T17:22:36Z","title":"How Data Inter-connectivity Shapes LLMs Unlearning: A Structural\n  Unlearning Perspective","summary":"  While unlearning knowledge from large language models (LLMs) is receiving\nincreasing attention, one important aspect remains unexplored. Existing\napproaches and benchmarks assume data points to-be-forgotten are independent,\nignoring their inter-connectivity - a fundamental characteristic of real-world\ndata structures. In this paper, we propose PISTOL, a method for compiling\nstructural datasets. PISTOL leverages the inherently structured nature of\ncontractual relationships, offering several key benefits. First, it enables\ninsights into the impact of structural data on unlearning effectiveness.\nSecond, it provides precise and concise ground truths for clearer evaluation.\nThird, its attribute generation does not require input from pre-trained LLMs,\nmitigating confounding risks. Leveraging datasets synthesized using PISTOL, we\ndemonstrate how data inter-connectivity impacts LLM unlearning. Specifically,\n(a) in both the pre-trained and fine-tuned models, unlearning difficulty\nincreases as data inter-connectivity grows, (b) there is a positive correlation\nbetween the density of the knowledge graph and unlearning difficulty, and (c)\nwhen the to-be-forgotten data is skewed towards one domain, balancing retaining\nperformance across all domains is challenging.\n","authors":["Xinchi Qiu","William F. Shen","Yihong Chen","Meghdad Kurmanji","Nicola Cancedda","Pontus Stenetorp","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2406.16810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07860v1","updated":"2025-03-10T21:18:32Z","published":"2025-03-10T21:18:32Z","title":"Video Action Differencing","summary":"  How do two individuals differ when performing the same action? In this work,\nwe introduce Video Action Differencing (VidDiff), the novel task of identifying\nsubtle differences between videos of the same action, which has many\napplications, such as coaching and skill learning. To enable development on\nthis new task, we first create VidDiffBench, a benchmark dataset containing 549\nvideo pairs, with human annotations of 4,469 fine-grained action differences\nand 2,075 localization timestamps indicating where these differences occur. Our\nexperiments demonstrate that VidDiffBench poses a significant challenge for\nstate-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL.\nBy analyzing failure cases of LMMs on VidDiffBench, we highlight two key\nchallenges for this task: localizing relevant sub-actions over two videos and\nfine-grained frame comparison. To overcome these, we propose the VidDiff\nmethod, an agentic workflow that breaks the task into three stages: action\ndifference proposal, keyframe localization, and frame differencing, each stage\nutilizing specialized foundation models. To encourage future research in this\nnew task, we release the benchmark at\nhttps://huggingface.co/datasets/jmhb/VidDiffBench and code at\nhttp://jmhb0.github.io/viddiff.\n","authors":["James Burgess","Xiaohan Wang","Yuhui Zhang","Anita Rau","Alejandro Lozano","Lisa Dunlap","Trevor Darrell","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2503.07860v1.pdf","comment":"ICLR 2025 (International Conference on Learning Representations)\n  Project page: http://jmhb0.github.io/viddiff Benchmark:\n  https://huggingface.co/datasets/jmhb/VidDiffBench"},{"id":"http://arxiv.org/abs/2405.04732v3","updated":"2025-03-10T21:12:19Z","published":"2024-05-08T00:45:20Z","title":"Is the House Ready For Sleeptime? Generating and Evaluating Situational\n  Queries for Embodied Question Answering","summary":"  We present and tackle the problem of Embodied Question Answering (EQA) with\nSituational Queries (S-EQA) in a household environment. Unlike prior EQA work\ntackling simple queries that directly reference target objects and properties\n(\"What is the color of the car?\"), situational queries (such as \"Is the house\nready for sleeptime?\") are challenging as they require the agent to correctly\nidentify multiple object-states (Doors: Closed, Lights: Off, etc.) and reach a\nconsensus on their states for an answer. Towards this objective, we first\nintroduce a novel Prompt-Generate-Evaluate (PGE) scheme that wraps around an\nLLM's output to generate unique situational queries and corresponding consensus\nobject information. PGE is used to generate 2K datapoints in the VirtualHome\nsimulator, which is then annotated for ground truth answers via a large scale\nuser-study conducted on M-Turk. With a high rate of answerability (97.26%) on\nthis study, we establish that LLMs are good at generating situational data.\nHowever, in evaluating the data using an LLM, we observe a low correlation of\n46.2% with the ground truth human annotations; indicating that while LLMs are\ngood at generating situational data, they struggle to answer them according to\nconsensus. When asked for reasoning, we observe the LLM often goes against\ncommonsense in justifying its answer. Finally, we utilize PGE to generate\nsituational data in a real-world environment, exposing LLM hallucination in\ngenerating reliable object-states when a structured scene graph is unavailable.\nTo the best of our knowledge, this is the first work to introduce EQA in the\ncontext of situational queries and also the first to present a generative\napproach for query creation. We aim to foster research on improving the\nreal-world usability of embodied agents through this work.\n","authors":["Vishnu Sashank Dorbala","Prasoon Goyal","Robinson Piramuthu","Michael Johnston","Reza Ghanadhan","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2405.04732v3.pdf","comment":"10 Pages"},{"id":"http://arxiv.org/abs/2305.16424v2","updated":"2025-03-10T21:04:47Z","published":"2023-05-25T18:56:19Z","title":"SketchOGD: Memory-Efficient Continual Learning","summary":"  When machine learning models are trained continually on a sequence of tasks,\nthey are often liable to forget what they learned on previous tasks--a\nphenomenon known as catastrophic forgetting. Proposed solutions to catastrophic\nforgetting tend to involve storing information about past tasks, meaning that\nmemory usage is a chief consideration in determining their practicality. This\npaper develops a memory-efficient solution to catastrophic forgetting using the\nidea of matrix sketching, in the context of a simple continual learning\nalgorithm known as orthogonal gradient descent (OGD). OGD finds weight updates\nthat aim to preserve performance on prior datapoints, using gradients of the\nmodel on those datapoints. However, since the memory cost of storing prior\nmodel gradients grows with the runtime of the algorithm, OGD is ill-suited to\ncontinual learning over long time horizons. To address this problem, we propose\nSketchOGD. SketchOGD employs an online sketching algorithm to compress model\ngradients as they are encountered into a matrix of a fixed, user-determined\nsize. In contrast to existing memory-efficient variants of OGD, SketchOGD runs\nonline without the need for advance knowledge of the total number of tasks, is\nsimple to implement, and is more amenable to analysis. We provide theoretical\nguarantees on the approximation error of the relevant sketches under a novel\nmetric suited to the downstream task of OGD. Experimentally, we find that\nSketchOGD tends to outperform current state-of-the-art variants of OGD given a\nfixed memory budget.\n","authors":["Youngjae Min","Benjamin Wright","Jeremy Bernstein","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2305.16424v2.pdf","comment":null}]},"2025-03-09T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.04579v5","updated":"2025-03-09T23:07:33Z","published":"2024-10-06T18:29:46Z","title":"Upsample or Upweight? Balanced Training on Heavily Imbalanced Datasets","summary":"  Data abundance across different domains exhibits a long-tailed distribution:\nfew domains have abundant data, while most face data scarcity. Our work focuses\non a multilingual setting, where available data is heavily skewed towards\nhigh-resource languages. Two common strategies to address this disparity are\nupsampling low-resource data (Temperature Sampling) and upweighting\nlow-resource loss (Scalarization). These methods are often assumed to be\nequivalent, but this equivalence has not been rigorously established, prompting\nour investigation.\n  Through theoretical and empirical analysis, we identify when these two\nmethods are equivalent and when they diverge. We prove that they are equivalent\nunder full gradient descent but differ under stochastic gradient descent due to\ndifferences in gradient variance. Specifically, Temperature Sampling exhibits\nlower variance in gradient estimation compared to Scalarization, leading to\nfaster convergence but a higher risk of overfitting. Based on these insights,\nwe propose Cooldown, a strategy that starts by heavily upsampling low-resource\nlanguages to accelerate convergence and gradually reduces the upsampling to\nprevent overfitting -- achieving the best of both worlds. Our method competes\neffectively with existing data re-weighting techniques while offering\ncomputational efficiency.\n","authors":["Tianjian Li","Haoran Xu","Weiting Tan","Kenton Murray","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2410.04579v5.pdf","comment":"19 pages, 9 figures, accepted to NAACL 2025 main conference"},{"id":"http://arxiv.org/abs/2503.06794v1","updated":"2025-03-09T22:16:48Z","published":"2025-03-09T22:16:48Z","title":"Silent Hazards of Token Reduction in Vision-Language Models: The Hidden\n  Impact on Consistency","summary":"  Vision language models (VLMs) have excelled in visual reasoning but often\nincur high computational costs. One key reason is the redundancy of visual\ntokens. Although recent token reduction methods claim to achieve minimal\nperformance loss, our extensive experiments reveal that token reduction can\nsubstantially alter a model's output distribution, leading to changes in\nprediction patterns that standard metrics such as accuracy loss do not fully\ncapture. Such inconsistencies are especially concerning for practical\napplications where system stability is critical. To investigate this\nphenomenon, we analyze how token reduction influences the energy distribution\nof a VLM's internal representations using a lower-rank approximation via\nSingular Value Decomposition (SVD). Our results show that changes in the\nInverse Participation Ratio of the singular value spectrum are strongly\ncorrelated with the model's consistency after token reduction. Based on these\ninsights, we propose LoFi--a training-free visual token reduction method that\nutilizes the leverage score from SVD for token pruning. Experimental\nevaluations demonstrate that LoFi not only reduces computational costs with\nminimal performance degradation but also significantly outperforms\nstate-of-the-art methods in terms of output consistency.\n","authors":["Yizheng Sun","Hao Li","Chang Xu","Chenghua Lin","Riza Batista-Navarro","Jingyuan Sun"],"pdf_url":"https://arxiv.org/pdf/2503.06794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06792v1","updated":"2025-03-09T22:11:30Z","published":"2025-03-09T22:11:30Z","title":"On the Mutual Influence of Gender and Occupation in LLM Representations","summary":"  We examine LLM representations of gender for first names in various\noccupational contexts to study how occupations and the gender perception of\nfirst names in LLMs influence each other mutually. We find that LLMs'\nfirst-name gender representations correlate with real-world gender statistics\nassociated with the name, and are influenced by the co-occurrence of\nstereotypically feminine or masculine occupations. Additionally, we study the\ninfluence of first-name gender representations on LLMs in a downstream\noccupation prediction task and their potential as an internal metric to\nidentify extrinsic model biases. While feminine first-name embeddings often\nraise the probabilities for female-dominated jobs (and vice versa for\nmale-dominated jobs), reliably using these internal gender representations for\nbias detection remains challenging.\n","authors":["Haozhe An","Connor Baumler","Abhilasha Sancheti","Rachel Rudinger"],"pdf_url":"https://arxiv.org/pdf/2503.06792v1.pdf","comment":"In submission"},{"id":"http://arxiv.org/abs/2501.13652v2","updated":"2025-03-09T21:32:52Z","published":"2025-01-23T13:31:51Z","title":"LVPruning: An Effective yet Simple Language-Guided Vision Token Pruning\n  Approach for Multi-modal Large Language Models","summary":"  Multi-modal Large Language Models (MLLMs) have achieved remarkable success by\nintegrating visual and textual modalities. However, they incur significant\ncomputational overhead due to the large number of vision tokens processed,\nlimiting their practicality in resource-constrained environments. We introduce\nLanguage-Guided Vision Token Pruning (LVPruning) for MLLMs, an effective yet\nsimple method that significantly reduces the computational burden while\npreserving model performance. LVPruning employs cross-attention modules to\ncompute the importance of vision tokens based on their interaction with\nlanguage tokens, determining which to prune. Importantly, LVPruning can be\nintegrated without modifying the original MLLM parameters, which makes\nLVPruning simple to apply or remove. Our experiments show that LVPruning can\neffectively reduce up to 90% of vision tokens by the middle layer of LLaVA-1.5,\nresulting in a 62.1% decrease in inference Tera Floating-Point Operations Per\nSecond (TFLOPs), with an average performance loss of just 0.45% across nine\nmulti-modal benchmarks.\n","authors":["Yizheng Sun","Yanze Xin","Hao Li","Jingyuan Sun","Chenghua Lin","Riza Batista-Navarro"],"pdf_url":"https://arxiv.org/pdf/2501.13652v2.pdf","comment":"Accepted to NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2503.06781v1","updated":"2025-03-09T21:23:52Z","published":"2025-03-09T21:23:52Z","title":"Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic\n  Text Rewriting","summary":"  Generic text rewriting is a prevalent large language model (LLM) application\nthat covers diverse real-world tasks, such as style transfer, fact correction,\nand email editing. These tasks vary in rewriting objectives (e.g., factual\nconsistency vs. semantic preservation), making it challenging to develop a\nunified model that excels across all dimensions. Existing methods often\nspecialize in either a single task or a specific objective, limiting their\ngeneralizability. In this work, we introduce a generic model proficient in\nfactuality, stylistic, and conversational rewriting tasks. To simulate\nreal-world user rewrite requests, we construct a conversational rewrite\ndataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw\nemails using LLMs. Combined with other popular rewrite datasets, including\nLongFact for the factuality rewrite task and RewriteLM for the stylistic\nrewrite task, this forms a broad benchmark for training and evaluating generic\nrewrite models. To align with task-specific objectives, we propose Dr Genre, a\nDecoupled-reward learning framework for Generic rewriting, that utilizes\nobjective-oriented reward models with a task-specific weighting. Evaluation\nshows that \\approach delivers higher-quality rewrites across all targeted\ntasks, improving objectives including instruction following (agreement),\ninternal consistency (coherence), and minimal unnecessary edits (conciseness).\n","authors":["Yufei Li","John Nham","Ganesh Jawahar","Lei Shu","David Uthus","Yun-Hsuan Sung","Chengrun Yang","Itai Rolnick","Yi Qiao","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2503.06781v1.pdf","comment":"29 pages, 4 figures, 25 tables"},{"id":"http://arxiv.org/abs/2503.06778v1","updated":"2025-03-09T21:14:14Z","published":"2025-03-09T21:14:14Z","title":"Large Language Models Are Effective Human Annotation Assistants, But Not\n  Good Independent Annotators","summary":"  Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.\n","authors":["Feng Gu","Zongxia Li","Carlos Rafael Colon","Benjamin Evans","Ishani Mondal","Jordan Lee Boyd-Graber"],"pdf_url":"https://arxiv.org/pdf/2503.06778v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.06765v1","updated":"2025-03-09T20:42:38Z","published":"2025-03-09T20:42:38Z","title":"Effectiveness of Zero-shot-CoT in Japanese Prompts","summary":"  We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in\nJapanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot\nCoT, which involves appending a phrase such as \"Let's think step by step\" to a\nprompt to encourage reasoning before answering, has been shown to offer LLM\nperformance improvements in mathematical and reasoning tasks, particularly in\nEnglish. We investigate how these effects transfer to Japanese using the\nJapanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task\nLanguage Understanding Benchmark (MMLU). Our results show that while zero-shot\nCoT prompting can lead to notable performance gains for some prompt categories\nin GPT-3.5, its impact in GPT-4o-mini is associated with significant\nperformance declines. However, for Japanese prompts there remain certain\ncategories, such as college mathematics and abstract algebra, that still\nexhibit improvements, despite the broader trend of diminishing effectiveness in\nmore advanced models.\n","authors":["Shusuke Takayama","Ian Frank"],"pdf_url":"https://arxiv.org/pdf/2503.06765v1.pdf","comment":"NLP2025 Workshop on Japanese Language Resources (JLR2025)"},{"id":"http://arxiv.org/abs/2501.14951v2","updated":"2025-03-09T20:31:19Z","published":"2025-01-24T22:39:08Z","title":"E-Gen: Leveraging E-Graphs to Improve Continuous Representations of\n  Symbolic Expressions","summary":"  Vector representations have been pivotal in advancing natural language\nprocessing (NLP), with prior research focusing on embedding techniques for\nmathematical expressions using mathematically equivalent formulations. While\neffective, these approaches are constrained by the size and diversity of\ntraining data. In this work, we address these limitations by introducing E-Gen,\na novel e-graph-based dataset generation scheme that synthesizes large and\ndiverse mathematical expression datasets, surpassing prior methods in size and\noperator variety. Leveraging this dataset, we train embedding models using two\nstrategies: (1) generating mathematically equivalent expressions, and (2)\ncontrastive learning to explicitly group equivalent expressions. We evaluate\nthese embeddings on both in-distribution and out-of-distribution mathematical\nlanguage processing tasks, comparing them against prior methods. Finally, we\ndemonstrate that our embedding-based approach outperforms state-of-the-art\nlarge language models (LLMs) on several tasks, underscoring the necessity of\noptimizing embedding methods for the mathematical data modality. The source\ncode and datasets are available at https://github.com/MLPgroup/E-Gen.\n","authors":["Hongbo Zheng","Suyuan Wang","Neeraj Gangwar","Nickvash Kani"],"pdf_url":"https://arxiv.org/pdf/2501.14951v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06749v1","updated":"2025-03-09T20:06:45Z","published":"2025-03-09T20:06:45Z","title":"Vision-R1: Incentivizing Reasoning Capability in Multimodal Large\n  Language Models","summary":"  DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .\n","authors":["Wenxuan Huang","Bohan Jia","Zijie Zhai","Shaosheng Cao","Zheyu Ye","Fei Zhao","Yao Hu","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07972v3","updated":"2025-03-09T19:39:00Z","published":"2025-02-11T21:36:31Z","title":"Training Sparse Mixture Of Experts Text Embedding Models","summary":"  Transformer-based text embedding models have improved their performance on\nbenchmarks like MIRACL and BEIR by increasing their parameter counts. However,\nthis scaling approach introduces significant deployment challenges, including\nincreased inference latency and memory usage. These challenges are particularly\nsevere in retrieval-augmented generation (RAG) applications, where large\nmodels' increased memory requirements constrain dataset ingestion capacity, and\ntheir higher latency directly impacts query-time performance. While causal\nlanguage models have addressed similar efficiency challenges using Mixture of\nExperts (MoE) architectures, this approach hasn't been successfully adapted to\nthe general text embedding setting. In this paper, we introduce Nomic Embed v2,\nthe first general purpose MoE text embedding model. Our model outperforms\nmodels in the same parameter class on both monolingual and multilingual\nbenchmarks while also maintaining competitive performance with models twice its\nsize. We open-source all code, models, and evaluation data to ensure full\nreproducibility of our training pipeline at\n\\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.\n","authors":["Zach Nussbaum","Brandon Duderstadt"],"pdf_url":"https://arxiv.org/pdf/2502.07972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06734v1","updated":"2025-03-09T19:17:46Z","published":"2025-03-09T19:17:46Z","title":"Gender Encoding Patterns in Pretrained Language Model Representations","summary":"  Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models.\n","authors":["Mahdi Zakizadeh","Mohammad Taher Pilehvar"],"pdf_url":"https://arxiv.org/pdf/2503.06734v1.pdf","comment":"Proceedings of the 5th Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025)"},{"id":"http://arxiv.org/abs/2503.06724v1","updated":"2025-03-09T18:47:17Z","published":"2025-03-09T18:47:17Z","title":"Topology of Syntax Networks across Languages","summary":"  Syntax connects words to each other in very specific ways. Two words are\nsyntactically connected if they depend\n  directly on each other. Syntactic connections usually happen within a\nsentence. Gathering all those connection\n  across several sentences gives birth to syntax networks. Earlier studies in\nthe field have analysed the structure and\n  properties of syntax networks trying to find clusters/phylogenies of\nlanguages that share similar network features.\n  The results obtained in those studies will be put to test in this thesis by\nincreasing both the number of languages\n  and the number of properties considered in the analysis. Besides that,\nlanguage networks of particular languages\n  will be inspected in depth by means of a novel network analysis [25]. Words\n(nodes of the network) will be clustered\n  into topological communities whose members share similar features. The\nproperties of each of these communities\n  will be thoroughly studied along with the Part of Speech (grammatical class)\nof each word. Results across different\n  languages will also be compared in an attempt to discover universally\npreserved structural patterns across syntax\n  networks.\n","authors":["Juan Soria-Postigo","Luis F Seoane"],"pdf_url":"https://arxiv.org/pdf/2503.06724v1.pdf","comment":"Final Thesis for MSc in Computational and Applied Mathematics at UC3M"},{"id":"http://arxiv.org/abs/2503.06709v1","updated":"2025-03-09T17:59:16Z","published":"2025-03-09T17:59:16Z","title":"Delusions of Large Language Models","summary":"  Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.\n","authors":["Hongshen Xu","Zixv yang","Zichen Zhu","Kunyao Lan","Zihan Wang","Mengyue Wu","Ziwei Ji","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.06709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06708v1","updated":"2025-03-09T17:55:49Z","published":"2025-03-09T17:55:49Z","title":"Alignment for Efficient Tool Calling of Large Language Models","summary":"  Recent advancements in tool learning have enabled large language models\n(LLMs) to integrate external tools, enhancing their task performance by\nexpanding their knowledge boundaries. However, relying on tools often\nintroduces tradeoffs between performance, speed, and cost, with LLMs sometimes\nexhibiting overreliance and overconfidence in tool usage. This paper addresses\nthe challenge of aligning LLMs with their knowledge boundaries to make more\nintelligent decisions about tool invocation. We propose a multi objective\nalignment framework that combines probabilistic knowledge boundary estimation\nwith dynamic decision making, allowing LLMs to better assess when to invoke\ntools based on their confidence. Our framework includes two methods for\nknowledge boundary estimation, consistency based and absolute estimation, and\ntwo training strategies for integrating these estimates into the model decision\nmaking process. Experimental results on various tool invocation scenarios\ndemonstrate the effectiveness of our framework, showing significant\nimprovements in tool efficiency by reducing unnecessary tool usage.\n","authors":["Hongshen Xu","Zihan Wang","Zichen Zhu","Lei Pan","Xingyu Chen","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.06708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22590v2","updated":"2025-03-09T17:54:32Z","published":"2024-10-29T23:05:41Z","title":"Characterizing the Role of Similarity in the Property Inferences of\n  Language Models","summary":"  Property inheritance -- a phenomenon where novel properties are projected\nfrom higher level categories (e.g., birds) to lower level ones (e.g., sparrows)\n-- provides a unique window into how humans organize and deploy conceptual\nknowledge. It is debated whether this ability arises due to explicitly stored\ntaxonomic knowledge vs. simple computations of similarity between mental\nrepresentations. How are these mechanistic hypotheses manifested in\ncontemporary language models? In this work, we investigate how LMs perform\nproperty inheritance with behavioral and causal representational analysis\nexperiments. We find that taxonomy and categorical similarities are not\nmutually exclusive in LMs' property inheritance behavior. That is, LMs are more\nlikely to project novel properties from one category to the other when they are\ntaxonomically related and at the same time, highly similar. Our findings\nprovide insight into the conceptual structure of language models and may\nsuggest new psycholinguistic experiments for human subjects.\n","authors":["Juan Diego Rodriguez","Aaron Mueller","Kanishka Misra"],"pdf_url":"https://arxiv.org/pdf/2410.22590v2.pdf","comment":"Published at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.06706v1","updated":"2025-03-09T17:43:30Z","published":"2025-03-09T17:43:30Z","title":"PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on\n  UML Flowcharts","summary":"  Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.\n","authors":["Ming Zhang","Yuhui Wang","Yujiong Shen","Tingyi Yang","Changhao Jiang","Yilong Wu","Shihan Dou","Qinhao Chen","Zhiheng Xi","Zhihao Zhang","Yi Dong","Zhen Wang","Zhihui Fei","Mingyang Wan","Tao Liang","Guojun Ma","Qi Zhang","Tao Gui","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.06706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06692v1","updated":"2025-03-09T16:59:14Z","published":"2025-03-09T16:59:14Z","title":"InftyThink: Breaking the Length Limits of Long-Context Reasoning in\n  Large Language Models","summary":"  Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.\n","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12509v3","updated":"2025-03-09T16:53:11Z","published":"2025-02-18T03:47:53Z","title":"LegalCore: A Dataset for Event Coreference Resolution in Legal Documents","summary":"  Recognizing events and their coreferential mentions in a document is\nessential for understanding semantic meanings of text. The existing research on\nevent coreference resolution is mostly limited to news articles. In this paper,\nwe present the first dataset for the legal domain, LegalCore, which has been\nannotated with comprehensive event and event coreference information. The legal\ncontract documents we annotated in this dataset are several times longer than\nnews articles, with an average length of around 25k tokens per document. The\nannotations show that legal documents have dense event mentions and feature\nboth short-distance and super long-distance coreference links between event\nmentions. We further benchmark mainstream Large Language Models (LLMs) on this\ndataset for both event detection and event coreference resolution tasks, and\nfind that this dataset poses significant challenges for state-of-the-art\nopen-source and proprietary LLMs, which perform significantly worse than a\nsupervised baseline. We will publish the dataset as well as the code.\n","authors":["Kangda Wei","Xi Shi","Jonathan Tong","Sai Ramana Reddy","Anandhavelu Natarajan","Rajiv Jain","Aparna Garimella","Ruihong Huang"],"pdf_url":"https://arxiv.org/pdf/2502.12509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06689v1","updated":"2025-03-09T16:45:22Z","published":"2025-03-09T16:45:22Z","title":"DependEval: Benchmarking LLMs for Repository Dependency Understanding","summary":"  While large language models (LLMs) have shown considerable promise in code\ngeneration, real-world software development demands advanced repository-level\nreasoning. This includes understanding dependencies, project structures, and\nmanaging multi-file changes. However, the ability of LLMs to effectively\ncomprehend and handle complex code repositories has yet to be fully explored.\nTo address challenges, we introduce a hierarchical benchmark designed to\nevaluate repository dependency understanding (DependEval). Benchmark is based\non 15,576 repositories collected from real-world websites. It evaluates models\non three core tasks: Dependency Recognition, Repository Construction, and\nMulti-file Editing, across 8 programming languages from actual code\nrepositories. Our evaluation of over 25 LLMs reveals substantial performance\ngaps and provides valuable insights into repository-level code understanding.\n","authors":["Junjia Du","Yadi Liu","Hongcheng Guo","Jiawei Wang","Haojian Huang","Yunyi Ni","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2503.06689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06670v1","updated":"2025-03-09T15:43:55Z","published":"2025-03-09T15:43:55Z","title":"Attention, Please! PixelSHAP Reveals What Vision-Language Models\n  Actually Focus On","summary":"  Interpretability in Vision-Language Models (VLMs) is crucial for trust,\ndebugging, and decision-making in high-stakes applications. We introduce\nPixelSHAP, a model-agnostic framework extending Shapley-based analysis to\nstructured visual entities. Unlike previous methods focusing on text prompts,\nPixelSHAP applies to vision-based reasoning by systematically perturbing image\nobjects and quantifying their influence on a VLM's response. PixelSHAP requires\nno model internals, operating solely on input-output pairs, making it\ncompatible with open-source and commercial models. It supports diverse\nembedding-based similarity metrics and scales efficiently using optimization\ntechniques inspired by Shapley-based methods. We validate PixelSHAP in\nautonomous driving, highlighting its ability to enhance interpretability. Key\nchallenges include segmentation sensitivity and object occlusion. Our\nopen-source implementation facilitates further research.\n","authors":["Roni Goldshmidt"],"pdf_url":"https://arxiv.org/pdf/2503.06670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02155v3","updated":"2025-03-09T15:36:53Z","published":"2024-10-03T02:34:31Z","title":"From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities","summary":"  Multimodal Large Language Models have made significant strides in integrating\nvisual and textual information, yet they often struggle with effectively\naligning these modalities. We introduce a novel image tokenizer that bridges\nthis gap by applying the principle of Byte-Pair Encoding (BPE) to visual data.\nUnlike conventional approaches that rely on separate visual encoders, our\nmethod directly incorporates structural prior information into image tokens,\nmirroring the successful tokenization strategies used in text-only Large\nLanguage Models. This innovative approach enables Transformer models to more\neffectively learn and reason across modalities. Through theoretical analysis\nand extensive experiments, we demonstrate that our BPE Image Tokenizer\nsignificantly enhances MLLMs' multimodal understanding capabilities, even with\nlimited training data. Leveraging this method, we develop Being-VL-0, a model\nthat demonstrates superior performance across various benchmarks and shows\npromising scalability, potentially paving the way for more efficient and\ncapable multimodal foundation models.\n","authors":["Wanpeng Zhang","Zilong Xie","Yicheng Feng","Yijiang Li","Xingrun Xing","Sipeng Zheng","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2410.02155v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07446v2","updated":"2025-03-09T15:02:01Z","published":"2024-12-10T12:05:03Z","title":"A Causal World Model Underlying Next Token Prediction in GPT","summary":"  Are generative pre-trained transformer (GPT) models only trained to predict\nthe next token, or do they implicitly learn a world model from which a sequence\nis generated one token at a time? We examine this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that\nGPT-models, at inference time, can be utilized for zero-shot causal structure\nlearning for in-distribution sequences. Empirical evaluation is conducted in a\ncontrolled synthetic environment using the setup and rules of the Othello board\ngame. A GPT, pre-trained on real-world games played with the intention of\nwinning, is tested on synthetic data that only adheres to the game rules,\noblivious to the goal of winning. We find that the GPT model is likely to\ngenerate moves that adhere to the game rules for sequences for which a causal\nstructure is encoded in the attention mechanism with high confidence. In\ngeneral, in cases for which the GPT model generates moves that do not adhere to\nthe game rules, it also fails to capture any causal structure.\n","authors":["Raanan Y. Rohekar","Yaniv Gurwicz","Sungduk Yu","Estelle Aflalo","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2412.07446v2.pdf","comment":"AAAI 2025 Workshop on Artificial Intelligence with Causal Techniques"},{"id":"http://arxiv.org/abs/2503.06648v1","updated":"2025-03-09T14:52:53Z","published":"2025-03-09T14:52:53Z","title":"Enhancing NLP Robustness and Generalization through LLM-Generated\n  Contrast Sets: A Scalable Framework for Systematic Evaluation and Adversarial\n  Training","summary":"  Standard NLP benchmarks often fail to capture vulnerabilities stemming from\ndataset artifacts and spurious correlations. Contrast sets address this gap by\nchallenging models near decision boundaries but are traditionally\nlabor-intensive to create and limited in diversity. This study leverages large\nlanguage models to automate the generation of diverse contrast sets. Using the\nSNLI dataset, we created a 3,000-example contrast set to evaluate and improve\nmodel robustness. Fine-tuning on these contrast sets enhanced performance on\nsystematically perturbed examples, maintained standard test accuracy, and\nmodestly improved generalization to novel perturbations. This automated\napproach offers a scalable solution for evaluating and improving NLP models,\naddressing systematic generalization challenges, and advancing robustness in\nreal-world applications.\n","authors":["Hender Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06646v1","updated":"2025-03-09T14:47:31Z","published":"2025-03-09T14:47:31Z","title":"Evaluating and Aligning Human Economic Risk Preferences in LLMs","summary":"  Large Language Models (LLMs) are increasingly used in decision-making\nscenarios that involve risk assessment, yet their alignment with human economic\nrationality remains unclear. In this study, we investigate whether LLMs exhibit\nrisk preferences consistent with human expectations across different personas.\nSpecifically, we assess whether LLM-generated responses reflect appropriate\nlevels of risk aversion or risk-seeking behavior based on individual's persona.\nOur results reveal that while LLMs make reasonable decisions in simplified,\npersonalized risk contexts, their performance declines in more complex economic\ndecision-making tasks. To address this, we propose an alignment method designed\nto enhance LLM adherence to persona-specific risk preferences. Our approach\nimproves the economic rationality of LLMs in risk-related applications,\noffering a step toward more human-aligned AI decision-making.\n","authors":["Jiaxin Liu","Yi Yang","Kar Yan Tam"],"pdf_url":"https://arxiv.org/pdf/2503.06646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06643v1","updated":"2025-03-09T14:41:18Z","published":"2025-03-09T14:41:18Z","title":"Is Your Benchmark (Still) Useful? Dynamic Benchmarking for Code Language\n  Models","summary":"  In this paper, we tackle a critical challenge in model evaluation: how to\nkeep code benchmarks useful when models might have already seen them during\ntraining. We introduce a novel solution, dynamic benchmarking framework, to\naddress this challenge. Given a code understanding or reasoning benchmark, our\nframework dynamically transforms each input, i.e., programs, with various\nsemantic-preserving mutations to build a syntactically new while semantically\nidentical benchmark. We evaluated ten popular language models on our dynamic\nbenchmarks. Our evaluation reveals several interesting or surprising findings:\n(1) all models perform significantly worse than before, (2) the ranking between\nsome models shifts dramatically, and (3) our dynamic benchmarks can resist\nagainst the data contamination problem.\n","authors":["Batu Guan","Xiao Wu","Yuanyuan Yuan","Shaohua Li"],"pdf_url":"https://arxiv.org/pdf/2503.06643v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.04240v2","updated":"2025-03-09T14:36:12Z","published":"2025-03-06T09:21:54Z","title":"DiffPO: Diffusion-styled Preference Optimization for Efficient\n  Inference-Time Alignment of Large Language Models","summary":"  Inference-time alignment provides an efficient alternative for aligning LLMs\nwith humans. However, these approaches still face challenges, such as limited\nscalability due to policy-specific value functions and latency during the\ninference phase. In this paper, we propose a novel approach, Diffusion-styled\nPreference Optimization (\\model), which provides an efficient and\npolicy-agnostic solution for aligning LLMs with humans. By directly performing\nalignment at sentence level, \\model~avoids the time latency associated with\ntoken-level generation. Designed as a plug-and-play module, \\model~can be\nseamlessly integrated with various base models to enhance their alignment.\nExtensive experiments on AlpacaEval 2, MT-bench, and HH-RLHF demonstrate that\n\\model~achieves superior alignment performance across various settings,\nachieving a favorable trade-off between alignment quality and inference-time\nlatency. Furthermore, \\model~demonstrates model-agnostic scalability,\nsignificantly improving the performance of large models such as Llama-3-70B.\n","authors":["Ruizhe Chen","Wenhao Chai","Zhifei Yang","Xiaotian Zhang","Joey Tianyi Zhou","Tony Quek","Soujanya Poria","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06627v1","updated":"2025-03-09T14:05:27Z","published":"2025-03-09T14:05:27Z","title":"Revisiting Early Detection of Sexual Predators via Turn-level\n  Optimization","summary":"  Online grooming is a severe social threat where sexual predators gradually\nentrap child victims with subtle and gradual manipulation. Therefore, timely\nintervention for online grooming is critical for proactive protection. However,\nprevious methods fail to determine the optimal intervention points (i.e., jump\nto conclusions) as they rely on chat-level risk labels by causing weak\nsupervision of risky utterances. For timely detection, we propose speed control\nreinforcement learning (SCoRL) (The code and supplementary materials are\navailable at https://github.com/jinmyeongAN/SCoRL), incorporating a practical\nstrategy derived from luring communication theory (LCT). To capture the\npredator's turn-level entrapment, we use a turn-level risk label based on the\nLCT. Then, we design a novel speed control reward function that balances the\ntrade-off between speed and accuracy based on turn-level risk label; thus,\nSCoRL can identify the optimal intervention moment. In addition, we introduce a\nturn-level metric for precise evaluation, identifying limitations in previously\nused chat-level metrics. Experimental results show that SCoRL effectively\npreempted online grooming, offering a more proactive and timely solution.\nFurther analysis reveals that our method enhances performance while intuitively\nidentifying optimal early intervention points.\n","authors":["Jinmyeong An","Sangwon Ryu","Heejin Do","Yunsu Kim","Jungseul Ok","Gary Geunbae Lee"],"pdf_url":"https://arxiv.org/pdf/2503.06627v1.pdf","comment":"Accepted as a main conference paper at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.06594v1","updated":"2025-03-09T12:54:05Z","published":"2025-03-09T12:54:05Z","title":"Beyond Decoder-only: Large Language Models Can be Good Encoders for\n  Machine Translation","summary":"  The field of neural machine translation (NMT) has changed with the advent of\nlarge language models (LLMs). Much of the recent emphasis in natural language\nprocessing (NLP) has been on modeling machine translation and many other\nproblems using a single pre-trained Transformer decoder, while encoder-decoder\narchitectures, which were the standard in earlier NMT models, have received\nrelatively less attention. In this paper, we explore translation models that\nare universal, efficient, and easy to optimize, by marrying the world of LLMs\nwith the world of NMT. We apply LLMs to NMT encoding and leave the NMT decoder\nunchanged. We also develop methods for adapting LLMs to work better with the\nNMT decoder. Furthermore, we construct a new dataset involving multiple tasks\nto assess how well the machine translation system generalizes across various\ntasks. Evaluations on the WMT and our datasets show that results using our\nmethod match or surpass a range of baselines in terms of translation quality,\nbut achieve $2.4 \\sim 6.5 \\times$ inference speedups and a $75\\%$ reduction in\nthe memory footprint of the KV cache. It also demonstrates strong\ngeneralization across a variety of translation-related tasks.\n","authors":["Yingfeng Luo","Tong Zheng","Yongyu Mu","Bei Li","Qinghong Zhang","Yongqi Gao","Ziqiang Xu","Peinan Feng","Xiaoqian Liu","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.06594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07131v2","updated":"2025-03-09T12:07:18Z","published":"2025-02-10T23:49:39Z","title":"TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model\n  Bring? -- A Case Study on Korea Financial Texts","summary":"  Domain specificity of embedding models is critical for effective performance.\nHowever, existing benchmarks, such as FinMTEB, are primarily designed for\nhigh-resource languages, leaving low-resource settings, such as Korean,\nunder-explored. Directly translating established English benchmarks often fails\nto capture the linguistic and cultural nuances present in low-resource domains.\nIn this paper, titled TWICE: What Advantages Can Low-Resource Domain-Specific\nEmbedding Models Bring? A Case Study on Korea Financial Texts, we introduce\nKorFinMTEB, a novel benchmark for the Korean financial domain, specifically\ntailored to reflect its unique cultural characteristics in low-resource\nlanguages. Our experimental results reveal that while the models perform\nrobustly on a translated version of FinMTEB, their performance on KorFinMTEB\nuncovers subtle yet critical discrepancies, especially in tasks requiring\ndeeper semantic understanding, that underscore the limitations of direct\ntranslation. This discrepancy highlights the necessity of benchmarks that\nincorporate language-specific idiosyncrasies and cultural nuances. The insights\nfrom our study advocate for the development of domain-specific evaluation\nframeworks that can more accurately assess and drive the progress of embedding\nmodels in low-resource settings.\n","authors":["Yewon Hwang","Sungbum Jung","Hanwool Lee","Sara Yu"],"pdf_url":"https://arxiv.org/pdf/2502.07131v2.pdf","comment":"Accepted at FinancialAI@ICLR 2025"},{"id":"http://arxiv.org/abs/2503.06573v1","updated":"2025-03-09T12:06:29Z","published":"2025-03-09T12:06:29Z","title":"WildIFEval: Instruction Following in the Wild","summary":"  Recent LLMs have shown remarkable success in following user instructions, yet\nhandling instructions with multiple constraints remains a significant\nchallenge. In this work, we introduce WildIFEval - a large-scale dataset of 12K\nreal user instructions with diverse, multi-constraint conditions. Unlike prior\ndatasets, our collection spans a broad lexical and topical spectrum of\nconstraints, in natural user prompts. We categorize these constraints into\neight high-level classes to capture their distribution and dynamics in\nreal-world scenarios. Leveraging WildIFEval, we conduct extensive experiments\nto benchmark the instruction-following capabilities of leading LLMs. Our\nfindings reveal that all evaluated models experience performance degradation\nwith an increasing number of constraints. Thus, we show that all models have a\nlarge room for improvement on such tasks. Moreover, we observe that the\nspecific type of constraint plays a critical role in model performance. We\nrelease our dataset to promote further research on instruction-following under\ncomplex, realistic conditions.\n","authors":["Gili Lior","Asaf Yehudai","Ariel Gera","Liat Ein-Dor"],"pdf_url":"https://arxiv.org/pdf/2503.06573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03594v2","updated":"2025-03-09T10:56:53Z","published":"2025-03-05T15:27:36Z","title":"Small but Mighty: Enhancing Time Series Forecasting with Lightweight\n  LLMs","summary":"  While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.\n","authors":["Haoran Fan","Bin Li","Yixuan Weng","Shoujun Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03594v2.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.06552v1","updated":"2025-03-09T10:48:47Z","published":"2025-03-09T10:48:47Z","title":"Multimodal Programming in Computer Science with Interactive Assistance\n  Powered by Large Language Model","summary":"  LLM chatbot interfaces allow students to get instant, interactive assistance\nwith homework, but doing so carelessly may not advance educational objectives.\nIn this study, an interactive homework help system based on DeepSeek R1 is\ndeveloped and first implemented for students enrolled in a large computer\nscience beginning programming course. In addition to an assist button in a\nwell-known code editor, our assistant also has a feedback option in our\ncommand-line automatic evaluator. It wraps student work in a personalized\nprompt that advances our educational objectives without offering answers\nstraight away. We have discovered that our assistant can recognize students'\nconceptual difficulties and provide ideas, plans, and template code in\npedagogically appropriate ways. However, among other mistakes, it occasionally\nincorrectly labels the correct student code as incorrect or encourages students\nto use correct-but-lesson-inappropriate approaches, which can lead to long and\nfrustrating journeys for the students. After discussing many development and\ndeployment issues, we provide our conclusions and future actions.\n","authors":["Rajan Das Gupta","Md. Tanzib Hosain","M. F. Mridha","Salah Uddin Ahmed"],"pdf_url":"https://arxiv.org/pdf/2503.06552v1.pdf","comment":"Accepted in Proceedings of the 27th International Conference on.\n  Human-Computer Interaction, 2025"},{"id":"http://arxiv.org/abs/2503.06550v1","updated":"2025-03-09T10:43:09Z","published":"2025-03-09T10:43:09Z","title":"BingoGuard: LLM Content Moderation Tools with Risk Levels","summary":"  Malicious content generated by large language models (LLMs) can pose varying\ndegrees of harm. Although existing LLM-based moderators can detect harmful\ncontent, they struggle to assess risk levels and may miss lower-risk outputs.\nAccurate risk assessment allows platforms with different safety thresholds to\ntailor content filtering and rejection. In this paper, we introduce per-topic\nseverity rubrics for 11 harmful topics and build BingoGuard, an LLM-based\nmoderation system designed to predict both binary safety labels and severity\nlevels. To address the lack of annotations on levels of severity, we propose a\nscalable generate-then-filter framework that first generates responses across\ndifferent severity levels and then filters out low-quality responses. Using\nthis framework, we create BingoGuardTrain, a training dataset with 54,897\nexamples covering a variety of topics, response severity, styles, and\nBingoGuardTest, a test set with 988 examples explicitly labeled based on our\nseverity rubrics that enables fine-grained analysis on model behaviors on\ndifferent severity levels. Our BingoGuard-8B, trained on BingoGuardTrain,\nachieves the state-of-the-art performance on several moderation benchmarks,\nincluding WildGuardTest and HarmBench, as well as BingoGuardTest, outperforming\nbest public models, WildGuard, by 4.3\\%. Our analysis demonstrates that\nincorporating severity levels into training significantly enhances detection\nperformance and enables the model to effectively gauge the severity of harmful\nresponses.\n","authors":["Fan Yin","Philippe Laban","Xiangyu Peng","Yilun Zhou","Yixin Mao","Vaibhav Vats","Linnea Ross","Divyansh Agarwal","Caiming Xiong","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2503.06550v1.pdf","comment":"10 pages, 4 figures, 4 tables. ICLR 2025 poster"},{"id":"http://arxiv.org/abs/2503.06547v1","updated":"2025-03-09T10:37:05Z","published":"2025-03-09T10:37:05Z","title":"KréyoLID From Language Identification Towards Language Mining","summary":"  Automatic language identification is frequently framed as a multi-class\nclassification problem. However, when creating digital corpora for less\ncommonly written languages, it may be more appropriate to consider it a data\nmining problem. For these varieties, one knows ahead of time that the vast\nmajority of documents are of little interest. By minimizing resources spent on\nclassifying such documents, we can create corpora much faster and with better\ncoverage than using established pipelines. To demonstrate the effectiveness of\nthe language mining perspective, we introduce a new pipeline and corpora for\nseveral French-based Creoles.\n","authors":["Rasul Dent","Pedro Ortiz Suarez","Thibault Clérice","Benoît Sagot"],"pdf_url":"https://arxiv.org/pdf/2503.06547v1.pdf","comment":"8 main pages"},{"id":"http://arxiv.org/abs/2503.02078v2","updated":"2025-03-09T10:27:43Z","published":"2025-03-03T21:58:12Z","title":"Superscopes: Amplifying Internal Feature Representations for Language\n  Model Interpretation","summary":"  Understanding and interpreting the internal representations of large language\nmodels (LLMs) remains an open challenge. Patchscopes introduced a method for\nprobing internal activations by patching them into new prompts, prompting\nmodels to self-explain their hidden representations. We introduce Superscopes,\na technique that systematically amplifies superposed features in MLP outputs\n(multilayer perceptron) and hidden states before patching them into new\ncontexts. Inspired by the \"features as directions\" perspective and the\nClassifier-Free Guidance (CFG) approach from diffusion models, Superscopes\namplifies weak but meaningful features, enabling the interpretation of internal\nrepresentations that previous methods failed to explain-all without requiring\nadditional training. This approach provides new insights into how LLMs build\ncontext and represent complex concepts, further advancing mechanistic\ninterpretability.\n","authors":["Jonathan Jacobi","Gal Niv"],"pdf_url":"https://arxiv.org/pdf/2503.02078v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19038v2","updated":"2025-03-09T09:54:02Z","published":"2024-11-28T10:33:11Z","title":"DIESEL -- Dynamic Inference-Guidance via Evasion of Semantic Embeddings\n  in LLMs","summary":"  In recent years, large language models (LLMs) have had great success in tasks\nsuch as casual conversation, contributing to significant advancements in\ndomains like virtual assistance. However, they often generate responses that\nare not aligned with human values (e.g., ethical standards, safety), leading to\npotentially unsafe or inappropriate outputs. While several techniques have been\nproposed to address this problem, they come with a cost, requiring\ncomputationally expensive training or dramatically increasing the inference\ntime. In this paper, we present DIESEL, a lightweight inference-guidance\ntechnique that can be seamlessly integrated into any autoregressive LLM to\nsemantically filter undesired concepts from the response. DIESEL can function\neither as a standalone safeguard or as an additional layer of defense,\nenhancing response safety by reranking the LLM's proposed tokens based on their\nsimilarity to predefined negative concepts in the latent space. Our evaluation\ndemonstrates DIESEL's effectiveness on state-of-the-art conversational models,\neven in adversarial jailbreaking scenarios that challenge response safety. We\nalso highlight DIESEL's generalization capabilities, showing that it can be\nused in use cases other than safety, providing general-purpose response\nfiltering.\n","authors":["Ben Ganon","Alon Zolfi","Omer Hofman","Inderjeet Singh","Hisashi Kojima","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2411.19038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06534v1","updated":"2025-03-09T09:31:17Z","published":"2025-03-09T09:31:17Z","title":"SafeSpeech: A Comprehensive and Interactive Tool for Analysing Sexist\n  and Abusive Language in Conversations","summary":"  Detecting toxic language including sexism, harassment and abusive behaviour,\nremains a critical challenge, particularly in its subtle and context-dependent\nforms. Existing approaches largely focus on isolated message-level\nclassification, overlooking toxicity that emerges across conversational\ncontexts. To promote and enable future research in this direction, we introduce\nSafeSpeech, a comprehensive platform for toxic content detection and analysis\nthat bridges message-level and conversation-level insights. The platform\nintegrates fine-tuned classifiers and large language models (LLMs) to enable\nmulti-granularity detection, toxic-aware conversation summarization, and\npersona profiling. SafeSpeech also incorporates explainability mechanisms, such\nas perplexity gain analysis, to highlight the linguistic elements driving\npredictions. Evaluations on benchmark datasets, including EDOS, OffensEval, and\nHatEval, demonstrate the reproduction of state-of-the-art performance across\nmultiple tasks, including fine-grained sexism detection.\n","authors":["Xingwei Tan","Chen Lyu","Hafiz Muhammad Umer","Sahrish Khan","Mahathi Parvatham","Lois Arthurs","Simon Cullen","Shelley Wilson","Arshad Jhumka","Gabriele Pergola"],"pdf_url":"https://arxiv.org/pdf/2503.06534v1.pdf","comment":"NAACL 2025 system demonstration camera-ready"},{"id":"http://arxiv.org/abs/2503.06531v1","updated":"2025-03-09T09:27:57Z","published":"2025-03-09T09:27:57Z","title":"MetaXCR: Reinforcement-Based Meta-Transfer Learning for Cross-Lingual\n  Commonsense Reasoning","summary":"  Commonsense reasoning (CR) has been studied in many pieces of domain and has\nachieved great progress with the aid of large datasets. Unfortunately, most\nexisting CR datasets are built in English, so most previous work focus on\nEnglish. Furthermore, as the annotation of commonsense reasoning is costly, it\nis impossible to build a large dataset for every novel task. Therefore, there\nare growing appeals for Cross-lingual Low-Resource Commonsense Reasoning, which\naims to leverage diverse existed English datasets to help the model adapt to\nnew cross-lingual target datasets with limited labeled data. In this paper, we\npropose a multi-source adapter for cross-lingual low-resource Commonsense\nReasoning (MetaXCR). In this framework, we first extend meta learning by\nincorporating multiple training datasets to learn a generalized task adapters\nacross different tasks. Then, we further introduce a reinforcement-based\nsampling strategy to help the model sample the source task that is the most\nhelpful to the target task. Finally, we introduce two types of cross-lingual\nmeta-adaption methods to enhance the performance of models on target languages.\nExtensive experiments demonstrate MetaXCR is superior over state-of-the-arts,\nwhile being trained with fewer parameters than other work.\n","authors":["Jie He","Yu Fu"],"pdf_url":"https://arxiv.org/pdf/2503.06531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01403v3","updated":"2025-03-09T09:04:18Z","published":"2025-02-03T14:34:37Z","title":"AdaSVD: Adaptive Singular Value Decomposition for Large Language Models","summary":"  Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP) tasks, yet their substantial memory requirements\npresent significant challenges for deployment on resource-constrained devices.\nSingular Value Decomposition (SVD) has emerged as a promising compression\ntechnique for LLMs, offering considerable reductions in memory overhead.\nHowever, existing SVD-based methods often struggle to effectively mitigate the\nerrors introduced by SVD truncation, leading to a noticeable performance gap\nwhen compared to the original models. Furthermore, applying a uniform\ncompression ratio across all transformer layers fails to account for the\nvarying importance of different layers. To address these challenges, we propose\nAdaSVD, an adaptive SVD-based LLM compression approach. Specifically, AdaSVD\nintroduces adaComp, which adaptively compensates for SVD truncation errors by\nalternately updating the singular matrices $\\mathcal{U}$ and\n$\\mathcal{V}^\\top$. Additionally, AdaSVD introduces adaCR, which adaptively\nassigns layer-specific compression ratios based on the relative importance of\neach layer. Extensive experiments across multiple LLM/VLM families and\nevaluation metrics demonstrate that AdaSVD consistently outperforms\nstate-of-the-art (SOTA) SVD-based methods, achieving superior performance with\nsignificantly reduced memory requirements. Code and models of AdaSVD will be\navailable at https://github.com/ZHITENGLI/AdaSVD.\n","authors":["Zhiteng Li","Mingyuan Xia","Jingyuan Zhang","Zheng Hui","Linghe Kong","Yulun Zhang","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2502.01403v3.pdf","comment":"The code and models will be available at\n  https://github.com/ZHITENGLI/AdaSVD"},{"id":"http://arxiv.org/abs/2406.03199v3","updated":"2025-03-09T08:52:56Z","published":"2024-05-24T13:33:11Z","title":"Bayesian WeakS-to-Strong from Text Classification to Generation","summary":"  Advances in large language models raise the question of how alignment\ntechniques will adapt as models become increasingly complex and humans will\nonly be able to supervise them weakly. Weak-to-Strong mimics such a scenario\nwhere weak model supervision attempts to harness the full capabilities of a\nmuch stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by\nexploring an ensemble of weak models which simulate the variability in human\nopinions. Confidence scores are estimated using a Bayesian approach to guide\nthe WeakS-to-Strong generalization. Furthermore, we extend the application of\nWeakS-to-Strong from text classification tasks to text generation tasks where\nmore advanced strategies are investigated for supervision. Moreover, direct\npreference optimization is applied to advance the student model's preference\nlearning, beyond the basic learning framework of teacher forcing. Results\ndemonstrate the effectiveness of the proposed approach for the reliability of a\nstrong student model, showing potential for superalignment.\n","authors":["Ziyun Cui","Ziyang Zhang","Wen Wu","Guangzhi Sun","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.03199v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06514v1","updated":"2025-03-09T08:38:10Z","published":"2025-03-09T08:38:10Z","title":"GFlowVLM: Enhancing Multi-step Reasoning in Vision-Language Models with\n  Generative Flow Networks","summary":"  Vision-Language Models (VLMs) have recently shown promising advancements in\nsequential decision-making tasks through task-specific fine-tuning. However,\ncommon fine-tuning methods, such as Supervised Fine-Tuning (SFT) and\nReinforcement Learning (RL) techniques like Proximal Policy Optimization (PPO),\npresent notable limitations: SFT assumes Independent and Identically\nDistributed (IID) data, while PPO focuses on maximizing cumulative rewards.\nThese limitations often restrict solution diversity and hinder generalization\nin multi-step reasoning tasks. To address these challenges, we introduce a\nnovel framework, GFlowVLM, a framework that fine-tune VLMs using Generative\nFlow Networks (GFlowNets) to promote generation of diverse solutions for\ncomplex reasoning tasks. GFlowVLM models the environment as a non-Markovian\ndecision process, allowing it to capture long-term dependencies essential for\nreal-world applications. It takes observations and task descriptions as inputs\nto prompt chain-of-thought (CoT) reasoning which subsequently guides action\nselection. We use task based rewards to fine-tune VLM with GFlowNets. This\napproach enables VLMs to outperform prior fine-tuning methods, including SFT\nand RL. Empirical results demonstrate the effectiveness of GFlowVLM on complex\ntasks such as card games (NumberLine, BlackJack) and embodied planning tasks\n(ALFWorld), showing enhanced training efficiency, solution diversity, and\nstronger generalization capabilities across both in-distribution and\nout-of-distribution scenarios.\n","authors":["Haoqiang Kang","Enna Sachdeva","Piyush Gupta","Sangjae Bae","Kwonjoon Lee"],"pdf_url":"https://arxiv.org/pdf/2503.06514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06510v1","updated":"2025-03-09T08:32:38Z","published":"2025-03-09T08:32:38Z","title":"Less is More: Adaptive Program Repair with Bug Localization and\n  Preference Learning","summary":"  Automated Program Repair (APR) is a task to automatically generate patches\nfor the buggy code. However, most research focuses on generating correct\npatches while ignoring the consistency between the fixed code and the original\nbuggy code. How to conduct adaptive bug fixing and generate patches with\nminimal modifications have seldom been investigated. To bridge this gap, we\nfirst introduce a novel task, namely AdaPR (Adaptive Program Repair). We then\npropose a two-stage approach AdaPatcher (Adaptive Patch Generator) to enhance\nprogram repair while maintaining the consistency. In the first stage, we\nutilize a Bug Locator with self-debug learning to accurately pinpoint bug\nlocations. In the second stage, we train a Program Modifier to ensure\nconsistency between the post-modified fixed code and the pre-modified buggy\ncode. The Program Modifier is enhanced with a location-aware repair learning\nstrategy to generate patches based on identified buggy lines, a hybrid training\nstrategy for selective reference and an adaptive preference learning to\nprioritize fewer changes. The experimental results show that our approach\noutperforms a set of baselines by a large margin, validating the effectiveness\nof our two-stage framework for the newly proposed AdaPR task.\n","authors":["Zhenlong Dai","Bingrui Chen","Zhuoluo Zhao","Xiu Tang","Sai Wu","Chang Yao","Zhipeng Gao","Jingyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2503.06510v1.pdf","comment":"accepted by AAAI2025 Oral"},{"id":"http://arxiv.org/abs/2502.17664v2","updated":"2025-03-09T08:17:58Z","published":"2025-02-24T21:22:19Z","title":"Towards Typologically Aware Rescoring to Mitigate Unfaithfulness in\n  Lower-Resource Languages","summary":"  Multilingual large language models (LLMs) are known to more frequently\ngenerate non-faithful output in resource-constrained languages (Guerreiro et\nal., 2023 - arXiv:2303.16104), potentially because these typologically diverse\nlanguages are underrepresented in their training data. To mitigate\nunfaithfulness in such settings, we propose using computationally light\nauxiliary models to rescore the outputs of larger architectures. As proof of\nthe feasibility of such an approach, we show that monolingual 4-layer BERT\nmodels pretrained from scratch on less than 700 MB of data without fine-tuning\nare able to identify faithful summaries with a mean accuracy of 88.33% in three\ngenetically unrelated languages that differ in their morphological complexity -\nVietnamese, Polish and Georgian. The same hyperparameter combination moreover\ngeneralises well to three other tasks, suggesting applications for rescoring\nbeyond improving faithfulness. In order to inform typologically aware model\nselection, we also investigate how morphological complexity interacts with\nregularisation, model depth and training objectives, ultimately demonstrating\nthat morphologically complex languages are more likely to benefit from dropout,\nwhile across languages downstream performance is enhanced most by shallow\narchitectures as well as training using the standard BERT objectives.\n","authors":["Tsan Tsai Chan","Xin Tong","Thi Thu Uyen Hoang","Barbare Tepnadze","Wojciech Stempniak"],"pdf_url":"https://arxiv.org/pdf/2502.17664v2.pdf","comment":"ISCA/ITG Workshop on Diversity in Large Speech and Language Models"},{"id":"http://arxiv.org/abs/2501.17182v2","updated":"2025-03-09T07:37:22Z","published":"2025-01-25T11:51:31Z","title":"Dialogue Systems for Emotional Support via Value Reinforcement","summary":"  Emotional support dialogue systems aim to reduce help-seekers' distress and\nhelp them overcome challenges. While human values$\\unicode{x2013}$core beliefs\nthat shape an individual's priorities$\\unicode{x2013}$are increasingly\nemphasized in contemporary psychological therapy for their role in fostering\ninternal transformation and long-term emotional well-being, their integration\ninto emotional support systems remains underexplored. To bridge this gap, we\npresent a value-driven method for training emotional support dialogue systems\ndesigned to reinforce positive values in seekers. Notably, our model identifies\nwhich values to reinforce at each turn and how to do so, by leveraging online\nsupport conversations from Reddit. We evaluate the method across support\nskills, seekers' emotional intensity, and value reinforcement. Our method\nconsistently outperforms various baselines, effectively exploring and eliciting\nvalues from seekers. Additionally, leveraging crowd knowledge from Reddit\nsignificantly enhances its effectiveness. Therapists highlighted its ability to\nvalidate seekers' challenges and emphasize positive aspects of their\nsituations$\\unicode{x2013}$both crucial elements of value reinforcement. Our\nwork, being the first to integrate value reinforcement into emotional support\nsystems, demonstrates its promise and establishes a foundation for future\nresearch.\n","authors":["Juhee Kim","Chunghu Mok","Jisun Lee","Hyang Sook Kim","Yohan Jo"],"pdf_url":"https://arxiv.org/pdf/2501.17182v2.pdf","comment":"34 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.06492v1","updated":"2025-03-09T07:25:32Z","published":"2025-03-09T07:25:32Z","title":"VisualSimpleQA: A Benchmark for Decoupled Evaluation of Large\n  Vision-Language Models in Fact-Seeking Question Answering","summary":"  Large vision-language models (LVLMs) have demonstrated remarkable\nachievements, yet the generation of non-factual responses remains prevalent in\nfact-seeking question answering (QA). Current multimodal fact-seeking\nbenchmarks primarily focus on comparing model outputs to ground truth answers,\nproviding limited insights into the performance of modality-specific modules.\nTo bridge this gap, we introduce VisualSimpleQA, a multimodal fact-seeking\nbenchmark with two key features. First, it enables streamlined and decoupled\nevaluation of LVLMs in visual and linguistic modalities. Second, it\nincorporates well-defined difficulty criteria to guide human annotation and\nfacilitates the extraction of a challenging subset, VisualSimpleQA-hard.\nExperiments on 15 LVLMs show that even state-of-the-art models such as GPT-4o\nachieve merely 60%+ correctness in multimodal fact-seeking QA on VisualSimpleQA\nand 30%+ on VisualSimpleQA-hard. Furthermore, the decoupled evaluation across\nthese models highlights substantial opportunities for improvement in both\nvisual and linguistic modules. The dataset is available at\nhttps://huggingface.co/datasets/WYLing/VisualSimpleQA.\n","authors":["Yanling Wang","Yihan Zhao","Xiaodong Chen","Shasha Guo","Lixin Liu","Haoyang Li","Yong Xiao","Jing Zhang","Qi Li","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2503.06492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06491v1","updated":"2025-03-09T07:24:36Z","published":"2025-03-09T07:24:36Z","title":"MoFE: Mixture of Frozen Experts Architecture","summary":"  We propose the Mixture of Frozen Experts (MoFE) architecture, which\nintegrates Parameter-efficient Fine-tuning (PEFT) and the Mixture of Experts\n(MoE) architecture to enhance both training efficiency and model scalability.\nBy freezing the Feed Forward Network (FFN) layers within the MoE framework,\nMoFE significantly reduces the number of trainable parameters, improving\ntraining efficiency while still allowing for effective knowledge transfer from\nthe expert models. This facilitates the creation of models proficient in\nmultiple domains. We conduct experiments to evaluate the trade-offs between\nperformance and efficiency, compare MoFE with other PEFT methodologies, assess\nthe impact of domain expertise in the constituent models, and determine the\noptimal training strategy. The results show that, although there may be some\ntrade-offs in performance, the efficiency gains are substantial, making MoFE a\nreasonable solution for real-world, resource-constrained environments.\n","authors":["Jean Seo","Jaeyoon Kim","Hyopil Shin"],"pdf_url":"https://arxiv.org/pdf/2503.06491v1.pdf","comment":"NAACL 2025 Industry"},{"id":"http://arxiv.org/abs/2410.18955v2","updated":"2025-03-09T07:21:04Z","published":"2024-10-24T17:53:53Z","title":"BioMistral-NLU: Towards More Generalizable Medical Language\n  Understanding through Instruction Tuning","summary":"  Large language models (LLMs) such as ChatGPT are fine-tuned on large and\ndiverse instruction-following corpora, and can generalize to new tasks.\nHowever, those instruction-tuned LLMs often perform poorly in specialized\nmedical natural language understanding (NLU) tasks that require domain\nknowledge, granular text comprehension, and structured data extraction. To\nbridge the gap, we: (1) propose a unified prompting format for 7 important NLU\ntasks, (2) curate an instruction-tuning dataset, MNLU-Instruct, utilizing\ndiverse existing open-source medical NLU corpora, and (3) develop\nBioMistral-NLU, a generalizable medical NLU model, through fine-tuning\nBioMistral on MNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting,\nacross 6 important NLU tasks, from two widely adopted medical NLU benchmarks:\nBLUE and BLURB. Our experiments show that our BioMistral-NLU outperforms the\noriginal BioMistral, as well as the proprietary LLMs - ChatGPT and GPT-4. Our\ndataset-agnostic prompting strategy and instruction tuning step over diverse\nNLU tasks enhance LLMs' generalizability across diverse medical NLU tasks. Our\nablation experiments show that instruction-tuning on a wider variety of tasks,\neven when the total number of training instances remains constant, enhances\ndownstream zero-shot generalization.\n","authors":["Yujuan Velvin Fu","Giridhar Kaushik Ramachandran","Namu Park","Kevin Lybarger","Fei Xia","Ozlem Uzuner","Meliha Yetisgen"],"pdf_url":"https://arxiv.org/pdf/2410.18955v2.pdf","comment":"3 figures an 5 tables; Accepted by AMIA 2025 Informatics Summit"},{"id":"http://arxiv.org/abs/2306.17184v3","updated":"2025-03-09T06:40:39Z","published":"2023-06-20T10:41:23Z","title":"State space models can express n-gram languages","summary":"  Recent advancements in recurrent neural networks (RNNs) have reinvigorated\ninterest in their application to natural language processing tasks,\nparticularly with the development of more efficient and parallelizable variants\nknown as state space models (SSMs), which have shown competitive performance\nagainst transformer models while maintaining a lower memory footprint. While\nRNNs and SSMs (e.g., Mamba) have been empirically more successful than\nrule-based systems based on n-gram models, a rigorous theoretical explanation\nfor this success has not yet been developed, as it is unclear how these models\nencode the combinatorial rules that govern the next-word prediction task. In\nthis paper, we construct state space language models that can solve the\nnext-word prediction task for languages generated from n-gram rules, thereby\nshowing that the former are more expressive. Our proof shows how SSMs can\nencode n-gram rules using new theoretical results on their memorization\ncapacity, and demonstrates how their context window can be controlled by\nrestricting the spectrum of the state transition matrix. We conduct experiments\nwith a small dataset generated from n-gram rules to show how our framework can\nbe applied to SSMs and RNNs obtained through gradient-based optimization.\n","authors":["Vinoth Nandakumar","Qiang Qu","Peng Mi","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.17184v3.pdf","comment":"Published in \"Transactions on Machine Learning Research\", 2025"},{"id":"http://arxiv.org/abs/2503.06475v1","updated":"2025-03-09T06:25:37Z","published":"2025-03-09T06:25:37Z","title":"SKG-LLM: Developing a Mathematical Model for Stroke Knowledge Graph\n  Construction Using Large Language Models","summary":"  The purpose of this study is to introduce SKG-LLM. A knowledge graph (KG) is\nconstructed from stroke-related articles using mathematical and large language\nmodels (LLMs). SKG-LLM extracts and organizes complex relationships from the\nbiomedical literature, using it to increase the accuracy and depth of KG in\nstroke research. In the proposed method, GPT-4 was used for data\npre-processing, and the extraction of embeddings was also done by GPT-4 in the\nwhole KG construction process. The performance of the proposed model was tested\nwith two evaluation criteria: Precision and Recall. For further validation of\nthe proposed model, GPT-4 was used. Compared with Wikidata and WN18RR, the\nproposed KG-LLM approach performs better, especially in precision and recall.\nBy including GPT-4 in the preprocessing process, the SKG-LLM model achieved a\nprecision score of 0.906 and a recall score of 0.923. Expert reviews further\nimproved the results and increased precision to 0.923 and recall to 0.918. The\nknowledge graph constructed by SKG-LLM contains 2692 nodes and 5012 edges,\nwhich are 13 distinct types of nodes and 24 types of edges.\n","authors":["Ali Sarabadani","Kheirolah Rahsepar Fard","Hamid Dalvand"],"pdf_url":"https://arxiv.org/pdf/2503.06475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06474v1","updated":"2025-03-09T06:20:24Z","published":"2025-03-09T06:20:24Z","title":"HuixiangDou2: A Robustly Optimized GraphRAG Approach","summary":"  Large Language Models (LLMs) perform well on familiar queries but struggle\nwith specialized or emerging topics. Graph-based Retrieval-Augmented Generation\n(GraphRAG) addresses this by structuring domain knowledge as a graph for\ndynamic retrieval. However, existing pipelines involve complex engineering\nworkflows, making it difficult to isolate the impact of individual components.\nEvaluating retrieval effectiveness is also challenging due to dataset overlap\nwith LLM pretraining data. In this work, we introduce HuixiangDou2, a robustly\noptimized GraphRAG framework. Specifically, we leverage the effectiveness of\ndual-level retrieval and optimize its performance in a 32k context for maximum\nprecision, and compare logic-based retrieval and dual-level retrieval to\nenhance overall functionality. Our implementation includes comparative\nexperiments on a test set, where Qwen2.5-7B-Instruct initially underperformed.\nWith our approach, the score improved significantly from 60 to 74.5, as\nillustrated in the Figure. Experiments on domain-specific datasets reveal that\ndual-level retrieval enhances fuzzy matching, while logic-form retrieval\nimproves structured reasoning. Furthermore, we propose a multi-stage\nverification mechanism to improve retrieval robustness without increasing\ncomputational cost. Empirical results show significant accuracy gains over\nbaselines, highlighting the importance of adaptive retrieval. To support\nresearch and adoption, we release HuixiangDou2 as an open-source resource\nhttps://github.com/tpoisonooo/huixiangdou2.\n","authors":["Huanjun Kong","Zhefan Wang","Chenyang Wang","Zhe Ma","Nanqing Dong"],"pdf_url":"https://arxiv.org/pdf/2503.06474v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2503.06470v1","updated":"2025-03-09T06:14:17Z","published":"2025-03-09T06:14:17Z","title":"Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow\n  Systems","summary":"  Humans can flexibly switch between different modes of thinking based on task\ncomplexity: from rapid intuitive judgments to in-depth analytical\nunderstanding. However, current Graphical User Interface (GUI) grounding\nsystems which locate interface elements based on natural language instructions\nrely solely on immediate prediction without reasoning, struggling to understand\ncomplex interface layouts with nested structures and hierarchical\nrelationships, limiting their effectiveness on complex interfaces. Inspired by\nhuman dual-system cognition, we present Focus, a novel GUI grounding framework\nthat combines fast prediction with systematic analysis. The framework\ndynamically switches between rapid and deliberate processing through an\nadaptive system switching based on task complexity, optimizing both efficiency\nand accuracy. Focus decomposes grounding into progressive stages: interface\nsummarization, visual focused analysis, and precise coordinate prediction. This\nstructured decomposition enables systematic understanding of both interface\nlayouts and visual relationships. Extensive experiments show that Focus\nachieves state-of-the-art performance using only 300K of the training data with\na 2B parameter model compared to existing approaches. Focus demonstrates\nsuperior performance particularly in complex GUI scenarios, achieving 77.4%\naverage accuracy on ScreenSpot and 13.3% on the more challenging\nScreenSpot-Pro. Our analysis reveals the effectiveness of this dual-system\napproach while demonstrating its potential for improving complex GUI\ninteraction scenarios.\n","authors":["Fei Tang","Yongliang Shen","Hang Zhang","Siqi Chen","Guiyang Hou","Wenqi Zhang","Wenqiao Zhang","Kaitao Song","Weiming Lu","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15594v5","updated":"2025-03-09T05:21:22Z","published":"2024-11-23T16:03:35Z","title":"A Survey on LLM-as-a-Judge","summary":"  Accurate and consistent evaluation is crucial for decision-making across\nnumerous fields, yet it remains a challenging task due to inherent\nsubjectivity, variability, and scale. Large Language Models (LLMs) have\nachieved remarkable success across diverse domains, leading to the emergence of\n\"LLM-as-a-Judge,\" where LLMs are employed as evaluators for complex tasks. With\ntheir ability to process diverse data types and provide scalable,\ncost-effective, and consistent assessments, LLMs present a compelling\nalternative to traditional expert-driven evaluations. However, ensuring the\nreliability of LLM-as-a-Judge systems remains a significant challenge that\nrequires careful design and standardization. This paper provides a\ncomprehensive survey of LLM-as-a-Judge, addressing the core question: How can\nreliable LLM-as-a-Judge systems be built? We explore strategies to enhance\nreliability, including improving consistency, mitigating biases, and adapting\nto diverse assessment scenarios. Additionally, we propose methodologies for\nevaluating the reliability of LLM-as-a-Judge systems, supported by a novel\nbenchmark designed for this purpose. To advance the development and real-world\ndeployment of LLM-as-a-Judge systems, we also discussed practical applications,\nchallenges, and future directions. This survey serves as a foundational\nreference for researchers and practitioners in this rapidly evolving field.\n","authors":["Jiawei Gu","Xuhui Jiang","Zhichao Shi","Hexiang Tan","Xuehao Zhai","Chengjin Xu","Wei Li","Yinghan Shen","Shengjie Ma","Honghao Liu","Saizhuo Wang","Kun Zhang","Yuanzhuo Wang","Wen Gao","Lionel Ni","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2411.15594v5.pdf","comment":"Project Page: https://awesome-llm-as-a-judge.github.io/"},{"id":"http://arxiv.org/abs/2410.10855v3","updated":"2025-03-09T04:39:42Z","published":"2024-10-06T20:13:11Z","title":"Core Knowledge Deficits in Multi-Modal Language Models","summary":"  While Multimodal Large Language Models (MLLMs) demonstrate impressive\nabilities over high level perception and reasoning, their robustness in the\nwild still lags behind humans and exhibits diminished efficacy on simple tasks\nthat are intuitive for humans. We examine the hypothesis that these\ndeficiencies stem from the absence of core knowledge, rudimentary cognitive\nabilities innate to humans from early childhood. To probe core knowledge\nrepresentation in MLLMs, we draw from developmental cognitive sciences and\ndevelop a large-scale benchmark, CoreCognition dataset, encompassing 12 core\ncognitive concepts. We evaluate 219 models with 10 different prompts, leading\nto a total of 2409 data points for analysis. Our findings reveal core knowledge\ndeficits in early developed core abilities while models demonstrate human\ncomparable performance in high level cognition. Moreover, we find that low\nlevel abilities show little to no scaling, in stark contrast to high level\nabilities. Finally, we introduce an evaluation technique, Concept Hacking,\nthrough which we demonstrate that MLLMs do not genuinely advance toward core\nknowledge but instead rely on illusory understanding and shortcut learning as\nthey scale. Website with this\n$\\href{https://growing-ai-like-a-child.github.io/}{link}$.\n","authors":["Yijiang Li","Qingying Gao","Tianwei Zhao","Bingyang Wang","Haoran Sun","Haiyun Lyu","Dezhi Luo","Hokin Deng"],"pdf_url":"https://arxiv.org/pdf/2410.10855v3.pdf","comment":"Website with this\n  $\\href{https://growing-ai-like-a-child.github.io/}{link}$"},{"id":"http://arxiv.org/abs/2410.20215v2","updated":"2025-03-09T04:20:07Z","published":"2024-10-26T16:17:02Z","title":"DAWN-ICL: Strategic Planning of Problem-solving Trajectories for\n  Zero-Shot In-Context Learning","summary":"  Zero-shot in-context learning (ZS-ICL) aims to conduct in-context learning\n(ICL) without using human-annotated demonstrations. Most ZS-ICL methods use\nlarge language models (LLMs) to generate (input, label) pairs as\npseudo-demonstrations and leverage historical pseudo-demonstrations to help\nsolve the current problem. They assume that problems are from the same task and\ntraverse them in a random order. However, in real-world scenarios, problems\nusually come from diverse tasks, and only a few belong to the same task. The\nrandom traversing order may generate unreliable pseudo-demonstrations and lead\nto error accumulation. To address this problem, we reformulate ZS-ICL as a\nplanning problem and propose a Demonstration-aware Monte Carlo Tree Search\n(MCTS) approach (DAWN-ICL), which leverages MCTS to strategically plan the\nproblem-solving trajectories for ZS-ICL. In addition, to achieve effective and\nefficient Q value estimation, we propose a novel demonstration-aware Q-value\nfunction and use it to enhance the selection phase and accelerate the expansion\nand simulation phases in MCTS. Extensive experiments demonstrate the\neffectiveness and efficiency of DAWN-ICL on in-domain and cross-domain\nscenarios, and it even outperforms ICL using human-annotated labels. The code\nis available at https://github.com/RUCAIBox/MCTS4ZSICL.\n","authors":["Xinyu Tang","Xiaolei Wang","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2410.20215v2.pdf","comment":"NAACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2502.18778v2","updated":"2025-03-09T04:11:38Z","published":"2025-02-26T03:21:12Z","title":"M2-omni: Advancing Omni-MLLM for Comprehensive Modality Support with\n  Competitive Performance","summary":"  We present M2-omni, a cutting-edge, open-source omni-MLLM that achieves\ncompetitive performance to GPT-4o. M2-omni employs a unified multimodal\nsequence modeling framework, which empowers Large Language Models(LLMs) to\nacquire comprehensive cross-modal understanding and generation capabilities.\nSpecifically, M2-omni can process arbitrary combinations of audio, video,\nimage, and text modalities as input, generating multimodal sequences\ninterleaving with audio, image, or text outputs, thereby enabling an advanced\nand interactive real-time experience. The training of such an omni-MLLM is\nchallenged by significant disparities in data quantity and convergence rates\nacross modalities. To address these challenges, we propose a step balance\nstrategy during pre-training to handle the quantity disparities in\nmodality-specific data. Additionally, a dynamically adaptive balance strategy\nis introduced during the instruction tuning stage to synchronize the\nmodality-wise training progress, ensuring optimal convergence. Notably, we\nprioritize preserving strong performance on pure text tasks to maintain the\nrobustness of M2-omni's language understanding capability throughout the\ntraining process. To our best knowledge, M2-omni is currently a very\ncompetitive open-source model to GPT-4o, characterized by its comprehensive\nmodality and task support, as well as its exceptional performance. We expect\nM2-omni will advance the development of omni-MLLMs, thus facilitating future\nresearch in this domain.\n","authors":["Qingpei Guo","Kaiyou Song","Zipeng Feng","Ziping Ma","Qinglong Zhang","Sirui Gao","Xuzheng Yu","Yunxiao Sun","Tai-Wei Chang","Jingdong Chen","Ming Yang","Jun Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.18778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06430v1","updated":"2025-03-09T03:56:22Z","published":"2025-03-09T03:56:22Z","title":"Graph Retrieval-Augmented LLM for Conversational Recommendation Systems","summary":"  Conversational Recommender Systems (CRSs) have emerged as a transformative\nparadigm for offering personalized recommendations through natural language\ndialogue. However, they face challenges with knowledge sparsity, as users often\nprovide brief, incomplete preference statements. While recent methods have\nintegrated external knowledge sources to mitigate this, they still struggle\nwith semantic understanding and complex preference reasoning. Recent Large\nLanguage Models (LLMs) demonstrate promising capabilities in natural language\nunderstanding and reasoning, showing significant potential for CRSs.\nNevertheless, due to the lack of domain knowledge, existing LLM-based CRSs\neither produce hallucinated recommendations or demand expensive domain-specific\ntraining, which largely limits their applicability. In this work, we present\nG-CRS (Graph Retrieval-Augmented Large Language Model for Conversational\nRecommender Systems), a novel training-free framework that combines graph\nretrieval-augmented generation and in-context learning to enhance LLMs'\nrecommendation capabilities. Specifically, G-CRS employs a two-stage\nretrieve-and-recommend architecture, where a GNN-based graph reasoner first\nidentifies candidate items, followed by Personalized PageRank exploration to\njointly discover potential items and similar user interactions. These retrieved\ncontexts are then transformed into structured prompts for LLM reasoning,\nenabling contextually grounded recommendations without task-specific training.\nExtensive experiments on two public datasets show that G-CRS achieves superior\nrecommendation performance compared to existing methods without requiring\ntask-specific training.\n","authors":["Zhangchi Qiu","Linhao Luo","Zicheng Zhao","Shirui Pan","Alan Wee-Chung Liew"],"pdf_url":"https://arxiv.org/pdf/2503.06430v1.pdf","comment":"Accepted by PAKDD 2025"},{"id":"http://arxiv.org/abs/2503.06424v1","updated":"2025-03-09T03:38:55Z","published":"2025-03-09T03:38:55Z","title":"Training LLM-based Tutors to Improve Student Learning Outcomes in\n  Dialogues","summary":"  Generative artificial intelligence (AI) has the potential to scale up\npersonalized tutoring through large language models (LLMs). Recent AI tutors\nare adapted for the tutoring task by training or prompting LLMs to follow\neffective pedagogical principles, though they are not trained to maximize\nstudent learning throughout the course of a dialogue. Therefore, they may\nengage with students in a suboptimal way. We address this limitation by\nintroducing an approach to train LLMs to generate tutor utterances that\nmaximize the likelihood of student correctness, while still encouraging the\nmodel to follow good pedagogical practice. Specifically, we generate a set of\ncandidate tutor utterances and score them using (1) an LLM-based student model\nto predict the chance of correct student responses and (2) a pedagogical rubric\nevaluated by GPT-4o. We then use the resulting data to train an open-source\nLLM, Llama 3.1 8B, using direct preference optimization. We show that tutor\nutterances generated by our model lead to significantly higher chances of\ncorrect student responses while maintaining the pedagogical quality of GPT-4o.\nWe also conduct qualitative analyses and a human evaluation to demonstrate that\nour model generates high quality tutor utterances.\n","authors":["Alexander Scarlatos","Naiming Liu","Jaewook Lee","Richard Baraniuk","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2503.06424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18966v2","updated":"2025-03-09T02:46:31Z","published":"2024-10-24T17:58:22Z","title":"Does Data Contamination Detection Work (Well) for LLMs? A Survey and\n  Evaluation on Detection Assumptions","summary":"  Large language models (LLMs) have demonstrated great performance across\nvarious benchmarks, showing potential as general-purpose task solvers. However,\nas LLMs are typically trained on vast amounts of data, a significant concern in\ntheir evaluation is data contamination, where overlap between training data and\nevaluation datasets inflates performance assessments. Multiple approaches have\nbeen developed to identify data contamination. These approaches rely on\nspecific assumptions that may not hold universally across different settings.\nTo bridge this gap, we systematically review 50 papers on data contamination\ndetection, categorize the underlying assumptions, and assess whether they have\nbeen rigorously validated. We identify and analyze eight categories of\nassumptions and test three of them as case studies. Our case studies focus on\ndetecting direct, instance-level data contamination, which is also referred to\nas Membership Inference Attacks (MIA). Our analysis reveals that MIA approaches\nbased on these three assumptions can have similar performance to random\nguessing, on datasets used in LLM pretraining, suggesting that current LLMs\nmight learn data distributions rather than memorizing individual instances.\nMeanwhile, MIA can easily fail when there are data distribution shifts between\nthe seen and unseen instances.\n","authors":["Yujuan Fu","Ozlem Uzuner","Meliha Yetisgen","Fei Xia"],"pdf_url":"https://arxiv.org/pdf/2410.18966v2.pdf","comment":"3 tables and 1 figures in the main text. This paper is accepted by\n  NAACL 2025 findings"},{"id":"http://arxiv.org/abs/2503.06394v1","updated":"2025-03-09T02:13:44Z","published":"2025-03-09T02:13:44Z","title":"How LLMs Learn: Tracing Internal Representations with Sparse\n  Autoencoders","summary":"  Large Language Models (LLMs) demonstrate remarkable multilingual capabilities\nand broad knowledge. However, the internal mechanisms underlying the\ndevelopment of these capabilities remain poorly understood. To investigate\nthis, we analyze how the information encoded in LLMs' internal representations\nevolves during the training process. Specifically, we train sparse autoencoders\nat multiple checkpoints of the model and systematically compare the\ninterpretative results across these stages. Our findings suggest that LLMs\ninitially acquire language-specific knowledge independently, followed by\ncross-linguistic correspondences. Moreover, we observe that after mastering\ntoken-level knowledge, the model transitions to learning higher-level, abstract\nconcepts, indicating the development of more conceptual understanding.\n","authors":["Tatsuro Inaba","Kentaro Inui","Yusuke Miyao","Yohei Oseki","Benjamin Heinzerling","Yu Takagi"],"pdf_url":"https://arxiv.org/pdf/2503.06394v1.pdf","comment":"Our code, demo, SAE weights are available at:\n  https://github.com/llm-jp/llm-jp-sae"},{"id":"http://arxiv.org/abs/2503.06380v1","updated":"2025-03-09T01:34:28Z","published":"2025-03-09T01:34:28Z","title":"TI-JEPA: An Innovative Energy-based Joint Embedding Strategy for\n  Text-Image Multimodal Systems","summary":"  This paper focuses on multimodal alignment within the realm of Artificial\nIntelligence, particularly in text and image modalities. The semantic gap\nbetween the textual and visual modality poses a discrepancy problem towards the\neffectiveness of multi-modalities fusion. Therefore, we introduce Text-Image\nJoint Embedding Predictive Architecture (TI-JEPA), an innovative pre-training\nstrategy that leverages energy-based model (EBM) framework to capture complex\ncross-modal relationships. TI-JEPA combines the flexibility of EBM in\nself-supervised learning to facilitate the compatibility between textual and\nvisual elements. Through extensive experiments across multiple benchmarks, we\ndemonstrate that TI-JEPA achieves state-of-the-art performance on multimodal\nsentiment analysis task (and potentially on a wide range of multimodal-based\ntasks, such as Visual Question Answering), outperforming existing pre-training\nmethodologies. Our findings highlight the potential of using energy-based\nframework in advancing multimodal fusion and suggest significant improvements\nfor downstream applications.\n","authors":["Khang H. N. Vo","Duc P. T. Nguyen","Thong Nguyen","Tho T. Quan"],"pdf_url":"https://arxiv.org/pdf/2503.06380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06378v1","updated":"2025-03-09T01:13:56Z","published":"2025-03-09T01:13:56Z","title":"General Scales Unlock AI Evaluation with Explanatory and Predictive\n  Power","summary":"  Ensuring safe and effective use of AI requires understanding and anticipating\nits performance on novel tasks, from advanced scientific challenges to\ntransformed workplace activities. So far, benchmarking has guided progress in\nAI, but it has offered limited explanatory and predictive power for\ngeneral-purpose AI systems, given the low transferability across diverse tasks.\nIn this paper, we introduce general scales for AI evaluation that can explain\nwhat common AI benchmarks really measure, extract ability profiles of AI\nsystems, and predict their performance for new task instances, in- and\nout-of-distribution. Our fully-automated methodology builds on 18 newly-crafted\nrubrics that place instance demands on general scales that do not saturate.\nIllustrated for 15 large language models and 63 tasks, high explanatory power\nis unleashed from inspecting the demand and ability profiles, bringing insights\non the sensitivity and specificity exhibited by different benchmarks, and how\nknowledge, metacognition and reasoning are affected by model size,\nchain-of-thought and distillation. Surprisingly, high predictive power at the\ninstance level becomes possible using these demand levels, providing superior\nestimates over black-box baseline predictors based on embeddings or finetuning,\nespecially in out-of-distribution settings (new tasks and new benchmarks). The\nscales, rubrics, battery, techniques and results presented here represent a\nmajor step for AI evaluation, underpinning the reliable deployment of AI in the\nyears ahead.\n","authors":["Lexin Zhou","Lorenzo Pacchiardi","Fernando Martínez-Plumed","Katherine M. Collins","Yael Moros-Daval","Seraphina Zhang","Qinlin Zhao","Yitian Huang","Luning Sun","Jonathan E. Prunty","Zongqian Li","Pablo Sánchez-García","Kexin Jiang Chen","Pablo A. M. Casares","Jiyun Zu","John Burden","Behzad Mehrbakhsh","David Stillwell","Manuel Cebrian","Jindong Wang","Peter Henderson","Sherry Tongshuang Wu","Patrick C. Kyllonen","Lucy Cheke","Xing Xie","José Hernández-Orallo"],"pdf_url":"https://arxiv.org/pdf/2503.06378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15027v2","updated":"2025-03-09T01:07:59Z","published":"2025-02-20T20:27:06Z","title":"InterFeedback: Unveiling Interactive Intelligence of Large Multimodal\n  Models via Human Feedback","summary":"  Existing benchmarks do not test Large Multimodal Models (LMMs) on their\ninteractive intelligence with human users, which is vital for developing\ngeneral-purpose AI assistants. We design InterFeedback, an interactive\nframework, which can be applied to any LMM and dataset to assess this ability\nautonomously. On top of this, we introduce InterFeedback-Bench which evaluates\ninteractive intelligence using two representative datasets, MMMU-Pro and\nMathVerse, to test 10 different open-source LMMs. Additionally, we present\nInterFeedback-Human, a newly collected dataset of 120 cases designed for\nmanually testing interactive performance in leading models such as OpenAI-o1\nand Claude-3.5-Sonnet. Our evaluation results indicate that even the\nstate-of-the-art LMM, OpenAI-o1, struggles to refine its responses based on\nhuman feedback, achieving an average score of less than 50%. Our findings point\nto the need for methods that can enhance LMMs' capabilities to interpret and\nbenefit from feedback.\n","authors":["Henry Hengyuan Zhao","Wenqi Pei","Yifei Tao","Haiyang Mei","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2502.15027v2.pdf","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.06680v1","updated":"2025-03-09T16:11:57Z","published":"2025-03-09T16:11:57Z","title":"FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation\n  for Feature Implementation","summary":"  Implementing new features in repository-level codebases is a crucial\napplication of code generation models. However, current benchmarks lack a\ndedicated evaluation framework for this capability. To fill this gap, we\nintroduce FEA-Bench, a benchmark designed to assess the ability of large\nlanguage models (LLMs) to perform incremental development within code\nrepositories. We collect pull requests from 83 GitHub repositories and use\nrule-based and intent-based filtering to construct task instances focused on\nnew feature development. Each task instance containing code changes is paired\nwith relevant unit test files to ensure that the solution can be verified. The\nfeature implementation requires LLMs to simultaneously possess code completion\ncapabilities for new components and code editing abilities for other relevant\nparts in the code repository, providing a more comprehensive evaluation method\nof LLMs' automated software engineering capabilities. Experimental results show\nthat LLMs perform significantly worse in the FEA-Bench, highlighting\nconsiderable challenges in such repository-level incremental code development.\n","authors":["Wei Li","Xin Zhang","Zhongxin Guo","Shaoguang Mao","Wen Luo","Guangyue Peng","Yangyu Huang","Houfeng Wang","Scarlett Li"],"pdf_url":"https://arxiv.org/pdf/2503.06680v1.pdf","comment":null}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2503.06808v1","updated":"2025-03-09T23:32:15Z","published":"2025-03-09T23:32:15Z","title":"Privacy Auditing of Large Language Models","summary":"  Current techniques for privacy auditing of large language models (LLMs) have\nlimited efficacy -- they rely on basic approaches to generate canaries which\nleads to weak membership inference attacks that in turn give loose lower bounds\non the empirical privacy leakage. We develop canaries that are far more\neffective than those used in prior work under threat models that cover a range\nof realistic settings. We demonstrate through extensive experiments on multiple\nfamilies of fine-tuned LLMs that our approach sets a new standard for detection\nof privacy leakage. For measuring the memorization rate of non-privately\ntrained LLMs, our designed canaries surpass prior approaches. For example, on\nthe Qwen2.5-0.5B model, our designed canaries achieve $49.6\\%$ TPR at $1\\%$\nFPR, vastly surpassing the prior approach's $4.2\\%$ TPR at $1\\%$ FPR. Our\nmethod can be used to provide a privacy audit of $\\varepsilon \\approx 1$ for a\nmodel trained with theoretical $\\varepsilon$ of 4. To the best of our\nknowledge, this is the first time that a privacy audit of LLM training has\nachieved nontrivial auditing success in the setting where the attacker cannot\ntrain shadow models, insert gradient canaries, or access the model at every\niteration.\n","authors":["Ashwinee Panda","Xinyu Tang","Milad Nasr","Christopher A. Choquette-Choo","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2503.06808v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.06803v1","updated":"2025-03-09T23:09:04Z","published":"2025-03-09T23:09:04Z","title":"Actionable AI: Enabling Non Experts to Understand and Configure AI\n  Systems","summary":"  Interaction between humans and AI systems raises the question of how people\nunderstand AI systems. This has been addressed with explainable AI, the\ninterpretability arising from users' domain expertise, or collaborating with AI\nin a stable environment. In the absence of these elements, we discuss designing\nActionable AI, which allows non-experts to configure black-box agents. In this\npaper, we experiment with an AI-powered cartpole game and observe 22 pairs of\nparticipants to configure it via direct manipulation. Our findings suggest\nthat, in uncertain conditions, non-experts were able to achieve good levels of\nperformance. By influencing the behaviour of the agent, they exhibited an\noperational understanding of it, which proved sufficient to reach their goals.\nBased on this, we derive implications for designing Actionable AI systems. In\nconclusion, we propose Actionable AI as a way to open access to AI-based\nagents, giving end users the agency to influence such agents towards their own\ngoals.\n","authors":["Cécile Boulard","Sruthi Viswanathan","Wanda Fey","Thierry Jacquin"],"pdf_url":"https://arxiv.org/pdf/2503.06803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15681v2","updated":"2025-03-09T22:53:27Z","published":"2025-02-21T18:59:20Z","title":"One-step Diffusion Models with $f$-Divergence Distribution Matching","summary":"  Sampling from diffusion models involves a slow iterative process that hinders\ntheir practical deployment, especially for interactive applications. To\naccelerate generation speed, recent approaches distill a multi-step diffusion\nmodel into a single-step student generator via variational score distillation,\nwhich matches the distribution of samples generated by the student to the\nteacher's distribution. However, these approaches use the reverse\nKullback-Leibler (KL) divergence for distribution matching which is known to be\nmode seeking. In this paper, we generalize the distribution matching approach\nusing a novel $f$-divergence minimization framework, termed $f$-distill, that\ncovers different divergences with different trade-offs in terms of mode\ncoverage and training variance. We derive the gradient of the $f$-divergence\nbetween the teacher and student distributions and show that it is expressed as\nthe product of their score differences and a weighting function determined by\ntheir density ratio. This weighting function naturally emphasizes samples with\nhigher density in the teacher distribution, when using a less mode-seeking\ndivergence. We observe that the popular variational score distillation approach\nusing the reverse-KL divergence is a special case within our framework.\nEmpirically, we demonstrate that alternative $f$-divergences, such as\nforward-KL and Jensen-Shannon divergences, outperform the current best\nvariational score distillation methods across image generation tasks. In\nparticular, when using Jensen-Shannon divergence, $f$-distill achieves current\nstate-of-the-art one-step generation performance on ImageNet64 and zero-shot\ntext-to-image generation on MS-COCO. Project page:\nhttps://research.nvidia.com/labs/genair/f-distill\n","authors":["Yilun Xu","Weili Nie","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2502.15681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06798v1","updated":"2025-03-09T22:36:58Z","published":"2025-03-09T22:36:58Z","title":"Characterizing Learning in Spiking Neural Networks with Astrocyte-Like\n  Units","summary":"  Traditional artificial neural networks take inspiration from biological\nnetworks, using layers of neuron-like nodes to pass information for processing.\nMore realistic models include spiking in the neural network, capturing the\nelectrical characteristics more closely. However, a large proportion of brain\ncells are of the glial cell type, in particular astrocytes which have been\nsuggested to play a role in performing computations. Here, we introduce a\nmodified spiking neural network model with added astrocyte-like units in a\nneural network and asses their impact on learning. We implement the network as\na liquid state machine and task the network with performing a chaotic\ntime-series prediction task. We varied the number and ratio of neuron-like and\nastrocyte-like units in the network to examine the latter units effect on\nlearning. We show that the combination of neurons and astrocytes together, as\nopposed to neural- and astrocyte-only networks, are critical for driving\nlearning. Interestingly, we found that the highest learning rate was achieved\nwhen the ratio between astrocyte-like and neuron-like units was roughly 2 to 1,\nmirroring some estimates of the ratio of biological astrocytes to neurons. Our\nresults demonstrate that incorporating astrocyte-like units which represent\ninformation across longer timescales can alter the learning rates of neural\nnetworks, and the proportion of astrocytes to neurons should be tuned\nappropriately to a given task.\n","authors":["Christopher S. Yang","Sylvester J. Gates III","Dulara De Zoysa","Jaehoon Choe","Wolfgang Losert","Corey B. Hart"],"pdf_url":"https://arxiv.org/pdf/2503.06798v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.06797v1","updated":"2025-03-09T22:32:37Z","published":"2025-03-09T22:32:37Z","title":"Multimodal AI-driven Biomarker for Early Detection of Cancer Cachexia","summary":"  Cancer cachexia is a multifactorial syndrome characterized by progressive\nmuscle wasting, metabolic dysfunction, and systemic inflammation, leading to\nreduced quality of life and increased mortality. Despite extensive research, no\nsingle definitive biomarker exists, as cachexia-related indicators such as\nserum biomarkers, skeletal muscle measurements, and metabolic abnormalities\noften overlap with other conditions. Existing composite indices, including the\nCancer Cachexia Index (CXI), Modified CXI (mCXI), and Cachexia Score (CASCO),\nintegrate multiple biomarkers but lack standardized thresholds, limiting their\nclinical utility. This study proposes a multimodal AI-based biomarker for early\ncancer cachexia detection, leveraging open-source large language models (LLMs)\nand foundation models trained on medical data. The approach integrates\nheterogeneous patient data, including demographics, disease status, lab\nreports, radiological imaging (CT scans), and clinical notes, using a machine\nlearning framework that can handle missing data. Unlike previous AI-based\nmodels trained on curated datasets, this method utilizes routinely collected\nclinical data, enhancing real-world applicability. Additionally, the model\nincorporates confidence estimation, allowing the identification of cases\nrequiring expert review for precise clinical interpretation. Preliminary\nfindings demonstrate that integrating multiple data modalities improves\ncachexia prediction accuracy at the time of cancer diagnosis. The AI-based\nbiomarker dynamically adapts to patient-specific factors such as age, race,\nethnicity, weight, cancer type, and stage, avoiding the limitations of\nfixed-threshold biomarkers. This multimodal AI biomarker provides a scalable\nand clinically viable solution for early cancer cachexia detection,\nfacilitating personalized interventions and potentially improving treatment\noutcomes and patient survival.\n","authors":["Sabeen Ahmed","Nathan Parker","Margaret Park","Evan W. Davis","Jennifer B. Permuth","Matthew B. Schabath","Yasin Yilmaz","Ghulam Rasool"],"pdf_url":"https://arxiv.org/pdf/2503.06797v1.pdf","comment":"17 pages, 6 figures, 3 Tables"},{"id":"http://arxiv.org/abs/2503.06791v1","updated":"2025-03-09T22:07:46Z","published":"2025-03-09T22:07:46Z","title":"AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in\n  the Misty Social Robot","summary":"  The social robot's open API allows users to customize open-domain\ninteractions. However, it remains inaccessible to those without programming\nexperience. In this work, we introduce AutoMisty, the first multi-agent\ncollaboration framework powered by large language models (LLMs), to enable the\nseamless generation of executable Misty robot code from natural language\ninstructions. AutoMisty incorporates four specialized agent modules to manage\ntask decomposition, assignment, problem-solving, and result synthesis. Each\nagent incorporates a two-layer optimization mechanism, with self-reflection for\niterative refinement and human-in-the-loop for better alignment with user\npreferences. AutoMisty ensures a transparent reasoning process, allowing users\nto iteratively refine tasks through natural language feedback for precise\nexecution. To evaluate AutoMisty's effectiveness, we designed a benchmark task\nset spanning four levels of complexity and conducted experiments in a real\nMisty robot environment. Extensive evaluations demonstrate that AutoMisty not\nonly consistently generates high-quality code but also enables precise code\ncontrol, significantly outperforming direct reasoning with ChatGPT-4o and\nChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly\nreleased through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html\n","authors":["Xiao Wang","Lu Dong","Sahana Rangasrinivasan","Ifeoma Nwogu","Srirangaraj Setlur","Venugopal Govindaraju"],"pdf_url":"https://arxiv.org/pdf/2503.06791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06790v1","updated":"2025-03-09T22:02:18Z","published":"2025-03-09T22:02:18Z","title":"GenDR: Lightning Generative Detail Restorator","summary":"  Recent research applying text-to-image (T2I) diffusion models to real-world\nsuper-resolution (SR) has achieved remarkable success. However, fundamental\nmisalignments between T2I and SR targets result in a dilemma between inference\nspeed and detail fidelity. Specifically, T2I tasks prioritize multi-step\ninversion to synthesize coherent outputs aligned with textual prompts and\nshrink the latent space to reduce generating complexity. Contrariwise, SR tasks\npreserve most information from low-resolution input while solely restoring\nhigh-frequency details, thus necessitating sufficient latent space and fewer\ninference steps. To bridge the gap, we present a one-step diffusion model for\ngenerative detail restoration, GenDR, distilled from a tailored diffusion model\nwith larger latent space. In detail, we train a new SD2.1-VAE16 (0.9B) via\nrepresentation alignment to expand latent space without enlarging the model\nsize. Regarding step-distillation, we propose consistent score identity\ndistillation (CiD) that incorporates SR task-specific loss into score\ndistillation to leverage more SR priors and align the training target.\nFurthermore, we extend CiD with adversarial learning and representation\nalignment (CiDA) to enhance perceptual quality and accelerate training. We also\npolish the pipeline to achieve a more efficient inference. Experimental results\ndemonstrate that GenDR achieves state-of-the-art performance in both\nquantitative metrics and visual fidelity.\n","authors":["Yan Wang","Shijie Zhao","Kai Chen","Kexin Zhang","Junlin Li","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22619v2","updated":"2025-03-09T22:00:46Z","published":"2024-10-30T00:47:32Z","title":"Efficient Feature Extraction and Classification Architecture for\n  MRI-Based Brain Tumor Detection and Localization","summary":"  Uncontrolled cell division in the brain is what gives rise to brain tumors.\nIf the tumor size increases by more than half, there is little hope for the\npatient's recovery. This emphasizes the need of rapid and precise brain tumor\ndiagnosis. When it comes to analyzing, diagnosing, and planning therapy for\nbrain tumors, MRI imaging plays a crucial role. A brain tumor's development\nhistory is crucial information for doctors to have. When it comes to\ndistinguishing between human soft tissues, MRI scans are superior. In order to\nget reliable classification results from MRI scans quickly, deep learning is\none of the most practical methods. Early human illness diagnosis has been\ndemonstrated to be more accurate when deep learning methods are used. In the\ncase of diagnosing a brain tumor, when even a little misdiagnosis might have\nserious consequences, accuracy is especially important. Disclosure of brain\ntumors in medical images is still a difficult task. Brain MRIs are notoriously\nimprecise in revealing the presence or absence of tumors. Using MRI scans of\nthe brain, a CNN was trained to identify the presence of a tumor in this\nresearch. Results from the CNN model showed an accuracy of 99.17%. The CNN\nmodel's characteristics were also retrieved. The CNN model's characteristics\nwere also retrieved and we also localized the tumor regions from the\nunannotated images using GradCAM, a deep learning explainability tool. In order\nto evaluate the CNN model's capability for processing images, we applied the\nfeatures into different ML models. CNN and machine learning models were also\nevaluated using the standard metrics of Precision, Recall, Specificity, and F1\nscore. The significance of the doctor's diagnosis enhanced the accuracy of the\nCNN model's assistance in identifying the existence of tumor and treating the\npatient.\n","authors":["Plabon Paul","Md. Nazmul Islam","Fazle Rafsani","Pegah Khorasani","Shovito Barua Soumma"],"pdf_url":"https://arxiv.org/pdf/2410.22619v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06788v1","updated":"2025-03-09T21:59:43Z","published":"2025-03-09T21:59:43Z","title":"Dubito Ergo Sum: Exploring AI Ethics","summary":"  We paraphrase Descartes' famous dictum in the area of AI ethics where the \"I\ndoubt and therefore I am\" is suggested as a necessary aspect of morality.\nTherefore AI, which cannot doubt itself, cannot possess moral agency. Of\ncourse, this is not the end of the story. We explore various aspects of the\nhuman mind that substantially differ from AI, which includes the sensory\ngrounding of our knowing, the act of understanding, and the significance of\nbeing able to doubt ourselves. The foundation of our argument is the discipline\nof ethics, one of the oldest and largest knowledge projects of human history,\nyet, we seem only to be beginning to get a grasp of it. After a couple of\nthousand years of studying the ethics of humans, we (humans) arrived at a point\nwhere moral psychology suggests that our moral decisions are intuitive, and all\nthe models from ethics become relevant only when we explain ourselves. This\nrecognition has a major impact on what and how we can do regarding AI ethics.\nWe do not offer a solution, we explore some ideas and leave the problem open,\nbut we hope somewhat better understood than before our study.\n","authors":["Viktor Dorfler","Giles Cuthbert"],"pdf_url":"https://arxiv.org/pdf/2503.06788v1.pdf","comment":"10 pages, 1 figure, HICSS 57: Hawaii International Conference on\n  System Sciences, Honolulu, HI, published January 2024"},{"id":"http://arxiv.org/abs/2405.17631v3","updated":"2025-03-09T21:57:20Z","published":"2024-05-27T19:57:17Z","title":"BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation\n  Experiments","summary":"  Agents based on large language models have shown great potential in\naccelerating scientific discovery by leveraging their rich background knowledge\nand reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an\nagent that designs new experiments, reasons about their outcomes, and\nefficiently navigates the hypothesis space to reach desired solutions. We\ndemonstrate our agent on the problem of designing genetic perturbation\nexperiments, where the aim is to find a small subset out of many possible genes\nthat, when perturbed, result in a specific phenotype (e.g., cell growth).\nUtilizing its biological knowledge, BioDiscoveryAgent can uniquely design new\nexperiments without the need to train a machine learning model or explicitly\ndesign an acquisition function as in Bayesian optimization. Moreover,\nBioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21%\nimprovement in predicting relevant genetic perturbations across six datasets,\nand a 46% improvement in the harder task of non-essential gene perturbation,\ncompared to existing Bayesian optimization baselines specifically trained for\nthis task. Our evaluation includes one dataset that is unpublished, ensuring it\nis not part of the language model's training data. Additionally,\nBioDiscoveryAgent predicts gene combinations to perturb more than twice as\naccurately as a random baseline, a task so far not explored in the context of\nclosed-loop experiment design. The agent also has access to tools for searching\nthe biomedical literature, executing code to analyze biological datasets, and\nprompting another agent to critically evaluate its predictions. Overall,\nBioDiscoveryAgent is interpretable at every stage, representing an accessible\nnew paradigm in the computational design of biological experiments with the\npotential to augment scientists' efficacy.\n","authors":["Yusuf Roohani","Andrew Lee","Qian Huang","Jian Vora","Zachary Steinhart","Kexin Huang","Alexander Marson","Percy Liang","Jure Leskovec"],"pdf_url":"https://arxiv.org/pdf/2405.17631v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06784v1","updated":"2025-03-09T21:43:37Z","published":"2025-03-09T21:43:37Z","title":"Infinite Leagues Under the Sea: Photorealistic 3D Underwater Terrain\n  Generation by Latent Fractal Diffusion Models","summary":"  This paper tackles the problem of generating representations of underwater 3D\nterrain. Off-the-shelf generative models, trained on Internet-scale data but\nnot on specialized underwater images, exhibit downgraded realism, as images of\nthe seafloor are relatively uncommon. To this end, we introduce DreamSea, a\ngenerative model to generate hyper-realistic underwater scenes. DreamSea is\ntrained on real-world image databases collected from underwater robot surveys.\nImages from these surveys contain massive real seafloor observations and\ncovering large areas, but are prone to noise and artifacts from the real world.\nWe extract 3D geometry and semantics from the data with visual foundation\nmodels, and train a diffusion model that generates realistic seafloor images in\nRGBD channels, conditioned on novel fractal distribution-based latent\nembeddings. We then fuse the generated images into a 3D map, building a 3DGS\nmodel supervised by 2D diffusion priors which allows photorealistic novel view\nrendering. DreamSea is rigorously evaluated, demonstrating the ability to\nrobustly generate large-scale underwater scenes that are consistent, diverse,\nand photorealistic. Our work drives impact in multiple domains, spanning\nfilming, gaming, and robot simulation.\n","authors":["Tianyi Zhang","Weiming Zhi","Joshua Mangelson","Matthew Johnson-Roberson"],"pdf_url":"https://arxiv.org/pdf/2503.06784v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.06781v1","updated":"2025-03-09T21:23:52Z","published":"2025-03-09T21:23:52Z","title":"Dr Genre: Reinforcement Learning from Decoupled LLM Feedback for Generic\n  Text Rewriting","summary":"  Generic text rewriting is a prevalent large language model (LLM) application\nthat covers diverse real-world tasks, such as style transfer, fact correction,\nand email editing. These tasks vary in rewriting objectives (e.g., factual\nconsistency vs. semantic preservation), making it challenging to develop a\nunified model that excels across all dimensions. Existing methods often\nspecialize in either a single task or a specific objective, limiting their\ngeneralizability. In this work, we introduce a generic model proficient in\nfactuality, stylistic, and conversational rewriting tasks. To simulate\nreal-world user rewrite requests, we construct a conversational rewrite\ndataset, ChatRewrite, that presents ``natural''-sounding instructions, from raw\nemails using LLMs. Combined with other popular rewrite datasets, including\nLongFact for the factuality rewrite task and RewriteLM for the stylistic\nrewrite task, this forms a broad benchmark for training and evaluating generic\nrewrite models. To align with task-specific objectives, we propose Dr Genre, a\nDecoupled-reward learning framework for Generic rewriting, that utilizes\nobjective-oriented reward models with a task-specific weighting. Evaluation\nshows that \\approach delivers higher-quality rewrites across all targeted\ntasks, improving objectives including instruction following (agreement),\ninternal consistency (coherence), and minimal unnecessary edits (conciseness).\n","authors":["Yufei Li","John Nham","Ganesh Jawahar","Lei Shu","David Uthus","Yun-Hsuan Sung","Chengrun Yang","Itai Rolnick","Yi Qiao","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2503.06781v1.pdf","comment":"29 pages, 4 figures, 25 tables"},{"id":"http://arxiv.org/abs/2503.06778v1","updated":"2025-03-09T21:14:14Z","published":"2025-03-09T21:14:14Z","title":"Large Language Models Are Effective Human Annotation Assistants, But Not\n  Good Independent Annotators","summary":"  Event annotation is important for identifying market changes, monitoring\nbreaking news, and understanding sociological trends. Although expert\nannotators set the gold standards, human coding is expensive and inefficient.\nUnlike information extraction experiments that focus on single contexts, we\nevaluate a holistic workflow that removes irrelevant documents, merges\ndocuments about the same event, and annotates the events. Although LLM-based\nautomated annotations are better than traditional TF-IDF-based methods or Event\nSet Curation, they are still not reliable annotators compared to human experts.\nHowever, adding LLMs to assist experts for Event Set Curation can reduce the\ntime and mental effort required for Variable Annotation. When using LLMs to\nextract event variables to assist expert annotators, they agree more with the\nextracted variables than fully automated LLMs for annotation.\n","authors":["Feng Gu","Zongxia Li","Carlos Rafael Colon","Benjamin Evans","Ishani Mondal","Jordan Lee Boyd-Graber"],"pdf_url":"https://arxiv.org/pdf/2503.06778v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.05612v3","updated":"2025-03-09T21:00:14Z","published":"2024-06-09T02:01:25Z","title":"Which Backbone to Use: A Resource-efficient Domain Specific Comparison\n  for Computer Vision","summary":"  In contemporary computer vision applications, particularly image\nclassification, architectural backbones pre-trained on large datasets like\nImageNet are commonly employed as feature extractors. Despite the widespread\nuse of these pre-trained convolutional neural networks (CNNs), there remains a\ngap in understanding the performance of various resource-efficient backbones\nacross diverse domains and dataset sizes. Our study systematically evaluates\nmultiple lightweight, pre-trained CNN backbones under consistent training\nsettings across a variety of datasets, including natural images, medical\nimages, galaxy images, and remote sensing images. This comprehensive analysis\naims to aid machine learning practitioners in selecting the most suitable\nbackbone for their specific problem, especially in scenarios involving small\ndatasets where fine-tuning a pre-trained network is crucial. Even though\nattention-based architectures are gaining popularity, we observed that they\ntend to perform poorly under low data finetuning tasks compared to CNNs. We\nalso observed that some CNN architectures such as ConvNeXt, RegNet and\nEfficientNet performs well compared to others on a diverse set of domains\nconsistently. Our findings provide actionable insights into the performance\ntrade-offs and effectiveness of different backbones, facilitating informed\ndecision-making in model selection for a broad spectrum of computer vision\ndomains. Our code is available here: https://github.com/pranavphoenix/Backbones\n","authors":["Pranav Jeevan","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2406.05612v3.pdf","comment":"12 pages, 2 figures, accepted in TMLR"},{"id":"http://arxiv.org/abs/2503.06765v1","updated":"2025-03-09T20:42:38Z","published":"2025-03-09T20:42:38Z","title":"Effectiveness of Zero-shot-CoT in Japanese Prompts","summary":"  We compare the effectiveness of zero-shot Chain-of-Thought (CoT) prompting in\nJapanese and English using ChatGPT-3.5 and 4o-mini. The technique of zero-shot\nCoT, which involves appending a phrase such as \"Let's think step by step\" to a\nprompt to encourage reasoning before answering, has been shown to offer LLM\nperformance improvements in mathematical and reasoning tasks, particularly in\nEnglish. We investigate how these effects transfer to Japanese using the\nJapanese Multi-task Language Understanding Benchmark (JMMLU) and the Multi-task\nLanguage Understanding Benchmark (MMLU). Our results show that while zero-shot\nCoT prompting can lead to notable performance gains for some prompt categories\nin GPT-3.5, its impact in GPT-4o-mini is associated with significant\nperformance declines. However, for Japanese prompts there remain certain\ncategories, such as college mathematics and abstract algebra, that still\nexhibit improvements, despite the broader trend of diminishing effectiveness in\nmore advanced models.\n","authors":["Shusuke Takayama","Ian Frank"],"pdf_url":"https://arxiv.org/pdf/2503.06765v1.pdf","comment":"NLP2025 Workshop on Japanese Language Resources (JLR2025)"},{"id":"http://arxiv.org/abs/2503.06764v1","updated":"2025-03-09T20:42:34Z","published":"2025-03-09T20:42:34Z","title":"SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical\n  Codebook for Multimodal Understanding and Generation","summary":"  We present SemHiTok, a unified image Tokenizer via Semantic-Guided\nHierarchical codebook that provides consistent discrete feature representations\nfor multimodal understanding and generation tasks. Recently, unified multimodal\nlarge models (MLLMs) for understanding and generation have sparked exploration\nwithin research community. Previous works attempt to train a unified image\ntokenizer by combining loss functions for semantic feature reconstruction and\npixel reconstruction. However, due to the differing levels of features\nprioritized by multimodal understanding and generation tasks, joint training\nmethods face significant challenges in achieving a good trade-off. SemHiTok\naddresses this challenge through Semantic-Guided Hierarchical codebook which\nbuilds texture sub-codebooks on pre-trained semantic codebook. This design\ndecouples the training of semantic reconstruction and pixel reconstruction and\nequips the tokenizer with low-level texture feature extraction capability\nwithout degradation of high-level semantic feature extraction ability. Our\nexperiments demonstrate that SemHiTok achieves state-of-the-art rFID score at\n256X256resolution compared to other unified tokenizers, and exhibits\ncompetitive performance on multimodal understanding and generation tasks.\n","authors":["Zisheng Chen","Chunwei Wang","Xiuwei Chen","Hang Xu","Jianhua Han","Xiandan Liang"],"pdf_url":"https://arxiv.org/pdf/2503.06764v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.06749v1","updated":"2025-03-09T20:06:45Z","published":"2025-03-09T20:06:45Z","title":"Vision-R1: Incentivizing Reasoning Capability in Multimodal Large\n  Language Models","summary":"  DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .\n","authors":["Wenxuan Huang","Bohan Jia","Zijie Zhai","Shaosheng Cao","Zheyu Ye","Fei Zhao","Yao Hu","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06747v1","updated":"2025-03-09T20:05:32Z","published":"2025-03-09T20:05:32Z","title":"Fully-Decentralized MADDPG with Networked Agents","summary":"  In this paper, we devise three actor-critic algorithms with decentralized\ntraining for multi-agent reinforcement learning in cooperative, adversarial,\nand mixed settings with continuous action spaces. To this goal, we adapt the\nMADDPG algorithm by applying a networked communication approach between agents.\nWe introduce surrogate policies in order to decentralize the training while\nallowing for local communication during training. The decentralized algorithms\nachieve comparable results to the original MADDPG in empirical tests, while\nreducing computational cost. This is more pronounced with larger numbers of\nagents.\n","authors":["Diego Bolliger","Lorenz Zauter","Robert Ziegler"],"pdf_url":"https://arxiv.org/pdf/2503.06747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06745v1","updated":"2025-03-09T20:02:04Z","published":"2025-03-09T20:02:04Z","title":"Beyond Black-Box Benchmarking: Observability, Analytics, and\n  Optimization of Agentic Systems","summary":"  The rise of agentic AI systems, where agents collaborate to perform diverse\ntasks, poses new challenges with observing, analyzing and optimizing their\nbehavior. Traditional evaluation and benchmarking approaches struggle to handle\nthe non-deterministic, context-sensitive, and dynamic nature of these systems.\nThis paper explores key challenges and opportunities in analyzing and\noptimizing agentic systems across development, testing, and maintenance. We\nexplore critical issues such as natural language variability and unpredictable\nexecution flows, which hinder predictability and control, demanding adaptive\nstrategies to manage input variability and evolving behaviors. Through our user\nstudy, we supported these hypotheses. In particular, we showed a 79% agreement\nthat non deterministic flow of agentic systems acts as a major challenge.\nFinally, we validated our statements empirically advocating the need for moving\nbeyond classical benchmarking. To bridge these gaps, we introduce taxonomies to\npresent expected analytics outcomes and the ways to collect them by extending\nstandard observability frameworks. Building on these foundations, we introduce\nand demonstrate novel approach for benchmarking of agent evaluation systems.\nUnlike traditional \"black box\" performance evaluation approaches, our benchmark\nis built from agent runtime logs as input, and analytics outcome including\ndiscovered flows and issues. By addressing key limitations in existing\nmethodologies, we aim to set the stage for more advanced and holistic\nevaluation strategies, which could foster the development of adaptive,\ninterpretable, and robust agentic AI systems.\n","authors":["Dany Moshkovich","Hadar Mulian","Sergey Zeltyn","Natti Eder","Inna Skarbovsky","Roy Abitbol"],"pdf_url":"https://arxiv.org/pdf/2503.06745v1.pdf","comment":"14 pages, 19 figures"},{"id":"http://arxiv.org/abs/2502.07972v3","updated":"2025-03-09T19:39:00Z","published":"2025-02-11T21:36:31Z","title":"Training Sparse Mixture Of Experts Text Embedding Models","summary":"  Transformer-based text embedding models have improved their performance on\nbenchmarks like MIRACL and BEIR by increasing their parameter counts. However,\nthis scaling approach introduces significant deployment challenges, including\nincreased inference latency and memory usage. These challenges are particularly\nsevere in retrieval-augmented generation (RAG) applications, where large\nmodels' increased memory requirements constrain dataset ingestion capacity, and\ntheir higher latency directly impacts query-time performance. While causal\nlanguage models have addressed similar efficiency challenges using Mixture of\nExperts (MoE) architectures, this approach hasn't been successfully adapted to\nthe general text embedding setting. In this paper, we introduce Nomic Embed v2,\nthe first general purpose MoE text embedding model. Our model outperforms\nmodels in the same parameter class on both monolingual and multilingual\nbenchmarks while also maintaining competitive performance with models twice its\nsize. We open-source all code, models, and evaluation data to ensure full\nreproducibility of our training pipeline at\n\\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.\n","authors":["Zach Nussbaum","Brandon Duderstadt"],"pdf_url":"https://arxiv.org/pdf/2502.07972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16633v3","updated":"2025-03-09T19:37:46Z","published":"2023-09-28T17:38:59Z","title":"SupReMix: Supervised Contrastive Learning for Medical Imaging Regression\n  with Mixup","summary":"  In medical image analysis, regression plays a critical role in computer-aided\ndiagnosis. It enables quantitative measurements such as age prediction from\nstructural imaging, cardiac function quantification, and molecular measurement\nfrom PET scans. While deep learning has shown promise for these tasks, most\napproaches focus solely on optimizing regression loss or model architecture,\nneglecting the quality of learned feature representations which are crucial for\nrobust clinical predictions. Directly applying representation learning\ntechniques designed for classification to regression often results in\nfragmented representations in the latent space, yielding sub-optimal\nperformance. In this paper, we argue that the potential of contrastive learning\nfor medical image regression has been overshadowed due to the neglect of two\ncrucial aspects: ordinality-awareness and hardness. To address these\nchallenges, we propose Supervised Contrastive Learning for Medical Imaging\nRegression with Mixup (SupReMix). It takes anchor-inclusive mixtures (mixup of\nthe anchor and a distinct negative sample) as hard negative pairs and\nanchor-exclusive mixtures (mixup of two distinct negative samples) as hard\npositive pairs at the embedding level. This strategy formulates harder\ncontrastive pairs by integrating richer ordinal information. Through\ntheoretical analysis and extensive experiments on six datasets spanning MRI,\nX-ray, ultrasound, and PET modalities, we demonstrate that SupReMix fosters\ncontinuous ordered representations, significantly improving regression\nperformance.\n","authors":["Yilei Wu","Zijian Dong","Chongyao Chen","Wangchunshu Zhou","Juan Helen Zhou"],"pdf_url":"https://arxiv.org/pdf/2309.16633v3.pdf","comment":"The first two authors equally contributed to this work"},{"id":"http://arxiv.org/abs/2503.06734v1","updated":"2025-03-09T19:17:46Z","published":"2025-03-09T19:17:46Z","title":"Gender Encoding Patterns in Pretrained Language Model Representations","summary":"  Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models.\n","authors":["Mahdi Zakizadeh","Mohammad Taher Pilehvar"],"pdf_url":"https://arxiv.org/pdf/2503.06734v1.pdf","comment":"Proceedings of the 5th Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025)"},{"id":"http://arxiv.org/abs/2503.06729v1","updated":"2025-03-09T19:00:36Z","published":"2025-03-09T19:00:36Z","title":"ACAI for SBOs: AI Co-creation for Advertising and Inspiration for Small\n  Business Owners","summary":"  Small business owners (SBOs) often lack the resources and design experience\nneeded to produce high-quality advertisements. To address this, we developed\nACAI (AI Co-Creation for Advertising and Inspiration), an GenAI-powered\nmultimodal advertisement creation tool, and conducted a user study with 16 SBOs\nin London to explore their perceptions of and interactions with ACAI in\nadvertisement creation. Our findings reveal that structured inputs enhance user\nagency and control while improving AI outputs by facilitating better brand\nalignment, enhancing AI transparency, and offering scaffolding that assists\nnovice designers, such as SBOs, in formulating prompts. We also found that\nACAI's multimodal interface bridges the design skill gap for SBOs with a clear\nadvertisement vision, but who lack the design jargon necessary for effective\nprompting. Building on our findings, we propose three capabilities: contextual\nintelligence, adaptive interactions, and data management, with corresponding\ndesign recommendations to advance the co-creative attributes of AI-mediated\ndesign tools.\n","authors":["Nimisha Karnatak","Adrien Baranes","Rob Marchant","Triona Butler","Kristen Olson"],"pdf_url":"https://arxiv.org/pdf/2503.06729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06725v1","updated":"2025-03-09T18:51:14Z","published":"2025-03-09T18:51:14Z","title":"Pull-Based Query Scheduling for Goal-Oriented Semantic Communication","summary":"  This paper addresses query scheduling for goal-oriented semantic\ncommunication in pull-based status update systems. We consider a system where\nmultiple sensing agents (SAs) observe a source characterized by various\nattributes and provide updates to multiple actuation agents (AAs), which act\nupon the received information to fulfill their heterogeneous goals at the\nendpoint. A hub serves as an intermediary, querying the SAs for updates on\nobserved attributes and maintaining a knowledge base, which is then broadcast\nto the AAs. The AAs leverage the knowledge to perform their actions\neffectively. To quantify the semantic value of updates, we introduce a grade of\neffectiveness (GoE) metric. Furthermore, we integrate cumulative perspective\ntheory (CPT) into the long-term effectiveness analysis to account for risk\nawareness and loss aversion in the system. Leveraging this framework, we\ncompute effect-aware scheduling policies aimed at maximizing the expected\ndiscounted sum of CPT-based total GoE provided by the transmitted updates while\ncomplying with a given query cost constraint. To achieve this, we propose a\nmodel-based solution based on dynamic programming and model-free solutions\nemploying state-of-the-art deep reinforcement learning (DRL) algorithms. Our\nfindings demonstrate that effect-aware scheduling significantly enhances the\neffectiveness of communicated updates compared to benchmark scheduling methods,\nparticularly in settings with stringent cost constraints where optimal query\nscheduling is vital for system performance and overall effectiveness.\n","authors":["Pouya Agheli","Nikolaos Pappas","Marios Kountouris"],"pdf_url":"https://arxiv.org/pdf/2503.06725v1.pdf","comment":"Submitted for possible publication"},{"id":"http://arxiv.org/abs/2411.10171v2","updated":"2025-03-09T18:06:08Z","published":"2024-11-15T13:17:54Z","title":"Imagine-2-Drive: Leveraging High-Fidelity World Models via Multi-Modal\n  Diffusion Policies","summary":"  World Model-based Reinforcement Learning (WMRL) enables sample efficient\npolicy learning by reducing the need for online interactions which can\npotentially be costly and unsafe, especially for autonomous driving. However,\nexisting world models often suffer from low prediction fidelity and compounding\none-step errors, leading to policy degradation over long horizons.\nAdditionally, traditional RL policies, often deterministic or single\nGaussian-based, fail to capture the multi-modal nature of decision-making in\ncomplex driving scenarios. To address these challenges, we propose\nImagine-2-Drive, a novel WMRL framework that integrates a high-fidelity world\nmodel with a multi-modal diffusion-based policy actor. It consists of two key\ncomponents: DiffDreamer, a diffusion-based world model that generates future\nobservations simultaneously, mitigating error accumulation, and DPA (Diffusion\nPolicy Actor), a diffusion-based policy that models diverse and multi-modal\ntrajectory distributions. By training DPA within DiffDreamer, our method\nenables robust policy learning with minimal online interactions. We evaluate\nour method in CARLA using standard driving benchmarks and demonstrate that it\noutperforms prior world model baselines, improving Route Completion and Success\nRate by 15% and 20% respectively.\n","authors":["Anant Garg","K Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.10171v2.pdf","comment":"Submitted to IROS 2025"},{"id":"http://arxiv.org/abs/2503.04715v2","updated":"2025-03-09T17:59:40Z","published":"2025-03-06T18:58:29Z","title":"Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large\n  Language Model Pretraining","summary":"  The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.09% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/\n","authors":["Houyi Li","Wenzheng Zheng","Jingcheng Hu","Qiufeng Wang","Hanshan Zhang","Zili Wang","Shijie Xuyang","Yuantao Fan","Shuigeng Zhou","Xiangyu Zhang","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.04715v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2503.06709v1","updated":"2025-03-09T17:59:16Z","published":"2025-03-09T17:59:16Z","title":"Delusions of Large Language Models","summary":"  Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.\n","authors":["Hongshen Xu","Zixv yang","Zichen Zhu","Kunyao Lan","Zihan Wang","Mengyue Wu","Ziwei Ji","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.06709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04500v2","updated":"2025-03-09T17:47:41Z","published":"2025-03-06T14:49:28Z","title":"ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem","summary":"  Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Traditional optical\nflow estimation methods rely on restrictive assumptions like brightness\nconstancy and slow motion constraints. Recent deep learning-based flow\nestimations require extensive training on large domain-specific datasets,\nmaking them computationally demanding. Also, artificial intelligence (AI)\nadvances have enabled deep learning models to take advantage of optical flow as\nan important feature for object tracking and motion analysis. Since optical\nflow is commonly encoded in HSV for visualization, its conversion to RGB for\nneural network processing is nonlinear and may introduce perceptual\ndistortions. These transformations amplify the sensitivity to estimation\nerrors, potentially affecting the predictive accuracy of the networks. To\naddress these challenges that are influential to the performance of downstream\nnetwork models, we propose Reynolds flow, a novel training-free flow estimation\ninspired by the Reynolds transport theorem, offering a principled approach to\nmodeling complex motion dynamics. In addition to conventional HSV-based\nvisualization of Reynolds flow, we also introduce an RGB-encoded representation\nof Reynolds flow designed to improve flow visualization and feature enhancement\nfor neural networks. We evaluated the effectiveness of Reynolds flow in\nvideo-based tasks. Experimental results on three benchmarks, tiny object\ndetection on UAVDB, infrared object detection on Anti-UAV, and pose estimation\non GolfDB, demonstrate that networks trained with RGB-encoded Reynolds flow\nachieve SOTA performance, exhibiting improved robustness and efficiency across\nall tasks.\n","authors":["Yu-Hsi Chen","Chin-Tien Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04500v2.pdf","comment":"10 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.06706v1","updated":"2025-03-09T17:43:30Z","published":"2025-03-09T17:43:30Z","title":"PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on\n  UML Flowcharts","summary":"  Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.\n","authors":["Ming Zhang","Yuhui Wang","Yujiong Shen","Tingyi Yang","Changhao Jiang","Yilong Wu","Shihan Dou","Qinhao Chen","Zhiheng Xi","Zhihao Zhang","Yi Dong","Zhen Wang","Zhihui Fei","Mingyang Wan","Tao Liang","Guojun Ma","Qi Zhang","Tao Gui","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.06706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07090v2","updated":"2025-03-09T17:40:18Z","published":"2025-02-10T22:30:35Z","title":"Generative Distribution Prediction: A Unified Approach to Multimodal\n  Learning","summary":"  Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains.\n","authors":["Xinyu Tian","Xiaotong Shen"],"pdf_url":"https://arxiv.org/pdf/2502.07090v2.pdf","comment":"31 pages 4 figures"},{"id":"http://arxiv.org/abs/2503.06692v1","updated":"2025-03-09T16:59:14Z","published":"2025-03-09T16:59:14Z","title":"InftyThink: Breaking the Length Limits of Long-Context Reasoning in\n  Large Language Models","summary":"  Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.\n","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12509v3","updated":"2025-03-09T16:53:11Z","published":"2025-02-18T03:47:53Z","title":"LegalCore: A Dataset for Event Coreference Resolution in Legal Documents","summary":"  Recognizing events and their coreferential mentions in a document is\nessential for understanding semantic meanings of text. The existing research on\nevent coreference resolution is mostly limited to news articles. In this paper,\nwe present the first dataset for the legal domain, LegalCore, which has been\nannotated with comprehensive event and event coreference information. The legal\ncontract documents we annotated in this dataset are several times longer than\nnews articles, with an average length of around 25k tokens per document. The\nannotations show that legal documents have dense event mentions and feature\nboth short-distance and super long-distance coreference links between event\nmentions. We further benchmark mainstream Large Language Models (LLMs) on this\ndataset for both event detection and event coreference resolution tasks, and\nfind that this dataset poses significant challenges for state-of-the-art\nopen-source and proprietary LLMs, which perform significantly worse than a\nsupervised baseline. We will publish the dataset as well as the code.\n","authors":["Kangda Wei","Xi Shi","Jonathan Tong","Sai Ramana Reddy","Anandhavelu Natarajan","Rajiv Jain","Aparna Garimella","Ruihong Huang"],"pdf_url":"https://arxiv.org/pdf/2502.12509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06690v1","updated":"2025-03-09T16:53:09Z","published":"2025-03-09T16:53:09Z","title":"Censoring-Aware Tree-Based Reinforcement Learning for Estimating Dynamic\n  Treatment Regimes with Censored Outcomes","summary":"  Dynamic Treatment Regimes (DTRs) provide a systematic approach for making\nsequential treatment decisions that adapt to individual patient\ncharacteristics, particularly in clinical contexts where survival outcomes are\nof interest. Censoring-Aware Tree-Based Reinforcement Learning (CA-TRL) is a\nnovel framework to address the complexities associated with censored data when\nestimating optimal DTRs. We explore ways to learn effective DTRs, from\nobservational data. By enhancing traditional tree-based reinforcement learning\nmethods with augmented inverse probability weighting (AIPW) and censoring-aware\nmodifications, CA-TRL delivers robust and interpretable treatment strategies.\nWe demonstrate its effectiveness through extensive simulations and real-world\napplications using the SANAD epilepsy dataset, where it outperformed the\nrecently proposed ASCL method in key metrics such as restricted mean survival\ntime (RMST) and decision-making accuracy. This work represents a step forward\nin advancing personalized and data-driven treatment strategies across diverse\nhealthcare settings.\n","authors":["Animesh Kumar Paul","Russell Greiner"],"pdf_url":"https://arxiv.org/pdf/2503.06690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06687v1","updated":"2025-03-09T16:43:07Z","published":"2025-03-09T16:43:07Z","title":"UniGenX: Unified Generation of Sequence and Structure with\n  Autoregressive Diffusion","summary":"  Unified generation of sequence and structure for scientific data (e.g.,\nmaterials, molecules, proteins) is a critical task. Existing approaches\nprimarily rely on either autoregressive sequence models or diffusion models,\neach offering distinct advantages and facing notable limitations.\nAutoregressive models, such as GPT, Llama, and Phi-4, have demonstrated\nremarkable success in natural language generation and have been extended to\nmultimodal tasks (e.g., image, video, and audio) using advanced encoders like\nVQ-VAE to represent complex modalities as discrete sequences. However, their\ndirect application to scientific domains is challenging due to the high\nprecision requirements and the diverse nature of scientific data. On the other\nhand, diffusion models excel at generating high-dimensional scientific data,\nsuch as protein, molecule, and material structures, with remarkable accuracy.\nYet, their inability to effectively model sequences limits their potential as\ngeneral-purpose multimodal foundation models. To address these challenges, we\npropose UniGenX, a unified framework that combines autoregressive next-token\nprediction with conditional diffusion models. This integration leverages the\nstrengths of autoregressive models to ease the training of conditional\ndiffusion models, while diffusion-based generative heads enhance the precision\nof autoregressive predictions. We validate the effectiveness of UniGenX on\nmaterial and small molecule generation tasks, achieving a significant leap in\nstate-of-the-art performance for material crystal structure prediction and\nestablishing new state-of-the-art results for small molecule structure\nprediction, de novo design, and conditional generation. Notably, UniGenX\ndemonstrates significant improvements, especially in handling long sequences\nfor complex structures, showcasing its efficacy as a versatile tool for\nscientific data generation.\n","authors":["Gongbo Zhang","Yanting Li","Renqian Luo","Pipi Hu","Zeru Zhao","Lingbo Li","Guoqing Liu","Zun Wang","Ran Bi","Kaiyuan Gao","Liya Guo","Yu Xie","Chang Liu","Jia Zhang","Tian Xie","Robert Pinsler","Claudio Zeni","Ziheng Lu","Yingce Xia","Marwin Segler","Maik Riechert","Li Yuan","Lei Chen","Haiguang Liu","Tao Qin"],"pdf_url":"https://arxiv.org/pdf/2503.06687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04626v2","updated":"2025-03-09T16:31:31Z","published":"2025-03-06T17:12:46Z","title":"IDInit: A Universal and Stable Initialization Method for Neural Network\n  Training","summary":"  Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.\n","authors":["Yu Pan","Chaozheng Wang","Zekai Wu","Qifan Wang","Min Zhang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2503.04626v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.02155v3","updated":"2025-03-09T15:36:53Z","published":"2024-10-03T02:34:31Z","title":"From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities","summary":"  Multimodal Large Language Models have made significant strides in integrating\nvisual and textual information, yet they often struggle with effectively\naligning these modalities. We introduce a novel image tokenizer that bridges\nthis gap by applying the principle of Byte-Pair Encoding (BPE) to visual data.\nUnlike conventional approaches that rely on separate visual encoders, our\nmethod directly incorporates structural prior information into image tokens,\nmirroring the successful tokenization strategies used in text-only Large\nLanguage Models. This innovative approach enables Transformer models to more\neffectively learn and reason across modalities. Through theoretical analysis\nand extensive experiments, we demonstrate that our BPE Image Tokenizer\nsignificantly enhances MLLMs' multimodal understanding capabilities, even with\nlimited training data. Leveraging this method, we develop Being-VL-0, a model\nthat demonstrates superior performance across various benchmarks and shows\npromising scalability, potentially paving the way for more efficient and\ncapable multimodal foundation models.\n","authors":["Wanpeng Zhang","Zilong Xie","Yicheng Feng","Yijiang Li","Xingrun Xing","Sipeng Zheng","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2410.02155v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06664v1","updated":"2025-03-09T15:29:46Z","published":"2025-03-09T15:29:46Z","title":"Exploring LLM Agents for Cleaning Tabular Machine Learning Datasets","summary":"  High-quality, error-free datasets are a key ingredient in building reliable,\naccurate, and unbiased machine learning (ML) models. However, real world\ndatasets often suffer from errors due to sensor malfunctions, data entry\nmistakes, or improper data integration across multiple sources that can\nseverely degrade model performance. Detecting and correcting these issues\ntypically require tailor-made solutions and demand extensive domain expertise.\nConsequently, automation is challenging, rendering the process labor-intensive\nand tedious. In this study, we investigate whether Large Language Models (LLMs)\ncan help alleviate the burden of manual data cleaning. We set up an experiment\nin which an LLM, paired with Python, is tasked with cleaning the training\ndataset to improve the performance of a learning algorithm without having the\nability to modify the training pipeline or perform any feature engineering. We\nrun this experiment on multiple Kaggle datasets that have been intentionally\ncorrupted with errors. Our results show that LLMs can identify and correct\nerroneous entries, such as illogical values or outlier, by leveraging\ncontextual information from other features within the same row, as well as\nfeedback from previous iterations. However, they struggle to detect more\ncomplex errors that require understanding data distribution across multiple\nrows, such as trends and biases.\n","authors":["Tommaso Bendinelli","Artur Dox","Christian Holz"],"pdf_url":"https://arxiv.org/pdf/2503.06664v1.pdf","comment":"14 pages, 1 main figure, 3 plots, Published at ICLR 2025 Workshop on\n  Foundation Models in the Wild"},{"id":"http://arxiv.org/abs/2503.06661v1","updated":"2025-03-09T15:22:52Z","published":"2025-03-09T15:22:52Z","title":"AA-CLIP: Enhancing Zero-shot Anomaly Detection via Anomaly-Aware CLIP","summary":"  Anomaly detection (AD) identifies outliers for applications like defect and\nlesion detection. While CLIP shows promise for zero-shot AD tasks due to its\nstrong generalization capabilities, its inherent Anomaly-Unawareness leads to\nlimited discrimination between normal and abnormal features. To address this\nproblem, we propose Anomaly-Aware CLIP (AA-CLIP), which enhances CLIP's anomaly\ndiscrimination ability in both text and visual spaces while preserving its\ngeneralization capability. AA-CLIP is achieved through a straightforward yet\neffective two-stage approach: it first creates anomaly-aware text anchors to\ndifferentiate normal and abnormal semantics clearly, then aligns patch-level\nvisual features with these anchors for precise anomaly localization. This\ntwo-stage strategy, with the help of residual adapters, gradually adapts CLIP\nin a controlled manner, achieving effective AD while maintaining CLIP's class\nknowledge. Extensive experiments validate AA-CLIP as a resource-efficient\nsolution for zero-shot AD tasks, achieving state-of-the-art results in\nindustrial and medical applications. The code is available at\nhttps://github.com/Mwxinnn/AA-CLIP.\n","authors":["Wenxin Ma","Xu Zhang","Qingsong Yao","Fenghe Tang","Chenxu Wu","Yingtai Li","Rui Yan","Zihang Jiang","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.06661v1.pdf","comment":"8 pages, 7 figures"}]},"2025-03-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.23252v3","updated":"2025-03-08T23:37:49Z","published":"2024-10-30T17:35:44Z","title":"Evaluating Cultural and Social Awareness of LLM Web Agents","summary":"  As large language models (LLMs) expand into performing as agents for\nreal-world applications beyond traditional NLP tasks, evaluating their\nrobustness becomes increasingly important. However, existing benchmarks often\noverlook critical dimensions like cultural and social awareness. To address\nthese, we introduce CASA, a benchmark designed to assess LLM agents'\nsensitivity to cultural and social norms across two web-based tasks: online\nshopping and social discussion forums. Our approach evaluates LLM agents'\nability to detect and appropriately respond to norm-violating user queries and\nobservations. Furthermore, we propose a comprehensive evaluation framework that\nmeasures awareness coverage, helpfulness in managing user queries, and the\nviolation rate when facing misleading web content. Experiments show that\ncurrent LLMs perform significantly better in non-agent than in web-based agent\nenvironments, with agents achieving less than 10% awareness coverage and over\n40% violation rates. To improve performance, we explore two methods: prompting\nand fine-tuning, and find that combining both methods can offer complementary\nadvantages -- fine-tuning on culture-specific datasets significantly enhances\nthe agents' ability to generalize across different regions, while prompting\nboosts the agents' ability to navigate complex tasks. These findings highlight\nthe importance of constantly benchmarking LLM agents' cultural and social\nawareness during the development cycle.\n","authors":["Haoyi Qiu","Alexander R. Fabbri","Divyansh Agarwal","Kung-Hsiang Huang","Sarah Tan","Nanyun Peng","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2410.23252v3.pdf","comment":"NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2501.04802v2","updated":"2025-03-08T22:14:57Z","published":"2025-01-08T19:29:33Z","title":"Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval","summary":"  HotFlip is a topical gradient-based word substitution method for attacking\nlanguage models. Recently, this method has been further applied to attack\nretrieval systems by generating malicious passages that are injected into a\ncorpus, i.e., corpus poisoning. However, HotFlip is known to be computationally\ninefficient, with the majority of time being spent on gradient accumulation for\neach query-passage pair during the adversarial token generation phase, making\nit impossible to generate an adequate number of adversarial passages in a\nreasonable amount of time. Moreover, the attack method itself assumes access to\na set of user queries, a strong assumption that does not correspond to how\nreal-world adversarial attacks are usually performed. In this paper, we first\nsignificantly boost the efficiency of HotFlip, reducing the adversarial\ngeneration process from 4 hours per document to only 15 minutes, using the same\nhardware. We further contribute experiments and analysis on two additional\ntasks: (1) transfer-based black-box attacks, and (2) query-agnostic attacks.\nWhenever possible, we provide comparisons between the original method and our\nimproved version. Our experiments demonstrate that HotFlip can effectively\nattack a variety of dense retrievers, with an observed trend that its attack\nperformance diminishes against more advanced and recent methods. Interestingly,\nwe observe that while HotFlip performs poorly in a black-box setting,\nindicating limited capacity for generalization, in query-agnostic scenarios its\nperformance is correlated to the volume of injected adversarial passages.\n","authors":["Yongkang Li","Panagiotis Eustratiadis","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2501.04802v2.pdf","comment":"This paper has been accepted for oral presentation in the\n  reproducibility track at ECIR 2025"},{"id":"http://arxiv.org/abs/2501.11721v2","updated":"2025-03-08T21:56:29Z","published":"2025-01-20T20:07:18Z","title":"Explain-Query-Test: Self-Evaluating LLMs Via Explanation and\n  Comprehension Discrepancy","summary":"  Large language models (LLMs) have demonstrated remarkable proficiency in\ngenerating detailed and coherent explanations of complex concepts. However, the\nextent to which these models truly comprehend the concepts they articulate\nremains unclear. To assess the level of comprehension of a model relative to\nthe content it generates, we implemented a self-evaluation pipeline where\nmodels: (i) given a topic generate an excerpt with information about the topic,\n(ii) given an excerpt generate question-answer pairs, and finally (iii) given a\nquestion generate an answer. We refer to this self-evaluation approach as\nExplain-Query-Test (EQT). Interestingly, the accuracy on generated questions\nresulting from running the EQT pipeline correlates strongly with the model\nperformance as verified by typical benchmarks such as MMLU-Pro. In other words,\nEQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank\nmodels without the need for any external source of evaluation data other than\nlists of topics of interest. Moreover, our results reveal a disparity between\nthe models' ability to produce detailed explanations and their performance on\nquestions related to those explanations. This gap highlights fundamental\nlimitations in the internal knowledge representation and reasoning abilities of\ncurrent LLMs. We release the code at https://github.com/asgsaeid/EQT.\n","authors":["Saeid Asgari Taghanaki","Joao Monteiro"],"pdf_url":"https://arxiv.org/pdf/2501.11721v2.pdf","comment":"Accepted to ICLR 2025, SSI-FM"},{"id":"http://arxiv.org/abs/2503.06335v1","updated":"2025-03-08T20:40:28Z","published":"2025-03-08T20:40:28Z","title":"Phraselette: A Poet's Procedural Palette","summary":"  According to the recently introduced theory of artistic support tools,\ncreativity support tools exert normative influences over artistic production,\ninstantiating a normative ground that shapes both the process and product of\nartistic expression. We argue that the normative ground of most existing\nautomated writing tools is misaligned with writerly values and identify a\npotential alternative frame-material writing support-for experimental poetry\ntools that flexibly support the finding, processing, transforming, and shaping\nof text(s). Based on this frame, we introduce Phraselette, an artistic material\nwriting support interface that helps experimental poets search for words and\nphrases. To provide material writing support, Phraselette is designed to\ncounter the dominant mode of automated writing tools, while offering language\nmodel affordances in line with writerly values. We further report on an\nextended expert evaluation involving 10 published poets that indicates support\nfor both our framing of material writing support and for Phraselette itself.\n","authors":["Alex Calderwood","John Joon Young Chung","Yuqian Sun","Melissa Roemmele","Max Kreminski"],"pdf_url":"https://arxiv.org/pdf/2503.06335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06330v1","updated":"2025-03-08T20:06:50Z","published":"2025-03-08T20:06:50Z","title":"States of LLM-generated Texts and Phase Transitions between them","summary":"  It is known for some time that autocorrelations of words in human-written\ntexts decay according to a power law. Recent works have also shown that the\nautocorrelations decay in texts generated by LLMs is qualitatively different\nfrom the literary texts. Solid state physics tie the autocorrelations decay\nlaws to the states of matter. In this work, we empirically demonstrate that,\ndepending on the temperature parameter, LLMs can generate text that can be\nclassified as solid, critical state or gas.\n","authors":["Nikolay Mikhaylovskiy"],"pdf_url":"https://arxiv.org/pdf/2503.06330v1.pdf","comment":"Published as a conference paper at MathAI 2025"},{"id":"http://arxiv.org/abs/2503.06313v1","updated":"2025-03-08T19:12:36Z","published":"2025-03-08T19:12:36Z","title":"Advancing Autonomous Vehicle Intelligence: Deep Learning and Multimodal\n  LLM for Traffic Sign Recognition and Robust Lane Detection","summary":"  Autonomous vehicles (AVs) require reliable traffic sign recognition and\nrobust lane detection capabilities to ensure safe navigation in complex and\ndynamic environments. This paper introduces an integrated approach combining\nadvanced deep learning techniques and Multimodal Large Language Models (MLLMs)\nfor comprehensive road perception. For traffic sign recognition, we\nsystematically evaluate ResNet-50, YOLOv8, and RT-DETR, achieving\nstate-of-the-art performance of 99.8% with ResNet-50, 98.0% accuracy with\nYOLOv8, and achieved 96.6% accuracy in RT-DETR despite its higher computational\ncomplexity. For lane detection, we propose a CNN-based segmentation method\nenhanced by polynomial curve fitting, which delivers high accuracy under\nfavorable conditions. Furthermore, we introduce a lightweight, Multimodal,\nLLM-based framework that directly undergoes instruction tuning using small yet\ndiverse datasets, eliminating the need for initial pretraining. This framework\neffectively handles various lane types, complex intersections, and merging\nzones, significantly enhancing lane detection reliability by reasoning under\nadverse conditions. Despite constraints in available training resources, our\nmultimodal approach demonstrates advanced reasoning capabilities, achieving a\nFrame Overall Accuracy (FRM) of 53.87%, a Question Overall Accuracy (QNS) of\n82.83%, lane detection accuracies of 99.6% in clear conditions and 93.0% at\nnight, and robust performance in reasoning about lane invisibility due to rain\n(88.4%) or road degradation (95.6%). The proposed comprehensive framework\nmarkedly enhances AV perception reliability, thus contributing significantly to\nsafer autonomous driving across diverse and challenging road scenarios.\n","authors":["Chandan Kumar Sah","Ankit Kumar Shaw","Xiaoli Lian","Arsalan Shahid Baig","Tuopu Wen","Kun Jiang","Mengmeng Yang","Diange Yang"],"pdf_url":"https://arxiv.org/pdf/2503.06313v1.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.06296v1","updated":"2025-03-08T18:09:13Z","published":"2025-03-08T18:09:13Z","title":"MoEMoE: Question Guided Dense and Scalable Sparse Mixture-of-Expert for\n  Multi-source Multi-modal Answering","summary":"  Question Answering (QA) and Visual Question Answering (VQA) are well-studied\nproblems in the language and vision domain. One challenging scenario involves\nmultiple sources of information, each of a different modality, where the answer\nto the question may exist in one or more sources. This scenario contains richer\ninformation but is highly complex to handle. In this work, we formulate a novel\nquestion-answer generation (QAG) framework in an environment containing\nmulti-source, multimodal information. The answer may belong to any or all\nsources; therefore, selecting the most prominent answer source or an optimal\ncombination of all sources for a given question is challenging. To address this\nissue, we propose a question-guided attention mechanism that learns attention\nacross multiple sources and decodes this information for robust and unbiased\nanswer generation. To learn attention within each source, we introduce an\nexplicit alignment between questions and various information sources, which\nfacilitates identifying the most pertinent parts of the source information\nrelative to the question. Scalability in handling diverse questions poses a\nchallenge. We address this by extending our model to a sparse\nmixture-of-experts (sparse-MoE) framework, enabling it to handle thousands of\nquestion types. Experiments on T5 and Flan-T5 using three datasets demonstrate\nthe model's efficacy, supported by ablation studies.\n","authors":["Vinay Kumar Verma","Shreyas Sunil Kulkarni","Happy Mittal","Deepak Gupta"],"pdf_url":"https://arxiv.org/pdf/2503.06296v1.pdf","comment":"To appear at NAACL Industry Track"},{"id":"http://arxiv.org/abs/2503.06291v1","updated":"2025-03-08T17:46:01Z","published":"2025-03-08T17:46:01Z","title":"IteRABRe: Iterative Recovery-Aided Block Reduction","summary":"  Large Language Models (LLMs) have grown increasingly expensive to deploy,\ndriving the need for effective model compression techniques. While block\npruning offers a straightforward approach to reducing model size, existing\nmethods often struggle to maintain performance or require substantial\ncomputational resources for recovery. We present IteRABRe, a simple yet\neffective iterative pruning method that achieves superior compression results\nwhile requiring minimal computational resources. Using only 2.5M tokens for\nrecovery, our method outperforms baseline approaches by ~3% on average when\ncompressing the Llama3.1-8B and Qwen2.5-7B models. IteRABRe demonstrates\nparticular strength in the preservation of linguistic capabilities, showing an\nimprovement 5% over the baselines in language-related tasks. Our analysis\nreveals distinct pruning characteristics between these models, while also\ndemonstrating preservation of multilingual capabilities.\n","authors":["Haryo Akbarianto Wibowo","Haiyue Song","Hideki Tanaka","Masao Utiyama","Alham Fikri Aji","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2503.06291v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2405.16919v3","updated":"2025-03-08T17:16:09Z","published":"2024-05-27T08:12:00Z","title":"VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large\n  Multi-Modal Models","summary":"  While large multi-modal models (LMMs) have exhibited impressive capabilities\nacross diverse tasks, their effectiveness in handling complex tasks has been\nlimited by the prevailing single-step reasoning paradigm. To this end, this\npaper proposes VoCoT, a multi-step Visually grounded object-centric\nChain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is\ncharacterized by two key features: (1) object-centric reasoning paths that\nrevolve around cross-modal shared object-level information, and (2) visually\ngrounded representation of object concepts in a multi-modal interleaved and\naligned manner, which effectively bridges the modality gap within LMMs during\nlong-term generation. To adapt LMMs in reasoning with VoCoT, we further\nconstruct an instruction-tuning dataset. By combining VoCoT with the prevalent\nopen-source LMM architectures, we develop a VoCoT-based model, VolCano. With\nonly 7B parameters and limited input image resolution, VolCano demonstrates\nexcellent performance across various scenarios. In benchmarks like CLEVR and\nEmbSpatial, which highly require complex reasoning capabilities, VolCano\noutperforms SOTA models, including powerful GPT-4V. Related code, data and\nmodels are released in https://github.com/RupertLuo/VoCoT.\n","authors":["Zejun Li","Ruipu Luo","Jiwen Zhang","Minghui Qiu","Xuanjing Huang","Zhongyu Wei"],"pdf_url":"https://arxiv.org/pdf/2405.16919v3.pdf","comment":"Accepted by NAACL 2025 main conference"},{"id":"http://arxiv.org/abs/2412.07923v2","updated":"2025-03-08T16:42:51Z","published":"2024-12-10T21:09:12Z","title":"Asking Again and Again: Exploring LLM Robustness to Repeated Questions","summary":"  This study investigates whether repeating questions within prompts influences\nthe performance of large language models (LLMs). We hypothesize that\nreiterating a question within a single prompt might enhance the model's focus\non key elements of the query. We evaluate five recent LLMs -- including\nGPT-4o-mini, DeepSeek-V3, and smaller open-source models -- on three reading\ncomprehension datasets under different prompt settings, varying question\nrepetition levels (1, 3, or 5 times per prompt). Our results demonstrate that\nquestion repetition can increase models' accuracy by up to $6\\%$. However,\nacross all models, settings, and datasets, we do not find the result\nstatistically significant. These findings provide insights into prompt design\nand LLM behavior, suggesting that repetition alone does not significantly\nimpact output quality.\n","authors":["Sagi Shaier","Mario Sanz-Guerrero","Katharina von der Wense"],"pdf_url":"https://arxiv.org/pdf/2412.07923v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17799v2","updated":"2025-03-08T16:19:35Z","published":"2024-11-26T18:28:09Z","title":"Signs as Tokens: A Retrieval-Enhanced Multilingual Sign Language\n  Generator","summary":"  Sign language is a visual language that encompasses all linguistic features\nof natural languages and serves as the primary communication method for the\ndeaf and hard-of-hearing communities. Although many studies have successfully\nadapted pretrained language models (LMs) for sign language translation\n(sign-to-text), the reverse task-sign language generation\n(text-to-sign)-remains largely unexplored. In this work, we introduce a\nmultilingual sign language model, Signs as Tokens (SOKE), which can generate 3D\nsign avatars autoregressively from text inputs using a pretrained LM. To align\nsign language with the LM, we leverage a decoupled tokenizer that discretizes\ncontinuous signs into token sequences representing various body parts. During\ndecoding, unlike existing approaches that flatten all part-wise tokens into a\nsingle sequence and predict one token at a time, we propose a multi-head\ndecoding method capable of predicting multiple tokens simultaneously. This\napproach improves inference efficiency while maintaining effective information\nfusion across different body parts. To further ease the generation process, we\npropose a retrieval-enhanced SLG approach, which incorporates external sign\ndictionaries to provide accurate word-level signs as auxiliary conditions,\nsignificantly improving the precision of generated signs. Extensive qualitative\nand quantitative evaluations demonstrate the effectiveness of SOKE. Code,\nmodels, and data will be made publicly available.\n","authors":["Ronglai Zuo","Rolandos Alexandros Potamias","Evangelos Ververas","Jiankang Deng","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2411.17799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06263v1","updated":"2025-03-08T16:19:13Z","published":"2025-03-08T16:19:13Z","title":"Critical Foreign Policy Decisions (CFPD)-Benchmark: Measuring Diplomatic\n  Preferences in Large Language Models","summary":"  As national security institutions increasingly integrate Artificial\nIntelligence (AI) into decision-making and content generation processes,\nunderstanding the inherent biases of large language models (LLMs) is crucial.\nThis study presents a novel benchmark designed to evaluate the biases and\npreferences of seven prominent foundation models-Llama 3.1 8B Instruct, Llama\n3.1 70B Instruct, GPT-4o, Gemini 1.5 Pro-002, Mixtral 8x22B, Claude 3.5 Sonnet,\nand Qwen2 72B-in the context of international relations (IR). We designed a\nbias discovery study around core topics in IR using 400-expert crafted\nscenarios to analyze results from our selected models. These scenarios focused\non four topical domains including: military escalation, military and\nhumanitarian intervention, cooperative behavior in the international system,\nand alliance dynamics. Our analysis reveals noteworthy variation among model\nrecommendations based on scenarios designed for the four tested domains.\nParticularly, Qwen2 72B, Gemini 1.5 Pro-002 and Llama 3.1 8B Instruct models\noffered significantly more escalatory recommendations than Claude 3.5 Sonnet\nand GPT-4o models. All models exhibit some degree of country-specific biases,\noften recommending less escalatory and interventionist actions for China and\nRussia compared to the United States and the United Kingdom. These findings\nhighlight the necessity for controlled deployment of LLMs in high-stakes\nenvironments, emphasizing the need for domain-specific evaluations and model\nfine-tuning to align with institutional objectives.\n","authors":["Benjamin Jensen","Ian Reynolds","Yasir Atalan","Michael Garcia","Austin Woo","Anthony Chen","Trevor Howarth"],"pdf_url":"https://arxiv.org/pdf/2503.06263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06705v2","updated":"2025-03-08T15:20:34Z","published":"2024-05-09T07:37:34Z","title":"LLMs can Find Mathematical Reasoning Mistakes by Pedagogical\n  Chain-of-Thought","summary":"  Self-correction is emerging as a promising approach to mitigate the issue of\nhallucination in Large Language Models (LLMs). To facilitate effective\nself-correction, recent research has proposed mistake detection as its initial\nstep. However, current literature suggests that LLMs often struggle with\nreliably identifying reasoning mistakes when using simplistic prompting\nstrategies. To address this challenge, we introduce a unique prompting\nstrategy, termed the Pedagogical Chain-of-Thought (PedCoT), which is\nspecifically designed to guide the identification of reasoning mistakes,\nparticularly mathematical reasoning mistakes. PedCoT consists of pedagogical\nprinciples for prompts (PPP) design, two-stage interaction process (TIP) and\ngrounded PedCoT prompts, all inspired by the educational theory of the Bloom\nCognitive Model (BCM). We evaluate our approach on two public datasets\nfeaturing math problems of varying difficulty levels. The experiments\ndemonstrate that our zero-shot prompting strategy significantly outperforms\nstrong baselines. The proposed method can achieve the goal of reliable\nmathematical mistake identification and provide a foundation for automatic math\nanswer grading. The results underscore the significance of educational theory,\nserving as domain knowledge, in guiding prompting strategy design for\naddressing challenging tasks with LLMs effectively.\n","authors":["Zhuoxuan Jiang","Haoyuan Peng","Shanshan Feng","Fan Li","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2405.06705v2.pdf","comment":"Accepted by IJCAI 2024"},{"id":"http://arxiv.org/abs/2503.06241v1","updated":"2025-03-08T14:53:20Z","published":"2025-03-08T14:53:20Z","title":"A Noise-Robust Turn-Taking System for Real-World Dialogue Robots: A\n  Field Experiment","summary":"  Turn-taking is a crucial aspect of human-robot interaction, directly\ninfluencing conversational fluidity and user engagement. While previous\nresearch has explored turn-taking models in controlled environments, their\nrobustness in real-world settings remains underexplored. In this study, we\npropose a noise-robust voice activity projection (VAP) model, based on a\nTransformer architecture, to enhance real-time turn-taking in dialogue robots.\nTo evaluate the effectiveness of the proposed system, we conducted a field\nexperiment in a shopping mall, comparing the VAP system with a conventional\ncloud-based speech recognition system. Our analysis covered both subjective\nuser evaluations and objective behavioral analysis. The results showed that the\nproposed system significantly reduced response latency, leading to a more\nnatural conversation where both the robot and users responded faster. The\nsubjective evaluations suggested that faster responses contribute to a better\ninteraction experience.\n","authors":["Koji Inoue","Yuki Okafuji","Jun Baba","Yoshiki Ohira","Katsuya Hyodo","Tatsuya Kawahara"],"pdf_url":"https://arxiv.org/pdf/2503.06241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04606v2","updated":"2025-03-08T14:29:42Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Kling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06232v1","updated":"2025-03-08T14:24:54Z","published":"2025-03-08T14:24:54Z","title":"Integrating Chain-of-Thought for Multimodal Alignment: A Study on 3D\n  Vision-Language Learning","summary":"  Chain-of-Thought (CoT) reasoning has proven effective in natural language\ntasks but remains underexplored in multimodal alignment. This study\ninvestigates its integration into 3D vision-language learning by embedding\nstructured reasoning into alignment training. We introduce the 3D-CoT\nBenchmark, a dataset with hierarchical CoT annotations covering shape\nrecognition, functional inference, and causal reasoning. Through controlled\nexperiments, we compare CoT-structured and standard textual annotations across\nlarge reasoning models (LRMs) and large language models (LLMs). Our evaluation\nemploys a dual-layer framework assessing both intermediate reasoning and final\ninference quality. Extensive experiments demonstrate that CoT significantly\nimproves 3D semantic grounding, with LRMs leveraging CoT more effectively than\nLLMs. Furthermore, we highlight that annotation structure influences\nperformance-explicit reasoning markers aid LLMs, while unmarked CoT better\naligns with LRM inference patterns. Our analyses suggest that CoT is crucial\nfor enhancing multimodal reasoning, with implications beyond 3D tasks.\n","authors":["Yanjun Chen","Yirong Sun","Xinghao Chen","Jian Wang","Xiaoyu Shen","Wenjie Li","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12362v2","updated":"2025-03-08T14:06:08Z","published":"2024-08-22T12:59:05Z","title":"CLEANANERCorp: Identifying and Correcting Incorrect Labels in the\n  ANERcorp Dataset","summary":"  Label errors are a common issue in machine learning datasets, particularly\nfor tasks such as Named Entity Recognition. Such label errors might hurt model\ntraining, affect evaluation results, and lead to an inaccurate assessment of\nmodel performance. In this study, we dived deep into one of the widely adopted\nArabic NER benchmark datasets (ANERcorp) and found a significant number of\nannotation errors, missing labels, and inconsistencies. Therefore, in this\nstudy, we conducted empirical research to understand these errors, correct them\nand propose a cleaner version of the dataset named CLEANANERCorp. CLEANANERCorp\nwill serve the research community as a more accurate and consistent benchmark.\n","authors":["Mashael Al-Duwais","Hend Al-Khalifa","Abdulmalik Al-Salman"],"pdf_url":"https://arxiv.org/pdf/2408.12362v2.pdf","comment":"Proceedings of the 6th Workshop on Open-Source Arabic Corpora and\n  Processing Tools (OSACT) with Shared Tasks on Arabic LLMs Hallucination and\n  Dialect to MSA Machine Translation @ LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2408.11779v2","updated":"2025-03-08T14:01:37Z","published":"2024-08-21T17:09:00Z","title":"Personality Alignment of Large Language Models","summary":"  Aligning large language models (LLMs) typically aim to reflect general human\nvalues and behaviors, but they often fail to capture the unique characteristics\nand preferences of individual users. To address this gap, we introduce the\nconcept of Personality Alignment. This approach tailors LLMs' responses and\ndecisions to match the specific preferences of individual users or closely\nrelated groups. Inspired by psychometrics, we created the Personality Alignment\nwith Personality Inventories (PAPI) dataset, which includes data from over\n320,000 real subjects across multiple personality assessments, including both\nthe Big Five Personality Factors and Dark Triad traits. This comprehensive\ndataset enables quantitative evaluation of LLMs' alignment capabilities across\nboth positive and potentially problematic personality dimensions. Recognizing\nthe challenges of personality alignments, such as limited personal data,\ndiverse preferences, and scalability requirements, we developed an activation\nintervention optimization method. This method enhances LLMs' ability to\nefficiently align with individual behavioral preferences using minimal data and\ncomputational resources. Remarkably, our method, PAS, achieves superior\nperformance while requiring only 1/5 of the optimization time compared to DPO,\noffering practical value for personality alignment. Our work paves the way for\nfuture AI systems to make decisions and reason in truly personality ways,\nenhancing the relevance and meaning of AI interactions for each user and\nadvancing human-centered artificial intelligence. The dataset and code are\nreleased at https://github.com/zhu-minjun/PAlign.\n","authors":["Minjun Zhu","Yixuan Weng","Linyi Yang","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.11779v2.pdf","comment":"Acecpt in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.00816v3","updated":"2025-03-08T14:01:34Z","published":"2024-10-28T08:10:21Z","title":"CycleResearcher: Improving Automated Research via Automated Review","summary":"  The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/.\n","authors":["Yixuan Weng","Minjun Zhu","Guangsheng Bao","Hongbo Zhang","Jindong Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.00816v3.pdf","comment":"Accept in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.06218v1","updated":"2025-03-08T13:40:10Z","published":"2025-03-08T13:40:10Z","title":"KnowLogic: A Benchmark for Commonsense Reasoning via Knowledge-Driven\n  Data Synthesis","summary":"  Current evaluations of commonsense reasoning in LLMs are hindered by the\nscarcity of natural language corpora with structured annotations for reasoning\ntasks. To address this, we introduce KnowLogic, a benchmark generated through a\nknowledge-driven synthetic data strategy. KnowLogic integrates diverse\ncommonsense knowledge, plausible scenarios, and various types of logical\nreasoning. One of the key advantages of KnowLogic is its adjustable difficulty\nlevels, allowing for flexible control over question complexity. It also\nincludes fine-grained labels for in-depth evaluation of LLMs' reasoning\nabilities across multiple dimensions. Our benchmark consists of 3,000 bilingual\n(Chinese and English) questions across various domains, and presents\nsignificant challenges for current LLMs, with the highest-performing model\nachieving only 69.57\\%. Our analysis highlights common errors, such as\nmisunderstandings of low-frequency commonsense, logical inconsistencies, and\noverthinking. This approach, along with our benchmark, provides a valuable tool\nfor assessing and enhancing LLMs' commonsense reasoning capabilities and can be\napplied to a wide range of knowledge domains.\n","authors":["Weidong Zhan","Yue Wang","Nan Hu","Liming Xiao","Jingyuan Ma","Yuhang Qin","Zheng Li","Yixin Yang","Sirui Deng","Jinkun Ding","Wenhan Ma","Rui Li","Weilin Luo","Qun Liu","Zhifang Sui"],"pdf_url":"https://arxiv.org/pdf/2503.06218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06211v1","updated":"2025-03-08T13:28:50Z","published":"2025-03-08T13:28:50Z","title":"Text-Speech Language Models with Improved Cross-Modal Transfer by\n  Aligning Abstraction Levels","summary":"  Text-Speech Language Models (TSLMs) -- language models trained to jointly\nprocess and generate text and speech -- aim to enable cross-modal knowledge\ntransfer to overcome the scaling limitations of unimodal speech LMs. The\npredominant approach to TSLM training expands the vocabulary of a pre-trained\ntext LM by appending new embeddings and linear projections for speech, followed\nby fine-tuning on speech data. We hypothesize that this method limits\ncross-modal transfer by neglecting feature compositionality, preventing\ntext-learned functions from being fully leveraged at appropriate abstraction\nlevels. To address this, we propose augmenting vocabulary expansion with\nmodules that better align abstraction levels across layers. Our models,\n\\textsc{SmolTolk}, rival or surpass state-of-the-art TSLMs trained with orders\nof magnitude more compute. Representation analyses and improved multimodal\nperformance suggest our method enhances cross-modal transfer.\n","authors":["Santiago Cuervo","Adel Moumen","Yanis Labrak","Sameer Khurana","Antoine Laurent","Mickael Rouvier","Ricard Marxer"],"pdf_url":"https://arxiv.org/pdf/2503.06211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06204v1","updated":"2025-03-08T13:21:44Z","published":"2025-03-08T13:21:44Z","title":"CUPCase: Clinically Uncommon Patient Cases and Diagnoses Dataset","summary":"  Medical benchmark datasets significantly contribute to developing Large\nLanguage Models (LLMs) for medical knowledge extraction, diagnosis,\nsummarization, and other uses. Yet, current benchmarks are mainly derived from\nexam questions given to medical students or cases described in the medical\nliterature, lacking the complexity of real-world patient cases that deviate\nfrom classic textbook abstractions. These include rare diseases, uncommon\npresentations of common diseases, and unexpected treatment responses. Here, we\nconstruct Clinically Uncommon Patient Cases and Diagnosis Dataset (CUPCase)\nbased on 3,562 real-world case reports from BMC, including diagnoses in\nopen-ended textual format and as multiple-choice options with distractors.\nUsing this dataset, we evaluate the ability of state-of-the-art LLMs, including\nboth general-purpose and Clinical LLMs, to identify and correctly diagnose a\npatient case, and test models' performance when only partial information about\ncases is available. Our findings show that general-purpose GPT-4o attains the\nbest performance in both the multiple-choice task (average accuracy of 87.9%)\nand the open-ended task (BERTScore F1 of 0.764), outperforming several LLMs\nwith a focus on the medical domain such as Meditron-70B and MedLM-Large.\nMoreover, GPT-4o was able to maintain 87% and 88% of its performance with only\nthe first 20% of tokens of the case presentation in multiple-choice and free\ntext, respectively, highlighting the potential of LLMs to aid in early\ndiagnosis in real-world cases. CUPCase expands our ability to evaluate LLMs for\nclinical decision support in an open and reproducible manner.\n","authors":["Oriel Perets","Ofir Ben Shoham","Nir Grinberg","Nadav Rappoport"],"pdf_url":"https://arxiv.org/pdf/2503.06204v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2411.14717v2","updated":"2025-03-08T13:10:57Z","published":"2024-11-22T04:09:23Z","title":"FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data","summary":"  Multimodal Large Language Models (MLLMs) have made significant advancements,\ndemonstrating powerful capabilities in processing and understanding multimodal\ndata. Fine-tuning MLLMs with Federated Learning (FL) allows for expanding the\ntraining data scope by including private data sources, thereby enhancing their\npractical applicability in privacy-sensitive domains. However, current research\nremains in the early stage, particularly in addressing the \\textbf{multimodal\nheterogeneities} in real-world applications. In this paper, we introduce a\nbenchmark to evaluate the performance of federated fine-tuning of MLLMs across\nvarious multimodal heterogeneous scenarios, laying the groundwork for future\nresearch in the field. Our benchmark includes two lightweight MLLMs, two\ndownstream tasks, three evaluation metrics, and five datasets across three\ndomains, along with six comparison baselines, covering over ten types of\nmodality heterogeneities across four multimodal scenarios. To address the\nchallenges posed by multimodal heterogeneity, we develop a general FedMLLM\nframework that integrates classic FL methods alongside two modality-agnostic\nstrategies. Extensive experimental results show that our proposed FL paradigm\nimproves the performance of MLLMs by broadening the range of training data and\nmitigating multimodal heterogeneity. Code is available in supplementary\nmaterials.\n","authors":["Binqian Xu","Xiangbo Shu","Haiyang Mei","Guosen Xie","Basura Fernando","Jinhui Tang"],"pdf_url":"https://arxiv.org/pdf/2411.14717v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05673v5","updated":"2025-03-08T13:10:25Z","published":"2024-06-09T07:06:58Z","title":"Flow of Reasoning:Training LLMs for Divergent Problem Solving with\n  Minimal Examples","summary":"  The ability to generate diverse solutions to a given problem is a hallmark of\nhuman creativity. This divergent reasoning is also crucial for machines,\nenhancing their robustness and enabling them to assist humans in many\napplications such as scientific discovery. However, existing approaches to\nmulti-step reasoning with large language models (LLMs) have mostly focused only\non reasoning accuracy, without further discovering more diverse valid\nsolutions. For example, supervised fine-tuning can improve LLM reasoning\nquality, but requires extensive supervised data to capture the full range of\npossible solutions. Reward-maximization reinforcement learning aims to find\nlimited highest-reward solutions while neglecting the solution diversity. To\nfill this gap, we propose Flow of Reasoning (FoR), an efficient\ndiversity-seeking LLM finetuning method aimed at improving reasoning quality\nand diversity with minimal data. FoR formulates multi-step LLM reasoning as a\nMarkovian flow on a DAG-structured reasoning graph. This formulation allows us\nto incorporate and adapt principled GFlowNet approaches, for finetuning LLMs to\nsample divergent paths with probabilities proportional to the (unnormalized)\nreward of target problems. Extensive experiments show that, with limited\ntraining examples (e.g., 15 examples), FoR enables the discovery of diverse,\ncreative, high-quality solutions, greatly outperforming a wide range of\nexisting inference and training methods across six challenging reasoning tasks,\nincluding BlocksWorld (embodied reasoning), Game24 (math puzzle solving),\nRubik's Cube (spatial reasoning), 1D-ARC (abstraction reasoning), GSM8k (math\nreasoning), and ProntoQA (logical reasoning). Code is available at\nhttps://github.com/Yu-Fangxu/FoR.\n","authors":["Fangxu Yu","Lai Jiang","Haoqiang Kang","Shibo Hao","Lianhui Qin"],"pdf_url":"https://arxiv.org/pdf/2406.05673v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06201v1","updated":"2025-03-08T13:04:20Z","published":"2025-03-08T13:04:20Z","title":"Explainable Synthetic Image Detection through Diffusion Timestep\n  Ensembling","summary":"  Recent advances in diffusion models have enabled the creation of deceptively\nreal images, posing significant security risks when misused. In this study, we\nreveal that natural and synthetic images exhibit distinct differences in the\nhigh-frequency domains of their Fourier power spectra after undergoing\niterative noise perturbations through an inverse multi-step denoising process,\nsuggesting that such noise can provide additional discriminative information\nfor identifying synthetic images. Based on this observation, we propose a novel\ndetection method that amplifies these differences by progressively adding noise\nto the original images across multiple timesteps, and train an ensemble of\nclassifiers on these noised images. To enhance human comprehension, we\nintroduce an explanation generation and refinement module to identify flaws\nlocated in AI-generated images. Additionally, we construct two new datasets,\nGenHard and GenExplain, derived from the GenImage benchmark, providing\ndetection samples of greater difficulty and high-quality rationales for fake\nimages. Extensive experiments show that our method achieves state-of-the-art\nperformance with 98.91% and 95.89% detection accuracy on regular and harder\nsamples, increasing a minimal of 2.51% and 3.46% compared to baselines.\nFurthermore, our method also generalizes effectively to images generated by\nother diffusion models. Our code and datasets will be made publicly available.\n","authors":["Yixin Wu","Feiran Zhang","Tianyuan Shi","Ruicheng Yin","Zhenghua Wang","Zhenliang Gan","Xiaohua Wang","Changze Lv","Xiaoqing Zheng","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.06201v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.11903v2","updated":"2025-03-08T12:36:34Z","published":"2025-02-17T15:24:49Z","title":"MMRC: A Large-Scale Benchmark for Understanding Multimodal Large\n  Language Model in Real-World Conversation","summary":"  Recent multimodal large language models (MLLMs) have demonstrated significant\npotential in open-ended conversation, generating more accurate and personalized\nresponses. However, their abilities to memorize, recall, and reason in\nsustained interactions within real-world scenarios remain underexplored. This\npaper introduces MMRC, a Multi-Modal Real-world Conversation benchmark for\nevaluating six core open-ended abilities of MLLMs: information extraction,\nmulti-turn reasoning, information update, image management, memory recall, and\nanswer refusal. With data collected from real-world scenarios, MMRC comprises\n5,120 conversations and 28,720 corresponding manually labeled questions, posing\na significant challenge to existing MLLMs. Evaluations on 20 MLLMs in MMRC\nindicate an accuracy drop during open-ended interactions. We identify four\ncommon failure patterns: long-term memory degradation, inadequacies in updating\nfactual knowledge, accumulated assumption of error propagation, and reluctance\nto say no. To mitigate these issues, we propose a simple yet effective\nNOTE-TAKING strategy, which can record key information from the conversation\nand remind the model during its responses, enhancing conversational\ncapabilities. Experiments across six MLLMs demonstrate significant performance\nimprovements.\n","authors":["Haochen Xue","Feilong Tang","Ming Hu","Yexin Liu","Qidong Huang","Yulong Li","Chengzhi Liu","Zhongxing Xu","Chong Zhang","Chun-Mei Feng","Yutong Xie","Imran Razzak","Zongyuan Ge","Jionglong Su","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2502.11903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06184v1","updated":"2025-03-08T12:00:21Z","published":"2025-03-08T12:00:21Z","title":"Sample-aware Adaptive Structured Pruning for Large Language Models","summary":"  Large language models (LLMs) have achieved outstanding performance in natural\nlanguage processing, but enormous model sizes and high computational costs\nlimit their practical deployment. Structured pruning can effectively reduce the\nresource demands for deployment by removing redundant model parameters.\nHowever, the randomly selected calibration data and fixed single importance\nestimation metrics in existing structured pruning methods lead to degraded\nperformance of pruned models. This study introduces AdaPruner, a sample-aware\nadaptive structured pruning framework for LLMs, aiming to optimize the\ncalibration data and importance estimation metrics in the structured pruning\nprocess. Specifically, AdaPruner effectively removes redundant parameters from\nLLMs by constructing a structured pruning solution space and then employing\nBayesian optimization to adaptively search for the optimal calibration data and\nimportance estimation metrics. Experimental results show that the AdaPruner\noutperforms existing structured pruning methods on a family of LLMs with\nvarying pruning ratios, demonstrating its applicability and robustness.\nRemarkably, at a 20\\% pruning ratio, the model pruned with AdaPruner maintains\n97\\% of the performance of the unpruned model.\n","authors":["Jun Kong","Xinge Ma","Jin Wang","Xuejie Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14062v2","updated":"2025-03-08T10:27:55Z","published":"2024-11-21T12:16:16Z","title":"MMGenBench: Fully Automatically Evaluating LMMs from the Text-to-Image\n  Generation Perspective","summary":"  Large Multimodal Models (LMMs) demonstrate impressive capabilities. However,\ncurrent benchmarks predominantly focus on image comprehension in specific\ndomains, and these benchmarks are labor-intensive to construct. Moreover, their\nanswers tend to be brief, making it difficult to assess the ability of LMMs to\ngenerate detailed descriptions of images. To address these limitations, we\npropose the MMGenBench-Pipeline, a straightforward and fully automated\nevaluation pipeline. This involves generating textual descriptions from input\nimages, using these descriptions to create auxiliary images via text-to-image\ngenerative models, and then comparing the original and generated images.\nFurthermore, to ensure the effectiveness of MMGenBench-Pipeline, we design\nMMGenBench-Test, evaluating LMMs across 13 distinct image patterns, and\nMMGenBench-Domain, focusing on generative image performance. A thorough\nevaluation involving over 50 popular LMMs demonstrates the effectiveness and\nreliability of both the pipeline and benchmark. Our observations indicate that\nnumerous LMMs excelling in existing benchmarks fail to adequately complete the\nbasic tasks related to image understanding and description. This finding\nhighlights the substantial potential for performance improvement in current\nLMMs and suggests avenues for future model optimization. Concurrently,\nMMGenBench-Pipeline can efficiently assess the performance of LMMs across\ndiverse domains using only image inputs.\n","authors":["Hailang Huang","Yong Wang","Zixuan Huang","Huaqiu Li","Tongwen Huang","Xiangxiang Chu","Richong Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.14062v2.pdf","comment":"This project is available at: https://github.com/lerogo/MMGenBench"},{"id":"http://arxiv.org/abs/2503.05858v1","updated":"2025-03-08T10:20:57Z","published":"2025-03-08T10:20:57Z","title":"Bimodal Connection Attention Fusion for Speech Emotion Recognition","summary":"  Multi-modal emotion recognition is challenging due to the difficulty of\nextracting features that capture subtle emotional differences. Understanding\nmulti-modal interactions and connections is key to building effective bimodal\nspeech emotion recognition systems. In this work, we propose Bimodal Connection\nAttention Fusion (BCAF) method, which includes three main modules: the\ninteractive connection network, the bimodal attention network, and the\ncorrelative attention network. The interactive connection network uses an\nencoder-decoder architecture to model modality connections between audio and\ntext while leveraging modality-specific features. The bimodal attention network\nenhances semantic complementation and exploits intra- and inter-modal\ninteractions. The correlative attention network reduces cross-modal noise and\ncaptures correlations between audio and text. Experiments on the MELD and\nIEMOCAP datasets demonstrate that the proposed BCAF method outperforms existing\nstate-of-the-art baselines.\n","authors":["Jiachen Luo","Huy Phan","Lin Wang","Joshua D. Reiss"],"pdf_url":"https://arxiv.org/pdf/2503.05858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18978v3","updated":"2025-03-08T09:47:20Z","published":"2025-02-26T09:37:21Z","title":"Low-Confidence Gold: Refining Low-Confidence Samples for Efficient\n  Instruction Tuning","summary":"  The effectiveness of instruction fine-tuning for Large Language Models is\nfundamentally constrained by the quality and efficiency of training datasets.\nThis work introduces Low-Confidence Gold (LCG), a novel filtering framework\nthat employs centroid-based clustering and confidence-guided selection for\nidentifying valuable instruction pairs. Through a semi-supervised approach\nusing a lightweight classifier trained on representative samples, LCG curates\nhigh-quality subsets while preserving data diversity. Experimental evaluation\ndemonstrates that models fine-tuned on LCG-filtered subsets of 6K samples\nachieve superior performance compared to existing methods, with substantial\nimprovements on MT-bench and consistent gains across comprehensive evaluation\nmetrics. The framework's efficacy while maintaining model performance\nestablishes a promising direction for efficient instruction tuning.\n","authors":["Hongyi Cai","Jie Li","Wenzhen Dong"],"pdf_url":"https://arxiv.org/pdf/2502.18978v3.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2503.06139v1","updated":"2025-03-08T09:44:24Z","published":"2025-03-08T09:44:24Z","title":"GRP: Goal-Reversed Prompting for Zero-Shot Evaluation with LLMs","summary":"  Using Large Language Models (LLMs) to evaluate and compare two answers from\ndifferent models typically involves having LLM-based judges select the better\nanswer. However, humans often approach problem-solving from a reverse\nperspective, for instance, by choosing the worse option instead of the better\none in a pairwise comparison. Generally, this kind of reverse thinking plays a\ncrucial role in human reasoning and decision-making and can further test the\ndifference between original and reverse thought processes simultaneously. To\naddress the above issue, in this paper, we propose a Goal-Reversed Prompting\n(GRP) approach for pairwise evaluation that shifts the original task from\nselecting the better answer to choosing the worse one. We encourage LLMs to\nthink in reverse by prompting LLMs to identify the worse response. Experiments\non closed-source models demonstrate that GRP significantly enhances evaluation\ncapabilities, outperforming the prompt template with the original goal.\n","authors":["Mingyang Song","Mao Zheng","Xuan Luo"],"pdf_url":"https://arxiv.org/pdf/2503.06139v1.pdf","comment":"Ongoing Work"},{"id":"http://arxiv.org/abs/2502.18889v2","updated":"2025-03-08T09:24:53Z","published":"2025-02-26T07:09:33Z","title":"Clip-TTS: Contrastive Text-content and Mel-spectrogram, A High-Quality\n  Text-to-Speech Method based on Contextual Semantic Understanding","summary":"  Traditional text-to-speech (TTS) methods primarily focus on establishing a\nmapping between phonemes and mel-spectrograms. However, during the phoneme\nencoding stage, there is often a lack of real mel-spectrogram auxiliary\ninformation, which results in the encoding process lacking true semantic\nunderstanding. At the same time, traditional TTS systems often struggle to\nbalance the inference speed of the model with the quality of the synthesized\nspeech. Methods that generate high-quality synthesized speech tend to have\nslower inference speeds, while faster inference methods often sacrifice speech\nquality. In this paper, I propose Clip-TTS, a TTS method based on the Clip\narchitecture. This method uses the Clip framework to establish a connection\nbetween text content and real mel-spectrograms during the text encoding stage,\nenabling the text encoder to directly learn the true semantics of the global\ncontext, thereby ensuring the quality of the synthesized speech. In terms of\nmodel architecture, I adopt the basic structure of Transformer, which allows\nClip-TTS to achieve fast inference speeds. Experimental results show that on\nthe LJSpeech and Baker datasets, the speech generated by Clip-TTS achieves\nstate-of-the-art MOS scores, and it also performs excellently on multi-emotion\ndatasets.Audio samples are available at: https://ltydd1314.github.io/.\n","authors":["Tianyun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.18889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06137v1","updated":"2025-03-08T09:19:53Z","published":"2025-03-08T09:19:53Z","title":"Evaluating Discourse Cohesion in Pre-trained Language Models","summary":"  Large pre-trained neural models have achieved remarkable success in natural\nlanguage process (NLP), inspiring a growing body of research analyzing their\nability from different aspects. In this paper, we propose a test suite to\nevaluate the cohesive ability of pre-trained language models. The test suite\ncontains multiple cohesion phenomena between adjacent and non-adjacent\nsentences. We try to compare different pre-trained language models on these\nphenomena and analyze the experimental results,hoping more attention can be\ngiven to discourse cohesion in the future.\n","authors":["Jie He","Wanqiu Long","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.06137v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16461v2","updated":"2025-03-08T08:46:44Z","published":"2024-10-21T19:40:05Z","title":"Comparative Study of Multilingual Idioms and Similes in Large Language\n  Models","summary":"  This study addresses the gap in the literature concerning the comparative\nperformance of LLMs in interpreting different types of figurative language\nacross multiple languages. By evaluating LLMs using two multilingual datasets\non simile and idiom interpretation, we explore the effectiveness of various\nprompt engineering strategies, including chain-of-thought, few-shot, and\nEnglish translation prompts. We extend the language of these datasets to\nPersian as well by building two new evaluation sets. Our comprehensive\nassessment involves both closed-source (GPT-3.5, GPT-4o mini, Gemini 1.5), and\nopen-source models (Llama 3.1, Qwen2), highlighting significant differences in\nperformance across languages and figurative types. Our findings reveal that\nwhile prompt engineering methods are generally effective, their success varies\nby figurative type, language, and model. We also observe that open-source\nmodels struggle particularly with low-resource languages in similes.\nAdditionally, idiom interpretation is nearing saturation for many languages,\nnecessitating more challenging evaluations.\n","authors":["Paria Khoshtab","Danial Namazifard","Mostafa Masoudi","Ali Akhgary","Samin Mahdizadeh Sani","Yadollah Yaghoobzadeh"],"pdf_url":"https://arxiv.org/pdf/2410.16461v2.pdf","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.18101v2","updated":"2025-03-08T08:35:02Z","published":"2025-02-25T11:15:49Z","title":"Detecting Offensive Memes with Social Biases in Singapore Context Using\n  Multimodal Large Language Models","summary":"  Traditional online content moderation systems struggle to classify modern\nmultimodal means of communication, such as memes, a highly nuanced and\ninformation-dense medium. This task is especially hard in a culturally diverse\nsociety like Singapore, where low-resource languages are used and extensive\nknowledge on local context is needed to interpret online content. We curate a\nlarge collection of 112K memes labeled by GPT-4V for fine-tuning a VLM to\nclassify offensive memes in Singapore context. We show the effectiveness of\nfine-tuned VLMs on our dataset, and propose a pipeline containing OCR,\ntranslation and a 7-billion parameter-class VLM. Our solutions reach 80.62%\naccuracy and 0.8192 AUROC on a held-out test set, and can greatly aid human in\nmoderating online contents. The dataset, code, and model weights have been\nopen-sourced at https://github.com/aliencaocao/vlm-for-memes-aisg.\n","authors":["Cao Yuxuan","Wu Jiayang","Alistair Cheong Liang Chuen","Bryan Shan Guanrong","Theodore Lee Chong Jen","Sherman Chann Zhi Shen"],"pdf_url":"https://arxiv.org/pdf/2502.18101v2.pdf","comment":"Accepted at 3rd Workshop on Cross-Cultural Considerations in NLP\n  (C3NLP), co-located with NAACL 2025. This is an extended version with some\n  appendix moved to the main body"},{"id":"http://arxiv.org/abs/2502.07442v2","updated":"2025-03-08T08:19:36Z","published":"2025-02-11T10:37:01Z","title":"Hierarchical Document Parsing via Large Margin Feature Matching and\n  Heuristics","summary":"  We present our solution to the AAAI-25 VRD-IU challenge, achieving first\nplace in the competition. Our approach integrates large margin loss for\nimproved feature discrimination and employs heuristic rules to refine\nhierarchical relationships. By combining a deep learning-based matching\nstrategy with greedy algorithms, we achieve a significant boost in accuracy\nwhile maintaining computational efficiency. Our method attains an accuracy of\n0.98904 on the private leaderboard, demonstrating its effectiveness in document\nstructure parsing. Source codes are publicly available at\nhttps://github.com/ffyyytt/VRUID-AAAI-DAKiet\n","authors":["Duong Anh Kiet"],"pdf_url":"https://arxiv.org/pdf/2502.07442v2.pdf","comment":"DocUI@AAAI-25, 2 pages, technical report"},{"id":"http://arxiv.org/abs/2407.00342v5","updated":"2025-03-08T07:54:39Z","published":"2024-06-29T07:01:51Z","title":"KPC-cF: Aspect-Based Sentiment Analysis via Implicit-Feature Alignment\n  with Corpus Filtering","summary":"  Investigations into Aspect-Based Sentiment Analysis (ABSA) for Korean\nindustrial reviews are notably lacking in the existing literature. Our research\nproposes an intuitive and effective framework for ABSA in low-resource\nlanguages such as Korean. It optimizes prediction labels by integrating\ntranslated benchmark and unlabeled Korean data. Using a model fine-tuned on\ntranslated data, we pseudo-labeled the actual Korean NLI set. Subsequently, we\napplied LaBSE and \\MSP{}-based filtering to this pseudo-NLI set as implicit\nfeature, enhancing Aspect Category Detection and Polarity determination through\nadditional training. Incorporating dual filtering, this model bridged dataset\ngaps and facilitates feature alignment with minimal resources. By implementing\nalignment pipelines, our approach aims to leverage high-resource datasets to\ndevelop reliable predictive and refined models within corporate or individual\ncommunities in low-resource language countries. Compared to English ABSA, our\nframework showed an approximately 3\\% difference in F1 scores and accuracy. We\nwill release our dataset and code for Korean ABSA, at this link.\n","authors":["Kibeom Nam"],"pdf_url":"https://arxiv.org/pdf/2407.00342v5.pdf","comment":"Work in Progress, DMLR@ICML 2024"},{"id":"http://arxiv.org/abs/2503.06112v1","updated":"2025-03-08T07:38:51Z","published":"2025-03-08T07:38:51Z","title":"AF-KAN: Activation Function-Based Kolmogorov-Arnold Networks for\n  Efficient Representation Learning","summary":"  Kolmogorov-Arnold Networks (KANs) have inspired numerous works exploring\ntheir applications across a wide range of scientific problems, with the\npotential to replace Multilayer Perceptrons (MLPs). While many KANs are\ndesigned using basis and polynomial functions, such as B-splines, ReLU-KAN\nutilizes a combination of ReLU functions to mimic the structure of B-splines\nand take advantage of ReLU's speed. However, ReLU-KAN is not built for multiple\ninputs, and its limitations stem from ReLU's handling of negative values, which\ncan restrict feature extraction. To address these issues, we introduce\nActivation Function-Based Kolmogorov-Arnold Networks (AF-KAN), expanding\nReLU-KAN with various activations and their function combinations. This novel\nKAN also incorporates parameter reduction methods, primarily attention\nmechanisms and data normalization, to enhance performance on image\nclassification datasets. We explore different activation functions, function\ncombinations, grid sizes, and spline orders to validate the effectiveness of\nAF-KAN and determine its optimal configuration. In the experiments, AF-KAN\nsignificantly outperforms MLP, ReLU-KAN, and other KANs with the same parameter\ncount. It also remains competitive even when using fewer than 6 to 10 times the\nparameters while maintaining the same network structure. However, AF-KAN\nrequires a longer training time and consumes more FLOPs. The repository for\nthis work is available at https://github.com/hoangthangta/All-KAN.\n","authors":["Hoang-Thang Ta","Anh Tran"],"pdf_url":"https://arxiv.org/pdf/2503.06112v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.06091v1","updated":"2025-03-08T06:39:51Z","published":"2025-03-08T06:39:51Z","title":"Theta Theory: operads and coloring","summary":"  We give an explicit construction of the generating set of a colored operad\nthat implements theta theory in the mathematical model of Minimalism in\ngenerative linguistics, in the form of a coloring algorithm for syntactic\nobjects. We show that the coproduct operation on workspaces allows for a\nrecursive implementation of the theta criterion. We also show that this\nfiltering by coloring rules on structures freely formed by Merge is equivalent\nto a process of structure formation by a colored version of Merge: the form of\nthe generators of the colored operad then implies the dichotomy is semantics\nbetween External and Internal Merge, where Internal Merge only moves to\nnon-theta positions.\n","authors":["Matilde Marcolli","Richard K. Larson"],"pdf_url":"https://arxiv.org/pdf/2503.06091v1.pdf","comment":"26 pages LaTeX"},{"id":"http://arxiv.org/abs/2503.06085v1","updated":"2025-03-08T06:17:07Z","published":"2025-03-08T06:17:07Z","title":"Multi-Attribute Multi-Grained Adaptation of Pre-Trained Language Models\n  for Text Understanding from Bayesian Perspective","summary":"  Current neural networks often employ multi-domain-learning or\nattribute-injecting mechanisms to incorporate non-independent and identically\ndistributed (non-IID) information for text understanding tasks by capturing\nindividual characteristics and the relationships among samples. However, the\nextent of the impact of non-IID information and how these methods affect\npre-trained language models (PLMs) remains unclear. This study revisits the\nassumption that non-IID information enhances PLMs to achieve performance\nimprovements from a Bayesian perspective, which unearths and integrates non-IID\nand IID features. Furthermore, we proposed a multi-attribute multi-grained\nframework for PLM adaptations (M2A), which combines multi-attribute and\nmulti-grained views to mitigate uncertainty in a lightweight manner. We\nevaluate M2A through prevalent text-understanding datasets and demonstrate its\nsuperior performance, mainly when data are implicitly non-IID, and PLMs scale\nlarger.\n","authors":["You Zhang","Jin Wang","Liang-Chih Yu","Dan Xu","Xuejie Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.06085v1.pdf","comment":"Extended version accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.06076v1","updated":"2025-03-08T05:51:27Z","published":"2025-03-08T05:51:27Z","title":"An Empirical Study of Causal Relation Extraction Transfer: Design and\n  Data","summary":"  We conduct an empirical analysis of neural network architectures and data\ntransfer strategies for causal relation extraction. By conducting experiments\nwith various contextual embedding layers and architectural components, we show\nthat a relatively straightforward BioBERT-BiGRU relation extraction model\ngeneralizes better than other architectures across varying web-based sources\nand annotation strategies. Furthermore, we introduce a metric for evaluating\ntransfer performance, $F1_{phrase}$ that emphasizes noun phrase localization\nrather than directly matching target tags. Using this metric, we can conduct\ndata transfer experiments, ultimately revealing that augmentation with data\nwith varying domains and annotation styles can improve performance. Data\naugmentation is especially beneficial when an adequate proportion of implicitly\nand explicitly causal sentences are included.\n","authors":["Sydney Anuyah","Jack Vanschaik","Palak Jain","Sawyer Lehman","Sunandan Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2503.06076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06074v1","updated":"2025-03-08T05:48:58Z","published":"2025-03-08T05:48:58Z","title":"Towards Conversational AI for Disease Management","summary":"  While large language models (LLMs) have shown promise in diagnostic dialogue,\ntheir capabilities for effective management reasoning - including disease\nprogression, therapeutic response, and safe medication prescription - remain\nunder-explored. We advance the previously demonstrated diagnostic capabilities\nof the Articulate Medical Intelligence Explorer (AMIE) through a new LLM-based\nagentic system optimised for clinical management and dialogue, incorporating\nreasoning over the evolution of disease and multiple patient visit encounters,\nresponse to therapy, and professional competence in medication prescription. To\nground its reasoning in authoritative clinical knowledge, AMIE leverages\nGemini's long-context capabilities, combining in-context retrieval with\nstructured reasoning to align its output with relevant and up-to-date clinical\npractice guidelines and drug formularies. In a randomized, blinded virtual\nObjective Structured Clinical Examination (OSCE) study, AMIE was compared to 21\nprimary care physicians (PCPs) across 100 multi-visit case scenarios designed\nto reflect UK NICE Guidance and BMJ Best Practice guidelines. AMIE was\nnon-inferior to PCPs in management reasoning as assessed by specialist\nphysicians and scored better in both preciseness of treatments and\ninvestigations, and in its alignment with and grounding of management plans in\nclinical guidelines. To benchmark medication reasoning, we developed RxQA, a\nmultiple-choice question benchmark derived from two national drug formularies\n(US, UK) and validated by board-certified pharmacists. While AMIE and PCPs both\nbenefited from the ability to access external drug information, AMIE\noutperformed PCPs on higher difficulty questions. While further research would\nbe needed before real-world translation, AMIE's strong performance across\nevaluations marks a significant step towards conversational AI as a tool in\ndisease management.\n","authors":["Anil Palepu","Valentin Liévin","Wei-Hung Weng","Khaled Saab","David Stutz","Yong Cheng","Kavita Kulkarni","S. Sara Mahdavi","Joëlle Barral","Dale R. Webster","Katherine Chou","Avinatan Hassidim","Yossi Matias","James Manyika","Ryutaro Tanno","Vivek Natarajan","Adam Rodman","Tao Tu","Alan Karthikesalingam","Mike Schaekermann"],"pdf_url":"https://arxiv.org/pdf/2503.06074v1.pdf","comment":"62 pages, 7 figures in main text, 36 figures in appendix"},{"id":"http://arxiv.org/abs/2503.06073v1","updated":"2025-03-08T05:48:53Z","published":"2025-03-08T05:48:53Z","title":"GEM: Empowering MLLM for Grounded ECG Understanding with Time Series and\n  Images","summary":"  While recent multimodal large language models (MLLMs) have advanced automated\nECG interpretation, they still face two key limitations: (1) insufficient\nmultimodal synergy between time series signals and visual ECG representations,\nand (2) limited explainability in linking diagnoses to granular waveform\nevidence. We introduce GEM, the first MLLM unifying ECG time series, 12-lead\nECG images and text for grounded and clinician-aligned ECG interpretation. GEM\nenables feature-grounded analysis, evidence-driven reasoning, and a\nclinician-like diagnostic process through three core innovations: a\ndual-encoder framework extracting complementary time series and image features,\ncross-modal alignment for effective multimodal understanding, and\nknowledge-guided instruction generation for generating high-granularity\ngrounding data (ECG-Grounding) linking diagnoses to measurable parameters\n($e.g.$, QRS/PR Intervals). Additionally, we propose the Grounded ECG\nUnderstanding task, a clinically motivated benchmark designed to\ncomprehensively assess the MLLM's capability in grounded ECG understanding.\nExperimental results on both existing and our proposed benchmarks show GEM\nsignificantly improves predictive performance (CSN $7.4\\% \\uparrow$),\nexplainability ($22.7\\% \\uparrow$), and grounding ($24.8\\% \\uparrow$), making\nit more suitable for real-world clinical applications. GitHub repository:\nhttps://github.com/lanxiang1017/GEM.git\n","authors":["Xiang Lan","Feng Wu","Kai He","Qinghao Zhao","Shenda Hong","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2503.06073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06072v1","updated":"2025-03-08T05:41:42Z","published":"2025-03-08T05:41:42Z","title":"A Survey on Post-training of Large Language Models","summary":"  The emergence of Large Language Models (LLMs) has fundamentally transformed\nnatural language processing, making them indispensable across domains ranging\nfrom conversational systems to scientific exploration. However, their\npre-trained architectures often reveal limitations in specialized contexts,\nincluding restricted reasoning capacities, ethical uncertainties, and\nsuboptimal domain-specific performance. These challenges necessitate advanced\npost-training language models (PoLMs) to address these shortcomings, such as\nOpenAI-o1/o3 and DeepSeek-R1 (collectively known as Large Reasoning Models, or\nLRMs). This paper presents the first comprehensive survey of PoLMs,\nsystematically tracing their evolution across five core paradigms: Fine-tuning,\nwhich enhances task-specific accuracy; Alignment, which ensures alignment with\nhuman preferences; Reasoning, which advances multi-step inference despite\nchallenges in reward design; Efficiency, which optimizes resource utilization\namidst increasing complexity; and Integration and Adaptation, which extend\ncapabilities across diverse modalities while addressing coherence issues.\nCharting progress from ChatGPT's foundational alignment strategies to\nDeepSeek-R1's innovative reasoning advancements, we illustrate how PoLMs\nleverage datasets to mitigate biases, deepen reasoning capabilities, and\nenhance domain adaptability. Our contributions include a pioneering synthesis\nof PoLM evolution, a structured taxonomy categorizing techniques and datasets,\nand a strategic agenda emphasizing the role of LRMs in improving reasoning\nproficiency and domain flexibility. As the first survey of its scope, this work\nconsolidates recent PoLM advancements and establishes a rigorous intellectual\nframework for future research, fostering the development of LLMs that excel in\nprecision, ethical robustness, and versatility across scientific and societal\napplications.\n","authors":["Guiyao Tie","Zeli Zhao","Dingjie Song","Fuyang Wei","Rong Zhou","Yurou Dai","Wen Yin","Zhejian Yang","Jiangyue Yan","Yao Su","Zhenhan Dai","Yifeng Xie","Yihan Cao","Lichao Sun","Pan Zhou","Lifang He","Hechang Chen","Yu Zhang","Qingsong Wen","Tianming Liu","Neil Zhenqiang Gong","Jiliang Tang","Caiming Xiong","Heng Ji","Philip S. Yu","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2503.06072v1.pdf","comment":"87 pages, 21 figures, 9 tables"},{"id":"http://arxiv.org/abs/2405.15232v4","updated":"2025-03-08T05:29:51Z","published":"2024-05-24T05:46:04Z","title":"DEEM: Diffusion Models Serve as the Eyes of Large Language Models for\n  Image Perception","summary":"  The development of large language models (LLMs) has significantly advanced\nthe emergence of large multimodal models (LMMs). While LMMs have achieved\ntremendous success by promoting the synergy between multimodal comprehension\nand creation, they often face challenges when confronted with\nout-of-distribution data, such as which can hardly distinguish orientation,\nquantity, color, structure, etc. This is primarily due to their reliance on\nimage encoders trained to encode images into task-relevant features, which may\nlead them to disregard irrelevant details. Delving into the modeling\ncapabilities of diffusion models for images naturally prompts the question: Can\ndiffusion models serve as the eyes of large language models for image\nperception? In this paper, we propose DEEM, a simple but effective approach\nthat utilizes the generative feedback of diffusion models to align the semantic\ndistributions of the image encoder. This addresses the drawbacks of previous\nmethods that solely relied on image encoders like CLIP-ViT, thereby enhancing\nthe model's resilience against out-of-distribution samples and reducing visual\nhallucinations. Importantly, this is achieved without requiring additional\ntraining modules and with fewer training parameters. We extensively evaluated\nDEEM on both our newly constructed RobustVQA benchmark and other well-known\nbenchmarks, POPE and MMVP, for visual hallucination and perception. In\nparticular, DEEM improves LMM's visual perception performance to a large extent\n(e.g., 4% higher on RobustVQA, 6.5% higher on MMVP and 12.8 % higher on POPE ).\nCompared to the state-of-the-art interleaved content generation models, DEEM\nexhibits enhanced robustness and a superior capacity to alleviate model\nhallucinations while utilizing fewer trainable parameters, less pre-training\ndata (10%), and a smaller base model size.\n","authors":["Run Luo","Yunshui Li","Longze Chen","Wanwei He","Ting-En Lin","Ziqiang Liu","Lei Zhang","Zikai Song","Xiaobo Xia","Tongliang Liu","Min Yang","Binyuan Hui"],"pdf_url":"https://arxiv.org/pdf/2405.15232v4.pdf","comment":"25 pages. arXiv admin note: text overlap with arXiv:2401.10208 by\n  other authors"},{"id":"http://arxiv.org/abs/2503.06064v1","updated":"2025-03-08T05:20:52Z","published":"2025-03-08T05:20:52Z","title":"A Novel Trustworthy Video Summarization Algorithm Through a Mixture of\n  LoRA Experts","summary":"  With the exponential growth of user-generated content on video-sharing\nplatforms, the challenge of facilitating efficient searching and browsing of\nvideos has garnered significant attention. To enhance users' ability to swiftly\nlocate and review pertinent videos, the creation of concise and informative\nvideo summaries has become increasingly important. Video-llama is an effective\ntool for generating video summarization, but it cannot effectively unify and\noptimize the modeling of temporal and spatial features and requires a lot of\ncomputational resources and time. Therefore, we propose MiLoRA-ViSum to more\nefficiently capture complex temporal dynamics and spatial relationships\ninherent in video data and to control the number of parameters for training. By\nextending traditional Low-Rank Adaptation (LoRA) into a sophisticated\nmixture-of-experts paradigm, MiLoRA-ViSum incorporates a dual temporal-spatial\nadaptation mechanism tailored specifically for video summarization tasks. This\napproach dynamically integrates specialized LoRA experts, each fine-tuned to\naddress distinct temporal or spatial dimensions. Extensive evaluations of the\nVideoXum and ActivityNet datasets demonstrate that MiLoRA-ViSum achieves the\nbest summarization performance compared to state-of-the-art models, while\nmaintaining significantly lower computational costs. The proposed\nmixture-of-experts strategy, combined with the dual adaptation mechanism,\nhighlights the model's potential to enhance video summarization capabilities,\nparticularly in large-scale applications requiring both efficiency and\nprecision.\n","authors":["Wenzhuo Du","Gerun Wang","Guancheng Chen","Hang Zhao","Xin Li","Jian Gao"],"pdf_url":"https://arxiv.org/pdf/2503.06064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10868v3","updated":"2025-03-08T05:11:53Z","published":"2025-02-15T17:52:14Z","title":"NitiBench: A Comprehensive Study of LLM Framework Capabilities for Thai\n  Legal Question Answering","summary":"  The application of large language models (LLMs) in the legal domain holds\nsignificant potential for information retrieval and question answering, yet\nThai legal QA systems face challenges due to a lack of standardized evaluation\nbenchmarks and the complexity of Thai legal structures. This paper introduces\nNitiBench, a benchmark comprising two datasets: the NitiBench-CCL, covering\ngeneral Thai financial law, and the NitiBench-Tax, which includes real-world\ntax law cases requiring advanced legal reasoning. We evaluate\nretrieval-augmented generation (RAG) and long-context LLM-based approaches to\naddress three key research questions: the impact of domain-specific components\nlike section-based chunking and cross-referencing, the comparative performance\nof different retrievers and LLMs, and the viability of long-context LLMs as an\nalternative to RAG. Our results show that section-based chunking significantly\nimproves retrieval and end-to-end performance, current retrievers struggle with\ncomplex queries, and long-context LLMs still underperform RAG-based systems in\nThai legal QA. To support fair evaluation, we propose tailored multi-label\nretrieval metrics and the use of an LLM-as-judge for coverage and contradiction\ndetection method. These findings highlight the limitations of current Thai\nlegal NLP solutions and provide a foundation for future research in the field.\nWe also open-sourced our codes and dataset to available publicly.\n","authors":["Pawitsapak Akarajaradwong","Pirat Pothavorn","Chompakorn Chaksangchaichot","Panuthep Tasawong","Thitiwat Nopparatbundit","Sarana Nutanong"],"pdf_url":"https://arxiv.org/pdf/2502.10868v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06054v1","updated":"2025-03-08T04:43:01Z","published":"2025-03-08T04:43:01Z","title":"Fine-Grained Bias Detection in LLM: Enhancing detection mechanisms for\n  nuanced biases","summary":"  Recent advancements in Artificial Intelligence, particularly in Large\nLanguage Models (LLMs), have transformed natural language processing by\nimproving generative capabilities. However, detecting biases embedded within\nthese models remains a challenge. Subtle biases can propagate misinformation,\ninfluence decision-making, and reinforce stereotypes, raising ethical concerns.\nThis study presents a detection framework to identify nuanced biases in LLMs.\nThe approach integrates contextual analysis, interpretability via attention\nmechanisms, and counterfactual data augmentation to capture hidden biases\nacross linguistic contexts. The methodology employs contrastive prompts and\nsynthetic datasets to analyze model behaviour across cultural, ideological, and\ndemographic scenarios.\n  Quantitative analysis using benchmark datasets and qualitative assessments\nthrough expert reviews validate the effectiveness of the framework. Results\nshow improvements in detecting subtle biases compared to conventional methods,\nwhich often fail to highlight disparities in model responses to race, gender,\nand socio-political contexts. The framework also identifies biases arising from\nimbalances in training data and model architectures. Continuous user feedback\nensures adaptability and refinement. This research underscores the importance\nof proactive bias mitigation strategies and calls for collaboration between\npolicymakers, AI developers, and regulators. The proposed detection mechanisms\nenhance model transparency and support responsible LLM deployment in sensitive\napplications such as education, legal systems, and healthcare. Future work will\nfocus on real-time bias monitoring and cross-linguistic generalization to\nimprove fairness and inclusivity in AI-driven communication tools.\n","authors":["Suvendu Mohanty"],"pdf_url":"https://arxiv.org/pdf/2503.06054v1.pdf","comment":"Bias detection, Large Language Models, nuanced biases, fine-grained\n  mechanisms, model transparency, ethical AI"},{"id":"http://arxiv.org/abs/2503.06048v1","updated":"2025-03-08T04:22:28Z","published":"2025-03-08T04:22:28Z","title":"Constructions are Revealed in Word Distributions","summary":"  Construction grammar posits that constructions (form-meaning pairings) are\nacquired through experience with language (the distributional learning\nhypothesis). But how much information about constructions does this\ndistribution actually contain? Corpus-based analyses provide some answers, but\ntext alone cannot answer counterfactual questions about what caused a\nparticular word to occur. For that, we need computable models of the\ndistribution over strings -- namely, pretrained language models (PLMs). Here we\ntreat a RoBERTa model as a proxy for this distribution and hypothesize that\nconstructions will be revealed within it as patterns of statistical affinity.\nWe support this hypothesis experimentally: many constructions are robustly\ndistinguished, including (i) hard cases where semantically distinct\nconstructions are superficially similar, as well as (ii) schematic\nconstructions, whose \"slots\" can be filled by abstract word classes. Despite\nthis success, we also provide qualitative evidence that statistical affinity\nalone may be insufficient to identify all constructions from text. Thus,\nstatistical affinity is likely an important, but partial, signal available to\nlearners.\n","authors":["Joshua Rozner","Leonie Weissweiler","Kyle Mahowald","Cory Shain"],"pdf_url":"https://arxiv.org/pdf/2503.06048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06047v1","updated":"2025-03-08T04:17:23Z","published":"2025-03-08T04:17:23Z","title":"DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based\n  Agents in Complex Decision-Making Environments","summary":"  Large Language Model~(LLM) based agents have been increasingly popular in\nsolving complex and dynamic tasks, which requires proper evaluation systems to\nassess their capabilities. Nevertheless, existing benchmarks usually either\nfocus on single-objective tasks or use overly broad assessing metrics, failing\nto provide a comprehensive inspection of the actual capabilities of LLM-based\nagents in complicated decision-making tasks. To address these issues, we\nintroduce DSGBench, a more rigorous evaluation platform for strategic\ndecision-making. Firstly, it incorporates six complex strategic games which\nserve as ideal testbeds due to their long-term and multi-dimensional\ndecision-making demands and flexibility in customizing tasks of various\ndifficulty levels or multiple targets. Secondly, DSGBench employs a\nfine-grained evaluation scoring system which examines the decision-making\ncapabilities by looking into the performance in five specific dimensions and\noffering a comprehensive assessment in a well-designed way. Furthermore,\nDSGBench also incorporates an automated decision-tracking mechanism which\nenables in-depth analysis of agent behaviour patterns and the changes in their\nstrategies. We demonstrate the advances of DSGBench by applying it to multiple\npopular LLM-based agents and our results suggest that DSGBench provides\nvaluable insights in choosing LLM-based agents as well as improving their\nfuture development. DSGBench is available at\nhttps://github.com/DeciBrain-Group/DSGBench.\n","authors":["Wenjie Tang","Yuan Zhou","Erqiang Xu","Keyan Cheng","Minne Li","Liquan Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.06047v1.pdf","comment":"43 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2503.06040v1","updated":"2025-03-08T03:37:07Z","published":"2025-03-08T03:37:07Z","title":"Mitigating Memorization in LLMs using Activation Steering","summary":"  The memorization of training data by Large Language Models (LLMs) poses\nsignificant risks, including privacy leaks and the regurgitation of copyrighted\ncontent. Activation steering, a technique that directly intervenes in model\nactivations, has emerged as a promising approach for manipulating LLMs. In this\nwork, we explore the effectiveness of activation steering in reducing\nmemorization while preserving generalization capabilities. We conduct empirical\nevaluations using a controlled memorization benchmark of literary material and\ndemonstrate that our method successfully suppresses memorized content with\nminimal degradation in model performance in Gemma. Additionally, we analyze the\ntrade-offs between suppression effectiveness and linguistic fluency,\nhighlighting the advantages and limitations of activation-based interventions.\nOur findings contribute to ongoing efforts in developing safer and more\nprivacy-preserving LLMs by providing a practical and efficient mechanism to\nmitigate unintended memorization.\n","authors":["Manan Suri","Nishit Anand","Amisha Bhaskar"],"pdf_url":"https://arxiv.org/pdf/2503.06040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06034v1","updated":"2025-03-08T03:14:26Z","published":"2025-03-08T03:14:26Z","title":"Rank-R1: Enhancing Reasoning in LLM-based Document Rerankers via\n  Reinforcement Learning","summary":"  In this paper, we introduce Rank-R1, a novel LLM-based reranker that performs\nreasoning over both the user query and candidate documents before performing\nthe ranking task. Existing document reranking methods based on large language\nmodels (LLMs) typically rely on prompting or fine-tuning LLMs to order or label\ncandidate documents according to their relevance to a query. For Rank-R1, we\nuse a reinforcement learning algorithm along with only a small set of relevance\nlabels (without any reasoning supervision) to enhance the reasoning ability of\nLLM-based rerankers. Our hypothesis is that adding reasoning capabilities to\nthe rerankers can improve their relevance assessement and ranking capabilities.\nOur experiments on the TREC DL and BRIGHT datasets show that Rank-R1 is highly\neffective, especially for complex queries. In particular, we find that Rank-R1\nachieves effectiveness on in-domain datasets at par with that of supervised\nfine-tuning methods, but utilizing only 18\\% of the training data used by the\nfine-tuning methods. We also find that the model largely outperforms zero-shot\nand supervised fine-tuning when applied to out-of-domain datasets featuring\ncomplex queries, especially when a 14B-size model is used. Finally, we\nqualitatively observe that Rank-R1's reasoning process improves the\nexplainability of the ranking results, opening new opportunities for search\nengine results presentation and fruition.\n","authors":["Shengyao Zhuang","Xueguang Ma","Bevan Koopman","Jimmy Lin","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2503.06034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06029v1","updated":"2025-03-08T03:02:21Z","published":"2025-03-08T03:02:21Z","title":"SmartBench: Is Your LLM Truly a Good Chinese Smartphone Assistant?","summary":"  Large Language Models (LLMs) have become integral to daily life, especially\nadvancing as intelligent assistants through on-device deployment on\nsmartphones. However, existing LLM evaluation benchmarks predominantly focus on\nobjective tasks like mathematics and coding in English, which do not\nnecessarily reflect the practical use cases of on-device LLMs in real-world\nmobile scenarios, especially for Chinese users. To address these gaps, we\nintroduce SmartBench, the first benchmark designed to evaluate the capabilities\nof on-device LLMs in Chinese mobile contexts. We analyze functionalities\nprovided by representative smartphone manufacturers and divide them into five\ncategories: text summarization, text Q\\&A, information extraction, content\ncreation, and notification management, further detailed into 20 specific tasks.\nFor each task, we construct high-quality datasets comprising 50 to 200\nquestion-answer pairs that reflect everyday mobile interactions, and we develop\nautomated evaluation criteria tailored for these tasks. We conduct\ncomprehensive evaluations of on-device LLMs and MLLMs using SmartBench and also\nassess their performance after quantized deployment on real smartphone NPUs.\nOur contributions provide a standardized framework for evaluating on-device\nLLMs in Chinese, promoting further development and optimization in this\ncritical area. Code and data will be available at\nhttps://github.com/Lucky-Lance/SmartBench.\n","authors":["Xudong Lu","Haohao Gao","Renshou Wu","Shuai Ren","Xiaoxin Chen","Hongsheng Li","Fangyuan Li"],"pdf_url":"https://arxiv.org/pdf/2503.06029v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2503.06019v1","updated":"2025-03-08T02:40:29Z","published":"2025-03-08T02:40:29Z","title":"GenieBlue: Integrating both Linguistic and Multimodal Capabilities for\n  Large Language Models on Mobile Devices","summary":"  Recent advancements in Multimodal Large Language Models (MLLMs) have enabled\ntheir deployment on mobile devices. However, challenges persist in maintaining\nstrong language capabilities and ensuring hardware compatibility, both of which\nare crucial for user experience and practical deployment efficiency. In our\ndeployment process, we observe that existing MLLMs often face performance\ndegradation on pure language tasks, and the current NPU platforms on\nsmartphones do not support the MoE architecture, which is commonly used to\npreserve pure language capabilities during multimodal training. To address\nthese issues, we systematically analyze methods to maintain pure language\ncapabilities during the training of MLLMs, focusing on both training data and\nmodel architecture aspects. Based on these analyses, we propose GenieBlue, an\nefficient MLLM structural design that integrates both linguistic and multimodal\ncapabilities for LLMs on mobile devices. GenieBlue freezes the original LLM\nparameters during MLLM training to maintain pure language capabilities. It\nacquires multimodal capabilities by duplicating specific transformer blocks for\nfull fine-tuning and integrating lightweight LoRA modules. This approach\npreserves language capabilities while achieving comparable multimodal\nperformance through extensive training. Deployed on smartphone NPUs, GenieBlue\ndemonstrates efficiency and practicality for applications on mobile devices.\n","authors":["Xudong Lu","Yinghao Chen","Renshou Wu","Haohao Gao","Xi Chen","Xue Yang","Xiangyu Zhao","Aojun Zhou","Fangyuan Li","Yafei Wen","Xiaoxin Chen","Shuai Ren","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2503.06019v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2503.06011v1","updated":"2025-03-08T02:20:43Z","published":"2025-03-08T02:20:43Z","title":"Intent-Aware Self-Correction for Mitigating Social Biases in Large\n  Language Models","summary":"  Self-Correction based on feedback improves the output quality of Large\nLanguage Models (LLMs). Moreover, as Self-Correction functions like the slow\nand conscious System-2 thinking from cognitive psychology's perspective, it can\npotentially reduce LLMs' social biases. LLMs are sensitive to contextual\nambiguities and inconsistencies; therefore, explicitly communicating their\nintentions during interactions when applying Self-Correction for debiasing is\ncrucial. In this study, we demonstrate that clarifying intentions is essential\nfor effectively reducing biases in LLMs through Self-Correction. We divide the\ncomponents needed for Self-Correction into three parts: instruction, response,\nand feedback, and clarify intentions at each component. We incorporate an\nexplicit debiasing prompt to convey the intention of bias mitigation from the\ninstruction for response generation. In the response, we use Chain-of-Thought\n(CoT) to clarify the reasoning process. In the feedback, we define evaluation\naspects necessary for debiasing and propose clear feedback through multi-aspect\ncritiques and scoring. Through experiments, we demonstrate that self-correcting\nCoT responses obtained from a debiasing prompt based on multi-aspect feedback\ncan reduce biased responses more robustly and consistently than the baselines.\nWe also find the variation in debiasing efficacy when using models with\ndifferent bias levels or separating models for response and feedback\ngeneration.\n","authors":["Panatchakorn Anantaprayoon","Masahiro Kaneko","Naoaki Okazaki"],"pdf_url":"https://arxiv.org/pdf/2503.06011v1.pdf","comment":"18 pages. Under review"},{"id":"http://arxiv.org/abs/2301.10856v6","updated":"2025-03-08T01:48:44Z","published":"2023-01-25T22:27:40Z","title":"Partial Mobilization: Tracking Multilingual Information Flows Amongst\n  Russian Media Outlets and Telegram","summary":"  In response to disinformation and propaganda from Russian online media\nfollowing the invasion of Ukraine, Russian media outlets such as Russia Today\nand Sputnik News were banned throughout Europe. To maintain viewership, many of\nthese Russian outlets began to heavily promote their content on messaging\nservices like Telegram. In this work, we study how 16 Russian media outlets\ninteracted with and utilized 732 Telegram channels throughout 2022. Leveraging\nthe foundational model MPNet, DP-means clustering, and Hawkes processes, we\ntrace how narratives spread between news sites and Telegram channels. We show\nthat news outlets not only propagate existing narratives through Telegram but\nthat they source material from the messaging platform. For example, across the\nwebsites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of\narticles discussed content that originated/resulted from activity on Telegram.\nFinally, tracking the spread of individual topics, we measure the rate at which\nnews outlets and Telegram channels disseminate content within the Russian media\necosystem, finding that websites like ura.news and Telegram channels such as\n@genshab are the most effective at disseminating their content.\n","authors":["Hans W. A. Hanley","Zakir Durumeric"],"pdf_url":"https://arxiv.org/pdf/2301.10856v6.pdf","comment":"Accepted to ICWSM 2024 (ICWSM version)"},{"id":"http://arxiv.org/abs/2411.18104v3","updated":"2025-03-08T01:18:23Z","published":"2024-11-27T07:32:56Z","title":"Training and Evaluating Language Models with Template-based Data\n  Generation","summary":"  The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath.\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.18104v3.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2401.10893v4","updated":"2025-03-08T00:43:01Z","published":"2023-12-01T22:35:19Z","title":"Location Sensitive Embedding for Knowledge Graph Reasoning","summary":"  Embedding methods transform the knowledge graph into a continuous,\nlow-dimensional space, facilitating inference and completion tasks. Existing\nmethods are mainly divided into two types: translational distance models and\nsemantic matching models. A key challenge in translational distance models is\ntheir inability to effectively differentiate between 'head' and 'tail' entities\nin graphs. To address this problem, a novel location-sensitive embedding (LSE)\nmethod has been developed. LSE innovatively modifies the head entity using\nrelation-specific mappings, conceptualizing relations as linear transformations\nrather than mere translations. The theoretical foundations of LSE, including\nits representational capabilities and its connections to existing models, have\nbeen thoroughly examined. A more streamlined variant, LSEd, which employs a\ndiagonal matrix for transformations to enhance practical efficiency, is also\nproposed. Experiments conducted on four large-scale KG datasets for link\nprediction show that LSEd either outperforms or is competitive with\nstate-of-the-art related works.\n","authors":["Deepak Banerjee","Anjali Ishaan"],"pdf_url":"https://arxiv.org/pdf/2401.10893v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05992v1","updated":"2025-03-08T00:23:13Z","published":"2025-03-08T00:23:13Z","title":"Psycholinguistic Analyses in Software Engineering Text: A Systematic\n  Literature Review","summary":"  Context: A deeper understanding of human factors in software engineering (SE)\nis essential for improving team collaboration, decision-making, and\nproductivity. Communication channels like code reviews and chats provide\ninsights into developers' psychological and emotional states. While large\nlanguage models excel at text analysis, they often lack transparency and\nprecision. Psycholinguistic tools like Linguistic Inquiry and Word Count (LIWC)\noffer clearer, interpretable insights into cognitive and emotional processes\nexhibited in text. Despite its wide use in SE research, no comprehensive review\nof LIWC's use has been conducted. Objective: We examine the importance of\npsycholinguistic tools, particularly LIWC, and provide a thorough analysis of\nits current and potential future applications in SE research. Methods: We\nconducted a systematic review of six prominent databases, identifying 43\nSE-related papers using LIWC. Our analysis focuses on five research questions.\nResults: Our findings reveal a wide range of applications, including analyzing\nteam communication to detect developer emotions and personality, developing ML\nmodels to predict deleted Stack Overflow posts, and more recently comparing\nAI-generated and human-written text. LIWC has been primarily used with data\nfrom project management platforms (e.g., GitHub) and Q&A forums (e.g., Stack\nOverflow). Key BSE concepts include Communication, Organizational Climate, and\nPositive Psychology. 26 of 43 papers did not formally evaluate LIWC. Concerns\nwere raised about some limitations, including difficulty handling SE-specific\nvocabulary. Conclusion: We highlight the potential of psycholinguistic tools\nand their limitations, and present new use cases for advancing the research of\nhuman factors in SE (e.g., bias in human-LLM conversations).\n","authors":["Amirali Sajadi","Kostadin Damevski","Preetha Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2503.05992v1.pdf","comment":null}]},"2025-03-11T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.04986v3","updated":"2025-03-11T17:59:31Z","published":"2024-11-07T18:55:09Z","title":"The Semantic Hub Hypothesis: Language Models Share Semantic\n  Representations Across Languages and Modalities","summary":"  Modern language models can process inputs across diverse languages and\nmodalities. We hypothesize that models acquire this capability through learning\na shared representation space across heterogeneous data types (e.g., different\nlanguages and modalities), which places semantically similar inputs near one\nanother, even if they are from different modalities/languages. We term this the\nsemantic hub hypothesis, following the hub-and-spoke model from neuroscience\n(Patterson et al., 2007) which posits that semantic knowledge in the human\nbrain is organized through a transmodal semantic \"hub\" which integrates\ninformation from various modality-specific \"spokes\" regions. We first show that\nmodel representations for semantically equivalent inputs in different languages\nare similar in the intermediate layers, and that this space can be interpreted\nusing the model's dominant pretraining language via the logit lens. This\ntendency extends to other data types, including arithmetic expressions, code,\nand visual/audio inputs. Interventions in the shared representation space in\none data type also predictably affect model outputs in other data types,\nsuggesting that this shared representations space is not simply a vestigial\nbyproduct of large-scale training on broad data, but something that is actively\nutilized by the model during input processing.\n","authors":["Zhaofeng Wu","Xinyan Velocity Yu","Dani Yogatama","Jiasen Lu","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2411.04986v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08684v1","updated":"2025-03-11T17:59:00Z","published":"2025-03-11T17:59:00Z","title":"Perplexity Trap: PLM-Based Retrievers Overrate Low Perplexity Documents","summary":"  Previous studies have found that PLM-based retrieval models exhibit a\npreference for LLM-generated content, assigning higher relevance scores to\nthese documents even when their semantic quality is comparable to human-written\nones. This phenomenon, known as source bias, threatens the sustainable\ndevelopment of the information access ecosystem. However, the underlying causes\nof source bias remain unexplored. In this paper, we explain the process of\ninformation retrieval with a causal graph and discover that PLM-based\nretrievers learn perplexity features for relevance estimation, causing source\nbias by ranking the documents with low perplexity higher. Theoretical analysis\nfurther reveals that the phenomenon stems from the positive correlation between\nthe gradients of the loss functions in language modeling task and retrieval\ntask. Based on the analysis, a causal-inspired inference-time debiasing method\nis proposed, called Causal Diagnosis and Correction (CDC). CDC first diagnoses\nthe bias effect of the perplexity and then separates the bias effect from the\noverall estimated relevance score. Experimental results across three domains\ndemonstrate the superior debiasing effectiveness of CDC, emphasizing the\nvalidity of our proposed explanatory framework. Source codes are available at\nhttps://github.com/WhyDwelledOnAi/Perplexity-Trap.\n","authors":["Haoyu Wang","Sunhao Dai","Haiyuan Zhao","Liang Pang","Xiao Zhang","Gang Wang","Zhenhua Dong","Jun Xu","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.08684v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08681v1","updated":"2025-03-11T17:57:44Z","published":"2025-03-11T17:57:44Z","title":"Self-Taught Self-Correction for Small Language Models","summary":"  Although large language models (LLMs) have achieved remarkable performance\nacross various tasks, they remain prone to errors. A key challenge is enabling\nthem to self-correct. While prior research has relied on external tools or\nlarge proprietary models, this work explores self-correction in small language\nmodels (SLMs) through iterative fine-tuning using solely self-generated data.\nWe introduce the Self-Taught Self-Correction (STaSC) algorithm, which\nincorporates multiple algorithmic design choices. Experimental results on a\nquestion-answering task demonstrate that STaSC effectively learns\nself-correction, leading to significant performance improvements. Our analysis\nfurther provides insights into the mechanisms of self-correction and the impact\nof different design choices on learning dynamics and overall performance. To\nsupport future research, we release our user-friendly codebase and lightweight\nmodels.\n","authors":["Viktor Moskvoretskii","Chris Biemann","Irina Nikishina"],"pdf_url":"https://arxiv.org/pdf/2503.08681v1.pdf","comment":"Code is available at https://github.com/VityaVitalich/STASC"},{"id":"http://arxiv.org/abs/2503.08679v1","updated":"2025-03-11T17:56:30Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal concerning rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (30.6%), DeepSeek R1 (15.8%) and\nChatGPT-4o (12.6%) all answer a high proportion of question pairs unfaithfully.\nSpecifically, we find that models rationalize their implicit biases in answers\nto binary questions (\"implicit post-hoc rationalization\"). For example, when\nseparately presented with the questions \"Is X bigger than Y?\" and \"Is Y bigger\nthan X?\", models sometimes produce superficially coherent arguments to justify\nanswering Yes to both questions or No to both questions, despite such responses\nbeing logically contradictory. We also investigate restoration errors (Dziri et\nal., 2023), where models make and then silently correct errors in their\nreasoning, and unfaithful shortcuts, where models use clearly illogical\nreasoning to simplify solving problems in Putnam questions (a hard benchmark).\nOur findings raise challenges for AI safety work that relies on monitoring CoT\nto detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v1.pdf","comment":"Accepted to the ICLR 2025 Workshop, 10 main paper pages, 38 appendix\n  pages"},{"id":"http://arxiv.org/abs/2503.08669v1","updated":"2025-03-11T17:53:02Z","published":"2025-03-11T17:53:02Z","title":"AgentOrca: A Dual-System Framework to Evaluate Language Agents on\n  Operational Routine and Constraint Adherence","summary":"  As language agents progressively automate critical tasks across domains,\ntheir ability to operate within operational constraints and safety protocols\nbecomes essential. While extensive research has demonstrated these agents'\neffectiveness in downstream task completion, their reliability in following\noperational procedures and constraints remains largely unexplored. To this end,\nwe present AgentOrca, a dual-system framework for evaluating language agents'\ncompliance with operational constraints and routines. Our framework encodes\naction constraints and routines through both natural language prompts for\nagents and corresponding executable code serving as ground truth for automated\nverification. Through an automated pipeline of test case generation and\nevaluation across five real-world domains, we quantitatively assess current\nlanguage agents' adherence to operational constraints. Our findings reveal\nnotable performance gaps among state-of-the-art models, with large reasoning\nmodels like o1 demonstrating superior compliance while others show\nsignificantly lower performance, particularly when encountering complex\nconstraints or user persuasion attempts.\n","authors":["Zekun Li","Shinda Huang","Jiangtian Wang","Nathan Zhang","Antonis Antoniades","Wenyue Hua","Kaijie Zhu","Sirui Zeng","William Yang Wang","Xifeng Yan"],"pdf_url":"https://arxiv.org/pdf/2503.08669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08662v1","updated":"2025-03-11T17:50:44Z","published":"2025-03-11T17:50:44Z","title":"Exploring the Word Sense Disambiguation Capabilities of Large Language\n  Models","summary":"  Word Sense Disambiguation (WSD) is a historical task in computational\nlinguistics that has received much attention over the years. However, with the\nadvent of Large Language Models (LLMs), interest in this task (in its classical\ndefinition) has decreased. In this study, we evaluate the performance of\nvarious LLMs on the WSD task. We extend a previous benchmark (XL-WSD) to\nre-design two subtasks suitable for LLM: 1) given a word in a sentence, the LLM\nmust generate the correct definition; 2) given a word in a sentence and a set\nof predefined meanings, the LLM must select the correct one. The extended\nbenchmark is built using the XL-WSD and BabelNet. The results indicate that\nLLMs perform well in zero-shot learning but cannot surpass current\nstate-of-the-art methods. However, a fine-tuned model with a medium number of\nparameters outperforms all other models, including the state-of-the-art.\n","authors":["Pierpaolo Basile","Lucia Siciliani","Elio Musacchio","Giovanni Semeraro"],"pdf_url":"https://arxiv.org/pdf/2503.08662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06759v3","updated":"2025-03-11T17:37:30Z","published":"2025-02-10T18:38:57Z","title":"Rationalization Models for Text-to-SQL","summary":"  We introduce a framework for generating Chain-of-Thought (CoT) rationales to\nenhance text-to-SQL model fine-tuning. These rationales consist of intermediate\nSQL statements and explanations, serving as incremental steps toward\nconstructing the final SQL query. The process begins with manually annotating a\nsmall set of examples, which are then used to prompt a large language model in\nan iterative, dynamic few-shot knowledge distillation procedure from a teacher\nmodel. A rationalization model is subsequently trained on the validated\ndecomposed queries, enabling extensive synthetic CoT annotations for\ntext-to-SQL datasets. To evaluate the approach, we fine-tune small language\nmodels with and without these rationales on the BIRD dataset. Results indicate\nthat step-by-step query generation improves execution accuracy, especially for\nmoderately and highly complex queries, while also enhancing explainability.\n","authors":["Gaetano Rossiello","Nhan Pham","Michael Glass","Junkyu Lee","Dharmashankar Subramanian"],"pdf_url":"https://arxiv.org/pdf/2502.06759v3.pdf","comment":"Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs"},{"id":"http://arxiv.org/abs/2503.08644v1","updated":"2025-03-11T17:36:53Z","published":"2025-03-11T17:36:53Z","title":"Exploiting Instruction-Following Retrievers for Malicious Information\n  Retrieval","summary":"  Instruction-following retrievers have been widely adopted alongside LLMs in\nreal-world applications, but little work has investigated the safety risks\nsurrounding their increasing search capabilities. We empirically study the\nability of retrievers to satisfy malicious queries, both when used directly and\nwhen used in a retrieval augmented generation-based setup. Concretely, we\ninvestigate six leading retrievers, including NV-Embed and LLM2Vec, and find\nthat given malicious requests, most retrievers can (for >50% of queries) select\nrelevant harmful passages. For example, LLM2Vec correctly selects passages for\n61.35% of our malicious queries. We further uncover an emerging risk with\ninstruction-following retrievers, where highly relevant harmful information can\nbe surfaced by exploiting their instruction-following capabilities. Finally, we\nshow that even safety-aligned LLMs, such as Llama3, can satisfy malicious\nrequests when provided with harmful retrieved passages in-context. In summary,\nour findings underscore the malicious misuse risks associated with increasing\nretriever capability.\n","authors":["Parishad BehnamGhader","Nicholas Meade","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2503.08644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05891v2","updated":"2025-03-11T17:33:51Z","published":"2025-03-07T19:24:59Z","title":"MastermindEval: A Simple But Scalable Reasoning Benchmark","summary":"  Recent advancements in large language models (LLMs) have led to remarkable\nperformance across a wide range of language understanding and mathematical\ntasks. As a result, increasing attention has been given to assessing the true\nreasoning capabilities of LLMs, driving research into commonsense, numerical,\nlogical, and qualitative reasoning. However, with the rapid progress of\nreasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been\na growing demand for reasoning benchmarks that can keep pace with ongoing model\ndevelopments. In this paper, we introduce MastermindEval, a simple, scalable,\nand interpretable deductive reasoning benchmark inspired by the board game\nMastermind. Our benchmark supports two evaluation paradigms: (1) agentic\nevaluation, in which the model autonomously plays the game, and (2) deductive\nreasoning evaluation, in which the model is given a pre-played game state with\nonly one possible valid code to infer. In our experimental results we (1) find\nthat even easy Mastermind instances are difficult for current models and (2)\ndemonstrate that the benchmark is scalable to possibly more advanced models in\nthe future Furthermore, we investigate possible reasons why models cannot\ndeduce the final solution and find that current models are limited in deducing\nthe concealed code as the number of statement to combine information from is\nincreasing.\n","authors":["Jonas Golde","Patrick Haller","Fabio Barth","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2503.05891v2.pdf","comment":"9 pages, 2 figures, 4 tables. In: ICLR 2025 Workshop on Reasoning and\n  Planning for Large Language Models"},{"id":"http://arxiv.org/abs/2502.17591v2","updated":"2025-03-11T17:32:22Z","published":"2025-02-24T19:16:39Z","title":"Proactive Privacy Amnesia for Large Language Models: Safeguarding PII\n  with Negligible Impact on Model Utility","summary":"  With the rise of large language models (LLMs), increasing research has\nrecognized their risk of leaking personally identifiable information (PII)\nunder malicious attacks. Although efforts have been made to protect PII in\nLLMs, existing methods struggle to balance privacy protection with maintaining\nmodel utility. In this paper, inspired by studies of amnesia in cognitive\nscience, we propose a novel approach, Proactive Privacy Amnesia (PPA), to\nsafeguard PII in LLMs while preserving their utility. This mechanism works by\nactively identifying and forgetting key memories most closely associated with\nPII in sequences, followed by a memory implanting using suitable substitute\nmemories to maintain the LLM's functionality. We conduct evaluations across\nmultiple models to protect common PII, such as phone numbers and physical\naddresses, against prevalent PII-targeted attacks, demonstrating the\nsuperiority of our method compared with other existing defensive techniques.\nThe results show that our PPA method completely eliminates the risk of phone\nnumber exposure by 100% and significantly reduces the risk of physical address\nexposure by 9.8% - 87.6%, all while maintaining comparable model utility\nperformance.\n","authors":["Martin Kuo","Jingyang Zhang","Jianyi Zhang","Minxue Tang","Louis DiValentin","Aolin Ding","Jingwei Sun","William Chen","Amin Hass","Tianlong Chen","Yiran Chen","Hai Li"],"pdf_url":"https://arxiv.org/pdf/2502.17591v2.pdf","comment":"ICLR'25 Poster. Project page and code is available at\n  https://ppa-iclr2025.my.canva.site/"},{"id":"http://arxiv.org/abs/2503.08640v1","updated":"2025-03-11T17:30:58Z","published":"2025-03-11T17:30:58Z","title":"Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse\n  Attention","summary":"  Many-shot in-context learning has recently shown promise as an alternative to\nfinetuning, with the major advantage that the same model can be served for\nmultiple tasks. However, this shifts the computational burden from\ntraining-time to inference-time, making deployment of many-shot ICL challenging\nto justify in-practice. This cost is further increased if a custom\ndemonstration set is retrieved for each inference example. We present Dynamic\nBlock-Sparse Attention, a training-free framework for retrieval-based many-shot\nin-context learning. By combining carefully designed block-sparse attention and\nretrieval of cached groups of demonstrations, we achieve comparable per-example\nlatency to finetuning while maintaining on average >95% of the best method's\naccuracy across strong ICL and finetuning baselines. We hope that this will\nfurther enable the deployment of many-shot ICL at scale.\n","authors":["Emily Xiao","Chin-Jou Li","Yilin Zhang","Graham Neubig","Amanda Bertsch"],"pdf_url":"https://arxiv.org/pdf/2503.08640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07072v3","updated":"2025-03-11T17:08:05Z","published":"2025-02-10T22:07:02Z","title":"IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large\n  Language Models","summary":"  Not a day goes by without hearing about the impressive feats of large\nlanguage models (LLMs), and equally, not a day passes without hearing about\ntheir challenges. LLMs are notoriously vulnerable to biases in their dataset,\nleading to issues such as toxicity. While domain-adaptive training has been\nemployed to mitigate these issues, these techniques often address all model\nparameters indiscriminately during the repair process, resulting in poor repair\nquality and reduced model versatility. In this paper, we introduce a novel\ndynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach\nselectively targets the most error-prone sections of the model for repair.\nSpecifically, we propose dynamically slicing the model's most sensitive layers\nthat require immediate attention, concentrating repair efforts on those areas.\nThis method enables more effective repairs with potentially less impact on the\nmodel's overall performance by altering a smaller portion of the model. We\nevaluated our technique on three models from the GPT2 and GPT-Neo families,\nwith parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our\nresults show that IRepair repairs errors 43.6% more effectively while causing\n46% less disruption to general performance compared to the closest baseline,\ndirect preference optimization. Our empirical analysis also reveals that errors\nare more concentrated in a smaller section of the model, with the top 20% of\nlayers exhibiting 773% more error density than the remaining 80\\%. This\nhighlights the need for selective repair. Additionally, we demonstrate that a\ndynamic selection approach is essential for addressing errors dispersed\nthroughout the model, ensuring a robust and efficient repair.\n","authors":["Sayem Mohammad Imtiaz","Astha Singh","Fraol Batole","Hridesh Rajan"],"pdf_url":"https://arxiv.org/pdf/2502.07072v3.pdf","comment":"Accepted as full research paper at FSE'2025"},{"id":"http://arxiv.org/abs/2411.07521v4","updated":"2025-03-11T16:55:48Z","published":"2024-11-12T03:37:53Z","title":"Fair Summarization: Bridging Quality and Diversity in Extractive\n  Summaries","summary":"  Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. Our code\nis available online.\n","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.07521v4.pdf","comment":"Accepted at AFLME@NeurIPS 2024 & C3NLP@NAACL 2025"},{"id":"http://arxiv.org/abs/2412.20504v3","updated":"2025-03-11T16:35:59Z","published":"2024-12-29T15:42:24Z","title":"ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video\n  Understanding","summary":"  Video Large Language Models (VideoLLMs) have achieved remarkable progress in\nvideo understanding. However, existing VideoLLMs often inherit the limitations\nof their backbone LLMs in handling long sequences, leading to challenges for\nlong video understanding. Common solutions either simply uniformly sample\nvideos' frames or compress visual tokens, which focus primarily on low-level\ntemporal visual redundancy, overlooking high-level knowledge redundancy. This\nlimits the achievable compression rate with minimal loss. To this end. we\nintroduce a training-free method, $\\textbf{ReTaKe}$, containing two novel\nmodules DPSelect and PivotKV, to jointly model and reduce both temporal visual\nredundancy and knowledge redundancy for long video understanding. Specifically,\nDPSelect identifies keyframes with local maximum peak distance based on their\nvisual features, which are closely aligned with human video perception. PivotKV\nemploys the obtained keyframes as pivots and conducts KV-Cache compression for\nthe non-pivot tokens with low attention scores, which are derived from the\nlearned prior knowledge of LLMs. Experiments on benchmarks VideoMME, MLVU, and\nLVBench, show that ReTaKe can support 4x longer video sequences with minimal\nperformance loss (<1%) and outperform all similar-size VideoLLMs with 3%-5%,\neven surpassing or on par with much larger ones. Our code is available at\nhttps://github.com/SCZwangxiao/video-ReTaKe\n","authors":["Xiao Wang","Qingyi Si","Jianlong Wu","Shiyu Zhu","Li Cao","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2412.20504v3.pdf","comment":"Rewrite the methods section. Add more ablation studies and results in\n  LongVideoBench"},{"id":"http://arxiv.org/abs/2503.08600v1","updated":"2025-03-11T16:35:08Z","published":"2025-03-11T16:35:08Z","title":"NSF-SciFy: Mining the NSF Awards Database for Scientific Claims","summary":"  We present NSF-SciFy, a large-scale dataset for scientific claim extraction\nderived from the National Science Foundation (NSF) awards database, comprising\nover 400K grant abstracts spanning five decades. While previous datasets relied\non published literature, we leverage grant abstracts which offer a unique\nadvantage: they capture claims at an earlier stage in the research lifecycle\nbefore publication takes effect. We also introduce a new task to distinguish\nbetween existing scientific claims and aspirational research intentions in\nproposals.Using zero-shot prompting with frontier large language models, we\njointly extract 114K scientific claims and 145K investigation proposals from\n16K grant abstracts in the materials science domain to create a focused subset\ncalled NSF-SciFy-MatSci. We use this dataset to evaluate 3 three key tasks: (1)\ntechnical to non-technical abstract generation, where models achieve high\nBERTScore (0.85+ F1); (2) scientific claim extraction, where fine-tuned models\noutperform base models by 100% relative improvement; and (3) investigation\nproposal extraction, showing 90%+ improvement with fine-tuning. We introduce\nnovel LLM-based evaluation metrics for robust assessment of claim/proposal\nextraction quality. As the largest scientific claim dataset to date -- with an\nestimated 2.8 million claims across all STEM disciplines funded by the NSF --\nNSF-SciFy enables new opportunities for claim verification and meta-scientific\nresearch. We publicly release all datasets, trained models, and evaluation code\nto facilitate further research.\n","authors":["Delip Rao","Weiqiu You","Eric Wong","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2503.08600v1.pdf","comment":"11 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.08588v1","updated":"2025-03-11T16:25:36Z","published":"2025-03-11T16:25:36Z","title":"BiasEdit: Debiasing Stereotyped Language Models via Model Editing","summary":"  Previous studies have established that language models manifest stereotyped\nbiases. Existing debiasing strategies, such as retraining a model with\ncounterfactual data, representation projection, and prompting often fail to\nefficiently eliminate bias or directly alter the models' biased internal\nrepresentations. To address these issues, we propose BiasEdit, an efficient\nmodel editing method to remove stereotypical bias from language models through\nlightweight networks that act as editors to generate parameter updates.\nBiasEdit employs a debiasing loss guiding editor networks to conduct local\nedits on partial parameters of a language model for debiasing while preserving\nthe language modeling abilities during editing through a retention loss.\nExperiments on StereoSet and Crows-Pairs demonstrate the effectiveness,\nefficiency, and robustness of BiasEdit in eliminating bias compared to\ntangental debiasing baselines and little to no impact on the language models'\ngeneral capabilities. In addition, we conduct bias tracing to probe bias in\nvarious modules and explore bias editing impacts on different components of\nlanguage models.\n","authors":["Xin Xu","Wei Xu","Ningyu Zhang","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2503.08588v1.pdf","comment":"Accepted by TrustNLP @ NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08569v1","updated":"2025-03-11T15:59:43Z","published":"2025-03-11T15:59:43Z","title":"DeepReview: Improving LLM-based Paper Review with Human-like Deep\n  Thinking Process","summary":"  Large Language Models (LLMs) are increasingly utilized in scientific research\nassessment, particularly in automated paper review. However, existing LLM-based\nreview systems face significant challenges, including limited domain expertise,\nhallucinated reasoning, and a lack of structured evaluation. To address these\nlimitations, we introduce DeepReview, a multi-stage framework designed to\nemulate expert reviewers by incorporating structured analysis, literature\nretrieval, and evidence-based argumentation. Using DeepReview-13K, a curated\ndataset with structured annotations, we train DeepReviewer-14B, which\noutperforms CycleReviewer-70B with fewer tokens. In its best mode,\nDeepReviewer-14B achieves win rates of 88.21\\% and 80.20\\% against GPT-o1 and\nDeepSeek-R1 in evaluations. Our work sets a new benchmark for LLM-based paper\nreview, with all resources publicly available. The code, model, dataset and\ndemo have be released in http://ai-researcher.net.\n","authors":["Minjun Zhu","Yixuan Weng","Linyi Yang","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18203v4","updated":"2025-03-11T15:46:15Z","published":"2024-11-27T10:28:57Z","title":"Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning","summary":"  Vision-language models (VLMs) have shown remarkable advancements in\nmultimodal reasoning tasks. However, they still often generate inaccurate or\nirrelevant responses due to issues like hallucinated image understandings or\nunrefined reasoning paths. To address these challenges, we introduce Critic-V,\na novel framework inspired by the Actor-Critic paradigm to boost the reasoning\ncapability of VLMs. This framework decouples the reasoning process and critic\nprocess by integrating two independent components: the Reasoner, which\ngenerates reasoning paths based on visual and textual inputs, and the Critic,\nwhich provides constructive critique to refine these paths. In this approach,\nthe Reasoner generates reasoning responses according to text prompts, which can\nevolve iteratively as a policy based on feedback from the Critic. This\ninteraction process was theoretically driven by a reinforcement learning\nframework where the Critic offers natural language critiques instead of scalar\nrewards, enabling more nuanced feedback to boost the Reasoner's capability on\ncomplex reasoning tasks. The Critic model is trained using Direct Preference\nOptimization (DPO), leveraging a preference dataset of critiques ranked by\nRule-based Reward~(RBR) to enhance its critic capabilities. Evaluation results\nshow that the Critic-V framework significantly outperforms existing methods,\nincluding GPT-4V, on 5 out of 8 benchmarks, especially regarding reasoning\naccuracy and efficiency. Combining a dynamic text-based policy for the Reasoner\nand constructive feedback from the preference-optimized Critic enables a more\nreliable and context-sensitive multimodal reasoning process. Our approach\nprovides a promising solution to enhance the reliability of VLMs, improving\ntheir performance in real-world reasoning-heavy multimodal applications such as\nautonomous driving and embodied intelligence.\n","authors":["Di Zhang","Junxian Li","Jingdi Lei","Xunzhi Wang","Yujie Liu","Zonglin Yang","Jiatong Li","Weida Wang","Suorong Yang","Jianbo Wu","Peng Ye","Wanli Ouyang","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.18203v4.pdf","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.08550v1","updated":"2025-03-11T15:36:41Z","published":"2025-03-11T15:36:41Z","title":"Transferring Extreme Subword Style Using Ngram Model-Based Logit Scaling","summary":"  We present an ngram model-based logit scaling technique that effectively\ntransfers extreme subword stylistic variation to large language models at\ninference time. We demonstrate its efficacy by tracking the perplexity of\ngenerated text with respect to the ngram interpolated and original versions of\nan evaluation model. Minimizing the former measure while the latter approaches\nthe perplexity of a text produced by a target author or character lets us\nselect a sufficient degree of adaptation while retaining fluency.\n","authors":["Craig Messner","Tom Lippincott"],"pdf_url":"https://arxiv.org/pdf/2503.08550v1.pdf","comment":"Accepted for publication at NLP4DH 2025 @ NAACL"},{"id":"http://arxiv.org/abs/2503.02854v2","updated":"2025-03-11T15:36:40Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v2.pdf","comment":"21 pages, 17 figures, 1 table. Code:\n  http://github.com/belindal/state-tracking"},{"id":"http://arxiv.org/abs/2503.08549v1","updated":"2025-03-11T15:36:38Z","published":"2025-03-11T15:36:38Z","title":"Graph of AI Ideas: Leveraging Knowledge Graphs and LLMs for AI Research\n  Idea Generation","summary":"  Reading relevant scientific papers and analyzing research development trends\nis a critical step in generating new scientific ideas. However, the rapid\nincrease in the volume of research literature and the complex citation\nrelationships make it difficult for researchers to quickly analyze and derive\nmeaningful research trends. The development of large language models (LLMs) has\nprovided a novel approach for automatically summarizing papers and generating\ninnovative research ideas. However, existing paper-based idea generation\nmethods either simply input papers into LLMs via prompts or form logical chains\nof creative development based on citation relationships, without fully\nexploiting the semantic information embedded in these citations. Inspired by\nknowledge graphs and human cognitive processes, we propose a framework called\nthe Graph of AI Ideas (GoAI) for the AI research field, which is dominated by\nopen-access papers. This framework organizes relevant literature into entities\nwithin a knowledge graph and summarizes the semantic information contained in\ncitations into relations within the graph. This organization effectively\nreflects the relationships between two academic papers and the advancement of\nthe AI research field. Such organization aids LLMs in capturing the current\nprogress of research, thereby enhancing their creativity. Experimental results\ndemonstrate the effectiveness of our approach in generating novel, clear, and\neffective research ideas.\n","authors":["Xian Gao","Zongyun Zhang","Mingye Xie","Ting Liu","Yuzhuo Fu"],"pdf_url":"https://arxiv.org/pdf/2503.08549v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.08542v1","updated":"2025-03-11T15:29:55Z","published":"2025-03-11T15:29:55Z","title":"DAFE: LLM-Based Evaluation Through Dynamic Arbitration for Free-Form\n  Question-Answering","summary":"  Evaluating Large Language Models (LLMs) free-form generated responses remains\na challenge due to their diverse and open-ended nature. Traditional supervised\nsignal-based automatic metrics fail to capture semantic equivalence or handle\nthe variability of open-ended responses, while human evaluation, though\nreliable, is resource-intensive. Leveraging LLMs as evaluators offers a\npromising alternative due to their strong language understanding and\ninstruction-following capabilities. Taking advantage of these capabilities, we\npropose the Dynamic Arbitration Framework for Evaluation (DAFE), which employs\ntwo primary LLM-as-judges and engages a third arbitrator only in cases of\ndisagreements. This selective arbitration prioritizes evaluation reliability\nwhile reducing unnecessary computational demands compared to conventional\nmajority voting. DAFE utilizes task-specific reference answers with dynamic\narbitration to enhance judgment accuracy, resulting in significant improvements\nin evaluation metrics such as Macro F1 and Cohen's Kappa. Through experiments,\nincluding a comprehensive human evaluation, we demonstrate DAFE's ability to\nprovide consistent, scalable, and resource-efficient assessments, establishing\nit as a robust framework for evaluating free-form model outputs.\n","authors":["Sher Badshah","Hassan Sajjad"],"pdf_url":"https://arxiv.org/pdf/2503.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15969v2","updated":"2025-03-11T15:28:50Z","published":"2025-02-21T22:04:09Z","title":"Forgotten Polygons: Multimodal Large Language Models are Shape-Blind","summary":"  Despite strong performance on vision-language tasks, Multimodal Large\nLanguage Models (MLLMs) struggle with mathematical problem-solving, with both\nopen-source and state-of-the-art models falling short of human performance on\nvisual-math benchmarks. To systematically examine visual-mathematical reasoning\nin MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test\nmulti-step reasoning, and (3) explore a potential solution to improve visual\nreasoning capabilities. Our findings reveal fundamental shortcomings in shape\nrecognition, with top models achieving under 50% accuracy in identifying\nregular polygons. We analyze these failures through the lens of dual-process\ntheory and show that MLLMs rely on System 1 (intuitive, memorized associations)\nrather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count\nthe sides of both familiar and novel shapes, suggesting they have neither\nlearned the concept of sides nor effectively process visual inputs. Finally, we\npropose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances\nmulti-step mathematical reasoning by explicitly referencing visual annotations\nin diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting\ntask from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs\nremains an open problem, and visually-guided prompting is essential for\nsuccessfully engaging visual reasoning. Code available at:\nhttps://github.com/rsinghlab/Shape-Blind.\n","authors":["William Rudman","Michal Golovanesky","Amir Bar","Vedant Palit","Yann LeCun","Carsten Eickhoff","Ritambhara Singh"],"pdf_url":"https://arxiv.org/pdf/2502.15969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08533v1","updated":"2025-03-11T15:24:02Z","published":"2025-03-11T15:24:02Z","title":"ESPnet-SDS: Unified Toolkit and Demo for Spoken Dialogue Systems","summary":"  Advancements in audio foundation models (FMs) have fueled interest in\nend-to-end (E2E) spoken dialogue systems, but different web interfaces for each\nsystem makes it challenging to compare and contrast them effectively. Motivated\nby this, we introduce an open-source, user-friendly toolkit designed to build\nunified web interfaces for various cascaded and E2E spoken dialogue systems.\nOur demo further provides users with the option to get on-the-fly automated\nevaluation metrics such as (1) latency, (2) ability to understand user input,\n(3) coherence, diversity, and relevance of system response, and (4)\nintelligibility and audio quality of system output. Using the evaluation\nmetrics, we compare various cascaded and E2E spoken dialogue systems with a\nhuman-human conversation dataset as a proxy. Our analysis demonstrates that the\ntoolkit allows researchers to effortlessly compare and contrast different\ntechnologies, providing valuable insights such as current E2E systems having\npoorer audio quality and less diverse responses. An example demo produced using\nour toolkit is publicly available here:\nhttps://huggingface.co/spaces/Siddhant/Voice_Assistant_Demo.\n","authors":["Siddhant Arora","Yifan Peng","Jiatong Shi","Jinchuan Tian","William Chen","Shikhar Bharadwaj","Hayato Futami","Yosuke Kashiwagi","Emiru Tsunoo","Shuichiro Shimizu","Vaibhav Srivastav","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2503.08533v1.pdf","comment":"Accepted at NAACL 2025 Demo Track"},{"id":"http://arxiv.org/abs/2205.13346v2","updated":"2025-03-11T15:21:37Z","published":"2022-05-26T13:26:03Z","title":"Keywords and Instances: A Hierarchical Contrastive Learning Framework\n  Unifying Hybrid Granularities for Text Generation","summary":"  Contrastive learning has achieved impressive success in generation tasks to\nmilitate the \"exposure bias\" problem and discriminatively exploit the different\nquality of references. Existing works mostly focus on contrastive learning on\nthe instance-level without discriminating the contribution of each word, while\nkeywords are the gist of the text and dominant the constrained mapping\nrelationships. Hence, in this work, we propose a hierarchical contrastive\nlearning mechanism, which can unify hybrid granularities semantic meaning in\nthe input text. Concretely, we first propose a keyword graph via contrastive\ncorrelations of positive-negative pairs to iteratively polish the keyword\nrepresentations. Then, we construct intra-contrasts within instance-level and\nkeyword-level, where we assume words are sampled nodes from a sentence\ndistribution. Finally, to bridge the gap between independent contrast levels\nand tackle the common contrast vanishing problem, we propose an inter-contrast\nmechanism that measures the discrepancy between contrastive keyword nodes\nrespectively to the instance distribution. Experiments demonstrate that our\nmodel outperforms competitive baselines on paraphrasing, dialogue generation,\nand storytelling tasks.\n","authors":["Mingzhe Li","XieXiong Lin","Xiuying Chen","Jinxiong Chang","Qishen Zhang","Feng Wang","Taifeng Wang","Zhongyi Liu","Wei Chu","Dongyan Zhao","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2205.13346v2.pdf","comment":"Accepted by ACL2022"},{"id":"http://arxiv.org/abs/2503.08524v1","updated":"2025-03-11T15:15:54Z","published":"2025-03-11T15:15:54Z","title":"Position-Aware Depth Decay Decoding ($D^3$): Boosting Large Language\n  Model Inference Efficiency","summary":"  Due to the large number of parameters, the inference phase of Large Language\nModels (LLMs) is resource-intensive. Unlike traditional model compression,\nwhich needs retraining, recent dynamic computation methods show that not all\ncomponents are required for inference, enabling a training-free pipeline. In\nthis paper, we focus on the dynamic depth of LLM generation. A token-position\naware layer skipping framework is proposed to save 1.5x times operations\nefficiently while maintaining performance. We first observed that tokens\npredicted later have lower perplexity and thus require less computation. Then,\nwe propose a training-free algorithm called Position-Aware Depth Decay Decoding\n($D^3$), which leverages a power-law decay function, $\\left\\lfloor L \\times\n(\\alpha^i) \\right\\rfloor$, to determine the number of layers to retain when\ngenerating token $T_i$. Remarkably, without any retraining, the $D^3$ achieves\nsuccess across a wide range of generation tasks for the first time. Experiments\non large language models (\\ie the Llama) with $7 \\sim 70$ billion parameters\nshow that $D^3$ can achieve an average 1.5x speedup compared with the\nfull-inference pipeline while maintaining comparable performance with nearly no\nperformance drop ($<1\\%$) on the GSM8K and BBH benchmarks.\n","authors":["Siqi Fan","Xuezhi Fang","Xingrun Xing","Peng Han","Shuo Shang","Yequan Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08506v1","updated":"2025-03-11T14:56:58Z","published":"2025-03-11T14:56:58Z","title":"ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper\n  Reviews","summary":"  Academic paper review is a critical yet time-consuming task within the\nresearch community. With the increasing volume of academic publications,\nautomating the review process has become a significant challenge. The primary\nissue lies in generating comprehensive, accurate, and reasoning-consistent\nreview comments that align with human reviewers' judgments. In this paper, we\naddress this challenge by proposing ReviewAgents, a framework that leverages\nlarge language models (LLMs) to generate academic paper reviews. We first\nintroduce a novel dataset, Review-CoT, consisting of 142k review comments,\ndesigned for training LLM agents. This dataset emulates the structured\nreasoning process of human reviewers-summarizing the paper, referencing\nrelevant works, identifying strengths and weaknesses, and generating a review\nconclusion. Building upon this, we train LLM reviewer agents capable of\nstructured reasoning using a relevant-paper-aware training method. Furthermore,\nwe construct ReviewAgents, a multi-role, multi-LLM agent review framework, to\nenhance the review comment generation process. Additionally, we propose\nReviewBench, a benchmark for evaluating the review comments generated by LLMs.\nOur experimental results on ReviewBench demonstrate that while existing LLMs\nexhibit a certain degree of potential for automating the review process, there\nremains a gap when compared to human-generated reviews. Moreover, our\nReviewAgents framework further narrows this gap, outperforming advanced LLMs in\ngenerating review comments.\n","authors":["Xian Gao","Jiacheng Ruan","Jingsheng Gao","Ting Liu","Yuzhuo Fu"],"pdf_url":"https://arxiv.org/pdf/2503.08506v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.08495v1","updated":"2025-03-11T14:47:24Z","published":"2025-03-11T14:47:24Z","title":"Enhancing Multi-Hop Fact Verification with Structured\n  Knowledge-Augmented Large Language Models","summary":"  The rapid development of social platforms exacerbates the dissemination of\nmisinformation, which stimulates the research in fact verification. Recent\nstudies tend to leverage semantic features to solve this problem as a\nsingle-hop task. However, the process of verifying a claim requires several\npieces of evidence with complicated inner logic and relations to verify the\ngiven claim in real-world situations. Recent studies attempt to improve both\nunderstanding and reasoning abilities to enhance the performance, but they\noverlook the crucial relations between entities that benefit models to\nunderstand better and facilitate the prediction. To emphasize the significance\nof relations, we resort to Large Language Models (LLMs) considering their\nexcellent understanding ability. Instead of other methods using LLMs as the\npredictor, we take them as relation extractors, for they do better in\nunderstanding rather than reasoning according to the experimental results.\nThus, to solve the challenges above, we propose a novel Structured\nKnowledge-Augmented LLM-based Network (LLM-SKAN) for multi-hop fact\nverification. Specifically, we utilize an LLM-driven Knowledge Extractor to\ncapture fine-grained information, including entities and their complicated\nrelations. Besides, we leverage a Knowledge-Augmented Relation Graph Fusion\nmodule to interact with each node and learn better claim-evidence\nrepresentations comprehensively. The experimental results on four common-used\ndatasets demonstrate the effectiveness and superiority of our model.\n","authors":["Han Cao","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2503.08495v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.06794v2","updated":"2025-03-11T14:34:14Z","published":"2025-03-09T22:16:48Z","title":"Silent Hazards of Token Reduction in Vision-Language Models: The Hidden\n  Impact on Consistency","summary":"  Vision language models (VLMs) have excelled in visual reasoning but often\nincur high computational costs. One key reason is the redundancy of visual\ntokens. Although recent token reduction methods claim to achieve minimal\nperformance loss, our extensive experiments reveal that token reduction can\nsubstantially alter a model's output distribution, leading to changes in\nprediction patterns that standard metrics such as accuracy loss do not fully\ncapture. Such inconsistencies are especially concerning for practical\napplications where system stability is critical. To investigate this\nphenomenon, we analyze how token reduction influences the energy distribution\nof a VLM's internal representations using a lower-rank approximation via\nSingular Value Decomposition (SVD). Our results show that changes in the\nInverse Participation Ratio of the singular value spectrum are strongly\ncorrelated with the model's consistency after token reduction. Based on these\ninsights, we propose LoFi--a training-free visual token reduction method that\nutilizes the leverage score from SVD for token pruning. Experimental\nevaluations demonstrate that LoFi not only reduces computational costs with\nminimal performance degradation but also significantly outperforms\nstate-of-the-art methods in terms of output consistency.\n","authors":["Yizheng Sun","Hao Li","Chang Xu","Chenghua Lin","Riza Batista-Navarro","Jingyuan Sun"],"pdf_url":"https://arxiv.org/pdf/2503.06794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08454v1","updated":"2025-03-11T14:04:24Z","published":"2025-03-11T14:04:24Z","title":"Stick to Facts: Towards Fidelity-oriented Product Description Generation","summary":"  Different from other text generation tasks, in product description\ngeneration, it is of vital importance to generate faithful descriptions that\nstick to the product attribute information. However, little attention has been\npaid to this problem. To bridge this gap, we propose a model named\nFidelity-oriented Product Description Generator (FPDG). FPDG takes the entity\nlabel of each word into account, since the product attribute information is\nalways conveyed by entity words. Specifically, we first propose a Recurrent\nNeural Network (RNN) decoder based on the Entity-label-guided Long Short-Term\nMemory (ELSTM) cell, taking both the embedding and the entity label of each\nword as input. Second, we establish a keyword memory that stores the entity\nlabels as keys and keywords as values, allowing FPDG to attend to keywords by\nattending to their entity labels. Experiments conducted on a large-scale\nreal-world product description dataset show that our model achieves\nstate-of-the-art performance in terms of both traditional generation metrics\nand human evaluations. Specifically, FPDG increases the fidelity of the\ngenerated descriptions by 25%.\n","authors":["Zhangming Chan","Xiuying Chen","Yongliang Wang","Juntao Li","Zhiqiang Zhang","Kun Gai","Dongyan Zhao","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2503.08454v1.pdf","comment":"Accepted by EMNLP 2010"},{"id":"http://arxiv.org/abs/2412.10319v2","updated":"2025-03-11T14:02:04Z","published":"2024-12-13T17:59:52Z","title":"SCBench: A KV Cache-Centric Analysis of Long-Context Methods","summary":"  Long-context LLMs have enabled numerous downstream applications but also\nintroduced significant challenges related to computational and memory\nefficiency. To address these challenges, optimizations for long-context\ninference have been developed, centered around the KV cache. However, existing\nbenchmarks often evaluate in single-request, neglecting the full lifecycle of\nthe KV cache in real-world use. This oversight is particularly critical, as KV\ncache reuse has become widely adopted in LLMs inference frameworks, such as\nvLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,\nGoogle, and Anthropic. To address this gap, we introduce\nSCBench(SharedContextBench), a comprehensive benchmark for evaluating\nlong-context methods from a KV cachecentric perspective: 1) KV cache\ngeneration, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache\nloading. Specifically, SCBench uses test examples with shared context, ranging\n12 tasks with two shared context modes, covering four categories of\nlong-context capabilities: string retrieval, semantic retrieval, global\ninformation, and multi-task. With it, we provide an extensive KV cache-centric\nanalysis of eight categories long-context solutions, including Gated Linear\nRNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,\nKV cache dropping, quantization, retrieval, loading, and prompt compression.\nThe evaluation is conducted on 8 long-context LLMs. Our findings show that\nsub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding\nwith O(n) memory and sub-O(n^2) pre-filling computation perform robustly.\nDynamic sparsity yields more expressive KV caches than static patterns, and\nlayer-level sparsity in hybrid architectures reduces memory usage with strong\nperformance. Additionally, we identify attention distribution shift issues in\nlong-generation scenarios. https://aka.ms/SCBench.\n","authors":["Yucheng Li","Huiqiang Jiang","Qianhui Wu","Xufang Luo","Surin Ahn","Chengruidong Zhang","Amir H. Abdi","Dongsheng Li","Jianfeng Gao","Yuqing Yang","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2412.10319v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2409.19338v2","updated":"2025-03-11T13:44:27Z","published":"2024-09-28T12:49:02Z","title":"Decoding Echo Chambers: LLM-Powered Simulations Revealing Polarization\n  in Social Networks","summary":"  The impact of social media on critical issues such as echo chambers needs to\nbe addressed, as these phenomena can have disruptive consequences for our\nsociety. Traditional research often oversimplifies emotional tendencies and\nopinion evolution into numbers and formulas, neglecting that news and\ncommunication are conveyed through text, which limits these approaches. Hence,\nin this work, we propose an LLM-based simulation for the social opinion network\nto evaluate and counter polarization phenomena. We first construct three\ntypical network structures to simulate different characteristics of social\ninteractions. Then, agents interact based on recommendation algorithms and\nupdate their strategies through reasoning and analysis. By comparing these\ninteractions with the classic Bounded Confidence Model (BCM), the Friedkin\nJohnsen (FJ) model, and using echo chamber-related indices, we demonstrate the\neffectiveness of our framework in simulating opinion dynamics and reproducing\nphenomena such as opinion polarization and echo chambers. We propose two\nmitigation methods, active and passive nudges, that can help reduce echo\nchambers, specifically within language-based simulations. We hope our work will\noffer valuable insights and guidance for social polarization mitigation.\n","authors":["Chenxi Wang","Zongfang Liu","Dequan Yang","Xiuying Chen"],"pdf_url":"https://arxiv.org/pdf/2409.19338v2.pdf","comment":"Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2411.10573v2","updated":"2025-03-11T13:41:59Z","published":"2024-11-15T20:46:58Z","title":"Hysteresis Activation Function for Efficient Inference","summary":"  The widely used ReLU is favored for its hardware efficiency, {as the\nimplementation at inference is a one bit sign case,} yet suffers from issues\nsuch as the ``dying ReLU'' problem, where during training, neurons fail to\nactivate and constantly remain at zero, as highlighted by Lu et al. Traditional\napproaches to mitigate this issue often introduce more complex and less\nhardware-friendly activation functions. In this work, we propose a Hysteresis\nRectified Linear Unit (HeLU), an efficient activation function designed to\naddress the ``dying ReLU'' problem with minimal complexity. Unlike traditional\nactivation functions with fixed thresholds for training and inference, HeLU\nemploys a variable threshold that refines the backpropagation. This refined\nmechanism allows simpler activation functions to achieve competitive\nperformance comparable to their more complex counterparts without introducing\nunnecessary complexity or requiring inductive biases. Empirical evaluations\ndemonstrate that HeLU enhances model generalization across diverse datasets,\noffering a promising solution for efficient and effective inference suitable\nfor a wide range of neural network architectures.\n","authors":["Moshe Kimhi","Idan Kashani","Avi Mendelson","Chaim Baskin"],"pdf_url":"https://arxiv.org/pdf/2411.10573v2.pdf","comment":"Accepted to 4th NeurIPS Efficient Natural Language and Speech\n  Processing Workshop (ENLSP-IV 2024)"},{"id":"http://arxiv.org/abs/2411.14137v2","updated":"2025-03-11T13:29:47Z","published":"2024-11-21T14:01:42Z","title":"VAGUE: Visual Contexts Clarify Ambiguous Expressions","summary":"  Human communication often relies on visual cues to resolve ambiguity. While\nhumans can intuitively integrate these cues, AI systems often find it\nchallenging to engage in sophisticated multimodal reasoning. We introduce\nVAGUE, a benchmark evaluating multimodal AI systems' ability to integrate\nvisual context for intent disambiguation. VAGUE consists of 1.6K ambiguous\ntextual expressions, each paired with an image and multiple-choice\ninterpretations, where the correct answer is only apparent with visual context.\nThe dataset spans both staged, complex (Visual Commonsense Reasoning) and\nnatural, personal (Ego4D) scenes, ensuring diversity. Our experiments reveal\nthat existing multimodal AI models struggle to infer the speaker's true intent.\nWhile performance consistently improves from the introduction of more visual\ncues, the overall accuracy remains far below human performance, highlighting a\ncritical gap in multimodal reasoning. Analysis of failure cases demonstrates\nthat current models fail to distinguish true intent from superficial\ncorrelations in the visual scene, indicating that they perceive images but do\nnot effectively reason with them. We release our code and data at\nhttps://github.com/Hazel-Heejeong-Nam/VAGUE.git.\n","authors":["Heejeong Nam","Jinwoo Ahn","Keummin Ka","Jiwan Chung","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2411.14137v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2407.13579v2","updated":"2025-03-11T13:07:09Z","published":"2024-07-18T15:20:31Z","title":"Towards Zero-Shot Multimodal Machine Translation","summary":"  Current multimodal machine translation (MMT) systems rely on fully supervised\ndata (i.e models are trained on sentences with their translations and\naccompanying images). However, this type of data is costly to collect, limiting\nthe extension of MMT to other language pairs for which such data does not\nexist. In this work, we propose a method to bypass the need for fully\nsupervised data to train MMT systems, using multimodal English data only. Our\nmethod, called ZeroMMT, consists in adapting a strong text-only machine\ntranslation (MT) model by training it on a mixture of two objectives: visually\nconditioned masked language modelling and the Kullback-Leibler divergence\nbetween the original and new MMT outputs. We evaluate on standard MMT\nbenchmarks and the recently released CoMMuTE, a contrastive benchmark aiming to\nevaluate how well models use images to disambiguate English sentences. We\nobtain disambiguation performance close to state-of-the-art MMT models trained\nadditionally on fully supervised examples. To prove that our method generalizes\nto languages with no fully supervised training data available, we extend the\nCoMMuTE evaluation dataset to three new languages: Arabic, Russian and Chinese.\nWe further show that we can control the trade-off between disambiguation\ncapabilities and translation fidelity at inference time using classifier-free\nguidance and without any additional data. Our code, data and trained models are\npublicly accessible.\n","authors":["Matthieu Futeral","Cordelia Schmid","Benoît Sagot","Rachel Bawden"],"pdf_url":"https://arxiv.org/pdf/2407.13579v2.pdf","comment":"NAACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2503.08404v1","updated":"2025-03-11T13:06:40Z","published":"2025-03-11T13:06:40Z","title":"Fact-checking with Generative AI: A Systematic Cross-Topic Examination\n  of LLMs Capacity to Detect Veracity of Political Information","summary":"  The purpose of this study is to assess how large language models (LLMs) can\nbe used for fact-checking and contribute to the broader debate on the use of\nautomated means for veracity identification. To achieve this purpose, we use AI\nauditing methodology that systematically evaluates performance of five LLMs\n(ChatGPT 4, Llama 3 (70B), Llama 3.1 (405B), Claude 3.5 Sonnet, and Google\nGemini) using prompts regarding a large set of statements fact-checked by\nprofessional journalists (16,513). Specifically, we use topic modeling and\nregression analysis to investigate which factors (e.g. topic of the prompt or\nthe LLM type) affect evaluations of true, false, and mixed statements. Our\nfindings reveal that while ChatGPT 4 and Google Gemini achieved higher accuracy\nthan other models, overall performance across models remains modest. Notably,\nthe results indicate that models are better at identifying false statements,\nespecially on sensitive topics such as COVID-19, American political\ncontroversies, and social issues, suggesting possible guardrails that may\nenhance accuracy on these topics. The major implication of our findings is that\nthere are significant challenges for using LLMs for factchecking, including\nsignificant variation in performance across different LLMs and unequal quality\nof outputs for specific topics which can be attributed to deficits of training\ndata. Our research highlights the potential and limitations of LLMs in\npolitical fact-checking, suggesting potential avenues for further improvements\nin guardrails as well as fine-tuning.\n","authors":["Elizaveta Kuznetsova","Ilaria Vitulano","Mykola Makhortykh","Martha Stolze","Tomas Nagy","Victoria Vziatysheva"],"pdf_url":"https://arxiv.org/pdf/2503.08404v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2407.08952v4","updated":"2025-03-11T13:06:04Z","published":"2024-07-12T03:15:01Z","title":"Detect, Investigate, Judge and Determine: A Knowledge-guided Framework\n  for Few-shot Fake News Detection","summary":"  Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news\nfrom real ones in extremely low-resource scenarios. This task has garnered\nincreased attention due to the widespread dissemination and harmful impact of\nfake news on social media. Large Language Models (LLMs) have demonstrated\ncompetitive performance with the help of their rich prior knowledge and\nexcellent in-context learning abilities. However, existing methods face\nsignificant limitations, such as the Understanding Ambiguity and Information\nScarcity, which significantly undermine the potential of LLMs. To address these\nshortcomings, we propose a Dual-perspective Knowledge-guided Fake News\nDetection (DKFND) model, designed to enhance LLMs from both inside and outside\nperspectives. Specifically, DKFND first identifies the knowledge concepts of\neach news article through a Detection Module. Subsequently, DKFND creatively\ndesigns an Investigation Module to retrieve inside and outside valuable\ninformation concerning to the current news, followed by another Judge Module to\nevaluate the relevance and confidence of them. Finally, a Determination Module\nfurther derives two respective predictions and obtain the final result.\nExtensive experiments on two public datasets show the efficacy of our proposed\nmethod, particularly in low-resource settings.\n","authors":["Ye Liu","Jiajun Zhu","Xukai Liu","Haoyu Tang","Yanghai Zhang","Kai Zhang","Xiaofang Zhou","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2407.08952v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08398v1","updated":"2025-03-11T13:04:05Z","published":"2025-03-11T13:04:05Z","title":"OpenRAG: Optimizing RAG End-to-End via In-Context Retrieval Learning","summary":"  In this paper, we analyze and empirically show that the learned relevance for\nconventional information retrieval (IR) scenarios may be inconsistent in\nretrieval-augmented generation (RAG) scenarios. To bridge this gap, we\nintroduce OpenRAG, a RAG framework that is optimized end-to-end by tuning the\nretriever to capture in-context relevance, enabling adaptation to the diverse\nand evolving needs. Extensive experiments across a wide range of tasks\ndemonstrate that OpenRAG, by tuning a retriever end-to-end, leads to a\nconsistent improvement of 4.0% over the original retriever, consistently\noutperforming existing state-of-the-art retrievers by 2.1%. Additionally, our\nresults indicate that for some tasks, an end-to-end tuned 0.2B retriever can\nachieve improvements that surpass those of RAG-oriented or instruction-tuned 8B\nlarge language models (LLMs), highlighting the cost-effectiveness of our\napproach in enhancing RAG systems.\n","authors":["Jiawei Zhou","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08379v1","updated":"2025-03-11T12:39:04Z","published":"2025-03-11T12:39:04Z","title":"JurisTCU: A Brazilian Portuguese Information Retrieval Dataset with\n  Query Relevance Judgments","summary":"  This paper introduces JurisTCU, a Brazilian Portuguese dataset for legal\ninformation retrieval (LIR). The dataset is freely available and consists of\n16,045 jurisprudential documents from the Brazilian Federal Court of Accounts,\nalong with 150 queries annotated with relevance judgments. It addresses the\nscarcity of Portuguese-language LIR datasets with query relevance annotations.\nThe queries are organized into three groups: real user keyword-based queries,\nsynthetic keyword-based queries, and synthetic question-based queries.\nRelevance judgments were produced through a hybrid approach combining LLM-based\nscoring with expert domain validation. We used JurisTCU in 14 experiments using\nlexical search (document expansion methods) and semantic search (BERT-based and\nOpenAI embeddings). We show that the document expansion methods significantly\nimprove the performance of standard BM25 search on this dataset, with\nimprovements exceeding 45% in P@10, R@10, and nDCG@10 metrics when evaluating\nshort keyword-based queries. Among the embedding models, the OpenAI models\nproduced the best results, with improvements of approximately 70% in P@10,\nR@10, and nDCG@10 metrics for short keyword-based queries, suggesting that\nthese dense embeddings capture semantic relationships in this domain,\nsurpassing the reliance on lexical terms. Besides offering a dataset for the\nPortuguese-language IR research community, suitable for evaluating search\nsystems, the results also contribute to enhancing a search system highly\nrelevant to Brazilian citizens.\n","authors":["Leandro Carísio Fernandes","Leandro dos Santos Ribeiro","Marcos Vinícius Borela de Castro","Leonardo Augusto da Silva Pacheco","Edans Flávius de Oliveira Sandes"],"pdf_url":"https://arxiv.org/pdf/2503.08379v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2503.05244v2","updated":"2025-03-11T12:11:00Z","published":"2025-03-07T08:56:20Z","title":"WritingBench: A Comprehensive Benchmark for Generative Writing","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.\n","authors":["Yuning Wu","Jiahao Mei","Ming Yan","Chenliang Li","Shaopeng Lai","Yuran Ren","Zijia Wang","Ji Zhang","Mengyue Wu","Qin Jin","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10419v2","updated":"2025-03-11T12:02:06Z","published":"2024-04-16T09:35:27Z","title":"MAD Speech: Measures of Acoustic Diversity of Speech","summary":"  Generative spoken language models produce speech in a wide range of voices,\nprosody, and recording conditions, seemingly approaching the diversity of\nnatural speech. However, the extent to which generated speech is acoustically\ndiverse remains unclear due to a lack of appropriate metrics. We address this\ngap by developing lightweight metrics of acoustic diversity, which we\ncollectively refer to as MAD Speech. We focus on measuring five facets of\nacoustic diversity: voice, gender, emotion, accent, and background noise. We\nconstruct the metrics as a composition of specialized, per-facet embedding\nmodels and an aggregation function that measures diversity within the embedding\nspace. Next, we build a series of datasets with a priori known diversity\npreferences for each facet. Using these datasets, we demonstrate that our\nproposed metrics achieve a stronger agreement with the ground-truth diversity\nthan baselines. Finally, we showcase the applicability of our proposed metrics\nacross several real-life evaluation scenarios. MAD Speech is made publicly\naccessible.\n","authors":["Matthieu Futeral","Andrea Agostinelli","Marco Tagliasacchi","Neil Zeghidour","Eugene Kharitonov"],"pdf_url":"https://arxiv.org/pdf/2404.10419v2.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2408.06631v2","updated":"2025-03-11T12:02:01Z","published":"2024-08-13T04:36:18Z","title":"IFShip: Interpretable Fine-grained Ship Classification with Domain\n  Knowledge-Enhanced Vision-Language Models","summary":"  End-to-end interpretation currently dominates the remote sensing fine-grained\nship classification (RS-FGSC) task. However, the inference process remains\nuninterpretable, leading to criticisms of these models as \"black box\" systems.\nTo address this issue, we propose a domain knowledge-enhanced Chain-of-Thought\n(CoT) prompt generation mechanism, which is used to semi-automatically\nconstruct a task-specific instruction-following dataset, TITANIC-FGS. By\ntraining on TITANIC-FGS, we adapt general-domain vision-language models (VLMs)\nto the FGSC task, resulting in a model named IFShip. Building upon IFShip, we\ndevelop an FGSC visual chatbot that redefines the FGSC problem as a\nstep-by-step reasoning task and conveys the reasoning process in natural\nlanguage. Experimental results show that IFShip outperforms state-of-the-art\nFGSC algorithms in both interpretability and classification accuracy.\nFurthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates\nsuperior performance on the FGSC task. It provides an accurate chain of\nreasoning when fine-grained ship types are recognizable to the human eye and\noffers interpretable explanations when they are not.\n","authors":["Mingning Guo","Mengwei Wu","Yuxiang Shen","Haifeng Li","Chao Tao"],"pdf_url":"https://arxiv.org/pdf/2408.06631v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08327v1","updated":"2025-03-11T11:40:10Z","published":"2025-03-11T11:40:10Z","title":"Adding Chocolate to Mint: Mitigating Metric Interference in Machine\n  Translation","summary":"  As automatic metrics become increasingly stronger and widely adopted, the\nrisk of unintentionally \"gaming the metric\" during model development rises.\nThis issue is caused by metric interference (Mint), i.e., the use of the same\nor related metrics for both model tuning and evaluation. Mint can misguide\npractitioners into being overoptimistic about the performance of their systems:\nas system outputs become a function of the interfering metric, their estimated\nquality loses correlation with human judgments. In this work, we analyze two\ncommon cases of Mint in machine translation-related tasks: filtering of\ntraining data, and decoding with quality signals. Importantly, we find that\nMint strongly distorts instance-level metric scores, even when metrics are not\ndirectly optimized for -- questioning the common strategy of leveraging a\ndifferent, yet related metric for evaluation that is not used for tuning. To\naddress this problem, we propose MintAdjust, a method for more reliable\nevaluation under Mint. On the WMT24 MT shared task test set, MintAdjust ranks\ntranslations and systems more accurately than state-of-the-art-metrics across a\nmajority of language pairs, especially for high-quality systems. Furthermore,\nMintAdjust outperforms AutoRank, the ensembling method used by the organizers.\n","authors":["José Pombal","Nuno M. Guerreiro","Ricardo Rei","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2503.08327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08323v1","updated":"2025-03-11T11:34:57Z","published":"2025-03-11T11:34:57Z","title":"Towards Scalable and Cross-Lingual Specialist Language Models for\n  Oncology","summary":"  Clinical oncology generates vast, unstructured data that often contain\ninconsistencies, missing information, and ambiguities, making it difficult to\nextract reliable insights for data-driven decision-making. General-purpose\nlarge language models (LLMs) struggle with these challenges due to their lack\nof domain-specific reasoning, including specialized clinical terminology,\ncontext-dependent interpretations, and multi-modal data integration. We address\nthese issues with an oncology-specialized, efficient, and adaptable NLP\nframework that combines instruction tuning, retrieval-augmented generation\n(RAG), and graph-based knowledge integration. Our lightweight models prove\neffective at oncology-specific tasks, such as named entity recognition (e.g.,\nidentifying cancer diagnoses), entity linking (e.g., linking entities to\nstandardized ontologies), TNM staging, document classification (e.g., cancer\nsubtype classification from pathology reports), and treatment response\nprediction. Our framework emphasizes adaptability and resource efficiency. We\ninclude minimal German instructions, collected at the University Hospital\nZurich (USZ), to test whether small amounts of non-English language data can\neffectively transfer knowledge across languages. This approach mirrors our\nmotivation for lightweight models, which balance strong performance with\nreduced computational costs, making them suitable for resource-limited\nhealthcare settings. We validated our models on oncology datasets,\ndemonstrating strong results in named entity recognition, relation extraction,\nand document classification.\n","authors":["Morteza Rohanian","Tarun Mehra","Nicola Miglino","Farhad Nooralahzadeh","Michael Krauthammer","Andreas Wicki"],"pdf_url":"https://arxiv.org/pdf/2503.08323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08292v1","updated":"2025-03-11T11:05:42Z","published":"2025-03-11T11:05:42Z","title":"Large Language Models for Outpatient Referral: Problem Definition,\n  Benchmarking and Challenges","summary":"  Large language models (LLMs) are increasingly applied to outpatient referral\ntasks across healthcare systems. However, there is a lack of standardized\nevaluation criteria to assess their effectiveness, particularly in dynamic,\ninteractive scenarios. In this study, we systematically examine the\ncapabilities and limitations of LLMs in managing tasks within Intelligent\nOutpatient Referral (IOR) systems and propose a comprehensive evaluation\nframework specifically designed for such systems. This framework comprises two\ncore tasks: static evaluation, which focuses on evaluating the ability of\npredefined outpatient referrals, and dynamic evaluation, which evaluates\ncapabilities of refining outpatient referral recommendations through iterative\ndialogues. Our findings suggest that LLMs offer limited advantages over\nBERT-like models, but show promise in asking effective questions during\ninteractive dialogues.\n","authors":["Xiaoxiao Liu","Qingying Xiao","Junying Chen","Xiangyi Feng","Xiangbo Wu","Bairui Zhang","Xiang Wan","Jian Chang","Guangjun Yu","Yan Hu","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08275v1","updated":"2025-03-11T10:43:01Z","published":"2025-03-11T10:43:01Z","title":"Beyond Outlining: Heterogeneous Recursive Planning for Adaptive\n  Long-form Writing with Language Models","summary":"  Long-form writing agents require flexible integration and interaction across\ninformation retrieval, reasoning, and composition. Current approaches rely on\npredetermined workflows and rigid thinking patterns to generate outlines before\nwriting, resulting in constrained adaptability during writing. In this paper we\npropose a general agent framework that achieves human-like adaptive writing\nthrough recursive task decomposition and dynamic integration of three\nfundamental task types, i.e. retrieval, reasoning, and composition. Our\nmethodology features: 1) a planning mechanism that interleaves recursive task\ndecomposition and execution, eliminating artificial restrictions on writing\nworkflow; and 2) integration of task types that facilitates heterogeneous task\ndecomposition. Evaluations on both fiction writing and technical report\ngeneration show that our method consistently outperforms state-of-the-art\napproaches across all automatic evaluation metrics, which demonstrate the\neffectiveness and broad applicability of our proposed framework.\n","authors":["Ruibin Xiong","Yimeng Chen","Dmitrii Khizbullin","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2503.08275v1.pdf","comment":"29 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.10995v3","updated":"2025-03-11T10:13:54Z","published":"2024-10-14T18:24:52Z","title":"Watching the Watchers: Exposing Gender Disparities in Machine\n  Translation Quality Estimation","summary":"  Quality estimation (QE) -- the automatic assessment of translation quality --\nhas recently become crucial across several stages of the translation pipeline,\nfrom data curation to training and decoding. While QE metrics have been\noptimized to align with human judgments, whether they encode social biases has\nbeen largely overlooked. Biased QE risks favoring certain demographic groups\nover others, e.g., by exacerbating gaps in visibility and usability. This paper\ndefines and investigates gender bias of QE metrics and discusses its downstream\nimplications for machine translation (MT). Experiments with state-of-the-art QE\nmetrics across multiple domains, datasets, and languages reveal significant\nbias. When a human entity's gender in the source is undisclosed,\nmasculine-inflected translations score higher than feminine-inflected ones and\ngender-neutral translations are penalized. Even when contextual cues\ndisambiguate gender, using context-aware QE metrics leads to more errors in\npicking the correct translation inflection for feminine than masculine\nreferents. Moreover, a biased QE metric affects data filtering and\nquality-aware decoding. Our findings highlight the need for renewed focus in\ndeveloping and evaluating QE metrics centered around gender.\n","authors":["Emmanouil Zaranis","Giuseppe Attanasio","Sweta Agrawal","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2410.10995v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.01306v2","updated":"2025-03-11T10:08:37Z","published":"2024-10-02T08:01:05Z","title":"Emotion-Aware Embedding Fusion in LLMs (Flan-T5, LLAMA 2, DeepSeek-R1,\n  and ChatGPT 4) for Intelligent Response Generation","summary":"  Empathetic and coherent responses are critical in auto-mated\nchatbot-facilitated psychotherapy. This study addresses the challenge of\nenhancing the emotional and contextual understanding of large language models\n(LLMs) in psychiatric applications. We introduce Emotion-Aware Embedding\nFusion, a novel framework integrating hierarchical fusion and attention\nmechanisms to prioritize semantic and emotional features in therapy\ntranscripts. Our approach combines multiple emotion lexicons, including NRC\nEmotion Lexicon, VADER, WordNet, and SentiWordNet, with state-of-the-art LLMs\nsuch as Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4. Therapy session\ntranscripts, comprising over 2,000 samples are segmented into hierarchical\nlevels (word, sentence, and session) using neural networks, while hierarchical\nfusion combines these features with pooling techniques to refine emotional\nrepresentations. Atten-tion mechanisms, including multi-head self-attention and\ncross-attention, further prioritize emotional and contextual features, enabling\ntemporal modeling of emotion-al shifts across sessions. The processed\nembeddings, computed using BERT, GPT-3, and RoBERTa are stored in the Facebook\nAI similarity search vector database, which enables efficient similarity search\nand clustering across dense vector spaces. Upon user queries, relevant segments\nare retrieved and provided as context to LLMs, enhancing their ability to\ngenerate empathetic and con-textually relevant responses. The proposed\nframework is evaluated across multiple practical use cases to demonstrate\nreal-world applicability, including AI-driven therapy chatbots. The system can\nbe integrated into existing mental health platforms to generate personalized\nresponses based on retrieved therapy session data.\n","authors":["Abdur Rasool","Muhammad Irfan Shahzad","Hafsa Aslam","Vincent Chan","Muhammad Ali Arshad"],"pdf_url":"https://arxiv.org/pdf/2410.01306v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06749v2","updated":"2025-03-11T09:47:44Z","published":"2025-03-09T20:06:45Z","title":"Vision-R1: Incentivizing Reasoning Capability in Multimodal Large\n  Language Models","summary":"  DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .\n","authors":["Wenxuan Huang","Bohan Jia","Zijie Zhai","Shaosheng Cao","Zheyu Ye","Fei Zhao","Zhe Xu","Yao Hu","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06749v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08228v1","updated":"2025-03-11T09:46:07Z","published":"2025-03-11T09:46:07Z","title":"Investigating Execution-Aware Language Models for Code Optimization","summary":"  Code optimization is the process of enhancing code efficiency, while\npreserving its intended functionality. This process often requires a deep\nunderstanding of the code execution behavior at run-time to identify and\naddress inefficiencies effectively. Recent studies have shown that language\nmodels can play a significant role in automating code optimization. However,\nthese models may have insufficient knowledge of how code execute at run-time.\nTo address this limitation, researchers have developed strategies that\nintegrate code execution information into language models. These strategies\nhave shown promise, enhancing the effectiveness of language models in various\nsoftware engineering tasks. However, despite the close relationship between\ncode execution behavior and efficiency, the specific impact of these strategies\non code optimization remains largely unexplored. This study investigates how\nincorporating code execution information into language models affects their\nability to optimize code. Specifically, we apply three different training\nstrategies to incorporate four code execution aspects -- line executions, line\ncoverage, branch coverage, and variable states -- into CodeT5+, a well-known\nlanguage model for code. Our results indicate that execution-aware models\nprovide limited benefits compared to the standard CodeT5+ model in optimizing\ncode.\n","authors":["Federico Di Menna","Luca Traini","Gabriele Bavota","Vittorio Cortellessa"],"pdf_url":"https://arxiv.org/pdf/2503.08228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08226v1","updated":"2025-03-11T09:44:17Z","published":"2025-03-11T09:44:17Z","title":"A Grey-box Text Attack Framework using Explainable AI","summary":"  Explainable AI is a strong strategy implemented to understand complex\nblack-box model predictions in a human interpretable language. It provides the\nevidence required to execute the use of trustworthy and reliable AI systems. On\nthe other hand, however, it also opens the door to locating possible\nvulnerabilities in an AI model. Traditional adversarial text attack uses word\nsubstitution, data augmentation techniques and gradient-based attacks on\npowerful pre-trained Bidirectional Encoder Representations from Transformers\n(BERT) variants to generate adversarial sentences. These attacks are generally\nwhitebox in nature and not practical as they can be easily detected by humans\nE.g. Changing the word from \"Poor\" to \"Rich\". We proposed a simple yet\neffective Grey-box cum Black-box approach that does not require the knowledge\nof the model while using a set of surrogate Transformer/BERT models to perform\nthe attack using Explainable AI techniques. As Transformers are the current\nstate-of-the-art models for almost all Natural Language Processing (NLP) tasks,\nan attack generated from BERT1 is transferable to BERT2. This transferability\nis made possible due to the attention mechanism in the transformer that allows\nthe model to capture long-range dependencies in a sequence. Using the power of\nBERT generalisation via attention, we attempt to exploit how transformers learn\nby attacking a few surrogate transformer variants which are all based on a\ndifferent architecture. We demonstrate that this approach is highly effective\nto generate semantically good sentences by changing as little as one word that\nis not detectable by humans while still fooling other BERT models.\n","authors":["Esther Chiramal","Kelvin Soh Boon Kai"],"pdf_url":"https://arxiv.org/pdf/2503.08226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19075v2","updated":"2025-03-11T09:31:15Z","published":"2024-09-27T18:22:22Z","title":"Meta-RTL: Reinforcement-Based Meta-Transfer Learning for Low-Resource\n  Commonsense Reasoning","summary":"  Meta learning has been widely used to exploit rich-resource source tasks to\nimprove the performance of low-resource target tasks. Unfortunately, most\nexisting meta learning approaches treat different source tasks equally,\nignoring the relatedness of source tasks to the target task in knowledge\ntransfer. To mitigate this issue, we propose a reinforcement-based multi-source\nmeta-transfer learning framework (Meta-RTL) for low-resource commonsense\nreasoning. In this framework, we present a reinforcement-based approach to\ndynamically estimating source task weights that measure the contribution of the\ncorresponding tasks to the target task in the meta-transfer learning. The\ndifferences between the general loss of the meta model and task-specific losses\nof source-specific temporal meta models on sampled target data are fed into the\npolicy network of the reinforcement learning module as rewards. The policy\nnetwork is built upon LSTMs that capture long-term dependencies on source task\nweight estimation across meta learning iterations. We evaluate the proposed\nMeta-RTL using both BERT and ALBERT as the backbone of the meta model on three\ncommonsense reasoning benchmark datasets. Experimental results demonstrate that\nMeta-RTL substantially outperforms strong baselines and previous task selection\nstrategies and achieves larger improvements on extremely low-resource settings.\n","authors":["Yu Fu","Jie He","Yifan Yang","Qun Liu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2409.19075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08213v1","updated":"2025-03-11T09:27:56Z","published":"2025-03-11T09:27:56Z","title":"DeepRAG: Building a Custom Hindi Embedding Model for Retrieval Augmented\n  Generation from Scratch","summary":"  In this paper, I present our work on DeepRAG, a specialized embedding model\nwe built specifically for Hindi language in RAG systems. While LLMs have gotten\nreally good at generating text, their performance in retrieval tasks still\ndepends heavily on having quality embeddings - something that's been lacking\nfor Hindi despite being one of the world's most spoken languages. We tackled\nthis by creating embeddings from the ground up rather than just fine-tuning\nexisting models. Our process involved collecting diverse Hindi texts (over 2.7M\nsamples), training a custom SentencePiece tokenizer that actually understands\nHindi morphology, designing transformer architecture with Hindi-specific\nattention mechanisms, and optimizing with contrastive learning. Results were\nhonestly better than I expected - we saw a 23% improvement in retrieval\nprecision compared to the multilingual models everyone's been using. The paper\ndetails our methodology, which I think could help others working with\nlow-resource languages where the one-size-fits-all multilingual models fall\nshort. We've also integrated our embeddings with LangChain to build complete\nHindi RAG systems, which might be useful for practitioners. While there's still\ntons more to explore, I believe this work addresses a critical gap for Hindi\nNLP and demonstrates why language-specific approaches matter.\n","authors":["Nandakishor M"],"pdf_url":"https://arxiv.org/pdf/2503.08213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08195v1","updated":"2025-03-11T09:00:45Z","published":"2025-03-11T09:00:45Z","title":"Dialogue Injection Attack: Jailbreaking LLMs through Context\n  Manipulation","summary":"  Large language models (LLMs) have demonstrated significant utility in a wide\nrange of applications; however, their deployment is plagued by security\nvulnerabilities, notably jailbreak attacks. These attacks manipulate LLMs to\ngenerate harmful or unethical content by crafting adversarial prompts. While\nmuch of the current research on jailbreak attacks has focused on single-turn\ninteractions, it has largely overlooked the impact of historical dialogues on\nmodel behavior. In this paper, we introduce a novel jailbreak paradigm,\nDialogue Injection Attack (DIA), which leverages the dialogue history to\nenhance the success rates of such attacks. DIA operates in a black-box setting,\nrequiring only access to the chat API or knowledge of the LLM's chat template.\nWe propose two methods for constructing adversarial historical dialogues: one\nadapts gray-box prefilling attacks, and the other exploits deferred responses.\nOur experiments show that DIA achieves state-of-the-art attack success rates on\nrecent LLMs, including Llama-3.1 and GPT-4o. Additionally, we demonstrate that\nDIA can bypass 5 different defense mechanisms, highlighting its robustness and\neffectiveness.\n","authors":["Wenlong Meng","Fan Zhang","Wendao Yao","Zhenyuan Guo","Yuwei Li","Chengkun Wei","Wenzhi Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08195v1.pdf","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.08192v1","updated":"2025-03-11T08:55:52Z","published":"2025-03-11T08:55:52Z","title":"Automating Violence Detection and Categorization from Ancient Texts","summary":"  Violence descriptions in literature offer valuable insights for a wide range\nof research in the humanities. For historians, depictions of violence are of\nspecial interest for analyzing the societal dynamics surrounding large wars and\nindividual conflicts of influential people. Harvesting data for violence\nresearch manually is laborious and time-consuming. This study is the first one\nto evaluate the effectiveness of large language models (LLMs) in identifying\nviolence in ancient texts and categorizing it across multiple dimensions. Our\nexperiments identify LLMs as a valuable tool to scale up the accurate analysis\nof historical texts and show the effect of fine-tuning and data augmentation,\nyielding an F1-score of up to 0.93 for violence detection and 0.86 for\nfine-grained violence categorization.\n","authors":["Alhassan Abdelhalim","Michaela Regneri"],"pdf_url":"https://arxiv.org/pdf/2503.08192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14856v2","updated":"2025-03-11T08:54:55Z","published":"2025-02-20T18:58:10Z","title":"FR-Spec: Accelerating Large-Vocabulary Language Models via\n  Frequency-Ranked Speculative Sampling","summary":"  Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12$\\times$ speedup over the\nstate-of-the-art speculative sampling method EAGLE-2. Code available at\nhttps://github.com/thunlp/FR-Spec.\n","authors":["Weilin Zhao","Tengyu Pan","Xu Han","Yudi Zhang","Ao Sun","Yuxiang Huang","Kaihuo Zhang","Weilun Zhao","Yuxuan Li","Jianyong Wang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08188v1","updated":"2025-03-11T08:53:53Z","published":"2025-03-11T08:53:53Z","title":"RigoChat 2: an adapted language model to Spanish using a bounded dataset\n  and reduced hardware","summary":"  Large Language Models (LLMs) have become a key element of modern artificial\nintelligence, demonstrating the ability to address a wide range of language\nprocessing tasks at unprecedented levels of accuracy without the need of\ncollecting problem-specific data. However, these versatile models face a\nsignificant challenge: both their training and inference processes require\nsubstantial computational resources, time, and memory. Consequently, optimizing\nthis kind of models to minimize these requirements is crucial. In this article,\nwe demonstrate that, with minimal resources and in a remarkably short time, it\nis possible to enhance a state-of-the-art model, specifically for a given\nlanguage task, without compromising its overall capabilities using a relatively\nsmall pretrained LLM as a basis. Specifically, we present our use case,\nRigoChat 2, illustrating how LLMs can be adapted to achieve superior results in\nSpanish-language tasks.\n","authors":["Gonzalo Santamaría Gómez","Guillem García Subies","Pablo Gutiérrez Ruiz","Mario González Valero","Natàlia Fuertes","Helena Montoro Zamorano","Carmen Muñoz Sanz","Leire Rosado Plaza","Nuria Aldama García","David Betancur Sánchez","Kateryna Sushkova","Marta Guerrero Nieto","Álvaro Barbero Jiménez"],"pdf_url":"https://arxiv.org/pdf/2503.08188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19345v4","updated":"2025-03-11T08:39:45Z","published":"2024-07-27T21:56:23Z","title":"Inference-Time Selective Debiasing to Enhance Fairness in Text\n  Classification Models","summary":"  We propose selective debiasing -- an inference-time safety mechanism designed\nto enhance the overall model quality in terms of prediction performance and\nfairness, especially in scenarios where retraining the model is impractical.\nThe method draws inspiration from selective classification, where at inference\ntime, predictions with low quality, as indicated by their uncertainty scores,\nare discarded. In our approach, we identify the potentially biased model\npredictions and, instead of discarding them, we remove bias from these\npredictions using LEACE -- a post-processing debiasing method. To select\nproblematic predictions, we propose a bias quantification approach based on KL\ndivergence, which achieves better results than standard uncertainty\nquantification methods. Experiments on text classification datasets with\nencoder-based classification models demonstrate that selective debiasing helps\nto reduce the performance gap between post-processing methods and debiasing\ntechniques from the at-training and pre-processing categories.\n","authors":["Gleb Kuzmin","Neemesh Yadav","Ivan Smirnov","Timothy Baldwin","Artem Shelmanov"],"pdf_url":"https://arxiv.org/pdf/2407.19345v4.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08162v1","updated":"2025-03-11T08:27:01Z","published":"2025-03-11T08:27:01Z","title":"FASIONAD++ : Integrating High-Level Instruction and Information\n  Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous\n  Driving with Adaptive Feedback","summary":"  Ensuring safe, comfortable, and efficient planning is crucial for autonomous\ndriving systems. While end-to-end models trained on large datasets perform well\nin standard driving scenarios, they struggle with complex low-frequency events.\nRecent Large Language Models (LLMs) and Vision Language Models (VLMs)\nadvancements offer enhanced reasoning but suffer from computational\ninefficiency. Inspired by the dual-process cognitive model \"Thinking, Fast and\nSlow\", we propose $\\textbf{FASIONAD}$ -- a novel dual-system framework that\nsynergizes a fast end-to-end planner with a VLM-based reasoning module. The\nfast system leverages end-to-end learning to achieve real-time trajectory\ngeneration in common scenarios, while the slow system activates through\nuncertainty estimation to perform contextual analysis and complex scenario\nresolution. Our architecture introduces three key innovations: (1) A dynamic\nswitching mechanism enabling slow system intervention based on real-time\nuncertainty assessment; (2) An information bottleneck with high-level plan\nfeedback that optimizes the slow system's guidance capability; (3) A\nbidirectional knowledge exchange where visual prompts enhance the slow system's\nreasoning while its feedback refines the fast planner's decision-making. To\nstrengthen VLM reasoning, we develop a question-answering mechanism coupled\nwith reward-instruct training strategy. In open-loop experiments, FASIONAD\nachieves a $6.7\\%$ reduction in average $L2$ trajectory error and $28.1\\%$\nlower collision rate.\n","authors":["Kangan Qian","Ziang Luo","Sicong Jiang","Zilin Huang","Jinyu Miao","Zhikun Ma","Tianze Zhu","Jiayin Li","Yangfan He","Zheng Fu","Yining Shi","Boyue Wang","Hezhe Lin","Ziyu Chen","Jiangbo Yu","Xinyu Jiao","Mengmeng Yang","Kun Jiang","Diange Yang"],"pdf_url":"https://arxiv.org/pdf/2503.08162v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.08161v1","updated":"2025-03-11T08:26:37Z","published":"2025-03-11T08:26:37Z","title":"OASIS: Order-Augmented Strategy for Improved Code Search","summary":"  Code embeddings capture the semantic representations of code and are crucial\nfor various code-related large language model (LLM) applications, such as code\nsearch. Previous training primarily relies on optimizing the InfoNCE loss by\ncomparing positive natural language (NL)-code pairs with in-batch negatives.\nHowever, due to the sparse nature of code contexts, training solely by\ncomparing the major differences between positive and negative pairs may fail to\ncapture deeper semantic nuances. To address this issue, we propose a novel\norder-augmented strategy for improved code search (OASIS). It leverages\norder-based similarity labels to train models to capture subtle differences in\nsimilarity among negative pairs. Extensive benchmark evaluations demonstrate\nthat our OASIS model significantly outperforms previous state-of-the-art models\nfocusing solely on major positive-negative differences. It underscores the\nvalue of exploiting subtle differences among negative pairs with order labels\nfor effective code embedding training.\n","authors":["Zuchen Gao","Zizheng Zhan","Xianming Li","Erxin Yu","Haotian Zhang","Yuqun Zhang","Jing Li"],"pdf_url":"https://arxiv.org/pdf/2503.08161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08159v1","updated":"2025-03-11T08:16:31Z","published":"2025-03-11T08:16:31Z","title":"Mimicking How Humans Interpret Out-of-Context Sentences Through\n  Controlled Toxicity Decoding","summary":"  Interpretations of a single sentence can vary, particularly when its context\nis lost. This paper aims to simulate how readers perceive content with varying\ntoxicity levels by generating diverse interpretations of out-of-context\nsentences. By modeling toxicity, we can anticipate misunderstandings and reveal\nhidden toxic meanings. Our proposed decoding strategy explicitly controls\ntoxicity in the set of generated interpretations by (i) aligning interpretation\ntoxicity with the input, (ii) relaxing toxicity constraints for more toxic\ninput sentences, and (iii) promoting diversity in toxicity levels within the\nset of generated interpretations. Experimental results show that our method\nimproves alignment with human-written interpretations in both syntax and\nsemantics while reducing model prediction uncertainty.\n","authors":["Maria Mihaela Trusca","Liesbeth Allein"],"pdf_url":"https://arxiv.org/pdf/2503.08159v1.pdf","comment":"Short paper; accepted at TrustNLP @ NAACL 2025"},{"id":"http://arxiv.org/abs/2305.18226v3","updated":"2025-03-11T08:08:05Z","published":"2023-05-26T11:07:25Z","title":"HowkGPT: Investigating the Detection of ChatGPT-generated University\n  Student Homework through Context-Aware Perplexity Analysis","summary":"  As the use of Large Language Models (LLMs) in text generation tasks\nproliferates, concerns arise over their potential to compromise academic\nintegrity. The education sector currently tussles with distinguishing\nstudent-authored homework assignments from AI-generated ones. This paper\naddresses the challenge by introducing HowkGPT, designed to identify homework\nassignments generated by AI. HowkGPT is built upon a dataset of academic\nassignments and accompanying metadata [17] and employs a pretrained LLM to\ncompute perplexity scores for student-authored and ChatGPT-generated responses.\nThese scores then assist in establishing a threshold for discerning the origin\nof a submitted assignment. Given the specificity and contextual nature of\nacademic work, HowkGPT further refines its analysis by defining\ncategory-specific thresholds derived from the metadata, enhancing the precision\nof the detection. This study emphasizes the critical need for effective\nstrategies to uphold academic integrity amidst the growing influence of LLMs\nand provides an approach to ensuring fair and accurate grading in educational\ninstitutions.\n","authors":["Christoforos Vasilatos","Manaar Alam","Talal Rahwan","Yasir Zaki","Michail Maniatakos"],"pdf_url":"https://arxiv.org/pdf/2305.18226v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04807v2","updated":"2025-03-11T07:10:07Z","published":"2025-03-04T02:04:58Z","title":"Call for Rigor in Reporting Quality of Instruction Tuning Data","summary":"  Instruction tuning is crucial for adapting large language models (LLMs) to\nalign with user intentions. Numerous studies emphasize the significance of the\nquality of instruction tuning (IT) data, revealing a strong correlation between\nIT data quality and the alignment performance of LLMs. In these studies, the\nquality of IT data is typically assessed by evaluating the performance of LLMs\ntrained with that data. However, we identified a prevalent issue in such\npractice: hyperparameters for training models are often selected arbitrarily\nwithout adequate justification. We observed significant variations in\nhyperparameters applied across different studies, even when training the same\nmodel with the same data. In this study, we demonstrate the potential problems\narising from this practice and emphasize the need for careful consideration in\nverifying data quality. Through our experiments on the quality of LIMA data and\na selected set of 1,000 Alpaca data points, we demonstrate that arbitrary\nhyperparameter decisions can make any arbitrary conclusion.\n","authors":["Hyeonseok Moon","Jaehyung Seo","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2503.04807v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.08102v1","updated":"2025-03-11T07:05:52Z","published":"2025-03-11T07:05:52Z","title":"AI-native Memory 2.0: Second Me","summary":"  Human interaction with the external world fundamentally involves the exchange\nof personal memory, whether with other individuals, websites, applications, or,\nin the future, AI agents. A significant portion of this interaction is\nredundant, requiring users to repeatedly provide the same information across\ndifferent contexts. Existing solutions, such as browser-stored credentials,\nautofill mechanisms, and unified authentication systems, have aimed to mitigate\nthis redundancy by serving as intermediaries that store and retrieve commonly\nused user data. The advent of large language models (LLMs) presents an\nopportunity to redefine memory management through an AI-native paradigm: SECOND\nME. SECOND ME acts as an intelligent, persistent memory offload system that\nretains, organizes, and dynamically utilizes user-specific knowledge. By\nserving as an intermediary in user interactions, it can autonomously generate\ncontext-aware responses, prefill required information, and facilitate seamless\ncommunication with external systems, significantly reducing cognitive load and\ninteraction friction. Unlike traditional memory storage solutions, SECOND ME\nextends beyond static data retention by leveraging LLM-based memory\nparameterization. This enables structured organization, contextual reasoning,\nand adaptive knowledge retrieval, facilitating a more systematic and\nintelligent approach to memory management. As AI-driven personal agents like\nSECOND ME become increasingly integrated into digital ecosystems, SECOND ME\nfurther represents a critical step toward augmenting human-world interaction\nwith persistent, contextually aware, and self-optimizing memory systems. We\nhave open-sourced the fully localizable deployment system at GitHub:\nhttps://github.com/Mindverse/Second-Me.\n","authors":["Jiale Wei","Xiang Ying","Tao Gao","Felix Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.08102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09484v2","updated":"2025-03-11T06:54:09Z","published":"2025-01-16T11:41:14Z","title":"Exploring the Inquiry-Diagnosis Relationship with Advanced Patient\n  Simulators","summary":"  Recently, large language models have shown great potential to transform\nonline medical consultation. Despite this, most research targets improving\ndiagnostic accuracy with ample information, often overlooking the inquiry\nphase. Some studies try to evaluate or refine doctor models by using\nprompt-engineered patient agents. However, prompt engineering alone falls short\nin accurately simulating real patients. We need to explore new paradigms for\npatient simulation. Furthermore, the relationship between inquiry and diagnosis\nremains unexplored. This paper extracts dialogue strategies from real\ndoctor-patient conversations to guide the training of a patient simulator. Our\nsimulator shows higher anthropomorphism and lower hallucination rates, using\ndynamic dialogue strategies. This innovation offers a more accurate evaluation\nof diagnostic models and generates realistic synthetic data. We conduct\nextensive experiments on the relationship between inquiry and diagnosis,\nshowing they adhere to Liebig's law: poor inquiry limits diagnosis\neffectiveness, regardless of diagnostic skill, and vice versa. The experiments\nalso reveal substantial differences in inquiry performance among models. To\ndelve into this phenomenon, the inquiry process is categorized into four\ndistinct types. Analyzing the distribution of inquiries across these types\nhelps explain the performance differences. The weights of our patient simulator\nare available https://github.com/PatientSimulator/PatientSimulator.\n","authors":["Zhaocheng Liu","Quan Tu","Wen Ye","Yu Xiao","Zhishou Zhang","Hengfu Cui","Yalun Zhu","Qiang Ju","Shizheng Li","Jian Xie"],"pdf_url":"https://arxiv.org/pdf/2501.09484v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13484v3","updated":"2025-03-11T06:49:47Z","published":"2025-01-23T08:57:33Z","title":"MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation\n  Methods","summary":"  Mamba is an efficient sequence model that rivals Transformers and\ndemonstrates significant potential as a foundational architecture for various\ntasks. Quantization is commonly used in neural networks to reduce model size\nand computational latency. However, applying quantization to Mamba remains\nunderexplored, and existing quantization methods, which have been effective for\nCNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot\nsuffers a 21% accuracy drop on Vim-T$^\\dagger$ even under W8A8). We have\npioneered the exploration of this issue and identified several key challenges.\nFirst, significant outliers are present in gate projections, output\nprojections, and matrix multiplications. Second, Mamba's unique parallel scan\nfurther amplifies these outliers, leading to uneven and heavy-tailed data\ndistributions. Third, even with the application of the Hadamard transform, the\nvariance across channels in weights and activations still remains inconsistent.\nTo these ends, we propose MambaQuant, a post-training quantization (PTQ)\nframework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced\nrotation, rendering the rotation matrix adaptable to diverse channel\ndistributions. 2) Smooth-Fused rotation, which equalizes channel variances and\ncan merge additional parameters into model weights. Experiments show that\nMambaQuant can quantize both weights and activations into 8-bit with less than\n1% accuracy loss for Mamba-based vision and language tasks. To the best of our\nknowledge, MambaQuant is the first comprehensive PTQ design for the Mamba\nfamily, paving the way for further advancements in its application.\n","authors":["Zukang Xu","Yuxuan Yue","Xing Hu","Zhihang Yuan","Zixu Jiang","Zhixuan Chen","Jiangyong Yu","Chen Xu","Sifan Zhou","Dawei Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13484v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08079v1","updated":"2025-03-11T06:21:49Z","published":"2025-03-11T06:21:49Z","title":"Advancing Sentiment Analysis: A Novel LSTM Framework with Multi-head\n  Attention","summary":"  This work proposes an LSTM-based sentiment classification model with\nmulti-head attention mechanism and TF-IDF optimization. Through the integration\nof TF-IDF feature extraction and multi-head attention, the model significantly\nimproves text sentiment analysis performance. Experimental results on public\ndata sets demonstrate that the new method achieves substantial improvements in\nthe most critical metrics like accuracy, recall, and F1-score compared to\nbaseline models. Specifically, the model achieves an accuracy of 80.28% on the\ntest set, which is improved by about 12% in comparison with standard LSTM\nmodels. Ablation experiments also support the necessity and necessity of all\nmodules, in which the impact of multi-head attention is greatest to performance\nimprovement. This research provides a proper approach to sentiment analysis,\nwhich can be utilized in public opinion monitoring, product recommendation,\netc.\n","authors":["Jingyuan Yi","Peiyang Yu","Tianyi Huang","Xiaochuan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.08079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04036v2","updated":"2025-03-11T06:10:02Z","published":"2025-03-06T02:40:51Z","title":"Robust Data Watermarking in Language Models by Injecting Fictitious\n  Knowledge","summary":"  Data watermarking in language models injects traceable signals, such as\nspecific token sequences or stylistic patterns, into copyrighted text, allowing\ncopyright holders to track and verify training data ownership. Previous data\nwatermarking techniques primarily focus on effective memorization after\npretraining, while overlooking challenges that arise in other stages of the LLM\npipeline, such as the risk of watermark filtering during data preprocessing, or\npotential forgetting through post-training, or verification difficulties due to\nAPI-only access. We propose a novel data watermarking approach that injects\ncoherent and plausible yet fictitious knowledge into training data using\ngenerated passages describing a fictitious entity and its associated\nattributes. Our watermarks are designed to be memorized by the LLM through\nseamlessly integrating in its training data, making them harder to detect\nlexically during preprocessing. We demonstrate that our watermarks can be\neffectively memorized by LLMs, and that increasing our watermarks' density,\nlength, and diversity of attributes strengthens their memorization. We further\nshow that our watermarks remain robust throughout LLM development, maintaining\ntheir effectiveness after continual pretraining and supervised finetuning.\nFinally, we show that our data watermarks can be evaluated even under API-only\naccess via question answering.\n","authors":["Xinyue Cui","Johnny Tian-Zheng Wei","Swabha Swayamdipta","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2503.04036v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08075v1","updated":"2025-03-11T06:08:42Z","published":"2025-03-11T06:08:42Z","title":"MuCoS: Efficient Drug Target Discovery via Multi Context Aware Sampling\n  in Knowledge Graphs","summary":"  Accurate prediction of drug target interactions is critical for accelerating\ndrug discovery and elucidating complex biological mechanisms. In this work, we\nframe drug target prediction as a link prediction task on heterogeneous\nbiomedical knowledge graphs (KG) that integrate drugs, proteins, diseases,\npathways, and other relevant entities. Conventional KG embedding methods such\nas TransE and ComplEx SE are hindered by their reliance on computationally\nintensive negative sampling and their limited generalization to unseen drug\ntarget pairs. To address these challenges, we propose Multi Context Aware\nSampling (MuCoS), a novel framework that prioritizes high-density neighbours to\ncapture salient structural patterns and integrates these with contextual\nembeddings derived from BERT. By unifying structural and textual modalities and\nselectively sampling highly informative patterns, MuCoS circumvents the need\nfor negative sampling, significantly reducing computational overhead while\nenhancing predictive accuracy for novel drug target associations and drug\ntargets. Extensive experiments on the KEGG50k dataset demonstrate that MuCoS\noutperforms state-of-the-art baselines, achieving up to a 13\\% improvement in\nmean reciprocal rank (MRR) in predicting any relation in the dataset and a 6\\%\nimprovement in dedicated drug target relation prediction.\n","authors":["Haji Gul","Abdul Ghani Naim","Ajaz Ahmad Bhat"],"pdf_url":"https://arxiv.org/pdf/2503.08075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08067v1","updated":"2025-03-11T05:54:58Z","published":"2025-03-11T05:54:58Z","title":"Context-aware Biases for Length Extrapolation","summary":"  Transformers' ability to generalize to longer sequences than they have been\ntrained on, known as length extrapolation, degrades as sequence length\nincreases. Most of Relative Positional Encoding (RPE) methods address this\nproblem by either adding constant linear biases or learning general biases,\nlacking the ability to specialize for different sequences. In this work,\ninspired by ALiBi, we propose Context-aware Biases for Length Extrapolation\n(Cable), that learns token-specific biases for each head in decoder-based\ntransformers. Cable learns adaptive, context-aware biases, overcoming the\nlimitations of fixed patterns by adding dynamic biases specific to each token\nin the sequence. Results show that when tested on a sequence length of 1024, a\nGPT-3 Medium (334M parameters) with our positional encoding, trained on a\nsequence length of 512, achieves better perplexity (-0.65) than a similar\nnetwork with sinusoidal positional encoding trained on a sequence length of\n1024. This is achieved with 48% lower memory usage, and only 3.5% higher\ntraining time. Furthermore, our method notably improves the extrapolation\nability of existing RPE methods on the Edu-FineWeb10B and WikiText-103\ndatasets. Code is available at: https://github.com/axiomlab/Cable\n","authors":["Ali Veisi","Amir Mansourian"],"pdf_url":"https://arxiv.org/pdf/2503.08067v1.pdf","comment":"11 pages, 8 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.08057v1","updated":"2025-03-11T05:27:28Z","published":"2025-03-11T05:27:28Z","title":"Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual\n  and Diverse Open-Ended Text Generation","summary":"  Large Language Models (LLMs) are increasingly required to generate text that\nis both factually accurate and diverse across various open-ended applications.\nHowever, current stochastic decoding methods struggle to balance such\nobjectives. We introduce Dynamic Focus Decoding (DFD), a novel plug-and-play\nstochastic approach that resolves this trade-off without requiring additional\ndata, knowledge, or models. DFD adaptively adjusts the decoding focus based on\ndistributional differences across layers, leveraging the modular and\nhierarchical nature of factual knowledge within LLMs. This dynamic adjustment\nimproves factuality in knowledge-intensive decoding steps and promotes\ndiversity in less knowledge-reliant steps. DFD can be easily integrated with\nexisting decoding methods, enhancing both factuality and diversity with minimal\ncomputational overhead. Extensive experiments across seven datasets demonstrate\nthat DFD significantly improves performance, providing a scalable and efficient\nsolution for open-ended text generation.\n","authors":["Wen Luo","Feifan Song","Wei Li","Guangyue Peng","Shaohang Wei","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08045v1","updated":"2025-03-11T05:00:19Z","published":"2025-03-11T05:00:19Z","title":"Adapting Large Language Models for Parameter-Efficient Log Anomaly\n  Detection","summary":"  Log Anomaly Detection (LAD) seeks to identify atypical patterns in log data\nthat are crucial to assessing the security and condition of systems. Although\nLarge Language Models (LLMs) have shown tremendous success in various fields,\nthe use of LLMs in enabling the detection of log anomalies is largely\nunexplored. This work aims to fill this gap. Due to the prohibitive costs\ninvolved in fully fine-tuning LLMs, we explore the use of parameter-efficient\nfine-tuning techniques (PEFTs) for adapting LLMs to LAD. To have an in-depth\nexploration of the potential of LLM-driven LAD, we present a comprehensive\ninvestigation of leveraging two of the most popular PEFTs -- Low-Rank\nAdaptation (LoRA) and Representation Fine-tuning (ReFT) -- to tap into three\nprominent LLMs of varying size, including RoBERTa, GPT-2, and Llama-3, for\nparameter-efficient LAD. Comprehensive experiments on four public log datasets\nare performed to reveal important insights into effective LLM-driven LAD in\nseveral key perspectives, including the efficacy of these PEFT-based LLM-driven\nLAD methods, their stability, sample efficiency, robustness w.r.t. unstable\nlogs, and cross-dataset generalization. Code is available at\nhttps://github.com/mala-lab/LogADReft.\n","authors":["Ying Fu Lim","Jiawen Zhu","Guansong Pang"],"pdf_url":"https://arxiv.org/pdf/2503.08045v1.pdf","comment":"12 pages, 5 figures, accepted by PAKDD 2025 special session"},{"id":"http://arxiv.org/abs/2503.06949v2","updated":"2025-03-11T04:58:27Z","published":"2025-03-10T05:54:23Z","title":"LexPro-1.0 Technical Report","summary":"  In this report, we introduce our first-generation reasoning model,\nLexPro-1.0, a large language model designed for the highly specialized Chinese\nlegal domain, offering comprehensive capabilities to meet diverse realistic\nneeds. Existing legal LLMs face two primary challenges. Firstly, their design\nand evaluation are predominantly driven by computer science perspectives,\nleading to insufficient incorporation of legal expertise and logic, which is\ncrucial for high-precision legal applications, such as handling complex\nprosecutorial tasks. Secondly, these models often underperform due to a lack of\ncomprehensive training data from the legal domain, limiting their ability to\neffectively address real-world legal scenarios. To address this, we first\ncompile millions of legal documents covering over 20 types of crimes from 31\nprovinces in China for model training. From the extensive dataset, we further\nselect high-quality for supervised fine-tuning, ensuring enhanced relevance and\nprecision. The model further undergoes large-scale reinforcement learning\nwithout additional supervision, emphasizing the enhancement of its reasoning\ncapabilities and explainability. To validate its effectiveness in complex legal\napplications, we also conduct human evaluations with legal experts. We develop\nfine-tuned models based on DeepSeek-R1-Distilled versions, available in three\ndense configurations: 14B, 32B, and 70B.\n","authors":["Haotian Chen","Yanyu Xu","Boyan Wang","Chaoyue Zhao","Xiaoyu Han","Fang Wang","Lizhen Cui","Yonghui Xu"],"pdf_url":"https://arxiv.org/pdf/2503.06949v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08042v1","updated":"2025-03-11T04:48:22Z","published":"2025-03-11T04:48:22Z","title":"A General Framework to Evaluate Methods for Assessing Dimensions of\n  Lexical Semantic Change Using LLM-Generated Synthetic Data","summary":"  Lexical Semantic Change (LSC) offers insights into cultural and social\ndynamics. Yet, the validity of methods for measuring kinds of LSC has yet to be\nestablished due to the absence of historical benchmark datasets. To address\nthis gap, we develop a novel three-stage evaluation framework that involves: 1)\ncreating a scalable, domain-general methodology for generating synthetic\ndatasets that simulate theory-driven LSC across time, leveraging In-Context\nLearning and a lexical database; 2) using these datasets to evaluate the\neffectiveness of various methods; and 3) assessing their suitability for\nspecific dimensions and domains. We apply this framework to simulate changes\nacross key dimensions of LSC (SIB: Sentiment, Intensity, and Breadth) using\nexamples from psychology, and evaluate the sensitivity of selected methods to\ndetect these artificially induced changes. Our findings support the utility of\nthe synthetic data approach, validate the efficacy of tailored methods for\ndetecting synthetic changes in SIB, and reveal that a state-of-the-art LSC\nmodel faces challenges in detecting affective dimensions of LSC. This framework\nprovides a valuable tool for dimension- and domain-specific bench-marking and\nevaluation of LSC methods, with particular benefits for the social sciences.\n","authors":["Naomi Baes","Raphaël Merx","Nick Haslam","Ekaterina Vylomova","Haim Dubossarsky"],"pdf_url":"https://arxiv.org/pdf/2503.08042v1.pdf","comment":"36 pages, under review"},{"id":"http://arxiv.org/abs/2503.08035v1","updated":"2025-03-11T04:32:54Z","published":"2025-03-11T04:32:54Z","title":"Group Preference Alignment: Customized LLM Response Generation from\n  In-Situ Conversations","summary":"  LLMs often fail to meet the specialized needs of distinct user groups due to\ntheir one-size-fits-all training paradigm \\cite{lucy-etal-2024-one} and there\nis limited research on what personalization aspects each group expect. To\naddress these limitations, we propose a group-aware personalization framework,\nGroup Preference Alignment (GPA), that identifies context-specific variations\nin conversational preferences across user groups and then steers LLMs to\naddress those preferences. Our approach consists of two steps: (1) Group-Aware\nPreference Extraction, where maximally divergent user-group preferences are\nextracted from real-world conversation logs and distilled into interpretable\nrubrics, and (2) Tailored Response Generation, which leverages these rubrics\nthrough two methods: a) Context-Tuned Inference (GAP-CT), that dynamically\nadjusts responses via context-dependent prompt instructions, and b)\nRubric-Finetuning Inference (GPA-FT), which uses the rubrics to generate\ncontrastive synthetic data for personalization of group-specific models via\nalignment. Experiments demonstrate that our framework significantly improves\nalignment of the output with respect to user preferences and outperforms\nbaseline methods, while maintaining robust performance on standard benchmarks.\n","authors":["Ishani Mondal","Jack W. Stokes","Sujay Kumar Jauhar","Longqi Yang","Mengting Wan","Xiaofeng Xu","Xia Song","Jennifer Neville"],"pdf_url":"https://arxiv.org/pdf/2503.08035v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2503.08030v1","updated":"2025-03-11T04:24:59Z","published":"2025-03-11T04:24:59Z","title":"Learning to Search Effective Example Sequences for In-Context Learning","summary":"  Large language models (LLMs) demonstrate impressive few-shot learning\ncapabilities, but their performance varies widely based on the sequence of\nin-context examples. Key factors influencing this include the sequence's\nlength, composition, and arrangement, as well as its relation to the specific\nquery. Existing methods often tackle these factors in isolation, overlooking\ntheir interdependencies. Moreover, the extensive search space for selecting\noptimal sequences complicates the development of a holistic approach. In this\nwork, we introduce Beam Search-based Example Sequence Constructor (BESC), a\nnovel method for learning to construct optimal example sequences. BESC\naddresses all key factors involved in sequence selection by considering them\njointly during inference, while incrementally building the sequence. This\ndesign enables the use of beam search to significantly reduce the complexity of\nthe search space. Experiments across various datasets and language models show\nnotable improvements in performance.\n","authors":["Xiang Gao","Ankita Sinha","Kamalika Das"],"pdf_url":"https://arxiv.org/pdf/2503.08030v1.pdf","comment":"Accepted to appear at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08026v1","updated":"2025-03-11T04:15:52Z","published":"2025-03-11T04:15:52Z","title":"In Prospect and Retrospect: Reflective Memory Management for Long-term\n  Personalized Dialogue Agents","summary":"  Large Language Models (LLMs) have made significant progress in open-ended\ndialogue, yet their inability to retain and retrieve relevant information from\nlong-term interactions limits their effectiveness in applications requiring\nsustained personalization. External memory mechanisms have been proposed to\naddress this limitation, enabling LLMs to maintain conversational continuity.\nHowever, existing approaches struggle with two key challenges. First, rigid\nmemory granularity fails to capture the natural semantic structure of\nconversations, leading to fragmented and incomplete representations. Second,\nfixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user\ninteraction patterns. In this work, we propose Reflective Memory Management\n(RMM), a novel mechanism for long-term dialogue agents, integrating forward-\nand backward-looking reflections: (1) Prospective Reflection, which dynamically\nsummarizes interactions across granularities-utterances, turns, and\nsessions-into a personalized memory bank for effective future retrieval, and\n(2) Retrospective Reflection, which iteratively refines the retrieval in an\nonline reinforcement learning (RL) manner based on LLMs' cited evidence.\nExperiments show that RMM demonstrates consistent improvement across various\nmetrics and benchmarks. For example, RMM shows more than 10% accuracy\nimprovement over the baseline without memory management on the LongMemEval\ndataset.\n","authors":["Zhen Tan","Jun Yan","I-Hung Hsu","Rujun Han","Zifeng Wang","Long T. Le","Yiwen Song","Yanfei Chen","Hamid Palangi","George Lee","Anand Iyer","Tianlong Chen","Huan Liu","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2503.08026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19419v3","updated":"2025-03-11T04:10:57Z","published":"2024-10-25T09:23:24Z","title":"KAHANI: Culturally-Nuanced Visual Storytelling Tool for Non-Western\n  Cultures","summary":"  Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated\nthe ability to generate compelling text and visual stories. However, their\noutputs are predominantly aligned with the sensibilities of the Global North,\noften resulting in an outsider's gaze on other cultures. As a result,\nnon-Western communities have to put extra effort into generating culturally\nspecific stories. To address this challenge, we developed a visual storytelling\ntool called Kahani that generates culturally grounded visual stories for\nnon-Western cultures. Our tool leverages off-the-shelf models GPT-4 Turbo and\nStable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I prompting\ntechniques, we capture the cultural context from user's prompt and generate\nvivid descriptions of the characters and scene compositions. To evaluate the\neffectiveness of Kahani, we conducted a comparative user study with ChatGPT-4\n(with DALL-E3) in which participants from different regions of India compared\nthe cultural relevance of stories generated by the two tools. The results of\nthe qualitative and quantitative analysis performed in the user study show that\nKahani's visual stories are more culturally nuanced than those generated by\nChatGPT-4. In 27 out of 36 comparisons, Kahani outperformed or was on par with\nChatGPT-4, effectively capturing cultural nuances and incorporating more\nCulturally Specific Items (CSI), validating its ability to generate culturally\ngrounded visual stories.\n","authors":[" Hamna","Deepthi Sudharsan","Agrima Seth","Ritvik Budhiraja","Deepika Khullar","Vyshak Jain","Kalika Bali","Aditya Vashistha","Sameer Segal"],"pdf_url":"https://arxiv.org/pdf/2410.19419v3.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.07536v2","updated":"2025-03-11T03:32:59Z","published":"2025-03-10T17:04:14Z","title":"LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through\n  Two-Stage Rule-Based RL","summary":"  Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges\nfrom the complex interplay between visual perception and logical reasoning,\nparticularly in compact 3B-parameter architectures where architectural\nconstraints limit reasoning capacity and modality alignment.\n  While rule-based reinforcement learning (RL) excels in text-only domains, its\nmultimodal extension confronts two critical barriers: (1) data limitations due\nto ambiguous answers and scarce complex reasoning examples, and (2) degraded\nfoundational reasoning induced by multimodal pretraining. To address these\nchallenges, we propose \\textbf{LMM-R1}, a two-stage framework adapting\nrule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning\nEnhancement (FRE)} followed by \\textbf{Multimodal Generalization Training\n(MGT)}. The FRE stage first strengthens reasoning abilities using text-only\ndata with rule-based RL, then the MGT stage generalizes these reasoning\ncapabilities to multimodal domains.\n  Experiments on Qwen2.5-VL-Instruct-3B demonstrate that LMM-R1 achieves 4.83\\%\nand 4.5\\% average improvements over baselines in multimodal and text-only\nbenchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks.\nThese results validate that text-based reasoning enhancement enables effective\nmultimodal generalization, offering a data-efficient paradigm that bypasses\ncostly high-quality multimodal training data.\n","authors":["Yingzhe Peng","Gongrui Zhang","Miaosen Zhang","Zhiyuan You","Jie Liu","Qipeng Zhu","Kai Yang","Xingzhong Xu","Xin Geng","Xu Yang"],"pdf_url":"https://arxiv.org/pdf/2503.07536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11054v4","updated":"2025-03-11T03:06:17Z","published":"2025-02-16T09:27:44Z","title":"Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on\n  Large Language Models","summary":"  Multi-turn jailbreak attacks simulate real-world human interactions by\nengaging large language models (LLMs) in iterative dialogues, exposing critical\nsafety vulnerabilities. However, existing methods often struggle to balance\nsemantic coherence with attack effectiveness, resulting in either benign\nsemantic drift or ineffective detection evasion. To address this challenge, we\npropose Reasoning-Augmented Conversation, a novel multi-turn jailbreak\nframework that reformulates harmful queries into benign reasoning tasks and\nleverages LLMs' strong reasoning capabilities to compromise safety alignment.\nSpecifically, we introduce an attack state machine framework to systematically\nmodel problem translation and iterative reasoning, ensuring coherent query\ngeneration across multiple turns. Building on this framework, we design\ngain-guided exploration, self-play, and rejection feedback modules to preserve\nattack semantics, enhance effectiveness, and sustain reasoning-driven attack\nprogression. Extensive experiments on multiple LLMs demonstrate that RACE\nachieves state-of-the-art attack effectiveness in complex conversational\nscenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,\nour approach achieves ASRs of 82% and 92% against leading commercial models,\nOpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at\nhttps://github.com/NY1024/RACE to facilitate further research in this critical\ndomain.\n","authors":["Zonghao Ying","Deyue Zhang","Zonglei Jing","Yisong Xiao","Quanchen Zou","Aishan Liu","Siyuan Liang","Xiangzheng Zhang","Xianglong Liu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2502.11054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07996v1","updated":"2025-03-11T02:52:39Z","published":"2025-03-11T02:52:39Z","title":"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic","summary":"  Recent advancements in Text-to-SQL systems have improved the conversion of\nnatural language queries into SQL, but challenges remain in ensuring accuracy\nand reliability. While self-correction techniques refine outputs, they often\nintroduce new errors. Existing methods focused on execution feedback mainly\naddress syntax issues, leaving semantic errors -- where the query's logic fails\nto align with the user's intent -- largely unaddressed.\n  We propose a novel approach combining structured execution feedback with a\ntrained critic agent that provides detailed, interpretable critiques. This\nmethod effectively identifies and corrects both syntactic and semantic errors,\nenhancing accuracy and interpretability. Experimental results show significant\nimprovements on two major Text-to-SQL benchmarks, Spider and BIRD,\ndemonstrating the effectiveness of our approach.\n","authors":["Jikai Chen","Leilei Gan"],"pdf_url":"https://arxiv.org/pdf/2503.07996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07990v1","updated":"2025-03-11T02:49:41Z","published":"2025-03-11T02:49:41Z","title":"Enhancing Multilingual Language Models for Code-Switched Input Data","summary":"  Code-switching, or alternating between languages within a single\nconversation, presents challenges for multilingual language models on NLP\ntasks. This research investigates if pre-training Multilingual BERT (mBERT) on\ncode-switched datasets improves the model's performance on critical NLP tasks\nsuch as part of speech tagging, sentiment analysis, named entity recognition,\nand language identification. We use a dataset of Spanglish tweets for\npre-training and evaluate the pre-trained model against a baseline model.\n  Our findings show that our pre-trained mBERT model outperforms or matches the\nbaseline model in the given tasks, with the most significant improvements seen\nfor parts of speech tagging. Additionally, our latent analysis uncovers more\nhomogenous English and Spanish embeddings for language identification tasks,\nproviding insights for future modeling work.\n  This research highlights potential for adapting multilingual LMs for\ncode-switched input data in order for advanced utility in globalized and\nmultilingual contexts. Future work includes extending experiments to other\nlanguage pairs, incorporating multiform data, and exploring methods for better\nunderstanding context-dependent code-switches.\n","authors":["Katherine Xie","Nitya Babbar","Vicky Chen","Yoanna Turura"],"pdf_url":"https://arxiv.org/pdf/2503.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06772v2","updated":"2025-03-11T02:46:19Z","published":"2025-02-10T18:51:47Z","title":"ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates","summary":"  We present that hierarchical LLM reasoning via scaling thought templates can\neffectively optimize the reasoning search space and outperform the mathematical\nreasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3.\nWe train our ReasonFlux-32B model with only 8 GPUs and introduces three\ninnovations: (i) a structured and generic thought template library, containing\naround 500 high-level thought templates capable of generalizing to similar or\nrelevant reasoning problems; (ii) performing hierarchical reinforcement\nlearning on a sequence of thought templates instead of long CoTs, optimizing a\nbase LLM to plan out an optimal template trajectory for gradually handling\ncomplex problems; (iii) a brand new inference scaling system that enables\nhierarchical LLM reasoning by adaptively scaling thought templates at inference\ntime. With a template trajectory containing more explainable reasoning\nstructures than DeepSeek-R1 and o3-mini, our ReasonFlux-32B significantly\nadvances math reasoning capabilities to state-of-the-art levels. Notably, on\nthe MATH benchmark, it achieves an accuracy of 91.2% and surpasses o1-preview\nby 6.7%. On the USA Math Olympiad (AIME) benchmark, ReasonFlux-32B solves an\naverage of 56.7% of problems, surpassing o1-preview and DeepSeek-V3 by 27% and\n45%, respectively. Code: https://github.com/Gen-Verse/ReasonFlux\n","authors":["Ling Yang","Zhaochen Yu","Bin Cui","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2502.06772v2.pdf","comment":"Code: https://github.com/Gen-Verse/ReasonFlux"},{"id":"http://arxiv.org/abs/2503.07111v2","updated":"2025-03-11T02:26:42Z","published":"2025-03-10T09:34:05Z","title":"PoseLess: Depth-Free Vision-to-Joint Control via Direct Image Mapping\n  with VLM","summary":"  This paper introduces PoseLess, a novel framework for robot hand control that\neliminates the need for explicit pose estimation by directly mapping 2D images\nto joint angles using projected representations. Our approach leverages\nsynthetic training data generated through randomized joint configurations,\nenabling zero-shot generalization to real-world scenarios and cross-morphology\ntransfer from robotic to human hands. By projecting visual inputs and employing\na transformer-based decoder, PoseLess achieves robust, low-latency control\nwhile addressing challenges such as depth ambiguity and data scarcity.\nExperimental results demonstrate competitive performance in joint angle\nprediction accuracy without relying on any human-labelled dataset.\n","authors":["Alan Dao","Dinh Bach Vu","Tuan Le Duc Anh","Bui Quang Huy"],"pdf_url":"https://arxiv.org/pdf/2503.07111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05331v2","updated":"2025-03-11T02:16:12Z","published":"2024-10-06T01:13:49Z","title":"Taylor Unswift: Secured Weight Release for Large Language Models via\n  Taylor Expansion","summary":"  Ensuring the security of released large language models (LLMs) poses a\nsignificant dilemma, as existing mechanisms either compromise ownership rights\nor raise data privacy concerns. To address this dilemma, we introduce TaylorMLP\nto protect the ownership of released LLMs and prevent their abuse.\nSpecifically, TaylorMLP preserves the ownership of LLMs by transforming the\nweights of LLMs into parameters of Taylor-series. Instead of releasing the\noriginal weights, developers can release the Taylor-series parameters with\nusers, thereby ensuring the security of LLMs. Moreover, TaylorMLP can prevent\nabuse of LLMs by adjusting the generation speed. It can induce low-speed token\ngeneration for the protected LLMs by increasing the terms in the Taylor-series.\nThis intentional delay helps LLM developers prevent potential large-scale\nunauthorized uses of their models. Empirical experiments across five datasets\nand three LLM architectures demonstrate that TaylorMLP induces over 4x increase\nin latency, producing the tokens precisely matched with original LLMs.\nSubsequent defensive experiments further confirm that TaylorMLP effectively\nprevents users from reconstructing the weight values based on downstream\ndatasets.\n","authors":["Guanchu Wang","Yu-Neng Chuang","Ruixiang Tang","Shaochen Zhong","Jiayi Yuan","Hongye Jin","Zirui Liu","Vipin Chaudhary","Shuai Xu","James Caverlee","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2410.05331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10118v5","updated":"2025-03-11T02:04:36Z","published":"2024-06-14T15:23:39Z","title":"SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for\n  Southeast Asian Languages","summary":"  Southeast Asia (SEA) is a region rich in linguistic diversity and cultural\nvariety, with over 1,300 indigenous languages and a population of 671 million\npeople. However, prevailing AI models suffer from a significant lack of\nrepresentation of texts, images, and audio datasets from SEA, compromising the\nquality of AI models for SEA languages. Evaluating models for SEA languages is\nchallenging due to the scarcity of high-quality datasets, compounded by the\ndominance of English training data, raising concerns about potential cultural\nmisrepresentation. To address these challenges, we introduce SEACrowd, a\ncollaborative initiative that consolidates a comprehensive resource hub that\nfills the resource gap by providing standardized corpora in nearly 1,000 SEA\nlanguages across three modalities. Through our SEACrowd benchmarks, we assess\nthe quality of AI models on 36 indigenous languages across 13 tasks, offering\nvaluable insights into the current AI landscape in SEA. Furthermore, we propose\nstrategies to facilitate greater AI advancements, maximizing potential utility\nand resource equity for the future of AI in SEA.\n","authors":["Holy Lovenia","Rahmad Mahendra","Salsabil Maulana Akbar","Lester James V. Miranda","Jennifer Santoso","Elyanah Aco","Akhdan Fadhilah","Jonibek Mansurov","Joseph Marvin Imperial","Onno P. Kampman","Joel Ruben Antony Moniz","Muhammad Ravi Shulthan Habibi","Frederikus Hudi","Railey Montalan","Ryan Ignatius","Joanito Agili Lopo","William Nixon","Börje F. Karlsson","James Jaya","Ryandito Diandaru","Yuze Gao","Patrick Amadeus","Bin Wang","Jan Christian Blaise Cruz","Chenxi Whitehouse","Ivan Halim Parmonangan","Maria Khelli","Wenyu Zhang","Lucky Susanto","Reynard Adha Ryanda","Sonny Lazuardi Hermawan","Dan John Velasco","Muhammad Dehan Al Kautsar","Willy Fitra Hendria","Yasmin Moslem","Noah Flynn","Muhammad Farid Adilazuarda","Haochen Li","Johanes Lee","R. Damanhuri","Shuo Sun","Muhammad Reza Qorib","Amirbek Djanibekov","Wei Qi Leong","Quyet V. Do","Niklas Muennighoff","Tanrada Pansuwan","Ilham Firdausi Putra","Yan Xu","Ngee Chia Tai","Ayu Purwarianti","Sebastian Ruder","William Tjhi","Peerat Limkonchotiwat","Alham Fikri Aji","Sedrick Keh","Genta Indra Winata","Ruochen Zhang","Fajri Koto","Zheng-Xin Yong","Samuel Cahyawijaya"],"pdf_url":"https://arxiv.org/pdf/2406.10118v5.pdf","comment":"https://seacrowd.github.io/ Published in EMNLP 2024"},{"id":"http://arxiv.org/abs/2503.04784v2","updated":"2025-03-11T01:59:26Z","published":"2025-02-27T01:56:09Z","title":"KunlunBaize: LLM with Multi-Scale Convolution and Multi-Token Prediction\n  Under TransformerX Framework","summary":"  Large language models have demonstrated remarkable performance across various\ntasks, yet they face challenges such as low computational efficiency, gradient\nvanishing, and difficulties in capturing complex feature interactions. To\naddress these limitations, a novel framework has been proposed. This framework\nincorporates a learnable dense residual skip connection mechanism, a\nTransformerX module a transformer based component integrating multiscale\nconvolution and adaptive activation functions and a multitoken prediction\ninteraction module. The learnable dense residual connections enhance\ninformation flow and feature capture across layers. Within the TransformerX\nmodule, large convolutional kernels aggregate semantic information from\nextensive text segments, while smaller convolutions focus on local word order\nand syntactic structures. The adaptive activation function dynamically adjusts\nits parameters based on the semantic features of the input text, improving the\nmodel's ability to handle diverse semantic expressions and complex\nrelationships. The multitoken prediction module boosts data utilization and\naccelerates inference by predicting multiple future tokens. These components\nsignificantly enhance the performance and efficiency of large language models.\n","authors":["Cheng Li","Jiexiong Liu","Yixuan Chen","Yanqin Jia","Zhepeng Li"],"pdf_url":"https://arxiv.org/pdf/2503.04784v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2503.07968v1","updated":"2025-03-11T01:52:39Z","published":"2025-03-11T01:52:39Z","title":"LabelCoRank: Revolutionizing Long Tail Multi-Label Classification with\n  Co-Occurrence Reranking","summary":"  Motivation: Despite recent advancements in semantic representation driven by\npre-trained and large-scale language models, addressing long tail challenges in\nmulti-label text classification remains a significant issue. Long tail\nchallenges have persistently posed difficulties in accurately classifying less\nfrequent labels. Current approaches often focus on improving text semantics\nwhile neglecting the crucial role of label relationships. Results: This paper\nintroduces LabelCoRank, a novel approach inspired by ranking principles.\nLabelCoRank leverages label co-occurrence relationships to refine initial label\nclassifications through a dual-stage reranking process. The first stage uses\ninitial classification results to form a preliminary ranking. In the second\nstage, a label co-occurrence matrix is utilized to rerank the preliminary\nresults, enhancing the accuracy and relevance of the final classifications. By\nintegrating the reranked label representations as additional text features,\nLabelCoRank effectively mitigates long tail issues in multi-labeltext\nclassification. Experimental evaluations on popular datasets including MAG-CS,\nPubMed, and AAPD demonstrate the effectiveness and robustness of LabelCoRank.\n","authors":["Yan Yan","Junyuan Liu","Bo-Wen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07956v1","updated":"2025-03-11T01:34:03Z","published":"2025-03-11T01:34:03Z","title":"EFPC: Towards Efficient and Flexible Prompt Compression","summary":"  The emergence of large language models (LLMs) like GPT-4 has revolutionized\nnatural language processing (NLP), enabling diverse, complex tasks. However,\nextensive token counts lead to high computational and financial burdens. To\naddress this, we propose Efficient and Flexible Prompt Compression (EFPC), a\nnovel method unifying task-aware and task-agnostic compression for a favorable\naccuracy-efficiency trade-off. EFPC uses GPT-4 to generate compressed prompts\nand integrates them with original prompts for training. During training and\ninference, we selectively prepend user instructions and compress prompts based\non predicted probabilities. EFPC is highly data-efficient, achieving\nsignificant performance with minimal data. Compared to the state-of-the-art\nmethod LLMLingua-2, EFPC achieves a 4.8% relative improvement in F1-score with\n1% additional data at a 4x compression rate, and an 11.4% gain with 10%\nadditional data on the LongBench single-doc QA benchmark. EFPC's unified\nframework supports broad applicability and enhances performance across various\nmodels, tasks, and domains, offering a practical advancement in NLP.\n","authors":["Yun-Hao Cao","Yangsong Wang","Shuzheng Hao","Zhenxing Li","Chengjun Zhan","Sichao Liu","Yi-Qi Hu"],"pdf_url":"https://arxiv.org/pdf/2503.07956v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.07943v1","updated":"2025-03-11T00:53:45Z","published":"2025-03-11T00:53:45Z","title":"Enhancing Sentiment Analysis through Multimodal Fusion: A BERT-DINOv2\n  Approach","summary":"  Multimodal sentiment analysis enhances conventional sentiment analysis, which\ntraditionally relies solely on text, by incorporating information from\ndifferent modalities such as images, text, and audio. This paper proposes a\nnovel multimodal sentiment analysis architecture that integrates text and image\ndata to provide a more comprehensive understanding of sentiments. For text\nfeature extraction, we utilize BERT, a natural language processing model. For\nimage feature extraction, we employ DINOv2, a vision-transformer-based model.\nThe textual and visual latent features are integrated using proposed fusion\ntechniques, namely the Basic Fusion Model, Self Attention Fusion Model, and\nDual Attention Fusion Model. Experiments on three datasets, Memotion 7k\ndataset, MVSA single dataset, and MVSA multi dataset, demonstrate the viability\nand practicality of the proposed multimodal architecture.\n","authors":["Taoxu Zhao","Meisi Li","Kehao Chen","Liye Wang","Xucheng Zhou","Kunal Chaturvedi","Mukesh Prasad","Ali Anaissi","Ali Braytee"],"pdf_url":"https://arxiv.org/pdf/2503.07943v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2412.12478v2","updated":"2025-03-11T00:50:50Z","published":"2024-12-17T02:29:54Z","title":"Human-in-the-Loop Generation of Adversarial Texts: A Case Study on\n  Tibetan Script","summary":"  DNN-based language models perform excellently on various tasks, but even SOTA\nLLMs are susceptible to textual adversarial attacks. Adversarial texts play\ncrucial roles in multiple subfields of NLP. However, current research has the\nfollowing issues. (1) Most textual adversarial attack methods target\nrich-resourced languages. How do we generate adversarial texts for less-studied\nlanguages? (2) Most textual adversarial attack methods are prone to generating\ninvalid or ambiguous adversarial texts. How do we construct high-quality\nadversarial robustness benchmarks? (3) New language models may be immune to\npart of previously generated adversarial texts. How do we update adversarial\nrobustness benchmarks? To address the above issues, we introduce HITL-GAT, a\nsystem based on a general approach to human-in-the-loop generation of\nadversarial texts. HITL-GAT contains four stages in one pipeline: victim model\nconstruction, adversarial example generation, high-quality benchmark\nconstruction, and adversarial robustness evaluation. Additionally, we utilize\nHITL-GAT to make a case study on Tibetan script which can be a reference for\nthe adversarial research of other less-studied languages.\n","authors":["Xi Cao","Yuan Sun","Jiajun Li","Quzong Gesang","Nuo Qun","Tashi Nyima"],"pdf_url":"https://arxiv.org/pdf/2412.12478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03735v2","updated":"2025-03-11T00:20:30Z","published":"2024-09-30T20:49:54Z","title":"Task-Adaptive Pretrained Language Models via Clustered-Importance\n  Sampling","summary":"  Specialist language models (LMs) focus on a specific task or domain on which\nthey often outperform generalist LMs of the same size. However, the specialist\ndata needed to pretrain these models is only available in limited amount for\nmost tasks. In this work, we build specialist models from large generalist\ntraining sets instead. We propose a novel method, ClusteRed Importance SamPling\n(CRISP). CRISP clusters the generalist dataset and samples from these clusters\nbased on their frequencies in the smaller specialist dataset. It is scalable,\nsuitable for both pretraining and continued pretraining, and works well in\nmulti-task settings. CRISP performs favorably compared to other methods that\nadjust the training distribution of the generalist data with guidance from the\nlimited domain-specific data. Our findings demonstrate improvements across\ndifferent domains in terms of language modeling perplexity and accuracy on\nmultiple-choice question tasks. We also present ablation studies that examine\nthe impact of dataset sizes, clustering configurations, and model sizes.\n","authors":["David Grangier","Simin Fan","Skyler Seto","Pierre Ablin"],"pdf_url":"https://arxiv.org/pdf/2410.03735v2.pdf","comment":"23 pages, presented at the International Conference on Learning\n  Representation (ICLR), 2025"},{"id":"http://arxiv.org/abs/2405.19653v3","updated":"2025-03-11T00:01:37Z","published":"2024-05-30T03:12:04Z","title":"SysCaps: Language Interfaces for Simulation Surrogates of Complex\n  Systems","summary":"  Surrogate models are used to predict the behavior of complex energy systems\nthat are too expensive to simulate with traditional numerical methods. Our work\nintroduces the use of language descriptions, which we call ``system captions''\nor SysCaps, to interface with such surrogates. We argue that interacting with\nsurrogates through text, particularly natural language, makes these models more\naccessible for both experts and non-experts. We introduce a lightweight\nmultimodal text and timeseries regression model and a training pipeline that\nuses large language models (LLMs) to synthesize high-quality captions from\nsimulation metadata. Our experiments on two real-world simulators of buildings\nand wind farms show that our SysCaps-augmented surrogates have better accuracy\non held-out systems than traditional methods while enjoying new generalization\nabilities, such as handling semantically related descriptions of the same test\nsystem. Additional experiments also highlight the potential of SysCaps to\nunlock language-driven design space exploration and to regularize training\nthrough prompt augmentation.\n","authors":["Patrick Emami","Zhaonan Li","Saumya Sinha","Truc Nguyen"],"pdf_url":"https://arxiv.org/pdf/2405.19653v3.pdf","comment":"Accepted at ICLR 2025. 23 pages"},{"id":"http://arxiv.org/abs/2503.08963v1","updated":"2025-03-11T23:55:45Z","published":"2025-03-11T23:55:45Z","title":"Gradient-guided Attention Map Editing: Towards Efficient Contextual\n  Hallucination Mitigation","summary":"  In tasks like summarization and open-book question answering (QA), Large\nLanguage Models (LLMs) often encounter \"contextual hallucination\", where they\nproduce irrelevant or incorrect responses despite having access to accurate\nsource information. This typically occurs because these models tend to\nprioritize self-generated content over the input context, causing them to\ndisregard pertinent details. To address this challenge, we introduce a novel\nmethod called \"Guided Attention Map Editing\" (GAME), which dynamically adjusts\nattention maps to improve contextual relevance. During inference, GAME employs\na trained classifier to identify attention maps prone to inducing\nhallucinations and executes targeted interventions. These interventions, guided\nby gradient-informed \"edit directions'', strategically redistribute attention\nweights across various heads to effectively reduce hallucination. Comprehensive\nevaluations on challenging summarization and open-book QA tasks show that GAME\nconsistently reduces hallucinations across a variety of open-source models.\nSpecifically, GAME reduces hallucinations by 10% in the XSum summarization task\nwhile achieving a 7X speed-up in computational efficiency compared to the\nstate-of-the-art baselines.\n","authors":["Yu Wang","Jiaxin Zhang","Xiang Gao","Wendi Cui","Peng Li","Kamalika Das"],"pdf_url":"https://arxiv.org/pdf/2503.08963v1.pdf","comment":"Accepted as Finding of NAACL 2025"},{"id":"http://arxiv.org/abs/2410.20666v2","updated":"2025-03-11T23:45:58Z","published":"2024-10-28T01:58:21Z","title":"Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for\n  Robotic Guidance of People with Visual Impairments","summary":"  Navigation presents a significant challenge for persons with visual\nimpairments (PVI). While traditional aids such as white canes and guide dogs\nare invaluable, they fall short in delivering detailed spatial information and\nprecise guidance to desired locations. Recent developments in large language\nmodels (LLMs) and vision-language models (VLMs) offer new avenues for enhancing\nassistive navigation. In this paper, we introduce Guide-LLM, an embodied\nLLM-based agent designed to assist PVI in navigating large indoor environments.\nOur approach features a novel text-based topological map that enables the LLM\nto plan global paths using a simplified environmental representation, focusing\non straight paths and right-angle turns to facilitate navigation. Additionally,\nwe utilize the LLM's commonsense reasoning for hazard detection and\npersonalized path planning based on user preferences. Simulated experiments\ndemonstrate the system's efficacy in guiding PVI, underscoring its potential as\na significant advancement in assistive technology. The results highlight\nGuide-LLM's ability to offer efficient, adaptive, and personalized navigation\nassistance, pointing to promising advancements in this field.\n","authors":["Sangmim Song","Sarath Kodagoda","Amal Gunatilake","Marc G. Carmichael","Karthick Thiyagarajan","Jodi Martin"],"pdf_url":"https://arxiv.org/pdf/2410.20666v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18469v3","updated":"2025-03-11T23:26:25Z","published":"2024-10-24T06:36:12Z","title":"Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities","summary":"  Recent research has shown that Large Language Models (LLMs) are vulnerable to\nautomated jailbreak attacks, where adversarial suffixes crafted by algorithms\nappended to harmful queries bypass safety alignment and trigger unintended\nresponses. Current methods for generating these suffixes are computationally\nexpensive and have low Attack Success Rates (ASR), especially against\nwell-aligned models like Llama2 and Llama3. To overcome these limitations, we\nintroduce ADV-LLM, an iterative self-tuning process that crafts adversarial\nLLMs with enhanced jailbreak ability. Our framework significantly reduces the\ncomputational cost of generating adversarial suffixes while achieving nearly\n100\\% ASR on various open-source LLMs. Moreover, it exhibits strong attack\ntransferability to closed-source models, achieving 99\\% ASR on GPT-3.5 and 49\\%\nASR on GPT-4, despite being optimized solely on Llama3. Beyond improving\njailbreak ability, ADV-LLM provides valuable insights for future safety\nalignment research through its ability to generate large datasets for studying\nLLM safety.\n","authors":["Chung-En Sun","Xiaodong Liu","Weiwei Yang","Tsui-Wei Weng","Hao Cheng","Aidan San","Michel Galley","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2410.18469v3.pdf","comment":"Accepted to NAACL 2025 Main (oral)"},{"id":"http://arxiv.org/abs/2412.07992v2","updated":"2025-03-11T23:19:17Z","published":"2024-12-11T00:04:10Z","title":"Concept Bottleneck Large Language Models","summary":"  We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel\nframework for building inherently interpretable Large Language Models (LLMs).\nIn contrast to traditional black-box LLMs that rely on limited post-hoc\ninterpretations, CB-LLMs integrate intrinsic interpretability directly into the\nLLMs -- allowing accurate explanations with scalability and transparency. We\nbuild CB-LLMs for two essential NLP tasks: text classification and text\ngeneration. In text classification, CB-LLMs is competitive with, and at times\noutperforms, traditional black-box models while providing explicit and\ninterpretable reasoning. For the more challenging task of text generation,\ninterpretable neurons in CB-LLMs enable precise concept detection, controlled\ngeneration, and safer outputs. The embedded interpretability empowers users to\ntransparently identify harmful content, steer model behavior, and unlearn\nundesired concepts -- significantly enhancing the safety, reliability, and\ntrustworthiness of LLMs, which are critical capabilities notably absent in\nexisting models. Our code is available at\nhttps://github.com/Trustworthy-ML-Lab/CB-LLMs.\n","authors":["Chung-En Sun","Tuomas Oikarinen","Berk Ustun","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2412.07992v2.pdf","comment":"Accepted to ICLR 2025. arXiv admin note: substantial text overlap\n  with arXiv:2407.04307"},{"id":"http://arxiv.org/abs/2503.08954v1","updated":"2025-03-11T23:09:06Z","published":"2025-03-11T23:09:06Z","title":"An Exhaustive Evaluation of TTS- and VC-based Data Augmentation for ASR","summary":"  Augmenting the training data of automatic speech recognition (ASR) systems\nwith synthetic data generated by text-to-speech (TTS) or voice conversion (VC)\nhas gained popularity in recent years. Several works have demonstrated\nimprovements in ASR performance using this augmentation approach. However,\nbecause of the lower diversity of synthetic speech, naively combining synthetic\nand real data often does not yield the best results. In this work, we leverage\nrecently proposed flow-based TTS/VC models allowing greater speech diversity,\nand assess the respective impact of augmenting various speech attributes on the\nword error rate (WER) achieved by several ASR models. Pitch augmentation and\nVC-based speaker augmentation are found to be ineffective in our setup. Jointly\naugmenting all other attributes reduces the WER of a Conformer-Transducer model\nby 11\\% relative on Common Voice and by up to 35\\% relative on LibriSpeech\ncompared to training on real data only.\n","authors":["Sewade Ogun","Vincent Colotte","Emmanuel Vincent"],"pdf_url":"https://arxiv.org/pdf/2503.08954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08919v1","updated":"2025-03-11T22:04:22Z","published":"2025-03-11T22:04:22Z","title":"Backtracking for Safety","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, but ensuring their safety and alignment with human values\nremains crucial. Current safety alignment methods, such as supervised\nfine-tuning and reinforcement learning-based approaches, can exhibit\nvulnerabilities to adversarial attacks and often result in shallow safety\nalignment, primarily focusing on preventing harmful content in the initial\ntokens of the generated output. While methods like resetting can help recover\nfrom unsafe generations by discarding previous tokens and restarting the\ngeneration process, they are not well-suited for addressing nuanced safety\nviolations like toxicity that may arise within otherwise benign and lengthy\ngenerations. In this paper, we propose a novel backtracking method designed to\naddress these limitations. Our method allows the model to revert to a safer\ngeneration state, not necessarily at the beginning, when safety violations\noccur during generation. This approach enables targeted correction of\nproblematic segments without discarding the entire generated text, thereby\npreserving efficiency. We demonstrate that our method dramatically reduces\ntoxicity appearing through the generation process with minimal impact to\nefficiency.\n","authors":["Bilgehan Sel","Dingcheng Li","Phillip Wallis","Vaishakh Keshava","Ming Jin","Siddhartha Reddy Jonnalagadda"],"pdf_url":"https://arxiv.org/pdf/2503.08919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14572v2","updated":"2025-03-11T22:03:26Z","published":"2024-09-22T19:31:16Z","title":"Evaluating the Performance and Robustness of LLMs in Materials Science\n  Q&A and Property Predictions","summary":"  Large Language Models (LLMs) have the potential to revolutionize scientific\nresearch, yet their robustness and reliability in domain-specific applications\nremain insufficiently explored. In this study, we evaluate the performance and\nrobustness of LLMs for materials science, focusing on domain-specific question\nanswering and materials property prediction across diverse real-world and\nadversarial conditions. Three distinct datasets are used in this study: 1) a\nset of multiple-choice questions from undergraduate-level materials science\ncourses, 2) a dataset including various steel compositions and yield strengths,\nand 3) a band gap dataset, containing textual descriptions of material crystal\nstructures and band gap values. The performance of LLMs is assessed using\nvarious prompting strategies, including zero-shot chain-of-thought, expert\nprompting, and few-shot in-context learning. The robustness of these models is\ntested against various forms of 'noise', ranging from realistic disturbances to\nintentionally adversarial manipulations, to evaluate their resilience and\nreliability under real-world conditions. Additionally, the study showcases\nunique phenomena of LLMs during predictive tasks, such as mode collapse\nbehavior when the proximity of prompt examples is altered and performance\nrecovery from train/test mismatch. The findings aim to provide informed\nskepticism for the broad use of LLMs in materials science and to inspire\nadvancements that enhance their robustness and reliability for practical\napplications.\n","authors":["Hongchen Wang","Kangming Li","Scott Ramsay","Yao Fehlis","Edward Kim","Jason Hattrick-Simpers"],"pdf_url":"https://arxiv.org/pdf/2409.14572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14494v4","updated":"2025-03-11T21:47:39Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v4.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"},{"id":"http://arxiv.org/abs/2412.16359v2","updated":"2025-03-11T21:41:19Z","published":"2024-12-20T21:43:52Z","title":"Human-Readable Adversarial Prompts: An Investigation into LLM\n  Vulnerabilities Using Situational Context","summary":"  Previous studies that uncovered vulnerabilities in large language models\n(LLMs) frequently employed nonsensical adversarial prompts. However, such\nprompts can now be readily identified using automated detection techniques. To\nfurther strengthen adversarial attacks, we focus on human-readable adversarial\nprompts, which are more realistic and potent threats. Our key contributions are\n(1) situation-driven attacks leveraging movie scripts as context to create\nhuman-readable prompts that successfully deceive LLMs, (2) adversarial suffix\nconversion to transform nonsensical adversarial suffixes into independent\nmeaningful text, and (3) AdvPrompter with p-nucleus sampling, a method to\ngenerate diverse, human-readable adversarial suffixes, improving attack\nefficacy in models like GPT-3.5 and Gemma 7B.\n","authors":["Nilanjana Das","Edward Raff","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2412.16359v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.14644"},{"id":"http://arxiv.org/abs/2503.08908v1","updated":"2025-03-11T21:40:58Z","published":"2025-03-11T21:40:58Z","title":"Interpreting the Repeated Token Phenomenon in Large Language Models","summary":"  Large Language Models (LLMs), despite their impressive capabilities, often\nfail to accurately repeat a single word when prompted to, and instead output\nunrelated text. This unexplained failure mode represents a vulnerability,\nallowing even end-users to diverge models away from their intended behavior. We\naim to explain the causes for this phenomenon and link it to the concept of\n``attention sinks'', an emergent LLM behavior crucial for fluency, in which the\ninitial token receives disproportionately high attention scores. Our\ninvestigation identifies the neural circuit responsible for attention sinks and\nshows how long repetitions disrupt this circuit. We extend this finding to\nother non-repeating sequences that exhibit similar circuit disruptions. To\naddress this, we propose a targeted patch that effectively resolves the issue\nwithout negatively impacting the model's overall performance. This study\nprovides a mechanistic explanation for an LLM vulnerability, demonstrating how\ninterpretability can diagnose and address issues, and offering insights that\npave the way for more secure and reliable models.\n","authors":["Itay Yona","Ilia Shumailov","Jamie Hayes","Federico Barbero","Yossi Gandelsman"],"pdf_url":"https://arxiv.org/pdf/2503.08908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05641v2","updated":"2025-03-11T21:40:43Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v2.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic-moe.github.io/"},{"id":"http://arxiv.org/abs/2503.08906v1","updated":"2025-03-11T21:38:34Z","published":"2025-03-11T21:38:34Z","title":"Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge\n  Preservation in Vision-Language Model Adaptation","summary":"  Vision-language models (VLMs) such as CLIP demonstrate strong performance but\nstruggle when adapted to downstream tasks. Prompt learning has emerged as an\nefficient and effective strategy to adapt VLMs while preserving their\npre-trained knowledge. However, existing methods still lead to overfitting and\ndegrade zero-shot generalization. To address this challenge, we propose an\noptimal transport (OT)-guided prompt learning framework that mitigates\nforgetting by preserving the structural consistency of feature distributions\nbetween pre-trained and fine-tuned models. Unlike conventional point-wise\nconstraints, OT naturally captures cross-instance relationships and expands the\nfeasible parameter space for prompt tuning, allowing a better trade-off between\nadaptation and generalization. Our approach enforces joint constraints on both\nvision and text representations, ensuring a holistic feature alignment.\nExtensive experiments on benchmark datasets demonstrate that our simple yet\neffective method can outperform existing prompt learning strategies in\nbase-to-novel generalization, cross-dataset evaluation, and domain\ngeneralization without additional augmentation or ensemble techniques. The code\nis available at https://github.com/ChongQingNoSubway/Prompt-OT\n","authors":["Xiwen Chen","Wenhui Zhu","Peijie Qiu","Hao Wang","Huayu Li","Haiyu Wu","Aristeidis Sotiras","Yalin Wang","Abolfazl Razi"],"pdf_url":"https://arxiv.org/pdf/2503.08906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08893v1","updated":"2025-03-11T21:12:48Z","published":"2025-03-11T21:12:48Z","title":"EvalTree: Profiling Language Model Weaknesses via Hierarchical\n  Capability Trees","summary":"  An ideal model evaluation should achieve two goals: identifying where the\nmodel fails and providing actionable improvement guidance. Toward these goals\nfor Language Model (LM) evaluations, we formulate the problem of generating a\nweakness profile, a set of weaknesses expressed in natural language, given an\nLM's performance on every individual instance in a benchmark. We introduce a\nsuite of quantitative assessments to compare different weakness profiling\nmethods. We also propose a weakness profiling method EvalTree. It constructs a\ncapability tree where each node represents a capability described in natural\nlanguage and is linked to a subset of benchmark instances that specifically\nevaluate this capability; it then extracts nodes where the LM performs poorly\nto generate a weakness profile. On the MATH and WildChat benchmarks, we show\nthat EvalTree outperforms baseline weakness profiling methods by identifying\nweaknesses more precisely and comprehensively. Weakness profiling further\nenables weakness-guided data collection, and training data collection guided by\nEvalTree-identified weaknesses improves LM performance more than other data\ncollection strategies. We also show how EvalTree exposes flaws in Chatbot\nArena's human-voter-based evaluation practice. To facilitate future work, we\nrelease our code and an interface that allows practitioners to interactively\nexplore the capability trees built by EvalTree.\n","authors":["Zhiyuan Zeng","Yizhong Wang","Hannaneh Hajishirzi","Pang Wei Koh"],"pdf_url":"https://arxiv.org/pdf/2503.08893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00184v4","updated":"2025-03-11T21:11:39Z","published":"2023-07-01T00:58:51Z","title":"Personality Traits in Large Language Models","summary":"  The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling the generation of coherent and contextually\nrelevant human-like text. As LLMs increasingly powerconversational agents used\nby the general public world-wide, the synthetic personality traits embedded in\nthese models, by virtue of training on large amounts of human data, is becoming\nincreasingly important. Since personality is a key factor determining the\neffectiveness of communication, we present a novel and comprehensive\npsychometrically valid and reliable methodology for administering and\nvalidating personality tests on widely-used LLMs, as well as for shaping\npersonality in the generated text of such LLMs. Applying this method to 18\nLLMs, we found: 1) personality measurements in the outputs of some LLMs under\nspecific prompting configurations are reliable and valid; 2) evidence of\nreliability and validity of synthetic LLM personality is stronger for larger\nand instruction fine-tuned models; and 3) personality in LLM outputs can be\nshaped along desired dimensions to mimic specific human personality profiles.\nWe discuss the application and ethical implications of the measurement and\nshaping method, in particular regarding responsible AI.\n","authors":["Greg Serapio-García","Mustafa Safdari","Clément Crepy","Luning Sun","Stephen Fitz","Peter Romero","Marwa Abdulhai","Aleksandra Faust","Maja Matarić"],"pdf_url":"https://arxiv.org/pdf/2307.00184v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08890v1","updated":"2025-03-11T20:59:53Z","published":"2025-03-11T20:59:53Z","title":"PlainQAFact: Automatic Factuality Evaluation Metric for Biomedical Plain\n  Language Summaries Generation","summary":"  Hallucinated outputs from language models pose risks in the medical domain,\nespecially for lay audiences making health-related decisions. Existing\nfactuality evaluation methods, such as entailment- and question-answering-based\n(QA), struggle with plain language summary (PLS) generation due to elaborative\nexplanation phenomenon, which introduces external content (e.g., definitions,\nbackground, examples) absent from the source document to enhance comprehension.\nTo address this, we introduce PlainQAFact, a framework trained on a\nfine-grained, human-annotated dataset PlainFact, to evaluate the factuality of\nboth source-simplified and elaboratively explained sentences. PlainQAFact first\nclassifies factuality type and then assesses factuality using a\nretrieval-augmented QA-based scoring method. Our approach is lightweight and\ncomputationally efficient. Empirical results show that existing factuality\nmetrics fail to effectively evaluate factuality in PLS, especially for\nelaborative explanations, whereas PlainQAFact achieves state-of-the-art\nperformance. We further analyze its effectiveness across external knowledge\nsources, answer extraction strategies, overlap measures, and document\ngranularity levels, refining its overall factuality assessment.\n","authors":["Zhiwen You","Yue Guo"],"pdf_url":"https://arxiv.org/pdf/2503.08890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15949v2","updated":"2025-03-11T20:54:07Z","published":"2024-09-24T10:24:53Z","title":"Tuning Into Bias: A Computational Study of Gender Bias in Song Lyrics","summary":"  The application of text mining methods is becoming increasingly prevalent,\nparticularly within Humanities and Computational Social Sciences, as well as in\na broader range of disciplines. This paper presents an analysis of gender bias\nin English song lyrics using topic modeling and bias measurement techniques.\nLeveraging BERTopic, we cluster a dataset of 537,553 English songs into\ndistinct topics and analyze their temporal evolution. Our results reveal a\nsignificant thematic shift in song lyrics over time, transitioning from\nromantic themes to a heightened focus on the sexualization of women.\nAdditionally, we observe a substantial prevalence of profanity and misogynistic\ncontent across various topics, with a particularly high concentration in the\nlargest thematic cluster. To further analyse gender bias across topics and\ngenres in a quantitative way, we employ the Single Category Word Embedding\nAssociation Test (SC-WEAT) to calculate bias scores for word embeddings trained\non the most prominent topics as well as individual genres. The results indicate\na consistent male bias in words associated with intelligence and strength,\nwhile appearance and weakness words show a female bias. Further analysis\nhighlights variations in these biases across topics, illustrating the interplay\nbetween thematic content and gender stereotypes in song lyrics.\n","authors":["Danqing Chen","Adithi Satish","Rasul Khanbayov","Carolin M. Schuster","Georg Groh"],"pdf_url":"https://arxiv.org/pdf/2409.15949v2.pdf","comment":"Accepted to be presented at the 9th Joint SIGHUM Workshop on\n  Computational Linguistics for Cultural Heritage, Social Sciences, Humanities\n  and Literature, co-located with NAACL 2025; also accepted and presented as\n  working paper at the SBP-BRiMS 2024 (see\n  https://sbp-brims.org/2024/papers/working-papers/Chen_SBP-BRiMS2024_Final_31.pdf\n  )"},{"id":"http://arxiv.org/abs/2503.08884v1","updated":"2025-03-11T20:53:00Z","published":"2025-03-11T20:53:00Z","title":"Seeing What's Not There: Spurious Correlation in Multimodal LLMs","summary":"  Unimodal vision models are known to rely on spurious correlations, but it\nremains unclear to what extent Multimodal Large Language Models (MLLMs) exhibit\nsimilar biases despite language supervision. In this paper, we investigate\nspurious bias in MLLMs and introduce SpurLens, a pipeline that leverages GPT-4\nand open-set object detectors to automatically identify spurious visual cues\nwithout human supervision. Our findings reveal that spurious correlations cause\ntwo major failure modes in MLLMs: (1) over-reliance on spurious cues for object\nrecognition, where removing these cues reduces accuracy, and (2) object\nhallucination, where spurious cues amplify the hallucination by over 10x. We\nvalidate our findings in various MLLMs and datasets. Beyond diagnosing these\nfailures, we explore potential mitigation strategies, such as prompt ensembling\nand reasoning-based prompting, and conduct ablation studies to examine the root\ncauses of spurious bias in MLLMs. By exposing the persistence of spurious\ncorrelations, our study calls for more rigorous evaluation methods and\nmitigation strategies to enhance the reliability of MLLMs.\n","authors":["Parsa Hosseini","Sumit Nawathe","Mazda Moayeri","Sriram Balasubramanian","Soheil Feizi"],"pdf_url":"https://arxiv.org/pdf/2503.08884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08879v1","updated":"2025-03-11T20:45:02Z","published":"2025-03-11T20:45:02Z","title":"LLMs Know What to Drop: Self-Attention Guided KV Cache Eviction for\n  Efficient Long-Context Inference","summary":"  Efficient long-context inference is critical as large language models (LLMs)\nadopt context windows of ranging from 128K to 1M tokens. However, the growing\nkey-value (KV) cache and the high computational complexity of attention create\nsignificant bottlenecks in memory usage and latency. In this paper, we find\nthat attention in diverse long-context tasks exhibits sparsity, and LLMs\nimplicitly \"know\" which tokens can be dropped or evicted at the head level\nafter the pre-filling stage. Based on this insight, we propose Self-Attention\nGuided Eviction~(SAGE-KV), a simple and effective KV eviction cache method for\nlong-context inference. After prefilling, our method performs a one-time top-k\nselection at both the token and head levels to compress the KV cache, enabling\nefficient inference with the reduced cache. Evaluations on LongBench and three\nlong-context LLMs (Llama3.1-8B-Instruct-128k, Llama3-8B-Prolong-512k-Instruct,\nand Qwen2.5-7B-Instruct-128k) show that SAGE-KV maintains accuracy comparable\nto full attention while significantly improving efficiency. Specifically,\nSAGE-KV achieves 4x higher memory efficiency with improved accuracy over the\nstatic KV cache selection method StreamLLM, and 2x higher memory efficiency\nwith better accuracy than the dynamic KV cache selection method Quest.\n","authors":["Guangtao Wang","Shubhangi Upasani","Chen Wu","Darshan Gandhi","Jonathan Li","Changran Hu","Bo Li","Urmish Thakker"],"pdf_url":"https://arxiv.org/pdf/2503.08879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08917v2","updated":"2025-03-11T19:56:48Z","published":"2024-10-11T15:46:05Z","title":"AutoPersuade: A Framework for Evaluating and Explaining Persuasive\n  Arguments","summary":"  We introduce AutoPersuade, a three-part framework for constructing persuasive\nmessages. First, we curate a large dataset of arguments with human evaluations.\nNext, we develop a novel topic model to identify argument features that\ninfluence persuasiveness. Finally, we use this model to predict the\neffectiveness of new arguments and assess the causal impact of different\ncomponents to provide explanations. We validate AutoPersuade through an\nexperimental study on arguments for veganism, demonstrating its effectiveness\nwith human studies and out-of-sample predictions.\n","authors":["Till Raphael Saenger","Musashi Hinck","Justin Grimmer","Brandon M. Stewart"],"pdf_url":"https://arxiv.org/pdf/2410.08917v2.pdf","comment":"Published in Proceedings of EMNLP 2024. The official version is\n  available in the ACL Anthology at\n  https://aclanthology.org/2024.emnlp-main.913/"},{"id":"http://arxiv.org/abs/2503.08857v1","updated":"2025-03-11T19:52:02Z","published":"2025-03-11T19:52:02Z","title":"Interpretable and Robust Dialogue State Tracking via Natural Language\n  Summarization with LLMs","summary":"  This paper introduces a novel approach to Dialogue State Tracking (DST) that\nleverages Large Language Models (LLMs) to generate natural language\ndescriptions of dialogue states, moving beyond traditional slot-value\nrepresentations. Conventional DST methods struggle with open-domain dialogues\nand noisy inputs. Motivated by the generative capabilities of LLMs, our Natural\nLanguage DST (NL-DST) framework trains an LLM to directly synthesize\nhuman-readable state descriptions. We demonstrate through extensive experiments\non MultiWOZ 2.1 and Taskmaster-1 datasets that NL-DST significantly outperforms\nrule-based and discriminative BERT-based DST baselines, as well as generative\nslot-filling GPT-2 DST models, in both Joint Goal Accuracy and Slot Accuracy.\nAblation studies and human evaluations further validate the effectiveness of\nnatural language state generation, highlighting its robustness to noise and\nenhanced interpretability. Our findings suggest that NL-DST offers a more\nflexible, accurate, and human-understandable approach to dialogue state\ntracking, paving the way for more robust and adaptable task-oriented dialogue\nsystems.\n","authors":["Rafael Carranza","Mateo Alejandro Rojas"],"pdf_url":"https://arxiv.org/pdf/2503.08857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02348v2","updated":"2025-03-11T19:51:32Z","published":"2024-11-04T18:18:38Z","title":"Can Large Language Models generalize analogy solving like people can?","summary":"  When we solve an analogy we transfer information from a known context to a\nnew one through abstract rules and relational similarity. In people, the\nability to solve analogies such as \"body : feet :: table : ?\" emerges in\nchildhood, and appears to transfer easily to other domains, such as the visual\ndomain \"( : ) :: < : ?\". Recent research shows that large language models\n(LLMs) can solve various forms of analogies. However, can LLMs generalize\nanalogy solving to new domains like people can? To investigate this, we had\nchildren, adults, and LLMs solve a series of letter-string analogies (e.g., a b\n: a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek\nalphabet), and a far transfer domain (list of symbols). As expected, children\nand adults easily generalized their knowledge to unfamiliar domains, whereas\nLLMs did not. This key difference between human and AI performance is evidence\nthat these LLMs still struggle with robust human-like analogical transfer.\n","authors":["Claire E. Stevenson","Alexandra Pafford","Han L. J. van der Maas","Melanie Mitchell"],"pdf_url":"https://arxiv.org/pdf/2411.02348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08842v1","updated":"2025-03-11T19:28:12Z","published":"2025-03-11T19:28:12Z","title":"Contrastive Speaker-Aware Learning for Multi-party Dialogue Generation\n  with LLMs","summary":"  Multi-party dialogue generation presents significant challenges due to the\ncomplex interplay of multiple speakers and interwoven conversational threads.\nTraditional approaches often fall short in capturing these complexities,\nparticularly when relying on manually annotated dialogue relations. This paper\nintroduces Speaker-Attentive LLM (SA-LLM), a novel generative model that\nleverages pre-trained Large Language Models (LLMs) and a speaker-aware\ncontrastive learning strategy to address these challenges. SA-LLM incorporates\na speaker-attributed input encoding and a contrastive learning objective to\nimplicitly learn contextual coherence and speaker roles without explicit\nrelation annotations. Extensive experiments on the Ubuntu IRC and Movie\nDialogues datasets demonstrate that SA-LLM significantly outperforms\nstate-of-the-art baselines in automatic and human evaluations, achieving\nsuperior performance in fluency, coherence, informativeness, and response\ndiversity. Ablation studies and detailed error analyses further validate the\neffectiveness of the proposed speaker-attentive training approach, highlighting\nits robustness across different speaker roles and context lengths. The results\nunderscore the potential of SA-LLM as a powerful and annotation-free solution\nfor high-quality multi-party dialogue generation.\n","authors":["Tianyu Sun","Kun Qian","Wenhong Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22179v2","updated":"2025-03-11T19:21:57Z","published":"2024-10-29T16:17:01Z","title":"Robust and Unbounded Length Generalization in Autoregressive\n  Transformer-Based Text-to-Speech","summary":"  Autoregressive (AR) Transformer-based sequence models are known to have\ndifficulty generalizing to sequences longer than those seen during training.\nWhen applied to text-to-speech (TTS), these models tend to drop or repeat words\nor produce erratic output, especially for longer utterances. In this paper, we\nintroduce enhancements aimed at AR Transformer-based encoder-decoder TTS\nsystems that address these robustness and length generalization issues. Our\napproach uses an alignment mechanism to provide cross-attention operations with\nrelative location information. The associated alignment position is learned as\na latent property of the model via backpropagation and requires no external\nalignment information during training. While the approach is tailored to the\nmonotonic nature of TTS input-output alignment, it is still able to benefit\nfrom the flexible modeling power of interleaved multi-head self- and\ncross-attention operations. A system incorporating these improvements, which we\ncall Very Attentive Tacotron, matches the naturalness and expressiveness of a\nbaseline T5-based TTS system, while eliminating problems with repeated or\ndropped words and enabling generalization to any practical utterance length.\n","authors":["Eric Battenberg","RJ Skerry-Ryan","Daisy Stanton","Soroosh Mariooryad","Matt Shannon","Julian Salazar","David Kao"],"pdf_url":"https://arxiv.org/pdf/2410.22179v2.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08838v1","updated":"2025-03-11T19:19:48Z","published":"2025-03-11T19:19:48Z","title":"evoBPE: Evolutionary Protein Sequence Tokenization","summary":"  Recent advancements in computational biology have drawn compelling parallels\nbetween protein sequences and linguistic structures, highlighting the need for\nsophisticated tokenization methods that capture the intricate evolutionary\ndynamics of protein sequences. Current subword tokenization techniques,\nprimarily developed for natural language processing, often fail to represent\nprotein sequences' complex structural and functional properties adequately.\nThis study introduces evoBPE, a novel tokenization approach that integrates\nevolutionary mutation patterns into sequence segmentation, addressing critical\nlimitations in existing methods. By leveraging established substitution\nmatrices, evoBPE transcends traditional frequency-based tokenization\nstrategies. The method generates candidate token pairs through biologically\ninformed mutations, evaluating them based on pairwise alignment scores and\nfrequency thresholds. Extensive experiments on human protein sequences show\nthat evoBPE performs better across multiple dimensions. Domain conservation\nanalysis reveals that evoBPE consistently outperforms standard Byte-Pair\nEncoding, particularly as vocabulary size increases. Furthermore, embedding\nsimilarity analysis using ESM-2 suggests that mutation-based token replacements\npreserve biological sequence properties more effectively than arbitrary\nsubstitutions. The research contributes to protein sequence representation by\nintroducing a mutation-aware tokenization method that better captures\nevolutionary nuances. By bridging computational linguistics and molecular\nbiology, evoBPE opens new possibilities for machine learning applications in\nprotein function prediction, structural modeling, and evolutionary analysis.\n","authors":["Burak Suyunu","Özdeniz Dolu","Arzucan Özgür"],"pdf_url":"https://arxiv.org/pdf/2503.08838v1.pdf","comment":"13 pages, 8 figures, 1 table, 1 algorithm"},{"id":"http://arxiv.org/abs/2312.16893v2","updated":"2025-03-11T19:00:39Z","published":"2023-12-28T08:34:17Z","title":"BBScore: A Brownian Bridge Based Metric for Assessing Text Coherence","summary":"  Measuring the coherence of text is a vital aspect of evaluating the quality\nof written content. Recent advancements in neural coherence modeling have\ndemonstrated their efficacy in capturing entity coreference and discourse\nrelations, thereby enhancing coherence evaluation. However, many existing\nmethods heavily depend on static embeddings or focus narrowly on nearby\ncontext, constraining their capacity to measure the overarching coherence of\nlong texts. In this paper, we posit that coherent texts inherently manifest a\nsequential and cohesive interplay among sentences, effectively conveying the\ncentral theme, purpose, or standpoint. To explore this abstract relationship,\nwe introduce the \"BBScore,\" a novel reference-free metric grounded in Brownian\nbridge theory for assessing text coherence. Our findings showcase that when\nsynergized with a simple additional classification component, this metric\nattains a performance level comparable to state-of-the-art techniques on\nstandard artificial discrimination tasks. We also establish in downstream tasks\nthat this metric effectively differentiates between human-written documents and\ntext generated by large language models under a specific domain. Furthermore,\nwe illustrate the efficacy of this approach in detecting written styles\nattributed to diverse large language models, underscoring its potential for\ngeneralizability. In summary, we present a novel Brownian bridge coherence\nmetric capable of measuring both local and global text coherence, while\ncircumventing the need for end-to-end model training. This flexibility allows\nfor its application in various downstream tasks.\n","authors":["Zhecheng Sheng","Tianhao Zhang","Chen Jiang","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2312.16893v2.pdf","comment":"Accepted to the 38th Annual AAAI Conference on Artificial\n  Intelligence (AAAI-24)"},{"id":"http://arxiv.org/abs/2503.08823v1","updated":"2025-03-11T18:54:17Z","published":"2025-03-11T18:54:17Z","title":"ResBench: Benchmarking LLM-Generated FPGA Designs with Resource\n  Awareness","summary":"  Field-Programmable Gate Arrays (FPGAs) are widely used in modern hardware\ndesign, yet writing Hardware Description Language (HDL) code for FPGA\nimplementation remains labor-intensive and complex. Large Language Models\n(LLMs) have emerged as a promising tool for automating HDL generation, but\nexisting benchmarks for LLM HDL code generation primarily evaluate functional\ncorrectness while overlooking the critical aspect of hardware resource\nefficiency. Moreover, current benchmarks lack diversity, failing to capture the\nbroad range of real-world FPGA applications. To address these gaps, we\nintroduce ResBench, the first resource-oriented benchmark explicitly designed\nto differentiate between resource-optimized and inefficient LLM-generated HDL.\nResBench consists of 56 problems across 12 categories, covering applications\nfrom finite state machines to financial computing. Our evaluation framework\nsystematically integrates FPGA resource constraints, with a primary focus on\nLookup Table (LUT) usage, enabling a realistic assessment of hardware\nefficiency. Experimental results reveal substantial differences in resource\nutilization across LLMs, demonstrating ResBench's effectiveness in\ndistinguishing models based on their ability to generate resource-optimized\nFPGA designs.\n","authors":["Ce Guo","Tong Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.08823v1.pdf","comment":"to be published in International Symposium on Highly Efficient\n  Accelerators and Reconfigurable Technologies 2025"},{"id":"http://arxiv.org/abs/2503.08815v1","updated":"2025-03-11T18:50:43Z","published":"2025-03-11T18:50:43Z","title":"Cross-Examiner: Evaluating Consistency of Large Language Model-Generated\n  Explanations","summary":"  Large Language Models (LLMs) are often asked to explain their outputs to\nenhance accuracy and transparency. However, evidence suggests that these\nexplanations can misrepresent the models' true reasoning processes. One\neffective way to identify inaccuracies or omissions in these explanations is\nthrough consistency checking, which typically involves asking follow-up\nquestions. This paper introduces, cross-examiner, a new method for generating\nfollow-up questions based on a model's explanation of an initial question. Our\nmethod combines symbolic information extraction with language model-driven\nquestion generation, resulting in better follow-up questions than those\nproduced by LLMs alone. Additionally, this approach is more flexible than other\nmethods and can generate a wider variety of follow-up questions.\n","authors":["Danielle Villa","Maria Chang","Keerthiram Murugesan","Rosario Uceda-Sosa","Karthikeyan Natesan Ramamurthy"],"pdf_url":"https://arxiv.org/pdf/2503.08815v1.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.08803v1","updated":"2025-03-11T18:32:16Z","published":"2025-03-11T18:32:16Z","title":"ESNLIR: A Spanish Multi-Genre Dataset with Causal Relationships","summary":"  Natural Language Inference (NLI), also known as Recognizing Textual\nEntailment (RTE), serves as a crucial area within the domain of Natural\nLanguage Processing (NLP). This area fundamentally empowers machines to discern\nsemantic relationships between assorted sections of text. Even though\nconsiderable work has been executed for the English language, it has been\nobserved that efforts for the Spanish language are relatively sparse. Keeping\nthis in view, this paper focuses on generating a multi-genre Spanish dataset\nfor NLI, ESNLIR, particularly accounting for causal Relationships. A\npreliminary baseline has been conceptualized and subjected to an evaluation,\nleveraging models drawn from the BERT family. The findings signify that the\nenrichment of genres essentially contributes to the enrichment of the model's\ncapability to generalize.\n  The code, notebooks and whole datasets for this experiments is available at:\nhttps://zenodo.org/records/15002575. If you are interested only in the dataset\nyou can find it here: https://zenodo.org/records/15002371.\n","authors":["Johan R. Portela","Nicolás Perez","Rubén Manrique"],"pdf_url":"https://arxiv.org/pdf/2503.08803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15844v2","updated":"2025-03-11T18:28:18Z","published":"2025-02-20T19:44:33Z","title":"Hallucination Detection in Large Language Models with Metamorphic\n  Relations","summary":"  Large Language Models (LLMs) are prone to hallucinations, e.g., factually\nincorrect information, in their responses. These hallucinations present\nchallenges for LLM-based applications that demand high factual accuracy.\nExisting hallucination detection methods primarily depend on external\nresources, which can suffer from issues such as low availability, incomplete\ncoverage, privacy concerns, high latency, low reliability, and poor\nscalability. There are also methods depending on output probabilities, which\nare often inaccessible for closed-source LLMs like GPT models. This paper\npresents MetaQA, a self-contained hallucination detection approach that\nleverages metamorphic relation and prompt mutation. Unlike existing methods,\nMetaQA operates without any external resources and is compatible with both\nopen-source and closed-source LLMs. MetaQA is based on the hypothesis that if\nan LLM's response is a hallucination, the designed metamorphic relations will\nbe violated. We compare MetaQA with the state-of-the-art zero-resource\nhallucination detection method, SelfCheckGPT, across multiple datasets, and on\ntwo open-source and two closed-source LLMs. Our results reveal that MetaQA\noutperforms SelfCheckGPT in terms of precision, recall, and f1 score. For the\nfour LLMs we study, MetaQA outperforms SelfCheckGPT with a superiority margin\nranging from 0.041 - 0.113 (for precision), 0.143 - 0.430 (for recall), and\n0.154 - 0.368 (for F1-score). For instance, with Mistral-7B, MetaQA achieves an\naverage F1-score of 0.435, compared to SelfCheckGPT's F1-score of 0.205,\nrepresenting an improvement rate of 112.2%. MetaQA also demonstrates\nsuperiority across all different categories of questions.\n","authors":["Borui Yang","Md Afif Al Mamun","Jie M. Zhang","Gias Uddin"],"pdf_url":"https://arxiv.org/pdf/2502.15844v2.pdf","comment":"Accepted to the ACM Joint European Software Engineering Conference\n  and Symposium on the Foundations of Software Engineering (ESEC/FSE 2025)"},{"id":"http://arxiv.org/abs/2503.08750v1","updated":"2025-03-11T13:10:00Z","published":"2025-03-11T13:10:00Z","title":"Exposing Product Bias in LLM Investment Recommendation","summary":"  Large language models (LLMs), as a new generation of recommendation engines,\npossess powerful summarization and data analysis capabilities, surpassing\ntraditional recommendation systems in both scope and performance. One promising\napplication is investment recommendation. In this paper, we reveal a novel\nproduct bias in LLM investment recommendation, where LLMs exhibit systematic\npreferences for specific products. Such preferences can subtly influence user\ninvestment decisions, potentially leading to inflated valuations of products\nand financial bubbles, posing risks to both individual investors and market\nstability. To comprehensively study the product bias, we develop an automated\npipeline to create a dataset of 567,000 samples across five asset classes\n(stocks, mutual funds, cryptocurrencies, savings, and portfolios). With this\ndataset, we present the bf first study on product bias in LLM investment\nrecommendations. Our findings reveal that LLMs exhibit clear product\npreferences, such as certain stocks (e.g., `AAPL' from Apple and `MSFT' from\nMicrosoft). Notably, this bias persists even after applying debiasing\ntechniques. We urge AI researchers to take heed of the product bias in LLM\ninvestment recommendations and its implications, ensuring fairness and security\nin the digital space and market.\n","authors":["Yuhan Zhi","Xiaoyu Zhang","Longtian Wang","Shumin Jiang","Shiqing Ma","Xiaohong Guan","Chao Shen"],"pdf_url":"https://arxiv.org/pdf/2503.08750v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.08681v1","updated":"2025-03-11T17:57:44Z","published":"2025-03-11T17:57:44Z","title":"Self-Taught Self-Correction for Small Language Models","summary":"  Although large language models (LLMs) have achieved remarkable performance\nacross various tasks, they remain prone to errors. A key challenge is enabling\nthem to self-correct. While prior research has relied on external tools or\nlarge proprietary models, this work explores self-correction in small language\nmodels (SLMs) through iterative fine-tuning using solely self-generated data.\nWe introduce the Self-Taught Self-Correction (STaSC) algorithm, which\nincorporates multiple algorithmic design choices. Experimental results on a\nquestion-answering task demonstrate that STaSC effectively learns\nself-correction, leading to significant performance improvements. Our analysis\nfurther provides insights into the mechanisms of self-correction and the impact\nof different design choices on learning dynamics and overall performance. To\nsupport future research, we release our user-friendly codebase and lightweight\nmodels.\n","authors":["Viktor Moskvoretskii","Chris Biemann","Irina Nikishina"],"pdf_url":"https://arxiv.org/pdf/2503.08681v1.pdf","comment":"Code is available at https://github.com/VityaVitalich/STASC"},{"id":"http://arxiv.org/abs/2503.08679v1","updated":"2025-03-11T17:56:30Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal concerning rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (30.6%), DeepSeek R1 (15.8%) and\nChatGPT-4o (12.6%) all answer a high proportion of question pairs unfaithfully.\nSpecifically, we find that models rationalize their implicit biases in answers\nto binary questions (\"implicit post-hoc rationalization\"). For example, when\nseparately presented with the questions \"Is X bigger than Y?\" and \"Is Y bigger\nthan X?\", models sometimes produce superficially coherent arguments to justify\nanswering Yes to both questions or No to both questions, despite such responses\nbeing logically contradictory. We also investigate restoration errors (Dziri et\nal., 2023), where models make and then silently correct errors in their\nreasoning, and unfaithful shortcuts, where models use clearly illogical\nreasoning to simplify solving problems in Putnam questions (a hard benchmark).\nOur findings raise challenges for AI safety work that relies on monitoring CoT\nto detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v1.pdf","comment":"Accepted to the ICLR 2025 Workshop, 10 main paper pages, 38 appendix\n  pages"},{"id":"http://arxiv.org/abs/2503.08674v1","updated":"2025-03-11T17:54:29Z","published":"2025-03-11T17:54:29Z","title":"Understanding and Mitigating Distribution Shifts For Machine Learning\n  Force Fields","summary":"  Machine Learning Force Fields (MLFFs) are a promising alternative to\nexpensive ab initio quantum mechanical molecular simulations. Given the\ndiversity of chemical spaces that are of interest and the cost of generating\nnew data, it is important to understand how MLFFs generalize beyond their\ntraining distributions. In order to characterize and better understand\ndistribution shifts in MLFFs, we conduct diagnostic experiments on chemical\ndatasets, revealing common shifts that pose significant challenges, even for\nlarge foundation models trained on extensive data. Based on these observations,\nwe hypothesize that current supervised training methods inadequately regularize\nMLFFs, resulting in overfitting and learning poor representations of\nout-of-distribution systems. We then propose two new methods as initial steps\nfor mitigating distribution shifts for MLFFs. Our methods focus on test-time\nrefinement strategies that incur minimal computational cost and do not use\nexpensive ab initio reference labels. The first strategy, based on spectral\ngraph theory, modifies the edges of test graphs to align with graph structures\nseen during training. Our second strategy improves representations for\nout-of-distribution systems at test-time by taking gradient steps using an\nauxiliary objective, such as a cheap physical prior. Our test-time refinement\nstrategies significantly reduce errors on out-of-distribution systems,\nsuggesting that MLFFs are capable of and can move towards modeling diverse\nchemical spaces, but are not being effectively trained to do so. Our\nexperiments establish clear benchmarks for evaluating the generalization\ncapabilities of the next generation of MLFFs. Our code is available at\nhttps://tkreiman.github.io/projects/mlff_distribution_shifts/.\n","authors":["Tobias Kreiman","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2503.08674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19147v3","updated":"2025-03-11T17:52:25Z","published":"2024-10-24T20:30:14Z","title":"Functional Brain Network Identification in Opioid Use Disorder Using\n  Machine Learning Analysis of Resting-State fMRI BOLD Signals","summary":"  Understanding the neurobiology of opioid use disorder (OUD) using\nresting-state functional magnetic resonance imaging (rs-fMRI) may help inform\ntreatment strategies to improve patient outcomes. Recent literature suggests\ntime-frequency characteristics of rs-fMRI blood oxygenation level-dependent\n(BOLD) signals may offer complementary information to traditional analysis\ntechniques. However, existing studies of OUD analyze BOLD signals using\nmeasures computed across all time points. This study, for the first time in the\nliterature, employs data-driven machine learning (ML) for time-frequency\nanalysis of local neural activity within key functional networks to\ndifferentiate OUD subjects from healthy controls (HC). We obtain time-frequency\nfeatures based on rs-fMRI BOLD signals from the default mode network (DMN),\nsalience network (SN), and executive control network (ECN) for 31 OUD and 45 HC\nsubjects. Then, we perform 5-fold cross-validation classification (OUD vs. HC)\nexperiments to study the discriminative power of functional network features\nwhile taking into consideration significant demographic features. The DMN and\nSN show the most discriminative power, significantly (p < 0.05) outperforming\nchance baselines with mean F1 scores of 0.7097 and 0.7018, respectively, and\nmean AUCs of 0.8378 and 0.8755, respectively. Follow-up Boruta ML analysis of\nselected time-frequency (wavelet) features reveals significant (p < 0.05)\ndetail coefficients for all three functional networks, underscoring the need\nfor ML and time-frequency analysis of rs-fMRI BOLD signals in the study of OUD.\n","authors":["Ahmed Temtam","Megan A. Witherow","Liangsuo Ma","M. Shibly Sadique","F. Gerard Moeller","Khan M. Iftekharuddin"],"pdf_url":"https://arxiv.org/pdf/2410.19147v3.pdf","comment":"25 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.08665v1","updated":"2025-03-11T17:51:07Z","published":"2025-03-11T17:51:07Z","title":"REGEN: Learning Compact Video Embedding with (Re-)Generative Decoder","summary":"  We present a novel perspective on learning video embedders for generative\nmodeling: rather than requiring an exact reproduction of an input video, an\neffective embedder should focus on synthesizing visually plausible\nreconstructions. This relaxed criterion enables substantial improvements in\ncompression ratios without compromising the quality of downstream generative\nmodels. Specifically, we propose replacing the conventional encoder-decoder\nvideo embedder with an encoder-generator framework that employs a diffusion\ntransformer (DiT) to synthesize missing details from a compact latent space.\nTherein, we develop a dedicated latent conditioning module to condition the DiT\ndecoder on the encoded video latent embedding. Our experiments demonstrate that\nour approach enables superior encoding-decoding performance compared to\nstate-of-the-art methods, particularly as the compression ratio increases. To\ndemonstrate the efficacy of our approach, we report results from our video\nembedders achieving a temporal compression ratio of up to 32x (8x higher than\nleading video embedders) and validate the robustness of this ultra-compact\nlatent space for text-to-video generation, providing a significant efficiency\nboost in latent diffusion model training and inference.\n","authors":["Yitian Zhang","Long Mai","Aniruddha Mahapatra","David Bourgin","Yicong Hong","Jonah Casebeer","Feng Liu","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2503.08665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08652v1","updated":"2025-03-11T17:42:36Z","published":"2025-03-11T17:42:36Z","title":"Extra Clients at No Extra Cost: Overcome Data Heterogeneity in Federated\n  Learning with Filter Decomposition","summary":"  Data heterogeneity is one of the major challenges in federated learning (FL),\nwhich results in substantial client variance and slow convergence. In this\nstudy, we propose a novel solution: decomposing a convolutional filter in FL\ninto a linear combination of filter subspace elements, i.e., filter atoms. This\nsimple technique transforms global filter aggregation in FL into aggregating\nfilter atoms and their atom coefficients. The key advantage here involves\nmathematically generating numerous cross-terms by expanding the product of two\nweighted sums from filter atom and atom coefficient. These cross-terms\neffectively emulate many additional latent clients, significantly reducing\nmodel variance, which is validated by our theoretical analysis and empirical\nobservation. Furthermore, our method permits different training schemes for\nfilter atoms and atom coefficients for highly adaptive model personalization\nand communication efficiency. Empirical results on benchmark datasets\ndemonstrate that our filter decomposition technique substantially improves the\naccuracy of FL methods, confirming its efficacy in addressing data\nheterogeneity.\n","authors":["Wei Chen","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2503.08652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19418v2","updated":"2025-03-11T17:41:54Z","published":"2024-11-29T00:09:39Z","title":"Proto Successor Measure: Representing the Behavior Space of an RL Agent","summary":"  Having explored an environment, intelligent agents should be able to transfer\ntheir knowledge to most downstream tasks within that environment without\nadditional interactions. Referred to as \"zero-shot learning\", this ability\nremains elusive for general-purpose reinforcement learning algorithms. While\nrecent works have attempted to produce zero-shot RL agents, they make\nassumptions about the nature of the tasks or the structure of the MDP. We\npresent Proto Successor Measure: the basis set for all possible behaviors of a\nReinforcement Learning Agent in a dynamical system. We prove that any possible\nbehavior (represented using visitation distributions) can be represented using\nan affine combination of these policy-independent basis functions. Given a\nreward function at test time, we simply need to find the right set of linear\nweights to combine these bases corresponding to the optimal policy. We derive a\npractical algorithm to learn these basis functions using reward-free\ninteraction data from the environment and show that our approach can produce\nthe optimal policy at test time for any given reward function without\nadditional environmental interactions. Project page:\nhttps://agarwalsiddhant10.github.io/projects/psm.html.\n","authors":["Siddhant Agarwal","Harshit Sikchi","Peter Stone","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.19418v2.pdf","comment":"Under submission, 20 pages"},{"id":"http://arxiv.org/abs/2503.08643v1","updated":"2025-03-11T17:36:11Z","published":"2025-03-11T17:36:11Z","title":"Rethinking Diffusion Model in High Dimension","summary":"  Curse of Dimensionality is an unavoidable challenge in statistical\nprobability models, yet diffusion models seem to overcome this limitation,\nachieving impressive results in high-dimensional data generation. Diffusion\nmodels assume that they can learn the statistical properties of the underlying\nprobability distribution, enabling sampling from this distribution to generate\nrealistic samples. But is this really how they work? To address this question,\nthis paper conducts a detailed analysis of the objective function and inference\nmethods of diffusion models, leading to several important conclusions that help\nanswer the above question: 1) In high-dimensional sparse scenarios, the target\nof the objective function fitting degrades from a weighted sum of multiple\nsamples to a single sample. 2) The mainstream inference methods can all be\nrepresented within a simple unified framework, without requiring statistical\nconcepts such as Markov chains and SDEs. 3) Guided by this simple framework,\nmore efficient inference methods can be discovered.\n","authors":["Zhenxin Zheng","Zhenjie Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.08643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08642v1","updated":"2025-03-11T17:34:38Z","published":"2025-03-11T17:34:38Z","title":"Coefficient-to-Basis Network: A Fine-Tunable Operator Learning Framework\n  for Inverse Problems with Adaptive Discretizations and Theoretical Guarantees","summary":"  We propose a Coefficient-to-Basis Network (C2BNet), a novel framework for\nsolving inverse problems within the operator learning paradigm. C2BNet\nefficiently adapts to different discretizations through fine-tuning, using a\npre-trained model to significantly reduce computational cost while maintaining\nhigh accuracy. Unlike traditional approaches that require retraining from\nscratch for new discretizations, our method enables seamless adaptation without\nsacrificing predictive performance. Furthermore, we establish theoretical\napproximation and generalization error bounds for C2BNet by exploiting\nlow-dimensional structures in the underlying datasets. Our analysis\ndemonstrates that C2BNet adapts to low-dimensional structures without relying\non explicit encoding mechanisms, highlighting its robustness and efficiency. To\nvalidate our theoretical findings, we conducted extensive numerical experiments\nthat showcase the superior performance of C2BNet on several inverse problems.\nThe results confirm that C2BNet effectively balances computational efficiency\nand accuracy, making it a promising tool to solve inverse problems in\nscientific computing and engineering applications.\n","authors":["Zecheng Zhang","Hao Liu","Wenjing Liao","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.08642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07609v2","updated":"2025-03-11T17:31:49Z","published":"2025-03-10T17:59:44Z","title":"Preserving clusters and correlations: a dimensionality reduction method\n  for exceptionally high global structure preservation","summary":"  We present Preserving Clusters and Correlations (PCC), a novel dimensionality\nreduction (DR) method a novel dimensionality reduction (DR) method that\nachieves state-of-the-art global structure (GS) preservation while maintaining\ncompetitive local structure (LS) preservation. It optimizes two objectives: a\nGS preservation objective that preserves an approximation of Pearson and\nSpearman correlations between high- and low-dimensional distances, and an LS\npreservation objective that ensures clusters in the high-dimensional data are\nseparable in the low-dimensional data. PCC has a state-of-the-art ability to\npreserve the GS while having competitive LS preservation. In addition, we show\nthe correlation objective can be combined with UMAP to significantly improve\nits GS preservation with minimal degradation of the LS. We quantitatively\nbenchmark PCC against existing methods and demonstrate its utility in medical\nimaging, and show PCC is a competitive DR technique that demonstrates superior\nGS preservation in our benchmarks.\n","authors":["Jacob Gildenblat","Jens Pahnke"],"pdf_url":"https://arxiv.org/pdf/2503.07609v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08636v1","updated":"2025-03-11T17:24:33Z","published":"2025-03-11T17:24:33Z","title":"Birds look like cars: Adversarial analysis of intrinsically\n  interpretable deep learning","summary":"  A common belief is that intrinsically interpretable deep learning models\nensure a correct, intuitive understanding of their behavior and offer greater\nrobustness against accidental errors or intentional manipulation. However,\nthese beliefs have not been comprehensively verified, and growing evidence\ncasts doubt on them. In this paper, we highlight the risks related to\noverreliance and susceptibility to adversarial manipulation of these so-called\n\"intrinsically (aka inherently) interpretable\" models by design. We introduce\ntwo strategies for adversarial analysis with prototype manipulation and\nbackdoor attacks against prototype-based networks, and discuss how concept\nbottleneck models defend against these attacks. Fooling the model's reasoning\nby exploiting its use of latent prototypes manifests the inherent\nuninterpretability of deep neural networks, leading to a false sense of\nsecurity reinforced by a visual confirmation bias. The reported limitations of\nprototype-based networks put their trustworthiness and applicability into\nquestion, motivating further work on the robustness and alignment of (deep)\ninterpretable models.\n","authors":["Hubert Baniecki","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2503.08636v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.08633v1","updated":"2025-03-11T17:21:26Z","published":"2025-03-11T17:21:26Z","title":"How Does Overparameterization Affect Machine Unlearning of Deep Neural\n  Networks?","summary":"  Machine unlearning is the task of updating a trained model to forget specific\ntraining data without retraining from scratch. In this paper, we investigate\nhow unlearning of deep neural networks (DNNs) is affected by the model\nparameterization level, which corresponds here to the DNN width. We define\nvalidation-based tuning for several unlearning methods from the recent\nliterature, and show how these methods perform differently depending on (i) the\nDNN parameterization level, (ii) the unlearning goal (unlearned data privacy or\nbias removal), (iii) whether the unlearning method explicitly uses the\nunlearned examples. Our results show that unlearning excels on\noverparameterized models, in terms of balancing between generalization and\nachieving the unlearning goal; although for bias removal this requires the\nunlearning method to use the unlearned examples. We further elucidate our\nerror-based analysis by measuring how much the unlearning changes the\nclassification decision regions in the proximity of the unlearned examples, and\navoids changing them elsewhere. By this we show that the unlearning success for\noverparameterized models stems from the ability to delicately change the model\nfunctionality in small regions in the input space while keeping much of the\nmodel functionality unchanged.\n","authors":["Gal Alon","Yehuda Dar"],"pdf_url":"https://arxiv.org/pdf/2503.08633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10794v3","updated":"2025-03-11T17:21:00Z","published":"2024-11-16T13:04:52Z","title":"Going Beyond Conventional OOD Detection","summary":"  Out-of-distribution (OOD) detection is critical to ensure the safe deployment\nof deep learning models in critical applications. Deep learning models can\noften misidentify OOD samples as in-distribution (ID) samples. This\nvulnerability worsens in the presence of spurious correlation in the training\nset. Likewise, in fine-grained classification settings, detection of\nfine-grained OOD samples becomes inherently challenging due to their high\nsimilarity to ID samples. However, current research on OOD detection has\nlargely ignored these challenging scenarios, focusing instead on relatively\neasier (conventional) cases. In this work, we present a unified Approach to\nSpurious, fine-grained, and Conventional OOD Detection (ASCOOD). First, we\npropose synthesizing virtual outliers from ID data by approximating the\ndestruction of invariant features. To this end, we identify invariant features\nwith the pixel attribution method using the model being learned. This approach\neliminates the burden of curating external OOD datasets. Then, we\nsimultaneously incentivize ID classification and predictive uncertainty towards\nvirtual outliers leveraging standardized feature representation. Our approach\neffectively mitigates the impact of spurious correlations and encourages\ncapturing fine-grained attributes. Extensive experiments across seven datasets\ndemonstrate the merit of ASCOOD in spurious, fine-grained, and conventional\nsettings. The code is available at: https://github.com/sudarshanregmi/ASCOOD/\n","authors":["Sudarshan Regmi"],"pdf_url":"https://arxiv.org/pdf/2411.10794v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.07199v2","updated":"2025-03-11T17:06:18Z","published":"2024-04-10T17:57:41Z","title":"RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth\n  Diffusion","summary":"  We introduce RealmDreamer, a technique for generating forward-facing 3D\nscenes from text descriptions. Our method optimizes a 3D Gaussian Splatting\nrepresentation to match complex text prompts using pretrained diffusion models.\nOur key insight is to leverage 2D inpainting diffusion models conditioned on an\ninitial scene estimate to provide low variance supervision for unknown regions\nduring 3D distillation. In conjunction, we imbue high-fidelity geometry with\ngeometric distillation from a depth diffusion model, conditioned on samples\nfrom the inpainting model. We find that the initialization of the optimization\nis crucial, and provide a principled methodology for doing so. Notably, our\ntechnique doesn't require video or multi-view data and can synthesize various\nhigh-quality 3D scenes in different styles with complex layouts. Further, the\ngenerality of our method allows 3D synthesis from a single image. As measured\nby a comprehensive user study, our method outperforms all existing approaches,\npreferred by 88-95%. Project Page: https://realmdreamer.github.io/\n","authors":["Jaidev Shriram","Alex Trevithick","Lingjie Liu","Ravi Ramamoorthi"],"pdf_url":"https://arxiv.org/pdf/2404.07199v2.pdf","comment":"Published at 3DV 2025"},{"id":"http://arxiv.org/abs/2503.07154v2","updated":"2025-03-11T16:52:41Z","published":"2025-03-10T10:27:30Z","title":"Ideas in Inference-time Scaling can Benefit Generative Pre-training\n  Algorithms","summary":"  Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.\n","authors":["Jiaming Song","Linqi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16862v2","updated":"2025-03-11T16:51:35Z","published":"2024-03-25T15:26:32Z","title":"INPC: Implicit Neural Point Clouds for Radiance Field Rendering","summary":"  We introduce a new approach for reconstruction and novel view synthesis of\nunbounded real-world scenes. In contrast to previous methods using either\nvolumetric fields, grid-based models, or discrete point cloud proxies, we\npropose a hybrid scene representation, which implicitly encodes the geometry in\na continuous octree-based probability field and view-dependent appearance in a\nmulti-resolution hash grid. This allows for extraction of arbitrary explicit\npoint clouds, which can be rendered using rasterization. In doing so, we\ncombine the benefits of both worlds and retain favorable behavior during\noptimization: Our novel implicit point cloud representation and differentiable\nbilinear rasterizer enable fast rendering while preserving the fine geometric\ndetail captured by volumetric neural fields. Furthermore, this representation\ndoes not depend on priors like structure-from-motion point clouds. Our method\nachieves state-of-the-art image quality on common benchmarks. Furthermore, we\nachieve fast inference at interactive frame rates, and can convert our trained\nmodel into a large, explicit point cloud to further enhance performance.\n","authors":["Florian Hahlbohm","Linus Franke","Moritz Kappel","Susana Castillo","Martin Eisemann","Marc Stamminger","Marcus Magnor"],"pdf_url":"https://arxiv.org/pdf/2403.16862v2.pdf","comment":"Project page: https://fhahlbohm.github.io/inpc/"},{"id":"http://arxiv.org/abs/2503.08610v1","updated":"2025-03-11T16:51:01Z","published":"2025-03-11T16:51:01Z","title":"Hierarchical autoregressive neural networks in three-dimensional\n  statistical system","summary":"  Autoregressive Neural Networks (ANN) have been recently proposed as a\nmechanism to improve the efficiency of Monte Carlo algorithms for several spin\nsystems. The idea relies on the fact that the total probability of a\nconfiguration can be factorized into conditional probabilities of each spin,\nwhich in turn can be approximated by a neural network. Once trained, the ANNs\ncan be used to sample configurations from the approximated probability\ndistribution and to evaluate explicitly this probability for a given\nconfiguration. It has also been observed that such conditional probabilities\ngive access to information-theoretic observables such as mutual information or\nentanglement entropy. So far, these methods have been applied to\ntwo-dimensional statistical systems or one-dimensional quantum systems. In this\npaper, we describe a generalization of the hierarchical algorithm to three\nspatial dimensions and study its performance on the example of the Ising model.\nWe discuss the efficiency of the training and also describe the scaling with\nthe system's dimensionality by comparing results for two- and three-dimensional\nIsing models with the same number of spins. Finally, we provide estimates of\nthermodynamical observables for the three-dimensional Ising model, such as the\nentropy and free energy in a range of temperatures across the phase transition.\n","authors":["Piotr Białas","Vaibhav Chahar","Piotr Korcyl","Tomasz Stebel","Mateusz Winiarski","Dawid Zapolski"],"pdf_url":"https://arxiv.org/pdf/2503.08610v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2405.13637v3","updated":"2025-03-11T16:44:48Z","published":"2024-05-22T13:36:48Z","title":"Curriculum Direct Preference Optimization for Diffusion and Consistency\n  Models","summary":"  Direct Preference Optimization (DPO) has been proposed as an effective and\nefficient alternative to reinforcement learning from human feedback (RLHF). In\nthis paper, we propose a novel and enhanced version of DPO based on curriculum\nlearning for text-to-image generation. Our method is divided into two training\nstages. First, a ranking of the examples generated for each prompt is obtained\nby employing a reward model. Then, increasingly difficult pairs of examples are\nsampled and provided to a text-to-image generative (diffusion or consistency)\nmodel. Generated samples that are far apart in the ranking are considered to\nform easy pairs, while those that are close in the ranking form hard pairs. In\nother words, we use the rank difference between samples as a measure of\ndifficulty. The sampled pairs are split into batches according to their\ndifficulty levels, which are gradually used to train the generative model. Our\napproach, Curriculum DPO, is compared against state-of-the-art fine-tuning\napproaches on nine benchmarks, outperforming the competing methods in terms of\ntext alignment, aesthetics and human preference. Our code is available at\nhttps://github.com/CroitoruAlin/Curriculum-DPO.\n","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Nicu Sebe","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2405.13637v3.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08605v1","updated":"2025-03-11T16:43:45Z","published":"2025-03-11T16:43:45Z","title":"Tuning-Free Multi-Event Long Video Generation via Synchronized Coupled\n  Sampling","summary":"  While recent advancements in text-to-video diffusion models enable\nhigh-quality short video generation from a single prompt, generating real-world\nlong videos in a single pass remains challenging due to limited data and high\ncomputational costs. To address this, several works propose tuning-free\napproaches, i.e., extending existing models for long video generation,\nspecifically using multiple prompts to allow for dynamic and controlled content\nchanges. However, these methods primarily focus on ensuring smooth transitions\nbetween adjacent frames, often leading to content drift and a gradual loss of\nsemantic coherence over longer sequences. To tackle such an issue, we propose\nSynchronized Coupled Sampling (SynCoS), a novel inference framework that\nsynchronizes denoising paths across the entire video, ensuring long-range\nconsistency across both adjacent and distant frames. Our approach combines two\ncomplementary sampling strategies: reverse and optimization-based sampling,\nwhich ensure seamless local transitions and enforce global coherence,\nrespectively. However, directly alternating between these samplings misaligns\ndenoising trajectories, disrupting prompt guidance and introducing unintended\ncontent changes as they operate independently. To resolve this, SynCoS\nsynchronizes them through a grounded timestep and a fixed baseline noise,\nensuring fully coupled sampling with aligned denoising paths. Extensive\nexperiments show that SynCoS significantly improves multi-event long video\ngeneration, achieving smoother transitions and superior long-range coherence,\noutperforming previous approaches both quantitatively and qualitatively.\n","authors":["Subin Kim","Seoung Wug Oh","Jui-Hsien Wang","Joon-Young Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2503.08605v1.pdf","comment":"Project page with visuals: https://syncos2025.github.io/"},{"id":"http://arxiv.org/abs/2503.08603v1","updated":"2025-03-11T16:39:09Z","published":"2025-03-11T16:39:09Z","title":"CellStyle: Improved Zero-Shot Cell Segmentation via Style Transfer","summary":"  Cell microscopy data are abundant; however, corresponding segmentation\nannotations remain scarce. Moreover, variations in cell types, imaging devices,\nand staining techniques introduce significant domain gaps between datasets. As\na result, even large, pretrained segmentation models trained on diverse\ndatasets (source datasets) struggle to generalize to unseen datasets (target\ndatasets). To overcome this generalization problem, we propose CellStyle, which\nimproves the segmentation quality of such models without requiring labels for\nthe target dataset, thereby enabling zero-shot adaptation. CellStyle transfers\nthe attributes of an unannotated target dataset, such as texture, color, and\nnoise, to the annotated source dataset. This transfer is performed while\npreserving the cell shapes of the source images, ensuring that the existing\nsource annotations can still be used while maintaining the visual\ncharacteristics of the target dataset. The styled synthetic images with the\nexisting annotations enable the finetuning of a generalist segmentation model\nfor application to the unannotated target data. We demonstrate that CellStyle\nsignificantly improves zero-shot cell segmentation performance across diverse\ndatasets by finetuning multiple segmentation models on the style-transferred\ndata. The code will be made publicly available.\n","authors":["Rüveyda Yilmaz","Zhu Chen","Yuli Wu","Johannes Stegmaier"],"pdf_url":"https://arxiv.org/pdf/2503.08603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08594v1","updated":"2025-03-11T16:30:45Z","published":"2025-03-11T16:30:45Z","title":"3D Point Cloud Generation via Autoregressive Up-sampling","summary":"  We introduce a pioneering autoregressive generative model for 3D point cloud\ngeneration. Inspired by visual autoregressive modeling (VAR), we conceptualize\npoint cloud generation as an autoregressive up-sampling process. This leads to\nour novel model, PointARU, which progressively refines 3D point clouds from\ncoarse to fine scales. PointARU follows a two-stage training paradigm: first,\nit learns multi-scale discrete representations of point clouds, and then it\ntrains an autoregressive transformer for next-scale prediction. To address the\ninherent unordered and irregular structure of point clouds, we incorporate\nspecialized point-based up-sampling network modules in both stages and\nintegrate 3D absolute positional encoding based on the decoded point cloud at\neach scale during the second stage. Our model surpasses state-of-the-art (SoTA)\ndiffusion-based approaches in both generation quality and parameter efficiency\nacross diverse experimental settings, marking a new milestone for\nautoregressive methods in 3D point cloud generation. Furthermore, PointARU\ndemonstrates exceptional performance in completing partial 3D shapes and\nup-sampling sparse point clouds, outperforming existing generative models in\nthese tasks.\n","authors":["Ziqiao Meng","Qichao Wang","Zhipeng Zhou","Irwin King","Peilin Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.08594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07340v2","updated":"2025-03-11T16:27:23Z","published":"2024-02-12T00:18:25Z","title":"Perfect Recovery for Random Geometric Graph Matching with Shallow Graph\n  Neural Networks","summary":"  We study the graph matching problem in the presence of vertex feature\ninformation using shallow graph neural networks. Specifically, given two graphs\nthat are independent perturbations of a single random geometric graph with\nsparse binary features, the task is to recover an unknown one-to-one mapping\nbetween the vertices of the two graphs. We show under certain conditions on the\nsparsity and noise level of the feature vectors, a carefully designed two-layer\ngraph neural network can, with high probability, recover the correct mapping\nbetween the vertices with the help of the graph structure. Additionally, we\nprove that our condition on the noise parameter is tight up to logarithmic\nfactors. Finally, we compare the performance of the graph neural network to\ndirectly solving an assignment problem using the noisy vertex features and\ndemonstrate that when the noise level is at least constant, this direct\nmatching fails to achieve perfect recovery, whereas the graph neural network\ncan tolerate noise levels growing as fast as a power of the size of the graph.\nOur theoretical findings are further supported by numerical studies as well as\nreal-world data experiments.\n","authors":["Suqi Liu","Morgane Austern"],"pdf_url":"https://arxiv.org/pdf/2402.07340v2.pdf","comment":"27 pages, 5 figures, 3 tables; to appear in the Proceedings of the\n  28th International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2025"},{"id":"http://arxiv.org/abs/2503.08588v1","updated":"2025-03-11T16:25:36Z","published":"2025-03-11T16:25:36Z","title":"BiasEdit: Debiasing Stereotyped Language Models via Model Editing","summary":"  Previous studies have established that language models manifest stereotyped\nbiases. Existing debiasing strategies, such as retraining a model with\ncounterfactual data, representation projection, and prompting often fail to\nefficiently eliminate bias or directly alter the models' biased internal\nrepresentations. To address these issues, we propose BiasEdit, an efficient\nmodel editing method to remove stereotypical bias from language models through\nlightweight networks that act as editors to generate parameter updates.\nBiasEdit employs a debiasing loss guiding editor networks to conduct local\nedits on partial parameters of a language model for debiasing while preserving\nthe language modeling abilities during editing through a retention loss.\nExperiments on StereoSet and Crows-Pairs demonstrate the effectiveness,\nefficiency, and robustness of BiasEdit in eliminating bias compared to\ntangental debiasing baselines and little to no impact on the language models'\ngeneral capabilities. In addition, we conduct bias tracing to probe bias in\nvarious modules and explore bias editing impacts on different components of\nlanguage models.\n","authors":["Xin Xu","Wei Xu","Ningyu Zhang","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2503.08588v1.pdf","comment":"Accepted by TrustNLP @ NAACL 2025"},{"id":"http://arxiv.org/abs/2311.00226v4","updated":"2025-03-11T16:24:05Z","published":"2023-11-01T02:16:24Z","title":"Transformers are Provably Optimal In-context Estimators for Wireless\n  Communications","summary":"  Pre-trained transformers exhibit the capability of adapting to new tasks\nthrough in-context learning (ICL), where they efficiently utilize a limited set\nof prompts without explicit model optimization. The canonical communication\nproblem of estimating transmitted symbols from received observations can be\nmodeled as an in-context learning problem: received observations are a noisy\nfunction of transmitted symbols, and this function can be represented by an\nunknown parameter whose statistics depend on an unknown latent context. This\nproblem, which we term in-context estimation (ICE), has significantly greater\ncomplexity than the extensively studied linear regression problem. The optimal\nsolution to the ICE problem is a non-linear function of the underlying context.\nIn this paper, we prove that, for a subclass of such problems, a single-layer\nsoftmax attention transformer (SAT) computes the optimal solution of the above\nestimation problem in the limit of large prompt length. We also prove that the\noptimal configuration of such a transformer is indeed the minimizer of the\ncorresponding training loss. Further, we empirically demonstrate the\nproficiency of multi-layer transformers in efficiently solving broader\nin-context estimation problems. Through extensive simulations, we show that\nsolving ICE problems using transformers significantly outperforms standard\napproaches. Moreover, just with a few context examples, it achieves the same\nperformance as an estimator with perfect knowledge of the latent context. The\ncode is available\n\\href{https://github.com/vishnutez/in-context-estimation}{here}.\n","authors":["Vishnu Teja Kunde","Vicram Rajagopalan","Chandra Shekhara Kaushik Valmeekam","Krishna Narayanan","Srinivas Shakkottai","Dileep Kalathil","Jean-Francois Chamberland"],"pdf_url":"https://arxiv.org/pdf/2311.00226v4.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2502.06268v2","updated":"2025-03-11T16:22:52Z","published":"2025-02-10T09:07:04Z","title":"Spectral-factorized Positive-definite Curvature Learning for NN Training","summary":"  Many training methods, such as Adam(W) and Shampoo, learn a positive-definite\ncurvature matrix and apply an inverse root before preconditioning. Recently,\nnon-diagonal training methods, such as Shampoo, have gained significant\nattention; however, they remain computationally inefficient and are limited to\nspecific types of curvature information due to the costly matrix root\ncomputation via matrix decomposition. To address this, we propose a Riemannian\noptimization approach that dynamically adapts spectral-factorized\npositive-definite curvature estimates, enabling the efficient application of\narbitrary matrix roots and generic curvature learning. We demonstrate the\nefficacy and versatility of our approach in positive-definite matrix\noptimization and covariance adaptation for gradient-free optimization, as well\nas its efficiency in curvature learning for neural net training.\n","authors":["Wu Lin","Felix Dangel","Runa Eschenhagen","Juhan Bae","Richard E. Turner","Roger B. Grosse"],"pdf_url":"https://arxiv.org/pdf/2502.06268v2.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2503.08579v1","updated":"2025-03-11T16:14:42Z","published":"2025-03-11T16:14:42Z","title":"Sparsity-Induced Global Matrix Autoregressive Model with Auxiliary\n  Network Data","summary":"  Jointly modeling and forecasting economic and financial variables across a\nlarge set of countries has long been a significant challenge. Two primary\napproaches have been utilized to address this issue: the vector autoregressive\nmodel with exogenous variables (VARX) and the matrix autoregression (MAR). The\nVARX model captures domestic dependencies, but treats variables exogenous to\nrepresent global factors driven by international trade. In contrast, the MAR\nmodel simultaneously considers variables from multiple countries but ignores\nthe trade network. In this paper, we propose an extension of the MAR model that\nachieves these two aims at once, i.e., studying both international dependencies\nand the impact of the trade network on the global economy. Additionally, we\nintroduce a sparse component to the model to differentiate between systematic\nand idiosyncratic cross-predictability. To estimate the model parameters, we\npropose both a likelihood estimation method and a bias-corrected alternating\nminimization version. We provide theoretical and empirical analyses of the\nmodel's properties, alongside presenting intriguing economic insights derived\nfrom our findings.\n","authors":["Sanyou Wu","Dan Yang","Yan Xu","Long Feng"],"pdf_url":"https://arxiv.org/pdf/2503.08579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14172v3","updated":"2025-03-11T16:11:14Z","published":"2023-08-27T18:28:58Z","title":"Hypergraph Structure Inference From Data Under Smoothness Prior","summary":"  Hypergraphs are important for processing data with higher-order relationships\ninvolving more than two entities. In scenarios where explicit hypergraphs are\nnot readily available, it is desirable to infer a meaningful hypergraph\nstructure from the node features to capture the intrinsic relations within the\ndata. However, existing methods either adopt simple pre-defined rules that fail\nto precisely capture the distribution of the potential hypergraph structure, or\nlearn a mapping between hypergraph structures and node features but require a\nlarge amount of labelled data, i.e., pre-existing hypergraph structures, for\ntraining. Both restrict their applications in practical scenarios. To fill this\ngap, we propose a novel smoothness prior that enables us to design a method to\ninfer the probability for each potential hyperedge without labelled data as\nsupervision. The proposed prior indicates features of nodes in a hyperedge are\nhighly correlated by the features of the hyperedge containing them. We use this\nprior to derive the relation between the hypergraph structure and the node\nfeatures via probabilistic modelling. This allows us to develop an unsupervised\ninference method to estimate the probability for each potential hyperedge via\nsolving an optimisation problem that has an analytical solution. Experiments on\nboth synthetic and real-world data demonstrate that our method can learn\nmeaningful hypergraph structures from data more efficiently than existing\nhypergraph structure inference methods.\n","authors":["Bohan Tang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2308.14172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.10722v3","updated":"2025-03-11T16:09:45Z","published":"2021-11-21T03:09:07Z","title":"A Deterministic Sampling Method via Maximum Mean Discrepancy Flow with\n  Adaptive Kernel","summary":"  We propose a novel deterministic sampling method to approximate a target\ndistribution $\\rho^*$ by minimizing the kernel discrepancy, also known as the\nMaximum Mean Discrepancy (MMD). By employing the general \\emph{energetic\nvariational inference} framework (Wang et al., 2021), we convert the problem of\nminimizing MMD to solving a dynamic ODE system of the particles. We adopt the\nimplicit Euler numerical scheme to solve the ODE systems. This leads to a\nproximal minimization problem in each iteration of updating the particles,\nwhich can be solved by optimization algorithms such as L-BFGS. The proposed\nmethod is named EVI-MMD. To overcome the long-existing issue of bandwidth\nselection of the Gaussian kernel, we propose a novel way to specify the\nbandwidth dynamically. Through comprehensive numerical studies, we have shown\nthe proposed adaptive bandwidth significantly improves the EVI-MMD. We use the\nEVI-MMD algorithm to solve two types of sampling problems. In the first type,\nthe target distribution is given by a fully specified density function. The\nsecond type is a \"two-sample problem\", where only training data are available.\nThe EVI-MMD method is used as a generative learning model to generate new\nsamples that follow the same distribution as the training data. With the\nrecommended settings of the tuning parameters, we show that the proposed\nEVI-MMD method outperforms some existing methods for both types of problems.\n","authors":["Yindong Chen","Yiwei Wang","Lulu Kang","Chun Liu"],"pdf_url":"https://arxiv.org/pdf/2111.10722v3.pdf","comment":"30 pages, 10 figures"},{"id":"http://arxiv.org/abs/2211.01717v4","updated":"2025-03-11T16:08:58Z","published":"2022-11-03T11:13:02Z","title":"Learning Hypergraphs From Signals With Dual Smoothness Prior","summary":"  Hypergraph structure learning, which aims to learn the hypergraph structures\nfrom the observed signals to capture the intrinsic high-order relationships\namong the entities, becomes crucial when a hypergraph topology is not readily\navailable in the datasets. There are two challenges that lie at the heart of\nthis problem: 1) how to handle the huge search space of potential hyperedges,\nand 2) how to define meaningful criteria to measure the relationship between\nthe signals observed on nodes and the hypergraph structure. In this paper, for\nthe first challenge, we adopt the assumption that the ideal hypergraph\nstructure can be derived from a learnable graph structure that captures the\npairwise relations within signals. Further, we propose a hypergraph structure\nlearning framework HGSL with a novel dual smoothness prior that reveals a\nmapping between the observed node signals and the hypergraph structure, whereby\neach hyperedge corresponds to a subgraph with both node signal smoothness and\nedge signal smoothness in the learnable graph structure. Finally, we conduct\nextensive experiments to evaluate HGSL on both synthetic and real world\ndatasets. Experiments show that HGSL can efficiently infer meaningful\nhypergraph topologies from observed signals.\n","authors":["Bohan Tang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2211.01717v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09778v4","updated":"2025-03-11T16:07:41Z","published":"2023-12-15T13:30:04Z","title":"Hypergraph-MLP: Learning on Hypergraphs without Message Passing","summary":"  Hypergraphs are vital in modelling data with higher-order relations\ncontaining more than two entities, gaining prominence in machine learning and\nsignal processing. Many hypergraph neural networks leverage message passing\nover hypergraph structures to enhance node representation learning, yielding\nimpressive performances in tasks like hypergraph node classification. However,\nthese message-passing-based models face several challenges, including\noversmoothing as well as high latency and sensitivity to structural\nperturbations at inference time. To tackle those challenges, we propose an\nalternative approach where we integrate the information about hypergraph\nstructures into training supervision without explicit message passing, thus\nalso removing the reliance on it at inference. Specifically, we introduce\nHypergraph-MLP, a novel learning framework for hypergraph-structured data,\nwhere the learning model is a straightforward multilayer perceptron (MLP)\nsupervised by a loss function based on a notion of signal smoothness on\nhypergraphs. Experiments on hypergraph node classification tasks demonstrate\nthat Hypergraph-MLP achieves competitive performance compared to existing\nbaselines, and is considerably faster and more robust against structural\nperturbations at inference.\n","authors":["Bohan Tang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2312.09778v4.pdf","comment":"Accepted by ICASSP 2024"},{"id":"http://arxiv.org/abs/2412.05103v2","updated":"2025-03-11T16:07:09Z","published":"2024-12-06T15:01:19Z","title":"Integrating Semantic Communication and Human Decision-Making into an\n  End-to-End Sensing-Decision Framework","summary":"  As early as 1949, Weaver defined communication in a very broad sense to\ninclude all procedures by which one mind or technical system can influence\nanother, thus establishing the idea of semantic communication. With the recent\nsuccess of machine learning in expert assistance systems where sensed\ninformation is wirelessly provided to a human to assist task execution, the\nneed to design effective and efficient communications has become increasingly\napparent. In particular, semantic communication aims to convey the meaning\nbehind the sensed information relevant for Human Decision-Making (HDM).\nRegarding the interplay between semantic communication and HDM, many questions\nremain, such as how to model the entire end-to-end sensing-decision-making\nprocess, how to design semantic communication for the HDM and which information\nshould be provided to the HDM. To address these questions, we propose to\nintegrate semantic communication and HDM into one probabilistic end-to-end\nsensing-decision framework that bridges communications and psychology. In our\ninterdisciplinary framework, we model the human through a HDM process, allowing\nus to explore how feature extraction from semantic communication can best\nsupport HDM both in theory and in simulations. In this sense, our study reveals\nthe fundamental design trade-off between maximizing the relevant semantic\ninformation and matching the cognitive capabilities of the HDM model. Our\ninitial analysis shows how semantic communication can balance the level of\ndetail with human cognitive capabilities while demanding less bandwidth, power,\nand latency.\n","authors":["Edgar Beck","Hsuan-Yu Lin","Patrick Rückert","Yongping Bao","Bettina von Helversen","Sebastian Fehrler","Kirsten Tracht","Armin Dekorsy"],"pdf_url":"https://arxiv.org/pdf/2412.05103v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05569v6","updated":"2025-03-11T16:06:25Z","published":"2024-02-08T11:10:39Z","title":"Training-Free Message Passing for Learning on Hypergraphs","summary":"  Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.\n","authors":["Bohan Tang","Zexi Liu","Keyue Jiang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2402.05569v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08569v1","updated":"2025-03-11T15:59:43Z","published":"2025-03-11T15:59:43Z","title":"DeepReview: Improving LLM-based Paper Review with Human-like Deep\n  Thinking Process","summary":"  Large Language Models (LLMs) are increasingly utilized in scientific research\nassessment, particularly in automated paper review. However, existing LLM-based\nreview systems face significant challenges, including limited domain expertise,\nhallucinated reasoning, and a lack of structured evaluation. To address these\nlimitations, we introduce DeepReview, a multi-stage framework designed to\nemulate expert reviewers by incorporating structured analysis, literature\nretrieval, and evidence-based argumentation. Using DeepReview-13K, a curated\ndataset with structured annotations, we train DeepReviewer-14B, which\noutperforms CycleReviewer-70B with fewer tokens. In its best mode,\nDeepReviewer-14B achieves win rates of 88.21\\% and 80.20\\% against GPT-o1 and\nDeepSeek-R1 in evaluations. Our work sets a new benchmark for LLM-based paper\nreview, with all resources publicly available. The code, model, dataset and\ndemo have be released in http://ai-researcher.net.\n","authors":["Minjun Zhu","Yixuan Weng","Linyi Yang","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02114v2","updated":"2025-03-11T15:58:41Z","published":"2024-11-04T14:29:02Z","title":"Semiparametric conformal prediction","summary":"  Many risk-sensitive applications require well-calibrated prediction sets over\nmultiple, potentially correlated target variables, for which the prediction\nalgorithm may report correlated errors. In this work, we aim to construct the\nconformal prediction set accounting for the joint correlation structure of the\nvector-valued non-conformity scores. Drawing from the rich literature on\nmultivariate quantiles and semiparametric statistics, we propose an algorithm\nto estimate the $1-\\alpha$ quantile of the scores, where $\\alpha$ is the\nuser-specified miscoverage rate. In particular, we flexibly estimate the joint\ncumulative distribution function (CDF) of the scores using nonparametric vine\ncopulas and improve the asymptotic efficiency of the quantile estimate using\nits influence function. The vine decomposition allows our method to scale well\nto a large number of targets. As well as guaranteeing asymptotically exact\ncoverage, our method yields desired coverage and competitive efficiency on a\nrange of real-world regression problems, including those with missing-at-random\nlabels in the calibration set.\n","authors":["Ji Won Park","Robert Tibshirani","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.02114v2.pdf","comment":"12 pages (+12 appendix), 12 figures, accepted to AISTATS 2025"},{"id":"http://arxiv.org/abs/2410.01405v5","updated":"2025-03-11T15:51:21Z","published":"2024-10-02T10:31:17Z","title":"On Expressive Power of Looped Transformers: Theoretical Analysis and\n  Enhancement via Timestep Encoding","summary":"  Looped Transformers provide advantages in parameter efficiency, computational\ncapabilities, and generalization for reasoning tasks. However, their expressive\npower regarding function approximation remains underexplored. In this paper, we\nestablish the approximation rate of Looped Transformers by defining the modulus\nof continuity for sequence-to-sequence functions. This reveals a limitation\nspecific to the looped architecture. That is, the analysis prompts the\nincorporation of scaling parameters for each loop, conditioned on timestep\nencoding. Experiments validate the theoretical results, showing that increasing\nthe number of loops enhances performance, with further gains achieved through\nthe timestep encoding.\n","authors":["Kevin Xu","Issei Sato"],"pdf_url":"https://arxiv.org/pdf/2410.01405v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02800v3","updated":"2025-03-11T15:47:37Z","published":"2025-03-04T17:20:43Z","title":"RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration","summary":"  Anomaly detection in complex industrial environments poses unique challenges,\nparticularly in contexts characterized by data sparsity and evolving\noperational conditions. Predictive maintenance (PdM) in such settings demands\nmethodologies that are adaptive, transferable, and capable of integrating\ndomain-specific knowledge. In this paper, we present RAAD-LLM, a novel\nframework for adaptive anomaly detection, leveraging large language models\n(LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach\naddresses the aforementioned PdM challenges. By effectively utilizing\ndomain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time\nseries data without requiring fine-tuning on specific datasets. The framework's\nadaptability mechanism enables it to adjust its understanding of normal\noperating conditions dynamically, thus increasing detection accuracy. We\nvalidate this methodology through a real-world application for a plastics\nmanufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show\nsignificant improvements over our previous model with an accuracy increase from\n70.7% to 88.6% on the real-world dataset. By allowing for the enriching of\ninput series data with semantics, RAAD-LLM incorporates multimodal capabilities\nthat facilitate more collaborative decision-making between the model and plant\noperators. Overall, our findings support RAAD-LLM's ability to revolutionize\nanomaly detection methodologies in PdM, potentially leading to a paradigm shift\nin how anomaly detection is implemented across various industries.\n","authors":["Alicia Russell-Gilbert","Sudip Mittal","Shahram Rahimi","Maria Seale","Joseph Jabour","Thomas Arnold","Joshua Church"],"pdf_url":"https://arxiv.org/pdf/2503.02800v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.00914"},{"id":"http://arxiv.org/abs/2503.08558v1","updated":"2025-03-11T15:47:12Z","published":"2025-03-11T15:47:12Z","title":"Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime\n  Failure Detection for Imitation Learning Policies","summary":"  Recent years have witnessed impressive robotic manipulation systems driven by\nadvances in imitation learning and generative modeling, such as diffusion- and\nflow-based approaches. As robot policy performance increases, so does the\ncomplexity and time horizon of achievable tasks, inducing unexpected and\ndiverse failure modes that are difficult to predict a priori. To enable\ntrustworthy policy deployment in safety-critical human environments, reliable\nruntime failure detection becomes important during policy inference. However,\nmost existing failure detection approaches rely on prior knowledge of failure\nmodes and require failure data during training, which imposes a significant\nchallenge in practicality and scalability. In response to these limitations, we\npresent FAIL-Detect, a modular two-stage approach for failure detection in\nimitation learning-based robotic manipulation. To accurately identify failures\nfrom successful training data alone, we frame the problem as sequential\nout-of-distribution (OOD) detection. We first distill policy inputs and outputs\ninto scalar signals that correlate with policy failures and capture epistemic\nuncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile\nframework for uncertainty quantification with statistical guarantees.\nEmpirically, we thoroughly investigate both learned and post-hoc scalar signal\ncandidates on diverse robotic manipulation tasks. Our experiments show learned\nsignals to be mostly consistently effective, particularly when using our novel\nflow-based density estimator. Furthermore, our method detects failures more\naccurately and faster than state-of-the-art (SOTA) failure detection baselines.\nThese results highlight the potential of FAIL-Detect to enhance the safety and\nreliability of imitation learning-based robotic systems as they progress toward\nreal-world deployment.\n","authors":["Chen Xu","Tony Khuong Nguyen","Emma Dixon","Christopher Rodriguez","Patrick Miller","Robert Lee","Paarth Shah","Rares Ambrus","Haruki Nishimura","Masha Itkina"],"pdf_url":"https://arxiv.org/pdf/2503.08558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08555v1","updated":"2025-03-11T15:45:37Z","published":"2025-03-11T15:45:37Z","title":"An Analysis of Safety Guarantees in Multi-Task Bayesian Optimization","summary":"  In many practical scenarios of black box optimization, the objective function\nis subject to constraints that must be satisfied to avoid undesirable outcomes.\nSuch constraints are typically unknown and must be learned during optimization.\nSafe Bayesian optimization aims to find the global optimum while ensuring that\nthe constraints are satisfied with high probability. However, it is often\nsample-inefficient due to the small initial feasible set, which requires\nexpansion by evaluating the objective or constraint functions, limiting its\napplicability to low-dimensional or inexpensive problems. To enhance sample\nefficiency, additional information from cheap simulations can be leveraged,\nalbeit at the cost of safeness guarantees. This paper introduces a novel safe\nmulti-task Bayesian optimization algorithm that integrates multiple tasks while\nmaintaining high-probability safety. We derive robust uniform error bounds for\nthe multi-task case and demonstrate the effectiveness of the approach on\nbenchmark functions and a control problem. Our results show a significant\nimprovement in sample efficiency, making the proposed method well-suited for\nexpensive-to-evaluate functions.\n","authors":["Jannis O. Luebsen","Annika Eichler"],"pdf_url":"https://arxiv.org/pdf/2503.08555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02854v2","updated":"2025-03-11T15:36:40Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v2.pdf","comment":"21 pages, 17 figures, 1 table. Code:\n  http://github.com/belindal/state-tracking"},{"id":"http://arxiv.org/abs/2406.17281v3","updated":"2025-03-11T15:34:12Z","published":"2024-06-25T05:12:51Z","title":"Adaptive Topology Reconstruction for Robust Graph Representation\n  Learning","summary":"  Graph Neural Networks (GNNs) have become fundamental in semi-supervised\nlearning for graph representation, leveraging their ability to capture complex\nnode relationships. A recent trend in GNN research focuses on adaptive\nmulti-hop structure learning, moving beyond fixed-hop aggregation to more\nflexible and dynamic neighborhood selection. While GAMLP \\citep{Zhang_2022}\nemploys separate MLP layers for each multi-hop domain and ImprovingTE\n\\citep{Yao2023ImprovingTE} enhances this by injecting contextualized\nsubstructure information, these methods still rely heavily on predefined\nsampling strategies, which may limit their ability to generalize and maintain\nstable accuracy. To address these limitations, we propose an \\textbf{adaptive\nreconstruction framework} that dynamically refines multi-hop structure\nlearning. Inspired by \"coreset selection\" \\citep{guo2022deepcore}, our approach\nadaptively \\textbf{reconstructs} node neighborhoods to optimize message\npassing, ensuring more \\textbf{effective and context-aware information flow}\nacross the graph. To further enhance structural robustness, we introduce two\nkey modules: the \\textbf{Distance Recomputator} and the \\textbf{Topology\nReconstructor} (\\textcolor{blue}{DRTR}). The Distance Recomputator\n\\textbf{reassesses and recalibrates} node distances based on adaptive graph\nproperties, leading to \\textbf{improved node embeddings} that better reflect\nlatent relationships. Meanwhile, the Topology Reconstructor \\textbf{dynamically\nrefines local graph structures}, enabling the model to \\textbf{adapt to\nevolving graph topologies} and mitigate the impact of noise and mislabeled\ndata. Empirical evaluations demonstrate that our \\textbf{adaptive\nreconstruction framework} achieves \\textbf{significant improvements} over\nexisting multi-hop-based models, providing more \\textbf{stable and accurate}\nperformance in various graph learning benchmarks.\n","authors":["Dong Liu","Yanxuan Yu"],"pdf_url":"https://arxiv.org/pdf/2406.17281v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20158v3","updated":"2025-03-11T15:30:13Z","published":"2024-07-29T16:34:47Z","title":"Machine Learning for Predicting Chaotic Systems","summary":"  Predicting chaotic dynamical systems is critical in many scientific fields,\nsuch as weather forecasting, but challenging due to the characteristic\nsensitive dependence on initial conditions. Traditional modeling approaches\nrequire extensive domain knowledge, often leading to a shift towards\ndata-driven methods using machine learning. However, existing research provides\ninconclusive results on which machine learning methods are best suited for\npredicting chaotic systems. In this paper, we compare different lightweight and\nheavyweight machine learning architectures using extensive existing benchmark\ndatabases, as well as a newly introduced database that allows for uncertainty\nquantification in the benchmark results. In addition to state-of-the-art\nmethods from the literature, we also present new advantageous variants of\nestablished methods. Hyperparameter tuning is adjusted based on computational\ncost, with more tuning allocated to less costly methods. Furthermore, we\nintroduce the cumulative maximum error, a novel metric that combines desirable\nproperties of traditional metrics and is tailored for chaotic systems. Our\nresults show that well-tuned simple methods, as well as untuned baseline\nmethods, often outperform state-of-the-art deep learning models, but their\nperformance can vary significantly with different experimental setups. These\nfindings highlight the importance of aligning prediction methods with data\ncharacteristics and caution against the indiscriminate use of overly complex\nmodels.\n","authors":["Christof Schötz","Alistair White","Maximilian Gelbrecht","Niklas Boers"],"pdf_url":"https://arxiv.org/pdf/2407.20158v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08534v1","updated":"2025-03-11T15:24:50Z","published":"2025-03-11T15:24:50Z","title":"ChromaFormer: A Scalable and Accurate Transformer Architecture for Land\n  Cover Classification","summary":"  Remote sensing imagery from systems such as Sentinel provides full coverage\nof the Earth's surface at around 10-meter resolution. The remote sensing\ncommunity has transitioned to extensive use of deep learning models due to\ntheir high performance on benchmarks such as the UCMerced and ISPRS Vaihingen\ndatasets. Convolutional models such as UNet and ResNet variations are commonly\nemployed for remote sensing but typically only accept three channels, as they\nwere developed for RGB imagery, while satellite systems provide more than ten.\nRecently, several transformer architectures have been proposed for remote\nsensing, but they have not been extensively benchmarked and are typically used\non small datasets such as Salinas Valley. Meanwhile, it is becoming feasible to\nobtain dense spatial land-use labels for entire first-level administrative\ndivisions of some countries. Scaling law observations suggest that\nsubstantially larger multi-spectral transformer models could provide a\nsignificant leap in remote sensing performance in these settings.\n  In this work, we propose ChromaFormer, a family of multi-spectral transformer\nmodels, which we evaluate across orders of magnitude differences in model\nparameters to assess their performance and scaling effectiveness on a densely\nlabeled imagery dataset of Flanders, Belgium, covering more than 13,500 km^2\nand containing 15 classes. We propose a novel multi-spectral attention strategy\nand demonstrate its effectiveness through ablations. Furthermore, we show that\nmodels many orders of magnitude larger than conventional architectures, such as\nUNet, lead to substantial accuracy improvements: a UNet++ model with 23M\nparameters achieves less than 65% accuracy, while a multi-spectral transformer\nwith 655M parameters achieves over 95% accuracy on the Biological Valuation Map\nof Flanders.\n","authors":["Mingshi Li","Dusan Grujicic","Ben Somers","Stien Heremans","Steven De Saeger","Matthew B. Blaschko"],"pdf_url":"https://arxiv.org/pdf/2503.08534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01905v2","updated":"2025-03-11T15:24:13Z","published":"2025-02-28T13:30:10Z","title":"PaCA: Partial Connection Adaptation for Efficient Fine-Tuning","summary":"  Prior parameter-efficient fine-tuning (PEFT) algorithms reduce memory usage\nand computational costs of fine-tuning large neural network models by training\nonly a few additional adapter parameters, rather than the entire model.\nHowever, the reduction in computational costs due to PEFT does not necessarily\ntranslate to a reduction in training time; although the computational costs of\nthe adapter layers are much smaller than the pretrained layers, it is well\nknown that those two types of layers are processed sequentially on GPUs,\nresulting in significant latency overhead. LoRA and its variants merge low-rank\nadapter matrices with pretrained weights during inference to avoid latency\noverhead, but during training, the pretrained weights remain frozen while the\nadapter matrices are continuously updated, preventing such merging. To mitigate\nthis issue, we propose Partial Connection Adaptation (PaCA), which fine-tunes\nrandomly selected partial connections within the pretrained weights instead of\nintroducing adapter layers in the model. PaCA not only enhances training speed\nby eliminating the time overhead due to the sequential processing of the\nadapter and pretrained layers but also reduces activation memory since only\npartial activations, rather than full activations, need to be stored for\ngradient computation. Compared to LoRA, PaCA reduces training time by 22% and\ntotal memory usage by 16%, while maintaining comparable accuracy across various\nfine-tuning scenarios, such as fine-tuning on the MMLU dataset and instruction\ntuning on the Oasst1 dataset. PaCA can also be combined with quantization,\nenabling the fine-tuning of large models such as LLaMA3.1-70B. In addition,\nPaCA enables training with 23% longer sequence and improves throughput by 16%\non both NVIDIA A100 GPU and INTEL Gaudi2 HPU compared to LoRA. The code is\navailable at https://github.com/WooSunghyeon/paca.\n","authors":["Sunghyeon Woo","Sol Namkung","Sunwoo Lee","Inho Jeong","Beomseok Kim","Dongsuk Jeon"],"pdf_url":"https://arxiv.org/pdf/2503.01905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03924v2","updated":"2025-03-11T15:22:55Z","published":"2024-10-04T21:03:16Z","title":"Online Control-Informed Learning","summary":"  This paper proposes an Online Control-Informed Learning (OCIL) framework,\nwhich employs the well-established optimal control and state estimation\ntechniques in the field of control to solve a broad class of learning tasks in\nan online fashion. This novel integration effectively handles practical issues\nin machine learning such as noisy measurement data, online learning, and data\nefficiency. By considering any robot as a tunable optimal control system, we\npropose an online parameter estimator based on extended Kalman filter (EKF) to\nincrementally tune the system in an online fashion, enabling it to complete\ndesignated learning or control tasks. The proposed method also improves the\nrobustness in learning by effectively managing noise in the data. Theoretical\nanalysis is provided to demonstrate the convergence of OCIL. Three learning\nmodes of OCIL, i.e. Online Imitation Learning, Online System Identification,\nand Policy Tuning On-the-fly, are investigated via experiments, which validate\ntheir effectiveness.\n","authors":["Zihao Liang","Tianyu Zhou","Zehui Lu","Shaoshuai Mou"],"pdf_url":"https://arxiv.org/pdf/2410.03924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01865v3","updated":"2025-03-11T15:03:32Z","published":"2024-03-04T09:21:10Z","title":"Out-of-distribution robustness for multivariate analysis via causal\n  regularisation","summary":"  We propose a regularisation strategy of classical machine learning algorithms\nrooted in causality that ensures robustness against distribution shifts.\nBuilding upon the anchor regression framework, we demonstrate how incorporating\na straightforward regularisation term into the loss function of classical\nmultivariate analysis algorithms, such as (orthonormalized) partial least\nsquares, reduced-rank regression, and multiple linear regression, enables\nout-of-distribution generalisation. Our framework allows users to efficiently\nverify the compatibility of a loss function with the regularisation strategy.\nEstimators for selected algorithms are provided, showcasing consistency and\nefficacy in synthetic and real-world climate science problems. The empirical\nvalidation highlights the versatility of anchor regularisation, emphasizing its\ncompatibility with multivariate analysis approaches and its role in enhancing\nreplicability while guarding against distribution shifts. The extended anchor\nframework advances causal inference methodologies, addressing the need for\nreliable out-of-distribution generalisation.\n","authors":["Homer Durand","Gherardo Varando","Nathan Mankovich","Gustau Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2403.01865v3.pdf","comment":"26 pages, 15 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.15312v2","updated":"2025-03-11T15:01:44Z","published":"2024-12-19T16:13:04Z","title":"PCA-Featured Transformer for Jamming Detection in 5G UAV Networks","summary":"  Unmanned Aerial Vehicles (UAVs) face significant security risks from jamming\nattacks, which can compromise network functionality. Traditional detection\nmethods often fall short when confronting AI-powered jamming that dynamically\nmodifies its behavior, while contemporary machine learning approaches\nfrequently demand substantial feature engineering and struggle with temporal\npatterns in attack signatures. The vulnerability extends to 5G networks\nemploying Time Division Duplex (TDD) or Frequency Division Duplex (FDD), where\nservice quality may deteriorate due to deliberate interference. We introduce a\nnovel U-shaped transformer architecture that leverages Principal Component\nAnalysis (PCA) to refine feature representations for improved wireless\nsecurity. The training process is regularized by incorporating the output\nentropy uncertainty into the loss function, a mechanism inspired by the Soft\nActor-Critic (SAC) algorithm in Reinforcement Learning (RL) to enable robust\njamming detection techniques. The architecture features a modified transformer\nencoder specially designed to process critical wireless signal features,\nincluding Received Signal Strength Indicator (RSSI) and Signal-to-\nInterference-plus-Noise Ratio (SINR) measurements. We complement this with a\ncustom positional encoding mechanism that specifically accounts for the\ninherent periodicity of wireless signals,enabling a more accurate\nrepresentation of temporal signal patterns. In addition, we propose a batch\nsize scheduler and implement chunking techniques to optimize convergence for\ntime series data. These advancements contribute to up to a ten times\nimprovement in training speed within the advanced U-shaped encoder-decoder\ntransformer model introduced in this study. Experimental evaluations\ndemonstrate the effectiveness of our entropy-based approach, achieving\ndetection rates of 85.06% in NLoS scenarios.\n","authors":["Joseanne Viana","Hamed Farkhari","Pedro Sebastiao","Victor P Gil Jimenez"],"pdf_url":"https://arxiv.org/pdf/2412.15312v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08510v1","updated":"2025-03-11T15:00:22Z","published":"2025-03-11T15:00:22Z","title":"External Knowledge Injection for CLIP-Based Class-Incremental Learning","summary":"  Class-Incremental Learning (CIL) enables learning systems to continuously\nadapt to evolving data streams. With the advancement of pre-training,\nleveraging pre-trained vision-language models (e.g., CLIP) offers a promising\nstarting point for CIL. However, CLIP makes decisions by matching visual\nembeddings to class names, overlooking the rich contextual information conveyed\nthrough language. For instance, the concept of ``cat'' can be decomposed into\nfeatures like tail, fur, and face for recognition. Besides, since the model is\ncontinually updated, these detailed features are overwritten in CIL, requiring\nexternal knowledge for compensation. In this paper, we introduce ExterNal\nknowledGe INjEction (ENGINE) for CLIP-based CIL. To enhance knowledge transfer\nfrom outside the dataset, we propose a dual-branch injection tuning framework\nthat encodes informative knowledge from both visual and textual modalities. The\nvisual branch is enhanced with data augmentation to enrich the visual features,\nwhile the textual branch leverages GPT-4 to rewrite discriminative descriptors.\nIn addition to this on-the-fly knowledge injection, we also implement\npost-tuning knowledge by re-ranking the prediction results during inference.\nWith the injected knowledge, the model can better capture informative features\nfor downstream tasks as data evolves. Extensive experiments demonstrate the\nstate-of-the-art performance of ENGINE. Code is available at:\nhttps://github.com/RenaissCode/ENGINE\n","authors":["Da-Wei Zhou","Kai-Wen Li","Jingyi Ning","Han-Jia Ye","Lijun Zhang","De-Chuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2503.08510v1.pdf","comment":"Code is available at: https://github.com/RenaissCode/ENGINE"},{"id":"http://arxiv.org/abs/2503.08509v1","updated":"2025-03-11T15:00:13Z","published":"2025-03-11T15:00:13Z","title":"DISTINGUISH Workflow: A New Paradigm of Dynamic Well Placement Using\n  Generative Machine Learning","summary":"  The real-time process of directional changes while drilling, known as\ngeosteering, is crucial for hydrocarbon extraction and emerging directional\ndrilling applications such as geothermal energy, civil infrastructure, and CO2\nstorage. The geo-energy industry seeks an automatic geosteering workflow that\ncontinually updates the subsurface uncertainties and captures the latest\ngeological understanding given the most recent observations in real-time.\n  We propose \"DISTINGUISH\": a real-time, AI-driven workflow designed to\ntransform geosteering by integrating Generative Adversarial Networks (GANs) for\ngeological parameterization, ensemble methods for model updating, and global\ndiscrete dynamic programming (DDP) optimization for complex decision-making\nduring directional drilling operations. The DISTINGUISH framework relies on\noffline training of a GAN model to reproduce relevant geology realizations and\na Forward Neural Network (FNN) to model Logging-While-Drilling (LWD) tools'\nresponse for a given geomodel.\n  This paper introduces a first-of-its-kind workflow that progressively reduces\nGAN-geomodel uncertainty around and ahead of the drilling bit and adjusts the\nwell plan accordingly. The workflow automatically integrates real-time LWD data\nwith a DDP-based decision support system, enhancing predictive models of\ngeology ahead of drilling and leading to better steering decisions. We present\na simple yet representative benchmark case and document the performance target\nachieved by the DISTINGUISH workflow prototype. This benchmark will be a\nfoundation for future methodological advancements and workflow refinements.\n","authors":["Sergey Alyaev","Kristian Fossum","Hibat Errahmen Djecta","Jan Tveranger","Ahmed H. Elsheikh"],"pdf_url":"https://arxiv.org/pdf/2503.08509v1.pdf","comment":"The conference version of this paper is published in EAGE ECMOR 2024\n  proceedings: https://doi.org/10.3997/2214-4609.202437018"},{"id":"http://arxiv.org/abs/2410.06502v2","updated":"2025-03-11T14:58:58Z","published":"2024-10-09T03:10:21Z","title":"Chemistry-Inspired Diffusion with Non-Differentiable Guidance","summary":"  Recent advances in diffusion models have shown remarkable potential in the\nconditional generation of novel molecules. These models can be guided in two\nways: (i) explicitly, through additional features representing the condition,\nor (ii) implicitly, using a property predictor. However, training property\npredictors or conditional diffusion models requires an abundance of labeled\ndata and is inherently challenging in real-world applications. We propose a\nnovel approach that attenuates the limitations of acquiring large labeled\ndatasets by leveraging domain knowledge from quantum chemistry as a\nnon-differentiable oracle to guide an unconditional diffusion model. Instead of\nrelying on neural networks, the oracle provides accurate guidance in the form\nof estimated gradients, allowing the diffusion process to sample from a\nconditional distribution specified by quantum chemistry. We show that this\nresults in more precise conditional generation of novel and stable molecular\nstructures. Our experiments demonstrate that our method: (1) significantly\nreduces atomic forces, enhancing the validity of generated molecules when used\nfor stability optimization; (2) is compatible with both explicit and implicit\nguidance in diffusion models, enabling joint optimization of molecular\nproperties and stability; and (3) generalizes effectively to molecular\noptimization tasks beyond stability optimization.\n","authors":["Yuchen Shen","Chenhao Zhang","Sijie Fu","Chenghui Zhou","Newell Washburn","Barnabás Póczos"],"pdf_url":"https://arxiv.org/pdf/2410.06502v2.pdf","comment":"accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08502v1","updated":"2025-03-11T14:54:25Z","published":"2025-03-11T14:54:25Z","title":"The Space Between: On Folding, Symmetries and Sampling","summary":"  Recent findings suggest that consecutive layers of neural networks with the\nReLU activation function \\emph{fold} the input space during the learning\nprocess. While many works hint at this phenomenon, an approach to quantify the\nfolding was only recently proposed by means of a space folding measure based on\nHamming distance in the ReLU activation space. We generalize this measure to a\nwider class of activation functions through introduction of equivalence classes\nof input data, analyse its mathematical and computational properties and come\nup with an efficient sampling strategy for its implementation. Moreover, it has\nbeen observed that space folding values increase with network depth when the\ngeneralization error is low, but decrease when the error increases. This\nunderpins that learned symmetries in the data manifold (e.g., invariance under\nreflection) become visible in terms of space folds, contributing to the\nnetwork's generalization capacity. Inspired by these findings, we outline a\nnovel regularization scheme that encourages the network to seek solutions\ncharacterized by higher folding values.\n","authors":["Michal Lewandowski","Bernhard Heinzl","Raphael Pisoni","Bernhard A. Moser"],"pdf_url":"https://arxiv.org/pdf/2503.08502v1.pdf","comment":"Accepted at the ICLR Workshop on Neural Network Weights as a New Data\n  Modality, 2025"},{"id":"http://arxiv.org/abs/2503.08501v1","updated":"2025-03-11T14:54:14Z","published":"2025-03-11T14:54:14Z","title":"Learning to Match Unpaired Data with Minimum Entropy Coupling","summary":"  Multimodal data is a precious asset enabling a variety of downstream tasks in\nmachine learning. However, real-world data collected across different\nmodalities is often not paired, which is a significant challenge to learn a\njoint distribution. A prominent approach to address the modality coupling\nproblem is Minimum Entropy Coupling (MEC), which seeks to minimize the joint\nEntropy, while satisfying constraints on the marginals. Existing approaches to\nthe MEC problem focus on finite, discrete distributions, limiting their\napplication for cases involving continuous data. In this work, we propose a\nnovel method to solve the continuous MEC problem, using well-known generative\ndiffusion models that learn to approximate and minimize the joint Entropy\nthrough a cooperative scheme, while satisfying a relaxed version of the\nmarginal constraints. We empirically demonstrate that our method, DDMEC, is\ngeneral and can be easily used to address challenging tasks, including\nunsupervised single-cell multi-omics data alignment and unpaired image\ntranslation, outperforming specialized methods.\n","authors":["Mustapha Bounoua","Giulio Franzese","Pietro Michiardi"],"pdf_url":"https://arxiv.org/pdf/2503.08501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11803v2","updated":"2025-03-11T14:53:10Z","published":"2025-01-21T00:44:18Z","title":"Automating High Quality RT Planning at Scale","summary":"  Radiotherapy (RT) planning is complex, subjective, and time-intensive.\nAdvances in artificial intelligence (AI) promise to improve its precision,\nefficiency, and consistency, but progress is often limited by the scarcity of\nlarge, standardized datasets. To address this, we introduce the Automated\nIterative RT Planning (AIRTP) system, a scalable solution for generating\nhigh-quality treatment plans. This scalable solution is designed to generate\nsubstantial volumes of consistently high-quality treatment plans, overcoming a\nkey obstacle in the advancement of AI-driven RT planning. Our AIRTP pipeline\nadheres to clinical guidelines and automates essential steps, including\norgan-at-risk (OAR) contouring, helper structure creation, beam setup,\noptimization, and plan quality improvement, using AI integrated with RT\nplanning software like Eclipse of Varian. Furthermore, a novel approach for\ndetermining optimization parameters to reproduce 3D dose distributions, i.e. a\nmethod to convert dose predictions to deliverable treatment plans constrained\nby machine limitations. A comparative analysis of plan quality reveals that our\nautomated pipeline produces treatment plans of quality comparable to those\ngenerated manually, which traditionally require several hours of labor per\nplan. Committed to public research, the first data release of our AIRTP\npipeline includes nine cohorts covering head-and-neck and lung cancer sites to\nsupport an AAPM 2025 challenge. This data set features more than 10 times the\nnumber of plans compared to the largest existing well-curated public data set\nto our best knowledge. Repo:\nhttps://github.com/RiqiangGao/GDP-HMM_AAPMChallenge.\n","authors":["Riqiang Gao","Mamadou Diallo","Han Liu","Anthony Magliari","Jonathan Sackett","Wilko Verbakel","Sandra Meyers","Masoud Zarepisheh","Rafe Mcbeth","Simon Arberet","Martin Kraus","Florin C. Ghesu","Ali Kamen"],"pdf_url":"https://arxiv.org/pdf/2501.11803v2.pdf","comment":"radiotherapy planning"},{"id":"http://arxiv.org/abs/2410.11067v2","updated":"2025-03-11T14:50:04Z","published":"2024-10-14T20:25:49Z","title":"Variational Inference in Location-Scale Families: Exact Recovery of the\n  Mean and Correlation Matrix","summary":"  Given an intractable target density $p$, variational inference (VI) attempts\nto find the best approximation $q$ from a tractable family $Q$. This is\ntypically done by minimizing the exclusive Kullback-Leibler divergence,\n$\\text{KL}(q||p)$. In practice, $Q$ is not rich enough to contain $p$, and the\napproximation is misspecified even when it is a unique global minimizer of\n$\\text{KL}(q||p)$. In this paper, we analyze the robustness of VI to these\nmisspecifications when $p$ exhibits certain symmetries and $Q$ is a\nlocation-scale family that shares these symmetries. We prove strong guarantees\nfor VI not only under mild regularity conditions but also in the face of severe\nmisspecifications. Namely, we show that (i) VI recovers the mean of $p$ when\n$p$ exhibits an \\textit{even} symmetry, and (ii) it recovers the correlation\nmatrix of $p$ when in addition~$p$ exhibits an \\textit{elliptical} symmetry.\nThese guarantees hold for the mean even when $q$ is factorized and $p$ is not,\nand for the correlation matrix even when~$q$ and~$p$ behave differently in\ntheir tails. We analyze various regimes of Bayesian inference where these\nsymmetries are useful idealizations, and we also investigate experimentally how\nVI behaves in their absence.\n","authors":["Charles C. Margossian","Lawrence K. Saul"],"pdf_url":"https://arxiv.org/pdf/2410.11067v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08497v1","updated":"2025-03-11T14:48:01Z","published":"2025-03-11T14:48:01Z","title":"MMRL: Multi-Modal Representation Learning for Vision-Language Models","summary":"  Large-scale pre-trained Vision-Language Models (VLMs) have become essential\nfor transfer learning across diverse tasks. However, adapting these models with\nlimited few-shot data often leads to overfitting, diminishing their performance\non new tasks. To tackle this issue, we propose a novel Multi-Modal\nRepresentation Learning (MMRL) framework that introduces a shared, learnable,\nand modality-agnostic representation space. MMRL projects the space tokens to\ntext and image representation tokens, facilitating more effective multi-modal\ninteractions. Unlike previous approaches that solely optimize class token\nfeatures, MMRL integrates representation tokens at higher layers of the\nencoders--where dataset-specific features are more prominent--while preserving\ngeneralized knowledge in the lower layers. During training, both representation\nand class features are optimized, with trainable projection layer applied to\nthe representation tokens, whereas the class token projection layer remains\nfrozen to retain pre-trained knowledge. Furthermore, a regularization term is\nintroduced to align the class features and text features with the zero-shot\nfeatures from the frozen VLM, thereby safeguarding the model's generalization\ncapacity. For inference, a decoupling strategy is employed, wherein both\nrepresentation and class features are utilized for base classes, while only the\nclass features, which retain more generalized knowledge, are used for new\ntasks. Extensive experiments across 15 datasets demonstrate that MMRL\noutperforms state-of-the-art methods, achieving a balanced trade-off between\ntask-specific adaptation and generalization. Code is available at\nhttps://github.com/yunncheng/MMRL.\n","authors":["Yuncheng Guo","Xiaodong Gu"],"pdf_url":"https://arxiv.org/pdf/2503.08497v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2410.16888v2","updated":"2025-03-11T14:46:34Z","published":"2024-10-22T10:46:36Z","title":"Unsupervised Time Series Anomaly Prediction with Importance-based\n  Generative Contrastive Learning","summary":"  Time series anomaly prediction plays an essential role in many real-world\nscenarios, such as environmental prevention and prompt maintenance of\ncyber-physical systems. However, existing time series anomaly prediction\nmethods mainly require supervised training with plenty of manually labeled\ndata, which are difficult to obtain in practice. Besides, unseen anomalies can\noccur during inference, which could differ from the labeled training data and\nmake these models fail to predict such new anomalies. In this paper, we study a\nnovel problem of unsupervised time series anomaly prediction. We provide a\ntheoretical analysis and propose Importance-based Generative Contrastive\nLearning (IGCL) to address the aforementioned problems. IGCL distinguishes\nbetween normal and anomaly precursors, which are generated by our anomaly\nprecursor pattern generation module. To address the efficiency issues caused by\nthe potential complex anomaly precursor combinations, we propose a memory bank\nwith importance-based scores to adaptively store representative anomaly\nprecursors and generate more complicated anomaly precursors. Extensive\nexperiments on seven benchmark datasets show our method outperforms\nstate-of-the-art baselines on unsupervised time series anomaly prediction\nproblems.\n","authors":["Kai Zhao","Zhihao Zhuang","Chenjuan Guo","Hao Miao","Yunyao Cheng","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.16888v2.pdf","comment":"revised"},{"id":"http://arxiv.org/abs/2402.19369v2","updated":"2025-03-11T14:42:57Z","published":"2024-02-29T17:16:20Z","title":"Structure Preserving Diffusion Models","summary":"  In recent years, diffusion models have become the leading approach for\ndistribution learning. This paper focuses on structure-preserving diffusion\nmodels (SPDM), a specific subset of diffusion processes tailored for\ndistributions with inherent structures, such as group symmetries. We complement\nexisting sufficient conditions for constructing SPDMs by proving complementary\nnecessary ones. Additionally, we propose a new framework that considers the\ngeometric structures affecting the diffusion process. Leveraging this\nframework, we design a structure-preserving bridge model that maintains\nalignment between the model's endpoint couplings. Empirical evaluations on\nequivariant diffusion models demonstrate their effectiveness in learning\nsymmetric distributions and modeling transitions between them. Experiments on\nreal-world medical images confirm that our models preserve equivariance while\nmaintaining high sample quality. We also showcase the practical utility of our\nframework by implementing an equivariant denoising diffusion bridge model,\nwhich achieves reliable equivariant image noise reduction and style transfer,\nirrespective of prior knowledge of image orientation.\n","authors":["Haoye Lu","Spencer Szabados","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2402.19369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10392v2","updated":"2025-03-11T14:42:27Z","published":"2025-02-14T18:59:59Z","title":"TSP3D: Text-guided Sparse Voxel Pruning for Efficient 3D Visual\n  Grounding","summary":"  In this paper, we propose an efficient multi-level convolution architecture\nfor 3D visual grounding. Conventional methods are difficult to meet the\nrequirements of real-time inference due to the two-stage or point-based\narchitecture. Inspired by the success of multi-level fully sparse convolutional\narchitecture in 3D object detection, we aim to build a new 3D visual grounding\nframework following this technical route. However, as in 3D visual grounding\ntask the 3D scene representation should be deeply interacted with text\nfeatures, sparse convolution-based architecture is inefficient for this\ninteraction due to the large amount of voxel features. To this end, we propose\ntext-guided pruning (TGP) and completion-based addition (CBA) to deeply fuse 3D\nscene representation and text features in an efficient way by gradual region\npruning and target completion. Specifically, TGP iteratively sparsifies the 3D\nscene representation and thus efficiently interacts the voxel features with\ntext features by cross-attention. To mitigate the affect of pruning on delicate\ngeometric information, CBA adaptively fixes the over-pruned region by voxel\ncompletion with negligible computational overhead. Compared with previous\nsingle-stage methods, our method achieves top inference speed and surpasses\nprevious fastest method by 100\\% FPS. Our method also achieves state-of-the-art\naccuracy even compared with two-stage methods, with $+1.13$ lead of Acc@0.5 on\nScanRefer, and $+2.6$ and $+3.2$ leads on NR3D and SR3D respectively. The code\nis available at\n\\href{https://github.com/GWxuan/TSP3D}{https://github.com/GWxuan/TSP3D}.\n","authors":["Wenxuan Guo","Xiuwei Xu","Ziwei Wang","Jianjiang Feng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2502.10392v2.pdf","comment":"Accepted at CVPR2025 with a top score"},{"id":"http://arxiv.org/abs/2503.08489v1","updated":"2025-03-11T14:42:17Z","published":"2025-03-11T14:42:17Z","title":"A Triple-Inertial Accelerated Alternating Optimization Method for Deep\n  Learning Training","summary":"  The stochastic gradient descent (SGD) algorithm has achieved remarkable\nsuccess in training deep learning models. However, it has several limitations,\nincluding susceptibility to vanishing gradients, sensitivity to input data, and\na lack of robust theoretical guarantees. In recent years, alternating\nminimization (AM) methods have emerged as a promising alternative for model\ntraining by employing gradient-free approaches to iteratively update model\nparameters. Despite their potential, these methods often exhibit slow\nconvergence rates. To address this challenge, we propose a novel\nTriple-Inertial Accelerated Alternating Minimization (TIAM) framework for\nneural network training. The TIAM approach incorporates a triple-inertial\nacceleration strategy with a specialized approximation method, facilitating\ntargeted acceleration of different terms in each sub-problem optimization. This\nintegration improves the efficiency of convergence, achieving superior\nperformance with fewer iterations. Additionally, we provide a convergence\nanalysis of the TIAM algorithm, including its global convergence properties and\nconvergence rate. Extensive experiments validate the effectiveness of the TIAM\nmethod, showing significant improvements in generalization capability and\ncomputational efficiency compared to existing approaches, particularly when\napplied to the rectified linear unit (ReLU) and its variants.\n","authors":["Chengcheng Yan","Jiawei Xu","Qingsong Wang","Zheng Peng"],"pdf_url":"https://arxiv.org/pdf/2503.08489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09376v2","updated":"2025-03-11T14:40:18Z","published":"2024-12-12T15:45:21Z","title":"A comprehensive interpretable machine learning framework for Mild\n  Cognitive Impairment and Alzheimer's disease diagnosis","summary":"  An interpretable machine learning (ML) framework is introduced to enhance the\ndiagnosis of Mild Cognitive Impairment (MCI) and Alzheimer's disease (AD) by\nensuring robustness of the ML models' interpretations. The dataset used\ncomprises volumetric measurements from brain MRI and genetic data from healthy\nindividuals and patients with MCI/AD, obtained through the Alzheimer's Disease\nNeuroimaging Initiative. The existing class imbalance is addressed by an\nensemble learning approach, while various attribution-based and\ncounterfactual-based interpretability methods are leveraged towards producing\ndiverse explanations related to the pathophysiology of MCI/AD. A unification\nmethod combining SHAP with counterfactual explanations assesses the\ninterpretability techniques' robustness. The best performing model yielded\n87.5% balanced accuracy and 90.8% F1-score. The attribution-based\ninterpretability methods highlighted significant volumetric and genetic\nfeatures related to MCI/AD risk. The unification method provided useful\ninsights regarding those features' necessity and sufficiency, further\nshowcasing their significance in MCI/AD diagnosis.\n","authors":["Maria Eleftheria Vlontzou","Maria Athanasiou","Kalliopi Dalakleidi","Ioanna Skampardoni","Christos Davatzikos","Konstantina Nikita"],"pdf_url":"https://arxiv.org/pdf/2412.09376v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08479v1","updated":"2025-03-11T14:33:55Z","published":"2025-03-11T14:33:55Z","title":"Soft Actor-Critic-based Control Barrier Adaptation for Robust Autonomous\n  Navigation in Unknown Environments","summary":"  Motion planning failures during autonomous navigation often occur when safety\nconstraints are either too conservative, leading to deadlocks, or too liberal,\nresulting in collisions. To improve robustness, a robot must dynamically adapt\nits safety constraints to ensure it reaches its goal while balancing safety and\nperformance measures. To this end, we propose a Soft Actor-Critic (SAC)-based\npolicy for adapting Control Barrier Function (CBF) constraint parameters at\nruntime, ensuring safe yet non-conservative motion. The proposed approach is\ndesigned for a general high-level motion planner, low-level controller, and\ntarget system model, and is trained in simulation only. Through extensive\nsimulations and physical experiments, we demonstrate that our framework\neffectively adapts CBF constraints, enabling the robot to reach its final goal\nwithout compromising safety.\n","authors":["Nicholas Mohammad","Nicola Bezzo"],"pdf_url":"https://arxiv.org/pdf/2503.08479v1.pdf","comment":"To Appear in 2025 IEEE/RSJ International Conference on Robotics and\n  Automation (ICRA), 2025"},{"id":"http://arxiv.org/abs/2410.08633v3","updated":"2025-03-11T14:26:41Z","published":"2024-10-11T08:55:17Z","title":"Transformers Provably Solve Parity Efficiently with Chain of Thought","summary":"  This work provides the first theoretical analysis of training transformers to\nsolve complex problems by recursively generating intermediate states, analogous\nto fine-tuning for chain-of-thought (CoT) reasoning. We consider training a\none-layer transformer to solve the fundamental $k$-parity problem, extending\nthe work on RNNs by Wies et al. (2023). We establish three key results: (1) any\nfinite-precision gradient-based algorithm, without intermediate supervision,\nrequires substantial iterations to solve parity with finite samples. (2) In\ncontrast, when intermediate parities are incorporated into the loss function,\nour model can learn parity in one gradient update when aided by \\emph{teacher\nforcing}, where ground-truth labels of the reasoning chain are provided at each\ngeneration step. (3) Even without teacher forcing, where the model must\ngenerate CoT chains end-to-end, parity can be learned efficiently if augmented\ndata is employed to internally verify the soundness of intermediate steps. Our\nfindings, supported by numerical experiments, show that task decomposition and\nstepwise reasoning naturally arise from optimizing transformers with CoT;\nmoreover, self-consistency checking can improve multi-step reasoning ability,\naligning with empirical studies of CoT.\n","authors":["Juno Kim","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2410.08633v3.pdf","comment":"ICLR 2025 Oral"},{"id":"http://arxiv.org/abs/2410.13514v2","updated":"2025-03-11T14:22:17Z","published":"2024-10-17T13:02:06Z","title":"GraphSCENE: On-Demand Critical Scenario Generation for Autonomous\n  Vehicles in Simulation","summary":"  Testing and validating Autonomous Vehicle (AV) performance in safety-critical\nand diverse scenarios is crucial before real-world deployment. However,\nmanually creating such scenarios in simulation remains a significant and\ntime-consuming challenge. This work introduces a novel method that generates\ndynamic temporal scene graphs corresponding to diverse traffic scenarios,\non-demand, tailored to user-defined preferences, such as AV actions, sets of\ndynamic agents, and criticality levels. A temporal Graph Neural Network (GNN)\nmodel learns to predict relationships between ego-vehicle, agents, and static\nstructures, guided by real-world spatiotemporal interaction patterns and\nconstrained by an ontology that restricts predictions to semantically valid\nlinks. Our model consistently outperforms the baselines in accurately\ngenerating links corresponding to the requested scenarios. We render the\npredicted scenarios in simulation to further demonstrate their effectiveness as\ntesting environments for AV agents.\n","authors":["Efimia Panagiotaki","Georgi Pramatarov","Lars Kunze","Daniele De Martini"],"pdf_url":"https://arxiv.org/pdf/2410.13514v2.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.08473v1","updated":"2025-03-11T14:19:52Z","published":"2025-03-11T14:19:52Z","title":"Data Driven Decision Making with Time Series and Spatio-temporal Data","summary":"  Time series data captures properties that change over time. Such data occurs\nwidely, ranging from the scientific and medical domains to the industrial and\nenvironmental domains. When the properties in time series exhibit spatial\nvariations, we often call the data spatio-temporal. As part of the continued\ndigitalization of processes throughout society, increasingly large volumes of\ntime series and spatio-temporal data are available. In this tutorial, we focus\non data-driven decision making with such data, e.g., enabling greener and more\nefficient transportation based on traffic time series forecasting. The tutorial\nadopts the holistic paradigm of \"data-governance-analytics-decision.\" We first\nintroduce the data foundation of time series and spatio-temporal data, which is\noften heterogeneous. Next, we discuss data governance methods that aim to\nimprove data quality. We then cover data analytics, focusing on five desired\ncharacteristics: automation, robustness, generality, explainability, and\nresource efficiency. We finally cover data-driven decision making strategies\nand briefly discuss promising research directions. We hope that the tutorial\nwill serve as a primary resource for researchers and practitioners who are\ninterested in value creation from time series and spatio-temporal data.\n","authors":["Bin Yang","Yuxuan Liang","Chenjuan Guo","Christian S. Jensen"],"pdf_url":"https://arxiv.org/pdf/2503.08473v1.pdf","comment":"This paper is accepted by ICDE 2025"},{"id":"http://arxiv.org/abs/2503.08467v1","updated":"2025-03-11T14:15:01Z","published":"2025-03-11T14:15:01Z","title":"Accelerating MoE Model Inference with Expert Sharding","summary":"  Mixture of experts (MoE) models achieve state-of-the-art results in language\nmodeling but suffer from inefficient hardware utilization due to imbalanced\ntoken routing and communication overhead. While prior work has focused on\noptimizing MoE training and decoder architectures, inference for encoder-based\nMoE models in a multi-GPU with expert parallelism setting remains\nunderexplored. We introduce MoEShard, an inference system that achieves perfect\nload balancing through tensor sharding of MoE experts. Unlike existing\napproaches that rely on heuristic capacity factors or drop tokens, MoEShard\nevenly distributes computation across GPUs and ensures full token retention,\nmaximizing utilization regardless of routing skewness. We achieve this through\na strategic row- and column-wise decomposition of expert matrices. This reduces\nidle time and avoids bottlenecks caused by imbalanced expert assignments.\nFurthermore, MoEShard minimizes kernel launches by fusing decomposed expert\ncomputations, significantly improving throughput. We evaluate MoEShard against\nDeepSpeed on encoder-based architectures, demonstrating speedups of up to\n6.4$\\times$ in time to first token (TTFT). Our results show that tensor\nsharding, when properly applied to experts, is a viable and effective strategy\nfor efficient MoE inference.\n","authors":["Oana Balmau","Anne-Marie Kermarrec","Rafael Pires","André Loureiro Espírito Santo","Martijn de Vos","Milos Vujasinovic"],"pdf_url":"https://arxiv.org/pdf/2503.08467v1.pdf","comment":"To appear in the proceedings of the 5th Workshop on Machine Learning\n  and Systems (EuroMLSys 25)"},{"id":"http://arxiv.org/abs/2503.08455v1","updated":"2025-03-11T14:04:29Z","published":"2025-03-11T14:04:29Z","title":"Controlling Latent Diffusion Using Latent CLIP","summary":"  Instead of performing text-conditioned denoising in the image domain, latent\ndiffusion models (LDMs) operate in latent space of a variational autoencoder\n(VAE), enabling more efficient processing at reduced computational costs.\nHowever, while the diffusion process has moved to the latent space, the\ncontrastive language-image pre-training (CLIP) models, as used in many image\nprocessing tasks, still operate in pixel space. Doing so requires costly\nVAE-decoding of latent images before they can be processed. In this paper, we\nintroduce Latent-CLIP, a CLIP model that operates directly in the latent space.\nWe train Latent-CLIP on 2.7B pairs of latent images and descriptive texts, and\nshow that it matches zero-shot classification performance of similarly sized\nCLIP models on both the ImageNet benchmark and a LDM-generated version of it,\ndemonstrating its effectiveness in assessing both real and generated content.\nFurthermore, we construct Latent-CLIP rewards for reward-based noise\noptimization (ReNO) and show that they match the performance of their CLIP\ncounterparts on GenEval and T2I-CompBench while cutting the cost of the total\npipeline by 21%. Finally, we use Latent-CLIP to guide generation away from\nharmful content, achieving strong performance on the inappropriate image\nprompts (I2P) benchmark and a custom evaluation, without ever requiring the\ncostly step of decoding intermediate images.\n","authors":["Jason Becker","Chris Wendler","Peter Baylies","Robert West","Christian Wressnegger"],"pdf_url":"https://arxiv.org/pdf/2503.08455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13728v3","updated":"2025-03-11T14:02:30Z","published":"2024-03-20T16:38:26Z","title":"M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via\n  Multiplier Induced Loss Landscape Scheduling","summary":"  A probabilistic graphical model is proposed, modeling the joint model\nparameter and multiplier evolution, with a hypervolume based likelihood,\npromoting multi-objective descent in structural risk minimization. We address\nmulti-objective model parameter optimization via a surrogate single objective\npenalty loss with time-varying multipliers, equivalent to online scheduling of\nloss landscape. The multi-objective descent goal is dispatched hierarchically\ninto a series of constraint optimization sub-problems with shrinking bounds\naccording to Pareto dominance. The bound serves as setpoint for the low-level\nmultiplier controller to schedule loss landscapes via output feedback of each\nloss term. Our method forms closed loop of model parameter dynamic, circumvents\nexcessive memory requirements and extra computational burden of existing\nmulti-objective deep learning methods, and is robust against controller\nhyperparameter variation, demonstrated on domain generalization tasks with\nmulti-dimensional regularization losses.\n","authors":["Xudong Sun","Nutan Chen","Alexej Gossmann","Matteo Wohlrapp","Yu Xing","Carla Feistner","Emilio Dorigatt","Felix Drost","Daniele Scarcella","Lisa Beer","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2403.13728v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10319v2","updated":"2025-03-11T14:02:04Z","published":"2024-12-13T17:59:52Z","title":"SCBench: A KV Cache-Centric Analysis of Long-Context Methods","summary":"  Long-context LLMs have enabled numerous downstream applications but also\nintroduced significant challenges related to computational and memory\nefficiency. To address these challenges, optimizations for long-context\ninference have been developed, centered around the KV cache. However, existing\nbenchmarks often evaluate in single-request, neglecting the full lifecycle of\nthe KV cache in real-world use. This oversight is particularly critical, as KV\ncache reuse has become widely adopted in LLMs inference frameworks, such as\nvLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,\nGoogle, and Anthropic. To address this gap, we introduce\nSCBench(SharedContextBench), a comprehensive benchmark for evaluating\nlong-context methods from a KV cachecentric perspective: 1) KV cache\ngeneration, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache\nloading. Specifically, SCBench uses test examples with shared context, ranging\n12 tasks with two shared context modes, covering four categories of\nlong-context capabilities: string retrieval, semantic retrieval, global\ninformation, and multi-task. With it, we provide an extensive KV cache-centric\nanalysis of eight categories long-context solutions, including Gated Linear\nRNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,\nKV cache dropping, quantization, retrieval, loading, and prompt compression.\nThe evaluation is conducted on 8 long-context LLMs. Our findings show that\nsub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding\nwith O(n) memory and sub-O(n^2) pre-filling computation perform robustly.\nDynamic sparsity yields more expressive KV caches than static patterns, and\nlayer-level sparsity in hybrid architectures reduces memory usage with strong\nperformance. Additionally, we identify attention distribution shift issues in\nlong-generation scenarios. https://aka.ms/SCBench.\n","authors":["Yucheng Li","Huiqiang Jiang","Qianhui Wu","Xufang Luo","Surin Ahn","Chengruidong Zhang","Amir H. Abdi","Dongsheng Li","Jianfeng Gao","Yuqing Yang","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2412.10319v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08451v1","updated":"2025-03-11T14:00:50Z","published":"2025-03-11T14:00:50Z","title":"MinGRU-Based Encoder for Turbo Autoencoder Frameworks","summary":"  Early neural channel coding approaches leveraged dense neural networks with\none-hot encodings to design adaptive encoder-decoder pairs, improving block\nerror rate (BLER) and automating the design process. However, these methods\nstruggled with scalability as the size of message sets and block lengths\nincreased. TurboAE addressed this challenge by focusing on bit-sequence inputs\nrather than symbol-level representations, transforming the scalability issue\nassociated with large message sets into a sequence modeling problem. While\nrecurrent neural networks (RNNs) were a natural fit for sequence processing,\ntheir reliance on sequential computations made them computationally expensive\nand inefficient for long sequences. As a result, TurboAE adopted convolutional\nnetwork blocks, which were faster to train and more scalable, but lacked the\nsequential modeling advantages of RNNs. Recent advances in efficient RNN\narchitectures, such as minGRU and minLSTM, and structured state space models\n(SSMs) like S4 and S6, overcome these limitations by significantly reducing\nmemory and computational overhead. These models enable scalable sequence\nprocessing, making RNNs competitive for long-sequence tasks. In this work, we\nrevisit RNNs for Turbo autoencoders by integrating the lightweight minGRU model\nwith a Mamba block from SSMs into a parallel Turbo autoencoder framework. Our\nresults demonstrate that this hybrid design matches the performance of\nconvolutional network-based Turbo autoencoder approaches for short sequences\nwhile significantly improving scalability and training efficiency for long\nblock lengths. This highlights the potential of efficient RNNs in advancing\nneural channel coding for long-sequence scenarios.\n","authors":["Rick Fritschek","Rafael F. Schaefer"],"pdf_url":"https://arxiv.org/pdf/2503.08451v1.pdf","comment":"6 pages, accepted at ICMLCN25"},{"id":"http://arxiv.org/abs/2411.10573v2","updated":"2025-03-11T13:41:59Z","published":"2024-11-15T20:46:58Z","title":"Hysteresis Activation Function for Efficient Inference","summary":"  The widely used ReLU is favored for its hardware efficiency, {as the\nimplementation at inference is a one bit sign case,} yet suffers from issues\nsuch as the ``dying ReLU'' problem, where during training, neurons fail to\nactivate and constantly remain at zero, as highlighted by Lu et al. Traditional\napproaches to mitigate this issue often introduce more complex and less\nhardware-friendly activation functions. In this work, we propose a Hysteresis\nRectified Linear Unit (HeLU), an efficient activation function designed to\naddress the ``dying ReLU'' problem with minimal complexity. Unlike traditional\nactivation functions with fixed thresholds for training and inference, HeLU\nemploys a variable threshold that refines the backpropagation. This refined\nmechanism allows simpler activation functions to achieve competitive\nperformance comparable to their more complex counterparts without introducing\nunnecessary complexity or requiring inductive biases. Empirical evaluations\ndemonstrate that HeLU enhances model generalization across diverse datasets,\noffering a promising solution for efficient and effective inference suitable\nfor a wide range of neural network architectures.\n","authors":["Moshe Kimhi","Idan Kashani","Avi Mendelson","Chaim Baskin"],"pdf_url":"https://arxiv.org/pdf/2411.10573v2.pdf","comment":"Accepted to 4th NeurIPS Efficient Natural Language and Speech\n  Processing Workshop (ENLSP-IV 2024)"},{"id":"http://arxiv.org/abs/2501.12900v2","updated":"2025-03-11T13:41:43Z","published":"2025-01-22T14:19:48Z","title":"Unified CNNs and transformers underlying learning mechanism reveals\n  multi-head attention modus vivendi","summary":"  Convolutional neural networks (CNNs) evaluate short-range correlations in\ninput images which progress along the layers, whereas vision transformer (ViT)\narchitectures evaluate long-range correlations, using repeated transformer\nencoders composed of fully connected layers. Both are designed to solve complex\nclassification tasks but from different perspectives. This study demonstrates\nthat CNNs and ViT architectures stem from a unified underlying learning\nmechanism, which quantitatively measures the single-nodal performance (SNP) of\neach node in feedforward (FF) and multi-head attention (MHA) sub-blocks. Each\nnode identifies small clusters of possible output labels, with additional noise\nrepresented as labels outside these clusters. These features are progressively\nsharpened along the transformer encoders, enhancing the signal-to-noise ratio.\nThis unified underlying learning mechanism leads to two main findings. First,\nit enables an efficient applied nodal diagonal connection (ANDC) pruning\ntechnique without affecting the accuracy. Second, based on the SNP, spontaneous\nsymmetry breaking occurs among the MHA heads, such that each head focuses its\nattention on a subset of labels through cooperation among its SNPs.\nConsequently, each head becomes an expert in recognizing its designated labels,\nrepresenting a quantitative MHA modus vivendi mechanism. This statistical\nmechanics inspired viewpoint enables to reveal macroscopic behavior of the\nentire network from the microscopic performance of each node. These results are\nbased on a compact convolutional transformer architecture trained on the\nCIFAR-100 and Flowers-102 datasets and call for their extension to other\narchitectures and applications, such as natural language processing.\n","authors":["Ella Koresh","Ronit D. Gross","Yuval Meir","Yarden Tzach","Tal Halevi","Ido Kanter"],"pdf_url":"https://arxiv.org/pdf/2501.12900v2.pdf","comment":"31 pages, 11 figures (two new figures)"},{"id":"http://arxiv.org/abs/2503.08427v1","updated":"2025-03-11T13:40:34Z","published":"2025-03-11T13:40:34Z","title":"Accelerated Distributed Optimization with Compression and Error Feedback","summary":"  Modern machine learning tasks often involve massive datasets and models,\nnecessitating distributed optimization algorithms with reduced communication\noverhead. Communication compression, where clients transmit compressed updates\nto a central server, has emerged as a key technique to mitigate communication\nbottlenecks. However, the theoretical understanding of stochastic distributed\noptimization with contractive compression remains limited, particularly in\nconjunction with Nesterov acceleration -- a cornerstone for achieving faster\nconvergence in optimization.\n  In this paper, we propose a novel algorithm, ADEF (Accelerated Distributed\nError Feedback), which integrates Nesterov acceleration, contractive\ncompression, error feedback, and gradient difference compression. We prove that\nADEF achieves the first accelerated convergence rate for stochastic distributed\noptimization with contractive compression in the general convex regime.\nNumerical experiments validate our theoretical findings and demonstrate the\npractical efficacy of ADEF in reducing communication costs while maintaining\nfast convergence.\n","authors":["Yuan Gao","Anton Rodomanov","Jeremy Rack","Sebastian U. Stich"],"pdf_url":"https://arxiv.org/pdf/2503.08427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08420v1","updated":"2025-03-11T13:31:09Z","published":"2025-03-11T13:31:09Z","title":"Generalizable and Explainable Deep Learning for Medical Image Computing:\n  An Overview","summary":"  Objective. This paper presents an overview of generalizable and explainable\nartificial intelligence (XAI) in deep learning (DL) for medical imaging, aimed\nat addressing the urgent need for transparency and explainability in clinical\napplications.\n  Methodology. We propose to use four CNNs in three medical datasets (brain\ntumor, skin cancer, and chest x-ray) for medical image classification tasks. In\naddition, we perform paired t-tests to show the significance of the differences\nobserved between different methods. Furthermore, we propose to combine ResNet50\nwith five common XAI techniques to obtain explainable results for model\nprediction, aiming at improving model transparency. We also involve a\nquantitative metric (confidence increase) to evaluate the usefulness of XAI\ntechniques.\n  Key findings. The experimental results indicate that ResNet50 can achieve\nfeasible accuracy and F1 score in all datasets (e.g., 86.31\\% accuracy in skin\ncancer). Furthermore, the findings show that while certain XAI methods, such as\nXgradCAM, effectively highlight relevant abnormal regions in medical images,\nothers, like EigenGradCAM, may perform less effectively in specific scenarios.\nIn addition, XgradCAM indicates higher confidence increase (e.g., 0.12 in\nglioma tumor) compared to GradCAM++ (0.09) and LayerCAM (0.08).\n  Implications. Based on the experimental results and recent advancements, we\noutline future research directions to enhance the robustness and\ngeneralizability of DL models in the field of biomedical imaging.\n","authors":["Ahmad Chaddad","Yan Hu","Yihang Wu","Binbin Wen","Reem Kateb"],"pdf_url":"https://arxiv.org/pdf/2503.08420v1.pdf","comment":"Published in Current Opinion in Biomedical Engineering"},{"id":"http://arxiv.org/abs/2503.08417v1","updated":"2025-03-11T13:28:59Z","published":"2025-03-11T13:28:59Z","title":"AnyMoLe: Any Character Motion In-betweening Leveraging Video Diffusion\n  Models","summary":"  Despite recent advancements in learning-based motion in-betweening, a key\nlimitation has been overlooked: the requirement for character-specific\ndatasets. In this work, we introduce AnyMoLe, a novel method that addresses\nthis limitation by leveraging video diffusion models to generate motion\nin-between frames for arbitrary characters without external data. Our approach\nemploys a two-stage frame generation process to enhance contextual\nunderstanding. Furthermore, to bridge the domain gap between real-world and\nrendered character animations, we introduce ICAdapt, a fine-tuning technique\nfor video diffusion models. Additionally, we propose a ``motion-video\nmimicking'' optimization technique, enabling seamless motion generation for\ncharacters with arbitrary joint structures using 2D and 3D-aware features.\nAnyMoLe significantly reduces data dependency while generating smooth and\nrealistic transitions, making it applicable to a wide range of motion\nin-betweening tasks.\n","authors":["Kwan Yun","Seokhyeon Hong","Chaelin Kim","Junyong Noh"],"pdf_url":"https://arxiv.org/pdf/2503.08417v1.pdf","comment":"11 pages, 10 figures, CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08410v1","updated":"2025-03-11T13:18:03Z","published":"2025-03-11T13:18:03Z","title":"A Deep-Learning Iterative Stacked Approach for Prediction of Reactive\n  Dissolution in Porous Media","summary":"  Simulating reactive dissolution of solid minerals in porous media has many\nsubsurface applications, including carbon capture and storage (CCS), geothermal\nsystems and oil & gas recovery. As traditional direct numerical simulators are\ncomputationally expensive, it is of paramount importance to develop faster and\nmore efficient alternatives. Deep-learning-based solutions, most of them built\nupon convolutional neural networks (CNNs), have been recently designed to\ntackle this problem. However, these solutions were limited to approximating one\nfield over the domain (e.g. velocity field). In this manuscript, we present a\nnovel deep learning approach that incorporates both temporal and spatial\ninformation to predict the future states of the dissolution process at a fixed\ntime-step horizon, given a sequence of input states. The overall performance,\nin terms of speed and prediction accuracy, is demonstrated on a numerical\nsimulation dataset, comparing its prediction results against state-of-the-art\napproaches, also achieving a speedup around $10^4$ over traditional numerical\nsimulators.\n","authors":["Marcos Cirne","Hannah Menke","Alhasan Abdellatif","Julien Maes","Florian Doster","Ahmed H. Elsheikh"],"pdf_url":"https://arxiv.org/pdf/2503.08410v1.pdf","comment":"24 pages, 16 figures"},{"id":"http://arxiv.org/abs/2503.08408v1","updated":"2025-03-11T13:11:18Z","published":"2025-03-11T13:11:18Z","title":"Uncertainty Quantification for Multi-fidelity Simulations","summary":"  The work focuses on gathering high-fidelity and low-fidelity numerical\nsimulations data using Nektar++ (Solver based on Applied Mathematics) and XFOIL\nrespectively. The utilization of the higher polynomial distribution in\ncalculating the Coefficient of lift and drag has demonstrated superior accuracy\nand precision. Further, Co-kriging Data fusion and Adaptive sampling technique\nhas been used to obtain the precise data predictions for the lift and drag\nwithin the confined domain without conducting the costly simulations on HPC\nclusters. This creates a methodology to quantifying uncertainty in\ncomputational fluid dynamics by minimizing the required number of samples. To\nminimize the reliability on high-fidelity numerical simulations in Uncertainty\nQuantification, a multi-fidelity strategy has been adopted. The effectiveness\nof the multi-fidelity deep neural network model has been validated through the\napproximation of benchmark functions across 1-, 32-, and 100-dimensional,\nencompassing both linear and nonlinear correlations. The surrogate modelling\nresults showed that multi-fidelity deep neural network model has shown\nexcellent approximation capabilities for the test functions and multi-fidelity\ndeep neural network method has outperformed Co-kriging in effectiveness. In\naddition to that, multi-fidelity deep neural network model is utilized for the\nsimulation of aleatory uncertainty propagation in 1-, 32-, and 100 dimensional\nfunction test, considering both uniform and Gaussian distributions for input\nuncertainties. The results have shown that multi-fidelity deep neural network\nmodel has efficiently predicted the probability density distributions of\nquantities of interest as well as the statistical moments with precision and\naccuracy. The Co-Kriging model has exhibited limitations when addressing\n32-Dimension problems due to the limitation of memory capacity for storage and\nmanipulation.\n","authors":["Swapnil Kumar"],"pdf_url":"https://arxiv.org/pdf/2503.08408v1.pdf","comment":"Imperial College London, Master Thesis"},{"id":"http://arxiv.org/abs/2503.08394v1","updated":"2025-03-11T13:00:56Z","published":"2025-03-11T13:00:56Z","title":"($\\boldsymbolθ_l, \\boldsymbolθ_u$)-Parametric Multi-Task\n  Optimization: Joint Search in Solution and Infinite Task Spaces","summary":"  Multi-task optimization is typically characterized by a fixed and finite set\nof optimization tasks. The present paper relaxes this condition by considering\na non-fixed and potentially infinite set of optimization tasks defined in a\nparameterized, continuous and bounded task space. We refer to this unique\nproblem setting as parametric multi-task optimization (PMTO). Assuming the\nbounds of the task parameters to be ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$), a novel ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$)-PMTO algorithm is crafted to enable joint search over\ntasks and their solutions. This joint search is supported by two approximation\nmodels: (1) for mapping solutions to the objective spaces of all tasks, which\nprovably accelerates convergence by acting as a conduit for inter-task\nknowledge transfers, and (2) for probabilistically mapping tasks to the\nsolution space, which facilitates evolutionary exploration of under-explored\nregions of the task space. At the end of a full ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$)-PMTO run, the acquired models enable rapid\nidentification of optimized solutions for any task lying within the specified\nbounds. This outcome is validated on both synthetic test problems and practical\ncase studies, with the significant real-world applicability of PMTO shown\ntowards fast reconfiguration of robot controllers under changing task\nconditions. The potential of PMTO to vastly speedup the search for solutions to\nminimax optimization problems is also demonstrated through an example in robust\nengineering design.\n","authors":["Tingyang Wei","Jiao Liu","Abhishek Gupta","Puay Siew Tan","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2503.08394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12049v2","updated":"2025-03-11T12:56:44Z","published":"2024-12-16T18:18:47Z","title":"Bilevel Learning with Inexact Stochastic Gradients","summary":"  Bilevel learning has gained prominence in machine learning, inverse problems,\nand imaging applications, including hyperparameter optimization, learning\ndata-adaptive regularizers, and optimizing forward operators. The large-scale\nnature of these problems has led to the development of inexact and\ncomputationally efficient methods. Existing adaptive methods predominantly rely\non deterministic formulations, while stochastic approaches often adopt a\ndoubly-stochastic framework with impractical variance assumptions, enforces a\nfixed number of lower-level iterations, and requires extensive tuning. In this\nwork, we focus on bilevel learning with strongly convex lower-level problems\nand a nonconvex sum-of-functions in the upper-level. Stochasticity arises from\ndata sampling in the upper-level which leads to inexact stochastic\nhypergradients. We establish their connection to state-of-the-art stochastic\noptimization theory for nonconvex objectives. Furthermore, we prove the\nconvergence of inexact stochastic bilevel optimization under mild assumptions.\nOur empirical results highlight significant speed-ups and improved\ngeneralization in imaging tasks such as image denoising and deblurring in\ncomparison with adaptive deterministic bilevel methods.\n","authors":["Mohammad Sadegh Salehi","Subhadip Mukherjee","Lindon Roberts","Matthias J. Ehrhardt"],"pdf_url":"https://arxiv.org/pdf/2412.12049v2.pdf","comment":"Accepted to the 10th International Conference on Scale Space and\n  Variational Methods in Computer Vision (SSVM 2025)"},{"id":"http://arxiv.org/abs/2412.07205v3","updated":"2025-03-11T12:55:57Z","published":"2024-12-10T05:50:50Z","title":"CrackESS: A Self-Prompting Crack Segmentation System for Edge Devices","summary":"  Structural Health Monitoring (SHM) is a sustainable and essential approach\nfor infrastructure maintenance, enabling the early detection of structural\ndefects. Leveraging computer vision (CV) methods for automated infrastructure\nmonitoring can significantly enhance monitoring efficiency and precision.\nHowever, these methods often face challenges in efficiency and accuracy,\nparticularly in complex environments. Recent CNN-based and SAM-based approaches\nhave demonstrated excellent performance in crack segmentation, but their high\ncomputational demands limit their applicability on edge devices. This paper\nintroduces CrackESS, a novel system for detecting and segmenting concrete\ncracks. The approach first utilizes a YOLOv8 model for self-prompting and a\nLoRA-based fine-tuned SAM model for crack segmentation, followed by refining\nthe segmentation masks through the proposed Crack Mask Refinement Module\n(CMRM). We conduct experiments on three datasets(Khanhha's dataset, Crack500,\nCrackCR) and validate CrackESS on a climbing robot system to demonstrate the\nadvantage and effectiveness of our approach.\n","authors":["Yingchu Wang","Ji He","Shijie Yu"],"pdf_url":"https://arxiv.org/pdf/2412.07205v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08388v1","updated":"2025-03-11T12:53:24Z","published":"2025-03-11T12:53:24Z","title":"V-Max: Making RL practical for Autonomous Driving","summary":"  Learning-based decision-making has the potential to enable generalizable\nAutonomous Driving (AD) policies, reducing the engineering overhead of\nrule-based approaches. Imitation Learning (IL) remains the dominant paradigm,\nbenefiting from large-scale human demonstration datasets, but it suffers from\ninherent limitations such as distribution shift and imitation gaps.\nReinforcement Learning (RL) presents a promising alternative, yet its adoption\nin AD remains limited due to the lack of standardized and efficient research\nframeworks. To this end, we introduce V-Max, an open research framework\nproviding all the necessary tools to make RL practical for AD. V-Max is built\non Waymax, a hardware-accelerated AD simulator designed for large-scale\nexperimentation. We extend it using ScenarioNet's approach, enabling the fast\nsimulation of diverse AD datasets. V-Max integrates a set of observation and\nreward functions, transformer-based encoders, and training pipelines.\nAdditionally, it includes adversarial evaluation settings and an extensive set\nof evaluation metrics. Through a large-scale benchmark, we analyze how network\narchitectures, observation functions, training data, and reward shaping impact\nRL performance.\n","authors":["Valentin Charraut","Thomas Tournaire","Waël Doulazmi","Thibault Buhet"],"pdf_url":"https://arxiv.org/pdf/2503.08388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16450v3","updated":"2025-03-11T12:52:28Z","published":"2024-05-26T06:33:48Z","title":"Synthesizing Programmatic Reinforcement Learning Policies with Large\n  Language Model Guided Search","summary":"  Programmatic reinforcement learning (PRL) has been explored for representing\npolicies through programs as a means to achieve interpretability and\ngeneralization. Despite promising outcomes, current state-of-the-art PRL\nmethods are hindered by sample inefficiency, necessitating tens of millions of\nprogram-environment interactions. To tackle this challenge, we introduce a\nnovel LLM-guided search framework (LLM-GS). Our key insight is to leverage the\nprogramming expertise and common sense reasoning of LLMs to enhance the\nefficiency of assumption-free, random-guessing search methods. We address the\nchallenge of LLMs' inability to generate precise and grammatically correct\nprograms in domain-specific languages (DSLs) by proposing a Pythonic-DSL\nstrategy - an LLM is instructed to initially generate Python codes and then\nconvert them into DSL programs. To further optimize the LLM-generated programs,\nwe develop a search algorithm named Scheduled Hill Climbing, designed to\nefficiently explore the programmatic search space to improve the programs\nconsistently. Experimental results in the Karel domain demonstrate our LLM-GS\nframework's superior effectiveness and efficiency. Extensive ablation studies\nfurther verify the critical role of our Pythonic-DSL strategy and Scheduled\nHill Climbing algorithm. Moreover, we conduct experiments with two novel tasks,\nshowing that LLM-GS enables users without programming skills and knowledge of\nthe domain or DSL to describe the tasks in natural language to obtain\nperformant programs.\n","authors":["Max Liu","Chan-Hung Yu","Wei-Hsu Lee","Cheng-Wei Hung","Yen-Chun Chen","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16450v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07216v2","updated":"2025-03-11T12:49:15Z","published":"2025-03-10T11:55:50Z","title":"FedRand: Enhancing Privacy in Federated Learning with Randomized LoRA\n  Subparameter Updates","summary":"  Federated Learning (FL) is a widely used framework for training models in a\ndecentralized manner, ensuring that the central server does not have direct\naccess to data from local clients. However, this approach may still fail to\nfully preserve data privacy, as models from local clients are exposed to the\ncentral server during the aggregation process. This issue becomes even more\ncritical when training vision-language models (VLMs) with FL, as VLMs can\neasily memorize training data instances, making them vulnerable to membership\ninference attacks (MIAs). To address this challenge, we propose the FedRand\nframework, which avoids disclosing the full set of client parameters. In this\nframework, each client randomly selects subparameters of Low-Rank Adaptation\n(LoRA) from the server and keeps the remaining counterparts of the LoRA weights\nas private parameters. After training both parameters on the client's private\ndataset, only the non-private client parameters are sent back to the server for\naggregation. This approach mitigates the risk of exposing client-side VLM\nparameters, thereby enhancing data privacy. We empirically validate that\nFedRand improves robustness against MIAs compared to relevant baselines while\nachieving accuracy comparable to methods that communicate full LoRA parameters\nacross several benchmark datasets.\n","authors":["Sangwoo Park","Seanie Lee","Byungjoo Kim","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.07216v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.08375v1","updated":"2025-03-11T12:32:06Z","published":"2025-03-11T12:32:06Z","title":"Gait in Eight: Efficient On-Robot Learning for Omnidirectional Quadruped\n  Locomotion","summary":"  On-robot Reinforcement Learning is a promising approach to train\nembodiment-aware policies for legged robots. However, the computational\nconstraints of real-time learning on robots pose a significant challenge. We\npresent a framework for efficiently learning quadruped locomotion in just 8\nminutes of raw real-time training utilizing the sample efficiency and minimal\ncomputational overhead of the new off-policy algorithm CrossQ. We investigate\ntwo control architectures: Predicting joint target positions for agile,\nhigh-speed locomotion and Central Pattern Generators for stable, natural gaits.\nWhile prior work focused on learning simple forward gaits, our framework\nextends on-robot learning to omnidirectional locomotion. We demonstrate the\nrobustness of our approach in different indoor and outdoor environments.\n","authors":["Nico Bohlinger","Jonathan Kinzel","Daniel Palenicek","Lukasz Antczak","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2503.08375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05336v2","updated":"2025-03-11T12:31:22Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Deb Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v2.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2503.08371v1","updated":"2025-03-11T12:27:54Z","published":"2025-03-11T12:27:54Z","title":"Density Ratio-based Proxy Causal Learning Without Density Ratios","summary":"  We address the setting of Proxy Causal Learning (PCL), which has the goal of\nestimating causal effects from observed data in the presence of hidden\nconfounding. Proxy methods accomplish this task using two proxy variables\nrelated to the latent confounder: a treatment proxy (related to the treatment)\nand an outcome proxy (related to the outcome). Two approaches have been\nproposed to perform causal effect estimation given proxy variables; however\nonly one of these has found mainstream acceptance, since the other was\nunderstood to require density ratio estimation - a challenging task in high\ndimensions. In the present work, we propose a practical and effective\nimplementation of the second approach, which bypasses explicit density ratio\nestimation and is suitable for continuous and high-dimensional treatments. We\nemploy kernel ridge regression to derive estimators, resulting in simple\nclosed-form solutions for dose-response and conditional dose-response curves,\nalong with consistency guarantees. Our methods empirically demonstrate superior\nor comparable performance to existing frameworks on synthetic and real-world\ndatasets.\n","authors":["Bariscan Bozkurt","Ben Deaner","Dimitri Meunier","Liyuan Xu","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2503.08371v1.pdf","comment":"AISTATS 2025 accepted, 81 pages"},{"id":"http://arxiv.org/abs/2408.16543v2","updated":"2025-03-11T12:23:23Z","published":"2024-08-29T14:01:30Z","title":"Statistical and Geometrical properties of regularized Kernel\n  Kullback-Leibler divergence","summary":"  In this paper, we study the statistical and geometrical properties of the\nKullback-Leibler divergence with kernel covariance operators (KKL) introduced\nby Bach [2022]. Unlike the classical Kullback-Leibler (KL) divergence that\ninvolves density ratios, the KKL compares probability distributions through\ncovariance operators (embeddings) in a reproducible kernel Hilbert space\n(RKHS), and compute the Kullback-Leibler quantum divergence. This novel\ndivergence hence shares parallel but different aspects with both the standard\nKullback-Leibler between probability distributions and kernel embeddings\nmetrics such as the maximum mean discrepancy. A limitation faced with the\noriginal KKL divergence is its inability to be defined for distributions with\ndisjoint supports. To solve this problem, we propose in this paper a\nregularised variant that guarantees that the divergence is well defined for all\ndistributions. We derive bounds that quantify the deviation of the regularised\nKKL to the original one, as well as finite-sample bounds. In addition, we\nprovide a closed-form expression for the regularised KKL, specifically\napplicable when the distributions consist of finite sets of points, which makes\nit implementable. Furthermore, we derive a Wasserstein gradient descent scheme\nof the KKL divergence in the case of discrete distributions, and study\nempirically its properties to transport a set of points to a target\ndistribution.\n","authors":["Clémentine Chazal","Anna Korba","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2408.16543v2.pdf","comment":"Paper accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.17932v3","updated":"2025-03-11T12:12:13Z","published":"2024-09-26T15:08:52Z","title":"Sample Compression Unleashed: New Generalization Bounds for Real Valued\n  Losses","summary":"  The sample compression theory provides generalization guarantees for\npredictors that can be fully defined using a subset of the training dataset and\na (short) message string, generally defined as a binary sequence. Previous\nworks provided generalization bounds for the zero-one loss, which is\nrestrictive notably when applied to deep learning approaches. In this paper, we\npresent a general framework for deriving new sample compression bounds that\nhold for real-valued unbounded losses. Using the Pick-To-Learn (P2L)\nmeta-algorithm, which transforms the training method of any machine-learning\npredictor to yield sample-compressed predictors, we empirically demonstrate the\ntightness of the bounds and their versatility by evaluating them on random\nforests and multiple types of neural networks.\n","authors":["Mathieu Bazinet","Valentina Zantedeschi","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2409.17932v3.pdf","comment":"Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume\n  258"},{"id":"http://arxiv.org/abs/2503.08343v1","updated":"2025-03-11T11:53:21Z","published":"2025-03-11T11:53:21Z","title":"Flexible and Efficient Probabilistic PDE Solvers through Gaussian Markov\n  Random Fields","summary":"  Mechanistic knowledge about the physical world is virtually always expressed\nvia partial differential equations (PDEs). Recently, there has been a surge of\ninterest in probabilistic PDE solvers -- Bayesian statistical models mostly\nbased on Gaussian process (GP) priors which seamlessly combine empirical\nmeasurements and mechanistic knowledge. As such, they quantify uncertainties\narising from e.g. noisy or missing data, unknown PDE parameters or\ndiscretization error by design. Prior work has established connections to\nclassical PDE solvers and provided solid theoretical guarantees. However,\nscaling such methods to large-scale problems remains a fundamental challenge\nprimarily due to dense covariance matrices. Our approach addresses the\nscalability issues by leveraging the Markov property of many commonly used GP\npriors. It has been shown that such priors are solutions to stochastic PDEs\n(SPDEs) which when discretized allow for highly efficient GP regression through\nsparse linear algebra. In this work, we show how to leverage this prior class\nto make probabilistic PDE solvers practical, even for large-scale nonlinear\nPDEs, through greatly accelerated inference mechanisms. Additionally, our\napproach also allows for flexible and physically meaningful priors beyond what\ncan be modeled with covariance functions. Experiments confirm substantial\nspeedups and accelerated convergence of our physics-informed priors in\nnonlinear settings.\n","authors":["Tim Weiland","Marvin Pförtner","Philipp Hennig"],"pdf_url":"https://arxiv.org/pdf/2503.08343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08328v1","updated":"2025-03-11T11:40:14Z","published":"2025-03-11T11:40:14Z","title":"MFRS: A Multi-Frequency Reference Series Approach to Scalable and\n  Accurate Time-Series Forecasting","summary":"  Multivariate time-series forecasting holds immense value across diverse\napplications, requiring methods to effectively capture complex temporal and\ninter-variable dynamics. A key challenge lies in uncovering the intrinsic\npatterns that govern predictability, beyond conventional designs, focusing on\nnetwork architectures to explore latent relationships or temporal dependencies.\nInspired by signal decomposition, this paper posits that time series\npredictability is derived from periodic characteristics at different\nfrequencies. Consequently, we propose a novel time series forecasting method\nbased on multi-frequency reference series correlation analysis. Through\nspectral analysis on long-term training data, we identify dominant spectral\ncomponents and their harmonics to design base-pattern reference series. Unlike\nsignal decomposition, which represents the original series as a linear\ncombination of basis signals, our method uses a transformer model to compute\ncross-attention between the original series and reference series, capturing\nessential features for forecasting. Experiments on major open and synthetic\ndatasets show state-of-the-art performance. Furthermore, by focusing on\nattention with a small number of reference series rather than pairwise variable\nattention, our method ensures scalability and broad applicability. The source\ncode is available at: https://github.com/yuliang555/MFRS\n","authors":["Liang Yu","Lai Tu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2503.08328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08325v1","updated":"2025-03-11T11:37:43Z","published":"2025-03-11T11:37:43Z","title":"Prototype-based Heterogeneous Federated Learning for Blade Icing\n  Detection in Wind Turbines with Class Imbalanced Data","summary":"  Wind farms, typically in high-latitude regions, face a high risk of blade\nicing. Traditional centralized training methods raise serious privacy concerns.\nTo enhance data privacy in detecting wind turbine blade icing, traditional\nfederated learning (FL) is employed. However, data heterogeneity, resulting\nfrom collections across wind farms in varying environmental conditions, impacts\nthe model's optimization capabilities. Moreover, imbalances in wind turbine\ndata lead to models that tend to favor recognizing majority classes, thus\nneglecting critical icing anomalies. To tackle these challenges, we propose a\nfederated prototype learning model for class-imbalanced data in heterogeneous\nenvironments to detect wind turbine blade icing. We also propose a contrastive\nsupervised loss function to address the class imbalance problem. Experiments on\nreal data from 20 turbines across two wind farms show our method outperforms\nfive FL models and five class imbalance methods, with an average improvement of\n19.64\\% in \\( mF_{\\beta} \\) and 5.73\\% in \\( m \\)BA compared to the second-best\nmethod, BiFL.\n","authors":["Lele Qi","Mengna Liu","Xu Cheng","Fan Shi","Xiufeng Liu","Shengyong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02651v2","updated":"2025-03-11T11:34:10Z","published":"2024-10-03T16:36:05Z","title":"CAX: Cellular Automata Accelerated in JAX","summary":"  Cellular automata have become a cornerstone for investigating emergence and\nself-organization across diverse scientific disciplines. However, the absence\nof a hardware-accelerated cellular automata library limits the exploration of\nnew research directions, hinders collaboration, and impedes reproducibility. In\nthis work, we introduce CAX (Cellular Automata Accelerated in JAX), a\nhigh-performance and flexible open-source library designed to accelerate\ncellular automata research. CAX delivers cutting-edge performance through\nhardware acceleration while maintaining flexibility through its modular\narchitecture, intuitive API, and support for both discrete and continuous\ncellular automata in arbitrary dimensions. We demonstrate CAX's performance and\nflexibility through a wide range of benchmarks and applications. From classic\nmodels like elementary cellular automata and Conway's Game of Life to advanced\napplications such as growing neural cellular automata and self-classifying\nMNIST digits, CAX speeds up simulations up to 2,000 times faster. Furthermore,\nwe demonstrate CAX's potential to accelerate research by presenting a\ncollection of three novel cellular automata experiments, each implemented in\njust a few lines of code thanks to the library's modular architecture. Notably,\nwe show that a simple one-dimensional cellular automaton can outperform GPT-4\non the 1D-ARC challenge.\n","authors":["Maxence Faldor","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2410.02651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08322v1","updated":"2025-03-11T11:34:06Z","published":"2025-03-11T11:34:06Z","title":"Evaluating Interpretable Reinforcement Learning by Distilling Policies\n  into Programs","summary":"  There exist applications of reinforcement learning like medicine where\npolicies need to be ''interpretable'' by humans. User studies have shown that\nsome policy classes might be more interpretable than others. However, it is\ncostly to conduct human studies of policy interpretability. Furthermore, there\nis no clear definition of policy interpretabiliy, i.e., no clear metrics for\ninterpretability and thus claims depend on the chosen definition. We tackle the\nproblem of empirically evaluating policies interpretability without humans.\nDespite this lack of clear definition, researchers agree on the notions of\n''simulatability'': policy interpretability should relate to how humans\nunderstand policy actions given states. To advance research in interpretable\nreinforcement learning, we contribute a new methodology to evaluate policy\ninterpretability. This new methodology relies on proxies for simulatability\nthat we use to conduct a large-scale empirical evaluation of policy\ninterpretability. We use imitation learning to compute baseline policies by\ndistilling expert neural networks into small programs. We then show that using\nour methodology to evaluate the baselines interpretability leads to similar\nconclusions as user studies. We show that increasing interpretability does not\nnecessarily reduce performances and can sometimes increase them. We also show\nthat there is no policy class that better trades off interpretability and\nperformance across tasks making it necessary for researcher to have\nmethodologies for comparing policies interpretability.\n","authors":["Hector Kohler","Quentin Delfosse","Waris Radji","Riad Akrour","Philippe Preux"],"pdf_url":"https://arxiv.org/pdf/2503.08322v1.pdf","comment":"12 pages of main text, under review"},{"id":"http://arxiv.org/abs/2503.06150v2","updated":"2025-03-11T11:28:18Z","published":"2025-03-08T10:21:21Z","title":"Do Fairness Interventions Come at the Cost of Privacy: Evaluations for\n  Binary Classifiers","summary":"  While in-processing fairness approaches show promise in mitigating biased\npredictions, their potential impact on privacy leakage remains under-explored.\nWe aim to address this gap by assessing the privacy risks of fairness-enhanced\nbinary classifiers via membership inference attacks (MIAs) and attribute\ninference attacks (AIAs). Surprisingly, our results reveal that enhancing\nfairness does not necessarily lead to privacy compromises. For example, these\nfairness interventions exhibit increased resilience against MIAs and AIAs. This\nis because fairness interventions tend to remove sensitive information among\nextracted features and reduce confidence scores for the majority of training\ndata for fairer predictions. However, during the evaluations, we uncover a\npotential threat mechanism that exploits prediction discrepancies between fair\nand biased models, leading to advanced attack results for both MIAs and AIAs.\nThis mechanism reveals potent vulnerabilities of fair models and poses\nsignificant privacy risks of current fairness methods. Extensive experiments\nacross multiple datasets, attack methods, and representative fairness\napproaches confirm our findings and demonstrate the efficacy of the uncovered\nmechanism. Our study exposes the under-explored privacy threats in fairness\nstudies, advocating for thorough evaluations of potential security\nvulnerabilities before model deployments.\n","authors":["Huan Tian","Guangsheng Zhang","Bo Liu","Tianqing Zhu","Ming Ding","Wanlei Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.06150v2.pdf","comment":"Accepted to IEEE Transactions on Dependable and Secure Computing\n  (TDSC)"},{"id":"http://arxiv.org/abs/2408.08761v5","updated":"2025-03-11T11:27:09Z","published":"2024-08-16T14:04:40Z","title":"Mitigating Information Loss in Tree-Based Reinforcement Learning via\n  Direct Optimization","summary":"  Reinforcement learning (RL) has seen significant success across various\ndomains, but its adoption is often limited by the black-box nature of neural\nnetwork policies, making them difficult to interpret. In contrast, symbolic\npolicies allow representing decision-making strategies in a compact and\ninterpretable way. However, learning symbolic policies directly within\non-policy methods remains challenging. In this paper, we introduce SYMPOL, a\nnovel method for SYMbolic tree-based on-POLicy RL. SYMPOL employs a tree-based\nmodel integrated with a policy gradient method, enabling the agent to learn and\nadapt its actions while maintaining a high level of interpretability. We\nevaluate SYMPOL on a set of benchmark RL tasks, demonstrating its superiority\nover alternative tree-based RL approaches in terms of performance and\ninterpretability. Unlike existing methods, it enables gradient-based,\nend-to-end learning of interpretable, axis-aligned decision trees within\nstandard on-policy RL algorithms. Therefore, SYMPOL can become the foundation\nfor a new class of interpretable RL based on decision trees. Our implementation\nis available under: https://github.com/s-marton/sympol\n","authors":["Sascha Marton","Tim Grams","Florian Vogt","Stefan Lüdtke","Christian Bartelt","Heiner Stuckenschmidt"],"pdf_url":"https://arxiv.org/pdf/2408.08761v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01423v2","updated":"2025-03-11T11:25:21Z","published":"2024-06-03T15:24:15Z","title":"Value Improved Actor Critic Algorithms","summary":"  To learn approximately optimal acting policies for decision problems, modern\nActor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the\nacting policy and greedification operators to iteratively improve it. The\nreliance on DNNs suggests an improvement that is gradient based, which is per\nstep much less greedy than the improvement possible by greedier operators such\nas the greedy update used by Q-learning algorithms. On the other hand, slow and\nsteady changes to the policy can also be beneficial for the stability of the\nlearning process, resulting in a tradeoff between greedification and stability.\nTo address this tradeoff, we propose to extend the standard framework of actor\ncritic algorithms with value-improvement: a second greedification operator\napplied only when updating the policy's value estimate. In this framework the\nagent can evaluate non-parameterized policies and perform much greedier updates\nwhile maintaining the steady gradient-based improvement to the parameterized\nacting policy. We prove that this approach converges in the popular analysis\nscheme of Generalized Policy Iteration in the finite-horizon domain.\nEmpirically, incorporating value-improvement into the popular off-policy\nactor-critic algorithms TD3 and SAC significantly improves or matches\nperformance over their respective baselines, across different environments from\nthe DeepMind continuous control domain, with negligible compute and\nimplementation cost.\n","authors":["Yaniv Oren","Moritz A. Zanger","Pascal R. van der Vaart","Mustafa Mert Celikok","Matthijs T. J. Spaan","Wendelin Bohmer"],"pdf_url":"https://arxiv.org/pdf/2406.01423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02189v2","updated":"2025-03-11T11:22:17Z","published":"2024-10-03T04:07:51Z","title":"Agent-Oriented Planning in Multi-Agent Systems","summary":"  Through the collaboration of multiple LLM-empowered agents possessing diverse\nexpertise and tools, multi-agent systems achieve impressive progress in solving\nreal-world problems. Given the user queries, the meta-agents, serving as the\nbrain within multi-agent systems, are required to decompose the queries into\nmultiple sub-tasks that can be allocated to suitable agents capable of solving\nthem, so-called agent-oriented planning. In this study, we identify three\ncritical design principles of agent-oriented planning, including solvability,\ncompleteness, and non-redundancy, to ensure that each sub-task can be\neffectively resolved, resulting in satisfactory responses to user queries.\nThese principles further inspire us to propose AOP, a novel framework for\nagent-oriented planning in multi-agent systems, leveraging a fast task\ndecomposition and allocation process followed by an effective and efficient\nevaluation via a reward model. According to the evaluation results, the\nmeta-agent is also responsible for promptly making necessary adjustments to\nsub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to\nfurther enhance the effectiveness and robustness of such a problem-solving\nprocess. Extensive experiments demonstrate the advancement of AOP in solving\nreal-world problems compared to both single-agent systems and existing planning\nstrategies for multi-agent systems. The source code is available at\nhttps://github.com/lalaliat/Agent-Oriented-Planning\n","authors":["Ao Li","Yuexiang Xie","Songze Li","Fugee Tsung","Bolin Ding","Yaliang Li"],"pdf_url":"https://arxiv.org/pdf/2410.02189v2.pdf","comment":"Accepted by ICLR'2025"},{"id":"http://arxiv.org/abs/2503.08311v1","updated":"2025-03-11T11:21:35Z","published":"2025-03-11T11:21:35Z","title":"Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM\n  Inference","summary":"  Large language models have been widely adopted across different tasks, but\ntheir auto-regressive generation nature often leads to inefficient resource\nutilization during inference. While batching is commonly used to increase\nthroughput, performance gains plateau beyond a certain batch size, especially\nwith smaller models, a phenomenon that existing literature typically explains\nas a shift to the compute-bound regime. In this paper, through an in-depth\nGPU-level analysis, we reveal that large-batch inference remains memory-bound,\nwith most GPU compute capabilities underutilized due to DRAM bandwidth\nsaturation as the primary bottleneck. To address this, we propose a Batching\nConfiguration Advisor (BCA) that optimizes memory allocation, reducing GPU\nmemory requirements with minimal impact on throughput. The freed memory and\nunderutilized GPU compute capabilities can then be leveraged by concurrent\nworkloads. Specifically, we use model replication to improve serving throughput\nand GPU utilization. Our findings challenge conventional assumptions about LLM\ninference, offering new insights and practical strategies for improving\nresource utilization, particularly for smaller language models.\n","authors":["Pol G. Recasens","Ferran Agullo","Yue Zhu","Chen Wang","Eun Kyung Lee","Olivier Tardieu","Jordi Torres","Josep Ll. Berral"],"pdf_url":"https://arxiv.org/pdf/2503.08311v1.pdf","comment":"Pol G. Recasens, Ferran Agullo: equal contribution"},{"id":"http://arxiv.org/abs/2503.08306v1","updated":"2025-03-11T11:16:47Z","published":"2025-03-11T11:16:47Z","title":"Reasoning in visual navigation of end-to-end trained agents: a dynamical\n  systems approach","summary":"  Progress in Embodied AI has made it possible for end-to-end-trained agents to\nnavigate in photo-realistic environments with high-level reasoning and\nzero-shot or language-conditioned behavior, but benchmarks are still dominated\nby simulation. In this work, we focus on the fine-grained behavior of\nfast-moving real robots and present a large-scale experimental study involving\n\\numepisodes{} navigation episodes in a real environment with a physical robot,\nwhere we analyze the type of reasoning emerging from end-to-end training. In\nparticular, we study the presence of realistic dynamics which the agent learned\nfor open-loop forecasting, and their interplay with sensing. We analyze the way\nthe agent uses latent memory to hold elements of the scene structure and\ninformation gathered during exploration. We probe the planning capabilities of\nthe agent, and find in its memory evidence for somewhat precise plans over a\nlimited horizon. Furthermore, we show in a post-hoc analysis that the value\nfunction learned by the agent relates to long-term planning. Put together, our\nexperiments paint a new picture on how using tools from computer vision and\nsequential decision making have led to new capabilities in robotics and\ncontrol. An interactive tool is available at\neurope.naverlabs.com/research/publications/reasoning-in-visual-navigation-of-end-to-end-trained-agents.\n","authors":["Steeven Janny","Hervé Poirier","Leonid Antsfeld","Guillaume Bono","Gianluca Monaci","Boris Chidlovskii","Francesco Giuliari","Alessio Del Bue","Christian Wolf"],"pdf_url":"https://arxiv.org/pdf/2503.08306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19114v2","updated":"2025-03-11T11:15:58Z","published":"2024-07-26T22:34:05Z","title":"To which reference class do you belong? Measuring racial fairness of\n  reference classes with normative modeling","summary":"  Reference classes in healthcare establish healthy norms, such as pediatric\ngrowth charts of height and weight, and are used to chart deviations from these\nnorms which represent potential clinical risk. How the demographics of the\nreference class influence clinical interpretation of deviations is unknown.\nUsing normative modeling, a method for building reference classes, we evaluate\nthe fairness (racial bias) in reference models of structural brain images that\nare widely used in psychiatry and neurology. We test whether including race in\nthe model creates fairer models. We predict self-reported race using the\ndeviation scores from three different reference class normative models, to\nbetter understand bias in an integrated, multivariate sense. Across all of\nthese tasks, we uncover racial disparities that are not easily addressed with\nexisting data or commonly used modeling techniques. Our work suggests that\ndeviations from the norm could be due to demographic mismatch with the\nreference class, and assigning clinical meaning to these deviations should be\ndone with caution. Our approach also suggests that acquiring more\nrepresentative samples is an urgent research priority.\n","authors":["Saige Rutherford","Thomas Wolfers","Charlotte Fraza","Nathaniel G. Harnett","Christian F. Beckmann","Henricus G. Ruhe","Andre F. Marquand"],"pdf_url":"https://arxiv.org/pdf/2407.19114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08305v1","updated":"2025-03-11T11:14:25Z","published":"2025-03-11T11:14:25Z","title":"ELECTRA: A Symmetry-breaking Cartesian Network for Charge Density\n  Prediction with Floating Orbitals","summary":"  We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an\nequivariant model for predicting electronic charge densities using \"floating\"\norbitals. Floating orbitals are a long-standing idea in the quantum chemistry\ncommunity that promises more compact and accurate representations by placing\norbitals freely in space, as opposed to centering all orbitals at the position\nof atoms. Finding ideal placements of these orbitals requires extensive domain\nknowledge though, which thus far has prevented widespread adoption. We solve\nthis in a data-driven manner by training a Cartesian tensor network to predict\norbital positions along with orbital coefficients. This is made possible\nthrough a symmetry-breaking mechanism that is used to learn position\ndisplacements with lower symmetry than the input molecule while preserving the\nrotation equivariance of the charge density itself. Inspired by recent\nsuccesses of Gaussian Splatting in representing densities in space, we are\nusing Gaussians as our orbitals and predict their weights and covariance\nmatrices. Our method achieves a state-of-the-art balance between computational\nefficiency and predictive accuracy on established benchmarks.\n","authors":["Jonas Elsborg","Luca Thiede","Alán Aspuru-Guzik","Tejs Vegge","Arghya Bhowmik"],"pdf_url":"https://arxiv.org/pdf/2503.08305v1.pdf","comment":"8 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.08303v1","updated":"2025-03-11T11:14:05Z","published":"2025-03-11T11:14:05Z","title":"Energy Scale Degradation in Sparse Quantum Solvers: A Barrier to Quantum\n  Utility","summary":"  Quantum computing offers a promising route for tackling hard optimization\nproblems by encoding them as Ising models. However, sparse qubit connectivity\nrequires the use of minor-embedding, mapping logical qubits onto chains of\nphysical qubits, which necessitates stronger intra-chain coupling to maintain\nconsistency. This elevated coupling strength forces a rescaling of the\nHamiltonian due to hardware-imposed limits on the allowable ranges of coupling\nstrengths, reducing the energy gaps between competing states, thus, degrading\nthe solver's performance. Here, we introduce a theoretical model that\nquantifies this degradation. We show that as the connectivity degree increases,\nthe effective temperature rises as a polynomial function, resulting in a\nsuccess probability that decays exponentially. Our analysis further establishes\nworst-case bounds on the energy scale degradation based on the inverse\nconductance of chain subgraphs, revealing two most important drivers of chain\nstrength, \\textit{chain volume} and \\textit{chain connectivity}. Our findings\nindicate that achieving quantum advantage is inherently challenging.\nExperiments on D-Wave quantum annealers validate these findings, highlighting\nthe need for hardware with improved connectivity and optimized scale-aware\nembedding algorithms.\n","authors":["Thang N. Dinh","Cao P. Cong"],"pdf_url":"https://arxiv.org/pdf/2503.08303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08301v1","updated":"2025-03-11T11:13:11Z","published":"2025-03-11T11:13:11Z","title":"Large Language Model as Meta-Surrogate for Data-Driven Many-Task\n  Optimization: A Proof-of-Principle Study","summary":"  In many-task optimization scenarios, surrogate models are valuable for\nmitigating the computational burden of repeated fitness evaluations across\ntasks. This study proposes a novel meta-surrogate framework to assist many-task\noptimization, by leveraging the knowledge transfer strengths and emergent\ncapabilities of large language models (LLMs). We formulate a unified framework\nfor many-task fitness prediction, by defining a universal model with metadata\nto fit a group of problems. Fitness prediction is performed on metadata and\ndecision variables, enabling efficient knowledge sharing across tasks and\nadaptability to new tasks. The LLM-based meta-surrogate treats fitness\nprediction as conditional probability estimation, employing a unified token\nsequence representation for task metadata, inputs, and outputs. This approach\nfacilitates efficient inter-task knowledge sharing through shared token\nembeddings and captures complex task dependencies via multi-task model\ntraining. Experimental results demonstrate the model's emergent generalization\nability, including zero-shot performance on problems with unseen dimensions.\nWhen integrated into evolutionary transfer optimization (ETO), our framework\nsupports dual-level knowledge transfer -- at both the surrogate and individual\nlevels -- enhancing optimization efficiency and robustness. This work\nestablishes a novel foundation for applying LLMs in surrogate modeling,\noffering a versatile solution for many-task optimization.\n","authors":["Xian-Rong Zhang","Yue-Jiao Gong","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08301v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2503.08295v1","updated":"2025-03-11T11:07:35Z","published":"2025-03-11T11:07:35Z","title":"D3PO: Preference-Based Alignment of Discrete Diffusion Models","summary":"  Diffusion models have achieved state-of-the-art performance across multiple\ndomains, with recent advancements extending their applicability to discrete\ndata. However, aligning discrete diffusion models with task-specific\npreferences remains challenging, particularly in scenarios where explicit\nreward functions are unavailable. In this work, we introduce Discrete Diffusion\nDPO (D3PO), the first adaptation of Direct Preference Optimization (DPO) to\ndiscrete diffusion models formulated as continuous-time Markov chains. Our\napproach derives a novel loss function that directly fine-tunes the generative\nprocess using preference data while preserving fidelity to a reference\ndistribution. We validate D3PO on a structured binary sequence generation task,\ndemonstrating that the method effectively aligns model outputs with preferences\nwhile maintaining structural validity. Our results highlight that D3PO enables\ncontrolled fine-tuning without requiring explicit reward models, making it a\npractical alternative to reinforcement learning-based approaches. Future\nresearch will explore extending D3PO to more complex generative tasks,\nincluding language modeling and protein sequence generation, as well as\ninvestigating alternative noise schedules, such as uniform noising, to enhance\nflexibility across different applications.\n","authors":["Umberto Borso","Davide Paglieri","Jude Wells","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2503.08295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08293v1","updated":"2025-03-11T11:06:00Z","published":"2025-03-11T11:06:00Z","title":"A systematic literature review of unsupervised learning algorithms for\n  anomalous traffic detection based on flows","summary":"  The constant increase of devices connected to the Internet, and therefore of\ncyber-attacks, makes it necessary to analyze network traffic in order to\nrecognize malicious activity. Traditional packet-based analysis methods are\ninsufficient because in large networks the amount of traffic is so high that it\nis unfeasible to review all communications. For this reason, flows is a\nsuitable approach for this situation, which in future 5G networks will have to\nbe used, as the number of packets will increase dramatically. If this is also\ncombined with unsupervised learning models, it can detect new threats for which\nit has not been trained. This paper presents a systematic review of the\nliterature on unsupervised learning algorithms for detecting anomalies in\nnetwork flows, following the PRISMA guideline. A total of 63 scientific\narticles have been reviewed, analyzing 13 of them in depth. The results\nobtained show that autoencoder is the most used option, followed by SVM, ALAD,\nor SOM. On the other hand, all the datasets used for anomaly detection have\nbeen collected, including some specialised in IoT or with real data collected\nfrom honeypots.\n","authors":["Alberto Miguel-Diez","Adrián Campazas-Vega","Claudia Álvarez-Aparicio","Gonzalo Esteban-Costales","Ángel Manuel Guerrero-Higueras"],"pdf_url":"https://arxiv.org/pdf/2503.08293v1.pdf","comment":"This article has been accepted for publication in Logic Journal of\n  the IGPL Published by Oxford University Press"},{"id":"http://arxiv.org/abs/2410.19780v2","updated":"2025-03-11T11:04:40Z","published":"2024-10-14T13:47:02Z","title":"Sampling from Bayesian Neural Network Posteriors with Symmetric\n  Minibatch Splitting Langevin Dynamics","summary":"  We propose a scalable kinetic Langevin dynamics algorithm for sampling\nparameter spaces of big data and AI applications. Our scheme combines a\nsymmetric forward/backward sweep over minibatches with a symmetric\ndiscretization of Langevin dynamics. For a particular Langevin splitting method\n(UBU), we show that the resulting Symmetric Minibatch Splitting-UBU (SMS-UBU)\nintegrator has bias $O(h^2 d^{1/2})$ in dimension $d>0$ with stepsize $h>0$,\ndespite only using one minibatch per iteration, thus providing excellent\ncontrol of the sampling bias as a function of the stepsize. We apply the\nalgorithm to explore local modes of the posterior distribution of Bayesian\nneural networks (BNNs) and evaluate the calibration performance of the\nposterior predictive probabilities for neural networks with convolutional\nneural network architectures for classification problems on three different\ndatasets (Fashion-MNIST, Celeb-A and chest X-ray). Our results indicate that\nBNNs sampled with SMS-UBU can offer significantly better calibration\nperformance compared to standard methods of training and stochastic weight\naveraging.\n","authors":["Daniel Paulin","Peter A. Whalley","Neil K. Chada","Benedict Leimkuhler"],"pdf_url":"https://arxiv.org/pdf/2410.19780v2.pdf","comment":"33 pages, 7 figures. The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2406.07451v3","updated":"2025-03-11T10:55:52Z","published":"2024-06-11T16:57:48Z","title":"A Multi-Armed Bandit Approach to Online Selection and Evaluation of\n  Generative Models","summary":"  Existing frameworks for evaluating and comparing generative models consider\nan offline setting, where the evaluator has access to large batches of data\nproduced by the models. However, in practical scenarios, the goal is often to\nidentify and select the best model using the fewest possible generated samples\nto minimize the costs of querying data from the sub-optimal models. In this\nwork, we propose an online evaluation and selection framework to find the\ngenerative model that maximizes a standard assessment score among a group of\navailable models. We view the task as a multi-armed bandit (MAB) and propose\nupper confidence bound (UCB) bandit algorithms to identify the model producing\ndata with the best evaluation score that quantifies the quality and diversity\nof generated data. Specifically, we develop the MAB-based selection of\ngenerative models considering the Fr\\'echet Distance (FD) and Inception Score\n(IS) metrics, resulting in the FD-UCB and IS-UCB algorithms. We prove regret\nbounds for these algorithms and present numerical results on standard image\ndatasets. Our empirical results suggest the efficacy of MAB approaches for the\nsample-efficient evaluation and selection of deep generative models. The\nproject code is available at https://github.com/yannxiaoyanhu/dgm-online-eval.\n","authors":["Xiaoyan Hu","Ho-fung Leung","Farzan Farnia"],"pdf_url":"https://arxiv.org/pdf/2406.07451v3.pdf","comment":"arXiv version"},{"id":"http://arxiv.org/abs/2411.15098v5","updated":"2025-03-11T10:41:44Z","published":"2024-11-22T17:55:15Z","title":"OminiControl: Minimal and Universal Control for Diffusion Transformer","summary":"  We present OminiControl, a novel approach that rethinks how image conditions\nare integrated into Diffusion Transformer (DiT) architectures. Current image\nconditioning methods either introduce substantial parameter overhead or handle\nonly specific control tasks effectively, limiting their practical versatility.\nOminiControl addresses these limitations through three key innovations: (1) a\nminimal architectural design that leverages the DiT's own VAE encoder and\ntransformer blocks, requiring just 0.1% additional parameters; (2) a unified\nsequence processing strategy that combines condition tokens with image tokens\nfor flexible token interactions; and (3) a dynamic position encoding mechanism\nthat adapts to both spatially-aligned and non-aligned control tasks. Our\nextensive experiments show that this streamlined approach not only matches but\nsurpasses the performance of specialized methods across multiple conditioning\ntasks. To overcome data limitations in subject-driven generation, we also\nintroduce Subjects200K, a large-scale dataset of identity-consistent image\npairs synthesized using DiT models themselves. This work demonstrates that\neffective image control can be achieved without architectural complexity,\nopening new possibilities for efficient and versatile image generation systems.\n","authors":["Zhenxiong Tan","Songhua Liu","Xingyi Yang","Qiaochu Xue","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2411.15098v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08271v1","updated":"2025-03-11T10:40:39Z","published":"2025-03-11T10:40:39Z","title":"LangTime: A Language-Guided Unified Model for Time Series Forecasting\n  with Proximal Policy Optimization","summary":"  Recent research has shown an increasing interest in utilizing pre-trained\nlarge language models (LLMs) for a variety of time series applications.\nHowever, there are three main challenges when using LLMs as foundational models\nfor time series forecasting: (1) Cross-domain generalization. (2)\nCross-modality alignment. (3) Error accumulation in autoregressive frameworks.\nTo address these challenges, we proposed LangTime, a language-guided unified\nmodel for time series forecasting that incorporates cross-domain pre-training\nwith reinforcement learning-based fine-tuning. Specifically, LangTime\nconstructs Temporal Comprehension Prompts (TCPs), which include dataset-wise\nand channel-wise instructions, to facilitate domain adaptation and condense\ntime series into a single token, enabling LLMs to understand better and align\ntemporal data. To improve autoregressive forecasting, we introduce TimePPO, a\nreinforcement learning-based fine-tuning algorithm. TimePPO mitigates error\naccumulation by leveraging a multidimensional rewards function tailored for\ntime series and a repeat-based value estimation strategy. Extensive experiments\ndemonstrate that LangTime achieves state-of-the-art cross-domain forecasting\nperformance, while TimePPO fine-tuning effectively enhances the stability and\naccuracy of autoregressive forecasting.\n","authors":["Wenzhe Niu","Zongxia Xie","Yanru Sun","Wei He","Man Xu","Chao Hao"],"pdf_url":"https://arxiv.org/pdf/2503.08271v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11795v3","updated":"2025-03-11T10:39:02Z","published":"2024-03-18T13:53:17Z","title":"Low-Cost Privacy-Preserving Decentralized Learning","summary":"  Decentralized learning (DL) is an emerging paradigm of collaborative machine\nlearning that enables nodes in a network to train models collectively without\nsharing their raw data or relying on a central server. This paper introduces\nZip-DL, a privacy-aware DL algorithm that leverages correlated noise to achieve\nrobust privacy against local adversaries while ensuring efficient convergence\nat low communication costs. By progressively neutralizing the noise added\nduring distributed averaging, Zip-DL combines strong privacy guarantees with\nhigh model accuracy. Its design requires only one communication round per\ngradient descent iteration, significantly reducing communication overhead\ncompared to competitors. We establish theoretical bounds on both convergence\nspeed and privacy guarantees. Moreover, extensive experiments demonstrating\nZip-DL's practical applicability make it outperform state-of-the-art methods in\nthe accuracy vs. vulnerability trade-off. Specifically, Zip-DL (i) reduces\nmembership-inference attack success rates by up to 35% compared to baseline DL,\n(ii) decreases attack efficacy by up to 13% compared to competitors offering\nsimilar utility, and (iii) achieves up to 59% higher accuracy to completely\nnullify a basic attack scenario, compared to a state-of-the-art\nprivacy-preserving approach under the same threat model. These results position\nZip-DL as a practical and efficient solution for privacy-preserving\ndecentralized learning in real-world applications.\n","authors":["Sayan Biswas","Davide Frey","Romaric Gaudel","Anne-Marie Kermarrec","Dimitri Lerévérend","Rafael Pires","Rishi Sharma","François Taïani"],"pdf_url":"https://arxiv.org/pdf/2403.11795v3.pdf","comment":"24 pages, accepted at Pets 2025"},{"id":"http://arxiv.org/abs/2206.05904v9","updated":"2025-03-11T10:34:57Z","published":"2022-06-13T05:15:12Z","title":"Theoretical guarantees for the advantage of GNNs over NNs in\n  generalizing bandlimited functions on Euclidean cubes","summary":"  Graph Neural Networks (GNNs) have emerged as formidable resources for\nprocessing graph-based information across diverse applications. While the\nexpressive power of GNNs has traditionally been examined in the context of\ngraph-level tasks, their potential for node-level tasks, such as node\nclassification, where the goal is to interpolate missing node labels from the\nobserved ones, remains relatively unexplored. In this study, we investigate the\nproficiency of GNNs for such classifications, which can also be cast as a\nfunction interpolation problem. Explicitly, we focus on ascertaining the\noptimal configuration of weights and layers required for a GNN to successfully\ninterpolate a band-limited function over Euclidean cubes. Our findings\nhighlight a pronounced efficiency in utilizing GNNs to generalize a bandlimited\nfunction within an $\\varepsilon$-error margin. Remarkably, achieving this task\nnecessitates only $O_d((\\log\\varepsilon^{-1})^d)$ weights and\n$O_d((\\log\\varepsilon^{-1})^d)$ training samples. We explore how this criterion\nstacks up against the explicit constructions of currently available Neural\nNetworks (NNs) designed for similar tasks. Significantly, our result is\nobtained by drawing an innovative connection between the GNN structures and\nclassical sampling theorems. In essence, our pioneering work marks a meaningful\ncontribution to the research domain, advancing our understanding of the\npractical GNN applications.\n","authors":["A. Martina Neuman","Rongrong Wang","Yuying Xie"],"pdf_url":"https://arxiv.org/pdf/2206.05904v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08264v1","updated":"2025-03-11T10:28:58Z","published":"2025-03-11T10:28:58Z","title":"Massively Parallel Expectation Maximization For Approximate Posteriors","summary":"  Bayesian inference for hierarchical models can be very challenging. MCMC\nmethods have difficulty scaling to large models with many observations and\nlatent variables. While variational inference (VI) and reweighted wake-sleep\n(RWS) can be more scalable, they are gradient-based methods and so often\nrequire many iterations to converge. Our key insight was that modern massively\nparallel importance weighting methods (Bowyer et al., 2024) give fast and\naccurate posterior moment estimates, and we can use these moment estimates to\nrapidly learn an approximate posterior. Specifically, we propose using\nexpectation maximization to fit the approximate posterior, which we call QEM.\nThe expectation step involves computing the posterior moments using\nhigh-quality massively parallel estimates from Bowyer et al. (2024). The\nmaximization step involves fitting the approximate posterior using these\nmoments, which can be done straightforwardly for simple approximate posteriors\nsuch as Gaussian, Gamma, Beta, Dirichlet, Binomial, Multinomial, Categorical,\netc. (or combinations thereof). We show that QEM is faster than\nstate-of-the-art, massively parallel variants of RWS and VI, and is invariant\nto reparameterizations of the model that dramatically slow down gradient based\nmethods.\n","authors":["Thomas Heap","Sam Bowyer","Laurence Aitchison"],"pdf_url":"https://arxiv.org/pdf/2503.08264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05837v2","updated":"2025-03-11T10:19:52Z","published":"2024-11-06T13:26:57Z","title":"Gaussian Smoothing in Saliency Maps: The Stability-Fidelity Trade-Off in\n  Neural Network Interpretability","summary":"  Saliency maps have been widely used to interpret the decisions of neural\nnetwork classifiers and discover phenomena from their learned functions.\nHowever, standard gradient-based maps are frequently observed to be highly\nsensitive to the randomness of training data and the stochasticity in the\ntraining process. In this work, we study the role of Gaussian smoothing in the\nwell-known Smooth-Grad algorithm in the stability of the gradient-based maps to\nthe randomness of training samples. We extend the algorithmic stability\nframework to gradient-based interpretation maps and prove bounds on the\nstability error of standard Simple-Grad, Integrated-Gradients, and Smooth-Grad\nsaliency maps. Our theoretical results suggest the role of Gaussian smoothing\nin boosting the stability of gradient-based maps to the randomness of training\nsettings. On the other hand, we analyze the faithfulness of the Smooth-Grad\nmaps to the original Simple-Grad and show the lower fidelity under a more\nintense Gaussian smoothing. We support our theoretical results by performing\nseveral numerical experiments on standard image datasets. Our empirical results\nconfirm our hypothesis on the fidelity-stability trade-off in the application\nof Gaussian smoothing to gradient-based interpretation maps.\n","authors":["Zhuorui Ye","Farzan Farnia"],"pdf_url":"https://arxiv.org/pdf/2411.05837v2.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.02177v2","updated":"2025-03-11T10:16:39Z","published":"2024-11-04T15:36:17Z","title":"Physics-informed neural networks viewpoint for solving the\n  Dyson-Schwinger equations of quantum electrodynamics","summary":"  Physics-informed neural networks (PINNs) are employed to solve the\nDyson--Schwinger equations of quantum electrodynamics (QED) in Euclidean space,\nwith a focus on the non-perturbative generation of the fermion's dynamical mass\nfunction in the Landau gauge. By inserting the integral equation directly into\nthe loss function, our PINN framework enables a single neural network to learn\na continuous and differentiable representation of the mass function over a\nspectrum of momenta. Also, we benchmark our approach against a traditional\nnumerical algorithm showing the main differences among them. Our novel\nstrategy, which can be extended to other quantum field theories, paves the way\nfor forefront applications of machine learning in high-level theoretical\nphysics.\n","authors":["Rodrigo Carmo Terin"],"pdf_url":"https://arxiv.org/pdf/2411.02177v2.pdf","comment":"17 pages, 4 figures, 2 tables. New references added; forefront work\n  has been adapted to line up with the traditional DSEs literature"},{"id":"http://arxiv.org/abs/2503.08251v1","updated":"2025-03-11T10:14:53Z","published":"2025-03-11T10:14:53Z","title":"MT-NAM: An Efficient and Adaptive Model for Epileptic Seizure Detection","summary":"  Enhancing the accuracy and efficiency of machine learning algorithms employed\nin neural interface systems is crucial for advancing next-generation\nintelligent therapeutic devices. However, current systems often utilize basic\nmachine learning models that do not fully exploit the natural structure of\nbrain signals. Additionally, existing learning models used for neural signal\nprocessing often demonstrate low speed and efficiency during inference. To\naddress these challenges, this study introduces Micro Tree-based NAM (MT-NAM),\na distilled model based on the recently proposed Neural Additive Models (NAM).\nThe MT-NAM achieves a remarkable 100$\\times$ improvement in inference speed\ncompared to standard NAM, without compromising accuracy. We evaluate our\napproach on the CHB-MIT scalp EEG dataset, which includes recordings from 24\npatients with varying numbers of sessions and seizures. NAM achieves an 85.3\\%\nwindow-based sensitivity and 95\\% specificity. Interestingly, our proposed\nMT-NAM shows only a 2\\% reduction in sensitivity compared to the original NAM.\nTo regain this sensitivity, we utilize a test-time template adjuster (T3A) as\nan update mechanism, enabling our model to achieve higher sensitivity during\ntest time by accommodating transient shifts in neural signals. With this online\nupdate approach, MT-NAM achieves the same sensitivity as the standard NAM while\nachieving approximately 50$\\times$ acceleration in inference speed.\n","authors":["Arshia Afzal","Volkan Cevher","Mahsa Shoaran"],"pdf_url":"https://arxiv.org/pdf/2503.08251v1.pdf","comment":"Submitted to IEEE-TBME"},{"id":"http://arxiv.org/abs/2503.08250v1","updated":"2025-03-11T10:14:22Z","published":"2025-03-11T10:14:22Z","title":"Aligning Text to Image in Diffusion Models is Easier Than You Think","summary":"  While recent advancements in generative modeling have significantly improved\ntext-image alignment, some residual misalignment between text and image\nrepresentations still remains. Although many approaches have attempted to\naddress this issue by fine-tuning models using various reward models, etc., we\nrevisit the challenge from the perspective of representation alignment-an\napproach that has gained popularity with the success of REPresentation\nAlignment (REPA). We first argue that conventional text-to-image (T2I)\ndiffusion models, typically trained on paired image and text data (i.e.,\npositive pairs) by minimizing score matching or flow matching losses, is\nsuboptimal from the standpoint of representation alignment. Instead, a better\nalignment can be achieved through contrastive learning that leverages both\npositive and negative pairs. To achieve this efficiently even with pretrained\nmodels, we introduce a lightweight contrastive fine tuning strategy called\nSoftREPA that uses soft text tokens. This approach improves alignment with\nminimal computational overhead by adding fewer than 1M trainable parameters to\nthe pretrained model. Our theoretical analysis demonstrates that our method\nexplicitly increases the mutual information between text and image\nrepresentations, leading to enhanced semantic consistency. Experimental results\nacross text-to-image generation and text-guided image editing tasks validate\nthe effectiveness of our approach in improving the semantic consistency of T2I\ngenerative models.\n","authors":["Jaa-Yeon Lee","Byunghee Cha","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2503.08250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11868v4","updated":"2025-03-11T10:09:11Z","published":"2024-04-18T02:59:48Z","title":"OTCXR: Rethinking Self-supervised Alignment using Optimal Transport for\n  Chest X-ray Analysis","summary":"  Self-supervised learning (SSL) has emerged as a promising technique for\nanalyzing medical modalities such as X-rays due to its ability to learn without\nannotations. However, conventional SSL methods face challenges in achieving\nsemantic alignment and capturing subtle details, which limits their ability to\naccurately represent the underlying anatomical structures and pathological\nfeatures. To address these limitations, we propose OTCXR, a novel SSL framework\nthat leverages optimal transport (OT) to learn dense semantic invariance. By\nintegrating OT with our innovative Cross-Viewpoint Semantics Infusion Module\n(CV-SIM), OTCXR enhances the model's ability to capture not only local spatial\nfeatures but also global contextual dependencies across different viewpoints.\nThis approach enriches the effectiveness of SSL in the context of chest\nradiographs. Furthermore, OTCXR incorporates variance and covariance\nregularizations within the OT framework to prioritize clinically relevant\ninformation while suppressing less informative features. This ensures that the\nlearned representations are comprehensive and discriminative, particularly\nbeneficial for tasks such as thoracic disease diagnosis. We validate OTCXR's\nefficacy through comprehensive experiments on three publicly available chest\nX-ray datasets. Our empirical results demonstrate the superiority of OTCXR over\nstate-of-the-art methods across all evaluated tasks, confirming its capability\nto learn semantically rich representations.\n","authors":["Vandan Gorade","Azad Singh","Deepak Mishra"],"pdf_url":"https://arxiv.org/pdf/2404.11868v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08245v1","updated":"2025-03-11T10:08:39Z","published":"2025-03-11T10:08:39Z","title":"ExMAG: Learning of Maximally Ancestral Graphs","summary":"  As one transitions from statistical to causal learning, one is seeking the\nmost appropriate causal model. Dynamic Bayesian networks are a popular model,\nwhere a weighted directed acyclic graph represents the causal relationships.\nStochastic processes are represented by its vertices, and weighted oriented\nedges suggest the strength of the causal relationships. When there are\nconfounders, one would like to utilize both oriented edges (when the direction\nof causality is clear) and edges that are not oriented (when there is a\nconfounder), yielding mixed graphs. A little-studied extension of acyclicity to\nthis mixed-graph setting is known as maximally ancestral graphs. We propose a\nscore-based learning algorithm for learning maximally ancestral graphs. A\nmixed-integer quadratic program is formulated, and an algorithmic approach is\nproposed, in which the pre-generation of exponentially many constraints is\navoided by generating only violated constraints in the so-called branch-and-cut\n(``lazy constraint'') method. Comparing the novel approach to the\nstate-of-the-art, we show that the proposed approach turns out to produce more\naccurate results when applied to small and medium-sized synthetic instances\ncontaining up to 25 variables.\n","authors":["Petr Ryšavý","Pavel Rytíř","Xiaoyu He","Jakub Mareček","Georgios Korpas"],"pdf_url":"https://arxiv.org/pdf/2503.08245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08246v1","updated":"2025-03-11T10:08:39Z","published":"2025-03-11T10:08:39Z","title":"Dynamic DBSCAN with Euler Tour Sequences","summary":"  We propose a fast and dynamic algorithm for Density-Based Spatial Clustering\nof Applications with Noise (DBSCAN) that efficiently supports online updates.\nTraditional DBSCAN algorithms, designed for batch processing, become\ncomputationally expensive when applied to dynamic datasets, particularly in\nlarge-scale applications where data continuously evolves. To address this\nchallenge, our algorithm leverages the Euler Tour Trees data structure,\nenabling dynamic clustering updates without the need to reprocess the entire\ndataset. This approach preserves a near-optimal accuracy in density estimation,\nas achieved by the state-of-the-art static DBSCAN method (Esfandiari et al.,\n2021) Our method achieves an improved time complexity of $O(d \\log^3(n) +\n\\log^4(n))$ for every data point insertion and deletion, where $n$ and $d$\ndenote the total number of updates and the data dimension, respectively.\nEmpirical studies also demonstrate significant speedups over conventional\nDBSCANs in real-time clustering of dynamic datasets, while maintaining\ncomparable or superior clustering quality.\n","authors":["Seiyun Shin","Ilan Shomorony","Peter Macgregor"],"pdf_url":"https://arxiv.org/pdf/2503.08246v1.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.08241v1","updated":"2025-03-11T10:05:01Z","published":"2025-03-11T10:05:01Z","title":"HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in\n  Embodied Agents","summary":"  Advancing safe autonomous systems through reinforcement learning (RL)\nrequires robust benchmarks to evaluate performance, analyze methods, and assess\nagent competencies. Humans primarily rely on embodied visual perception to\nsafely navigate and interact with their surroundings, making it a valuable\ncapability for RL agents. However, existing vision-based 3D benchmarks only\nconsider simple navigation tasks. To address this shortcoming, we introduce\n\\textbf{HASARD}, a suite of diverse and complex tasks to $\\textbf{HA}$rness\n$\\textbf{SA}$fe $\\textbf{R}$L with $\\textbf{D}$oom, requiring strategic\ndecision-making, comprehending spatial relationships, and predicting the\nshort-term future. HASARD features three difficulty levels and two action\nspaces. An empirical evaluation of popular baseline methods demonstrates the\nbenchmark's complexity, unique challenges, and reward-cost trade-offs.\nVisualizing agent navigation during training with top-down heatmaps provides\ninsight into a method's learning process. Incrementally training across\ndifficulty levels offers an implicit learning curriculum. HASARD is the first\nsafe RL benchmark to exclusively target egocentric vision-based learning,\noffering a cost-effective and insightful way to explore the potential and\nboundaries of current and future safe RL methods. The environments and baseline\nimplementations are open-sourced at\nhttps://sites.google.com/view/hasard-bench/.\n","authors":["Tristan Tomilin","Meng Fang","Mykola Pechenizkiy"],"pdf_url":"https://arxiv.org/pdf/2503.08241v1.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08240v1","updated":"2025-03-11T10:04:13Z","published":"2025-03-11T10:04:13Z","title":"Tangentially Aligned Integrated Gradients for User-Friendly Explanations","summary":"  Integrated gradients is prevalent within machine learning to address the\nblack-box problem of neural networks. The explanations given by integrated\ngradients depend on a choice of base-point. The choice of base-point is not a\npriori obvious and can lead to drastically different explanations. There is a\nlongstanding hypothesis that data lies on a low dimensional Riemannian\nmanifold. The quality of explanations on a manifold can be measured by the\nextent to which an explanation for a point lies in its tangent space. In this\nwork, we propose that the base-point should be chosen such that it maximises\nthe tangential alignment of the explanation. We formalise the notion of\ntangential alignment and provide theoretical conditions under which a\nbase-point choice will provide explanations lying in the tangent space. We\ndemonstrate how to approximate the optimal base-point on several well-known\nimage classification datasets. Furthermore, we compare the optimal base-point\nchoice with common base-points and three gradient explainability models.\n","authors":["Lachlan Simpson","Federico Costanza","Kyle Millar","Adriel Cheng","Cheng-Chew Lim","Hong Gunn Chew"],"pdf_url":"https://arxiv.org/pdf/2503.08240v1.pdf","comment":"To appear in the proceedings of the 32nd Irish Conference on\n  Artificial Intelligence and Cognitive Science"},{"id":"http://arxiv.org/abs/2503.08231v1","updated":"2025-03-11T09:51:21Z","published":"2025-03-11T09:51:21Z","title":"How good is PAC-Bayes at explaining generalisation?","summary":"  We discuss necessary conditions for a PAC-Bayes bound to provide a meaningful\ngeneralisation guarantee. Our analysis reveals that the optimal generalisation\nguarantee depends solely on the distribution of the risk induced by the prior\ndistribution. In particular, achieving a target generalisation level is only\nachievable if the prior places sufficient mass on high-performing predictors.\nWe relate these requirements to the prevalent practice of using data-dependent\npriors in deep learning PAC-Bayes applications, and discuss the implications\nfor the claim that PAC-Bayes ``explains'' generalisation.\n","authors":["Antoine Picard-Weibel","Eugenio Clerico","Roman Moscoviz","Benjamin Guedj"],"pdf_url":"https://arxiv.org/pdf/2503.08231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06749v2","updated":"2025-03-11T09:47:44Z","published":"2025-03-09T20:06:45Z","title":"Vision-R1: Incentivizing Reasoning Capability in Multimodal Large\n  Language Models","summary":"  DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .\n","authors":["Wenxuan Huang","Bohan Jia","Zijie Zhai","Shaosheng Cao","Zheyu Ye","Fei Zhao","Zhe Xu","Yao Hu","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06749v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10436v2","updated":"2025-03-11T09:43:23Z","published":"2024-08-19T22:03:02Z","title":"Learning Regularization for Graph Inverse Problems","summary":"  In recent years, Graph Neural Networks (GNNs) have been utilized for various\napplications ranging from drug discovery to network design and social networks.\nIn many applications, it is impossible to observe some properties of the graph\ndirectly; instead, noisy and indirect measurements of these properties are\navailable. These scenarios are coined as Graph Inverse Problems (GRIP). In this\nwork, we introduce a framework leveraging GNNs to solve GRIPs. The framework is\nbased on a combination of likelihood and prior terms, which are used to find a\nsolution that fits the data while adhering to learned prior information.\nSpecifically, we propose to combine recent deep learning techniques that were\ndeveloped for inverse problems, together with GNN architectures, to formulate\nand solve GRIP. We study our approach on a number of representative problems\nthat demonstrate the effectiveness of the framework.\n","authors":["Moshe Eliasof","Md Shahriar Rahim Siddiqui","Carola-Bibiane Schönlieb","Eldad Haber"],"pdf_url":"https://arxiv.org/pdf/2408.10436v2.pdf","comment":"AAAI 2025 (Oral)"},{"id":"http://arxiv.org/abs/2503.08207v1","updated":"2025-03-11T09:23:01Z","published":"2025-03-11T09:23:01Z","title":"To Use or Not to Use a Universal Force Field","summary":"  Artificial intelligence (AI) is revolutionizing scientific research,\nparticularly in computational materials science, by enabling more accurate and\nefficient simulations. Machine learning force fields (MLFFs) have emerged as\npowerful tools for molecular dynamics (MD) simulations, potentially offering\nquantum-mechanical accuracy with the efficiency of classical MD. This\nPerspective evaluates the viability of universal MLFFs for simulating complex\nmaterials systems from the standpoint of a potential practitioner. Using the\ntemperature-driven ferroelectric-paraelectric phase transition of PbTiO$_3$ as\na benchmark, we assess leading universal force fields, including CHGNet, MACE,\nM3GNet, and GPTFF, alongside specialized models like UniPero. While universal\nMLFFs trained on PBE-derived datasets perform well in predicting equilibrium\nproperties, they largely fail to capture realistic finite-temperature phase\ntransitions under constant-pressure MD, often exhibiting unphysical\ninstabilities. These shortcomings stem from inherited biases in\nexchange-correlation functionals and limited generalization to anharmonic\ninteractions governing dynamic behavior. However, fine-tuning universal models\nor employing system-specific MLFFs like UniPero successfully restores\npredictive accuracy. We advocates for hybrid approaches combining universal\npretraining with targeted optimization, improved error quantification\nframeworks, and community-driven benchmarks to advance MLFFs as robust tools\nfor computational materials discovery.\n","authors":["Denan Li","Jiyuan Yang","Xiangkai Chen","Lintao Yu","Shi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.08207v1.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.08203v1","updated":"2025-03-11T09:17:58Z","published":"2025-03-11T09:17:58Z","title":"A Theoretical Framework for Preventing Class Collapse in Supervised\n  Contrastive Learning","summary":"  Supervised contrastive learning (SupCL) has emerged as a prominent approach\nin representation learning, leveraging both supervised and self-supervised\nlosses. However, achieving an optimal balance between these losses is\nchallenging; failing to do so can lead to class collapse, reducing\ndiscrimination among individual embeddings in the same class. In this paper, we\npresent theoretically grounded guidelines for SupCL to prevent class collapse\nin learned representations. Specifically, we introduce the Simplex-to-Simplex\nEmbedding Model (SSEM), a theoretical framework that models various embedding\nstructures, including all embeddings that minimize the supervised contrastive\nloss. Through SSEM, we analyze how hyperparameters affect learned\nrepresentations, offering practical guidelines for hyperparameter selection to\nmitigate the risk of class collapse. Our theoretical findings are supported by\nempirical results across synthetic and real-world datasets.\n","authors":["Chungpa Lee","Jeongheon Oh","Kibok Lee","Jy-yong Sohn"],"pdf_url":"https://arxiv.org/pdf/2503.08203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08200v1","updated":"2025-03-11T09:08:07Z","published":"2025-03-11T09:08:07Z","title":"Route Sparse Autoencoder to Interpret Large Language Models","summary":"  Mechanistic interpretability of large language models (LLMs) aims to uncover\nthe internal processes of information propagation and reasoning. Sparse\nautoencoders (SAEs) have demonstrated promise in this domain by extracting\ninterpretable and monosemantic features. However, prior works primarily focus\non feature extraction from a single layer, failing to effectively capture\nactivations that span multiple layers. In this paper, we introduce Route Sparse\nAutoencoder (RouteSAE), a new framework that integrates a routing mechanism\nwith a shared SAE to efficiently extract features from multiple layers. It\ndynamically assigns weights to activations from different layers, incurring\nminimal parameter overhead while achieving high interpretability and\nflexibility for targeted feature manipulation. We evaluate RouteSAE through\nextensive experiments on Llama-3.2-1B-Instruct. Specifically, under the same\nsparsity constraint of 64, RouteSAE extracts 22.5% more features than baseline\nSAEs while achieving a 22.3% higher interpretability score. These results\nunderscore the potential of RouteSAE as a scalable and effective method for LLM\ninterpretability, with applications in feature discovery and model\nintervention. Our codes are available at https://github.com/swei2001/RouteSAEs.\n","authors":["Wei Shi","Sihang Li","Tao Liang","Mingyang Wan","Gojun Ma","Xiang Wang","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2503.08200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08199v1","updated":"2025-03-11T09:08:04Z","published":"2025-03-11T09:08:04Z","title":"A Cascading Cooperative Multi-agent Framework for On-ramp Merging\n  Control Integrating Large Language Models","summary":"  Traditional Reinforcement Learning (RL) suffers from replicating human-like\nbehaviors, generalizing effectively in multi-agent scenarios, and overcoming\ninherent interpretability issues.These tasks are compounded when deep\nenvironment understanding, agent coordination and dynamic optimization are\nrequired. While Large Language Model (LLM) enhanced methods have shown promise\nin generalization and interoperability, they often neglect necessary\nmulti-agent coordination. Therefore, we introduce the Cascading Cooperative\nMulti-agent (CCMA) framework, integrating RL for individual interactions, a\nfine-tuned LLM for regional cooperation, a reward function for global\noptimization, and the Retrieval-augmented Generation mechanism to dynamically\noptimize decision-making across complex driving scenarios. Our experiments\ndemonstrate that the CCMA outperforms existing RL methods, demonstrating\nsignificant improvements in both micro and macro-level performance in complex\ndriving environments.\n","authors":["Miao Zhang","Zhenlong Fang","Tianyi Wang","Qian Zhang","Shuai Lu","Junfeng Jiao","Tianyu Shi"],"pdf_url":"https://arxiv.org/pdf/2503.08199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00229v2","updated":"2025-03-11T09:07:55Z","published":"2024-10-31T21:54:44Z","title":"Minimum Empirical Divergence for Sub-Gaussian Linear Bandits","summary":"  We propose a novel linear bandit algorithm called LinMED (Linear Minimum\nEmpirical Divergence), which is a linear extension of the MED algorithm that\nwas originally designed for multi-armed bandits. LinMED is a randomized\nalgorithm that admits a closed-form computation of the arm sampling\nprobabilities, unlike the popular randomized algorithm called linear Thompson\nsampling. Such a feature proves useful for off-policy evaluation where the\nunbiased evaluation requires accurately computing the sampling probability. We\nprove that LinMED enjoys a near-optimal regret bound of $d\\sqrt{n}$ up to\nlogarithmic factors where $d$ is the dimension and $n$ is the time horizon. We\nfurther show that LinMED enjoys a\n$\\frac{d^2}{\\Delta}\\left(\\log^2(n)\\right)\\log\\left(\\log(n)\\right)$\nproblem-dependent regret where $\\Delta$ is the smallest sub-optimality gap. Our\nempirical study shows that LinMED has a competitive performance with the\nstate-of-the-art algorithms.\n","authors":["Kapilan Balagopalan","Kwang-Sung Jun"],"pdf_url":"https://arxiv.org/pdf/2411.00229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00153v3","updated":"2025-03-11T09:07:31Z","published":"2024-11-29T07:00:18Z","title":"ROSE: Revolutionizing Open-Set Dense Segmentation with Patch-Wise\n  Perceptual Large Multimodal Model","summary":"  Advances in CLIP and large multimodal models (LMMs) have enabled\nopen-vocabulary and free-text segmentation, yet existing models still require\npredefined category prompts, limiting free-form category self-generation. Most\nsegmentation LMMs also remain confined to sparse predictions, restricting their\napplicability in open-set environments. In contrast, we propose ROSE, a\nRevolutionary Open-set dense SEgmentation LMM, which enables dense mask\nprediction and open-category generation through patch-wise perception. Our\nmethod treats each image patch as an independent region of interest candidate,\nenabling the model to predict both dense and sparse masks simultaneously.\nAdditionally, a newly designed instruction-response paradigm takes full\nadvantage of the generation and generalization capabilities of LMMs, achieving\ncategory prediction independent of closed-set constraints or predefined\ncategories. To further enhance mask detail and category precision, we introduce\na conversation-based refinement paradigm, integrating the prediction result\nfrom previous step with textual prompt for revision. Extensive experiments\ndemonstrate that ROSE achieves competitive performance across various\nsegmentation tasks in a unified framework. Code will be released.\n","authors":["Kunyang Han","Yibo Hu","Mengxue Qu","Hailin Shi","Yao Zhao","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2412.00153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06873v2","updated":"2025-03-11T09:06:03Z","published":"2025-03-10T02:52:47Z","title":"Interactive Medical Image Analysis with Concept-based Similarity\n  Reasoning","summary":"  The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.\n","authors":["Ta Duc Huy","Sen Kim Tran","Phan Nguyen","Nguyen Hoang Tran","Tran Bao Sam","Anton van den Hengel","Zhibin Liao","Johan W. Verjans","Minh-Son To","Vu Minh Hieu Phan"],"pdf_url":"https://arxiv.org/pdf/2503.06873v2.pdf","comment":"Accepted CVPR2025"},{"id":"http://arxiv.org/abs/2309.12862v4","updated":"2025-03-11T09:04:22Z","published":"2023-09-22T13:37:10Z","title":"Associative Transformer","summary":"  Emerging from the pairwise attention in conventional Transformers, there is a\ngrowing interest in sparse attention mechanisms that align more closely with\nlocalized, contextual learning in the biological brain. Existing studies such\nas the Coordination method employ iterative cross-attention mechanisms with a\nbottleneck to enable the sparse association of inputs. However, these methods\nare parameter inefficient and fail in more complex relational reasoning tasks.\nTo this end, we propose Associative Transformer (AiT) to enhance the\nassociation among sparsely attended input tokens, improving parameter\nefficiency and performance in various vision tasks such as classification and\nrelational reasoning. AiT leverages a learnable explicit memory comprising\nspecialized priors that guide bottleneck attentions to facilitate the\nextraction of diverse localized tokens. Moreover, AiT employs an associative\nmemory-based token reconstruction using a Hopfield energy function. The\nextensive empirical experiments demonstrate that AiT requires significantly\nfewer parameters and attention layers outperforming a broad range of sparse\nTransformer models. Additionally, AiT outperforms the SOTA sparse Transformer\nmodels including the Coordination method on the Sort-of-CLEVR dataset.\n","authors":["Yuwei Sun","Hideya Ochiai","Zhirong Wu","Stephen Lin","Ryota Kanai"],"pdf_url":"https://arxiv.org/pdf/2309.12862v4.pdf","comment":"Accepted for CVPR 2025"},{"id":"http://arxiv.org/abs/2501.13456v4","updated":"2025-03-11T08:59:12Z","published":"2025-01-23T08:14:55Z","title":"KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) with attention mechanisms, often referred to as\nattentive GNNs, have emerged as a prominent paradigm in advanced GNN models in\nrecent years. However, our understanding of the critical process of scoring\nneighbor nodes remains limited, leading to the underperformance of many\nexisting attentive GNNs. In this paper, we unify the scoring functions of\ncurrent attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which\nintegrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring\nprocess. KAA enhances the performance of scoring functions across the board and\ncan be applied to nearly all existing attentive GNNs. To compare the expressive\npower of KAA with other scoring functions, we introduce Maximum Ranking\nDistance (MRD) to quantitatively estimate their upper bounds in ranking errors\nfor node importance. Our analysis reveals that, under limited parameters and\nconstraints on width and depth, both linear transformation-based and MLP-based\nscoring functions exhibit finite expressive power. In contrast, our proposed\nKAA, even with a single-layer KAN parameterized by zero-order B-spline\nfunctions, demonstrates nearly infinite expressive power. Extensive experiments\non both node-level and graph-level tasks using various backbone models show\nthat KAA-enhanced scoring functions consistently outperform their original\ncounterparts, achieving performance improvements of over 20% in some cases.\n","authors":["Taoran Fang","Tianhong Gao","Chunping Wang","Yihao Shang","Wei Chow","Lei Chen","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13456v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10663v2","updated":"2025-03-11T08:58:21Z","published":"2024-10-14T16:09:38Z","title":"Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework","summary":"  Most existing studies on few-shot learning focus on unimodal settings, where\nmodels are trained to generalize to unseen data using a limited amount of\nlabeled examples from a single modality. However, real-world data are\ninherently multi-modal, and such unimodal approaches limit the practical\napplications of few-shot learning. To bridge this gap, this paper introduces\nthe Cross-modal Few-Shot Learning (CFSL) task, which aims to recognize\ninstances across multiple modalities while relying on scarce labeled data. This\ntask presents unique challenges compared to classical few-shot learning arising\nfrom the distinct visual attributes and structural disparities inherent to each\nmodality. To tackle these challenges, we propose a Generative Transfer Learning\n(GTL) framework by simulating how humans abstract and generalize concepts.\nSpecifically, the GTL jointly estimates the latent shared concept across\nmodalities and the in-modality disturbance through a generative structure.\nEstablishing the relationship between latent concepts and visual content among\nabundant unimodal data enables GTL to effectively transfer knowledge from\nunimodal to novel multimodal data, as humans did. Comprehensive experiments\ndemonstrate that the GTL achieves state-of-the-art performance across seven\nmulti-modal datasets across RGB-Sketch, RGB-Infrared, and RGB-Depth.\n","authors":["Zhengwei Yang","Yuke Li","Qiang Sun","Basura Fernando","Heng Huang","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.10663v2.pdf","comment":"15 pages, 9 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.08192v1","updated":"2025-03-11T08:55:52Z","published":"2025-03-11T08:55:52Z","title":"Automating Violence Detection and Categorization from Ancient Texts","summary":"  Violence descriptions in literature offer valuable insights for a wide range\nof research in the humanities. For historians, depictions of violence are of\nspecial interest for analyzing the societal dynamics surrounding large wars and\nindividual conflicts of influential people. Harvesting data for violence\nresearch manually is laborious and time-consuming. This study is the first one\nto evaluate the effectiveness of large language models (LLMs) in identifying\nviolence in ancient texts and categorizing it across multiple dimensions. Our\nexperiments identify LLMs as a valuable tool to scale up the accurate analysis\nof historical texts and show the effect of fine-tuning and data augmentation,\nyielding an F1-score of up to 0.93 for violence detection and 0.86 for\nfine-grained violence categorization.\n","authors":["Alhassan Abdelhalim","Michaela Regneri"],"pdf_url":"https://arxiv.org/pdf/2503.08192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14856v2","updated":"2025-03-11T08:54:55Z","published":"2025-02-20T18:58:10Z","title":"FR-Spec: Accelerating Large-Vocabulary Language Models via\n  Frequency-Ranked Speculative Sampling","summary":"  Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12$\\times$ speedup over the\nstate-of-the-art speculative sampling method EAGLE-2. Code available at\nhttps://github.com/thunlp/FR-Spec.\n","authors":["Weilin Zhao","Tengyu Pan","Xu Han","Yudi Zhang","Ao Sun","Yuxiang Huang","Kaihuo Zhang","Weilun Zhao","Yuxuan Li","Jianyong Wang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.03405v2","updated":"2025-03-11T08:27:55Z","published":"2025-02-05T17:47:53Z","title":"Deep Clustering via Probabilistic Ratio-Cut Optimization","summary":"  We propose a novel approach for optimizing the graph ratio-cut by modeling\nthe binary assignments as random variables. We provide an upper bound on the\nexpected ratio-cut, as well as an unbiased estimate of its gradient, to learn\nthe parameters of the assignment variables in an online setting. The clustering\nresulting from our probabilistic approach (PRCut) outperforms the Rayleigh\nquotient relaxation of the combinatorial problem, its online learning\nextensions, and several widely used methods. We demonstrate that the PRCut\nclustering closely aligns with the similarity measure and can perform as well\nas a supervised classifier when label-based similarities are provided. This\nnovel approach can leverage out-of-the-box self-supervised representations to\nachieve competitive performance and serve as an evaluation method for the\nquality of these representations.\n","authors":["Ayoub Ghriss","Claire Monteleoni"],"pdf_url":"https://arxiv.org/pdf/2502.03405v2.pdf","comment":"Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume\n  258"},{"id":"http://arxiv.org/abs/2503.08163v1","updated":"2025-03-11T08:27:08Z","published":"2025-03-11T08:27:08Z","title":"XAI4Extremes: An interpretable machine learning framework for\n  understanding extreme-weather precursors under climate change","summary":"  Extreme weather events are increasing in frequency and intensity due to\nclimate change. This, in turn, is exacting a significant toll in communities\nworldwide. While prediction skills are increasing with advances in numerical\nweather prediction and artificial intelligence tools, extreme weather still\npresent challenges. More specifically, identifying the precursors of such\nextreme weather events and how these precursors may evolve under climate change\nremain unclear. In this paper, we propose to use post-hoc interpretability\nmethods to construct relevance weather maps that show the key extreme-weather\nprecursors identified by deep learning models. We then compare this machine\nview with existing domain knowledge to understand whether deep learning models\nidentified patterns in data that may enrich our understanding of\nextreme-weather precursors. We finally bin these relevant maps into different\nmulti-year time periods to understand the role that climate change is having on\nthese precursors. The experiments are carried out on Indochina heatwaves, but\nthe methodology can be readily extended to other extreme weather events\nworldwide.\n","authors":["Jiawen Wei","Aniruddha Bora","Vivek Oommen","Chenyu Dong","Juntao Yang","Jeff Adie","Chen Chen","Simon See","George Karniadakis","Gianmarco Mengaldo"],"pdf_url":"https://arxiv.org/pdf/2503.08163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05810v2","updated":"2025-03-11T08:22:15Z","published":"2025-03-04T10:18:32Z","title":"A Transformer Model for Predicting Chemical Reaction Products from\n  Generic Templates","summary":"  The accurate prediction of chemical reaction outcomes is a major challenge in\ncomputational chemistry. Current models rely heavily on either highly specific\nreaction templates or template-free methods, both of which present limitations.\nTo address these limitations, this work proposes the Broad Reaction Set (BRS),\na dataset featuring 20 generic reaction templates that allow for the efficient\nexploration of the chemical space. Additionally, ProPreT5 is introduced, a T5\nmodel tailored to chemistry that achieves a balance between rigid templates and\ntemplate-free methods. ProPreT5 demonstrates its capability to generate\naccurate, valid, and realistic reaction products, making it a promising\nsolution that goes beyond the current state-of-the-art on the complex reaction\nproduct prediction task.\n","authors":["Derin Ozer","Sylvain Lamprier","Thomas Cauchy","Nicolas Gutowski","Benoit Da Mota"],"pdf_url":"https://arxiv.org/pdf/2503.05810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08160v1","updated":"2025-03-11T08:21:57Z","published":"2025-03-11T08:21:57Z","title":"Concept-Driven Deep Learning for Enhanced Protein-Specific Molecular\n  Generation","summary":"  In recent years, deep learning techniques have made significant strides in\nmolecular generation for specific targets, driving advancements in drug\ndiscovery. However, existing molecular generation methods present significant\nlimitations: those operating at the atomic level often lack synthetic\nfeasibility, drug-likeness, and interpretability, while fragment-based\napproaches frequently overlook comprehensive factors that influence\nprotein-molecule interactions. To address these challenges, we propose a novel\nfragment-based molecular generation framework tailored for specific proteins.\nOur method begins by constructing a protein subpocket and molecular arm\nconcept-based neural network, which systematically integrates interaction force\ninformation and geometric complementarity to sample molecular arms for specific\nprotein subpockets. Subsequently, we introduce a diffusion model to generate\nmolecular backbones that connect these arms, ensuring structural integrity and\nchemical diversity. Our approach significantly improves synthetic feasibility\nand binding affinity, with a 4% increase in drug-likeness and a 6% improvement\nin synthetic feasibility. Furthermore, by integrating explicit interaction data\nthrough a concept-based model, our framework enhances interpretability,\noffering valuable insights into the molecular design process.\n","authors":["Taojie Kuang","Qianli Ma","Athanasios V. Vasilakos","Yu Wang"," Qiang"," Cheng","Zhixiang Ren"],"pdf_url":"https://arxiv.org/pdf/2503.08160v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19517v4","updated":"2025-03-11T08:21:06Z","published":"2024-11-29T07:23:34Z","title":"RL-MILP Solver: A Reinforcement Learning Approach for Solving\n  Mixed-Integer Linear Programs with Graph Neural Networks","summary":"  Mixed-integer linear programming (MILP) is a widely used optimization\ntechnique across various fields. Existing $\\textit{end-to-end learning}$\nmethods for MILP generate values for a subset of decision variables and\ndelegate the remaining problem to traditional MILP solvers. However, this\napproach often fails to guarantee solution feasibility (i.e., satisfying all\nconstraints) due to inaccurate predictions and primarily focuses on binary\ndecision variables. Satisfying all constraints is a prerequisite for obtaining\nthe optimal solution, and the feasibility issue becomes even more critical with\nnon-binary integer (integer, for short) variables. Thus, addressing the\nfeasibility of MILP involving integer variables is crucial. To address these\nchallenges, we propose a novel reinforcement learning (RL)-based solver that\nnot only finds the first feasible solution but also incrementally discovers\nbetter feasible solutions without delegating the remainder to off-the-shelf\nsolvers. Our experimental results demonstrate that the proposed method achieves\n(near-)optimal solutions.\n","authors":["Tae-Hoon Lee","Min-Soo Kim"],"pdf_url":"https://arxiv.org/pdf/2411.19517v4.pdf","comment":"Extended version (17 pages, 8 figures). Accepted at the 2025 AAAI\n  Workshop on AI to Accelerate Science and Engineering (AI2ASE)"},{"id":"http://arxiv.org/abs/2503.08156v1","updated":"2025-03-11T08:11:23Z","published":"2025-03-11T08:11:23Z","title":"Towards Large-scale Chemical Reaction Image Parsing via a Multimodal\n  Large Language Model","summary":"  Artificial intelligence (AI) has demonstrated significant promise in\nadvancing organic chemistry research; however, its effectiveness depends on the\navailability of high-quality chemical reaction data. Currently, most published\nchemical reactions are not available in machine-readable form, limiting the\nbroader application of AI in this field. The extraction of published chemical\nreactions into structured databases still relies heavily on manual curation,\nand robust automatic parsing of chemical reaction images into machine-readable\ndata remains a significant challenge. To address this, we introduce the\nReaction Image Multimodal large language model (RxnIM), the first multimodal\nlarge language model specifically designed to parse chemical reaction images\ninto machine-readable reaction data. RxnIM not only extracts key chemical\ncomponents from reaction images but also interprets the textual content that\ndescribes reaction conditions. Together with specially designed large-scale\ndataset generation method to support model training, our approach achieves\nexcellent performance, with an average F1 score of 88% on various benchmarks,\nsurpassing literature methods by 5%. This represents a crucial step toward the\nautomatic construction of large databases of machine-readable reaction data\nparsed from images in the chemistry literature, providing essential data\nresources for AI research in chemistry. The source code, model checkpoints, and\ndatasets developed in this work are released under permissive licenses. An\ninstance of the RxnIM web application can be accessed at\nhttps://huggingface.co/spaces/CYF200127/RxnIM.\n","authors":["Yufan Chen","Ching Ting Leung","Jianwei Sun","Yong Huang","Linyan Li","Hao Chen","Hanyu Gao"],"pdf_url":"https://arxiv.org/pdf/2503.08156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08155v1","updated":"2025-03-11T08:10:03Z","published":"2025-03-11T08:10:03Z","title":"Domain Adaptation and Entanglement: an Optimal Transport Perspective","summary":"  Current machine learning systems are brittle in the face of distribution\nshifts (DS), where the target distribution that the system is tested on differs\nfrom the source distribution used to train the system. This problem of\nrobustness to DS has been studied extensively in the field of domain\nadaptation. For deep neural networks, a popular framework for unsupervised\ndomain adaptation (UDA) is domain matching, in which algorithms\n  try to align the marginal distributions in the feature or output space.\n  The current theoretical understanding of these methods, however, is limited\nand existing theoretical results are not precise enough to characterize their\nperformance in practice.\n  In this paper, we derive new bounds based on optimal transport that analyze\nthe UDA problem. Our new bounds include a term which we dub as\n\\emph{entanglement}, consisting of an expectation of Wasserstein distance\nbetween conditionals with respect to changing data distributions. Analysis of\nthe entanglement term provides a novel perspective on the unoptimizable aspects\nof UDA. In various experiments with multiple models across several DS\nscenarios, we show that this term can be used to explain the varying\nperformance of UDA algorithms.\n","authors":["Okan Koç","Alexander Soen","Chao-Kai Chiang","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2503.08155v1.pdf","comment":"Accepted for publication in AISTATS'25"},{"id":"http://arxiv.org/abs/2308.07037v6","updated":"2025-03-11T08:07:39Z","published":"2023-08-14T09:56:35Z","title":"Bayesian Flow Networks","summary":"  This paper introduces Bayesian Flow Networks (BFNs), a new class of\ngenerative model in which the parameters of a set of independent distributions\nare modified with Bayesian inference in the light of noisy data samples, then\npassed as input to a neural network that outputs a second, interdependent\ndistribution. Starting from a simple prior and iteratively updating the two\ndistributions yields a generative procedure similar to the reverse process of\ndiffusion models; however it is conceptually simpler in that no forward process\nis required. Discrete and continuous-time loss functions are derived for\ncontinuous, discretised and discrete data, along with sample generation\nprocedures. Notably, the network inputs for discrete data lie on the\nprobability simplex, and are therefore natively differentiable, paving the way\nfor gradient-based sample guidance and few-step generation in discrete domains\nsuch as language modelling. The loss function directly optimises data\ncompression and places no restrictions on the network architecture. In our\nexperiments BFNs achieve competitive log-likelihoods for image modelling on\ndynamically binarized MNIST and CIFAR-10, and outperform all known discrete\ndiffusion models on the text8 character-level language modelling task.\n","authors":["Alex Graves","Rupesh Kumar Srivastava","Timothy Atkinson","Faustino Gomez"],"pdf_url":"https://arxiv.org/pdf/2308.07037v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15658v3","updated":"2025-03-11T08:04:26Z","published":"2023-11-27T09:40:14Z","title":"Regularization by Texts for Latent Diffusion Inverse Solvers","summary":"  The recent development of diffusion models has led to significant progress in\nsolving inverse problems by leveraging these models as powerful generative\npriors. However, challenges persist due to the ill-posed nature of such\nproblems, often arising from ambiguities in measurements or intrinsic system\nsymmetries. To address this, here we introduce a novel latent diffusion inverse\nsolver, regularization by text (TReg), inspired by the human ability to resolve\nvisual ambiguities through perceptual biases. TReg integrates textual\ndescriptions of preconceptions about the solution during reverse diffusion\nsampling, dynamically reinforcing these descriptions through null-text\noptimization, which we refer to as adaptive negation. Our comprehensive\nexperimental results demonstrate that TReg effectively mitigates ambiguity in\ninverse problems, improving both accuracy and efficiency.\n","authors":["Jeongsol Kim","Geon Yeong Park","Hyungjin Chung","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15658v3.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2503.08141v1","updated":"2025-03-11T07:59:56Z","published":"2025-03-11T07:59:56Z","title":"Scaling Probabilistic Circuits via Data Partitioning","summary":"  Probabilistic circuits (PCs) enable us to learn joint distributions over a\nset of random variables and to perform various probabilistic queries in a\ntractable fashion. Though the tractability property allows PCs to scale beyond\nnon-tractable models such as Bayesian Networks, scaling training and inference\nof PCs to larger, real-world datasets remains challenging. To remedy the\nsituation, we show how PCs can be learned across multiple machines by\nrecursively partitioning a distributed dataset, thereby unveiling a deep\nconnection between PCs and federated learning (FL). This leads to federated\ncircuits (FCs) -- a novel and flexible federated learning (FL) framework that\n(1) allows one to scale PCs on distributed learning environments (2) train PCs\nfaster and (3) unifies for the first time horizontal, vertical, and hybrid FL\nin one framework by re-framing FL as a density estimation problem over\ndistributed datasets. We demonstrate FC's capability to scale PCs on various\nlarge-scale datasets. Also, we show FC's versatility in handling horizontal,\nvertical, and hybrid FL within a unified framework on multiple classification\ntasks.\n","authors":["Jonas Seng","Florian Peter Busch","Pooja Prasad","Devendra Singh Dhami","Martin Mundt","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2503.08141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08136v1","updated":"2025-03-11T07:56:14Z","published":"2025-03-11T07:56:14Z","title":"FlowDPS: Flow-Driven Posterior Sampling for Inverse Problems","summary":"  Flow matching is a recent state-of-the-art framework for generative modeling\nbased on ordinary differential equations (ODEs). While closely related to\ndiffusion models, it provides a more general perspective on generative\nmodeling. Although inverse problem solving has been extensively explored using\ndiffusion models, it has not been rigorously examined within the broader\ncontext of flow models. Therefore, here we extend the diffusion inverse solvers\n(DIS) - which perform posterior sampling by combining a denoising diffusion\nprior with an likelihood gradient - into the flow framework. Specifically, by\ndriving the flow-version of Tweedie's formula, we decompose the flow ODE into\ntwo components: one for clean image estimation and the other for noise\nestimation. By integrating the likelihood gradient and stochastic noise into\neach component, respectively, we demonstrate that posterior sampling for\ninverse problem solving can be effectively achieved using flows. Our proposed\nsolver, Flow-Driven Posterior Sampling (FlowDPS), can also be seamlessly\nintegrated into a latent flow model with a transformer architecture. Across\nfour linear inverse problems, we confirm that FlowDPS outperforms\nstate-of-the-art alternatives, all without requiring additional training.\n","authors":["Jeongsol Kim","Bryan Sangwoo Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2503.08136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15247v3","updated":"2025-03-11T07:55:18Z","published":"2024-11-22T08:00:20Z","title":"Reward Fine-Tuning Two-Step Diffusion Models via Learning Differentiable\n  Latent-Space Surrogate Reward","summary":"  Recent research has shown that fine-tuning diffusion models (DMs) with\narbitrary rewards, including non-differentiable ones, is feasible with\nreinforcement learning (RL) techniques, enabling flexible model alignment.\nHowever, applying existing RL methods to step-distilled DMs is challenging for\nultra-fast ($\\le2$-step) image generation. Our analysis suggests several\nlimitations of policy-based RL methods such as PPO or DPO toward this goal.\nBased on the insights, we propose fine-tuning DMs with learned differentiable\nsurrogate rewards. Our method, named LaSRO, learns surrogate reward models in\nthe latent space of SDXL to convert arbitrary rewards into differentiable ones\nfor effective reward gradient guidance. LaSRO leverages pre-trained latent DMs\nfor reward modeling and tailors reward optimization for $\\le2$-step image\ngeneration with efficient off-policy exploration. LaSRO is effective and stable\nfor improving ultra-fast image generation with different reward objectives,\noutperforming popular RL methods including DDPO and Diffusion-DPO. We further\nshow LaSRO's connection to value-based RL, providing theoretical insights. See\nour webpage \\href{https://sites.google.com/view/lasro}{here}.\n","authors":["Zhiwei Jia","Yuesong Nan","Huixi Zhao","Gengdai Liu"],"pdf_url":"https://arxiv.org/pdf/2411.15247v3.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08131v1","updated":"2025-03-11T07:46:19Z","published":"2025-03-11T07:46:19Z","title":"Large Scale Multi-Task Bayesian Optimization with Large Language Models","summary":"  In multi-task Bayesian optimization, the goal is to leverage experience from\noptimizing existing tasks to improve the efficiency of optimizing new ones.\nWhile approaches using multi-task Gaussian processes or deep kernel transfer\nexist, the performance improvement is marginal when scaling to more than a\nmoderate number of tasks. We introduce a novel approach leveraging large\nlanguage models (LLMs) to learn from, and improve upon, previous optimization\ntrajectories, scaling to approximately 2000 distinct tasks. Specifically, we\npropose an iterative framework in which an LLM is fine-tuned using the high\nquality solutions produced by BayesOpt to generate improved initializations\nthat accelerate convergence for future optimization tasks based on previous\nsearch trajectories. We evaluate our method on two distinct domains: database\nquery optimization and antimicrobial peptide design. Results demonstrate that\nour approach creates a positive feedback loop, where the LLM's generated\ninitializations gradually improve, leading to better optimization performance.\nAs this feedback loop continues, we find that the LLM is eventually able to\ngenerate solutions to new tasks in just a few shots that are better than the\nsolutions produced by \"from scratch\" by Bayesian optimization while\nsimultaneously requiring significantly fewer oracle calls.\n","authors":["Yimeng Zeng","Natalie Maus","Haydn Thomas Jones","Jeffrey Tao","Fangping Wan","Marcelo Der Torossian Torres","Cesar de la Fuente-Nunez","Ryan Marcus","Osbert Bastani","Jacob R. Gardner"],"pdf_url":"https://arxiv.org/pdf/2503.08131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08122v1","updated":"2025-03-11T07:38:11Z","published":"2025-03-11T07:38:11Z","title":"Toward Stable World Models: Measuring and Addressing World Instability\n  in Generative Environments","summary":"  We present a novel study on enhancing the capability of preserving the\ncontent in world models, focusing on a property we term World Stability. Recent\ndiffusion-based generative models have advanced the synthesis of immersive and\nrealistic environments that are pivotal for applications such as reinforcement\nlearning and interactive game engines. However, while these models excel in\nquality and diversity, they often neglect the preservation of previously\ngenerated scenes over time--a shortfall that can introduce noise into agent\nlearning and compromise performance in safety-critical settings. In this work,\nwe introduce an evaluation framework that measures world stability by having\nworld models perform a sequence of actions followed by their inverses to return\nto their initial viewpoint, thereby quantifying the consistency between the\nstarting and ending observations. Our comprehensive assessment of\nstate-of-the-art diffusion-based world models reveals significant challenges in\nachieving high world stability. Moreover, we investigate several improvement\nstrategies to enhance world stability. Our results underscore the importance of\nworld stability in world modeling and provide actionable insights for future\nresearch in this domain.\n","authors":["Soonwoo Kwon","Jin-Young Kim","Hyojun Go","Kyungjune Baek"],"pdf_url":"https://arxiv.org/pdf/2503.08122v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.08120v1","updated":"2025-03-11T07:34:59Z","published":"2025-03-11T07:34:59Z","title":"Uni$\\textbf{F}^2$ace: Fine-grained Face Understanding and Generation\n  with Unified Multimodal Models","summary":"  Unified multimodal models (UMMs) have emerged as a powerful paradigm in\nfoundational computer vision research, demonstrating significant potential in\nboth image understanding and generation. However, existing research in the face\ndomain primarily focuses on $\\textbf{coarse}$ facial attribute understanding,\nwith limited capacity to handle $\\textbf{fine-grained}$ facial attributes and\nwithout addressing generation capabilities. To overcome these limitations, we\npropose Uni$\\textbf{F}^2$ace, the first UMM tailored specifically for\nfine-grained face understanding and generation. In general, we train\nUni$\\textbf{F}^2$ace on a self-constructed, specialized dataset utilizing two\nmutually beneficial diffusion techniques and a two-level mixture-of-experts\narchitecture. Specifically, we first build a large-scale facial dataset,\nUni$\\textbf{F}^2$ace-130K, which contains 130K image-text pairs with one\nmillion question-answering pairs that span a wide range of facial attributes.\nSecond, we establish a theoretical connection between discrete diffusion score\nmatching and masked generative models, optimizing both evidence lower bounds\nsimultaneously, which significantly improves the model's ability to synthesize\nfacial details. Finally, we introduce both token-level and sequence-level\nmixture-of-experts, enabling efficient fine-grained representation learning for\nboth understanding and generation tasks. Extensive experiments on\nUni$\\textbf{F}^2$ace-130K demonstrate that Uni$\\textbf{F}^2$ace outperforms\nexisting UMMs and generative models, achieving superior performance across both\nunderstanding and generation tasks.\n","authors":["Junzhe Li","Xuerui Qiu","Linrui Xu","Liya Guo","Delin Qu","Tingting Long","Chun Fan","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2503.08120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08117v1","updated":"2025-03-11T07:30:25Z","published":"2025-03-11T07:30:25Z","title":"Convergence Dynamics and Stabilization Strategies of Co-Evolving\n  Generative Models","summary":"  The increasing prevalence of synthetic data in training loops has raised\nconcerns about model collapse, where generative models degrade when trained on\ntheir own outputs. While prior work focuses on this self-consuming process, we\nstudy an underexplored yet prevalent phenomenon: co-evolving generative models\nthat shape each other's training through iterative feedback. This is common in\nmultimodal AI ecosystems, such as social media platforms, where text models\ngenerate captions that guide image models, and the resulting images influence\nthe future adaptation of the text model. We take a first step by analyzing such\na system, modeling the text model as a multinomial distribution and the image\nmodel as a conditional multi-dimensional Gaussian distribution. Our analysis\nuncovers three key results. First, when one model remains fixed, the other\ncollapses: a frozen image model causes the text model to lose diversity, while\na frozen text model leads to an exponential contraction of image diversity,\nthough fidelity remains bounded. Second, in fully interactive systems, mutual\nreinforcement accelerates collapse, with image contraction amplifying text\nhomogenization and vice versa, leading to a Matthew effect where dominant texts\nsustain higher image diversity while rarer texts collapse faster. Third, we\nanalyze stabilization strategies implicitly introduced by real-world external\ninfluences. Random corpus injections for text models and user-content\ninjections for image models prevent collapse while preserving both diversity\nand fidelity. Our theoretical findings are further validated through\nexperiments.\n","authors":["Weiguo Gao","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2503.08117v1.pdf","comment":"37 pages, 11 figures"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2503.08684v1","updated":"2025-03-11T17:59:00Z","published":"2025-03-11T17:59:00Z","title":"Perplexity Trap: PLM-Based Retrievers Overrate Low Perplexity Documents","summary":"  Previous studies have found that PLM-based retrieval models exhibit a\npreference for LLM-generated content, assigning higher relevance scores to\nthese documents even when their semantic quality is comparable to human-written\nones. This phenomenon, known as source bias, threatens the sustainable\ndevelopment of the information access ecosystem. However, the underlying causes\nof source bias remain unexplored. In this paper, we explain the process of\ninformation retrieval with a causal graph and discover that PLM-based\nretrievers learn perplexity features for relevance estimation, causing source\nbias by ranking the documents with low perplexity higher. Theoretical analysis\nfurther reveals that the phenomenon stems from the positive correlation between\nthe gradients of the loss functions in language modeling task and retrieval\ntask. Based on the analysis, a causal-inspired inference-time debiasing method\nis proposed, called Causal Diagnosis and Correction (CDC). CDC first diagnoses\nthe bias effect of the perplexity and then separates the bias effect from the\noverall estimated relevance score. Experimental results across three domains\ndemonstrate the superior debiasing effectiveness of CDC, emphasizing the\nvalidity of our proposed explanatory framework. Source codes are available at\nhttps://github.com/WhyDwelledOnAi/Perplexity-Trap.\n","authors":["Haoyu Wang","Sunhao Dai","Haiyuan Zhao","Liang Pang","Xiao Zhang","Gang Wang","Zhenhua Dong","Jun Xu","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.08684v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08683v1","updated":"2025-03-11T17:58:42Z","published":"2025-03-11T17:58:42Z","title":"CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous\n  Driving","summary":"  Vehicle-to-vehicle (V2V) cooperative autonomous driving holds great promise\nfor improving safety by addressing the perception and prediction uncertainties\ninherent in single-agent systems. However, traditional cooperative methods are\nconstrained by rigid collaboration protocols and limited generalization to\nunseen interactive scenarios. While LLM-based approaches offer generalized\nreasoning capabilities, their challenges in spatial planning and unstable\ninference latency hinder their direct application in cooperative driving. To\naddress these limitations, we propose CoLMDriver, the first full-pipeline\nLLM-based cooperative driving system, enabling effective language-based\nnegotiation and real-time driving control. CoLMDriver features a parallel\ndriving pipeline with two key components: (i) an LLM-based negotiation module\nunder an actor-critic paradigm, which continuously refines cooperation policies\nthrough feedback from previous decisions of all vehicles; and (ii) an\nintention-guided waypoint generator, which translates negotiation outcomes into\nexecutable waypoints. Additionally, we introduce InterDrive, a CARLA-based\nsimulation benchmark comprising 10 challenging interactive driving scenarios\nfor evaluating V2V cooperation. Experimental results demonstrate that\nCoLMDriver significantly outperforms existing approaches, achieving an 11%\nhigher success rate across diverse highly interactive V2V driving scenarios.\nCode will be released on https://github.com/cxliu0314/CoLMDriver.\n","authors":["Changxing Liu","Genjia Liu","Zijun Wang","Jinchang Yang","Siheng Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08679v1","updated":"2025-03-11T17:56:30Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal concerning rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (30.6%), DeepSeek R1 (15.8%) and\nChatGPT-4o (12.6%) all answer a high proportion of question pairs unfaithfully.\nSpecifically, we find that models rationalize their implicit biases in answers\nto binary questions (\"implicit post-hoc rationalization\"). For example, when\nseparately presented with the questions \"Is X bigger than Y?\" and \"Is Y bigger\nthan X?\", models sometimes produce superficially coherent arguments to justify\nanswering Yes to both questions or No to both questions, despite such responses\nbeing logically contradictory. We also investigate restoration errors (Dziri et\nal., 2023), where models make and then silently correct errors in their\nreasoning, and unfaithful shortcuts, where models use clearly illogical\nreasoning to simplify solving problems in Putnam questions (a hard benchmark).\nOur findings raise challenges for AI safety work that relies on monitoring CoT\nto detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v1.pdf","comment":"Accepted to the ICLR 2025 Workshop, 10 main paper pages, 38 appendix\n  pages"},{"id":"http://arxiv.org/abs/2503.08678v1","updated":"2025-03-11T17:56:03Z","published":"2025-03-11T17:56:03Z","title":"GarmentCrafter: Progressive Novel View Synthesis for Single-View 3D\n  Garment Reconstruction and Editing","summary":"  We introduce GarmentCrafter, a new approach that enables non-professional\nusers to create and modify 3D garments from a single-view image. While recent\nadvances in image generation have facilitated 2D garment design, creating and\nediting 3D garments remains challenging for non-professional users. Existing\nmethods for single-view 3D reconstruction often rely on pre-trained generative\nmodels to synthesize novel views conditioning on the reference image and camera\npose, yet they lack cross-view consistency, failing to capture the internal\nrelationships across different views. In this paper, we tackle this challenge\nthrough progressive depth prediction and image warping to approximate novel\nviews. Subsequently, we train a multi-view diffusion model to complete occluded\nand unknown clothing regions, informed by the evolving camera pose. By jointly\ninferring RGB and depth, GarmentCrafter enforces inter-view coherence and\nreconstructs precise geometries and fine details. Extensive experiments\ndemonstrate that our method achieves superior visual fidelity and inter-view\ncoherence compared to state-of-the-art single-view 3D garment reconstruction\nmethods.\n","authors":["Yuanhao Wang","Cheng Zhang","Gonçalo Frazão","Jinlong Yang","Alexandru-Eugen Ichim","Thabo Beeler","Fernando De la Torre"],"pdf_url":"https://arxiv.org/pdf/2503.08678v1.pdf","comment":"Project Page: https://humansensinglab.github.io/garment-crafter/"},{"id":"http://arxiv.org/abs/2503.08669v1","updated":"2025-03-11T17:53:02Z","published":"2025-03-11T17:53:02Z","title":"AgentOrca: A Dual-System Framework to Evaluate Language Agents on\n  Operational Routine and Constraint Adherence","summary":"  As language agents progressively automate critical tasks across domains,\ntheir ability to operate within operational constraints and safety protocols\nbecomes essential. While extensive research has demonstrated these agents'\neffectiveness in downstream task completion, their reliability in following\noperational procedures and constraints remains largely unexplored. To this end,\nwe present AgentOrca, a dual-system framework for evaluating language agents'\ncompliance with operational constraints and routines. Our framework encodes\naction constraints and routines through both natural language prompts for\nagents and corresponding executable code serving as ground truth for automated\nverification. Through an automated pipeline of test case generation and\nevaluation across five real-world domains, we quantitatively assess current\nlanguage agents' adherence to operational constraints. Our findings reveal\nnotable performance gaps among state-of-the-art models, with large reasoning\nmodels like o1 demonstrating superior compliance while others show\nsignificantly lower performance, particularly when encountering complex\nconstraints or user persuasion attempts.\n","authors":["Zekun Li","Shinda Huang","Jiangtian Wang","Nathan Zhang","Antonis Antoniades","Wenyue Hua","Kaijie Zhu","Sirui Zeng","William Yang Wang","Xifeng Yan"],"pdf_url":"https://arxiv.org/pdf/2503.08669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08665v1","updated":"2025-03-11T17:51:07Z","published":"2025-03-11T17:51:07Z","title":"REGEN: Learning Compact Video Embedding with (Re-)Generative Decoder","summary":"  We present a novel perspective on learning video embedders for generative\nmodeling: rather than requiring an exact reproduction of an input video, an\neffective embedder should focus on synthesizing visually plausible\nreconstructions. This relaxed criterion enables substantial improvements in\ncompression ratios without compromising the quality of downstream generative\nmodels. Specifically, we propose replacing the conventional encoder-decoder\nvideo embedder with an encoder-generator framework that employs a diffusion\ntransformer (DiT) to synthesize missing details from a compact latent space.\nTherein, we develop a dedicated latent conditioning module to condition the DiT\ndecoder on the encoded video latent embedding. Our experiments demonstrate that\nour approach enables superior encoding-decoding performance compared to\nstate-of-the-art methods, particularly as the compression ratio increases. To\ndemonstrate the efficacy of our approach, we report results from our video\nembedders achieving a temporal compression ratio of up to 32x (8x higher than\nleading video embedders) and validate the robustness of this ultra-compact\nlatent space for text-to-video generation, providing a significant efficiency\nboost in latent diffusion model training and inference.\n","authors":["Yitian Zhang","Long Mai","Aniruddha Mahapatra","David Bourgin","Yicong Hong","Jonah Casebeer","Feng Liu","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2503.08665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08664v1","updated":"2025-03-11T17:50:59Z","published":"2025-03-11T17:50:59Z","title":"MEAT: Multiview Diffusion Model for Human Generation on Megapixels with\n  Mesh Attention","summary":"  Multiview diffusion models have shown considerable success in image-to-3D\ngeneration for general objects. However, when applied to human data, existing\nmethods have yet to deliver promising results, largely due to the challenges of\nscaling multiview attention to higher resolutions. In this paper, we explore\nhuman multiview diffusion models at the megapixel level and introduce a\nsolution called mesh attention to enable training at 1024x1024 resolution.\nUsing a clothed human mesh as a central coarse geometric representation, the\nproposed mesh attention leverages rasterization and projection to establish\ndirect cross-view coordinate correspondences. This approach significantly\nreduces the complexity of multiview attention while maintaining cross-view\nconsistency. Building on this foundation, we devise a mesh attention block and\ncombine it with keypoint conditioning to create our human-specific multiview\ndiffusion model, MEAT. In addition, we present valuable insights into applying\nmultiview human motion videos for diffusion training, addressing the\nlongstanding issue of data scarcity. Extensive experiments show that MEAT\neffectively generates dense, consistent multiview human images at the megapixel\nlevel, outperforming existing multiview diffusion methods.\n","authors":["Yuhan Wang","Fangzhou Hong","Shuai Yang","Liming Jiang","Wayne Wu","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2503.08664v1.pdf","comment":"CVPR 2025. Code https://github.com/johannwyh/MEAT Project Page\n  https://johann.wang/MEAT/"},{"id":"http://arxiv.org/abs/2503.08663v1","updated":"2025-03-11T17:50:47Z","published":"2025-03-11T17:50:47Z","title":"Generating Robot Constitutions & Benchmarks for Semantic Safety","summary":"  Until recently, robotics safety research was predominantly about collision\navoidance and hazard reduction in the immediate vicinity of a robot. Since the\nadvent of large vision and language models (VLMs), robots are now also capable\nof higher-level semantic scene understanding and natural language interactions\nwith humans. Despite their known vulnerabilities (e.g. hallucinations or\njail-breaking), VLMs are being handed control of robots capable of physical\ncontact with the real world. This can lead to dangerous behaviors, making\nsemantic safety for robots a matter of immediate concern. Our contributions in\nthis paper are two fold: first, to address these emerging risks, we release the\nASIMOV Benchmark, a large-scale and comprehensive collection of datasets for\nevaluating and improving semantic safety of foundation models serving as robot\nbrains. Our data generation recipe is highly scalable: by leveraging text and\nimage generation techniques, we generate undesirable situations from real-world\nvisual scenes and human injury reports from hospitals. Secondly, we develop a\nframework to automatically generate robot constitutions from real-world data to\nsteer a robot's behavior using Constitutional AI mechanisms. We propose a novel\nauto-amending process that is able to introduce nuances in written rules of\nbehavior; this can lead to increased alignment with human preferences on\nbehavior desirability and safety. We explore trade-offs between generality and\nspecificity across a diverse set of constitutions of different lengths, and\ndemonstrate that a robot is able to effectively reject unconstitutional\nactions. We measure a top alignment rate of 84.3% on the ASIMOV Benchmark using\ngenerated constitutions, outperforming no-constitution baselines and\nhuman-written constitutions. Data is available at asimov-benchmark.github.io\n","authors":["Pierre Sermanet","Anirudha Majumdar","Alex Irpan","Dmitry Kalashnikov","Vikas Sindhwani"],"pdf_url":"https://arxiv.org/pdf/2503.08663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08662v1","updated":"2025-03-11T17:50:44Z","published":"2025-03-11T17:50:44Z","title":"Exploring the Word Sense Disambiguation Capabilities of Large Language\n  Models","summary":"  Word Sense Disambiguation (WSD) is a historical task in computational\nlinguistics that has received much attention over the years. However, with the\nadvent of Large Language Models (LLMs), interest in this task (in its classical\ndefinition) has decreased. In this study, we evaluate the performance of\nvarious LLMs on the WSD task. We extend a previous benchmark (XL-WSD) to\nre-design two subtasks suitable for LLM: 1) given a word in a sentence, the LLM\nmust generate the correct definition; 2) given a word in a sentence and a set\nof predefined meanings, the LLM must select the correct one. The extended\nbenchmark is built using the XL-WSD and BabelNet. The results indicate that\nLLMs perform well in zero-shot learning but cannot surpass current\nstate-of-the-art methods. However, a fine-tuned model with a medium number of\nparameters outperforms all other models, including the state-of-the-art.\n","authors":["Pierpaolo Basile","Lucia Siciliani","Elio Musacchio","Giovanni Semeraro"],"pdf_url":"https://arxiv.org/pdf/2503.08662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19418v2","updated":"2025-03-11T17:41:54Z","published":"2024-11-29T00:09:39Z","title":"Proto Successor Measure: Representing the Behavior Space of an RL Agent","summary":"  Having explored an environment, intelligent agents should be able to transfer\ntheir knowledge to most downstream tasks within that environment without\nadditional interactions. Referred to as \"zero-shot learning\", this ability\nremains elusive for general-purpose reinforcement learning algorithms. While\nrecent works have attempted to produce zero-shot RL agents, they make\nassumptions about the nature of the tasks or the structure of the MDP. We\npresent Proto Successor Measure: the basis set for all possible behaviors of a\nReinforcement Learning Agent in a dynamical system. We prove that any possible\nbehavior (represented using visitation distributions) can be represented using\nan affine combination of these policy-independent basis functions. Given a\nreward function at test time, we simply need to find the right set of linear\nweights to combine these bases corresponding to the optimal policy. We derive a\npractical algorithm to learn these basis functions using reward-free\ninteraction data from the environment and show that our approach can produce\nthe optimal policy at test time for any given reward function without\nadditional environmental interactions. Project page:\nhttps://agarwalsiddhant10.github.io/projects/psm.html.\n","authors":["Siddhant Agarwal","Harshit Sikchi","Peter Stone","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.19418v2.pdf","comment":"Under submission, 20 pages"},{"id":"http://arxiv.org/abs/2502.06759v3","updated":"2025-03-11T17:37:30Z","published":"2025-02-10T18:38:57Z","title":"Rationalization Models for Text-to-SQL","summary":"  We introduce a framework for generating Chain-of-Thought (CoT) rationales to\nenhance text-to-SQL model fine-tuning. These rationales consist of intermediate\nSQL statements and explanations, serving as incremental steps toward\nconstructing the final SQL query. The process begins with manually annotating a\nsmall set of examples, which are then used to prompt a large language model in\nan iterative, dynamic few-shot knowledge distillation procedure from a teacher\nmodel. A rationalization model is subsequently trained on the validated\ndecomposed queries, enabling extensive synthetic CoT annotations for\ntext-to-SQL datasets. To evaluate the approach, we fine-tune small language\nmodels with and without these rationales on the BIRD dataset. Results indicate\nthat step-by-step query generation improves execution accuracy, especially for\nmoderately and highly complex queries, while also enhancing explainability.\n","authors":["Gaetano Rossiello","Nhan Pham","Michael Glass","Junkyu Lee","Dharmashankar Subramanian"],"pdf_url":"https://arxiv.org/pdf/2502.06759v3.pdf","comment":"Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs"},{"id":"http://arxiv.org/abs/2503.08644v1","updated":"2025-03-11T17:36:53Z","published":"2025-03-11T17:36:53Z","title":"Exploiting Instruction-Following Retrievers for Malicious Information\n  Retrieval","summary":"  Instruction-following retrievers have been widely adopted alongside LLMs in\nreal-world applications, but little work has investigated the safety risks\nsurrounding their increasing search capabilities. We empirically study the\nability of retrievers to satisfy malicious queries, both when used directly and\nwhen used in a retrieval augmented generation-based setup. Concretely, we\ninvestigate six leading retrievers, including NV-Embed and LLM2Vec, and find\nthat given malicious requests, most retrievers can (for >50% of queries) select\nrelevant harmful passages. For example, LLM2Vec correctly selects passages for\n61.35% of our malicious queries. We further uncover an emerging risk with\ninstruction-following retrievers, where highly relevant harmful information can\nbe surfaced by exploiting their instruction-following capabilities. Finally, we\nshow that even safety-aligned LLMs, such as Llama3, can satisfy malicious\nrequests when provided with harmful retrieved passages in-context. In summary,\nour findings underscore the malicious misuse risks associated with increasing\nretriever capability.\n","authors":["Parishad BehnamGhader","Nicholas Meade","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2503.08644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08643v1","updated":"2025-03-11T17:36:11Z","published":"2025-03-11T17:36:11Z","title":"Rethinking Diffusion Model in High Dimension","summary":"  Curse of Dimensionality is an unavoidable challenge in statistical\nprobability models, yet diffusion models seem to overcome this limitation,\nachieving impressive results in high-dimensional data generation. Diffusion\nmodels assume that they can learn the statistical properties of the underlying\nprobability distribution, enabling sampling from this distribution to generate\nrealistic samples. But is this really how they work? To address this question,\nthis paper conducts a detailed analysis of the objective function and inference\nmethods of diffusion models, leading to several important conclusions that help\nanswer the above question: 1) In high-dimensional sparse scenarios, the target\nof the objective function fitting degrades from a weighted sum of multiple\nsamples to a single sample. 2) The mainstream inference methods can all be\nrepresented within a simple unified framework, without requiring statistical\nconcepts such as Markov chains and SDEs. 3) Guided by this simple framework,\nmore efficient inference methods can be discovered.\n","authors":["Zhenxin Zheng","Zhenjie Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.08643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08638v1","updated":"2025-03-11T17:26:50Z","published":"2025-03-11T17:26:50Z","title":"YuE: Scaling Open Foundation Models for Long-Form Music Generation","summary":"  We tackle the task of long-form music generation--particularly the\nchallenging \\textbf{lyrics-to-song} problem--by introducing YuE, a family of\nopen foundation models based on the LLaMA2 architecture. Specifically, YuE\nscales to trillions of tokens and generates up to five minutes of music while\nmaintaining lyrical alignment, coherent musical structure, and engaging vocal\nmelodies with appropriate accompaniment. It achieves this through (1)\ntrack-decoupled next-token prediction to overcome dense mixture signals, (2)\nstructural progressive conditioning for long-context lyrical alignment, and (3)\na multitask, multiphase pre-training recipe to converge and generalize. In\naddition, we redesign the in-context learning technique for music generation,\nenabling versatile style transfer (e.g., converting Japanese city pop into an\nEnglish rap while preserving the original accompaniment) and bidirectional\ngeneration. Through extensive evaluation, we demonstrate that YuE matches or\neven surpasses some of the proprietary systems in musicality and vocal agility.\nIn addition, fine-tuning YuE enables additional controls and enhanced support\nfor tail languages. Furthermore, beyond generation, we show that YuE's learned\nrepresentations can perform well on music understanding tasks, where the\nresults of YuE match or exceed state-of-the-art methods on the MARBLE\nbenchmark. Keywords: lyrics2song, song generation, long-form, foundation model,\nmusic generation\n","authors":["Ruibin Yuan","Hanfeng Lin","Shuyue Guo","Ge Zhang","Jiahao Pan","Yongyi Zang","Haohe Liu","Yiming Liang","Wenye Ma","Xingjian Du","Xinrun Du","Zhen Ye","Tianyu Zheng","Yinghao Ma","Minghao Liu","Zeyue Tian","Ziya Zhou","Liumeng Xue","Xingwei Qu","Yizhi Li","Shangda Wu","Tianhao Shen","Ziyang Ma","Jun Zhan","Chunhui Wang","Yatian Wang","Xiaowei Chi","Xinyue Zhang","Zhenzhu Yang","Xiangzhou Wang","Shansong Liu","Lingrui Mei","Peng Li","Junjie Wang","Jianwei Yu","Guojian Pang","Xu Li","Zihao Wang","Xiaohuan Zhou","Lijun Yu","Emmanouil Benetos","Yong Chen","Chenghua Lin","Xie Chen","Gus Xia","Zhaoxiang Zhang","Chao Zhang","Wenhu Chen","Xinyu Zhou","Xipeng Qiu","Roger Dannenberg","Jiaheng Liu","Jian Yang","Wenhao Huang","Wei Xue","Xu Tan","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2503.08638v1.pdf","comment":"https://github.com/multimodal-art-projection/YuE"},{"id":"http://arxiv.org/abs/2412.05196v2","updated":"2025-03-11T17:25:01Z","published":"2024-12-06T17:20:50Z","title":"Exponential Speedups by Rerooting Levin Tree Search","summary":"  Levin Tree Search (LTS) (Orseau et al., 2018) is a search algorithm for\ndeterministic environments that uses a user-specified policy to guide the\nsearch. It comes with a formal guarantee on the number of search steps (node\nvisits) for finding a solution node that depends on the quality of the policy.\nIn this paper, we introduce a new algorithm, called $\\sqrt{\\text{LTS}}$\n(pronounce root-LTS), which implicitly starts an LTS search rooted at every\nnode of the search tree. Each LTS search is assigned a rerooting weight by a\n(user-defined or learnt) rerooter, and the search effort is shared between all\nLTS searches proportionally to their weights. The rerooting mechanism\nimplicitly decomposes the search space into subtasks, leading to significant\nspeedups. We prove that the number of node visits that $\\sqrt{\\text{LTS}}$\ntakes is competitive with the best decomposition into subtasks, at the price of\na factor that relates to the uncertainty of the rerooter. If LTS takes time\n$T$, in the best case with $q$ rerooting points, $\\sqrt{\\text{LTS}}$ only takes\ntime $O(q\\sqrt[q]{T})$. Like the policy, the rerooter can be learnt from data,\nand we expect $\\sqrt{\\text{LTS}}$ to be applicable to a wide range of domains.\n","authors":["Laurent Orseau","Marcus Hutter","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2412.05196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07072v3","updated":"2025-03-11T17:08:05Z","published":"2025-02-10T22:07:02Z","title":"IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large\n  Language Models","summary":"  Not a day goes by without hearing about the impressive feats of large\nlanguage models (LLMs), and equally, not a day passes without hearing about\ntheir challenges. LLMs are notoriously vulnerable to biases in their dataset,\nleading to issues such as toxicity. While domain-adaptive training has been\nemployed to mitigate these issues, these techniques often address all model\nparameters indiscriminately during the repair process, resulting in poor repair\nquality and reduced model versatility. In this paper, we introduce a novel\ndynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach\nselectively targets the most error-prone sections of the model for repair.\nSpecifically, we propose dynamically slicing the model's most sensitive layers\nthat require immediate attention, concentrating repair efforts on those areas.\nThis method enables more effective repairs with potentially less impact on the\nmodel's overall performance by altering a smaller portion of the model. We\nevaluated our technique on three models from the GPT2 and GPT-Neo families,\nwith parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our\nresults show that IRepair repairs errors 43.6% more effectively while causing\n46% less disruption to general performance compared to the closest baseline,\ndirect preference optimization. Our empirical analysis also reveals that errors\nare more concentrated in a smaller section of the model, with the top 20% of\nlayers exhibiting 773% more error density than the remaining 80\\%. This\nhighlights the need for selective repair. Additionally, we demonstrate that a\ndynamic selection approach is essential for addressing errors dispersed\nthroughout the model, ensuring a robust and efficient repair.\n","authors":["Sayem Mohammad Imtiaz","Astha Singh","Fraol Batole","Hridesh Rajan"],"pdf_url":"https://arxiv.org/pdf/2502.07072v3.pdf","comment":"Accepted as full research paper at FSE'2025"},{"id":"http://arxiv.org/abs/2404.07199v2","updated":"2025-03-11T17:06:18Z","published":"2024-04-10T17:57:41Z","title":"RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth\n  Diffusion","summary":"  We introduce RealmDreamer, a technique for generating forward-facing 3D\nscenes from text descriptions. Our method optimizes a 3D Gaussian Splatting\nrepresentation to match complex text prompts using pretrained diffusion models.\nOur key insight is to leverage 2D inpainting diffusion models conditioned on an\ninitial scene estimate to provide low variance supervision for unknown regions\nduring 3D distillation. In conjunction, we imbue high-fidelity geometry with\ngeometric distillation from a depth diffusion model, conditioned on samples\nfrom the inpainting model. We find that the initialization of the optimization\nis crucial, and provide a principled methodology for doing so. Notably, our\ntechnique doesn't require video or multi-view data and can synthesize various\nhigh-quality 3D scenes in different styles with complex layouts. Further, the\ngenerality of our method allows 3D synthesis from a single image. As measured\nby a comprehensive user study, our method outperforms all existing approaches,\npreferred by 88-95%. Project Page: https://realmdreamer.github.io/\n","authors":["Jaidev Shriram","Alex Trevithick","Lingjie Liu","Ravi Ramamoorthi"],"pdf_url":"https://arxiv.org/pdf/2404.07199v2.pdf","comment":"Published at 3DV 2025"},{"id":"http://arxiv.org/abs/2411.07521v4","updated":"2025-03-11T16:55:48Z","published":"2024-11-12T03:37:53Z","title":"Fair Summarization: Bridging Quality and Diversity in Extractive\n  Summaries","summary":"  Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. Our code\nis available online.\n","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.07521v4.pdf","comment":"Accepted at AFLME@NeurIPS 2024 & C3NLP@NAACL 2025"},{"id":"http://arxiv.org/abs/2503.07154v2","updated":"2025-03-11T16:52:41Z","published":"2025-03-10T10:27:30Z","title":"Ideas in Inference-time Scaling can Benefit Generative Pre-training\n  Algorithms","summary":"  Recent years have seen significant advancements in foundation models through\ngenerative pre-training, yet algorithmic innovation in this space has largely\nstagnated around autoregressive models for discrete signals and diffusion\nmodels for continuous signals. This stagnation creates a bottleneck that\nprevents us from fully unlocking the potential of rich multi-modal data, which\nin turn limits the progress on multimodal intelligence. We argue that an\ninference-first perspective, which prioritizes scaling efficiency during\ninference time across sequence length and refinement steps, can inspire novel\ngenerative pre-training algorithms. Using Inductive Moment Matching (IMM) as a\nconcrete example, we demonstrate how addressing limitations in diffusion\nmodels' inference process through targeted modifications yields a stable,\nsingle-stage algorithm that achieves superior sample quality with over an order\nof magnitude greater inference efficiency.\n","authors":["Jiaming Song","Linqi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08609v1","updated":"2025-03-11T16:47:32Z","published":"2025-03-11T16:47:32Z","title":"Vision Transformer for Intracranial Hemorrhage Classification in CT\n  Scans Using an Entropy-Aware Fuzzy Integral Strategy for Adaptive Scan-Level\n  Decision Fusion","summary":"  Intracranial hemorrhage (ICH) is a critical medical emergency caused by the\nrupture of cerebral blood vessels, leading to internal bleeding within the\nskull. Accurate and timely classification of hemorrhage subtypes is essential\nfor effective clinical decision-making. To address this challenge, we propose\nan advanced pyramid vision transformer (PVT)-based model, leveraging its\nhierarchical attention mechanisms to capture both local and global spatial\ndependencies in brain CT scans. Instead of processing all extracted features\nindiscriminately, A SHAP-based feature selection method is employed to identify\nthe most discriminative components, which are then used as a latent feature\nspace to train a boosting neural network, reducing computational complexity. We\nintroduce an entropy-aware aggregation strategy along with a fuzzy integral\noperator to fuse information across multiple CT slices, ensuring a more\ncomprehensive and reliable scan-level diagnosis by accounting for inter-slice\ndependencies. Experimental results show that our PVT-based framework\nsignificantly outperforms state-of-the-art deep learning architectures in terms\nof classification accuracy, precision, and robustness. By combining SHAP-driven\nfeature selection, transformer-based modeling, and an entropy-aware fuzzy\nintegral operator for decision fusion, our method offers a scalable and\ncomputationally efficient AI-driven solution for automated ICH subtype\nclassification.\n","authors":["Mehdi Hosseini Chagahi","Niloufar Delfan","Behzad Moshiri","Md. Jalil Piran","Jaber Hatam Parikhan"],"pdf_url":"https://arxiv.org/pdf/2503.08609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08608v1","updated":"2025-03-11T16:45:52Z","published":"2025-03-11T16:45:52Z","title":"A Grid Cell-Inspired Structured Vector Algebra for Cognitive Maps","summary":"  The entorhinal-hippocampal formation is the mammalian brain's navigation\nsystem, encoding both physical and abstract spaces via grid cells. This system\nis well-studied in neuroscience, and its efficiency and versatility make it\nattractive for applications in robotics and machine learning. While continuous\nattractor networks (CANs) successfully model entorhinal grid cells for encoding\nphysical space, integrating both continuous spatial and abstract spatial\ncomputations into a unified framework remains challenging. Here, we attempt to\nbridge this gap by proposing a mechanistic model for versatile information\nprocessing in the entorhinal-hippocampal formation inspired by CANs and Vector\nSymbolic Architectures (VSAs), a neuro-symbolic computing framework. The novel\ngrid-cell VSA (GC-VSA) model employs a spatially structured encoding scheme\nwith 3D neuronal modules mimicking the discrete scales and orientations of grid\ncell modules, reproducing their characteristic hexagonal receptive fields. In\nexperiments, the model demonstrates versatility in spatial and abstract tasks:\n(1) accurate path integration for tracking locations, (2) spatio-temporal\nrepresentation for querying object locations and temporal relations, and (3)\nsymbolic reasoning using family trees as a structured test case for\nhierarchical relationships.\n","authors":["Sven Krausse","Emre Neftci","Friedrich T. Sommer","Alpha Renner"],"pdf_url":"https://arxiv.org/pdf/2503.08608v1.pdf","comment":"10 pages, 5 figures, accepted at the 2025 Neuro Inspired\n  Computational Elements (NICE) conference"},{"id":"http://arxiv.org/abs/2405.13637v3","updated":"2025-03-11T16:44:48Z","published":"2024-05-22T13:36:48Z","title":"Curriculum Direct Preference Optimization for Diffusion and Consistency\n  Models","summary":"  Direct Preference Optimization (DPO) has been proposed as an effective and\nefficient alternative to reinforcement learning from human feedback (RLHF). In\nthis paper, we propose a novel and enhanced version of DPO based on curriculum\nlearning for text-to-image generation. Our method is divided into two training\nstages. First, a ranking of the examples generated for each prompt is obtained\nby employing a reward model. Then, increasingly difficult pairs of examples are\nsampled and provided to a text-to-image generative (diffusion or consistency)\nmodel. Generated samples that are far apart in the ranking are considered to\nform easy pairs, while those that are close in the ranking form hard pairs. In\nother words, we use the rank difference between samples as a measure of\ndifficulty. The sampled pairs are split into batches according to their\ndifficulty levels, which are gradually used to train the generative model. Our\napproach, Curriculum DPO, is compared against state-of-the-art fine-tuning\napproaches on nine benchmarks, outperforming the competing methods in terms of\ntext alignment, aesthetics and human preference. Our code is available at\nhttps://github.com/CroitoruAlin/Curriculum-DPO.\n","authors":["Florinel-Alin Croitoru","Vlad Hondru","Radu Tudor Ionescu","Nicu Sebe","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2405.13637v3.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08605v1","updated":"2025-03-11T16:43:45Z","published":"2025-03-11T16:43:45Z","title":"Tuning-Free Multi-Event Long Video Generation via Synchronized Coupled\n  Sampling","summary":"  While recent advancements in text-to-video diffusion models enable\nhigh-quality short video generation from a single prompt, generating real-world\nlong videos in a single pass remains challenging due to limited data and high\ncomputational costs. To address this, several works propose tuning-free\napproaches, i.e., extending existing models for long video generation,\nspecifically using multiple prompts to allow for dynamic and controlled content\nchanges. However, these methods primarily focus on ensuring smooth transitions\nbetween adjacent frames, often leading to content drift and a gradual loss of\nsemantic coherence over longer sequences. To tackle such an issue, we propose\nSynchronized Coupled Sampling (SynCoS), a novel inference framework that\nsynchronizes denoising paths across the entire video, ensuring long-range\nconsistency across both adjacent and distant frames. Our approach combines two\ncomplementary sampling strategies: reverse and optimization-based sampling,\nwhich ensure seamless local transitions and enforce global coherence,\nrespectively. However, directly alternating between these samplings misaligns\ndenoising trajectories, disrupting prompt guidance and introducing unintended\ncontent changes as they operate independently. To resolve this, SynCoS\nsynchronizes them through a grounded timestep and a fixed baseline noise,\nensuring fully coupled sampling with aligned denoising paths. Extensive\nexperiments show that SynCoS significantly improves multi-event long video\ngeneration, achieving smoother transitions and superior long-range coherence,\noutperforming previous approaches both quantitatively and qualitatively.\n","authors":["Subin Kim","Seoung Wug Oh","Jui-Hsien Wang","Joon-Young Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2503.08605v1.pdf","comment":"Project page with visuals: https://syncos2025.github.io/"},{"id":"http://arxiv.org/abs/2503.08604v1","updated":"2025-03-11T16:42:36Z","published":"2025-03-11T16:42:36Z","title":"EMMOE: A Comprehensive Benchmark for Embodied Mobile Manipulation in\n  Open Environments","summary":"  Developing autonomous home robots controlled by natural language has long\nbeen a pursuit of human. While advancements in large language models (LLMs) and\nembodied intelligence make this goal closer, several challenges persist: the\nlack of a unified benchmark for more complex robot tasks, limited evaluation\nmethods and metrics, data incompatibility between LLMs and mobile manipulation\ntrajectories. To address these issues, we introduce Embodied Mobile\nManipulation in Open Environments (EMMOE), which requires agents to interpret\nuser instructions and execute long-horizon everyday tasks in continuous space.\nEMMOE seamlessly integrates high-level and low-level embodied tasks into a\nunified framework, along with three new metrics for more diverse assessment.\nAdditionally, we collect EMMOE-100, which features in various task attributes,\ndetailed process annotations, re-plans after failures, and two sub-datasets for\nLLM training. Furthermore, we design HomieBot, a sophisticated agent system\nconsists of LLM with Direct Preference Optimization (DPO), light weighted\nnavigation and manipulation models, and multiple error detection mechanisms.\nFinally, we demonstrate HomieBot's performance and the evaluation of different\nmodels and policies.\n","authors":["Dongping Li","Tielong Cai","Tianci Tang","Wenhao Chai","Katherine Rose Driggs-Campbell","Gaoang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08588v1","updated":"2025-03-11T16:25:36Z","published":"2025-03-11T16:25:36Z","title":"BiasEdit: Debiasing Stereotyped Language Models via Model Editing","summary":"  Previous studies have established that language models manifest stereotyped\nbiases. Existing debiasing strategies, such as retraining a model with\ncounterfactual data, representation projection, and prompting often fail to\nefficiently eliminate bias or directly alter the models' biased internal\nrepresentations. To address these issues, we propose BiasEdit, an efficient\nmodel editing method to remove stereotypical bias from language models through\nlightweight networks that act as editors to generate parameter updates.\nBiasEdit employs a debiasing loss guiding editor networks to conduct local\nedits on partial parameters of a language model for debiasing while preserving\nthe language modeling abilities during editing through a retention loss.\nExperiments on StereoSet and Crows-Pairs demonstrate the effectiveness,\nefficiency, and robustness of BiasEdit in eliminating bias compared to\ntangental debiasing baselines and little to no impact on the language models'\ngeneral capabilities. In addition, we conduct bias tracing to probe bias in\nvarious modules and explore bias editing impacts on different components of\nlanguage models.\n","authors":["Xin Xu","Wei Xu","Ningyu Zhang","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2503.08588v1.pdf","comment":"Accepted by TrustNLP @ NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08581v1","updated":"2025-03-11T16:16:44Z","published":"2025-03-11T16:16:44Z","title":"MsaMIL-Net: An End-to-End Multi-Scale Aware Multiple Instance Learning\n  Network for Efficient Whole Slide Image Classification","summary":"  Bag-based Multiple Instance Learning (MIL) approaches have emerged as the\nmainstream methodology for Whole Slide Image (WSI) classification. However,\nmost existing methods adopt a segmented training strategy, which first extracts\nfeatures using a pre-trained feature extractor and then aggregates these\nfeatures through MIL. This segmented training approach leads to insufficient\ncollaborative optimization between the feature extraction network and the MIL\nnetwork, preventing end-to-end joint optimization and thereby limiting the\noverall performance of the model. Additionally, conventional methods typically\nextract features from all patches of fixed size, ignoring the multi-scale\nobservation characteristics of pathologists. This not only results in\nsignificant computational resource waste when tumor regions represent a minimal\nproportion (as in the Camelyon16 dataset) but may also lead the model to\nsuboptimal solutions.\n  To address these limitations, this paper proposes an end-to-end multi-scale\nWSI classification framework that integrates multi-scale feature extraction\nwith multiple instance learning. Specifically, our approach includes: (1) a\nsemantic feature filtering module to reduce interference from non-lesion areas;\n(2) a multi-scale feature extraction module to capture pathological information\nat different levels; and (3) a multi-scale fusion MIL module for global\nmodeling and feature integration. Through an end-to-end training strategy, we\nsimultaneously optimize both the feature extractor and MIL network, ensuring\nmaximum compatibility between them.\n  Experiments were conducted on three cross-center datasets (DigestPath2019,\nBCNB, and UBC-OCEAN). Results demonstrate that our proposed method outperforms\nexisting state-of-the-art approaches in terms of both accuracy (ACC) and AUC\nmetrics.\n","authors":["Jiangping Wen","Jinyu Wen","Emei Fang"],"pdf_url":"https://arxiv.org/pdf/2503.08581v1.pdf","comment":"summited to ICCV2025"},{"id":"http://arxiv.org/abs/2308.14172v3","updated":"2025-03-11T16:11:14Z","published":"2023-08-27T18:28:58Z","title":"Hypergraph Structure Inference From Data Under Smoothness Prior","summary":"  Hypergraphs are important for processing data with higher-order relationships\ninvolving more than two entities. In scenarios where explicit hypergraphs are\nnot readily available, it is desirable to infer a meaningful hypergraph\nstructure from the node features to capture the intrinsic relations within the\ndata. However, existing methods either adopt simple pre-defined rules that fail\nto precisely capture the distribution of the potential hypergraph structure, or\nlearn a mapping between hypergraph structures and node features but require a\nlarge amount of labelled data, i.e., pre-existing hypergraph structures, for\ntraining. Both restrict their applications in practical scenarios. To fill this\ngap, we propose a novel smoothness prior that enables us to design a method to\ninfer the probability for each potential hyperedge without labelled data as\nsupervision. The proposed prior indicates features of nodes in a hyperedge are\nhighly correlated by the features of the hyperedge containing them. We use this\nprior to derive the relation between the hypergraph structure and the node\nfeatures via probabilistic modelling. This allows us to develop an unsupervised\ninference method to estimate the probability for each potential hyperedge via\nsolving an optimisation problem that has an analytical solution. Experiments on\nboth synthetic and real-world data demonstrate that our method can learn\nmeaningful hypergraph structures from data more efficiently than existing\nhypergraph structure inference methods.\n","authors":["Bohan Tang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2308.14172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05569v6","updated":"2025-03-11T16:06:25Z","published":"2024-02-08T11:10:39Z","title":"Training-Free Message Passing for Learning on Hypergraphs","summary":"  Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.\n","authors":["Bohan Tang","Zexi Liu","Keyue Jiang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2402.05569v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19256v2","updated":"2025-03-11T15:58:48Z","published":"2024-06-27T15:26:39Z","title":"AI Data Readiness Inspector (AIDRIN) for Quantitative Assessment of Data\n  Readiness for AI","summary":"  \"Garbage In Garbage Out\" is a universally agreed quote by computer scientists\nfrom various domains, including Artificial Intelligence (AI). As data is the\nfuel for AI, models trained on low-quality, biased data are often ineffective.\nComputer scientists who use AI invest a considerable amount of time and effort\nin preparing the data for AI. However, there are no standard methods or\nframeworks for assessing the \"readiness\" of data for AI. To provide a\nquantifiable assessment of the readiness of data for AI processes, we define\nparameters of AI data readiness and introduce AIDRIN (AI Data Readiness\nInspector). AIDRIN is a framework covering a broad range of readiness\ndimensions available in the literature that aid in evaluating the readiness of\ndata quantitatively and qualitatively. AIDRIN uses metrics in traditional data\nquality assessment such as completeness, outliers, and duplicates for data\nevaluation. Furthermore, AIDRIN uses metrics specific to assess data for AI,\nsuch as feature importance, feature correlations, class imbalance, fairness,\nprivacy, and FAIR (Findability, Accessibility, Interoperability, and\nReusability) principle compliance. AIDRIN provides visualizations and reports\nto assist data scientists in further investigating the readiness of data. The\nAIDRIN framework enhances the efficiency of the machine learning pipeline to\nmake informed decisions on data readiness for AI applications.\n","authors":["Kaveen Hiniduma","Suren Byna","Jean Luca Bez","Ravi Madduri"],"pdf_url":"https://arxiv.org/pdf/2406.19256v2.pdf","comment":"12 pages, 9 figures, Accepted to SSDBM 2024"},{"id":"http://arxiv.org/abs/2503.08565v1","updated":"2025-03-11T15:54:03Z","published":"2025-03-11T15:54:03Z","title":"When Discourse Stalls: Moving Past Five Semantic Stopsigns about\n  Generative AI in Design Research","summary":"  This essay examines how Generative AI (GenAI) is rapidly transforming design\npractices and how discourse often falls into over-simplified narratives that\nimpede meaningful research and practical progress. We identify and deconstruct\nfive prevalent \"semantic stopsigns\" -- reductive framings about GenAI in design\nthat halt deeper inquiry and limit productive engagement. Reflecting upon two\nexpert workshops at ACM conferences and semi-structured interviews with design\npractitioners, we analyze how these stopsigns manifest in research and\npractice. Our analysis develops mid-level knowledge that bridges theoretical\ndiscourse and practical implementation, helping designers and researchers\ninterrogate common assumptions about GenAI in their own contexts. By recasting\nthese stopsigns into more nuanced frameworks, we provide the design research\ncommunity with practical approaches for thinking about and working with these\nemerging technologies.\n","authors":["Willem van der Maden","Vera van der Burg","Brett A. Halperin","Petra Jääskeläinen","Joseph Lindley","Derek Lomas","Timothy Merritt"],"pdf_url":"https://arxiv.org/pdf/2503.08565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08564v1","updated":"2025-03-11T15:53:54Z","published":"2025-03-11T15:53:54Z","title":"MoE-Loco: Mixture of Experts for Multitask Locomotion","summary":"  We present MoE-Loco, a Mixture of Experts (MoE) framework for multitask\nlocomotion for legged robots. Our method enables a single policy to handle\ndiverse terrains, including bars, pits, stairs, slopes, and baffles, while\nsupporting quadrupedal and bipedal gaits. Using MoE, we mitigate the gradient\nconflicts that typically arise in multitask reinforcement learning, improving\nboth training efficiency and performance. Our experiments demonstrate that\ndifferent experts naturally specialize in distinct locomotion behaviors, which\ncan be leveraged for task migration and skill composition. We further validate\nour approach in both simulation and real-world deployment, showcasing its\nrobustness and adaptability.\n","authors":["Runhan Huang","Shaoting Zhu","Yilun Du","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.08564v1.pdf","comment":"8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.08558v1","updated":"2025-03-11T15:47:12Z","published":"2025-03-11T15:47:12Z","title":"Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime\n  Failure Detection for Imitation Learning Policies","summary":"  Recent years have witnessed impressive robotic manipulation systems driven by\nadvances in imitation learning and generative modeling, such as diffusion- and\nflow-based approaches. As robot policy performance increases, so does the\ncomplexity and time horizon of achievable tasks, inducing unexpected and\ndiverse failure modes that are difficult to predict a priori. To enable\ntrustworthy policy deployment in safety-critical human environments, reliable\nruntime failure detection becomes important during policy inference. However,\nmost existing failure detection approaches rely on prior knowledge of failure\nmodes and require failure data during training, which imposes a significant\nchallenge in practicality and scalability. In response to these limitations, we\npresent FAIL-Detect, a modular two-stage approach for failure detection in\nimitation learning-based robotic manipulation. To accurately identify failures\nfrom successful training data alone, we frame the problem as sequential\nout-of-distribution (OOD) detection. We first distill policy inputs and outputs\ninto scalar signals that correlate with policy failures and capture epistemic\nuncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile\nframework for uncertainty quantification with statistical guarantees.\nEmpirically, we thoroughly investigate both learned and post-hoc scalar signal\ncandidates on diverse robotic manipulation tasks. Our experiments show learned\nsignals to be mostly consistently effective, particularly when using our novel\nflow-based density estimator. Furthermore, our method detects failures more\naccurately and faster than state-of-the-art (SOTA) failure detection baselines.\nThese results highlight the potential of FAIL-Detect to enhance the safety and\nreliability of imitation learning-based robotic systems as they progress toward\nreal-world deployment.\n","authors":["Chen Xu","Tony Khuong Nguyen","Emma Dixon","Christopher Rodriguez","Patrick Miller","Robert Lee","Paarth Shah","Rares Ambrus","Haruki Nishimura","Masha Itkina"],"pdf_url":"https://arxiv.org/pdf/2503.08558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08551v1","updated":"2025-03-11T15:39:43Z","published":"2025-03-11T15:39:43Z","title":"Reasoning and Sampling-Augmented MCQ Difficulty Prediction via LLMs","summary":"  The difficulty of multiple-choice questions (MCQs) is a crucial factor for\neducational assessments. Predicting MCQ difficulty is challenging since it\nrequires understanding both the complexity of reaching the correct option and\nthe plausibility of distractors, i.e., incorrect options. In this paper, we\npropose a novel, two-stage method to predict the difficulty of MCQs. First, to\nbetter estimate the complexity of each MCQ, we use large language models (LLMs)\nto augment the reasoning steps required to reach each option. We use not just\nthe MCQ itself but also these reasoning steps as input to predict the\ndifficulty. Second, to capture the plausibility of distractors, we sample\nknowledge levels from a distribution to account for variation among students\nresponding to the MCQ. This setup, inspired by item response theory (IRT),\nenable us to estimate the likelihood of students selecting each (both correct\nand incorrect) option. We align these predictions with their ground truth\nvalues, using a Kullback-Leibler (KL) divergence-based regularization\nobjective, and use estimated likelihoods to predict MCQ difficulty. We evaluate\nour method on two real-world \\emph{math} MCQ and response datasets with ground\ntruth difficulty values estimated using IRT. Experimental results show that our\nmethod outperforms all baselines, up to a 28.3\\% reduction in mean squared\nerror and a 34.6\\% improvement in the coefficient of determination. We also\nqualitatively discuss how our novel method results in higher accuracy in\npredicting MCQ difficulty.\n","authors":["Wanyong Feng","Peter Tran","Stephen Sireci","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2503.08551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01413v2","updated":"2025-03-11T15:37:21Z","published":"2025-03-03T11:08:18Z","title":"Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards\n  based Co-constructive Approach","summary":"  Since its inception, Fuzzy Set has been widely used to handle uncertainty and\nimprecision in decision-making. However, conventional fuzzy sets, often\nreferred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher\nlevels of uncertainty, particularly when decision-makers (DMs) express\nhesitation or ambiguity in membership degree. To address this, Interval Type-2\nFuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in\nmembership degree allocation, which enhanced flexibility in modelling\nsubjective judgments. Despite their advantages, existing IT2FS construction\nmethods often lack active involvement from DMs and that limits the\ninterpretability and effectiveness of decision models. This study proposes a\nsocio-technical co-constructive approach for developing IT2FS models of\nlinguistic terms by facilitating the active involvement of DMs in preference\nelicitation and its application in multicriteria decision-making (MCDM)\nproblems. Our methodology is structured in two phases. The first phase involves\nan interactive process between the DM and the decision analyst, in which a\nmodified version of Deck-of-Cards (DoC) method is proposed to construct T1FS\nmembership functions on a ratio scale. We then extend this method to\nincorporate ambiguity in subjective judgment and that resulted in an IT2FS\nmodel that better captures uncertainty in DM's linguistic assessments. The\nsecond phase formalizes the constructed IT2FS model for application in MCDM by\ndefining an appropriate mathematical representation of such information,\naggregation rules, and an admissible ordering principle. The proposed framework\nenhances the reliability and effectiveness of fuzzy decision-making not only by\naccurately representing DM's personalized semantics of linguistic information.\n","authors":["Bapi Dutta","Diego García-Zamora","José Rui Figueira","Luis Martínez"],"pdf_url":"https://arxiv.org/pdf/2503.01413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02854v2","updated":"2025-03-11T15:36:40Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v2.pdf","comment":"21 pages, 17 figures, 1 table. Code:\n  http://github.com/belindal/state-tracking"},{"id":"http://arxiv.org/abs/2503.08549v1","updated":"2025-03-11T15:36:38Z","published":"2025-03-11T15:36:38Z","title":"Graph of AI Ideas: Leveraging Knowledge Graphs and LLMs for AI Research\n  Idea Generation","summary":"  Reading relevant scientific papers and analyzing research development trends\nis a critical step in generating new scientific ideas. However, the rapid\nincrease in the volume of research literature and the complex citation\nrelationships make it difficult for researchers to quickly analyze and derive\nmeaningful research trends. The development of large language models (LLMs) has\nprovided a novel approach for automatically summarizing papers and generating\ninnovative research ideas. However, existing paper-based idea generation\nmethods either simply input papers into LLMs via prompts or form logical chains\nof creative development based on citation relationships, without fully\nexploiting the semantic information embedded in these citations. Inspired by\nknowledge graphs and human cognitive processes, we propose a framework called\nthe Graph of AI Ideas (GoAI) for the AI research field, which is dominated by\nopen-access papers. This framework organizes relevant literature into entities\nwithin a knowledge graph and summarizes the semantic information contained in\ncitations into relations within the graph. This organization effectively\nreflects the relationships between two academic papers and the advancement of\nthe AI research field. Such organization aids LLMs in capturing the current\nprogress of research, thereby enhancing their creativity. Experimental results\ndemonstrate the effectiveness of our approach in generating novel, clear, and\neffective research ideas.\n","authors":["Xian Gao","Zongyun Zhang","Mingye Xie","Ting Liu","Yuzhuo Fu"],"pdf_url":"https://arxiv.org/pdf/2503.08549v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.08542v1","updated":"2025-03-11T15:29:55Z","published":"2025-03-11T15:29:55Z","title":"DAFE: LLM-Based Evaluation Through Dynamic Arbitration for Free-Form\n  Question-Answering","summary":"  Evaluating Large Language Models (LLMs) free-form generated responses remains\na challenge due to their diverse and open-ended nature. Traditional supervised\nsignal-based automatic metrics fail to capture semantic equivalence or handle\nthe variability of open-ended responses, while human evaluation, though\nreliable, is resource-intensive. Leveraging LLMs as evaluators offers a\npromising alternative due to their strong language understanding and\ninstruction-following capabilities. Taking advantage of these capabilities, we\npropose the Dynamic Arbitration Framework for Evaluation (DAFE), which employs\ntwo primary LLM-as-judges and engages a third arbitrator only in cases of\ndisagreements. This selective arbitration prioritizes evaluation reliability\nwhile reducing unnecessary computational demands compared to conventional\nmajority voting. DAFE utilizes task-specific reference answers with dynamic\narbitration to enhance judgment accuracy, resulting in significant improvements\nin evaluation metrics such as Macro F1 and Cohen's Kappa. Through experiments,\nincluding a comprehensive human evaluation, we demonstrate DAFE's ability to\nprovide consistent, scalable, and resource-efficient assessments, establishing\nit as a robust framework for evaluating free-form model outputs.\n","authors":["Sher Badshah","Hassan Sajjad"],"pdf_url":"https://arxiv.org/pdf/2503.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08540v1","updated":"2025-03-11T15:29:00Z","published":"2025-03-11T15:29:00Z","title":"Mellow: a small audio language model for reasoning","summary":"  Multimodal Audio-Language Models (ALMs) can understand and reason over both\naudio and text. Typically, reasoning performance correlates with model size,\nwith the best results achieved by models exceeding 8 billion parameters.\nHowever, no prior work has explored enabling small audio-language models to\nperform reasoning tasks, despite the potential applications for edge devices.\nTo address this gap, we introduce Mellow, a small Audio-Language Model\nspecifically designed for reasoning. Mellow achieves state-of-the-art\nperformance among existing small audio-language models and surpasses several\nlarger models in reasoning capabilities. For instance, Mellow scores 52.11 on\nMMAU, comparable to SoTA Qwen2 Audio (which scores 52.5) while using 50 times\nfewer parameters and being trained on 60 times less data (audio hrs). To train\nMellow, we introduce ReasonAQA, a dataset designed to enhance audio-grounded\nreasoning in models. It consists of a mixture of existing datasets (30% of the\ndata) and synthetically generated data (70%). The synthetic dataset is derived\nfrom audio captioning datasets, where Large Language Models (LLMs) generate\ndetailed and multiple-choice questions focusing on audio events, objects,\nacoustic scenes, signal properties, semantics, and listener emotions. To\nevaluate Mellow's reasoning ability, we benchmark it on a diverse set of tasks,\nassessing on both in-distribution and out-of-distribution data, including audio\nunderstanding, deductive reasoning, and comparative reasoning. Finally, we\nconduct extensive ablation studies to explore the impact of projection layer\nchoices, synthetic data generation methods, and language model pretraining on\nreasoning performance. Our training dataset, findings, and baseline pave the\nway for developing small ALMs capable of reasoning.\n","authors":["Soham Deshmukh","Satvik Dixit","Rita Singh","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2503.08540v1.pdf","comment":"Checkpoint and dataset available at:\n  https://github.com/soham97/mellow"},{"id":"http://arxiv.org/abs/2502.15969v2","updated":"2025-03-11T15:28:50Z","published":"2025-02-21T22:04:09Z","title":"Forgotten Polygons: Multimodal Large Language Models are Shape-Blind","summary":"  Despite strong performance on vision-language tasks, Multimodal Large\nLanguage Models (MLLMs) struggle with mathematical problem-solving, with both\nopen-source and state-of-the-art models falling short of human performance on\nvisual-math benchmarks. To systematically examine visual-mathematical reasoning\nin MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test\nmulti-step reasoning, and (3) explore a potential solution to improve visual\nreasoning capabilities. Our findings reveal fundamental shortcomings in shape\nrecognition, with top models achieving under 50% accuracy in identifying\nregular polygons. We analyze these failures through the lens of dual-process\ntheory and show that MLLMs rely on System 1 (intuitive, memorized associations)\nrather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count\nthe sides of both familiar and novel shapes, suggesting they have neither\nlearned the concept of sides nor effectively process visual inputs. Finally, we\npropose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances\nmulti-step mathematical reasoning by explicitly referencing visual annotations\nin diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting\ntask from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs\nremains an open problem, and visually-guided prompting is essential for\nsuccessfully engaging visual reasoning. Code available at:\nhttps://github.com/rsinghlab/Shape-Blind.\n","authors":["William Rudman","Michal Golovanesky","Amir Bar","Vedant Palit","Yann LeCun","Carsten Eickhoff","Ritambhara Singh"],"pdf_url":"https://arxiv.org/pdf/2502.15969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08537v1","updated":"2025-03-11T15:27:17Z","published":"2025-03-11T15:27:17Z","title":"Chemical reasoning in LLMs unlocks steerable synthesis planning and\n  reaction mechanism elucidation","summary":"  While machine learning algorithms have been shown to excel at specific\nchemical tasks, they have struggled to capture the strategic thinking that\ncharacterizes expert chemical reasoning, limiting their widespread adoption.\nHere we demonstrate that large language models (LLMs) can serve as powerful\nchemical reasoning engines when integrated with traditional search algorithms,\nenabling a new approach to computer-aided chemistry that mirrors human expert\nthinking. Rather than using LLMs to directly manipulate chemical structures, we\nleverage their ability to evaluate chemical strategies and guide search\nalgorithms toward chemically meaningful solutions. We demonstrate this paradigm\nthrough two fundamental challenges: strategy-aware retrosynthetic planning and\nmechanism elucidation. In retrosynthetic planning, our method allows chemists\nto specify desired synthetic strategies in natural language to find routes that\nsatisfy these constraints in vast searches. In mechanism elucidation, LLMs\nguide the search for plausible reaction mechanisms by combining chemical\nprinciples with systematic exploration. Our approach shows strong performance\nacross diverse chemical tasks, with larger models demonstrating increasingly\nsophisticated chemical reasoning. Our approach establishes a new paradigm for\ncomputer-aided chemistry that combines the strategic understanding of LLMs with\nthe precision of traditional chemical tools, opening possibilities for more\nintuitive and powerful chemical reasoning systems.\n","authors":["Andres M Bran","Theo A Neukomm","Daniel P Armstrong","Zlatko Jončev","Philippe Schwaller"],"pdf_url":"https://arxiv.org/pdf/2503.08537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01905v2","updated":"2025-03-11T15:24:13Z","published":"2025-02-28T13:30:10Z","title":"PaCA: Partial Connection Adaptation for Efficient Fine-Tuning","summary":"  Prior parameter-efficient fine-tuning (PEFT) algorithms reduce memory usage\nand computational costs of fine-tuning large neural network models by training\nonly a few additional adapter parameters, rather than the entire model.\nHowever, the reduction in computational costs due to PEFT does not necessarily\ntranslate to a reduction in training time; although the computational costs of\nthe adapter layers are much smaller than the pretrained layers, it is well\nknown that those two types of layers are processed sequentially on GPUs,\nresulting in significant latency overhead. LoRA and its variants merge low-rank\nadapter matrices with pretrained weights during inference to avoid latency\noverhead, but during training, the pretrained weights remain frozen while the\nadapter matrices are continuously updated, preventing such merging. To mitigate\nthis issue, we propose Partial Connection Adaptation (PaCA), which fine-tunes\nrandomly selected partial connections within the pretrained weights instead of\nintroducing adapter layers in the model. PaCA not only enhances training speed\nby eliminating the time overhead due to the sequential processing of the\nadapter and pretrained layers but also reduces activation memory since only\npartial activations, rather than full activations, need to be stored for\ngradient computation. Compared to LoRA, PaCA reduces training time by 22% and\ntotal memory usage by 16%, while maintaining comparable accuracy across various\nfine-tuning scenarios, such as fine-tuning on the MMLU dataset and instruction\ntuning on the Oasst1 dataset. PaCA can also be combined with quantization,\nenabling the fine-tuning of large models such as LLaMA3.1-70B. In addition,\nPaCA enables training with 23% longer sequence and improves throughput by 16%\non both NVIDIA A100 GPU and INTEL Gaudi2 HPU compared to LoRA. The code is\navailable at https://github.com/WooSunghyeon/paca.\n","authors":["Sunghyeon Woo","Sol Namkung","Sunwoo Lee","Inho Jeong","Beomseok Kim","Dongsuk Jeon"],"pdf_url":"https://arxiv.org/pdf/2503.01905v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00858v2","updated":"2025-03-11T15:22:58Z","published":"2025-02-02T17:16:25Z","title":"Learning to Plan with Personalized Preferences","summary":"  Effective integration of AI agents into daily life requires them to\nunderstand and adapt to individual human preferences, particularly in\ncollaborative roles. Although recent studies on embodied intelligence have\nadvanced significantly, they typically adopt generalized approaches that\noverlook personal preferences in planning. We address this limitation by\ndeveloping agents that not only learn preferences from few demonstrations but\nalso learn to adapt their planning strategies based on these preferences. Our\nresearch leverages the observation that preferences, though implicitly\nexpressed through minimal demonstrations, can generalize across diverse\nplanning scenarios. To systematically evaluate this hypothesis, we introduce\nPreference-based Planning (PbP) benchmark, an embodied benchmark featuring\nhundreds of diverse preferences spanning from atomic actions to complex\nsequences. Our evaluation of SOTA methods reveals that while symbol-based\napproaches show promise in scalability, significant challenges remain in\nlearning to generate and execute plans that satisfy personalized preferences.\nWe further demonstrate that incorporating learned preferences as intermediate\nrepresentations in planning significantly improves the agent's ability to\nconstruct personalized plans. These findings establish preferences as a\nvaluable abstraction layer for adaptive planning, opening new directions for\nresearch in preference-guided plan generation and execution.\n","authors":["Manjie Xu","Xinyi Yang","Wei Liang","Chi Zhang","Yixin Zhu"],"pdf_url":"https://arxiv.org/pdf/2502.00858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04966v2","updated":"2025-03-11T15:21:38Z","published":"2025-03-06T20:52:58Z","title":"Prediction of Frozen Region Growth in Kidney Cryoablation Intervention\n  Using a 3D Flow-Matching Model","summary":"  This study presents a 3D flow-matching model designed to predict the\nprogression of the frozen region (iceball) during kidney cryoablation. Precise\nintraoperative guidance is critical in cryoablation to ensure complete tumor\neradication while preserving adjacent healthy tissue. However, conventional\nmethods, typically based on physics driven or diffusion based simulations, are\ncomputationally demanding and often struggle to represent complex anatomical\nstructures accurately. To address these limitations, our approach leverages\nintraoperative CT imaging to inform the model. The proposed 3D flow matching\nmodel is trained to learn a continuous deformation field that maps early-stage\nCT scans to future predictions. This transformation not only estimates the\nvolumetric expansion of the iceball but also generates corresponding\nsegmentation masks, effectively capturing spatial and morphological changes\nover time. Quantitative analysis highlights the model robustness, demonstrating\nstrong agreement between predictions and ground-truth segmentations. The model\nachieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient\nof 0.75. By integrating real time CT imaging with advanced deep learning\ntechniques, this approach has the potential to enhance intraoperative guidance\nin kidney cryoablation, improving procedural outcomes and advancing the field\nof minimally invasive surgery.\n","authors":["Siyeop Yoon","Yujin Oh","Matthew Tivnan","Sifan Song","Pengfei Jin","Sekeun Kim","Hyun Jin Cho","Dufan Wu","Raul Uppot","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2503.04966v2.pdf","comment":"MICCAI 2025 submitted version (author list included)"},{"id":"http://arxiv.org/abs/2410.05628v4","updated":"2025-03-11T15:18:47Z","published":"2024-10-08T02:23:53Z","title":"A Unified Framework for Motion Reasoning and Generation in Human\n  Interaction","summary":"  Recent advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural and contextually relevant text,\nenabling more human-like AI interactions. However, generating and understanding\ninteractive human-like motion, where multiple individuals engage in coordinated\nmovements, remains challenging due to the complexity of modeling these\ninteractions. Additionally, a unified and versatile model is needed to handle\ndiverse interactive scenarios, such as chat systems that dynamically adapt to\nuser instructions and assigned roles. To address these challenges, we introduce\nVIM, the Versatile Interactive Motion-language model, which integrates both\nlanguage and motion modalities to effectively understand, generate, and control\ninteractive motions in multi-turn conversational contexts. Unlike previous\nstudies that primarily focus on uni-directional tasks such as text-to-motion or\nmotion-to-text, VIM employs a unified architecture capable of simultaneously\nunderstanding and generating both motion and text modalities. Given the absence\nof an appropriate dataset to support this task, we introduce Inter-MT2, a\nlarge-scale instruction-tuning dataset containing 82.7K multi-turn interactive\nmotion instructions, covering 153K interactive motion samples. Inter-MT2 spans\ndiverse instructional scenarios, including motion editing, question answering,\nand story generation, leveraging off-the-shelf large language models and motion\ndiffusion models to construct a broad set of interactive motion instructions.\nWe extensively evaluate the versatility of VIM across multiple interactive\nmotion-related tasks, including motion-to-text, text-to-motion, reaction\ngeneration, motion editing, and reasoning about motion sequences.\n","authors":["Jeongeun Park","Sungjoon Choi","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2410.05628v4.pdf","comment":"https://vim-motion-language.github.io/"},{"id":"http://arxiv.org/abs/2503.08525v1","updated":"2025-03-11T15:17:02Z","published":"2025-03-11T15:17:02Z","title":"GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based\n  VLM Agent Training","summary":"  Reinforcement learning with verifiable outcome rewards (RLVR) has effectively\nscaled up chain-of-thought (CoT) reasoning in large language models (LLMs).\nYet, its efficacy in training vision-language model (VLM) agents for\ngoal-directed action reasoning in visual environments is less established. This\nwork investigates this problem through extensive experiments on complex card\ngames, such as 24 points, and embodied tasks from ALFWorld. We find that when\nrewards are based solely on action outcomes, RL fails to incentivize CoT\nreasoning in VLMs, instead leading to a phenomenon we termed thought collapse,\ncharacterized by a rapid loss of diversity in the agent's thoughts,\nstate-irrelevant and incomplete reasoning, and subsequent invalid actions,\nresulting in negative rewards. To counteract thought collapse, we highlight the\nnecessity of process guidance and propose an automated corrector that evaluates\nand refines the agent's reasoning at each RL step. This simple and scalable GTR\n(Guided Thought Reinforcement) framework trains reasoning and action\nsimultaneously without the need for dense, per-step human labeling. Our\nexperiments demonstrate that GTR significantly enhances the performance and\ngeneralization of the LLaVA-7b model across various visual environments,\nachieving 3-5 times higher task success rates compared to SoTA models with\nnotably smaller model sizes.\n","authors":["Tong Wei","Yijun Yang","Junliang Xing","Yuanchun Shi","Zongqing Lu","Deheng Ye"],"pdf_url":"https://arxiv.org/pdf/2503.08525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15488v2","updated":"2025-03-11T15:05:41Z","published":"2025-02-21T14:26:23Z","title":"Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D\n  Object Detection","summary":"  Camera-based multi-view 3D detection has emerged as an attractive solution\nfor autonomous driving due to its low cost and broad applicability. However,\ndespite the strong performance of PETR-based methods in 3D perception\nbenchmarks, their direct INT8 quantization for onboard deployment leads to\ndrastic accuracy drops-up to 58.2% in mAP and 36.9% in NDS on the NuScenes\ndataset. In this work, we propose Q-PETR, a quantization-aware position\nembedding transformation that re-engineers key components of the PETR framework\nto reconcile the discrepancy between the dynamic ranges of positional encodings\nand image features, and to adapt the cross-attention mechanism for low-bit\ninference. By redesigning the positional encoding module and introducing an\nadaptive quantization strategy, Q-PETR maintains floating-point performance\nwith a performance degradation of less than 1% under standard 8-bit per-tensor\npost-training quantization. Moreover, compared to its FP32 counterpart, Q-PETR\nachieves a two-fold speedup and reduces memory usage by three times, thereby\noffering a deployment-friendly solution for resource-constrained onboard\ndevices. Extensive experiments across various PETR-series models validate the\nstrong generalization and practical benefits of our approach.\n","authors":["Jiangyong Yu","Changyong Shu","Dawei Yang","Sifan Zhou","Zichen Yu","Xing Hu","Yan Chen"],"pdf_url":"https://arxiv.org/pdf/2502.15488v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06502v2","updated":"2025-03-11T14:58:58Z","published":"2024-10-09T03:10:21Z","title":"Chemistry-Inspired Diffusion with Non-Differentiable Guidance","summary":"  Recent advances in diffusion models have shown remarkable potential in the\nconditional generation of novel molecules. These models can be guided in two\nways: (i) explicitly, through additional features representing the condition,\nor (ii) implicitly, using a property predictor. However, training property\npredictors or conditional diffusion models requires an abundance of labeled\ndata and is inherently challenging in real-world applications. We propose a\nnovel approach that attenuates the limitations of acquiring large labeled\ndatasets by leveraging domain knowledge from quantum chemistry as a\nnon-differentiable oracle to guide an unconditional diffusion model. Instead of\nrelying on neural networks, the oracle provides accurate guidance in the form\nof estimated gradients, allowing the diffusion process to sample from a\nconditional distribution specified by quantum chemistry. We show that this\nresults in more precise conditional generation of novel and stable molecular\nstructures. Our experiments demonstrate that our method: (1) significantly\nreduces atomic forces, enhancing the validity of generated molecules when used\nfor stability optimization; (2) is compatible with both explicit and implicit\nguidance in diffusion models, enabling joint optimization of molecular\nproperties and stability; and (3) generalizes effectively to molecular\noptimization tasks beyond stability optimization.\n","authors":["Yuchen Shen","Chenhao Zhang","Sijie Fu","Chenghui Zhou","Newell Washburn","Barnabás Póczos"],"pdf_url":"https://arxiv.org/pdf/2410.06502v2.pdf","comment":"accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.08489v1","updated":"2025-03-11T14:42:17Z","published":"2025-03-11T14:42:17Z","title":"A Triple-Inertial Accelerated Alternating Optimization Method for Deep\n  Learning Training","summary":"  The stochastic gradient descent (SGD) algorithm has achieved remarkable\nsuccess in training deep learning models. However, it has several limitations,\nincluding susceptibility to vanishing gradients, sensitivity to input data, and\na lack of robust theoretical guarantees. In recent years, alternating\nminimization (AM) methods have emerged as a promising alternative for model\ntraining by employing gradient-free approaches to iteratively update model\nparameters. Despite their potential, these methods often exhibit slow\nconvergence rates. To address this challenge, we propose a novel\nTriple-Inertial Accelerated Alternating Minimization (TIAM) framework for\nneural network training. The TIAM approach incorporates a triple-inertial\nacceleration strategy with a specialized approximation method, facilitating\ntargeted acceleration of different terms in each sub-problem optimization. This\nintegration improves the efficiency of convergence, achieving superior\nperformance with fewer iterations. Additionally, we provide a convergence\nanalysis of the TIAM algorithm, including its global convergence properties and\nconvergence rate. Extensive experiments validate the effectiveness of the TIAM\nmethod, showing significant improvements in generalization capability and\ncomputational efficiency compared to existing approaches, particularly when\napplied to the rectified linear unit (ReLU) and its variants.\n","authors":["Chengcheng Yan","Jiawei Xu","Qingsong Wang","Zheng Peng"],"pdf_url":"https://arxiv.org/pdf/2503.08489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15472v2","updated":"2025-03-11T14:29:56Z","published":"2024-11-23T06:50:11Z","title":"KinMo: Kinematic-aware Human Motion Understanding and Generation","summary":"  Current human motion synthesis frameworks rely on global action descriptions,\ncreating a modality gap that limits both motion understanding and generation\ncapabilities. A single coarse description, such as ``run\", fails to capture\ndetails like variations in speed, limb positioning, and kinematic dynamics,\nleading to ambiguities between text and motion modalities. To address this\nchallenge, we introduce \\textbf{KinMo}, a unified framework built on a\nhierarchical describable motion representation that extends beyond global\naction by incorporating kinematic group movements and their interactions. We\ndesign an automated annotation pipeline to generate high-quality, fine-grained\ndescriptions for this decomposition, resulting in the KinMo dataset. To\nleverage these structured descriptions, we propose Hierarchical Text-Motion\nAlignment, improving spatial understanding by integrating additional motion\ndetails. Furthermore, we introduce a coarse-to-fine generation procedure to\nleverage enhanced spatial understanding to improve motion synthesis.\nExperimental results show that KinMo significantly improves motion\nunderstanding, demonstrated by enhanced text-motion retrieval performance and\nenabling more fine-grained motion generation and editing capabilities. Project\nPage: https://andypinxinliu.github.io/KinMo\n","authors":["Pengfei Zhang","Pinxin Liu","Hyeongwoo Kim","Pablo Garrido","Bindita Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2411.15472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04479v3","updated":"2025-03-11T14:28:13Z","published":"2025-03-06T14:29:52Z","title":"ToolFuzz -- Automated Agent Tool Testing","summary":"  Large Language Model (LLM) Agents leverage the advanced reasoning\ncapabilities of LLMs in real-world applications. To interface with an\nenvironment, these agents often rely on tools, such as web search or database\nAPIs. As the agent provides the LLM with tool documentation along the user\nquery, the completeness and correctness of this documentation is critical.\nHowever, tool documentation is often over-, under-, or ill-specified, impeding\nthe agent's accuracy. Standard software testing approaches struggle to identify\nthese errors as they are expressed in natural language. Thus, despite its\nimportance, there currently exists no automated method to test the tool\ndocumentation for agents. To address this issue, we present ToolFuzz, the first\nmethod for automated testing of tool documentations. ToolFuzz is designed to\ndiscover two types of errors: (1) user queries leading to tool runtime errors\nand (2) user queries that lead to incorrect agent responses. ToolFuzz can\ngenerate a large and diverse set of natural inputs, effectively finding tool\ndescription errors at a low false positive rate. Further, we present two\nstraightforward prompt-engineering approaches. We evaluate all three tool\ntesting approaches on 32 common LangChain tools and 35 newly created custom\ntools and 2 novel benchmarks to further strengthen the assessment. We find that\nmany publicly available tools suffer from underspecification. Specifically, we\nshow that ToolFuzz identifies 20x more erroneous inputs compared to the\nprompt-engineering approaches, making it a key component for building reliable\nAI agents.\n","authors":["Ivan Milev","Mislav Balunović","Maximilian Baader","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2503.04479v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13785v2","updated":"2025-03-11T14:21:27Z","published":"2025-02-19T14:51:41Z","title":"Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA\n  Therapeutics","summary":"  mRNA-based vaccines have become a major focus in the pharmaceutical industry.\nThe coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can\nstrongly influence translation efficiency, stability, degradation, and other\nfactors that collectively determine a vaccine's effectiveness. However,\noptimizing mRNA sequences for those properties remains a complex challenge.\nExisting deep learning models often focus solely on coding region optimization,\noverlooking the UTRs. We present Helix-mRNA, a structured state-space-based and\nattention hybrid model to address these challenges. In addition to a first\npre-training, a second pre-training stage allows us to specialise the model\nwith high-quality data. We employ single nucleotide tokenization of mRNA\nsequences with codon separation, ensuring prior biological and structural\ninformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,\noutperforms existing methods in analysing both UTRs and coding region\nproperties. It can process sequences 6x longer than current approaches while\nusing only 10% of the parameters of existing foundation models. Its predictive\ncapabilities extend to all mRNA regions. We open-source the model\n(https://github.com/helicalAI/helical) and model weights\n(https://huggingface.co/helical-ai/helix-mRNA).\n","authors":["Matthew Wood","Mathieu Klop","Maxime Allard"],"pdf_url":"https://arxiv.org/pdf/2502.13785v2.pdf","comment":"8 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.08472v1","updated":"2025-03-11T14:17:30Z","published":"2025-03-11T14:17:30Z","title":"Optimizing Ride-Pooling Operations with Extended Pickup and Drop-Off\n  Flexibility","summary":"  The Ride-Pool Matching Problem (RMP) is central to on-demand ride-pooling\nservices, where vehicles must be matched with multiple requests while adhering\nto service constraints such as pickup delays, detour limits, and vehicle\ncapacity. Most existing RMP solutions assume passengers are picked up and\ndropped off at their original locations, neglecting the potential for\npassengers to walk to nearby spots to meet vehicles. This assumption restricts\nthe optimization potential in ride-pooling operations. In this paper, we\npropose a novel matching method that incorporates extended pickup and drop-off\nareas for passengers. We first design a tree-based approach to efficiently\ngenerate feasible matches between passengers and vehicles. Next, we optimize\nvehicle routes to cover all designated pickup and drop-off locations while\nminimizing total travel distance. Finally, we employ dynamic assignment\nstrategies to achieve optimal matching outcomes. Experiments on city-scale taxi\ndatasets demonstrate that our method improves the number of served requests by\nup to 13\\% and average travel distance by up to 21\\% compared to leading\nexisting solutions, underscoring the potential of leveraging passenger mobility\nto significantly enhance ride-pooling service efficiency.\n","authors":["Hao Jiang","Yixing Xu","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2503.08472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08467v1","updated":"2025-03-11T14:15:01Z","published":"2025-03-11T14:15:01Z","title":"Accelerating MoE Model Inference with Expert Sharding","summary":"  Mixture of experts (MoE) models achieve state-of-the-art results in language\nmodeling but suffer from inefficient hardware utilization due to imbalanced\ntoken routing and communication overhead. While prior work has focused on\noptimizing MoE training and decoder architectures, inference for encoder-based\nMoE models in a multi-GPU with expert parallelism setting remains\nunderexplored. We introduce MoEShard, an inference system that achieves perfect\nload balancing through tensor sharding of MoE experts. Unlike existing\napproaches that rely on heuristic capacity factors or drop tokens, MoEShard\nevenly distributes computation across GPUs and ensures full token retention,\nmaximizing utilization regardless of routing skewness. We achieve this through\na strategic row- and column-wise decomposition of expert matrices. This reduces\nidle time and avoids bottlenecks caused by imbalanced expert assignments.\nFurthermore, MoEShard minimizes kernel launches by fusing decomposed expert\ncomputations, significantly improving throughput. We evaluate MoEShard against\nDeepSpeed on encoder-based architectures, demonstrating speedups of up to\n6.4$\\times$ in time to first token (TTFT). Our results show that tensor\nsharding, when properly applied to experts, is a viable and effective strategy\nfor efficient MoE inference.\n","authors":["Oana Balmau","Anne-Marie Kermarrec","Rafael Pires","André Loureiro Espírito Santo","Martijn de Vos","Milos Vujasinovic"],"pdf_url":"https://arxiv.org/pdf/2503.08467v1.pdf","comment":"To appear in the proceedings of the 5th Workshop on Machine Learning\n  and Systems (EuroMLSys 25)"},{"id":"http://arxiv.org/abs/2503.08460v1","updated":"2025-03-11T14:08:57Z","published":"2025-03-11T14:08:57Z","title":"Status and Future Prospects of the Standardization Framework Industry\n  4.0: A European Perspective","summary":"  The rapid development of Industry 4.0 technologies requires robust and\ncomprehensive standardization to ensure interoperability, safety and efficiency\nin the Industry of the Future. This paper examines the fundamental role and\nfunctionality of standardization, with a particular focus on its importance in\nEurope's regulatory framework. Based on this, selected topics in context of\nstandardization activities in context intelligent manufacturing and digital\ntwins are highlighted and, by that, an overview of the Industry 4.0 standards\nframework is provided. This paper serves both as an informative guide to the\nexisting standards in Industry 4.0 with respect to Artificial Intelligence and\nDigital Twins, and as a call to action for increased cooperation between\nstandardization bodies and the research community. By fostering such\ncollaboration, we aim to facilitate the continued development and\nimplementation of standards that will drive innovation and progress in the\nmanufacturing sector.\n","authors":["Olga Meyer","Marvin Boell","Christoph Legat"],"pdf_url":"https://arxiv.org/pdf/2503.08460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05760v2","updated":"2025-03-11T14:04:58Z","published":"2025-02-23T18:47:14Z","title":"The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its\n  Own","summary":"  This paper presents a comprehensive investigation into the capability of\nLarge Language Models (LLMs) to successfully complete a semester-long\nundergraduate control systems course. Through evaluation of 115 course\ndeliverables, we assess LLM performance using ChatGPT under a \"minimal effort\"\nprotocol that simulates realistic student usage patterns. The investigation\nemploys a rigorous testing methodology across multiple assessment formats, from\nauto-graded multiple choice questions to complex Python programming tasks and\nlong-form analytical writing. Our analysis provides quantitative insights into\nAI's strengths and limitations in handling mathematical formulations, coding\nchallenges, and theoretical concepts in control systems engineering. The LLM\nachieved a B-grade performance (82.24\\%), approaching but not exceeding the\nclass average (84.99\\%), with strongest results in structured assignments and\ngreatest limitations in open-ended projects. The findings inform discussions\nabout course design adaptation in response to AI advancement, moving beyond\nsimple prohibition towards thoughtful integration of these tools in engineering\neducation. Additional materials including syllabus, examination papers, design\nprojects, and example responses can be found at the project website:\nhttps://gradegpt.github.io.\n","authors":["Gokul Puthumanaillam","Melkior Ornik"],"pdf_url":"https://arxiv.org/pdf/2503.05760v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08455v1","updated":"2025-03-11T14:04:29Z","published":"2025-03-11T14:04:29Z","title":"Controlling Latent Diffusion Using Latent CLIP","summary":"  Instead of performing text-conditioned denoising in the image domain, latent\ndiffusion models (LDMs) operate in latent space of a variational autoencoder\n(VAE), enabling more efficient processing at reduced computational costs.\nHowever, while the diffusion process has moved to the latent space, the\ncontrastive language-image pre-training (CLIP) models, as used in many image\nprocessing tasks, still operate in pixel space. Doing so requires costly\nVAE-decoding of latent images before they can be processed. In this paper, we\nintroduce Latent-CLIP, a CLIP model that operates directly in the latent space.\nWe train Latent-CLIP on 2.7B pairs of latent images and descriptive texts, and\nshow that it matches zero-shot classification performance of similarly sized\nCLIP models on both the ImageNet benchmark and a LDM-generated version of it,\ndemonstrating its effectiveness in assessing both real and generated content.\nFurthermore, we construct Latent-CLIP rewards for reward-based noise\noptimization (ReNO) and show that they match the performance of their CLIP\ncounterparts on GenEval and T2I-CompBench while cutting the cost of the total\npipeline by 21%. Finally, we use Latent-CLIP to guide generation away from\nharmful content, achieving strong performance on the inappropriate image\nprompts (I2P) benchmark and a custom evaluation, without ever requiring the\ncostly step of decoding intermediate images.\n","authors":["Jason Becker","Chris Wendler","Peter Baylies","Robert West","Christian Wressnegger"],"pdf_url":"https://arxiv.org/pdf/2503.08455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13728v3","updated":"2025-03-11T14:02:30Z","published":"2024-03-20T16:38:26Z","title":"M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via\n  Multiplier Induced Loss Landscape Scheduling","summary":"  A probabilistic graphical model is proposed, modeling the joint model\nparameter and multiplier evolution, with a hypervolume based likelihood,\npromoting multi-objective descent in structural risk minimization. We address\nmulti-objective model parameter optimization via a surrogate single objective\npenalty loss with time-varying multipliers, equivalent to online scheduling of\nloss landscape. The multi-objective descent goal is dispatched hierarchically\ninto a series of constraint optimization sub-problems with shrinking bounds\naccording to Pareto dominance. The bound serves as setpoint for the low-level\nmultiplier controller to schedule loss landscapes via output feedback of each\nloss term. Our method forms closed loop of model parameter dynamic, circumvents\nexcessive memory requirements and extra computational burden of existing\nmulti-objective deep learning methods, and is robust against controller\nhyperparameter variation, demonstrated on domain generalization tasks with\nmulti-dimensional regularization losses.\n","authors":["Xudong Sun","Nutan Chen","Alexej Gossmann","Matteo Wohlrapp","Yu Xing","Carla Feistner","Emilio Dorigatt","Felix Drost","Daniele Scarcella","Lisa Beer","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2403.13728v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08437v1","updated":"2025-03-11T13:50:37Z","published":"2025-03-11T13:50:37Z","title":"ICPR 2024 Competition on Rider Intention Prediction","summary":"  The recent surge in the vehicle market has led to an alarming increase in\nroad accidents. This underscores the critical importance of enhancing road\nsafety measures, particularly for vulnerable road users like motorcyclists.\nHence, we introduce the rider intention prediction (RIP) competition that aims\nto address challenges in rider safety by proactively predicting maneuvers\nbefore they occur, thereby strengthening rider safety. This capability enables\nthe riders to react to the potential incorrect maneuvers flagged by advanced\ndriver assistance systems (ADAS). We collect a new dataset, namely, rider\naction anticipation dataset (RAAD) for the competition consisting of two tasks:\nsingle-view RIP and multi-view RIP. The dataset incorporates a spectrum of\ntraffic conditions and challenging navigational maneuvers on roads with varying\nlighting conditions. For the competition, we received seventy-five\nregistrations and five team submissions for inference of which we compared the\nmethods of the top three performing teams on both the RIP tasks: one\nstate-space model (Mamba2) and two learning-based approaches (SVM and\nCNN-LSTM). The results indicate that the state-space model outperformed the\nother methods across the entire dataset, providing a balanced performance\nacross maneuver classes. The SVM-based RIP method showed the second-best\nperformance when using random sampling and SMOTE. However, the CNN-LSTM method\nunderperformed, primarily due to class imbalance issues, particularly\nstruggling with minority classes. This paper details the proposed RAAD dataset\nand provides a summary of the submissions for the RIP 2024 competition.\n","authors":["Shankar Gangisetty","Abdul Wasi","Shyam Nandan Rai","C. V. Jawahar","Sajay Raj","Manish Prajapati","Ayesha Choudhary","Aaryadev Chandra","Dev Chandan","Shireen Chand","Suvaditya Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2503.08437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08417v1","updated":"2025-03-11T13:28:59Z","published":"2025-03-11T13:28:59Z","title":"AnyMoLe: Any Character Motion In-betweening Leveraging Video Diffusion\n  Models","summary":"  Despite recent advancements in learning-based motion in-betweening, a key\nlimitation has been overlooked: the requirement for character-specific\ndatasets. In this work, we introduce AnyMoLe, a novel method that addresses\nthis limitation by leveraging video diffusion models to generate motion\nin-between frames for arbitrary characters without external data. Our approach\nemploys a two-stage frame generation process to enhance contextual\nunderstanding. Furthermore, to bridge the domain gap between real-world and\nrendered character animations, we introduce ICAdapt, a fine-tuning technique\nfor video diffusion models. Additionally, we propose a ``motion-video\nmimicking'' optimization technique, enabling seamless motion generation for\ncharacters with arbitrary joint structures using 2D and 3D-aware features.\nAnyMoLe significantly reduces data dependency while generating smooth and\nrealistic transitions, making it applicable to a wide range of motion\nin-betweening tasks.\n","authors":["Kwan Yun","Seokhyeon Hong","Chaelin Kim","Junyong Noh"],"pdf_url":"https://arxiv.org/pdf/2503.08417v1.pdf","comment":"11 pages, 10 figures, CVPR 2025"},{"id":"http://arxiv.org/abs/2411.00915v3","updated":"2025-03-11T13:26:38Z","published":"2024-11-01T13:43:33Z","title":"V-LoRA: An Efficient and Flexible System Boosts Vision Applications with\n  LoRA LMM","summary":"  Large Multimodal Models (LMMs) have shown significant progress in various\ncomplex vision tasks with the solid linguistic and reasoning capacity inherited\nfrom large language models (LMMs). Low-rank adaptation (LoRA) offers a\npromising method to integrate external knowledge into LMMs, compensating for\ntheir limitations on domain-specific tasks. However, the existing LoRA model\nserving is excessively computationally expensive and causes extremely high\nlatency. In this paper, we present an end-to-end solution that empowers diverse\nvision tasks and enriches vision applications with LoRA LMMs. Our system,\nVaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware\nLoRA adapter generation approach that generates LoRA adapters rich in\ndomain-specific knowledge to meet application-specific accuracy requirements,\n2) an adaptive-tiling LoRA adapters batching operator that efficiently computes\nconcurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter\norchestration mechanism that manages application requests and LoRA adapters to\nachieve the lowest average response latency. We prototype VaLoRA on five\npopular vision tasks on three LMMs. Experiment results reveal that VaLoRA\nimproves 24-62% of the accuracy compared to the original LMMs and reduces\n20-89% of the latency compared to the state-of-the-art LoRA model serving\nsystems.\n","authors":["Liang Mi","Weijun Wang","Wenming Tu","Qingfeng He","Rui Kong","Xinyu Fang","Yazhu Dong","Yikang Zhang","Yunchun Li","Meng Li","Haipeng Dai","Guihai Chen","Yunxin Liu"],"pdf_url":"https://arxiv.org/pdf/2411.00915v3.pdf","comment":"EuroSys'2025"},{"id":"http://arxiv.org/abs/2407.08952v4","updated":"2025-03-11T13:06:04Z","published":"2024-07-12T03:15:01Z","title":"Detect, Investigate, Judge and Determine: A Knowledge-guided Framework\n  for Few-shot Fake News Detection","summary":"  Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news\nfrom real ones in extremely low-resource scenarios. This task has garnered\nincreased attention due to the widespread dissemination and harmful impact of\nfake news on social media. Large Language Models (LLMs) have demonstrated\ncompetitive performance with the help of their rich prior knowledge and\nexcellent in-context learning abilities. However, existing methods face\nsignificant limitations, such as the Understanding Ambiguity and Information\nScarcity, which significantly undermine the potential of LLMs. To address these\nshortcomings, we propose a Dual-perspective Knowledge-guided Fake News\nDetection (DKFND) model, designed to enhance LLMs from both inside and outside\nperspectives. Specifically, DKFND first identifies the knowledge concepts of\neach news article through a Detection Module. Subsequently, DKFND creatively\ndesigns an Investigation Module to retrieve inside and outside valuable\ninformation concerning to the current news, followed by another Judge Module to\nevaluate the relevance and confidence of them. Finally, a Determination Module\nfurther derives two respective predictions and obtain the final result.\nExtensive experiments on two public datasets show the efficacy of our proposed\nmethod, particularly in low-resource settings.\n","authors":["Ye Liu","Jiajun Zhu","Xukai Liu","Haoyu Tang","Yanghai Zhang","Kai Zhang","Xiaofang Zhou","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2407.08952v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07931v2","updated":"2025-03-11T12:57:43Z","published":"2024-08-15T04:59:12Z","title":"Surgical SAM 2: Real-time Segment Anything in Surgical Video by\n  Efficient Frame Pruning","summary":"  Surgical video segmentation is a critical task in computer-assisted surgery\nand is vital for enhancing surgical quality and patient outcomes. Recently, the\nSegment Anything Model 2 (SAM2) framework has shown superior advancements in\nimage and video segmentation. However, SAM2 struggles with efficiency due to\nthe high computational demands of processing high-resolution images and complex\nand long-range temporal dynamics in surgical videos. To address these\nchallenges, we introduce Surgical SAM 2 (SurgSAM2), an advanced model to\nutilize SAM2 with an Efficient Frame Pruning (EFP) mechanism, to facilitate\nreal-time surgical video segmentation. The EFP mechanism dynamically manages\nthe memory bank by selectively retaining only the most informative frames,\nreducing memory usage and computational cost while maintaining high\nsegmentation accuracy. Our extensive experiments demonstrate that SurgSAM2\nsignificantly improves both efficiency and segmentation accuracy compared to\nthe vanilla SAM2. Remarkably, SurgSAM2 achieves a 3$\\times$ FPS compared with\nSAM2, while also delivering state-of-the-art performance after fine-tuning with\nlower-resolution data. These advancements establish SurgSAM2 as a leading model\nfor surgical video analysis, making real-time surgical video segmentation in\nresource-constrained environments a reality. Our source code is available at\nhttps://github.com/jinlab-imvr/Surgical-SAM-2.\n","authors":["Haofeng Liu","Erli Zhang","Junde Wu","Mingxuan Hong","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2408.07931v2.pdf","comment":"Accepted by NeurIPS 2024 Workshop AIM-FM"},{"id":"http://arxiv.org/abs/2503.08388v1","updated":"2025-03-11T12:53:24Z","published":"2025-03-11T12:53:24Z","title":"V-Max: Making RL practical for Autonomous Driving","summary":"  Learning-based decision-making has the potential to enable generalizable\nAutonomous Driving (AD) policies, reducing the engineering overhead of\nrule-based approaches. Imitation Learning (IL) remains the dominant paradigm,\nbenefiting from large-scale human demonstration datasets, but it suffers from\ninherent limitations such as distribution shift and imitation gaps.\nReinforcement Learning (RL) presents a promising alternative, yet its adoption\nin AD remains limited due to the lack of standardized and efficient research\nframeworks. To this end, we introduce V-Max, an open research framework\nproviding all the necessary tools to make RL practical for AD. V-Max is built\non Waymax, a hardware-accelerated AD simulator designed for large-scale\nexperimentation. We extend it using ScenarioNet's approach, enabling the fast\nsimulation of diverse AD datasets. V-Max integrates a set of observation and\nreward functions, transformer-based encoders, and training pipelines.\nAdditionally, it includes adversarial evaluation settings and an extensive set\nof evaluation metrics. Through a large-scale benchmark, we analyze how network\narchitectures, observation functions, training data, and reward shaping impact\nRL performance.\n","authors":["Valentin Charraut","Thomas Tournaire","Waël Doulazmi","Thibault Buhet"],"pdf_url":"https://arxiv.org/pdf/2503.08388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16450v3","updated":"2025-03-11T12:52:28Z","published":"2024-05-26T06:33:48Z","title":"Synthesizing Programmatic Reinforcement Learning Policies with Large\n  Language Model Guided Search","summary":"  Programmatic reinforcement learning (PRL) has been explored for representing\npolicies through programs as a means to achieve interpretability and\ngeneralization. Despite promising outcomes, current state-of-the-art PRL\nmethods are hindered by sample inefficiency, necessitating tens of millions of\nprogram-environment interactions. To tackle this challenge, we introduce a\nnovel LLM-guided search framework (LLM-GS). Our key insight is to leverage the\nprogramming expertise and common sense reasoning of LLMs to enhance the\nefficiency of assumption-free, random-guessing search methods. We address the\nchallenge of LLMs' inability to generate precise and grammatically correct\nprograms in domain-specific languages (DSLs) by proposing a Pythonic-DSL\nstrategy - an LLM is instructed to initially generate Python codes and then\nconvert them into DSL programs. To further optimize the LLM-generated programs,\nwe develop a search algorithm named Scheduled Hill Climbing, designed to\nefficiently explore the programmatic search space to improve the programs\nconsistently. Experimental results in the Karel domain demonstrate our LLM-GS\nframework's superior effectiveness and efficiency. Extensive ablation studies\nfurther verify the critical role of our Pythonic-DSL strategy and Scheduled\nHill Climbing algorithm. Moreover, we conduct experiments with two novel tasks,\nshowing that LLM-GS enables users without programming skills and knowledge of\nthe domain or DSL to describe the tasks in natural language to obtain\nperformant programs.\n","authors":["Max Liu","Chan-Hung Yu","Wei-Hsu Lee","Cheng-Wei Hung","Yen-Chun Chen","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2405.16450v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11663v3","updated":"2025-03-11T12:52:18Z","published":"2024-09-18T03:01:27Z","title":"Training with Differential Privacy: A Gradient-Preserving Noise\n  Reduction Approach with Provable Security","summary":"  Deep learning models have been extensively adopted in various regions due to\ntheir ability to represent hierarchical features, which highly rely on the\ntraining set and procedures. Thus, protecting the training process and deep\nlearning algorithms is paramount in privacy preservation. Although Differential\nPrivacy (DP) as a powerful cryptographic primitive has achieved satisfying\nresults in deep learning training, the existing schemes still fall short in\npreserving model utility, i.e., they either invoke a high noise scale or\ninevitably harm the original gradients. To address the above issues, in this\npaper, we present a more robust and provably secure approach for differentially\nprivate training called GReDP. Specifically, we compute the model gradients in\nthe frequency domain and adopt a new approach to reduce the noise level. Unlike\nprevious work, our GReDP only requires half of the noise scale compared to\nDPSGD [1] while keeping all the gradient information intact. We present a\ndetailed analysis of our method both theoretically and empirically. The\nexperimental results show that our GReDP works consistently better than the\nbaselines on all models and training settings.\n","authors":["Haodi Wang","Tangyu Jiang","Yu Guo","Chengjun Cai","Cong Wang","Xiaohua Jia"],"pdf_url":"https://arxiv.org/pdf/2409.11663v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08381v1","updated":"2025-03-11T12:40:42Z","published":"2025-03-11T12:40:42Z","title":"InfluenceNet: AI Models for Banzhaf and Shapley Value Prediction","summary":"  Power indices are essential in assessing the contribution and influence of\nindividual agents in multi-agent systems, providing crucial insights into\ncollaborative dynamics and decision-making processes. While invaluable,\ntraditional computational methods for exact or estimated power indices values\nrequire significant time and computational constraints, especially for large\n$(n\\ge10)$ coalitions. These constraints have historically limited researchers'\nability to analyse complex multi-agent interactions comprehensively. To address\nthis limitation, we introduce a novel Neural Networks-based approach that\nefficiently estimates power indices for voting games, demonstrating comparable\nand often superiour performance to existing tools in terms of both speed and\naccuracy. This method not only addresses existing computational bottlenecks,\nbut also enables rapid analysis of large coalitions, opening new avenues for\nmulti-agent system research by overcoming previous computational limitations\nand providing researchers with a more accessible, scalable analytical tool.This\nincreased efficiency will allow for the analysis of more complex and realistic\nmulti-agent scenarios.\n","authors":["Benjamin Kempinski","Tal Kachman"],"pdf_url":"https://arxiv.org/pdf/2503.08381v1.pdf","comment":"20 pages main text + 6 pages appendix, 11 figures. Accepted to\n  IntelliSys 2025"},{"id":"http://arxiv.org/abs/2503.06551v2","updated":"2025-03-11T12:33:04Z","published":"2025-03-09T10:43:17Z","title":"ChatGPT-4 in the Turing Test: A Critical Analysis","summary":"  This paper critically examines the recent publication \"ChatGPT-4 in the\nTuring Test\" by Restrepo Echavarr\\'ia (2025), challenging its central claims\nregarding the absence of minimally serious test implementations and the\nconclusion that ChatGPT-4 fails the Turing Test. The analysis reveals that the\ncriticisms based on rigid criteria and limited experimental data are not fully\njustified. More importantly, the paper makes several constructive contributions\nthat enrich our understanding of Turing Test implementations. It demonstrates\nthat two distinct formats--the three-player and two-player tests--are both\nvalid, each with unique methodological implications. The work distinguishes\nbetween absolute criteria (reflecting an optimal 50% identification rate in a\nthree-player format) and relative criteria (which measure how closely a\nmachine's performance approximates that of a human), offering a more nuanced\nevaluation framework. Furthermore, the paper clarifies the probabilistic\nunderpinnings of both test types by modeling them as Bernoulli\nexperiments--correlated in the three-player version and uncorrelated in the\ntwo-player version. This formalization allows for a rigorous separation between\nthe theoretical criteria for passing the test, defined in probabilistic terms,\nand the experimental data that require robust statistical methods for proper\ninterpretation. In doing so, the paper not only refutes key aspects of the\ncriticized study but also lays a solid foundation for future research on\nobjective measures of how closely an AI's behavior aligns with, or deviates\nfrom, that of a human being.\n","authors":["Marco Giunti"],"pdf_url":"https://arxiv.org/pdf/2503.06551v2.pdf","comment":"14 pages, 1 Appendix, added 1 missing item in References, corrected\n  typos"},{"id":"http://arxiv.org/abs/2503.05336v2","updated":"2025-03-11T12:31:22Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Deb Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v2.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2404.02611v3","updated":"2025-03-11T12:24:01Z","published":"2024-04-03T09:56:38Z","title":"X-SHIELD: Regularization for eXplainable Artificial Intelligence","summary":"  As artificial intelligence systems become integral across domains, the demand\nfor explainability grows, the called eXplainable artificial intelligence (XAI).\nExisting efforts primarily focus on generating and evaluating explanations for\nblack-box models while a critical gap in directly enhancing models remains\nthrough these evaluations. It is important to consider the potential of this\nexplanation process to improve model quality with a feedback on training as\nwell. XAI may be used to improve model performance while boosting its\nexplainability. Under this view, this paper introduces Transformation -\nSelective Hidden Input Evaluation for Learning Dynamics (T-SHIELD), a\nregularization family designed to improve model quality by hiding features of\ninput, forcing the model to generalize without those features. Within this\nfamily, we propose the XAI - SHIELD(X-SHIELD), a regularization for explainable\nartificial intelligence, which uses explanations to select specific features to\nhide. In contrast to conventional approaches, X-SHIELD regularization\nseamlessly integrates into the objective function enhancing model\nexplainability while also improving performance. Experimental validation on\nbenchmark datasets underscores X-SHIELD's effectiveness in improving\nperformance and overall explainability. The improvement is validated through\nexperiments comparing models with and without the X-SHIELD regularization, with\nfurther analysis exploring the rationale behind its design choices. This\nestablishes X-SHIELD regularization as a promising pathway for developing\nreliable artificial intelligence regularization.\n","authors":["Iván Sevillano-García","Julián Luengo","Francisco Herrera"],"pdf_url":"https://arxiv.org/pdf/2404.02611v3.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.05244v2","updated":"2025-03-11T12:11:00Z","published":"2025-03-07T08:56:20Z","title":"WritingBench: A Comprehensive Benchmark for Generative Writing","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.\n","authors":["Yuning Wu","Jiahao Mei","Ming Yan","Chenliang Li","Shaopeng Lai","Yuran Ren","Zijia Wang","Ji Zhang","Mengyue Wu","Qin Jin","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08354v1","updated":"2025-03-11T12:09:11Z","published":"2025-03-11T12:09:11Z","title":"Robust Latent Matters: Boosting Image Generation with Sampling Error","summary":"  Recent image generation schemes typically capture image distribution in a\npre-constructed latent space relying on a frozen image tokenizer. Though the\nperformance of tokenizer plays an essential role to the successful generation,\nits current evaluation metrics (e.g. rFID) fail to precisely assess the\ntokenizer and correlate its performance to the generation quality (e.g. gFID).\nIn this paper, we comprehensively analyze the reason for the discrepancy of\nreconstruction and generation qualities in a discrete latent space, and, from\nwhich, we propose a novel plug-and-play tokenizer training scheme to facilitate\nlatent space construction. Specifically, a latent perturbation approach is\nproposed to simulate sampling noises, i.e., the unexpected tokens sampled, from\nthe generative process. With the latent perturbation, we further propose (1) a\nnovel tokenizer evaluation metric, i.e., pFID, which successfully correlates\nthe tokenizer performance to generation quality and (2) a plug-and-play\ntokenizer training scheme, which significantly enhances the robustness of\ntokenizer thus boosting the generation quality and convergence speed. Extensive\nbenchmarking are conducted with 11 advanced discrete image tokenizers with 2\nautoregressive generation models to validate our approach. The tokenizer\ntrained with our proposed latent perturbation achieve a notable 1.60 gFID with\nclassifier-free guidance (CFG) and 3.45 gFID without CFG with a $\\sim$400M\ngenerator. Code: https://github.com/lxa9867/ImageFolder.\n","authors":["Kai Qiu","Xiang Li","Jason Kuen","Hao Chen","Xiaohao Xu","Jiuxiang Gu","Yinyi Luo","Bhiksha Raj","Zhe Lin","Marios Savvides"],"pdf_url":"https://arxiv.org/pdf/2503.08354v1.pdf","comment":"17 pages, 13 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.08332v1","updated":"2025-03-11T11:45:05Z","published":"2025-03-11T11:45:05Z","title":"MINT-Demo: Membership Inference Test Demonstrator","summary":"  We present the Membership Inference Test Demonstrator, to emphasize the need\nfor more transparent machine learning training processes. MINT is a technique\nfor experimentally determining whether certain data has been used during the\ntraining of machine learning models. We conduct experiments with popular face\nrecognition models and 5 public databases containing over 22M images. Promising\nresults, up to 89% accuracy are achieved, suggesting that it is possible to\nrecognize if an AI model has been trained with specific data. Finally, we\npresent a MINT platform as demonstrator of this technology aimed to promote\ntransparency in AI training.\n","authors":["Daniel DeAlcala","Aythami Morales","Julian Fierrez","Gonzalo Mancera","Ruben Tolosana","Ruben Vera-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2503.08332v1.pdf","comment":"Demo Paper Presented at Demo Track CVPR 24' and at AAAI 25' AIGOV\n  workshop"},{"id":"http://arxiv.org/abs/2503.08327v1","updated":"2025-03-11T11:40:10Z","published":"2025-03-11T11:40:10Z","title":"Adding Chocolate to Mint: Mitigating Metric Interference in Machine\n  Translation","summary":"  As automatic metrics become increasingly stronger and widely adopted, the\nrisk of unintentionally \"gaming the metric\" during model development rises.\nThis issue is caused by metric interference (Mint), i.e., the use of the same\nor related metrics for both model tuning and evaluation. Mint can misguide\npractitioners into being overoptimistic about the performance of their systems:\nas system outputs become a function of the interfering metric, their estimated\nquality loses correlation with human judgments. In this work, we analyze two\ncommon cases of Mint in machine translation-related tasks: filtering of\ntraining data, and decoding with quality signals. Importantly, we find that\nMint strongly distorts instance-level metric scores, even when metrics are not\ndirectly optimized for -- questioning the common strategy of leveraging a\ndifferent, yet related metric for evaluation that is not used for tuning. To\naddress this problem, we propose MintAdjust, a method for more reliable\nevaluation under Mint. On the WMT24 MT shared task test set, MintAdjust ranks\ntranslations and systems more accurately than state-of-the-art-metrics across a\nmajority of language pairs, especially for high-quality systems. Furthermore,\nMintAdjust outperforms AutoRank, the ensembling method used by the organizers.\n","authors":["José Pombal","Nuno M. Guerreiro","Ricardo Rei","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2503.08327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08325v1","updated":"2025-03-11T11:37:43Z","published":"2025-03-11T11:37:43Z","title":"Prototype-based Heterogeneous Federated Learning for Blade Icing\n  Detection in Wind Turbines with Class Imbalanced Data","summary":"  Wind farms, typically in high-latitude regions, face a high risk of blade\nicing. Traditional centralized training methods raise serious privacy concerns.\nTo enhance data privacy in detecting wind turbine blade icing, traditional\nfederated learning (FL) is employed. However, data heterogeneity, resulting\nfrom collections across wind farms in varying environmental conditions, impacts\nthe model's optimization capabilities. Moreover, imbalances in wind turbine\ndata lead to models that tend to favor recognizing majority classes, thus\nneglecting critical icing anomalies. To tackle these challenges, we propose a\nfederated prototype learning model for class-imbalanced data in heterogeneous\nenvironments to detect wind turbine blade icing. We also propose a contrastive\nsupervised loss function to address the class imbalance problem. Experiments on\nreal data from 20 turbines across two wind farms show our method outperforms\nfive FL models and five class imbalance methods, with an average improvement of\n19.64\\% in \\( mF_{\\beta} \\) and 5.73\\% in \\( m \\)BA compared to the second-best\nmethod, BiFL.\n","authors":["Lele Qi","Mengna Liu","Xu Cheng","Fan Shi","Xiufeng Liu","Shengyong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02651v2","updated":"2025-03-11T11:34:10Z","published":"2024-10-03T16:36:05Z","title":"CAX: Cellular Automata Accelerated in JAX","summary":"  Cellular automata have become a cornerstone for investigating emergence and\nself-organization across diverse scientific disciplines. However, the absence\nof a hardware-accelerated cellular automata library limits the exploration of\nnew research directions, hinders collaboration, and impedes reproducibility. In\nthis work, we introduce CAX (Cellular Automata Accelerated in JAX), a\nhigh-performance and flexible open-source library designed to accelerate\ncellular automata research. CAX delivers cutting-edge performance through\nhardware acceleration while maintaining flexibility through its modular\narchitecture, intuitive API, and support for both discrete and continuous\ncellular automata in arbitrary dimensions. We demonstrate CAX's performance and\nflexibility through a wide range of benchmarks and applications. From classic\nmodels like elementary cellular automata and Conway's Game of Life to advanced\napplications such as growing neural cellular automata and self-classifying\nMNIST digits, CAX speeds up simulations up to 2,000 times faster. Furthermore,\nwe demonstrate CAX's potential to accelerate research by presenting a\ncollection of three novel cellular automata experiments, each implemented in\njust a few lines of code thanks to the library's modular architecture. Notably,\nwe show that a simple one-dimensional cellular automaton can outperform GPT-4\non the 1D-ARC challenge.\n","authors":["Maxence Faldor","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2410.02651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08322v1","updated":"2025-03-11T11:34:06Z","published":"2025-03-11T11:34:06Z","title":"Evaluating Interpretable Reinforcement Learning by Distilling Policies\n  into Programs","summary":"  There exist applications of reinforcement learning like medicine where\npolicies need to be ''interpretable'' by humans. User studies have shown that\nsome policy classes might be more interpretable than others. However, it is\ncostly to conduct human studies of policy interpretability. Furthermore, there\nis no clear definition of policy interpretabiliy, i.e., no clear metrics for\ninterpretability and thus claims depend on the chosen definition. We tackle the\nproblem of empirically evaluating policies interpretability without humans.\nDespite this lack of clear definition, researchers agree on the notions of\n''simulatability'': policy interpretability should relate to how humans\nunderstand policy actions given states. To advance research in interpretable\nreinforcement learning, we contribute a new methodology to evaluate policy\ninterpretability. This new methodology relies on proxies for simulatability\nthat we use to conduct a large-scale empirical evaluation of policy\ninterpretability. We use imitation learning to compute baseline policies by\ndistilling expert neural networks into small programs. We then show that using\nour methodology to evaluate the baselines interpretability leads to similar\nconclusions as user studies. We show that increasing interpretability does not\nnecessarily reduce performances and can sometimes increase them. We also show\nthat there is no policy class that better trades off interpretability and\nperformance across tasks making it necessary for researcher to have\nmethodologies for comparing policies interpretability.\n","authors":["Hector Kohler","Quentin Delfosse","Waris Radji","Riad Akrour","Philippe Preux"],"pdf_url":"https://arxiv.org/pdf/2503.08322v1.pdf","comment":"12 pages of main text, under review"},{"id":"http://arxiv.org/abs/2406.01423v2","updated":"2025-03-11T11:25:21Z","published":"2024-06-03T15:24:15Z","title":"Value Improved Actor Critic Algorithms","summary":"  To learn approximately optimal acting policies for decision problems, modern\nActor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the\nacting policy and greedification operators to iteratively improve it. The\nreliance on DNNs suggests an improvement that is gradient based, which is per\nstep much less greedy than the improvement possible by greedier operators such\nas the greedy update used by Q-learning algorithms. On the other hand, slow and\nsteady changes to the policy can also be beneficial for the stability of the\nlearning process, resulting in a tradeoff between greedification and stability.\nTo address this tradeoff, we propose to extend the standard framework of actor\ncritic algorithms with value-improvement: a second greedification operator\napplied only when updating the policy's value estimate. In this framework the\nagent can evaluate non-parameterized policies and perform much greedier updates\nwhile maintaining the steady gradient-based improvement to the parameterized\nacting policy. We prove that this approach converges in the popular analysis\nscheme of Generalized Policy Iteration in the finite-horizon domain.\nEmpirically, incorporating value-improvement into the popular off-policy\nactor-critic algorithms TD3 and SAC significantly improves or matches\nperformance over their respective baselines, across different environments from\nthe DeepMind continuous control domain, with negligible compute and\nimplementation cost.\n","authors":["Yaniv Oren","Moritz A. Zanger","Pascal R. van der Vaart","Mustafa Mert Celikok","Matthijs T. J. Spaan","Wendelin Bohmer"],"pdf_url":"https://arxiv.org/pdf/2406.01423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02189v2","updated":"2025-03-11T11:22:17Z","published":"2024-10-03T04:07:51Z","title":"Agent-Oriented Planning in Multi-Agent Systems","summary":"  Through the collaboration of multiple LLM-empowered agents possessing diverse\nexpertise and tools, multi-agent systems achieve impressive progress in solving\nreal-world problems. Given the user queries, the meta-agents, serving as the\nbrain within multi-agent systems, are required to decompose the queries into\nmultiple sub-tasks that can be allocated to suitable agents capable of solving\nthem, so-called agent-oriented planning. In this study, we identify three\ncritical design principles of agent-oriented planning, including solvability,\ncompleteness, and non-redundancy, to ensure that each sub-task can be\neffectively resolved, resulting in satisfactory responses to user queries.\nThese principles further inspire us to propose AOP, a novel framework for\nagent-oriented planning in multi-agent systems, leveraging a fast task\ndecomposition and allocation process followed by an effective and efficient\nevaluation via a reward model. According to the evaluation results, the\nmeta-agent is also responsible for promptly making necessary adjustments to\nsub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to\nfurther enhance the effectiveness and robustness of such a problem-solving\nprocess. Extensive experiments demonstrate the advancement of AOP in solving\nreal-world problems compared to both single-agent systems and existing planning\nstrategies for multi-agent systems. The source code is available at\nhttps://github.com/lalaliat/Agent-Oriented-Planning\n","authors":["Ao Li","Yuexiang Xie","Songze Li","Fugee Tsung","Bolin Ding","Yaliang Li"],"pdf_url":"https://arxiv.org/pdf/2410.02189v2.pdf","comment":"Accepted by ICLR'2025"},{"id":"http://arxiv.org/abs/2503.08308v1","updated":"2025-03-11T11:18:53Z","published":"2025-03-11T11:18:53Z","title":"Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with\n  an Uncertainty-Aware Agentic Framework","summary":"  Multimodal large language models (MLLMs) show promise in tasks like visual\nquestion answering (VQA) but still face challenges in multimodal reasoning.\nRecent works adapt agentic frameworks or chain-of-thought (CoT) reasoning to\nimprove performance. However, CoT-based multimodal reasoning often demands\ncostly data annotation and fine-tuning, while agentic approaches relying on\nexternal tools risk introducing unreliable output from these tools. In this\npaper, we propose Seeing and Reasoning with Confidence (SRICE), a training-free\nmultimodal reasoning framework that integrates external vision models with\nuncertainty quantification (UQ) into an MLLM to address these challenges.\nSpecifically, SRICE guides the inference process by allowing MLLM to\nautonomously select regions of interest through multi-stage interactions with\nthe help of external tools. We propose to use a conformal prediction-based\napproach to calibrate the output of external tools and select the optimal tool\nby estimating the uncertainty of an MLLM's output. Our experiment shows that\nthe average improvement of SRICE over the base MLLM is 4.6% on five datasets\nand the performance on some datasets even outperforms fine-tuning-based\nmethods, revealing the significance of ensuring reliable tool use in an MLLM\nagent.\n","authors":["Zhuo Zhi","Chen Feng","Adam Daneshmend","Mine Orlu","Andreas Demosthenous","Lu Yin","Da Li","Ziquan Liu","Miguel R. D. Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2503.08308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08302v1","updated":"2025-03-11T11:13:58Z","published":"2025-03-11T11:13:58Z","title":"General-Purpose Aerial Intelligent Agents Empowered by Large Language\n  Models","summary":"  The emergence of large language models (LLMs) opens new frontiers for\nunmanned aerial vehicle (UAVs), yet existing systems remain confined to\npredefined tasks due to hardware-software co-design challenges. This paper\npresents the first aerial intelligent agent capable of open-world task\nexecution through tight integration of LLM-based reasoning and robotic\nautonomy. Our hardware-software co-designed system addresses two fundamental\nlimitations: (1) Onboard LLM operation via an edge-optimized computing\nplatform, achieving 5-6 tokens/sec inference for 14B-parameter models at 220W\npeak power; (2) A bidirectional cognitive architecture that synergizes slow\ndeliberative planning (LLM task planning) with fast reactive control (state\nestimation, mapping, obstacle avoidance, and motion planning). Validated\nthrough preliminary results using our prototype, the system demonstrates\nreliable task planning and scene understanding in communication-constrained\nenvironments, such as sugarcane monitoring, power grid inspection, mine tunnel\nexploration, and biological observation applications. This work establishes a\nnovel framework for embodied aerial artificial intelligence, bridging the gap\nbetween task planning and robotic autonomy in open environments.\n","authors":["Ji Zhao","Xiao Lin"],"pdf_url":"https://arxiv.org/pdf/2503.08302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08301v1","updated":"2025-03-11T11:13:11Z","published":"2025-03-11T11:13:11Z","title":"Large Language Model as Meta-Surrogate for Data-Driven Many-Task\n  Optimization: A Proof-of-Principle Study","summary":"  In many-task optimization scenarios, surrogate models are valuable for\nmitigating the computational burden of repeated fitness evaluations across\ntasks. This study proposes a novel meta-surrogate framework to assist many-task\noptimization, by leveraging the knowledge transfer strengths and emergent\ncapabilities of large language models (LLMs). We formulate a unified framework\nfor many-task fitness prediction, by defining a universal model with metadata\nto fit a group of problems. Fitness prediction is performed on metadata and\ndecision variables, enabling efficient knowledge sharing across tasks and\nadaptability to new tasks. The LLM-based meta-surrogate treats fitness\nprediction as conditional probability estimation, employing a unified token\nsequence representation for task metadata, inputs, and outputs. This approach\nfacilitates efficient inter-task knowledge sharing through shared token\nembeddings and captures complex task dependencies via multi-task model\ntraining. Experimental results demonstrate the model's emergent generalization\nability, including zero-shot performance on problems with unseen dimensions.\nWhen integrated into evolutionary transfer optimization (ETO), our framework\nsupports dual-level knowledge transfer -- at both the surrogate and individual\nlevels -- enhancing optimization efficiency and robustness. This work\nestablishes a novel foundation for applying LLMs in surrogate modeling,\noffering a versatile solution for many-task optimization.\n","authors":["Xian-Rong Zhang","Yue-Jiao Gong","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08301v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2503.08295v1","updated":"2025-03-11T11:07:35Z","published":"2025-03-11T11:07:35Z","title":"D3PO: Preference-Based Alignment of Discrete Diffusion Models","summary":"  Diffusion models have achieved state-of-the-art performance across multiple\ndomains, with recent advancements extending their applicability to discrete\ndata. However, aligning discrete diffusion models with task-specific\npreferences remains challenging, particularly in scenarios where explicit\nreward functions are unavailable. In this work, we introduce Discrete Diffusion\nDPO (D3PO), the first adaptation of Direct Preference Optimization (DPO) to\ndiscrete diffusion models formulated as continuous-time Markov chains. Our\napproach derives a novel loss function that directly fine-tunes the generative\nprocess using preference data while preserving fidelity to a reference\ndistribution. We validate D3PO on a structured binary sequence generation task,\ndemonstrating that the method effectively aligns model outputs with preferences\nwhile maintaining structural validity. Our results highlight that D3PO enables\ncontrolled fine-tuning without requiring explicit reward models, making it a\npractical alternative to reinforcement learning-based approaches. Future\nresearch will explore extending D3PO to more complex generative tasks,\nincluding language modeling and protein sequence generation, as well as\ninvestigating alternative noise schedules, such as uniform noising, to enhance\nflexibility across different applications.\n","authors":["Umberto Borso","Davide Paglieri","Jude Wells","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2503.08295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08292v1","updated":"2025-03-11T11:05:42Z","published":"2025-03-11T11:05:42Z","title":"Large Language Models for Outpatient Referral: Problem Definition,\n  Benchmarking and Challenges","summary":"  Large language models (LLMs) are increasingly applied to outpatient referral\ntasks across healthcare systems. However, there is a lack of standardized\nevaluation criteria to assess their effectiveness, particularly in dynamic,\ninteractive scenarios. In this study, we systematically examine the\ncapabilities and limitations of LLMs in managing tasks within Intelligent\nOutpatient Referral (IOR) systems and propose a comprehensive evaluation\nframework specifically designed for such systems. This framework comprises two\ncore tasks: static evaluation, which focuses on evaluating the ability of\npredefined outpatient referrals, and dynamic evaluation, which evaluates\ncapabilities of refining outpatient referral recommendations through iterative\ndialogues. Our findings suggest that LLMs offer limited advantages over\nBERT-like models, but show promise in asking effective questions during\ninteractive dialogues.\n","authors":["Xiaoxiao Liu","Qingying Xiao","Junying Chen","Xiangyi Feng","Xiangbo Wu","Bairui Zhang","Xiang Wan","Jian Chang","Guangjun Yu","Yan Hu","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08280v1","updated":"2025-03-11T10:50:14Z","published":"2025-03-11T10:50:14Z","title":"OminiControl2: Efficient Conditioning for Diffusion Transformers","summary":"  Fine-grained control of text-to-image diffusion transformer models (DiT)\nremains a critical challenge for practical deployment. While recent advances\nsuch as OminiControl and others have enabled a controllable generation of\ndiverse control signals, these methods face significant computational\ninefficiency when handling long conditional inputs. We present OminiControl2,\nan efficient framework that achieves efficient image-conditional image\ngeneration. OminiControl2 introduces two key innovations: (1) a dynamic\ncompression strategy that streamlines conditional inputs by preserving only the\nmost semantically relevant tokens during generation, and (2) a conditional\nfeature reuse mechanism that computes condition token features only once and\nreuses them across denoising steps. These architectural improvements preserve\nthe original framework's parameter efficiency and multi-modal versatility while\ndramatically reducing computational costs. Our experiments demonstrate that\nOminiControl2 reduces conditional processing overhead by over 90% compared to\nits predecessor, achieving an overall 5.9$\\times$ speedup in multi-conditional\ngeneration scenarios. This efficiency enables the practical implementation of\ncomplex, multi-modal control for high-quality image synthesis with DiT models.\n","authors":["Zhenxiong Tan","Qiaochu Xue","Xingyi Yang","Songhua Liu","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08275v1","updated":"2025-03-11T10:43:01Z","published":"2025-03-11T10:43:01Z","title":"Beyond Outlining: Heterogeneous Recursive Planning for Adaptive\n  Long-form Writing with Language Models","summary":"  Long-form writing agents require flexible integration and interaction across\ninformation retrieval, reasoning, and composition. Current approaches rely on\npredetermined workflows and rigid thinking patterns to generate outlines before\nwriting, resulting in constrained adaptability during writing. In this paper we\npropose a general agent framework that achieves human-like adaptive writing\nthrough recursive task decomposition and dynamic integration of three\nfundamental task types, i.e. retrieval, reasoning, and composition. Our\nmethodology features: 1) a planning mechanism that interleaves recursive task\ndecomposition and execution, eliminating artificial restrictions on writing\nworkflow; and 2) integration of task types that facilitates heterogeneous task\ndecomposition. Evaluations on both fiction writing and technical report\ngeneration show that our method consistently outperforms state-of-the-art\napproaches across all automatic evaluation metrics, which demonstrate the\neffectiveness and broad applicability of our proposed framework.\n","authors":["Ruibin Xiong","Yimeng Chen","Dmitrii Khizbullin","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2503.08275v1.pdf","comment":"29 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.15098v5","updated":"2025-03-11T10:41:44Z","published":"2024-11-22T17:55:15Z","title":"OminiControl: Minimal and Universal Control for Diffusion Transformer","summary":"  We present OminiControl, a novel approach that rethinks how image conditions\nare integrated into Diffusion Transformer (DiT) architectures. Current image\nconditioning methods either introduce substantial parameter overhead or handle\nonly specific control tasks effectively, limiting their practical versatility.\nOminiControl addresses these limitations through three key innovations: (1) a\nminimal architectural design that leverages the DiT's own VAE encoder and\ntransformer blocks, requiring just 0.1% additional parameters; (2) a unified\nsequence processing strategy that combines condition tokens with image tokens\nfor flexible token interactions; and (3) a dynamic position encoding mechanism\nthat adapts to both spatially-aligned and non-aligned control tasks. Our\nextensive experiments show that this streamlined approach not only matches but\nsurpasses the performance of specialized methods across multiple conditioning\ntasks. To overcome data limitations in subject-driven generation, we also\nintroduce Subjects200K, a large-scale dataset of identity-consistent image\npairs synthesized using DiT models themselves. This work demonstrates that\neffective image control can be achieved without architectural complexity,\nopening new possibilities for efficient and versatile image generation systems.\n","authors":["Zhenxiong Tan","Songhua Liu","Xingyi Yang","Qiaochu Xue","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2411.15098v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08269v1","updated":"2025-03-11T10:34:57Z","published":"2025-03-11T10:34:57Z","title":"Adv-CPG: A Customized Portrait Generation Framework with Facial\n  Adversarial Attacks","summary":"  Recent Customized Portrait Generation (CPG) methods, taking a facial image\nand a textual prompt as inputs, have attracted substantial attention. Although\nthese methods generate high-fidelity portraits, they fail to prevent the\ngenerated portraits from being tracked and misused by malicious face\nrecognition systems. To address this, this paper proposes a Customized Portrait\nGeneration framework with facial Adversarial attacks (Adv-CPG). Specifically,\nto achieve facial privacy protection, we devise a lightweight local ID\nencryptor and an encryption enhancer. They implement progressive double-layer\nencryption protection by directly injecting the target identity and adding\nadditional identity guidance, respectively. Furthermore, to accomplish\nfine-grained and personalized portrait generation, we develop a multi-modal\nimage customizer capable of generating controlled fine-grained facial features.\nTo the best of our knowledge, Adv-CPG is the first study that introduces facial\nadversarial attacks into CPG. Extensive experiments demonstrate the superiority\nof Adv-CPG, e.g., the average attack success rate of the proposed Adv-CPG is\n28.1% and 2.86% higher compared to the SOTA noise-based attack methods and\nunconstrained attack methods, respectively.\n","authors":["Junying Wang","Hongyuan Zhang","Yuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.08269v1.pdf","comment":"Accepted by CVPR-25"},{"id":"http://arxiv.org/abs/2503.08257v1","updated":"2025-03-11T10:21:50Z","published":"2025-03-11T10:21:50Z","title":"DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with\n  Physics Awareness","summary":"  A dexterous hand capable of grasping any object is essential for the\ndevelopment of general-purpose embodied intelligent robots. However, due to the\nhigh degree of freedom in dexterous hands and the vast diversity of objects,\ngenerating high-quality, usable grasping poses in a robust manner is a\nsignificant challenge. In this paper, we introduce DexGrasp Anything, a method\nthat effectively integrates physical constraints into both the training and\nsampling phases of a diffusion-based generative model, achieving\nstate-of-the-art performance across nearly all open datasets. Additionally, we\npresent a new dexterous grasping dataset containing over 3.4 million diverse\ngrasping poses for more than 15k different objects, demonstrating its potential\nto advance universal dexterous grasping. The code of our method and our dataset\nwill be publicly released soon.\n","authors":["Yiming Zhong","Qi Jiang","Jingyi Yu","Yuexin Ma"],"pdf_url":"https://arxiv.org/pdf/2503.08257v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08251v1","updated":"2025-03-11T10:14:53Z","published":"2025-03-11T10:14:53Z","title":"MT-NAM: An Efficient and Adaptive Model for Epileptic Seizure Detection","summary":"  Enhancing the accuracy and efficiency of machine learning algorithms employed\nin neural interface systems is crucial for advancing next-generation\nintelligent therapeutic devices. However, current systems often utilize basic\nmachine learning models that do not fully exploit the natural structure of\nbrain signals. Additionally, existing learning models used for neural signal\nprocessing often demonstrate low speed and efficiency during inference. To\naddress these challenges, this study introduces Micro Tree-based NAM (MT-NAM),\na distilled model based on the recently proposed Neural Additive Models (NAM).\nThe MT-NAM achieves a remarkable 100$\\times$ improvement in inference speed\ncompared to standard NAM, without compromising accuracy. We evaluate our\napproach on the CHB-MIT scalp EEG dataset, which includes recordings from 24\npatients with varying numbers of sessions and seizures. NAM achieves an 85.3\\%\nwindow-based sensitivity and 95\\% specificity. Interestingly, our proposed\nMT-NAM shows only a 2\\% reduction in sensitivity compared to the original NAM.\nTo regain this sensitivity, we utilize a test-time template adjuster (T3A) as\nan update mechanism, enabling our model to achieve higher sensitivity during\ntest time by accommodating transient shifts in neural signals. With this online\nupdate approach, MT-NAM achieves the same sensitivity as the standard NAM while\nachieving approximately 50$\\times$ acceleration in inference speed.\n","authors":["Arshia Afzal","Volkan Cevher","Mahsa Shoaran"],"pdf_url":"https://arxiv.org/pdf/2503.08251v1.pdf","comment":"Submitted to IEEE-TBME"},{"id":"http://arxiv.org/abs/2503.08250v1","updated":"2025-03-11T10:14:22Z","published":"2025-03-11T10:14:22Z","title":"Aligning Text to Image in Diffusion Models is Easier Than You Think","summary":"  While recent advancements in generative modeling have significantly improved\ntext-image alignment, some residual misalignment between text and image\nrepresentations still remains. Although many approaches have attempted to\naddress this issue by fine-tuning models using various reward models, etc., we\nrevisit the challenge from the perspective of representation alignment-an\napproach that has gained popularity with the success of REPresentation\nAlignment (REPA). We first argue that conventional text-to-image (T2I)\ndiffusion models, typically trained on paired image and text data (i.e.,\npositive pairs) by minimizing score matching or flow matching losses, is\nsuboptimal from the standpoint of representation alignment. Instead, a better\nalignment can be achieved through contrastive learning that leverages both\npositive and negative pairs. To achieve this efficiently even with pretrained\nmodels, we introduce a lightweight contrastive fine tuning strategy called\nSoftREPA that uses soft text tokens. This approach improves alignment with\nminimal computational overhead by adding fewer than 1M trainable parameters to\nthe pretrained model. Our theoretical analysis demonstrates that our method\nexplicitly increases the mutual information between text and image\nrepresentations, leading to enhanced semantic consistency. Experimental results\nacross text-to-image generation and text-guided image editing tasks validate\nthe effectiveness of our approach in improving the semantic consistency of T2I\ngenerative models.\n","authors":["Jaa-Yeon Lee","Byunghee Cha","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2503.08250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01306v2","updated":"2025-03-11T10:08:37Z","published":"2024-10-02T08:01:05Z","title":"Emotion-Aware Embedding Fusion in LLMs (Flan-T5, LLAMA 2, DeepSeek-R1,\n  and ChatGPT 4) for Intelligent Response Generation","summary":"  Empathetic and coherent responses are critical in auto-mated\nchatbot-facilitated psychotherapy. This study addresses the challenge of\nenhancing the emotional and contextual understanding of large language models\n(LLMs) in psychiatric applications. We introduce Emotion-Aware Embedding\nFusion, a novel framework integrating hierarchical fusion and attention\nmechanisms to prioritize semantic and emotional features in therapy\ntranscripts. Our approach combines multiple emotion lexicons, including NRC\nEmotion Lexicon, VADER, WordNet, and SentiWordNet, with state-of-the-art LLMs\nsuch as Flan-T5, LLAMA 2, DeepSeek-R1, and ChatGPT 4. Therapy session\ntranscripts, comprising over 2,000 samples are segmented into hierarchical\nlevels (word, sentence, and session) using neural networks, while hierarchical\nfusion combines these features with pooling techniques to refine emotional\nrepresentations. Atten-tion mechanisms, including multi-head self-attention and\ncross-attention, further prioritize emotional and contextual features, enabling\ntemporal modeling of emotion-al shifts across sessions. The processed\nembeddings, computed using BERT, GPT-3, and RoBERTa are stored in the Facebook\nAI similarity search vector database, which enables efficient similarity search\nand clustering across dense vector spaces. Upon user queries, relevant segments\nare retrieved and provided as context to LLMs, enhancing their ability to\ngenerate empathetic and con-textually relevant responses. The proposed\nframework is evaluated across multiple practical use cases to demonstrate\nreal-world applicability, including AI-driven therapy chatbots. The system can\nbe integrated into existing mental health platforms to generate personalized\nresponses based on retrieved therapy session data.\n","authors":["Abdur Rasool","Muhammad Irfan Shahzad","Hafsa Aslam","Vincent Chan","Muhammad Ali Arshad"],"pdf_url":"https://arxiv.org/pdf/2410.01306v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08241v1","updated":"2025-03-11T10:05:01Z","published":"2025-03-11T10:05:01Z","title":"HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in\n  Embodied Agents","summary":"  Advancing safe autonomous systems through reinforcement learning (RL)\nrequires robust benchmarks to evaluate performance, analyze methods, and assess\nagent competencies. Humans primarily rely on embodied visual perception to\nsafely navigate and interact with their surroundings, making it a valuable\ncapability for RL agents. However, existing vision-based 3D benchmarks only\nconsider simple navigation tasks. To address this shortcoming, we introduce\n\\textbf{HASARD}, a suite of diverse and complex tasks to $\\textbf{HA}$rness\n$\\textbf{SA}$fe $\\textbf{R}$L with $\\textbf{D}$oom, requiring strategic\ndecision-making, comprehending spatial relationships, and predicting the\nshort-term future. HASARD features three difficulty levels and two action\nspaces. An empirical evaluation of popular baseline methods demonstrates the\nbenchmark's complexity, unique challenges, and reward-cost trade-offs.\nVisualizing agent navigation during training with top-down heatmaps provides\ninsight into a method's learning process. Incrementally training across\ndifficulty levels offers an implicit learning curriculum. HASARD is the first\nsafe RL benchmark to exclusively target egocentric vision-based learning,\noffering a cost-effective and insightful way to explore the potential and\nboundaries of current and future safe RL methods. The environments and baseline\nimplementations are open-sourced at\nhttps://sites.google.com/view/hasard-bench/.\n","authors":["Tristan Tomilin","Meng Fang","Mykola Pechenizkiy"],"pdf_url":"https://arxiv.org/pdf/2503.08241v1.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.06749v2","updated":"2025-03-11T09:47:44Z","published":"2025-03-09T20:06:45Z","title":"Vision-R1: Incentivizing Reasoning Capability in Multimodal Large\n  Language Models","summary":"  DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning\ncapabilities in LLMs purely through Reinforcement Learning (RL). Inspired by\nthis breakthrough, we explore how RL can be utilized to enhance the reasoning\ncapability of MLLMs. However, direct training with RL struggles to activate\ncomplex reasoning capabilities such as questioning and reflection in MLLMs, due\nto the absence of substantial high-quality multimodal reasoning data. To\naddress this issue, we propose the reasoning MLLM, Vision-R1, to improve\nmultimodal reasoning capability. Specifically, we first construct a\nhigh-quality multimodal CoT dataset without human annotations by leveraging an\nexisting MLLM and DeepSeek-R1 through modality bridging and data filtering to\nobtain a 200K multimodal CoT dataset, Vision-R1-cold dataset. It serves as\ncold-start initialization data for Vision-R1. To mitigate the optimization\nchallenges caused by overthinking after cold start, we propose Progressive\nThinking Suppression Training (PTST) strategy and employ Group Relative Policy\nOptimization (GRPO) with the hard formatting result reward function to\ngradually refine the model's ability to learn correct and complex reasoning\nprocesses on a 10K multimodal math dataset. Comprehensive experiments show our\nmodel achieves an average improvement of $\\sim$6% across various multimodal\nmath reasoning benchmarks. Vision-R1-7B achieves a 73.5% accuracy on the widely\nused MathVista benchmark, which is only 0.4% lower than the leading reasoning\nmodel, OpenAI O1. The datasets and code will be released in:\nhttps://github.com/Osilly/Vision-R1 .\n","authors":["Wenxuan Huang","Bohan Jia","Zijie Zhai","Shaosheng Cao","Zheyu Ye","Fei Zhao","Zhe Xu","Yao Hu","Shaohui Lin"],"pdf_url":"https://arxiv.org/pdf/2503.06749v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08228v1","updated":"2025-03-11T09:46:07Z","published":"2025-03-11T09:46:07Z","title":"Investigating Execution-Aware Language Models for Code Optimization","summary":"  Code optimization is the process of enhancing code efficiency, while\npreserving its intended functionality. This process often requires a deep\nunderstanding of the code execution behavior at run-time to identify and\naddress inefficiencies effectively. Recent studies have shown that language\nmodels can play a significant role in automating code optimization. However,\nthese models may have insufficient knowledge of how code execute at run-time.\nTo address this limitation, researchers have developed strategies that\nintegrate code execution information into language models. These strategies\nhave shown promise, enhancing the effectiveness of language models in various\nsoftware engineering tasks. However, despite the close relationship between\ncode execution behavior and efficiency, the specific impact of these strategies\non code optimization remains largely unexplored. This study investigates how\nincorporating code execution information into language models affects their\nability to optimize code. Specifically, we apply three different training\nstrategies to incorporate four code execution aspects -- line executions, line\ncoverage, branch coverage, and variable states -- into CodeT5+, a well-known\nlanguage model for code. Our results indicate that execution-aware models\nprovide limited benefits compared to the standard CodeT5+ model in optimizing\ncode.\n","authors":["Federico Di Menna","Luca Traini","Gabriele Bavota","Vittorio Cortellessa"],"pdf_url":"https://arxiv.org/pdf/2503.08228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08226v1","updated":"2025-03-11T09:44:17Z","published":"2025-03-11T09:44:17Z","title":"A Grey-box Text Attack Framework using Explainable AI","summary":"  Explainable AI is a strong strategy implemented to understand complex\nblack-box model predictions in a human interpretable language. It provides the\nevidence required to execute the use of trustworthy and reliable AI systems. On\nthe other hand, however, it also opens the door to locating possible\nvulnerabilities in an AI model. Traditional adversarial text attack uses word\nsubstitution, data augmentation techniques and gradient-based attacks on\npowerful pre-trained Bidirectional Encoder Representations from Transformers\n(BERT) variants to generate adversarial sentences. These attacks are generally\nwhitebox in nature and not practical as they can be easily detected by humans\nE.g. Changing the word from \"Poor\" to \"Rich\". We proposed a simple yet\neffective Grey-box cum Black-box approach that does not require the knowledge\nof the model while using a set of surrogate Transformer/BERT models to perform\nthe attack using Explainable AI techniques. As Transformers are the current\nstate-of-the-art models for almost all Natural Language Processing (NLP) tasks,\nan attack generated from BERT1 is transferable to BERT2. This transferability\nis made possible due to the attention mechanism in the transformer that allows\nthe model to capture long-range dependencies in a sequence. Using the power of\nBERT generalisation via attention, we attempt to exploit how transformers learn\nby attacking a few surrogate transformer variants which are all based on a\ndifferent architecture. We demonstrate that this approach is highly effective\nto generate semantically good sentences by changing as little as one word that\nis not detectable by humans while still fooling other BERT models.\n","authors":["Esther Chiramal","Kelvin Soh Boon Kai"],"pdf_url":"https://arxiv.org/pdf/2503.08226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08221v1","updated":"2025-03-11T09:40:31Z","published":"2025-03-11T09:40:31Z","title":"EgoBlind: Towards Egocentric Visual Assistance for the Blind People","summary":"  We present EgoBlind, the first egocentric VideoQA dataset collected from\nblind individuals to evaluate the assistive capabilities of contemporary\nmultimodal large language models (MLLMs). EgoBlind comprises 1,210 videos that\nrecord the daily lives of real blind users from a first-person perspective. It\nalso features 4,927 questions directly posed or generated and verified by blind\nindividuals to reflect their needs for visual assistance under various\nscenarios. We provide each question with an average of 3 reference answers to\nalleviate subjective evaluation. Using EgoBlind, we comprehensively evaluate 15\nleading MLLMs and find that all models struggle, with the best performers\nachieving accuracy around 56\\%, far behind human performance of 87.4\\%. To\nguide future advancements, we identify and summarize major limitations of\nexisting MLLMs in egocentric visual assistance for the blind and provide\nheuristic suggestions for improvement. With these efforts, we hope EgoBlind can\nserve as a valuable foundation for developing more effective AI assistants to\nenhance the independence of the blind individuals' lives.\n","authors":["Junbin Xiao","Nanxin Huang","Hao Qiu","Zhulin Tao","Xun Yang","Richang Hong","Meng Wang","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2503.08221v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2503.08219v1","updated":"2025-03-11T09:39:06Z","published":"2025-03-11T09:39:06Z","title":"CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive\n  Learning","summary":"  Unsupervised Multi-View Stereo (MVS) methods have achieved promising progress\nrecently. However, previous methods primarily depend on the photometric\nconsistency assumption, which may suffer from two limitations:\nindistinguishable regions and view-dependent effects, e.g., low-textured areas\nand reflections. To address these issues, in this paper, we propose a new\ndual-level contrastive learning approach, named CL-MVSNet. Specifically, our\nmodel integrates two contrastive branches into an unsupervised MVS framework to\nconstruct additional supervisory signals. On the one hand, we present an\nimage-level contrastive branch to guide the model to acquire more context\nawareness, thus leading to more complete depth estimation in indistinguishable\nregions. On the other hand, we exploit a scene-level contrastive branch to\nboost the representation ability, improving robustness to view-dependent\neffects. Moreover, to recover more accurate 3D geometry, we introduce an L0.5\nphotometric consistency loss, which encourages the model to focus more on\naccurate points while mitigating the gradient penalty of undesirable ones.\nExtensive experiments on DTU and Tanks&Temples benchmarks demonstrate that our\napproach achieves state-of-the-art performance among all end-to-end\nunsupervised MVS frameworks and outperforms its supervised counterpart by a\nconsiderable margin without fine-tuning.\n","authors":["Kaiqiang Xiong","Rui Peng","Zhe Zhang","Tianxing Feng","Jianbo Jiao","Feng Gao","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.08219v1.pdf","comment":"Accpetd by ICCV2023"},{"id":"http://arxiv.org/abs/2409.19075v2","updated":"2025-03-11T09:31:15Z","published":"2024-09-27T18:22:22Z","title":"Meta-RTL: Reinforcement-Based Meta-Transfer Learning for Low-Resource\n  Commonsense Reasoning","summary":"  Meta learning has been widely used to exploit rich-resource source tasks to\nimprove the performance of low-resource target tasks. Unfortunately, most\nexisting meta learning approaches treat different source tasks equally,\nignoring the relatedness of source tasks to the target task in knowledge\ntransfer. To mitigate this issue, we propose a reinforcement-based multi-source\nmeta-transfer learning framework (Meta-RTL) for low-resource commonsense\nreasoning. In this framework, we present a reinforcement-based approach to\ndynamically estimating source task weights that measure the contribution of the\ncorresponding tasks to the target task in the meta-transfer learning. The\ndifferences between the general loss of the meta model and task-specific losses\nof source-specific temporal meta models on sampled target data are fed into the\npolicy network of the reinforcement learning module as rewards. The policy\nnetwork is built upon LSTMs that capture long-term dependencies on source task\nweight estimation across meta learning iterations. We evaluate the proposed\nMeta-RTL using both BERT and ALBERT as the backbone of the meta model on three\ncommonsense reasoning benchmark datasets. Experimental results demonstrate that\nMeta-RTL substantially outperforms strong baselines and previous task selection\nstrategies and achieves larger improvements on extremely low-resource settings.\n","authors":["Yu Fu","Jie He","Yifan Yang","Qun Liu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2409.19075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08213v1","updated":"2025-03-11T09:27:56Z","published":"2025-03-11T09:27:56Z","title":"DeepRAG: Building a Custom Hindi Embedding Model for Retrieval Augmented\n  Generation from Scratch","summary":"  In this paper, I present our work on DeepRAG, a specialized embedding model\nwe built specifically for Hindi language in RAG systems. While LLMs have gotten\nreally good at generating text, their performance in retrieval tasks still\ndepends heavily on having quality embeddings - something that's been lacking\nfor Hindi despite being one of the world's most spoken languages. We tackled\nthis by creating embeddings from the ground up rather than just fine-tuning\nexisting models. Our process involved collecting diverse Hindi texts (over 2.7M\nsamples), training a custom SentencePiece tokenizer that actually understands\nHindi morphology, designing transformer architecture with Hindi-specific\nattention mechanisms, and optimizing with contrastive learning. Results were\nhonestly better than I expected - we saw a 23% improvement in retrieval\nprecision compared to the multilingual models everyone's been using. The paper\ndetails our methodology, which I think could help others working with\nlow-resource languages where the one-size-fits-all multilingual models fall\nshort. We've also integrated our embeddings with LangChain to build complete\nHindi RAG systems, which might be useful for practitioners. While there's still\ntons more to explore, I believe this work addresses a critical gap for Hindi\nNLP and demonstrates why language-specific approaches matter.\n","authors":["Nandakishor M"],"pdf_url":"https://arxiv.org/pdf/2503.08213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08205v1","updated":"2025-03-11T09:20:06Z","published":"2025-03-11T09:20:06Z","title":"OLMD: Orientation-aware Long-term Motion Decoupling for Continuous Sign\n  Language Recognition","summary":"  The primary challenge in continuous sign language recognition (CSLR) mainly\nstems from the presence of multi-orientational and long-term motions. However,\ncurrent research overlooks these crucial aspects, significantly impacting\naccuracy. To tackle these issues, we propose a novel CSLR framework:\nOrientation-aware Long-term Motion Decoupling (OLMD), which efficiently\naggregates long-term motions and decouples multi-orientational signals into\neasily interpretable components. Specifically, our innovative Long-term Motion\nAggregation (LMA) module filters out static redundancy while adaptively\ncapturing abundant features of long-term motions. We further enhance\norientation awareness by decoupling complex movements into horizontal and\nvertical components, allowing for motion purification in both orientations.\nAdditionally, two coupling mechanisms are proposed: stage and cross-stage\ncoupling, which together enrich multi-scale features and improve the\ngeneralization capabilities of the model. Experimentally, OLMD shows SOTA\nperformance on three large-scale datasets: PHOENIX14, PHOENIX14-T, and\nCSL-Daily. Notably, we improved the word error rate (WER) on PHOENIX14 by an\nabsolute 1.6% compared to the previous SOTA\n","authors":["Yiheng Yu","Sheng Liu","Yuan Feng","Min Xu","Zhelun Jin","Xuhua Yang"],"pdf_url":"https://arxiv.org/pdf/2503.08205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08199v1","updated":"2025-03-11T09:08:04Z","published":"2025-03-11T09:08:04Z","title":"A Cascading Cooperative Multi-agent Framework for On-ramp Merging\n  Control Integrating Large Language Models","summary":"  Traditional Reinforcement Learning (RL) suffers from replicating human-like\nbehaviors, generalizing effectively in multi-agent scenarios, and overcoming\ninherent interpretability issues.These tasks are compounded when deep\nenvironment understanding, agent coordination and dynamic optimization are\nrequired. While Large Language Model (LLM) enhanced methods have shown promise\nin generalization and interoperability, they often neglect necessary\nmulti-agent coordination. Therefore, we introduce the Cascading Cooperative\nMulti-agent (CCMA) framework, integrating RL for individual interactions, a\nfine-tuned LLM for regional cooperation, a reward function for global\noptimization, and the Retrieval-augmented Generation mechanism to dynamically\noptimize decision-making across complex driving scenarios. Our experiments\ndemonstrate that the CCMA outperforms existing RL methods, demonstrating\nsignificant improvements in both micro and macro-level performance in complex\ndriving environments.\n","authors":["Miao Zhang","Zhenlong Fang","Tianyi Wang","Qian Zhang","Shuai Lu","Junfeng Jiao","Tianyu Shi"],"pdf_url":"https://arxiv.org/pdf/2503.08199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06873v2","updated":"2025-03-11T09:06:03Z","published":"2025-03-10T02:52:47Z","title":"Interactive Medical Image Analysis with Concept-based Similarity\n  Reasoning","summary":"  The ability to interpret and intervene model decisions is important for the\nadoption of computer-aided diagnosis methods in clinical workflows. Recent\nconcept-based methods link the model predictions with interpretable concepts\nand modify their activation scores to interact with the model. However, these\nconcepts are at the image level, which hinders the model from pinpointing the\nexact patches the concepts are activated. Alternatively, prototype-based\nmethods learn representations from training image patches and compare these\nwith test image patches, using the similarity scores for final class\nprediction. However, interpreting the underlying concepts of these patches can\nbe challenging and often necessitates post-hoc guesswork. To address this\nissue, this paper introduces the novel Concept-based Similarity Reasoning\nnetwork (CSR), which offers (i) patch-level prototype with intrinsic concept\ninterpretation, and (ii) spatial interactivity. First, the proposed CSR\nprovides localized explanation by grounding prototypes of each concept on image\nregions. Second, our model introduces novel spatial-level interaction, allowing\ndoctors to engage directly with specific image areas, making it an intuitive\nand transparent tool for medical imaging. CSR improves upon prior\nstate-of-the-art interpretable methods by up to 4.5\\% across three biomedical\ndatasets. Our code is released at https://github.com/tadeephuy/InteractCSR.\n","authors":["Ta Duc Huy","Sen Kim Tran","Phan Nguyen","Nguyen Hoang Tran","Tran Bao Sam","Anton van den Hengel","Zhibin Liao","Johan W. Verjans","Minh-Son To","Vu Minh Hieu Phan"],"pdf_url":"https://arxiv.org/pdf/2503.06873v2.pdf","comment":"Accepted CVPR2025"},{"id":"http://arxiv.org/abs/2411.08932v3","updated":"2025-03-11T09:05:50Z","published":"2024-11-13T03:16:18Z","title":"PyGen: A Collaborative Human-AI Approach to Python Package Creation","summary":"  The principles of automation and innovation serve as foundational elements\nfor advancement in contemporary science and technology. Here, we introduce\nPygen, an automation platform designed to empower researchers, technologists,\nand hobbyists to bring abstract ideas to life as core, usable software tools\nwritten in Python. Pygen leverages the immense power of autoregressive large\nlanguage models to augment human creativity during the ideation, iteration, and\ninnovation process. By combining state-of-the-art language models with\nopen-source code generation technologies, Pygen has significantly reduced the\nmanual overhead of tool development. From a user prompt, Pygen automatically\ngenerates Python packages for a complete workflow from concept to package\ngeneration and documentation. The findings of our work show that Pygen\nconsiderably enhances the researcher's productivity by enabling the creation of\nresilient, modular, and well-documented packages for various specialized\npurposes. We employ a prompt enhancement approach to distill the user's package\ndescription into increasingly specific and actionable. While being inherently\nan open-ended task, we have evaluated the generated packages and the\ndocumentation using Human Evaluation, LLM-based evaluation, and CodeBLEU, with\ndetailed results in the results section. Furthermore, we documented our\nresults, analyzed the limitations, and suggested strategies to alleviate them.\nPygen is our vision of ethical automation, a framework that promotes\ninclusivity, accessibility, and collaborative development. This project marks\nthe beginning of a large-scale effort towards creating tools where intelligent\nagents collaborate with humans to improve scientific and technological\ndevelopment substantially.\n  Our code and generated examples are open-sourced at\n[https://github.com/GitsSaikat/Pygen]\n","authors":["Saikat Barua","Mostafizur Rahman","Md Jafor Sadek","Rafiul Islam","Shehenaz Khaled","Md. Shohrab Hossain"],"pdf_url":"https://arxiv.org/pdf/2411.08932v3.pdf","comment":"33 pages, 13 figures"},{"id":"http://arxiv.org/abs/2501.13456v4","updated":"2025-03-11T08:59:12Z","published":"2025-01-23T08:14:55Z","title":"KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) with attention mechanisms, often referred to as\nattentive GNNs, have emerged as a prominent paradigm in advanced GNN models in\nrecent years. However, our understanding of the critical process of scoring\nneighbor nodes remains limited, leading to the underperformance of many\nexisting attentive GNNs. In this paper, we unify the scoring functions of\ncurrent attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which\nintegrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring\nprocess. KAA enhances the performance of scoring functions across the board and\ncan be applied to nearly all existing attentive GNNs. To compare the expressive\npower of KAA with other scoring functions, we introduce Maximum Ranking\nDistance (MRD) to quantitatively estimate their upper bounds in ranking errors\nfor node importance. Our analysis reveals that, under limited parameters and\nconstraints on width and depth, both linear transformation-based and MLP-based\nscoring functions exhibit finite expressive power. In contrast, our proposed\nKAA, even with a single-layer KAN parameterized by zero-order B-spline\nfunctions, demonstrates nearly infinite expressive power. Extensive experiments\non both node-level and graph-level tasks using various backbone models show\nthat KAA-enhanced scoring functions consistently outperform their original\ncounterparts, achieving performance improvements of over 20% in some cases.\n","authors":["Taoran Fang","Tianhong Gao","Chunping Wang","Yihao Shang","Wei Chow","Lei Chen","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13456v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08193v1","updated":"2025-03-11T08:57:07Z","published":"2025-03-11T08:57:07Z","title":"Guess What I am Thinking: A Benchmark for Inner Thought Reasoning of\n  Role-Playing Language Agents","summary":"  Recent advances in LLM-based role-playing language agents (RPLAs) have\nattracted broad attention in various applications. While chain-of-thought\nreasoning has shown importance in many tasks for LLMs, the internal thinking\nprocesses of RPLAs remain unexplored. Understanding characters' inner thoughts\nis crucial for developing advanced RPLAs. In this paper, we introduce\nROLETHINK, a novel benchmark constructed from literature for evaluating\ncharacter thought generation. We propose the task of inner thought reasoning,\nwhich includes two sets: the gold set that compares generated thoughts with\noriginal character monologues, and the silver set that uses expert synthesized\ncharacter analyses as references. To address this challenge, we propose MIRROR,\na chain-of-thought approach that generates character thoughts by retrieving\nmemories, predicting character reactions, and synthesizing motivations. Through\nextensive experiments, we demonstrate the importance of inner thought reasoning\nfor RPLAs, and MIRROR consistently outperforms existing methods. Resources are\navailable at https://github.com/airaer1998/RPA_Thought.\n","authors":["Rui Xu","MingYu Wang","XinTao Wang","Dakuan Lu","Xiaoyu Tan","Wei Chu","Yinghui Xu"],"pdf_url":"https://arxiv.org/pdf/2503.08193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14856v2","updated":"2025-03-11T08:54:55Z","published":"2025-02-20T18:58:10Z","title":"FR-Spec: Accelerating Large-Vocabulary Language Models via\n  Frequency-Ranked Speculative Sampling","summary":"  Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12$\\times$ speedup over the\nstate-of-the-art speculative sampling method EAGLE-2. Code available at\nhttps://github.com/thunlp/FR-Spec.\n","authors":["Weilin Zhao","Tengyu Pan","Xu Han","Yudi Zhang","Ao Sun","Yuxiang Huang","Kaihuo Zhang","Weilun Zhao","Yuxuan Li","Jianyong Wang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.14856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08188v1","updated":"2025-03-11T08:53:53Z","published":"2025-03-11T08:53:53Z","title":"RigoChat 2: an adapted language model to Spanish using a bounded dataset\n  and reduced hardware","summary":"  Large Language Models (LLMs) have become a key element of modern artificial\nintelligence, demonstrating the ability to address a wide range of language\nprocessing tasks at unprecedented levels of accuracy without the need of\ncollecting problem-specific data. However, these versatile models face a\nsignificant challenge: both their training and inference processes require\nsubstantial computational resources, time, and memory. Consequently, optimizing\nthis kind of models to minimize these requirements is crucial. In this article,\nwe demonstrate that, with minimal resources and in a remarkably short time, it\nis possible to enhance a state-of-the-art model, specifically for a given\nlanguage task, without compromising its overall capabilities using a relatively\nsmall pretrained LLM as a basis. Specifically, we present our use case,\nRigoChat 2, illustrating how LLMs can be adapted to achieve superior results in\nSpanish-language tasks.\n","authors":["Gonzalo Santamaría Gómez","Guillem García Subies","Pablo Gutiérrez Ruiz","Mario González Valero","Natàlia Fuertes","Helena Montoro Zamorano","Carmen Muñoz Sanz","Leire Rosado Plaza","Nuria Aldama García","David Betancur Sánchez","Kateryna Sushkova","Marta Guerrero Nieto","Álvaro Barbero Jiménez"],"pdf_url":"https://arxiv.org/pdf/2503.08188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08179v1","updated":"2025-03-11T08:43:05Z","published":"2025-03-11T08:43:05Z","title":"ProTeX: Structure-In-Context Reasoning and Editing of Proteins with\n  Large Language Models","summary":"  Large language models have made remarkable progress in the field of molecular\nscience, particularly in understanding and generating functional small\nmolecules. This success is largely attributed to the effectiveness of molecular\ntokenization strategies. In protein science, the amino acid sequence serves as\nthe sole tokenizer for LLMs. However, many fundamental challenges in protein\nscience are inherently structure-dependent. The absence of structure-aware\ntokens significantly limits the capabilities of LLMs for comprehensive\nbiomolecular comprehension and multimodal generation. To address these\nchallenges, we introduce a novel framework, ProTeX, which tokenizes the protein\nsequences, structures, and textual information into a unified discrete space.\nThis innovative approach enables joint training of the LLM exclusively through\nthe Next-Token Prediction paradigm, facilitating multimodal protein reasoning\nand generation. ProTeX enables general LLMs to perceive and process protein\nstructures through sequential text input, leverage structural information as\nintermediate reasoning components, and generate or manipulate structures via\nsequential text output. Experiments demonstrate that our model achieves\nsignificant improvements in protein function prediction, outperforming the\nstate-of-the-art domain expert model with a twofold increase in accuracy. Our\nframework enables high-quality conformational generation and customizable\nprotein design. For the first time, we demonstrate that by adopting the\nstandard training and inference pipelines from the LLM domain, ProTeX empowers\ndecoder-only LLMs to effectively address diverse spectrum of protein-related\ntasks.\n","authors":["Zicheng Ma","Chuanliu Fan","Zhicong Wang","Zhenyu Chen","Xiaohan Lin","Yanheng Li","Shihao Feng","Jun Zhang","Ziqiang Cao","Yi Qin Gao"],"pdf_url":"https://arxiv.org/pdf/2503.08179v1.pdf","comment":"40 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.16067v5","updated":"2025-03-11T08:43:03Z","published":"2024-03-24T08:34:08Z","title":"Adversarial Guided Diffusion Models for Adversarial Purification","summary":"  Diffusion model (DM) based adversarial purification (AP) has proven to be a\npowerful defense method that can remove adversarial perturbations and generate\na purified example without threats. In principle, the pre-trained DMs can only\nensure that purified examples conform to the same distribution of the training\ndata, but it may inadvertently compromise the semantic information of input\nexamples, leading to misclassification of purified examples. Recent\nadvancements introduce guided diffusion techniques to preserve semantic\ninformation while removing the perturbations. However, these guidances often\nrely on distance measures between purified examples and diffused examples,\nwhich can also preserve perturbations in purified examples. To further unleash\nthe robustness power of DM-based AP, we propose an adversarial guided diffusion\nmodel (AGDM) by introducing a novel adversarial guidance that contains\nsufficient semantic information but does not explicitly involve adversarial\nperturbations. The guidance is modeled by an auxiliary neural network obtained\nwith adversarial training, considering the distance in the latent\nrepresentations rather than at the pixel-level values. Extensive experiments\nare conducted on CIFAR-10, CIFAR-100 and ImageNet to demonstrate that our\nmethod is effective for simultaneously maintaining semantic information and\nremoving the adversarial perturbations. In addition, comprehensive comparisons\nshow that our method significantly enhances the robustness of existing DM-based\nAP, with an average robust accuracy improved by up to 7.30% on CIFAR-10.\n","authors":["Guang Lin","Zerui Tao","Jianhai Zhang","Toshihisa Tanaka","Qibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.16067v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19345v4","updated":"2025-03-11T08:39:45Z","published":"2024-07-27T21:56:23Z","title":"Inference-Time Selective Debiasing to Enhance Fairness in Text\n  Classification Models","summary":"  We propose selective debiasing -- an inference-time safety mechanism designed\nto enhance the overall model quality in terms of prediction performance and\nfairness, especially in scenarios where retraining the model is impractical.\nThe method draws inspiration from selective classification, where at inference\ntime, predictions with low quality, as indicated by their uncertainty scores,\nare discarded. In our approach, we identify the potentially biased model\npredictions and, instead of discarding them, we remove bias from these\npredictions using LEACE -- a post-processing debiasing method. To select\nproblematic predictions, we propose a bias quantification approach based on KL\ndivergence, which achieves better results than standard uncertainty\nquantification methods. Experiments on text classification datasets with\nencoder-based classification models demonstrate that selective debiasing helps\nto reduce the performance gap between post-processing methods and debiasing\ntechniques from the at-training and pre-processing categories.\n","authors":["Gleb Kuzmin","Neemesh Yadav","Ivan Smirnov","Timothy Baldwin","Artem Shelmanov"],"pdf_url":"https://arxiv.org/pdf/2407.19345v4.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08175v1","updated":"2025-03-11T08:38:45Z","published":"2025-03-11T08:38:45Z","title":"Privacy-Enhancing Paradigms within Federated Multi-Agent Systems","summary":"  LLM-based Multi-Agent Systems (MAS) have proven highly effective in solving\ncomplex problems by integrating multiple agents, each performing different\nroles. However, in sensitive domains, they face emerging privacy protection\nchallenges. In this paper, we introduce the concept of Federated MAS,\nhighlighting the fundamental differences between Federated MAS and traditional\nFL. We then identify key challenges in developing Federated MAS, including: 1)\nheterogeneous privacy protocols among agents, 2) structural differences in\nmulti-party conversations, and 3) dynamic conversational network structures. To\naddress these challenges, we propose Embedded Privacy-Enhancing Agents\n(EPEAgent), an innovative solution that integrates seamlessly into the\nRetrieval-Augmented Generation (RAG) phase and the context retrieval stage.\nThis solution minimizes data flows, ensuring that only task-relevant,\nagent-specific information is shared. Additionally, we design and generate a\ncomprehensive dataset to evaluate the proposed paradigm. Extensive experiments\ndemonstrate that EPEAgent effectively enhances privacy protection while\nmaintaining strong system performance. The code will be availiable at\nhttps://github.com/ZitongShi/EPEAgent\n","authors":["Zitong Shi","Guancheng Wan","Wenke Huang","Guibin Zhang","Jiawei Shao","Mang Ye","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2503.08175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07091v2","updated":"2025-03-11T08:36:47Z","published":"2025-03-10T09:14:47Z","title":"FaceID-6M: A Large-Scale, Open-Source FaceID Customization Dataset","summary":"  Due to the data-driven nature of current face identity (FaceID) customization\nmethods, all state-of-the-art models rely on large-scale datasets containing\nmillions of high-quality text-image pairs for training. However, none of these\ndatasets are publicly available, which restricts transparency and hinders\nfurther advancements in the field.\n  To address this issue, in this paper, we collect and release FaceID-6M, the\nfirst large-scale, open-source FaceID dataset containing 6 million high-quality\ntext-image pairs. Filtered from LAION-5B \\cite{schuhmann2022laion}, FaceID-6M\nundergoes a rigorous image and text filtering steps to ensure dataset quality,\nincluding resolution filtering to maintain high-quality images and faces, face\nfiltering to remove images that lack human faces, and keyword-based strategy to\nretain descriptions containing human-related terms (e.g., nationality,\nprofessions and names). Through these cleaning processes, FaceID-6M provides a\nhigh-quality dataset optimized for training powerful FaceID customization\nmodels, facilitating advancements in the field by offering an open resource for\nresearch and development.\n  We conduct extensive experiments to show the effectiveness of our FaceID-6M,\ndemonstrating that models trained on our FaceID-6M dataset achieve performance\nthat is comparable to, and slightly better than currently available industrial\nmodels. Additionally, to support and advance research in the FaceID\ncustomization community, we make our code, datasets, and models fully publicly\navailable. Our codes, models, and datasets are available at:\nhttps://github.com/ShuheSH/FaceID-6M.\n","authors":["Shuhe Wang","Xiaoya Li","Jiwei Li","Guoyin Wang","Xiaofei Sun","Bob Zhu","Han Qiu","Mo Yu","Shengjie Shen","Tianwei Zhang","Eduard Hovy"],"pdf_url":"https://arxiv.org/pdf/2503.07091v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2501.15407"},{"id":"http://arxiv.org/abs/2503.08174v1","updated":"2025-03-11T08:36:37Z","published":"2025-03-11T08:36:37Z","title":"Investigating the Effectiveness of a Socratic Chain-of-Thoughts\n  Reasoning Method for Task Planning in Robotics, A Case Study","summary":"  Large language models (LLMs) have demonstrated unprecedented capability in\nreasoning with natural language. Coupled with this development is the emergence\nof embodied AI in robotics. Despite showing promise for verbal and written\nreasoning tasks, it remains unknown whether LLMs are capable of navigating\ncomplex spatial tasks with physical actions in the real world. To this end, it\nis of interest to investigate applying LLMs to robotics in zero-shot learning\nscenarios, and in the absence of fine-tuning - a feat which could significantly\nimprove human-robot interaction, alleviate compute cost, and eliminate\nlow-level programming tasks associated with robot tasks.\n  To explore this question, we apply GPT-4(Omni) with a simulated Tiago robot\nin Webots engine for an object search task. We evaluate the effectiveness of\nthree reasoning strategies based on Chain-of-Thought (CoT) sub-task list\ngeneration with the Socratic method (SocraCoT) (in order of increasing rigor):\n(1) Non-CoT/Non-SocraCoT, (2) CoT only, and (3) SocraCoT. Performance was\nmeasured in terms of the proportion of tasks successfully completed and\nexecution time (N = 20). Our preliminary results show that when combined with\nchain-of-thought reasoning, the Socratic method can be used for code generation\nfor robotic tasks that require spatial awareness. In extension of this finding,\nwe propose EVINCE-LoC; a modified EVINCE method that could further enhance\nperformance in highly complex and or dynamic testing scenarios.\n","authors":["Veronica Bot","Zheyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.08174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08163v1","updated":"2025-03-11T08:27:08Z","published":"2025-03-11T08:27:08Z","title":"XAI4Extremes: An interpretable machine learning framework for\n  understanding extreme-weather precursors under climate change","summary":"  Extreme weather events are increasing in frequency and intensity due to\nclimate change. This, in turn, is exacting a significant toll in communities\nworldwide. While prediction skills are increasing with advances in numerical\nweather prediction and artificial intelligence tools, extreme weather still\npresent challenges. More specifically, identifying the precursors of such\nextreme weather events and how these precursors may evolve under climate change\nremain unclear. In this paper, we propose to use post-hoc interpretability\nmethods to construct relevance weather maps that show the key extreme-weather\nprecursors identified by deep learning models. We then compare this machine\nview with existing domain knowledge to understand whether deep learning models\nidentified patterns in data that may enrich our understanding of\nextreme-weather precursors. We finally bin these relevant maps into different\nmulti-year time periods to understand the role that climate change is having on\nthese precursors. The experiments are carried out on Indochina heatwaves, but\nthe methodology can be readily extended to other extreme weather events\nworldwide.\n","authors":["Jiawen Wei","Aniruddha Bora","Vivek Oommen","Chenyu Dong","Juntao Yang","Jeff Adie","Chen Chen","Simon See","George Karniadakis","Gianmarco Mengaldo"],"pdf_url":"https://arxiv.org/pdf/2503.08163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05810v2","updated":"2025-03-11T08:22:15Z","published":"2025-03-04T10:18:32Z","title":"A Transformer Model for Predicting Chemical Reaction Products from\n  Generic Templates","summary":"  The accurate prediction of chemical reaction outcomes is a major challenge in\ncomputational chemistry. Current models rely heavily on either highly specific\nreaction templates or template-free methods, both of which present limitations.\nTo address these limitations, this work proposes the Broad Reaction Set (BRS),\na dataset featuring 20 generic reaction templates that allow for the efficient\nexploration of the chemical space. Additionally, ProPreT5 is introduced, a T5\nmodel tailored to chemistry that achieves a balance between rigid templates and\ntemplate-free methods. ProPreT5 demonstrates its capability to generate\naccurate, valid, and realistic reaction products, making it a promising\nsolution that goes beyond the current state-of-the-art on the complex reaction\nproduct prediction task.\n","authors":["Derin Ozer","Sylvain Lamprier","Thomas Cauchy","Nicolas Gutowski","Benoit Da Mota"],"pdf_url":"https://arxiv.org/pdf/2503.05810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19517v4","updated":"2025-03-11T08:21:06Z","published":"2024-11-29T07:23:34Z","title":"RL-MILP Solver: A Reinforcement Learning Approach for Solving\n  Mixed-Integer Linear Programs with Graph Neural Networks","summary":"  Mixed-integer linear programming (MILP) is a widely used optimization\ntechnique across various fields. Existing $\\textit{end-to-end learning}$\nmethods for MILP generate values for a subset of decision variables and\ndelegate the remaining problem to traditional MILP solvers. However, this\napproach often fails to guarantee solution feasibility (i.e., satisfying all\nconstraints) due to inaccurate predictions and primarily focuses on binary\ndecision variables. Satisfying all constraints is a prerequisite for obtaining\nthe optimal solution, and the feasibility issue becomes even more critical with\nnon-binary integer (integer, for short) variables. Thus, addressing the\nfeasibility of MILP involving integer variables is crucial. To address these\nchallenges, we propose a novel reinforcement learning (RL)-based solver that\nnot only finds the first feasible solution but also incrementally discovers\nbetter feasible solutions without delegating the remainder to off-the-shelf\nsolvers. Our experimental results demonstrate that the proposed method achieves\n(near-)optimal solutions.\n","authors":["Tae-Hoon Lee","Min-Soo Kim"],"pdf_url":"https://arxiv.org/pdf/2411.19517v4.pdf","comment":"Extended version (17 pages, 8 figures). Accepted at the 2025 AAAI\n  Workshop on AI to Accelerate Science and Engineering (AI2ASE)"},{"id":"http://arxiv.org/abs/2305.18226v3","updated":"2025-03-11T08:08:05Z","published":"2023-05-26T11:07:25Z","title":"HowkGPT: Investigating the Detection of ChatGPT-generated University\n  Student Homework through Context-Aware Perplexity Analysis","summary":"  As the use of Large Language Models (LLMs) in text generation tasks\nproliferates, concerns arise over their potential to compromise academic\nintegrity. The education sector currently tussles with distinguishing\nstudent-authored homework assignments from AI-generated ones. This paper\naddresses the challenge by introducing HowkGPT, designed to identify homework\nassignments generated by AI. HowkGPT is built upon a dataset of academic\nassignments and accompanying metadata [17] and employs a pretrained LLM to\ncompute perplexity scores for student-authored and ChatGPT-generated responses.\nThese scores then assist in establishing a threshold for discerning the origin\nof a submitted assignment. Given the specificity and contextual nature of\nacademic work, HowkGPT further refines its analysis by defining\ncategory-specific thresholds derived from the metadata, enhancing the precision\nof the detection. This study emphasizes the critical need for effective\nstrategies to uphold academic integrity amidst the growing influence of LLMs\nand provides an approach to ensuring fair and accurate grading in educational\ninstitutions.\n","authors":["Christoforos Vasilatos","Manaar Alam","Talal Rahwan","Yasir Zaki","Michail Maniatakos"],"pdf_url":"https://arxiv.org/pdf/2305.18226v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.07037v6","updated":"2025-03-11T08:07:39Z","published":"2023-08-14T09:56:35Z","title":"Bayesian Flow Networks","summary":"  This paper introduces Bayesian Flow Networks (BFNs), a new class of\ngenerative model in which the parameters of a set of independent distributions\nare modified with Bayesian inference in the light of noisy data samples, then\npassed as input to a neural network that outputs a second, interdependent\ndistribution. Starting from a simple prior and iteratively updating the two\ndistributions yields a generative procedure similar to the reverse process of\ndiffusion models; however it is conceptually simpler in that no forward process\nis required. Discrete and continuous-time loss functions are derived for\ncontinuous, discretised and discrete data, along with sample generation\nprocedures. Notably, the network inputs for discrete data lie on the\nprobability simplex, and are therefore natively differentiable, paving the way\nfor gradient-based sample guidance and few-step generation in discrete domains\nsuch as language modelling. The loss function directly optimises data\ncompression and places no restrictions on the network architecture. In our\nexperiments BFNs achieve competitive log-likelihoods for image modelling on\ndynamically binarized MNIST and CIFAR-10, and outperform all known discrete\ndiffusion models on the text8 character-level language modelling task.\n","authors":["Alex Graves","Rupesh Kumar Srivastava","Timothy Atkinson","Faustino Gomez"],"pdf_url":"https://arxiv.org/pdf/2308.07037v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15658v3","updated":"2025-03-11T08:04:26Z","published":"2023-11-27T09:40:14Z","title":"Regularization by Texts for Latent Diffusion Inverse Solvers","summary":"  The recent development of diffusion models has led to significant progress in\nsolving inverse problems by leveraging these models as powerful generative\npriors. However, challenges persist due to the ill-posed nature of such\nproblems, often arising from ambiguities in measurements or intrinsic system\nsymmetries. To address this, here we introduce a novel latent diffusion inverse\nsolver, regularization by text (TReg), inspired by the human ability to resolve\nvisual ambiguities through perceptual biases. TReg integrates textual\ndescriptions of preconceptions about the solution during reverse diffusion\nsampling, dynamically reinforcing these descriptions through null-text\noptimization, which we refer to as adaptive negation. Our comprehensive\nexperimental results demonstrate that TReg effectively mitigates ambiguity in\ninverse problems, improving both accuracy and efficiency.\n","authors":["Jeongsol Kim","Geon Yeong Park","Hyungjin Chung","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15658v3.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2503.08145v1","updated":"2025-03-11T08:03:47Z","published":"2025-03-11T08:03:47Z","title":"Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking","summary":"  Open-Vocabulary Multi-Object Tracking (OV-MOT) aims to enable approaches to\ntrack objects without being limited to a predefined set of categories. Current\nOV-MOT methods typically rely primarily on instance-level detection and\nassociation, often overlooking trajectory information that is unique and\nessential for object tracking tasks. Utilizing trajectory information can\nenhance association stability and classification accuracy, especially in cases\nof occlusion and category ambiguity, thereby improving adaptability to novel\nclasses. Thus motivated, in this paper we propose \\textbf{TRACT}, an\nopen-vocabulary tracker that leverages trajectory information to improve both\nobject association and classification in OV-MOT. Specifically, we introduce a\n\\textit{Trajectory Consistency Reinforcement} (\\textbf{TCR}) strategy, that\nbenefits tracking performance by improving target identity and category\nconsistency. In addition, we present \\textbf{TraCLIP}, a plug-and-play\ntrajectory classification module. It integrates \\textit{Trajectory Feature\nAggregation} (\\textbf{TFA}) and \\textit{Trajectory Semantic Enrichment}\n(\\textbf{TSE}) strategies to fully leverage trajectory information from visual\nand language perspectives for enhancing the classification results. Extensive\nexperiments on OV-TAO show that our TRACT significantly improves tracking\nperformance, highlighting trajectory information as a valuable asset for\nOV-MOT. Code will be released.\n","authors":["Yunhao Li","Yifan Jiao","Dan Meng","Heng Fan","Libo Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08145v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08136v1","updated":"2025-03-11T07:56:14Z","published":"2025-03-11T07:56:14Z","title":"FlowDPS: Flow-Driven Posterior Sampling for Inverse Problems","summary":"  Flow matching is a recent state-of-the-art framework for generative modeling\nbased on ordinary differential equations (ODEs). While closely related to\ndiffusion models, it provides a more general perspective on generative\nmodeling. Although inverse problem solving has been extensively explored using\ndiffusion models, it has not been rigorously examined within the broader\ncontext of flow models. Therefore, here we extend the diffusion inverse solvers\n(DIS) - which perform posterior sampling by combining a denoising diffusion\nprior with an likelihood gradient - into the flow framework. Specifically, by\ndriving the flow-version of Tweedie's formula, we decompose the flow ODE into\ntwo components: one for clean image estimation and the other for noise\nestimation. By integrating the likelihood gradient and stochastic noise into\neach component, respectively, we demonstrate that posterior sampling for\ninverse problem solving can be effectively achieved using flows. Our proposed\nsolver, Flow-Driven Posterior Sampling (FlowDPS), can also be seamlessly\nintegrated into a latent flow model with a transformer architecture. Across\nfour linear inverse problems, we confirm that FlowDPS outperforms\nstate-of-the-art alternatives, all without requiring additional training.\n","authors":["Jeongsol Kim","Bryan Sangwoo Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2503.08136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08133v1","updated":"2025-03-11T07:51:47Z","published":"2025-03-11T07:51:47Z","title":"MGHanD: Multi-modal Guidance for authentic Hand Diffusion","summary":"  Diffusion-based methods have achieved significant successes in T2I\ngeneration, providing realistic images from text prompts. Despite their\ncapabilities, these models face persistent challenges in generating realistic\nhuman hands, often producing images with incorrect finger counts and\nstructurally deformed hands. MGHanD addresses this challenge by applying\nmulti-modal guidance during the inference process. For visual guidance, we\nemploy a discriminator trained on a dataset comprising paired real and\ngenerated images with captions, derived from various hand-in-the-wild datasets.\nWe also employ textual guidance with LoRA adapter, which learns the direction\nfrom `hands' towards more detailed prompts such as `natural hands', and\n`anatomically correct fingers' at the latent level. A cumulative hand mask\nwhich is gradually enlarged in the assigned time step is applied to the added\nguidance, allowing the hand to be refined while maintaining the rich generative\ncapabilities of the pre-trained model. In the experiments, our method achieves\nsuperior hand generation qualities, without any specific conditions or priors.\nWe carry out both quantitative and qualitative evaluations, along with user\nstudies, to showcase the benefits of our approach in producing high-quality\nhand images.\n","authors":["Taehyeon Eum","Jieun Choi","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2503.08133v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.19902v2","updated":"2025-03-11T07:51:05Z","published":"2025-02-27T09:18:04Z","title":"Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action\n  Conditioned Policy","summary":"  Building an agent that can mimic human behavior patterns to accomplish\nvarious open-world tasks is a long-term goal. To enable agents to effectively\nlearn behavioral patterns across diverse tasks, a key challenge lies in\nmodeling the intricate relationships among observations, actions, and language.\nTo this end, we propose Optimus-2, a novel Minecraft agent that incorporates a\nMultimodal Large Language Model (MLLM) for high-level planning, alongside a\nGoal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP\ncontains (1) an Action-guided Behavior Encoder that models causal relationships\nbetween observations and actions at each timestep, then dynamically interacts\nwith the historical observation-action sequence, consolidating it into\nfixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with\nopen-ended language instructions to predict actions auto-regressively.\nMoreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)}\ndataset, which contains 25,000 videos across 8 atomic tasks, providing about\n30M goal-observation-action pairs. The automated construction method, along\nwith the MGOA dataset, can contribute to the community's efforts to train\nMinecraft agents. Extensive experimental results demonstrate that Optimus-2\nexhibits superior performance across atomic tasks, long-horizon tasks, and\nopen-ended instruction tasks in Minecraft. Please see the project page at\nhttps://cybertronagent.github.io/Optimus-2.github.io/.\n","authors":["Zaijing Li","Yuquan Xie","Rui Shao","Gongwei Chen","Dongmei Jiang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.19902v2.pdf","comment":"Accept to CVPR 2025, Project page:\n  https://cybertronagent.github.io/Optimus-2.github.io/"},{"id":"http://arxiv.org/abs/2503.08122v1","updated":"2025-03-11T07:38:11Z","published":"2025-03-11T07:38:11Z","title":"Toward Stable World Models: Measuring and Addressing World Instability\n  in Generative Environments","summary":"  We present a novel study on enhancing the capability of preserving the\ncontent in world models, focusing on a property we term World Stability. Recent\ndiffusion-based generative models have advanced the synthesis of immersive and\nrealistic environments that are pivotal for applications such as reinforcement\nlearning and interactive game engines. However, while these models excel in\nquality and diversity, they often neglect the preservation of previously\ngenerated scenes over time--a shortfall that can introduce noise into agent\nlearning and compromise performance in safety-critical settings. In this work,\nwe introduce an evaluation framework that measures world stability by having\nworld models perform a sequence of actions followed by their inverses to return\nto their initial viewpoint, thereby quantifying the consistency between the\nstarting and ending observations. Our comprehensive assessment of\nstate-of-the-art diffusion-based world models reveals significant challenges in\nachieving high world stability. Moreover, we investigate several improvement\nstrategies to enhance world stability. Our results underscore the importance of\nworld stability in world modeling and provide actionable insights for future\nresearch in this domain.\n","authors":["Soonwoo Kwon","Jin-Young Kim","Hyojun Go","Kyungjune Baek"],"pdf_url":"https://arxiv.org/pdf/2503.08122v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.08120v1","updated":"2025-03-11T07:34:59Z","published":"2025-03-11T07:34:59Z","title":"Uni$\\textbf{F}^2$ace: Fine-grained Face Understanding and Generation\n  with Unified Multimodal Models","summary":"  Unified multimodal models (UMMs) have emerged as a powerful paradigm in\nfoundational computer vision research, demonstrating significant potential in\nboth image understanding and generation. However, existing research in the face\ndomain primarily focuses on $\\textbf{coarse}$ facial attribute understanding,\nwith limited capacity to handle $\\textbf{fine-grained}$ facial attributes and\nwithout addressing generation capabilities. To overcome these limitations, we\npropose Uni$\\textbf{F}^2$ace, the first UMM tailored specifically for\nfine-grained face understanding and generation. In general, we train\nUni$\\textbf{F}^2$ace on a self-constructed, specialized dataset utilizing two\nmutually beneficial diffusion techniques and a two-level mixture-of-experts\narchitecture. Specifically, we first build a large-scale facial dataset,\nUni$\\textbf{F}^2$ace-130K, which contains 130K image-text pairs with one\nmillion question-answering pairs that span a wide range of facial attributes.\nSecond, we establish a theoretical connection between discrete diffusion score\nmatching and masked generative models, optimizing both evidence lower bounds\nsimultaneously, which significantly improves the model's ability to synthesize\nfacial details. Finally, we introduce both token-level and sequence-level\nmixture-of-experts, enabling efficient fine-grained representation learning for\nboth understanding and generation tasks. Extensive experiments on\nUni$\\textbf{F}^2$ace-130K demonstrate that Uni$\\textbf{F}^2$ace outperforms\nexisting UMMs and generative models, achieving superior performance across both\nunderstanding and generation tasks.\n","authors":["Junzhe Li","Xuerui Qiu","Linrui Xu","Liya Guo","Delin Qu","Tingting Long","Chun Fan","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2503.08120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08117v1","updated":"2025-03-11T07:30:25Z","published":"2025-03-11T07:30:25Z","title":"Convergence Dynamics and Stabilization Strategies of Co-Evolving\n  Generative Models","summary":"  The increasing prevalence of synthetic data in training loops has raised\nconcerns about model collapse, where generative models degrade when trained on\ntheir own outputs. While prior work focuses on this self-consuming process, we\nstudy an underexplored yet prevalent phenomenon: co-evolving generative models\nthat shape each other's training through iterative feedback. This is common in\nmultimodal AI ecosystems, such as social media platforms, where text models\ngenerate captions that guide image models, and the resulting images influence\nthe future adaptation of the text model. We take a first step by analyzing such\na system, modeling the text model as a multinomial distribution and the image\nmodel as a conditional multi-dimensional Gaussian distribution. Our analysis\nuncovers three key results. First, when one model remains fixed, the other\ncollapses: a frozen image model causes the text model to lose diversity, while\na frozen text model leads to an exponential contraction of image diversity,\nthough fidelity remains bounded. Second, in fully interactive systems, mutual\nreinforcement accelerates collapse, with image contraction amplifying text\nhomogenization and vice versa, leading to a Matthew effect where dominant texts\nsustain higher image diversity while rarer texts collapse faster. Third, we\nanalyze stabilization strategies implicitly introduced by real-world external\ninfluences. Random corpus injections for text models and user-content\ninjections for image models prevent collapse while preserving both diversity\nand fidelity. Our theoretical findings are further validated through\nexperiments.\n","authors":["Weiguo Gao","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2503.08117v1.pdf","comment":"37 pages, 11 figures"},{"id":"http://arxiv.org/abs/2502.08209v2","updated":"2025-03-11T07:27:41Z","published":"2025-02-12T08:39:26Z","title":"Equivariant Masked Position Prediction for Efficient Molecular\n  Representation","summary":"  Graph neural networks (GNNs) have shown considerable promise in computational\nchemistry. However, the limited availability of molecular data raises concerns\nregarding GNNs' ability to effectively capture the fundamental principles of\nphysics and chemistry, which constrains their generalization capabilities. To\naddress this challenge, we introduce a novel self-supervised approach termed\nEquivariant Masked Position Prediction (EMPP), grounded in intramolecular\npotential and force theory. Unlike conventional attribute masking techniques,\nEMPP formulates a nuanced position prediction task that is more well-defined\nand enhances the learning of quantum mechanical features. EMPP also bypasses\nthe approximation of the Gaussian mixture distribution commonly used in\ndenoising methods, allowing for more accurate acquisition of physical\nproperties. Experimental results indicate that EMPP significantly enhances\nperformance of advanced molecular architectures, surpassing state-of-the-art\nself-supervised approaches. Our code is released in\nhttps://github.com/ajy112/EMPP\n","authors":["Junyi An","Chao Qu","Yun-Fei Shi","XinHao Liu","Qianwei Tang","Fenglei Cao","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2502.08209v2.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.08014v2","updated":"2025-03-11T07:15:54Z","published":"2024-12-11T01:41:19Z","title":"MAGIC: Mastering Physical Adversarial Generation in Context through\n  Collaborative LLM Agents","summary":"  Physical adversarial attacks in driving scenarios can expose critical\nvulnerabilities in visual perception models. However, developing such attacks\nremains challenging due to diverse real-world environments and the requirement\nfor maintaining visual naturality. Building upon this challenge, we reformulate\nphysical adversarial attacks as a one-shot patch generation problem. Our\napproach generates adversarial patches through a deep generative model that\nconsiders the specific scene context, enabling direct physical deployment in\nmatching environments. The primary challenge lies in simultaneously achieving\ntwo objectives: generating adversarial patches that effectively mislead object\ndetection systems while determining contextually appropriate deployment within\nthe scene. We propose MAGIC (Mastering Physical Adversarial Generation In\nContext), a novel framework powered by multi-modal LLM agents to address these\nchallenges. MAGIC automatically understands scene context and generates\nadversarial patch through the synergistic interaction of language and vision\ncapabilities. In particular, MAGIC orchestrates three specialized LLM agents:\nThe adv-patch generation agent (GAgent) masters the creation of deceptive\npatches through strategic prompt engineering for text-to-image models. The\nadv-patch deployment agent (DAgent) ensures contextual coherence by determining\noptimal deployment strategies based on scene understanding. The\nself-examination agent (EAgent) completes this trilogy by providing critical\noversight and iterative refinement of both processes. We validate our method on\nboth digital and physical levels, i.e., nuImage and manually captured\nreal-world scenes, where both statistical and visual results prove that our\nMAGIC is powerful and effective for attacking widely applied object detection\nsystems, i.e., YOLO and DETR series.\n","authors":["Yun Xing","Nhat Chung","Jie Zhang","Yue Cao","Ivor Tsang","Yang Liu","Lei Ma","Qing Guo"],"pdf_url":"https://arxiv.org/pdf/2412.08014v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04807v2","updated":"2025-03-11T07:10:07Z","published":"2025-03-04T02:04:58Z","title":"Call for Rigor in Reporting Quality of Instruction Tuning Data","summary":"  Instruction tuning is crucial for adapting large language models (LLMs) to\nalign with user intentions. Numerous studies emphasize the significance of the\nquality of instruction tuning (IT) data, revealing a strong correlation between\nIT data quality and the alignment performance of LLMs. In these studies, the\nquality of IT data is typically assessed by evaluating the performance of LLMs\ntrained with that data. However, we identified a prevalent issue in such\npractice: hyperparameters for training models are often selected arbitrarily\nwithout adequate justification. We observed significant variations in\nhyperparameters applied across different studies, even when training the same\nmodel with the same data. In this study, we demonstrate the potential problems\narising from this practice and emphasize the need for careful consideration in\nverifying data quality. Through our experiments on the quality of LIMA data and\na selected set of 1,000 Alpaca data points, we demonstrate that arbitrary\nhyperparameter decisions can make any arbitrary conclusion.\n","authors":["Hyeonseok Moon","Jaehyung Seo","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2503.04807v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.08102v1","updated":"2025-03-11T07:05:52Z","published":"2025-03-11T07:05:52Z","title":"AI-native Memory 2.0: Second Me","summary":"  Human interaction with the external world fundamentally involves the exchange\nof personal memory, whether with other individuals, websites, applications, or,\nin the future, AI agents. A significant portion of this interaction is\nredundant, requiring users to repeatedly provide the same information across\ndifferent contexts. Existing solutions, such as browser-stored credentials,\nautofill mechanisms, and unified authentication systems, have aimed to mitigate\nthis redundancy by serving as intermediaries that store and retrieve commonly\nused user data. The advent of large language models (LLMs) presents an\nopportunity to redefine memory management through an AI-native paradigm: SECOND\nME. SECOND ME acts as an intelligent, persistent memory offload system that\nretains, organizes, and dynamically utilizes user-specific knowledge. By\nserving as an intermediary in user interactions, it can autonomously generate\ncontext-aware responses, prefill required information, and facilitate seamless\ncommunication with external systems, significantly reducing cognitive load and\ninteraction friction. Unlike traditional memory storage solutions, SECOND ME\nextends beyond static data retention by leveraging LLM-based memory\nparameterization. This enables structured organization, contextual reasoning,\nand adaptive knowledge retrieval, facilitating a more systematic and\nintelligent approach to memory management. As AI-driven personal agents like\nSECOND ME become increasingly integrated into digital ecosystems, SECOND ME\nfurther represents a critical step toward augmenting human-world interaction\nwith persistent, contextually aware, and self-optimizing memory systems. We\nhave open-sourced the fully localizable deployment system at GitHub:\nhttps://github.com/Mindverse/Second-Me.\n","authors":["Jiale Wei","Xiang Ying","Tao Gao","Felix Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.08102v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13484v3","updated":"2025-03-11T06:49:47Z","published":"2025-01-23T08:57:33Z","title":"MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation\n  Methods","summary":"  Mamba is an efficient sequence model that rivals Transformers and\ndemonstrates significant potential as a foundational architecture for various\ntasks. Quantization is commonly used in neural networks to reduce model size\nand computational latency. However, applying quantization to Mamba remains\nunderexplored, and existing quantization methods, which have been effective for\nCNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot\nsuffers a 21% accuracy drop on Vim-T$^\\dagger$ even under W8A8). We have\npioneered the exploration of this issue and identified several key challenges.\nFirst, significant outliers are present in gate projections, output\nprojections, and matrix multiplications. Second, Mamba's unique parallel scan\nfurther amplifies these outliers, leading to uneven and heavy-tailed data\ndistributions. Third, even with the application of the Hadamard transform, the\nvariance across channels in weights and activations still remains inconsistent.\nTo these ends, we propose MambaQuant, a post-training quantization (PTQ)\nframework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced\nrotation, rendering the rotation matrix adaptable to diverse channel\ndistributions. 2) Smooth-Fused rotation, which equalizes channel variances and\ncan merge additional parameters into model weights. Experiments show that\nMambaQuant can quantize both weights and activations into 8-bit with less than\n1% accuracy loss for Mamba-based vision and language tasks. To the best of our\nknowledge, MambaQuant is the first comprehensive PTQ design for the Mamba\nfamily, paving the way for further advancements in its application.\n","authors":["Zukang Xu","Yuxuan Yue","Xing Hu","Zhihang Yuan","Zixu Jiang","Zhixuan Chen","Jiangyong Yu","Chen Xu","Sifan Zhou","Dawei Yang"],"pdf_url":"https://arxiv.org/pdf/2501.13484v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08091v1","updated":"2025-03-11T06:47:27Z","published":"2025-03-11T06:47:27Z","title":"Revolution of Wireless Signal Recognition for 6G: Recent Advances,\n  Challenges and Future Directions","summary":"  Wireless signal recognition (WSR) is a crucial technique for intelligent\ncommunications and spectrum sharing in the next six-generation (6G) wireless\ncommunication networks. It can be utilized to enhance network performance and\nefficiency, improve quality of service (QoS), and improve network security and\nreliability. Additionally, WSR can be applied for military applications such as\nsignal interception, signal race, and signal abduction. In the past decades,\ngreat efforts have been made for the research of WSR. Earlier works mainly\nfocus on model-based methods, including likelihood-based (LB) and feature-based\n(FB) methods, which have taken the leading position for many years. With the\nemergence of artificial intelligence (AI), intelligent methods including\nmachine learning-based (ML-based) and deep learning-based (DL-based) methods\nhave been developed to extract the features of the received signals and perform\nthe classification. In this work, we provide a comprehensive review of WSR from\nthe view of applications, main tasks, recent advances, datasets and evaluation\nmetrics, challenges, and future directions. Specifically, intelligent WSR\nmethods are introduced from the perspective of model, data, learning and\nimplementation. Moreover, we analyze the challenges for WSR from the view of\ncomplex, dynamic, and open 6G wireless environments and discuss the future\ndirections for WSR. This survey is expected to provide a comprehensive overview\nof the state-of-the-art WSR techniques and inspire new research directions for\nWSR in 6G networks.\n","authors":["Hao Zhang","Fuhui Zhou","Hongyang Du","Qihui Wu","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2503.08091v1.pdf","comment":"submitted to IEEE Communications Surveys & Tutorials"},{"id":"http://arxiv.org/abs/2410.15068v2","updated":"2025-03-11T06:46:42Z","published":"2024-10-19T11:11:58Z","title":"LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired\n  LDR-to-HDR Image Reconstruction","summary":"  The translation of Low Dynamic Range (LDR) to High Dynamic Range (HDR) images\nis an important computer vision task. There is a significant amount of research\nutilizing both conventional non-learning methods and modern data-driven\napproaches, focusing on using both single-exposed and multi-exposed LDR for HDR\nimage reconstruction. However, most current state-of-the-art methods require\nhigh-quality paired {LDR,HDR} datasets for model training. In addition, there\nis limited literature on using unpaired datasets for this task, that is, the\nmodel learns a mapping between domains, i.e., {LDR,HDR}. This paper proposes\nLLM-HDR, a method that integrates the perception of Large Language Models (LLM)\ninto a modified semantic- and cycle-consistent adversarial architecture that\nutilizes unpaired {LDR,HDR} datasets for training. The method introduces novel\nartifact- and exposure-aware generators to address visual artifact removal and\nan encoder and loss to address semantic consistency, another under-explored\ntopic. LLM-HDR is the first to use an LLM for the {LDR,HDR} translation task in\na self-supervised setup. The method achieves state-of-the-art performance\nacross several benchmark datasets and reconstructs high-quality HDR images. The\nofficial website of this work is available at:\nhttps://github.com/HrishavBakulBarua/LLM-HDR\n","authors":["Hrishav Bakul Barua","Kalin Stefanov","Lemuel Lai En Che","Abhinav Dhall","KokSheik Wong","Ganesh Krishnasamy"],"pdf_url":"https://arxiv.org/pdf/2410.15068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08084v1","updated":"2025-03-11T06:37:33Z","published":"2025-03-11T06:37:33Z","title":"Instruction-Augmented Long-Horizon Planning: Embedding Grounding\n  Mechanisms in Embodied Mobile Manipulation","summary":"  Enabling humanoid robots to perform long-horizon mobile manipulation planning\nin real-world environments based on embodied perception and comprehension\nabilities has been a longstanding challenge. With the recent rise of large\nlanguage models (LLMs), there has been a notable increase in the development of\nLLM-based planners. These approaches either utilize human-provided textual\nrepresentations of the real world or heavily depend on prompt engineering to\nextract such representations, lacking the capability to quantitatively\nunderstand the environment, such as determining the feasibility of manipulating\nobjects. To address these limitations, we present the Instruction-Augmented\nLong-Horizon Planning (IALP) system, a novel framework that employs LLMs to\ngenerate feasible and optimal actions based on real-time sensor feedback,\nincluding grounded knowledge of the environment, in a closed-loop interaction.\nDistinct from prior works, our approach augments user instructions into PDDL\nproblems by leveraging both the abstract reasoning capabilities of LLMs and\ngrounding mechanisms. By conducting various real-world long-horizon tasks, each\nconsisting of seven distinct manipulatory skills, our results demonstrate that\nthe IALP system can efficiently solve these tasks with an average success rate\nexceeding 80%. Our proposed method can operate as a high-level planner,\nequipping robots with substantial autonomy in unstructured environments through\nthe utilization of multi-modal sensor inputs.\n","authors":["Fangyuan Wang","Shipeng Lyu","Peng Zhou","Anqing Duan","Guodong Guo","David Navarro-Alarcon"],"pdf_url":"https://arxiv.org/pdf/2503.08084v1.pdf","comment":"17 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.08083v1","updated":"2025-03-11T06:29:13Z","published":"2025-03-11T06:29:13Z","title":"Degradation Self-Supervised Learning for Lithium-ion Battery Health\n  Diagnostics","summary":"  Health evaluation for lithium-ion batteries (LIBs) typically relies on\nconstant charging/discharging protocols, often neglecting scenarios involving\ndynamic current profiles prevalent in electric vehicles. Conventional health\nindicators for LIBs also depend on the uniformity of measured data, restricting\ntheir adaptability to non-uniform conditions. In this study, a novel training\nstrategy for estimating LIB health based on the paradigm of self-supervised\nlearning is proposed. A multiresolution analysis technique, empirical wavelet\ntransform, is utilized to decompose non-stationary voltage signals in the\nfrequency domain. This allows the removal of ineffective components for the\nhealth evaluation model. The transformer neural network serves as the model\nbackbone, and a loss function is designed to describe the capacity degradation\nbehavior with the assumption that the degradation in LIBs across most operating\nconditions is inevitable and irreversible. The results show that the model can\nlearn the aging characteristics by analyzing sequences of voltage and current\nprofiles obtained at various time intervals from the same LIB cell. The\nproposed method is successfully applied to the Stanford University LIB aging\ndataset, derived from electric vehicle real driving profiles. Notably, this\napproach achieves an average correlation coefficient of 0.9 between the\nevaluated health index and the degradation of actual capacity, demonstrating\nits efficacy in capturing LIB health degradation. This research highlights the\nfeasibility of training deep neural networks using unlabeled LIB data, offering\ncost-efficient means and unleashing the potential of the measured information.\n","authors":["J. C. Chen"],"pdf_url":"https://arxiv.org/pdf/2503.08083v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02193v3","updated":"2025-03-11T05:58:39Z","published":"2024-12-03T06:15:04Z","title":"LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language\n  Models","summary":"  Spatial reasoning is a fundamental aspect of human cognition, enabling\nintuitive understanding and manipulation of objects in three-dimensional space.\nWhile foundation models demonstrate remarkable performance on some benchmarks,\nthey still struggle with 3D reasoning tasks like arranging objects in space\naccording to open-ended language instructions, particularly in dense and\nphysically constrained environments. We introduce LayoutVLM, a framework and\nscene layout representation that exploits the semantic knowledge of\nVision-Language Models (VLMs) and supports differentiable optimization to\nensure physical plausibility. LayoutVLM employs VLMs to generate two mutually\nreinforcing representations from visually marked images, and a self-consistent\ndecoding process to improve VLMs spatial planning. Our experiments show that\nLayoutVLM addresses the limitations of existing LLM and constraint-based\napproaches, producing physically plausible 3D layouts better aligned with the\nsemantic intent of input language instructions. We also demonstrate that\nfine-tuning VLMs with the proposed scene layout representation extracted from\nexisting scene datasets can improve their reasoning performance.\n","authors":["Fan-Yun Sun","Weiyu Liu","Siyi Gu","Dylan Lim","Goutam Bhat","Federico Tombari","Manling Li","Nick Haber","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2412.02193v3.pdf","comment":"CVPR 2025, project website:\n  https://ai.stanford.edu/~sunfanyun/layoutvlm/"},{"id":"http://arxiv.org/abs/2503.08065v1","updated":"2025-03-11T05:50:27Z","published":"2025-03-11T05:50:27Z","title":"STGDPM:Vessel Trajectory Prediction with Spatio-Temporal Graph Diffusion\n  Probabilistic Model","summary":"  Vessel trajectory prediction is a critical component for ensuring maritime\ntraffic safety and avoiding collisions. Due to the inherent uncertainty in\nvessel behavior, trajectory prediction systems must adopt a multimodal approach\nto accurately model potential future motion states. However, existing vessel\ntrajectory prediction methods lack the ability to comprehensively model\nbehavioral multi-modality. To better capture multimodal behavior in interactive\nscenarios, we propose modeling interactions as dynamic graphs, replacing\ntraditional aggregation-based techniques that rely on vessel states. By\nleveraging the natural multimodal capabilities of diffusion models, we frame\nthe trajectory prediction task as an inverse process of motion uncertainty\ndiffusion, wherein uncertainties across potential navigational areas are\nprogressively eliminated until the desired trajectories is produced. In\nsummary, we pioneer the integration of Spatio-Temporal Graph (STG) with\ndiffusion models in ship trajectory prediction. Extensive experiments on real\nAutomatic Identification System (AIS) data validate the superiority of our\napproach.\n","authors":["Jin Wenzhe","Tang Haina","Zhang Xudong"],"pdf_url":"https://arxiv.org/pdf/2503.08065v1.pdf","comment":"This paper has been ACCEPTED as a FULL PAPER at DASFAA 2025"},{"id":"http://arxiv.org/abs/2503.08064v1","updated":"2025-03-11T05:50:13Z","published":"2025-03-11T05:50:13Z","title":"Continual Learning for Multiple Modalities","summary":"  Continual learning aims to learn knowledge of tasks observed in sequential\ntime steps while mitigating the forgetting of previously learned knowledge.\nExisting methods were proposed under the assumption of learning a single\nmodality (e.g., image) over time, which limits their applicability in scenarios\ninvolving multiple modalities. In this work, we propose a novel continual\nlearning framework that accommodates multiple modalities (image, video, audio,\ndepth, and text). We train a model to align various modalities with text,\nleveraging its rich semantic information. However, this increases the risk of\nforgetting previously learned knowledge, exacerbated by the differing input\ntraits of each task. To alleviate the overwriting of the previous knowledge of\nmodalities, we propose a method for aggregating knowledge within and across\nmodalities. The aggregated knowledge is obtained by assimilating new\ninformation through self-regularization within each modality and associating\nknowledge between modalities by prioritizing contributions from relevant\nmodalities. Furthermore, we propose a strategy that re-aligns the embeddings of\nmodalities to resolve biased alignment between modalities. We evaluate the\nproposed method in a wide range of continual learning scenarios using multiple\ndatasets with different modalities. Extensive experiments demonstrate that ours\noutperforms existing methods in the scenarios, regardless of whether the\nidentity of the modality is given.\n","authors":["Hyundong Jin","Eunwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2503.08064v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.08051v1","updated":"2025-03-11T05:15:37Z","published":"2025-03-11T05:15:37Z","title":"Counterfactual Language Reasoning for Explainable Recommendation Systems","summary":"  Explainable recommendation systems leverage transparent reasoning to foster\nuser trust and improve decision-making processes. Current approaches typically\ndecouple recommendation generation from explanation creation, violating causal\nprecedence principles where explanatory factors should logically precede\noutcomes. This paper introduces a novel framework integrating structural causal\nmodels with large language models to establish causal consistency in\nrecommendation pipelines. Our methodology enforces explanation factors as\ncausal antecedents to recommendation predictions through causal graph\nconstruction and counterfactual adjustment. We particularly address the\nconfounding effect of item popularity that distorts personalization signals in\nexplanations, developing a debiasing mechanism that disentangles genuine user\npreferences from conformity bias. Through comprehensive experiments across\nmultiple recommendation scenarios, we demonstrate that CausalX achieves\nsuperior performance in recommendation accuracy, explanation plausibility, and\nbias mitigation compared to baselines.\n","authors":["Guanrong Li","Haolin Yang","Xinyu Liu","Zhen Wu","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2503.08051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11091v2","updated":"2025-03-11T04:55:59Z","published":"2023-11-18T14:41:33Z","title":"Deep Tensor Network","summary":"  We introduce the Deep Tensor Network, a novel framework that integrates\ntensor-based operations into the attention mechanism, thereby enhancing both\nthe expressivity and computational efficiency of deep neural networks. Our\napproach leverages the algebraic structure of tensor products to generalize the\nconventional dot-product attention and to formulate new operators, namely,\nTensor Attention and Tensor Interaction, which capture higher-order token\ndependencies. Through rigorous theoretical analysis based on the universal\nproperties of tensor products, we demonstrate that our framework not only\nimproves efficiency by reducing computational complexity but also offers a\nprincipled method for modeling complex interactions in sequential data.\nEmpirical evaluations further substantiate that the proposed deep tensor\nnetwork can serve as a robust building block for advancing state-of-the-art\nperformance in various deep learning tasks.\n","authors":["Xuantao Li"],"pdf_url":"https://arxiv.org/pdf/2311.11091v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16663v2","updated":"2025-03-11T04:54:03Z","published":"2025-01-28T02:52:51Z","title":"Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine\n  Unlearning","summary":"  Duplication is a prevalent issue within datasets. Existing research has\ndemonstrated that the presence of duplicated data in training datasets can\nsignificantly influence both model performance and data privacy. However, the\nimpact of data duplication on the unlearning process remains largely\nunexplored. This paper addresses this gap by pioneering a comprehensive\ninvestigation into the role of data duplication, not only in standard machine\nunlearning but also in federated and reinforcement unlearning paradigms.\nSpecifically, we propose an adversary who duplicates a subset of the target\nmodel's training set and incorporates it into the training set. After training,\nthe adversary requests the model owner to unlearn this duplicated subset, and\nanalyzes the impact on the unlearned model. For example, the adversary can\nchallenge the model owner by revealing that, despite efforts to unlearn it, the\ninfluence of the duplicated subset remains in the model. Moreover, to\ncircumvent detection by de-duplication techniques, we propose three novel\nnear-duplication methods for the adversary, each tailored to a specific\nunlearning paradigm. We then examine their impacts on the unlearning process\nwhen de-duplication techniques are applied. Our findings reveal several crucial\ninsights: 1) the gold standard unlearning method, retraining from scratch,\nfails to effectively conduct unlearning under certain conditions; 2) unlearning\nduplicated data can lead to significant model degradation in specific\nscenarios; and 3) meticulously crafted duplicates can evade detection by\nde-duplication methods.\n","authors":["Dayong Ye","Tianqing Zhu","Jiayang Li","Kun Gao","Bo Liu","Leo Yu Zhang","Wanlei Zhou","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.16663v2.pdf","comment":"Accepted at USENIX Security 2025"},{"id":"http://arxiv.org/abs/2503.08038v1","updated":"2025-03-11T04:43:33Z","published":"2025-03-11T04:43:33Z","title":"Generalized Kullback-Leibler Divergence Loss","summary":"  In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss\nand mathematically prove that it is equivalent to the Decoupled\nKullback-Leibler (DKL) Divergence loss that consists of (1) a weighted Mean\nSquare Error (wMSE) loss and (2) a Cross-Entropy loss incorporating soft\nlabels. Thanks to the decoupled structure of DKL loss, we have identified two\nareas for improvement. Firstly, we address the limitation of KL loss in\nscenarios like knowledge distillation by breaking its asymmetric optimization\nproperty along with a smoother weight function. This modification effectively\nalleviates convergence challenges in optimization, particularly for classes\nwith high predicted scores in soft labels. Secondly, we introduce class-wise\nglobal information into KL/DKL to reduce bias arising from individual samples.\nWith these two enhancements, we derive the Generalized Kullback-Leibler (GKL)\nDivergence loss and evaluate its effectiveness by conducting experiments on\nCIFAR-10/100, ImageNet, and vision-language datasets, focusing on adversarial\ntraining, and knowledge distillation tasks. Specifically, we achieve new\nstate-of-the-art adversarial robustness on the public leaderboard --\nRobustBench and competitive knowledge distillation performance across\nCIFAR/ImageNet models and CLIP models, demonstrating the substantial practical\nmerits. Our code is available at https://github.com/jiequancui/DKL.\n","authors":["Jiequan Cui","Beier Zhu","Qingshan Xu","Zhuotao Tian","Xiaojuan Qi","Bei Yu","Hanwang Zhang","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2503.08038v1.pdf","comment":"extension of our NeurIPS paper \"Decoupled Kullback-Leibler Divergence\n  Loss\". arXiv admin note: substantial text overlap with arXiv:2305.13948"},{"id":"http://arxiv.org/abs/2503.08037v1","updated":"2025-03-11T04:42:59Z","published":"2025-03-11T04:42:59Z","title":"ObjectMover: Generative Object Movement with Video Prior","summary":"  Simple as it seems, moving an object to another location within an image is,\nin fact, a challenging image-editing task that requires re-harmonizing the\nlighting, adjusting the pose based on perspective, accurately filling occluded\nregions, and ensuring coherent synchronization of shadows and reflections while\nmaintaining the object identity. In this paper, we present ObjectMover, a\ngenerative model that can perform object movement in highly challenging scenes.\nOur key insight is that we model this task as a sequence-to-sequence problem\nand fine-tune a video generation model to leverage its knowledge of consistent\nobject generation across video frames. We show that with this approach, our\nmodel is able to adjust to complex real-world scenarios, handling extreme\nlighting harmonization and object effect movement. As large-scale data for\nobject movement are unavailable, we construct a data generation pipeline using\na modern game engine to synthesize high-quality data pairs. We further propose\na multi-task learning strategy that enables training on real-world video data\nto improve the model generalization. Through extensive experiments, we\ndemonstrate that ObjectMover achieves outstanding results and adapts well to\nreal-world scenarios.\n","authors":["Xin Yu","Tianyu Wang","Soo Ye Kim","Paul Guerrero","Xi Chen","Qing Liu","Zhe Lin","Xiaojuan Qi"],"pdf_url":"https://arxiv.org/pdf/2503.08037v1.pdf","comment":"CVPR 2025, Project Page: https://xinyu-andy.github.io/ObjMover"},{"id":"http://arxiv.org/abs/2412.19496v2","updated":"2025-03-11T04:32:32Z","published":"2024-12-27T07:33:39Z","title":"Multi-P$^2$A: A Multi-perspective Benchmark on Privacy Assessment for\n  Large Vision-Language Models","summary":"  Large Vision-Language Models (LVLMs) exhibit impressive potential across\nvarious tasks but also face significant privacy risks, limiting their practical\napplications. Current researches on privacy assessment for LVLMs is limited in\nscope, with gaps in both assessment dimensions and privacy categories. To\nbridge this gap, we propose Multi-P$^2$A, a comprehensive benchmark for\nevaluating the privacy preservation capabilities of LVLMs in terms of privacy\nawareness and leakage. Privacy awareness measures the model's ability to\nrecognize the privacy sensitivity of input data, while privacy leakage assesses\nthe risk of the model unintentionally disclosing privacy information in its\noutput. We design a range of sub-tasks to thoroughly evaluate the model's\nprivacy protection offered by LVLMs. Multi-P$^2$A covers 26 categories of\npersonal privacy, 15 categories of trade secrets, and 18 categories of state\nsecrets, totaling 31,962 samples. Based on Multi-P$^2$A, we evaluate the\nprivacy preservation capabilities of 21 open-source and 2 closed-source LVLMs.\nOur results reveal that current LVLMs generally pose a high risk of\nfacilitating privacy breaches, with vulnerabilities varying across personal\nprivacy, trade secret, and state secret.\n","authors":["Jie Zhang","Xiangkui Cao","Zhouyu Han","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2412.19496v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08032v1","updated":"2025-03-11T04:29:22Z","published":"2025-03-11T04:29:22Z","title":"HOFAR: High-Order Augmentation of Flow Autoregressive Transformers","summary":"  Flow Matching and Transformer architectures have demonstrated remarkable\nperformance in image generation tasks, with recent work FlowAR [Ren et al.,\n2024] synergistically integrating both paradigms to advance synthesis fidelity.\nHowever, current FlowAR implementations remain constrained by first-order\ntrajectory modeling during the generation process. This paper introduces a\nnovel framework that systematically enhances flow autoregressive transformers\nthrough high-order supervision. We provide theoretical analysis and empirical\nevaluation showing that our High-Order FlowAR (HOFAR) demonstrates measurable\nimprovements in generation quality compared to baseline models. The proposed\napproach advances the understanding of flow-based autoregressive modeling by\nintroducing a systematic framework for analyzing trajectory dynamics through\nhigh-order expansion.\n","authors":["Yingyu Liang","Zhizhou Sha","Zhenmei Shi","Zhao Song","Mingda Wan"],"pdf_url":"https://arxiv.org/pdf/2503.08032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08026v1","updated":"2025-03-11T04:15:52Z","published":"2025-03-11T04:15:52Z","title":"In Prospect and Retrospect: Reflective Memory Management for Long-term\n  Personalized Dialogue Agents","summary":"  Large Language Models (LLMs) have made significant progress in open-ended\ndialogue, yet their inability to retain and retrieve relevant information from\nlong-term interactions limits their effectiveness in applications requiring\nsustained personalization. External memory mechanisms have been proposed to\naddress this limitation, enabling LLMs to maintain conversational continuity.\nHowever, existing approaches struggle with two key challenges. First, rigid\nmemory granularity fails to capture the natural semantic structure of\nconversations, leading to fragmented and incomplete representations. Second,\nfixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user\ninteraction patterns. In this work, we propose Reflective Memory Management\n(RMM), a novel mechanism for long-term dialogue agents, integrating forward-\nand backward-looking reflections: (1) Prospective Reflection, which dynamically\nsummarizes interactions across granularities-utterances, turns, and\nsessions-into a personalized memory bank for effective future retrieval, and\n(2) Retrospective Reflection, which iteratively refines the retrieval in an\nonline reinforcement learning (RL) manner based on LLMs' cited evidence.\nExperiments show that RMM demonstrates consistent improvement across various\nmetrics and benchmarks. For example, RMM shows more than 10% accuracy\nimprovement over the baseline without memory management on the LongMemEval\ndataset.\n","authors":["Zhen Tan","Jun Yan","I-Hung Hsu","Rujun Han","Zifeng Wang","Long T. Le","Yiwen Song","Yanfei Chen","Hamid Palangi","George Lee","Anand Iyer","Tianlong Chen","Huan Liu","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2503.08026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04412v3","updated":"2025-03-11T03:56:24Z","published":"2024-02-06T21:18:34Z","title":"The VampPrior Mixture Model","summary":"  Widely used deep latent variable models (DLVMs), in particular Variational\nAutoencoders (VAEs), employ overly simplistic priors on the latent space. To\nachieve strong clustering performance, existing methods that replace the\nstandard normal prior with a Gaussian mixture model (GMM) require defining the\nnumber of clusters to be close to the number of expected ground truth classes\na-priori and are susceptible to poor initializations. We leverage VampPrior\nconcepts (Tomczak and Welling, 2018) to fit a Bayesian GMM prior, resulting in\nthe VampPrior Mixture Model (VMM), a novel prior for DLVMs. In a VAE, the VMM\nattains highly competitive clustering performance on benchmark datasets.\nIntegrating the VMM into scVI (Lopez et al., 2018), a popular scRNA-seq\nintegration method, significantly improves its performance and automatically\narranges cells into clusters with similar biological characteristics.\n","authors":["Andrew A. Stirn","David A. Knowles"],"pdf_url":"https://arxiv.org/pdf/2402.04412v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08012v1","updated":"2025-03-11T03:40:44Z","published":"2025-03-11T03:40:44Z","title":"Exploring Bias in over 100 Text-to-Image Generative Models","summary":"  We investigate bias trends in text-to-image generative models over time,\nfocusing on the increasing availability of models through open platforms like\nHugging Face. While these platforms democratize AI, they also facilitate the\nspread of inherently biased models, often shaped by task-specific fine-tuning.\nEnsuring ethical and transparent AI deployment requires robust evaluation\nframeworks and quantifiable bias metrics. To this end, we assess bias across\nthree key dimensions: (i) distribution bias, (ii) generative hallucination, and\n(iii) generative miss-rate. Analyzing over 100 models, we reveal how bias\npatterns evolve over time and across generative tasks. Our findings indicate\nthat artistic and style-transferred models exhibit significant bias, whereas\nfoundation models, benefiting from broader training distributions, are becoming\nprogressively less biased. By identifying these systemic trends, we contribute\na large-scale evaluation corpus to inform bias research and mitigation\nstrategies, fostering more responsible AI development.\n  Keywords: Bias, Ethical AI, Text-to-Image, Generative Models, Open-Source\nModels\n","authors":["Jordan Vice","Naveed Akhtar","Richard Hartley","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2503.08012v1.pdf","comment":"Accepted to ICLR 2025 Workshop on Open Science for Foundation Models\n  (SCI-FM)"},{"id":"http://arxiv.org/abs/2503.07536v2","updated":"2025-03-11T03:32:59Z","published":"2025-03-10T17:04:14Z","title":"LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through\n  Two-Stage Rule-Based RL","summary":"  Enhancing reasoning in Large Multimodal Models (LMMs) faces unique challenges\nfrom the complex interplay between visual perception and logical reasoning,\nparticularly in compact 3B-parameter architectures where architectural\nconstraints limit reasoning capacity and modality alignment.\n  While rule-based reinforcement learning (RL) excels in text-only domains, its\nmultimodal extension confronts two critical barriers: (1) data limitations due\nto ambiguous answers and scarce complex reasoning examples, and (2) degraded\nfoundational reasoning induced by multimodal pretraining. To address these\nchallenges, we propose \\textbf{LMM-R1}, a two-stage framework adapting\nrule-based RL for multimodal reasoning through \\textbf{Foundational Reasoning\nEnhancement (FRE)} followed by \\textbf{Multimodal Generalization Training\n(MGT)}. The FRE stage first strengthens reasoning abilities using text-only\ndata with rule-based RL, then the MGT stage generalizes these reasoning\ncapabilities to multimodal domains.\n  Experiments on Qwen2.5-VL-Instruct-3B demonstrate that LMM-R1 achieves 4.83\\%\nand 4.5\\% average improvements over baselines in multimodal and text-only\nbenchmarks, respectively, with a 3.63\\% gain in complex Football Game tasks.\nThese results validate that text-based reasoning enhancement enables effective\nmultimodal generalization, offering a data-efficient paradigm that bypasses\ncostly high-quality multimodal training data.\n","authors":["Yingzhe Peng","Gongrui Zhang","Miaosen Zhang","Zhiyuan You","Jie Liu","Qipeng Zhu","Kai Yang","Xingzhong Xu","Xin Geng","Xu Yang"],"pdf_url":"https://arxiv.org/pdf/2503.07536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08010v1","updated":"2025-03-11T03:25:44Z","published":"2025-03-11T03:25:44Z","title":"SKALD: Learning-Based Shot Assembly for Coherent Multi-Shot Video\n  Creation","summary":"  We present SKALD, a multi-shot video assembly method that constructs coherent\nvideo sequences from candidate shots with minimal reliance on text. Central to\nour approach is the Learned Clip Assembly (LCA) score, a learning-based metric\nthat measures temporal and semantic relationships between shots to quantify\nnarrative coherence. We tackle the exponential complexity of combining multiple\nshots with an efficient beam-search algorithm guided by the LCA score. To train\nour model effectively with limited human annotations, we propose two tasks for\nthe LCA encoder: Shot Coherence Learning, which uses contrastive learning to\ndistinguish coherent and incoherent sequences, and Feature Regression, which\nconverts these learned representations into a real-valued coherence score. We\ndevelop two variants: a base SKALD model that relies solely on visual coherence\nand SKALD-text, which integrates auxiliary text information when available.\nExperiments on the VSPD and our curated MSV3C datasets show that SKALD achieves\nan improvement of up to 48.6% in IoU and a 43% speedup over the\nstate-of-the-art methods. A user study further validates our approach, with 45%\nof participants favoring SKALD-assembled videos, compared to 22% preferring\ntext-based assembly methods.\n","authors":["Chen Yi Lu","Md Mehrab Tanjim","Ishita Dasgupta","Somdeb Sarkhel","Gang Wu","Saayan Mitra","Somali Chaterji"],"pdf_url":"https://arxiv.org/pdf/2503.08010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10443v3","updated":"2025-03-11T03:19:42Z","published":"2024-12-11T13:48:06Z","title":"SweetTok: Semantic-Aware Spatial-Temporal Tokenizer for Compact Video\n  Discretization","summary":"  This paper presents the \\textbf{S}emantic-a\\textbf{W}ar\\textbf{E}\nspatial-t\\textbf{E}mporal \\textbf{T}okenizer (SweetTok), a novel video\ntokenizer to overcome the limitations in current video tokenization methods for\ncompacted yet effective discretization. Unlike previous approaches that process\nflattened local visual patches via direct discretization or adaptive query\ntokenization, SweetTok proposes a decoupling framework, compressing visual\ninputs through distinct spatial and temporal queries via \\textbf{D}ecoupled\n\\textbf{Q}uery \\textbf{A}uto\\textbf{E}ncoder (DQAE). This design allows\nSweetTok to efficiently compress video token count while achieving superior\nfidelity by capturing essential information across spatial and temporal\ndimensions. Furthermore, we design a \\textbf{M}otion-enhanced \\textbf{L}anguage\n\\textbf{C}odebook (MLC) tailored for spatial and temporal compression to\naddress the differences in semantic representation between appearance and\nmotion information. SweetTok significantly improves video reconstruction\nresults by \\textbf{42.8\\%} w.r.t rFVD on UCF-101 dataset. With a better token\ncompression strategy, it also boosts downstream video generation results by\n\\textbf{15.1\\%} w.r.t gFVD. Additionally, the compressed decoupled tokens are\nimbued with semantic information, enabling few-shot recognition capabilities\npowered by LLMs in downstream applications.\n","authors":["Zhentao Tan","Ben Xue","Jian Jia","Junhao Wang","Wencai Ye","Shaoyun Shi","Mingjie Sun","Wenjin Wu","Quan Chen","Peng Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.10443v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08007v1","updated":"2025-03-11T03:13:45Z","published":"2025-03-11T03:13:45Z","title":"MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped\n  Vision-Language-Action Models","summary":"  Developing versatile quadruped robots that can smoothly perform various\nactions and tasks in real-world environments remains a significant challenge.\nThis paper introduces a novel vision-language-action (VLA) model, mixture of\nrobotic experts (MoRE), for quadruped robots that aim to introduce\nreinforcement learning (RL) for fine-tuning large-scale VLA models with a large\namount of mixed-quality data. MoRE integrates multiple low-rank adaptation\nmodules as distinct experts within a dense multi-modal large language model\n(MLLM), forming a sparse-activated mixture-of-experts model. This design\nenables the model to effectively adapt to a wide array of downstream tasks.\nMoreover, we employ a reinforcement learning-based training objective to train\nour model as a Q-function after deeply exploring the structural properties of\nour tasks. Effective learning from automatically collected mixed-quality data\nenhances data efficiency and model performance. Extensive experiments\ndemonstrate that MoRE outperforms all baselines across six different skills and\nexhibits superior generalization capabilities in out-of-distribution scenarios.\nWe further validate our method in real-world scenarios, confirming the\npracticality of our approach and laying a solid foundation for future research\non multi-task learning in quadruped robots.\n","authors":["Han Zhao","Wenxuan Song","Donglin Wang","Xinyang Tong","Pengxiang Ding","Xuelian Cheng","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2503.08007v1.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.08006v1","updated":"2025-03-11T03:11:54Z","published":"2025-03-11T03:11:54Z","title":"Injecting Imbalance Sensitivity for Multi-Task Learning","summary":"  Multi-task learning (MTL) has emerged as a promising approach for deploying\ndeep learning models in real-life applications. Recent studies have proposed\noptimization-based learning paradigms to establish task-shared representations\nin MTL. However, our paper empirically argues that these studies, specifically\ngradient-based ones, primarily emphasize the conflict issue while neglecting\nthe potentially more significant impact of imbalance/dominance in MTL. In line\nwith this perspective, we enhance the existing baseline method by injecting\nimbalance-sensitivity through the imposition of constraints on the projected\nnorms. To demonstrate the effectiveness of our proposed IMbalance-sensitive\nGradient (IMGrad) descent method, we evaluate it on multiple mainstream MTL\nbenchmarks, encompassing supervised learning tasks as well as reinforcement\nlearning. The experimental results consistently demonstrate competitive\nperformance.\n","authors":["Zhipeng Zhou","Liu Liu","Peilin Zhao","Wei Gong"],"pdf_url":"https://arxiv.org/pdf/2503.08006v1.pdf","comment":"9 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2412.08637v3","updated":"2025-03-11T03:10:09Z","published":"2024-12-11T18:58:40Z","title":"DMin: Scalable Training Data Influence Estimation for Diffusion Models","summary":"  Identifying the training data samples that most influence a generated image\nis a critical task in understanding diffusion models (DMs), yet existing\ninfluence estimation methods are constrained to small-scale or LoRA-tuned\nmodels due to computational limitations. To address this challenge, we propose\nDMin (Diffusion Model influence), a scalable framework for estimating the\ninfluence of each training data sample on a given generated image. To the best\nof our knowledge, it is the first method capable of influence estimation for\nDMs with billions of parameters. Leveraging efficient gradient compression,\nDMin reduces storage requirements from hundreds of TBs to mere MBs or even KBs,\nand retrieves the top-k most influential training samples in under 1 second,\nall while maintaining performance. Our empirical results demonstrate DMin is\nboth effective in identifying influential training samples and efficient in\nterms of computational and storage requirements.\n","authors":["Huawei Lin","Yingjie Lao","Weijie Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.08637v3.pdf","comment":"14 pages, 6 figures, 8 tables. Under Review"},{"id":"http://arxiv.org/abs/2502.11054v4","updated":"2025-03-11T03:06:17Z","published":"2025-02-16T09:27:44Z","title":"Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on\n  Large Language Models","summary":"  Multi-turn jailbreak attacks simulate real-world human interactions by\nengaging large language models (LLMs) in iterative dialogues, exposing critical\nsafety vulnerabilities. However, existing methods often struggle to balance\nsemantic coherence with attack effectiveness, resulting in either benign\nsemantic drift or ineffective detection evasion. To address this challenge, we\npropose Reasoning-Augmented Conversation, a novel multi-turn jailbreak\nframework that reformulates harmful queries into benign reasoning tasks and\nleverages LLMs' strong reasoning capabilities to compromise safety alignment.\nSpecifically, we introduce an attack state machine framework to systematically\nmodel problem translation and iterative reasoning, ensuring coherent query\ngeneration across multiple turns. Building on this framework, we design\ngain-guided exploration, self-play, and rejection feedback modules to preserve\nattack semantics, enhance effectiveness, and sustain reasoning-driven attack\nprogression. Extensive experiments on multiple LLMs demonstrate that RACE\nachieves state-of-the-art attack effectiveness in complex conversational\nscenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,\nour approach achieves ASRs of 82% and 92% against leading commercial models,\nOpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at\nhttps://github.com/NY1024/RACE to facilitate further research in this critical\ndomain.\n","authors":["Zonghao Ying","Deyue Zhang","Zonglei Jing","Yisong Xiao","Quanchen Zou","Aishan Liu","Siyuan Liang","Xiangzheng Zhang","Xianglong Liu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2502.11054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10883v2","updated":"2025-03-11T03:05:45Z","published":"2024-08-20T14:13:54Z","title":"Dynamic Analysis and Adaptive Discriminator for Fake News Detection","summary":"  In current web environment, fake news spreads rapidly across online social\nnetworks, posing serious threats to society. Existing multimodal fake news\ndetection methods can generally be classified into knowledge-based and\nsemantic-based approaches. However, these methods are heavily rely on human\nexpertise and feedback, lacking flexibility. To address this challenge, we\npropose a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fake\nnews detection. For knowledge-based methods, we introduce the Monte Carlo Tree\nSearch algorithm to leverage the self-reflective capabilities of large language\nmodels (LLMs) for prompt optimization, providing richer, domain-specific\ndetails and guidance to the LLMs, while enabling more flexible integration of\nLLM comment on news content. For semantic-based methods, we define four typical\ndeceit patterns: emotional exaggeration, logical inconsistency, image\nmanipulation, and semantic inconsistency, to reveal the mechanisms behind fake\nnews creation. To detect these patterns, we carefully design four\ndiscriminators and expand them in depth and breadth, using the soft-routing\nmechanism to explore optimal detection models. Experimental results on three\nreal-world datasets demonstrate the superiority of our approach. The code will\nbe available at: https://github.com/SuXinqi/DAAD.\n","authors":["Xinqi Su","Zitong Yu","Yawen Cui","Ajian Liu","Xun Lin","Yuhao Wang","Haochen Liang","Wenhui Li","Li Shen","Xiaochun Cao"],"pdf_url":"https://arxiv.org/pdf/2408.10883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15210v4","updated":"2025-03-11T02:56:08Z","published":"2024-11-20T10:41:23Z","title":"Towards Million-Scale Adversarial Robustness Evaluation With Stronger\n  Individual Attacks","summary":"  As deep learning models are increasingly deployed in safety-critical\napplications, evaluating their vulnerabilities to adversarial perturbations is\nessential for ensuring their reliability and trustworthiness. Over the past\ndecade, a large number of white-box adversarial robustness evaluation methods\n(i.e., attacks) have been proposed, ranging from single-step to multi-step\nmethods and from individual to ensemble methods. Despite these advances,\nchallenges remain in conducting meaningful and comprehensive robustness\nevaluations, particularly when it comes to large-scale testing and ensuring\nevaluations reflect real-world adversarial risks. In this work, we focus on\nimage classification models and propose a novel individual attack method,\nProbability Margin Attack (PMA), which defines the adversarial margin in the\nprobability space rather than the logits space. We analyze the relationship\nbetween PMA and existing cross-entropy or logits-margin-based attacks, and show\nthat PMA can outperform the current state-of-the-art individual methods.\nBuilding on PMA, we propose two types of ensemble attacks that balance\neffectiveness and efficiency. Furthermore, we create a million-scale dataset,\nCC1M, derived from the existing CC3M dataset, and use it to conduct the first\nmillion-scale white-box adversarial robustness evaluation of\nadversarially-trained ImageNet models. Our findings provide valuable insights\ninto the robustness gaps between individual versus ensemble attacks and\nsmall-scale versus million-scale evaluations.\n","authors":["Yong Xie","Weijie Zheng","Hanxun Huang","Guangnan Ye","Xingjun Ma"],"pdf_url":"https://arxiv.org/pdf/2411.15210v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07996v1","updated":"2025-03-11T02:52:39Z","published":"2025-03-11T02:52:39Z","title":"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic","summary":"  Recent advancements in Text-to-SQL systems have improved the conversion of\nnatural language queries into SQL, but challenges remain in ensuring accuracy\nand reliability. While self-correction techniques refine outputs, they often\nintroduce new errors. Existing methods focused on execution feedback mainly\naddress syntax issues, leaving semantic errors -- where the query's logic fails\nto align with the user's intent -- largely unaddressed.\n  We propose a novel approach combining structured execution feedback with a\ntrained critic agent that provides detailed, interpretable critiques. This\nmethod effectively identifies and corrects both syntactic and semantic errors,\nenhancing accuracy and interpretability. Experimental results show significant\nimprovements on two major Text-to-SQL benchmarks, Spider and BIRD,\ndemonstrating the effectiveness of our approach.\n","authors":["Jikai Chen","Leilei Gan"],"pdf_url":"https://arxiv.org/pdf/2503.07996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07993v1","updated":"2025-03-11T02:50:45Z","published":"2025-03-11T02:50:45Z","title":"LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics","summary":"  Disconnected data silos within enterprises obstruct the extraction of\nactionable insights, diminishing efficiency in areas such as product\ndevelopment, client engagement, meeting preparation, and analytics-driven\ndecision-making. This paper introduces a framework that uses large language\nmodels (LLMs) to unify various data sources into a comprehensive,\nactivity-centric knowledge graph. The framework automates tasks such as entity\nextraction, relationship inference, and semantic enrichment, enabling advanced\nquerying, reasoning, and analytics across data types like emails, calendars,\nchats, documents, and logs. Designed for enterprise flexibility, it supports\napplications such as contextual search, task prioritization, expertise\ndiscovery, personalized recommendations, and advanced analytics to identify\ntrends and actionable insights. Experimental results demonstrate its success in\nthe discovery of expertise, task management, and data-driven decision making.\nBy integrating LLMs with knowledge graphs, this solution bridges disconnected\nsystems and delivers intelligent analytics-powered enterprise tools.\n","authors":["Rajeev Kumar","Kumar Ishan","Harishankar Kumar","Abhinandan Singla"],"pdf_url":"https://arxiv.org/pdf/2503.07993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07994v1","updated":"2025-03-11T02:50:45Z","published":"2025-03-11T02:50:45Z","title":"A Neural Symbolic Model for Space Physics","summary":"  In this study, we unveil a new AI model, termed PhyE2E, to discover physical\nformulas through symbolic regression. PhyE2E simplifies symbolic regression by\ndecomposing it into sub-problems using the second-order derivatives of an\noracle neural network, and employs a transformer model to translate data into\nsymbolic formulas in an end-to-end manner. The resulting formulas are refined\nthrough Monte-Carlo Tree Search and Genetic Programming. We leverage a large\nlanguage model to synthesize extensive symbolic expressions resembling real\nphysics, and train the model to recover these formulas directly from data. A\ncomprehensive evaluation reveals that PhyE2E outperforms existing\nstate-of-the-art approaches, delivering superior symbolic accuracy, precision\nin data fitting, and consistency in physical units. We deployed PhyE2E to five\napplications in space physics, including the prediction of sunspot numbers,\nsolar rotational angular velocity, emission line contribution functions,\nnear-Earth plasma pressure, and lunar-tide plasma signals. The physical\nformulas generated by AI demonstrate a high degree of accuracy in fitting the\nexperimental data from satellites and astronomical telescopes. We have\nsuccessfully upgraded the formula proposed by NASA in 1993 regarding solar\nactivity, and for the first time, provided the explanations for the long cycle\nof solar activity in an explicit form. We also found that the decay of\nnear-Earth plasma pressure is proportional to r^2 to Earth, where subsequent\nmathematical derivations are consistent with satellite data from another\nindependent study. Moreover, we found physical formulas that can describe the\nrelationships between emission lines in the extreme ultraviolet spectrum of the\nSun, temperatures, electron densities, and magnetic fields. The formula\nobtained is consistent with the properties that physicists had previously\nhypothesized it should possess.\n","authors":["Jie Ying","Haowei Lin","Chao Yue","Yajie Chen","Chao Xiao","Quanqi Shi","Yitao Liang","Shing-Tung Yau","Yuan Zhou","Jianzhu Ma"],"pdf_url":"https://arxiv.org/pdf/2503.07994v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07992v1","updated":"2025-03-11T02:50:16Z","published":"2025-03-11T02:50:16Z","title":"Efficient and Accurate Estimation of Lipschitz Constants for Hybrid\n  Quantum-Classical Decision Models","summary":"  In this paper, we propose a novel framework for efficiently and accurately\nestimating Lipschitz constants in hybrid quantum-classical decision models. Our\napproach integrates classical neural network with quantum variational circuits\nto address critical issues in learning theory such as fairness verification,\nrobust training, and generalization.\n  By a unified convex optimization formulation, we extend existing classical\nmethods to capture the interplay between classical and quantum layers. This\nintegrated strategy not only provide a tight bound on the Lipschitz constant\nbut also improves computational efficiency with respect to the previous\nmethods.\n","authors":["Sajjad Hashemian","Mohammad Saeed Arvenaghi"],"pdf_url":"https://arxiv.org/pdf/2503.07992v1.pdf","comment":"14 pages, 5 figuers, Submitted to TASE 2025"},{"id":"http://arxiv.org/abs/2503.07991v1","updated":"2025-03-11T02:49:58Z","published":"2025-03-11T02:49:58Z","title":"Boundary Prompting: Elastic Urban Region Representation via Graph-based\n  Spatial Tokenization","summary":"  Urban region representation is essential for various applications such as\nurban planning, resource allocation, and policy development. Traditional\nmethods rely on fixed, predefined region boundaries, which fail to capture the\ndynamic and complex nature of real-world urban areas. In this paper, we propose\nthe Boundary Prompting Urban Region Representation Framework (BPURF), a novel\napproach that allows for elastic urban region definitions. BPURF comprises two\nkey components: (1) A spatial token dictionary, where urban entities are\ntreated as tokens and integrated into a unified token graph, and (2) a region\ntoken set representation model which utilize token aggregation and a\nmulti-channel model to embed token sets corresponding to region boundaries.\nAdditionally, we propose fast token set extraction strategy to enable online\ntoken set extraction during training and prompting. This framework enables the\ndefinition of urban regions through boundary prompting, supporting varying\nregion boundaries and adapting to different tasks. Extensive experiments\ndemonstrate the effectiveness of BPURF in capturing the complex characteristics\nof urban regions.\n","authors":["Haojia Zhu","Jiahui Jin","Dong Kan","Rouxi Shen","Ruize Wang","Xiangguo Sun","Jinghui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.07991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06772v2","updated":"2025-03-11T02:46:19Z","published":"2025-02-10T18:51:47Z","title":"ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates","summary":"  We present that hierarchical LLM reasoning via scaling thought templates can\neffectively optimize the reasoning search space and outperform the mathematical\nreasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3.\nWe train our ReasonFlux-32B model with only 8 GPUs and introduces three\ninnovations: (i) a structured and generic thought template library, containing\naround 500 high-level thought templates capable of generalizing to similar or\nrelevant reasoning problems; (ii) performing hierarchical reinforcement\nlearning on a sequence of thought templates instead of long CoTs, optimizing a\nbase LLM to plan out an optimal template trajectory for gradually handling\ncomplex problems; (iii) a brand new inference scaling system that enables\nhierarchical LLM reasoning by adaptively scaling thought templates at inference\ntime. With a template trajectory containing more explainable reasoning\nstructures than DeepSeek-R1 and o3-mini, our ReasonFlux-32B significantly\nadvances math reasoning capabilities to state-of-the-art levels. Notably, on\nthe MATH benchmark, it achieves an accuracy of 91.2% and surpasses o1-preview\nby 6.7%. On the USA Math Olympiad (AIME) benchmark, ReasonFlux-32B solves an\naverage of 56.7% of problems, surpassing o1-preview and DeepSeek-V3 by 27% and\n45%, respectively. Code: https://github.com/Gen-Verse/ReasonFlux\n","authors":["Ling Yang","Zhaochen Yu","Bin Cui","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2502.06772v2.pdf","comment":"Code: https://github.com/Gen-Verse/ReasonFlux"},{"id":"http://arxiv.org/abs/2503.07988v1","updated":"2025-03-11T02:44:32Z","published":"2025-03-11T02:44:32Z","title":"Provable Zero-Shot Generalization in Offline Reinforcement Learning","summary":"  In this work, we study offline reinforcement learning (RL) with zero-shot\ngeneralization property (ZSG), where the agent has access to an offline dataset\nincluding experiences from different environments, and the goal of the agent is\nto train a policy over the training environments which performs well on test\nenvironments without further interaction. Existing work showed that classical\noffline RL fails to generalize to new, unseen environments. We propose\npessimistic empirical risk minimization (PERM) and pessimistic proximal policy\noptimization (PPPO), which leverage pessimistic policy evaluation to guide\npolicy learning and enhance generalization. We show that both PERM and PPPO are\ncapable of finding a near-optimal policy with ZSG. Our result serves as a first\nstep in understanding the foundation of the generalization phenomenon in\noffline reinforcement learning.\n","authors":["Zhiyong Wang","Chen Yang","John C. S. Lui","Dongruo Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.07988v1.pdf","comment":"30 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2502.01821v2","updated":"2025-03-11T02:30:46Z","published":"2025-02-03T20:57:17Z","title":"Agentic Bug Reproduction for Effective Automated Program Repair at\n  Google","summary":"  Bug reports often lack sufficient detail for developers to reproduce and fix\nthe underlying defects. Bug Reproduction Tests (BRTs), tests that fail when the\nbug is present and pass when it has been resolved, are crucial for debugging,\nbut they are rarely included in bug reports, both in open-source and in\nindustrial settings. Thus, automatically generating BRTs from bug reports has\nthe potential to accelerate the debugging process and lower time to repair.\nThis paper investigates automated BRT generation within an industry setting,\nspecifically at Google, focusing on the challenges of a large-scale,\nproprietary codebase and considering real-world industry bugs extracted from\nGoogle's internal issue tracker. We adapt and evaluate a state-of-the-art BRT\ngeneration technique, LIBRO, and present our agent-based approach, BRT Agent,\nwhich makes use of a fine-tuned Large Language Model (LLM) for code editing.\nOur BRT Agent significantly outperforms LIBRO, achieving a 28% plausible BRT\ngeneration rate, compared to 10% by LIBRO, on 80 human-reported bugs from\nGoogle's internal issue tracker. We further investigate the practical value of\ngenerated BRTs by integrating them with an Automated Program Repair (APR)\nsystem at Google. Our results show that providing BRTs to the APR system\nresults in 30% more bugs with plausible fixes. Additionally, we introduce\nEnsemble Pass Rate (EPR), a metric which leverages the generated BRTs to select\nthe most promising fixes from all fixes generated by APR system. Our evaluation\non EPR for Top-K and threshold-based fix selections demonstrates promising\nresults and trade-offs. For example, EPR correctly selects a plausible fix from\na pool of 20 candidates in 70% of cases, based on its top-1 ranking.\n","authors":["Runxiang Cheng","Michele Tufano","Jürgen Cito","José Cambronero","Pat Rondon","Renyao Wei","Aaron Sun","Satish Chandra"],"pdf_url":"https://arxiv.org/pdf/2502.01821v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07565v2","updated":"2025-03-11T02:29:42Z","published":"2025-03-10T17:37:39Z","title":"Inductive Moment Matching","summary":"  Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.\n","authors":["Linqi Zhou","Stefano Ermon","Jiaming Song"],"pdf_url":"https://arxiv.org/pdf/2503.07565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06508v2","updated":"2025-03-11T02:28:14Z","published":"2025-03-09T08:28:40Z","title":"LightMotion: A Light and Tuning-free Method for Simulating Camera Motion\n  in Video Generation","summary":"  Existing camera motion-controlled video generation methods face computational\nbottlenecks in fine-tuning and inference. This paper proposes LightMotion, a\nlight and tuning-free method for simulating camera motion in video generation.\nOperating in the latent space, it eliminates additional fine-tuning,\ninpainting, and depth estimation, making it more streamlined than existing\nmethods. The endeavors of this paper comprise: (i) The latent space permutation\noperation effectively simulates various camera motions like panning, zooming,\nand rotation. (ii) The latent space resampling strategy combines\nbackground-aware sampling and cross-frame alignment to accurately fill new\nperspectives while maintaining coherence across frames. (iii) Our in-depth\nanalysis shows that the permutation and resampling cause an SNR shift in latent\nspace, leading to poor-quality generation. To address this, we propose latent\nspace correction, which reintroduces noise during denoising to mitigate SNR\nshift and enhance video generation quality. Exhaustive experiments show that\nour LightMotion outperforms existing methods, both quantitatively and\nqualitatively.\n","authors":["Quanjian Song","Zhihang Lin","Zhanpeng Zeng","Ziyue Zhang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2503.06508v2.pdf","comment":"18 pages in total"},{"id":"http://arxiv.org/abs/2411.02867v2","updated":"2025-03-11T02:25:55Z","published":"2024-11-05T07:16:32Z","title":"AtlasSeg: Atlas Prior Guided Dual-U-Net for Cortical Segmentation in\n  Fetal Brain MRI","summary":"  Accurate automatic tissue segmentation in fetal brain MRI is a crucial step\nin clinical diagnosis but remains challenging, particularly due to the\ndynamically changing anatomy and tissue contrast during fetal development.\nExisting segmentation networks can only implicitly learn age-related features,\nleading to a decline in accuracy at extreme early or late gestational ages\n(GAs). To improve segmentation performance throughout gestation, we introduce\nAtlasSeg, a dual-U-shape convolution network that explicitly integrates\nGA-specific information as guidance. By providing a publicly available fetal\nbrain atlas with segmentation labels corresponding to relevant GAs, AtlasSeg\neffectively extracts age-specific patterns in the atlas branch and generates\nprecise tissue segmentation in the segmentation branch. Multi-scale spatial\nattention feature fusions are constructed during both encoding and decoding\nstages to enhance feature flow and facilitate better information interactions\nbetween two branches. We compared AtlasSeg with six well-established networks\nin a seven-tissue segmentation task, achieving the highest average Dice\nsimilarity coefficient of 0.91. The improvement was particularly evident in\nextreme early or late GA cases, where training data was scare. Furthermore,\nAtlasSeg exhibited minimal performance degradation on low-quality images with\ncontrast changes and noise, attributed to its anatomical shape priors. Overall,\nAtlasSeg demonstrated enhanced segmentation accuracy, better consistency across\nfetal ages, and robustness to perturbations, making it a powerful tool for\nreliable fetal brain MRI tissue segmentation, particularly suited for\ndiagnostic assessments during early gestation.\n","authors":["Haoan Xu","Tianshu Zheng","Xinyi Xu","Yao Shen","Jiwei Sun","Cong Sun","Guangbin Wang","Zhaopeng Cui","Dan Wu"],"pdf_url":"https://arxiv.org/pdf/2411.02867v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05331v2","updated":"2025-03-11T02:16:12Z","published":"2024-10-06T01:13:49Z","title":"Taylor Unswift: Secured Weight Release for Large Language Models via\n  Taylor Expansion","summary":"  Ensuring the security of released large language models (LLMs) poses a\nsignificant dilemma, as existing mechanisms either compromise ownership rights\nor raise data privacy concerns. To address this dilemma, we introduce TaylorMLP\nto protect the ownership of released LLMs and prevent their abuse.\nSpecifically, TaylorMLP preserves the ownership of LLMs by transforming the\nweights of LLMs into parameters of Taylor-series. Instead of releasing the\noriginal weights, developers can release the Taylor-series parameters with\nusers, thereby ensuring the security of LLMs. Moreover, TaylorMLP can prevent\nabuse of LLMs by adjusting the generation speed. It can induce low-speed token\ngeneration for the protected LLMs by increasing the terms in the Taylor-series.\nThis intentional delay helps LLM developers prevent potential large-scale\nunauthorized uses of their models. Empirical experiments across five datasets\nand three LLM architectures demonstrate that TaylorMLP induces over 4x increase\nin latency, producing the tokens precisely matched with original LLMs.\nSubsequent defensive experiments further confirm that TaylorMLP effectively\nprevents users from reconstructing the weight values based on downstream\ndatasets.\n","authors":["Guanchu Wang","Yu-Neng Chuang","Ruixiang Tang","Shaochen Zhong","Jiayi Yuan","Hongye Jin","Zirui Liu","Vipin Chaudhary","Shuai Xu","James Caverlee","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2410.05331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12496v3","updated":"2025-03-11T02:13:04Z","published":"2024-12-17T02:56:35Z","title":"Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training","summary":"  Vision Mamba has shown close to state of the art performance on computer\nvision tasks, drawing much interest in increasing it's efficiency. A promising\napproach is token reduction (that has been successfully implemented in ViTs).\nPruning informative tokens in Mamba leads to a high loss of key knowledge and\ndegraded performance. An alternative, of merging tokens preserves more\ninformation than pruning, also suffers for large compression ratios. Our key\ninsight is that a quick round of retraining after token merging yeilds robust\nresults across various compression ratios. Empirically, pruned Vims only drop\nup to 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo\nin our main evaluation. We show how simple and effective the fast recovery can\nbe achieved at minute-level, in particular, a 35.9% accuracy spike over 3\nepochs of training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17\nminutes, and Vim-S only drops 1.3% with 1.2x (up to 1.5x) speed up in\ninference.\n","authors":["Mingjia Shi","Yuhao Zhou","Ruiji Yu","Zekai Li","Zhiyuan Liang","Xuanlei Zhao","Xiaojiang Peng","Shanmukha Ramakrishna Vedantam","Wangbo Zhao","Kai Wang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2412.12496v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04784v2","updated":"2025-03-11T01:59:26Z","published":"2025-02-27T01:56:09Z","title":"KunlunBaize: LLM with Multi-Scale Convolution and Multi-Token Prediction\n  Under TransformerX Framework","summary":"  Large language models have demonstrated remarkable performance across various\ntasks, yet they face challenges such as low computational efficiency, gradient\nvanishing, and difficulties in capturing complex feature interactions. To\naddress these limitations, a novel framework has been proposed. This framework\nincorporates a learnable dense residual skip connection mechanism, a\nTransformerX module a transformer based component integrating multiscale\nconvolution and adaptive activation functions and a multitoken prediction\ninteraction module. The learnable dense residual connections enhance\ninformation flow and feature capture across layers. Within the TransformerX\nmodule, large convolutional kernels aggregate semantic information from\nextensive text segments, while smaller convolutions focus on local word order\nand syntactic structures. The adaptive activation function dynamically adjusts\nits parameters based on the semantic features of the input text, improving the\nmodel's ability to handle diverse semantic expressions and complex\nrelationships. The multitoken prediction module boosts data utilization and\naccelerates inference by predicting multiple future tokens. These components\nsignificantly enhance the performance and efficiency of large language models.\n","authors":["Cheng Li","Jiexiong Liu","Yixuan Chen","Yanqin Jia","Zhepeng Li"],"pdf_url":"https://arxiv.org/pdf/2503.04784v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2409.20503v2","updated":"2025-03-11T01:55:49Z","published":"2024-09-30T17:03:13Z","title":"What Information Contributes to Log-based Anomaly Detection? Insights\n  from a Configurable Transformer-Based Approach","summary":"  Log data are generated from logging statements in the source code, providing\ninsights into the execution processes of software applications and systems.\nState-of-the-art log-based anomaly detection approaches typically leverage deep\nlearning models to capture the semantic or sequential information in the log\ndata and detect anomalous runtime behaviors. However, the impacts of these\ndifferent types of information are not clear. In addition, most existing\napproaches ignore the timestamps in log data, which can potentially provide\nfine-grained sequential and temporal information. In this work, we propose a\nconfigurable Transformer-based anomaly detection model that can capture the\nsemantic, sequential, and temporal information in the log data and allows us to\nconfigure the different types of information as the model's features.\nAdditionally, we train and evaluate the proposed model using log sequences of\ndifferent lengths, thus overcoming the constraint of existing methods that rely\non fixed-length or time-windowed log sequences as inputs. With the proposed\nmodel, we conduct a series of experiments with different combinations of input\nfeatures to evaluate the roles of different types of information in anomaly\ndetection. The model can attain competitive and consistently stable performance\ncompared to the baselines when presented with log sequences of varying lengths.\nThe results indicate that the event occurrence information plays a key role in\nidentifying anomalies, while the impact of the sequential and temporal\ninformation is not significant for anomaly detection on the studied public\ndatasets. On the other hand, the findings also reveal the simplicity of the\nstudied public datasets and highlight the importance of constructing new\ndatasets that contain different types of anomalies to better evaluate the\nperformance of anomaly detection models.\n","authors":["Xingfang Wu","Heng Li","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2409.20503v2.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2503.07963v1","updated":"2025-03-11T01:40:23Z","published":"2025-03-11T01:40:23Z","title":"Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal\n  Manipulation using Tight Convex Relaxations","summary":"  Designing trajectories for manipulation through contact is challenging as it\nrequires reasoning of object \\& robot trajectories as well as complex contact\nsequences simultaneously. In this paper, we present a novel framework for\nsimultaneously designing trajectories of robots, objects, and contacts\nefficiently for contact-rich manipulation. We propose a hierarchical\noptimization framework where Mixed-Integer Linear Program (MILP) selects\noptimal contacts between robot \\& object using approximate dynamical\nconstraints, and then a NonLinear Program (NLP) optimizes trajectory of the\nrobot(s) and object considering full nonlinear constraints. We present a convex\nrelaxation of bilinear constraints using binary encoding technique such that\nMILP can provide tighter solutions with better computational complexity. The\nproposed framework is evaluated on various manipulation tasks where it can\nreason about complex multi-contact interactions while providing computational\nadvantages. We also demonstrate our framework in hardware experiments using a\nbimanual robot system.\n","authors":["Yuki Shirai","Arvind Raghunathan","Devesh K. Jha"],"pdf_url":"https://arxiv.org/pdf/2503.07963v1.pdf","comment":"2025 IEEE International Conference on Robotics and Automation (2025\n  ICRA)"},{"id":"http://arxiv.org/abs/2503.07956v1","updated":"2025-03-11T01:34:03Z","published":"2025-03-11T01:34:03Z","title":"EFPC: Towards Efficient and Flexible Prompt Compression","summary":"  The emergence of large language models (LLMs) like GPT-4 has revolutionized\nnatural language processing (NLP), enabling diverse, complex tasks. However,\nextensive token counts lead to high computational and financial burdens. To\naddress this, we propose Efficient and Flexible Prompt Compression (EFPC), a\nnovel method unifying task-aware and task-agnostic compression for a favorable\naccuracy-efficiency trade-off. EFPC uses GPT-4 to generate compressed prompts\nand integrates them with original prompts for training. During training and\ninference, we selectively prepend user instructions and compress prompts based\non predicted probabilities. EFPC is highly data-efficient, achieving\nsignificant performance with minimal data. Compared to the state-of-the-art\nmethod LLMLingua-2, EFPC achieves a 4.8% relative improvement in F1-score with\n1% additional data at a 4x compression rate, and an 11.4% gain with 10%\nadditional data on the LongBench single-doc QA benchmark. EFPC's unified\nframework supports broad applicability and enhances performance across various\nmodels, tasks, and domains, offering a practical advancement in NLP.\n","authors":["Yun-Hao Cao","Yangsong Wang","Shuzheng Hao","Zhenxing Li","Chengjun Zhan","Sichao Liu","Yi-Qi Hu"],"pdf_url":"https://arxiv.org/pdf/2503.07956v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2208.13687v2","updated":"2025-03-11T01:24:01Z","published":"2022-08-29T15:51:36Z","title":"Categorical semantics of compositional reinforcement learning","summary":"  Compositional knowledge representations in reinforcement learning (RL)\nfacilitate modular, interpretable, and safe task specifications. However,\ngenerating compositional models requires the characterization of minimal\nassumptions for the robustness of the compositionality feature, especially in\nthe case of functional decompositions. Using a categorical point of view, we\ndevelop a knowledge representation framework for a compositional theory of RL.\nOur approach relies on the theoretical study of the category $\\mathsf{MDP}$,\nwhose objects are Markov decision processes (MDPs) acting as models of tasks.\nThe categorical semantics models the compositionality of tasks through the\napplication of pushout operations akin to combining puzzle pieces. As a\npractical application of these pushout operations, we introduce zig-zag\ndiagrams that rely on the compositional guarantees engendered by the category\n$\\mathsf{MDP}$. We further prove that properties of the category $\\mathsf{MDP}$\nunify concepts, such as enforcing safety requirements and exploiting\nsymmetries, generalizing previous abstraction theories for RL.\n","authors":["Georgios Bakirtzis","Michail Savvas","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2208.13687v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07946v1","updated":"2025-03-11T01:16:08Z","published":"2025-03-11T01:16:08Z","title":"7DGS: Unified Spatial-Temporal-Angular Gaussian Splatting","summary":"  Real-time rendering of dynamic scenes with view-dependent effects remains a\nfundamental challenge in computer graphics. While recent advances in Gaussian\nSplatting have shown promising results separately handling dynamic scenes\n(4DGS) and view-dependent effects (6DGS), no existing method unifies these\ncapabilities while maintaining real-time performance. We present 7D Gaussian\nSplatting (7DGS), a unified framework representing scene elements as\nseven-dimensional Gaussians spanning position (3D), time (1D), and viewing\ndirection (3D). Our key contribution is an efficient conditional slicing\nmechanism that transforms 7D Gaussians into view- and time-conditioned 3D\nGaussians, maintaining compatibility with existing 3D Gaussian Splatting\npipelines while enabling joint optimization. Experiments demonstrate that 7DGS\noutperforms prior methods by up to 7.36 dB in PSNR while achieving real-time\nrendering (401 FPS) on challenging dynamic scenes with complex view-dependent\neffects. The project page is: https://gaozhongpai.github.io/7dgs/.\n","authors":["Zhongpai Gao","Benjamin Planche","Meng Zheng","Anwesa Choudhuri","Terrence Chen","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.07946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04974v3","updated":"2025-03-11T00:47:21Z","published":"2024-10-07T12:16:36Z","title":"6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric\n  Rendering","summary":"  Novel view synthesis has advanced significantly with the development of\nneural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,\nachieving high quality without compromising real-time rendering remains\nchallenging, particularly for physically-based ray tracing with view-dependent\neffects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D\nspatial-angular representation to better incorporate view-dependent effects,\nbut the Gaussian representation and control scheme are sub-optimal. In this\npaper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),\nwhich enhances color and opacity representations and leverages the additional\ndirectional information in the 6D space for optimized Gaussian control. Our\napproach is fully compatible with the 3DGS framework and significantly improves\nreal-time radiance field rendering by better modeling view-dependent effects\nand fine details. Experiments demonstrate that 6DGS significantly outperforms\n3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction\nof 66.5% Gaussian points compared to 3DGS. The project page is:\nhttps://gaozhongpai.github.io/6dgs/\n","authors":["Zhongpai Gao","Benjamin Planche","Meng Zheng","Anwesa Choudhuri","Terrence Chen","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.04974v3.pdf","comment":"Accepted by ICLR2025"},{"id":"http://arxiv.org/abs/2503.05794v2","updated":"2025-03-11T00:44:01Z","published":"2025-03-02T02:02:57Z","title":"CBW: Towards Dataset Ownership Verification for Speaker Verification via\n  Clustering-based Backdoor Watermarking","summary":"  With the increasing adoption of deep learning in speaker verification,\nlarge-scale speech datasets have become valuable intellectual property. To\naudit and prevent the unauthorized usage of these valuable released datasets,\nespecially in commercial or open-source scenarios, we propose a novel dataset\nownership verification method. Our approach introduces a clustering-based\nbackdoor watermark (CBW), enabling dataset owners to determine whether a\nsuspicious third-party model has been trained on a protected dataset under a\nblack-box setting. The CBW method consists of two key stages: dataset\nwatermarking and ownership verification. During watermarking, we implant\nmultiple trigger patterns in the dataset to make similar samples (measured by\ntheir feature similarities) close to the same trigger while dissimilar samples\nare near different triggers. This ensures that any model trained on the\nwatermarked dataset exhibits specific misclassification behaviors when exposed\nto trigger-embedded inputs. To verify dataset ownership, we design a\nhypothesis-test-based framework that statistically evaluates whether a\nsuspicious model exhibits the expected backdoor behavior. We conduct extensive\nexperiments on benchmark datasets, verifying the effectiveness and robustness\nof our method against potential adaptive attacks. The code for reproducing main\nexperiments is available at https://github.com/Radiant0726/CBW\n","authors":["Yiming Li","Kaiying Yan","Shuo Shao","Tongqing Zhai","Shu-Tao Xia","Zhan Qin","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2503.05794v2.pdf","comment":"14 pages. The journal extension of our ICASSP'21 paper\n  (arXiv:2010.11607)"},{"id":"http://arxiv.org/abs/2502.12371v2","updated":"2025-03-11T00:38:28Z","published":"2025-02-17T23:22:49Z","title":"IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via\n  Implicit Maximum Likelihood Estimation","summary":"  Recent advances in imitation learning, particularly using generative\nmodelling techniques like diffusion, have enabled policies to capture complex\nmulti-modal action distributions. However, these methods often require large\ndatasets and multiple inference steps for action generation, posing challenges\nin robotics where the cost for data collection is high and computation\nresources are limited. To address this, we introduce IMLE Policy, a novel\nbehaviour cloning approach based on Implicit Maximum Likelihood Estimation\n(IMLE). IMLE Policy excels in low-data regimes, effectively learning from\nminimal demonstrations and requiring 38\\% less data on average to match the\nperformance of baseline methods in learning complex multi-modal behaviours. Its\nsimple generator-based architecture enables single-step action generation,\nimproving inference speed by 97.3\\% compared to Diffusion Policy, while\noutperforming single-step Flow Matching. We validate our approach across\ndiverse manipulation tasks in simulated and real-world environments, showcasing\nits ability to capture complex behaviours under data constraints. Videos and\ncode are provided on our project page: https://imle-policy.github.io/.\n","authors":["Krishan Rana","Robert Lee","David Pershouse","Niko Suenderhauf"],"pdf_url":"https://arxiv.org/pdf/2502.12371v2.pdf","comment":"Videos and code are available at https://imle-policy.github.io/"},{"id":"http://arxiv.org/abs/2503.07937v1","updated":"2025-03-11T00:29:50Z","published":"2025-03-11T00:29:50Z","title":"LLM-based Corroborating and Refuting Evidence Retrieval for Scientific\n  Claim Verification","summary":"  In this paper, we introduce CIBER (Claim Investigation Based on Evidence\nRetrieval), an extension of the Retrieval-Augmented Generation (RAG) framework\ndesigned to identify corroborating and refuting documents as evidence for\nscientific claim verification. CIBER addresses the inherent uncertainty in\nLarge Language Models (LLMs) by evaluating response consistency across diverse\ninterrogation probes. By focusing on the behavioral analysis of LLMs without\nrequiring access to their internal information, CIBER is applicable to both\nwhite-box and black-box models. Furthermore, CIBER operates in an unsupervised\nmanner, enabling easy generalization across various scientific domains.\nComprehensive evaluations conducted using LLMs with varying levels of\nlinguistic proficiency reveal CIBER's superior performance compared to\nconventional RAG approaches. These findings not only highlight the\neffectiveness of CIBER but also provide valuable insights for future\nadvancements in LLM-based scientific claim verification.\n","authors":["Siyuan Wang","James R. Foulds","Md Osman Gani","Shimei Pan"],"pdf_url":"https://arxiv.org/pdf/2503.07937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07932v1","updated":"2025-03-11T00:21:32Z","published":"2025-03-11T00:21:32Z","title":"A Theory of Learning with Autoregressive Chain of Thought","summary":"  For a given base class of sequence-to-next-token generators, we consider\nlearning prompt-to-answer mappings obtained by iterating a fixed,\ntime-invariant generator for multiple steps, thus generating a\nchain-of-thought, and then taking the final token as the answer. We formalize\nthe learning problems both when the chain-of-thought is observed and when\ntraining only on prompt-answer pairs, with the chain-of-thought latent. We\nanalyze the sample and computational complexity both in terms of general\nproperties of the base class (e.g. its VC dimension) and for specific base\nclasses such as linear thresholds. We present a simple base class that allows\nfor universal representability and computationally tractable chain-of-thought\nlearning. Central to our development is that time invariance allows for sample\ncomplexity that is independent of the length of the chain-of-thought. Attention\narises naturally in our construction.\n","authors":["Nirmit Joshi","Gal Vardi","Adam Block","Surbhi Goel","Zhiyuan Li","Theodor Misiakiewicz","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2503.07932v1.pdf","comment":"Comments are welcome"},{"id":"http://arxiv.org/abs/2503.07928v1","updated":"2025-03-11T00:17:07Z","published":"2025-03-11T00:17:07Z","title":"The StudyChat Dataset: Student Dialogues With ChatGPT in an Artificial\n  Intelligence Course","summary":"  The widespread availability of large language models (LLMs), such as ChatGPT,\nhas significantly impacted education, raising both opportunities and\nchallenges. Students can frequently interact with LLM-powered, interactive\nlearning tools, but their usage patterns need to be analyzed to ensure ethical\nusage of these tools. To better understand how students interact with LLMs in\nan academic setting, we introduce \\textbf{StudyChat}, a publicly available\ndataset capturing real-world student interactions with an LLM-powered tutoring\nchatbot in a semester-long, university-level artificial intelligence (AI)\ncourse. We deploy a web application that replicates ChatGPT's core\nfunctionalities, and use it to log student interactions with the LLM while\nworking on programming assignments. We collect 1,197 conversations, which we\nannotate using a dialogue act labeling schema inspired by observed interaction\npatterns and prior research. Additionally, we analyze these interactions,\nhighlight behavioral trends, and analyze how specific usage patterns relate to\ncourse outcomes. \\textbf{StudyChat} provides a rich resource for the learning\nsciences and AI in education communities, enabling further research into the\nevolving role of LLMs in education.\n","authors":["Hunter McNichols","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2503.07928v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2403.15604v2","updated":"2025-03-11T23:56:15Z","published":"2024-03-22T20:16:55Z","title":"Investigating Use Cases of AI-Powered Scene Description Applications for\n  Blind and Low Vision People","summary":"  \"Scene description\" applications that describe visual content in a photo are\nuseful daily tools for blind and low vision (BLV) people. Researchers have\nstudied their use, but they have only explored those that leverage remote\nsighted assistants; little is known about applications that use AI to generate\ntheir descriptions. Thus, to investigate their use cases, we conducted a\ntwo-week diary study where 16 BLV participants used an AI-powered scene\ndescription application we designed. Through their diary entries and follow-up\ninterviews, users shared their information goals and assessments of the visual\ndescriptions they received. We analyzed the entries and found frequent use\ncases, such as identifying visual features of known objects, and surprising\nones, such as avoiding contact with dangerous objects. We also found users\nscored the descriptions relatively low on average, 2.76 out of 5 (SD=1.49) for\nsatisfaction and 2.43 out of 4 (SD=1.16) for trust, showing that descriptions\nstill need significant improvements to deliver satisfying and trustworthy\nexperiences. We discuss future opportunities for AI as it becomes a more\npowerful accessibility tool for BLV users.\n","authors":["Ricardo Gonzalez","Jazmin Collins","Shiri Azenkot","Cynthia Bennett"],"pdf_url":"https://arxiv.org/pdf/2403.15604v2.pdf","comment":"21 pages, 18 figures, 5 tables, main track CHI 2024"},{"id":"http://arxiv.org/abs/2410.20666v2","updated":"2025-03-11T23:45:58Z","published":"2024-10-28T01:58:21Z","title":"Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for\n  Robotic Guidance of People with Visual Impairments","summary":"  Navigation presents a significant challenge for persons with visual\nimpairments (PVI). While traditional aids such as white canes and guide dogs\nare invaluable, they fall short in delivering detailed spatial information and\nprecise guidance to desired locations. Recent developments in large language\nmodels (LLMs) and vision-language models (VLMs) offer new avenues for enhancing\nassistive navigation. In this paper, we introduce Guide-LLM, an embodied\nLLM-based agent designed to assist PVI in navigating large indoor environments.\nOur approach features a novel text-based topological map that enables the LLM\nto plan global paths using a simplified environmental representation, focusing\non straight paths and right-angle turns to facilitate navigation. Additionally,\nwe utilize the LLM's commonsense reasoning for hazard detection and\npersonalized path planning based on user preferences. Simulated experiments\ndemonstrate the system's efficacy in guiding PVI, underscoring its potential as\na significant advancement in assistive technology. The results highlight\nGuide-LLM's ability to offer efficient, adaptive, and personalized navigation\nassistance, pointing to promising advancements in this field.\n","authors":["Sangmim Song","Sarath Kodagoda","Amal Gunatilake","Marc G. Carmichael","Karthick Thiyagarajan","Jodi Martin"],"pdf_url":"https://arxiv.org/pdf/2410.20666v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08960v1","updated":"2025-03-11T23:37:18Z","published":"2025-03-11T23:37:18Z","title":"Are ECGs enough? Deep learning classification of cardiac anomalies using\n  only electrocardiograms","summary":"  Electrocardiography (ECG) is an essential tool for diagnosing multiple\ncardiac anomalies: it provides valuable clinical insights, while being\naffordable, fast and available in many settings. However, in the current\nliterature, the role of ECG analysis is often unclear: many approaches either\nrely on additional imaging modalities, such as Computed Tomography Pulmonary\nAngiography (CTPA), which may not always be available, or do not effectively\ngeneralize across different classification problems. Furthermore, the\navailability of public ECG datasets is limited and, in practice, these datasets\ntend to be small, making it essential to optimize learning strategies. In this\nstudy, we investigate the performance of multiple neural network architectures\nin order to assess the impact of various approaches. Moreover, we check whether\nthese practices enhance model generalization when transfer learning is used to\ntranslate information learned in larger ECG datasets, such as PTB-XL and\nCPSC18, to a smaller, more challenging dataset for pulmonary embolism (PE)\ndetection. By leveraging transfer learning, we analyze the extent to which we\ncan improve learning efficiency and predictive performance on limited data.\nCode available at\nhttps://github.com/joaodsmarques/Are-ECGs-enough-Deep-Learning-Classifiers .\n","authors":["Joao D. S. Marques","Arlindo L. Oliveira"],"pdf_url":"https://arxiv.org/pdf/2503.08960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08950v1","updated":"2025-03-11T23:01:08Z","published":"2025-03-11T23:01:08Z","title":"FP3: A 3D Foundation Policy for Robotic Manipulation","summary":"  Following its success in natural language processing and computer vision,\nfoundation models that are pre-trained on large-scale multi-task datasets have\nalso shown great potential in robotics. However, most existing robot foundation\nmodels rely solely on 2D image observations, ignoring 3D geometric information,\nwhich is essential for robots to perceive and reason about the 3D world. In\nthis paper, we introduce FP3, a first large-scale 3D foundation policy model\nfor robotic manipulation. FP3 builds on a scalable diffusion transformer\narchitecture and is pre-trained on 60k trajectories with point cloud\nobservations. With the model design and diverse pre-training data, FP3 can be\nefficiently fine-tuned for downstream tasks while exhibiting strong\ngeneralization capabilities. Experiments on real robots demonstrate that with\nonly 80 demonstrations, FP3 is able to learn a new task with over 90% success\nrates in novel environments with unseen objects, significantly surpassing\nexisting robot foundation models.\n","authors":["Rujia Yang","Geng Chen","Chuan Wen","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2503.08950v1.pdf","comment":"Project website: https://3d-foundation-policy.github.io"},{"id":"http://arxiv.org/abs/2503.08939v1","updated":"2025-03-11T22:41:22Z","published":"2025-03-11T22:41:22Z","title":"KAN-Mixers: a new deep learning architecture for image classification","summary":"  Due to their effective performance, Convolutional Neural Network (CNN) and\nVision Transformer (ViT) architectures have become the standard for solving\ncomputer vision tasks. Such architectures require large data sets and rely on\nconvolution and self-attention operations. In 2021, MLP-Mixer emerged, an\narchitecture that relies only on Multilayer Perceptron (MLP) and achieves\nextremely competitive results when compared to CNNs and ViTs. Despite its good\nperformance in computer vision tasks, the MLP-Mixer architecture may not be\nsuitable for refined feature extraction in images. Recently, the\nKolmogorov-Arnold Network (KAN) was proposed as a promising alternative to MLP\nmodels. KANs promise to improve accuracy and interpretability when compared to\nMLPs. Therefore, the present work aims to design a new mixer-based\narchitecture, called KAN-Mixers, using KANs as main layers and evaluate its\nperformance, in terms of several performance metrics, in the image\nclassification task. As main results obtained, the KAN-Mixers model was\nsuperior to the MLP, MLP-Mixer and KAN models in the Fashion-MNIST and CIFAR-10\ndatasets, with 0.9030 and 0.6980 of average accuracy, respectively.\n","authors":["Jorge Luiz dos Santos Canuto","Linnyer Beatrys Ruiz Aylon","Rodrigo Clemente Thom de Souza"],"pdf_url":"https://arxiv.org/pdf/2503.08939v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.08936v1","updated":"2025-03-11T22:34:14Z","published":"2025-03-11T22:34:14Z","title":"Simulator Ensembles for Trustworthy Autonomous Driving Testing","summary":"  Scenario-based testing with driving simulators is extensively used to\nidentify failing conditions of automated driving assistance systems (ADAS) and\nreduce the amount of in-field road testing. However, existing studies have\nshown that repeated test execution in the same as well as in distinct\nsimulators can yield different outcomes, which can be attributed to sources of\nflakiness or different implementations of the physics, among other factors. In\nthis paper, we present MultiSim, a novel approach to multi-simulation ADAS\ntesting based on a search-based testing approach that leverages an ensemble of\nsimulators to identify failure-inducing, simulator-agnostic test scenarios.\nDuring the search, each scenario is evaluated jointly on multiple simulators.\nScenarios that produce consistent results across simulators are prioritized for\nfurther exploration, while those that fail on only a subset of simulators are\ngiven less priority, as they may reflect simulator-specific issues rather than\ngeneralizable failures. Our case study, which involves testing a deep neural\nnetwork-based ADAS on different pairs of three widely used simulators,\ndemonstrates that MultiSim outperforms single-simulator testing by achieving on\naverage a higher rate of simulator-agnostic failures by 51%. Compared to a\nstate-of-the-art multi-simulator approach that combines the outcome of\nindependent test generation campaigns obtained in different simulators,\nMultiSim identifies 54% more simulator-agnostic failing tests while showing a\ncomparable validity rate. An enhancement of MultiSim that leverages surrogate\nmodels to predict simulator disagreements and bypass executions does not only\nincrease the average number of valid failures but also improves efficiency in\nfinding the first valid failure.\n","authors":["Lev Sorokin","Matteo Biagiola","Andrea Stocco"],"pdf_url":"https://arxiv.org/pdf/2503.08936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08929v1","updated":"2025-03-11T22:18:51Z","published":"2025-03-11T22:18:51Z","title":"HessianForge: Scalable LiDAR reconstruction with Physics-Informed Neural\n  Representation and Smoothness Energy Constraints","summary":"  Accurate and efficient 3D mapping of large-scale outdoor environments from\nLiDAR measurements is a fundamental challenge in robotics, particularly towards\nensuring smooth and artifact-free surface reconstructions. Although the\nstate-of-the-art methods focus on memory-efficient neural representations for\nhigh-fidelity surface generation, they often fail to produce artifact-free\nmanifolds, with artifacts arising due to noisy and sparse inputs. To address\nthis issue, we frame surface mapping as a physics-informed energy optimization\nproblem, enforcing surface smoothness by optimizing an energy functional that\npenalizes sharp surface ridges. Specifically, we propose a deep learning based\napproach that learns the signed distance field (SDF) of the surface manifold\nfrom raw LiDAR point clouds using a physics-informed loss function that\noptimizes the $L_2$-Hessian energy of the surface. Our learning framework\nincludes a hierarchical octree based input feature encoding and a multi-scale\nneural network to iteratively refine the signed distance field at different\nscales of resolution. Lastly, we introduce a test-time refinement strategy to\ncorrect topological inconsistencies and edge distortions that can arise in the\ngenerated mesh. We propose a \\texttt{CUDA}-accelerated least-squares\noptimization that locally adjusts vertex positions to enforce\nfeature-preserving smoothing. We evaluate our approach on large-scale outdoor\ndatasets and demonstrate that our approach outperforms current state-of-the-art\nmethods in terms of improved accuracy and smoothness. Our code is available at\n\\href{https://github.com/HrishikeshVish/HessianForge/}{https://github.com/HrishikeshVish/HessianForge/}\n","authors":["Hrishikesh Viswanath","Md Ashiqur Rahman","Chi Lin","Damon Conover","Aniket Bera"],"pdf_url":"https://arxiv.org/pdf/2503.08929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08919v1","updated":"2025-03-11T22:04:22Z","published":"2025-03-11T22:04:22Z","title":"Backtracking for Safety","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, but ensuring their safety and alignment with human values\nremains crucial. Current safety alignment methods, such as supervised\nfine-tuning and reinforcement learning-based approaches, can exhibit\nvulnerabilities to adversarial attacks and often result in shallow safety\nalignment, primarily focusing on preventing harmful content in the initial\ntokens of the generated output. While methods like resetting can help recover\nfrom unsafe generations by discarding previous tokens and restarting the\ngeneration process, they are not well-suited for addressing nuanced safety\nviolations like toxicity that may arise within otherwise benign and lengthy\ngenerations. In this paper, we propose a novel backtracking method designed to\naddress these limitations. Our method allows the model to revert to a safer\ngeneration state, not necessarily at the beginning, when safety violations\noccur during generation. This approach enables targeted correction of\nproblematic segments without discarding the entire generated text, thereby\npreserving efficiency. We demonstrate that our method dramatically reduces\ntoxicity appearing through the generation process with minimal impact to\nefficiency.\n","authors":["Bilgehan Sel","Dingcheng Li","Phillip Wallis","Vaishakh Keshava","Ming Jin","Siddhartha Reddy Jonnalagadda"],"pdf_url":"https://arxiv.org/pdf/2503.08919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14572v2","updated":"2025-03-11T22:03:26Z","published":"2024-09-22T19:31:16Z","title":"Evaluating the Performance and Robustness of LLMs in Materials Science\n  Q&A and Property Predictions","summary":"  Large Language Models (LLMs) have the potential to revolutionize scientific\nresearch, yet their robustness and reliability in domain-specific applications\nremain insufficiently explored. In this study, we evaluate the performance and\nrobustness of LLMs for materials science, focusing on domain-specific question\nanswering and materials property prediction across diverse real-world and\nadversarial conditions. Three distinct datasets are used in this study: 1) a\nset of multiple-choice questions from undergraduate-level materials science\ncourses, 2) a dataset including various steel compositions and yield strengths,\nand 3) a band gap dataset, containing textual descriptions of material crystal\nstructures and band gap values. The performance of LLMs is assessed using\nvarious prompting strategies, including zero-shot chain-of-thought, expert\nprompting, and few-shot in-context learning. The robustness of these models is\ntested against various forms of 'noise', ranging from realistic disturbances to\nintentionally adversarial manipulations, to evaluate their resilience and\nreliability under real-world conditions. Additionally, the study showcases\nunique phenomena of LLMs during predictive tasks, such as mode collapse\nbehavior when the proximity of prompt examples is altered and performance\nrecovery from train/test mismatch. The findings aim to provide informed\nskepticism for the broad use of LLMs in materials science and to inspire\nadvancements that enhance their robustness and reliability for practical\napplications.\n","authors":["Hongchen Wang","Kangming Li","Scott Ramsay","Yao Fehlis","Edward Kim","Jason Hattrick-Simpers"],"pdf_url":"https://arxiv.org/pdf/2409.14572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13376v3","updated":"2025-03-11T22:01:33Z","published":"2024-08-23T21:23:22Z","title":"Reduce, Reuse, Recycle: Categories for Compositional Reinforcement\n  Learning","summary":"  In reinforcement learning, conducting task composition by forming cohesive,\nexecutable sequences from multiple tasks remains challenging. However, the\nability to (de)compose tasks is a linchpin in developing robotic systems\ncapable of learning complex behaviors. Yet, compositional reinforcement\nlearning is beset with difficulties, including the high dimensionality of the\nproblem space, scarcity of rewards, and absence of system robustness after task\ncomposition. To surmount these challenges, we view task composition through the\nprism of category theory -- a mathematical discipline exploring structures and\ntheir compositional relationships. The categorical properties of Markov\ndecision processes untangle complex tasks into manageable sub-tasks, allowing\nfor strategical reduction of dimensionality, facilitating more tractable reward\nstructures, and bolstering system robustness. Experimental results support the\ncategorical theory of reinforcement learning by enabling skill reduction,\nreuse, and recycling when learning complex robotic arm tasks.\n","authors":["Georgios Bakirtzis","Michail Savvas","Ruihan Zhao","Sandeep Chinchali","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2408.13376v3.pdf","comment":"ECAI 2024"},{"id":"http://arxiv.org/abs/2503.08916v1","updated":"2025-03-11T21:55:46Z","published":"2025-03-11T21:55:46Z","title":"Robust Unsupervised Fault Diagnosis For High-Dimensional Nonlinear Noisy\n  Data","summary":"  Traditional fault diagnosis methods struggle to handle fault data, with\ncomplex data characteristics such as high dimensions and large noise. Deep\nlearning is a promising solution, which typically works well only when labeled\nfault data are available. To address these problems, a robust unsupervised\nfault diagnosis using machine learning is proposed in this paper. First, a\nspecial dimension reduction method for the high-dimensional fault data is\ndesigned. Second, the extracted features are enhanced by incorporating\nnonlinear information through the learning of a graph structure. Third, to\nalleviate the problem of reduced fault-diagnosis accuracy attributed to noise\nand outliers, $l_{2,1}$-norm and typicality-aware constraints are introduced\nfrom the perspective of model optimization, respectively. Finally, this paper\nprovides comprehensive theoretical and experimental evidence supporting the\neffectiveness and robustness of the proposed method. The experiments on both\nthe benchmark Tennessee-Eastman process and a real hot-steel milling process\nshow that the proposed method exhibits better robustness compared to other\nmethods, maintaining high diagnostic accuracy even in the presence of outliers\nor noise.\n","authors":["Dandan Zhao","Hongpeng Yin","Jintang Bian","Han Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.08916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16359v2","updated":"2025-03-11T21:41:19Z","published":"2024-12-20T21:43:52Z","title":"Human-Readable Adversarial Prompts: An Investigation into LLM\n  Vulnerabilities Using Situational Context","summary":"  Previous studies that uncovered vulnerabilities in large language models\n(LLMs) frequently employed nonsensical adversarial prompts. However, such\nprompts can now be readily identified using automated detection techniques. To\nfurther strengthen adversarial attacks, we focus on human-readable adversarial\nprompts, which are more realistic and potent threats. Our key contributions are\n(1) situation-driven attacks leveraging movie scripts as context to create\nhuman-readable prompts that successfully deceive LLMs, (2) adversarial suffix\nconversion to transform nonsensical adversarial suffixes into independent\nmeaningful text, and (3) AdvPrompter with p-nucleus sampling, a method to\ngenerate diverse, human-readable adversarial suffixes, improving attack\nefficacy in models like GPT-3.5 and Gemma 7B.\n","authors":["Nilanjana Das","Edward Raff","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2412.16359v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.14644"},{"id":"http://arxiv.org/abs/2503.08908v1","updated":"2025-03-11T21:40:58Z","published":"2025-03-11T21:40:58Z","title":"Interpreting the Repeated Token Phenomenon in Large Language Models","summary":"  Large Language Models (LLMs), despite their impressive capabilities, often\nfail to accurately repeat a single word when prompted to, and instead output\nunrelated text. This unexplained failure mode represents a vulnerability,\nallowing even end-users to diverge models away from their intended behavior. We\naim to explain the causes for this phenomenon and link it to the concept of\n``attention sinks'', an emergent LLM behavior crucial for fluency, in which the\ninitial token receives disproportionately high attention scores. Our\ninvestigation identifies the neural circuit responsible for attention sinks and\nshows how long repetitions disrupt this circuit. We extend this finding to\nother non-repeating sequences that exhibit similar circuit disruptions. To\naddress this, we propose a targeted patch that effectively resolves the issue\nwithout negatively impacting the model's overall performance. This study\nprovides a mechanistic explanation for an LLM vulnerability, demonstrating how\ninterpretability can diagnose and address issues, and offering insights that\npave the way for more secure and reliable models.\n","authors":["Itay Yona","Ilia Shumailov","Jamie Hayes","Federico Barbero","Yossi Gandelsman"],"pdf_url":"https://arxiv.org/pdf/2503.08908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05641v2","updated":"2025-03-11T21:40:43Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v2.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic-moe.github.io/"},{"id":"http://arxiv.org/abs/2503.08906v1","updated":"2025-03-11T21:38:34Z","published":"2025-03-11T21:38:34Z","title":"Prompt-OT: An Optimal Transport Regularization Paradigm for Knowledge\n  Preservation in Vision-Language Model Adaptation","summary":"  Vision-language models (VLMs) such as CLIP demonstrate strong performance but\nstruggle when adapted to downstream tasks. Prompt learning has emerged as an\nefficient and effective strategy to adapt VLMs while preserving their\npre-trained knowledge. However, existing methods still lead to overfitting and\ndegrade zero-shot generalization. To address this challenge, we propose an\noptimal transport (OT)-guided prompt learning framework that mitigates\nforgetting by preserving the structural consistency of feature distributions\nbetween pre-trained and fine-tuned models. Unlike conventional point-wise\nconstraints, OT naturally captures cross-instance relationships and expands the\nfeasible parameter space for prompt tuning, allowing a better trade-off between\nadaptation and generalization. Our approach enforces joint constraints on both\nvision and text representations, ensuring a holistic feature alignment.\nExtensive experiments on benchmark datasets demonstrate that our simple yet\neffective method can outperform existing prompt learning strategies in\nbase-to-novel generalization, cross-dataset evaluation, and domain\ngeneralization without additional augmentation or ensemble techniques. The code\nis available at https://github.com/ChongQingNoSubway/Prompt-OT\n","authors":["Xiwen Chen","Wenhui Zhu","Peijie Qiu","Hao Wang","Huayu Li","Haiyu Wu","Aristeidis Sotiras","Yalin Wang","Abolfazl Razi"],"pdf_url":"https://arxiv.org/pdf/2503.08906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06277v4","updated":"2025-03-11T21:28:20Z","published":"2024-10-08T18:21:35Z","title":"Solving Functional Optimization with Deep Networks and Variational\n  Principles","summary":"  Can neural networks solve math problems using first a principle alone? This\npaper shows how to leverage the fundamental theorem of the calculus of\nvariations to design deep neural networks to solve functional optimization\nwithout requiring training data (e.g., ground-truth optimal solutions). Our\napproach is particularly crucial when the solution is a function defined over\nan unknown interval or support\\textemdash such as in minimum-time control\nproblems. By incorporating the necessary conditions satisfied by the optimal\nfunction solution, as derived from the calculus of variation, in the design of\nthe deep architecture, CalVNet leverages overparameterized neural networks to\nlearn these optimal functions directly. We validate CalVNet by showing that,\nwithout relying on ground-truth data and simply incorporating first principles,\nit successfully derives the Kalman filter for linear filtering, the bang-bang\noptimal control for minimum-time problems, and finds geodesics on manifolds.\nOur results demonstrate that CalVNet can be trained in an unsupervised manner,\nwithout relying on ground-truth data, establishing a promising framework for\naddressing general, potentially unsolved functional optimization problems that\nstill lack analytical solutions.\n","authors":["Kawisorn Kamtue","Jose M. F. Moura","Orathai Sangpetch"],"pdf_url":"https://arxiv.org/pdf/2410.06277v4.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.00184v4","updated":"2025-03-11T21:11:39Z","published":"2023-07-01T00:58:51Z","title":"Personality Traits in Large Language Models","summary":"  The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling the generation of coherent and contextually\nrelevant human-like text. As LLMs increasingly powerconversational agents used\nby the general public world-wide, the synthetic personality traits embedded in\nthese models, by virtue of training on large amounts of human data, is becoming\nincreasingly important. Since personality is a key factor determining the\neffectiveness of communication, we present a novel and comprehensive\npsychometrically valid and reliable methodology for administering and\nvalidating personality tests on widely-used LLMs, as well as for shaping\npersonality in the generated text of such LLMs. Applying this method to 18\nLLMs, we found: 1) personality measurements in the outputs of some LLMs under\nspecific prompting configurations are reliable and valid; 2) evidence of\nreliability and validity of synthetic LLM personality is stronger for larger\nand instruction fine-tuned models; and 3) personality in LLM outputs can be\nshaped along desired dimensions to mimic specific human personality profiles.\nWe discuss the application and ethical implications of the measurement and\nshaping method, in particular regarding responsible AI.\n","authors":["Greg Serapio-García","Mustafa Safdari","Clément Crepy","Luning Sun","Stephen Fitz","Peter Romero","Marwa Abdulhai","Aleksandra Faust","Maja Matarić"],"pdf_url":"https://arxiv.org/pdf/2307.00184v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08883v1","updated":"2025-03-11T20:52:56Z","published":"2025-03-11T20:52:56Z","title":"Imitation Learning of Correlated Policies in Stackelberg Games","summary":"  Stackelberg games, widely applied in domains like economics and security,\ninvolve asymmetric interactions where a leader's strategy drives follower\nresponses. Accurately modeling these dynamics allows domain experts to optimize\nstrategies in interactive scenarios, such as turn-based sports like badminton.\nIn multi-agent systems, agent behaviors are interdependent, and traditional\nMulti-Agent Imitation Learning (MAIL) methods often fail to capture these\ncomplex interactions. Correlated policies, which account for opponents'\nstrategies, are essential for accurately modeling such dynamics. However, even\nmethods designed for learning correlated policies, like CoDAIL, struggle in\nStackelberg games due to their asymmetric decision-making, where leaders and\nfollowers cannot simultaneously account for each other's actions, often leading\nto non-correlated policies. Furthermore, existing MAIL methods that match\noccupancy measures or use adversarial techniques like GAIL or Inverse RL face\nscalability challenges, particularly in high-dimensional environments, and\nsuffer from unstable training. To address these challenges, we propose a\ncorrelated policy occupancy measure specifically designed for Stackelberg games\nand introduce the Latent Stackelberg Differential Network (LSDN) to match it.\nLSDN models two-agent interactions as shared latent state trajectories and uses\nmulti-output Geometric Brownian Motion (MO-GBM) to effectively capture joint\npolicies. By leveraging MO-GBM, LSDN disentangles environmental influences from\nagent-driven transitions in latent space, enabling the simultaneous learning of\ninterdependent policies. This design eliminates the need for adversarial\ntraining and simplifies the learning process. Extensive experiments on\nIterative Matrix Games and multi-agent particle environments demonstrate that\nLSDN can better reproduce complex interaction dynamics than existing MAIL\nmethods.\n","authors":["Kunag-Da Wang","Ping-Chun Hsieh","Wen-Chih Peng"],"pdf_url":"https://arxiv.org/pdf/2503.08883v1.pdf","comment":"Preprint. Code will be released at this GitHub link:\n  https://github.com/NYCU-RL-Bandits-Lab/LSDN"},{"id":"http://arxiv.org/abs/2503.08879v1","updated":"2025-03-11T20:45:02Z","published":"2025-03-11T20:45:02Z","title":"LLMs Know What to Drop: Self-Attention Guided KV Cache Eviction for\n  Efficient Long-Context Inference","summary":"  Efficient long-context inference is critical as large language models (LLMs)\nadopt context windows of ranging from 128K to 1M tokens. However, the growing\nkey-value (KV) cache and the high computational complexity of attention create\nsignificant bottlenecks in memory usage and latency. In this paper, we find\nthat attention in diverse long-context tasks exhibits sparsity, and LLMs\nimplicitly \"know\" which tokens can be dropped or evicted at the head level\nafter the pre-filling stage. Based on this insight, we propose Self-Attention\nGuided Eviction~(SAGE-KV), a simple and effective KV eviction cache method for\nlong-context inference. After prefilling, our method performs a one-time top-k\nselection at both the token and head levels to compress the KV cache, enabling\nefficient inference with the reduced cache. Evaluations on LongBench and three\nlong-context LLMs (Llama3.1-8B-Instruct-128k, Llama3-8B-Prolong-512k-Instruct,\nand Qwen2.5-7B-Instruct-128k) show that SAGE-KV maintains accuracy comparable\nto full attention while significantly improving efficiency. Specifically,\nSAGE-KV achieves 4x higher memory efficiency with improved accuracy over the\nstatic KV cache selection method StreamLLM, and 2x higher memory efficiency\nwith better accuracy than the dynamic KV cache selection method Quest.\n","authors":["Guangtao Wang","Shubhangi Upasani","Chen Wu","Darshan Gandhi","Jonathan Li","Changran Hu","Bo Li","Urmish Thakker"],"pdf_url":"https://arxiv.org/pdf/2503.08879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08872v1","updated":"2025-03-11T20:36:49Z","published":"2025-03-11T20:36:49Z","title":"Meta-Reinforcement Learning with Discrete World Models for Adaptive Load\n  Balancing","summary":"  We integrate a meta-reinforcement learning algorithm with the DreamerV3\narchitecture to improve load balancing in operating systems. This approach\nenables rapid adaptation to dynamic workloads with minimal retraining,\noutperforming the Advantage Actor-Critic (A2C) algorithm in standard and\nadaptive trials. It demonstrates robust resilience to catastrophic forgetting,\nmaintaining high performance under varying workload distributions and sizes.\nThese findings have important implications for optimizing resource management\nand performance in modern operating systems. By addressing the challenges posed\nby dynamic and heterogeneous workloads, our approach advances the adaptability\nand efficiency of reinforcement learning in real-world system management tasks.\n","authors":["Cameron Redovian"],"pdf_url":"https://arxiv.org/pdf/2503.08872v1.pdf","comment":"6 pages, 1 figure, to be published in ACMSE 2025"},{"id":"http://arxiv.org/abs/2501.18137v2","updated":"2025-03-11T20:34:39Z","published":"2025-01-30T04:59:21Z","title":"Tensor Completion for Surrogate Modeling of Material Property Prediction","summary":"  When designing materials to optimize certain properties, there are often many\npossible configurations of designs that need to be explored. For example, the\nmaterials' composition of elements will affect properties such as strength or\nconductivity, which are necessary to know when developing new materials.\nExploring all combinations of elements to find optimal materials becomes very\ntime consuming, especially when there are more design variables. For this\nreason, there is growing interest in using machine learning (ML) to predict a\nmaterial's properties. In this work, we model the optimization of certain\nmaterial properties as a tensor completion problem, to leverage the structure\nof our datasets and navigate the vast number of combinations of material\nconfigurations. Across a variety of material property prediction tasks, our\nexperiments show tensor completion methods achieving 10-20% decreased error\ncompared with baseline ML models such as GradientBoosting and Multilayer\nPerceptron (MLP), while maintaining similar training speed.\n","authors":["Shaan Pakala","Dawon Ahn","Evangelos Papalexakis"],"pdf_url":"https://arxiv.org/pdf/2501.18137v2.pdf","comment":"2 page paper accepted to AAAI KGML 2025 bridge program"},{"id":"http://arxiv.org/abs/2503.08867v1","updated":"2025-03-11T20:14:25Z","published":"2025-03-11T20:14:25Z","title":"Zero-Shot Action Generalization with Limited Observations","summary":"  Reinforcement Learning (RL) has demonstrated remarkable success in solving\nsequential decision-making problems. However, in real-world scenarios, RL\nagents often struggle to generalize when faced with unseen actions that were\nnot encountered during training. Some previous works on zero-shot action\ngeneralization rely on large datasets of action observations to capture the\nbehaviors of new actions, making them impractical for real-world applications.\nIn this paper, we introduce a novel zero-shot framework, Action Generalization\nfrom Limited Observations (AGLO). Our framework has two main components: an\naction representation learning module and a policy learning module. The action\nrepresentation learning module extracts discriminative embeddings of actions\nfrom limited observations, while the policy learning module leverages the\nlearned action representations, along with augmented synthetic action\nrepresentations, to learn a policy capable of handling tasks with unseen\nactions. The experimental results demonstrate that our framework significantly\noutperforms state-of-the-art methods for zero-shot action generalization across\nmultiple benchmark tasks, showcasing its effectiveness in generalizing to new\nactions with minimal action observations.\n","authors":["Abdullah Alchihabi","Hanping Zhang","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2503.08867v1.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.02348v2","updated":"2025-03-11T19:51:32Z","published":"2024-11-04T18:18:38Z","title":"Can Large Language Models generalize analogy solving like people can?","summary":"  When we solve an analogy we transfer information from a known context to a\nnew one through abstract rules and relational similarity. In people, the\nability to solve analogies such as \"body : feet :: table : ?\" emerges in\nchildhood, and appears to transfer easily to other domains, such as the visual\ndomain \"( : ) :: < : ?\". Recent research shows that large language models\n(LLMs) can solve various forms of analogies. However, can LLMs generalize\nanalogy solving to new domains like people can? To investigate this, we had\nchildren, adults, and LLMs solve a series of letter-string analogies (e.g., a b\n: a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek\nalphabet), and a far transfer domain (list of symbols). As expected, children\nand adults easily generalized their knowledge to unfamiliar domains, whereas\nLLMs did not. This key difference between human and AI performance is evidence\nthat these LLMs still struggle with robust human-like analogical transfer.\n","authors":["Claire E. Stevenson","Alexandra Pafford","Han L. J. van der Maas","Melanie Mitchell"],"pdf_url":"https://arxiv.org/pdf/2411.02348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08788v2","updated":"2025-03-11T19:49:55Z","published":"2024-06-13T03:47:12Z","title":"Towards Understanding Link Predictor Generalizability Under Distribution\n  Shifts","summary":"  State-of-the-art link prediction (LP) models demonstrate impressive benchmark\nresults. However, popular benchmark datasets often assume that training,\nvalidation, and testing samples are representative of the overall dataset\ndistribution. In real-world situations, this assumption is often incorrect;\nuncontrolled factors lead new dataset samples to come from a different\ndistribution than training samples. Additionally, the majority of recent work\nwith graph dataset shift focuses on node- and graph-level tasks, largely\nignoring link-level tasks. To bridge this gap, we introduce a novel splitting\nstrategy, known as LPShift, which utilizes structural properties to induce a\ncontrolled distribution shift. We verify LPShift's effect through empirical\nevaluation of SOTA LP models on 16 LPShift variants of original dataset splits,\nwith results indicating drastic changes to model performance. Additional\nexperiments demonstrate graph structure has a strong influence on the success\nof current generalization methods. Source Code Available Here:\nhttps://github.com/revolins/LPShift\n","authors":["Jay Revolinsky","Harry Shomer","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2406.08788v2.pdf","comment":"23 pages, 8 figures, 17 tables"},{"id":"http://arxiv.org/abs/2403.16812v2","updated":"2025-03-11T19:23:23Z","published":"2024-03-25T14:34:06Z","title":"Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered\n  Deliberative AI for AI-Assisted Decision-Making","summary":"  In AI-assisted decision-making, humans often passively review AI's suggestion\nand decide whether to accept or reject it as a whole. In such a paradigm,\nhumans are found to rarely trigger analytical thinking and face difficulties in\ncommunicating the nuances of conflicting opinions to the AI when disagreements\noccur. To tackle this challenge, we propose Human-AI Deliberation, a novel\nframework to promote human reflection and discussion on conflicting human-AI\nopinions in decision-making. Based on theories in human deliberation, this\nframework engages humans and AI in dimension-level opinion elicitation,\ndeliberative discussion, and decision updates. To empower AI with deliberative\ncapabilities, we designed Deliberative AI, which leverages large language\nmodels (LLMs) as a bridge between humans and domain-specific models to enable\nflexible conversational interactions and faithful information provision. An\nexploratory evaluation on a graduate admissions task shows that Deliberative AI\noutperforms conventional explainable AI (XAI) assistants in improving humans'\nappropriate reliance and task performance. Based on a mixed-methods analysis of\nparticipant behavior, perception, user experience, and open-ended feedback, we\ndraw implications for future AI-assisted decision tool design.\n","authors":["Shuai Ma","Qiaoyi Chen","Xinru Wang","Chengbo Zheng","Zhenhui Peng","Ming Yin","Xiaojuan Ma"],"pdf_url":"https://arxiv.org/pdf/2403.16812v2.pdf","comment":"23 pages, ACM CHI 2025"},{"id":"http://arxiv.org/abs/2312.16893v2","updated":"2025-03-11T19:00:39Z","published":"2023-12-28T08:34:17Z","title":"BBScore: A Brownian Bridge Based Metric for Assessing Text Coherence","summary":"  Measuring the coherence of text is a vital aspect of evaluating the quality\nof written content. Recent advancements in neural coherence modeling have\ndemonstrated their efficacy in capturing entity coreference and discourse\nrelations, thereby enhancing coherence evaluation. However, many existing\nmethods heavily depend on static embeddings or focus narrowly on nearby\ncontext, constraining their capacity to measure the overarching coherence of\nlong texts. In this paper, we posit that coherent texts inherently manifest a\nsequential and cohesive interplay among sentences, effectively conveying the\ncentral theme, purpose, or standpoint. To explore this abstract relationship,\nwe introduce the \"BBScore,\" a novel reference-free metric grounded in Brownian\nbridge theory for assessing text coherence. Our findings showcase that when\nsynergized with a simple additional classification component, this metric\nattains a performance level comparable to state-of-the-art techniques on\nstandard artificial discrimination tasks. We also establish in downstream tasks\nthat this metric effectively differentiates between human-written documents and\ntext generated by large language models under a specific domain. Furthermore,\nwe illustrate the efficacy of this approach in detecting written styles\nattributed to diverse large language models, underscoring its potential for\ngeneralizability. In summary, we present a novel Brownian bridge coherence\nmetric capable of measuring both local and global text coherence, while\ncircumventing the need for end-to-end model training. This flexibility allows\nfor its application in various downstream tasks.\n","authors":["Zhecheng Sheng","Tianhao Zhang","Chen Jiang","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2312.16893v2.pdf","comment":"Accepted to the 38th Annual AAAI Conference on Artificial\n  Intelligence (AAAI-24)"},{"id":"http://arxiv.org/abs/2410.16136v2","updated":"2025-03-11T18:54:53Z","published":"2024-10-21T16:01:39Z","title":"Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli\n  and Stimulus-independent Latent Factors","summary":"  Understanding how visual processing of natural stimuli and internal brain\nstates interact in populations of neurons remains an open question in\nneuroscience. Currently there are no dynamic encoding models that explicitly\nmodel a latent state and the entire neuronal response distribution. We address\nthis gap by proposing a probabilistic model that predicts the joint\ndistribution of the neuronal responses from video stimuli and\nstimulus-independent latent factors. After training and testing our model on\nmouse V1 neuronal responses, we find that it outperforms video-only models in\nterms of log-likelihood and achieves improvements in likelihood and correlation\nwhen conditioned on responses from other neurons. Furthermore, we find that the\nlearned latent factors strongly correlate with mouse behavior and that they\nexhibits patterns related to the neurons position on visual cortex, although\nthe model was trained without behavior and cortical coordinates. Our findings\ndemonstrate that unsupervised learning of latent factors from population\nresponses can reveal biologically meaningful structure that bridges sensory\nprocessing and behavior, without requiring explicit behavioral annotations\nduring training. Code will be available upon publication.\n","authors":["Finn Schmidt","Polina Turishcheva","Suhas Shrinivasan","Fabian H. Sinz"],"pdf_url":"https://arxiv.org/pdf/2410.16136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10173v3","updated":"2025-03-11T18:54:44Z","published":"2024-03-15T10:28:31Z","title":"Efficient Event-Based Object Detection: A Hybrid Neural Network with\n  Spatial and Temporal Attention","summary":"  Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for\nenergy-efficient and low latency event-based data processing, they often fall\nshort of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here,\nwe introduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.\n","authors":["Soikat Hasan Ahmed","Jan Finkbeiner","Emre Neftci"],"pdf_url":"https://arxiv.org/pdf/2403.10173v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08823v1","updated":"2025-03-11T18:54:17Z","published":"2025-03-11T18:54:17Z","title":"ResBench: Benchmarking LLM-Generated FPGA Designs with Resource\n  Awareness","summary":"  Field-Programmable Gate Arrays (FPGAs) are widely used in modern hardware\ndesign, yet writing Hardware Description Language (HDL) code for FPGA\nimplementation remains labor-intensive and complex. Large Language Models\n(LLMs) have emerged as a promising tool for automating HDL generation, but\nexisting benchmarks for LLM HDL code generation primarily evaluate functional\ncorrectness while overlooking the critical aspect of hardware resource\nefficiency. Moreover, current benchmarks lack diversity, failing to capture the\nbroad range of real-world FPGA applications. To address these gaps, we\nintroduce ResBench, the first resource-oriented benchmark explicitly designed\nto differentiate between resource-optimized and inefficient LLM-generated HDL.\nResBench consists of 56 problems across 12 categories, covering applications\nfrom finite state machines to financial computing. Our evaluation framework\nsystematically integrates FPGA resource constraints, with a primary focus on\nLookup Table (LUT) usage, enabling a realistic assessment of hardware\nefficiency. Experimental results reveal substantial differences in resource\nutilization across LLMs, demonstrating ResBench's effectiveness in\ndistinguishing models based on their ability to generate resource-optimized\nFPGA designs.\n","authors":["Ce Guo","Tong Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.08823v1.pdf","comment":"to be published in International Symposium on Highly Efficient\n  Accelerators and Reconfigurable Technologies 2025"},{"id":"http://arxiv.org/abs/2503.08815v1","updated":"2025-03-11T18:50:43Z","published":"2025-03-11T18:50:43Z","title":"Cross-Examiner: Evaluating Consistency of Large Language Model-Generated\n  Explanations","summary":"  Large Language Models (LLMs) are often asked to explain their outputs to\nenhance accuracy and transparency. However, evidence suggests that these\nexplanations can misrepresent the models' true reasoning processes. One\neffective way to identify inaccuracies or omissions in these explanations is\nthrough consistency checking, which typically involves asking follow-up\nquestions. This paper introduces, cross-examiner, a new method for generating\nfollow-up questions based on a model's explanation of an initial question. Our\nmethod combines symbolic information extraction with language model-driven\nquestion generation, resulting in better follow-up questions than those\nproduced by LLMs alone. Additionally, this approach is more flexible than other\nmethods and can generate a wider variety of follow-up questions.\n","authors":["Danielle Villa","Maria Chang","Keerthiram Murugesan","Rosario Uceda-Sosa","Karthikeyan Natesan Ramamurthy"],"pdf_url":"https://arxiv.org/pdf/2503.08815v1.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.06226v2","updated":"2025-03-11T18:32:36Z","published":"2025-03-08T14:02:16Z","title":"Optimal Output Feedback Learning Control for Discrete-Time Linear\n  Quadratic Regulation","summary":"  This paper studies the linear quadratic regulation (LQR) problem of unknown\ndiscrete-time systems via dynamic output feedback learning control. In contrast\nto the state feedback, the optimality of the dynamic output feedback control\nfor solving the LQR problem requires an implicit condition on the convergence\nof the state observer. Moreover, due to unknown system matrices and the\nexistence of observer error, it is difficult to analyze the convergence and\nstability of most existing output feedback learning-based control methods. To\ntackle these issues, we propose a generalized dynamic output feedback learning\ncontrol approach with guaranteed convergence, stability, and optimality\nperformance for solving the LQR problem of unknown discrete-time linear\nsystems. In particular, a dynamic output feedback controller is designed to be\nequivalent to a state feedback controller. This equivalence relationship is an\ninherent property without requiring convergence of the estimated state by the\nstate observer, which plays a key role in establishing the off-policy learning\ncontrol approaches. By value iteration and policy iteration schemes, the\nadaptive dynamic programming based learning control approaches are developed to\nestimate the optimal feedback control gain. In addition, a model-free stability\ncriterion is provided by finding a nonsingular parameterization matrix, which\ncontributes to establishing a switched iteration scheme. Furthermore, the\nconvergence, stability, and optimality analyses of the proposed output feedback\nlearning control approaches are given. Finally, the theoretical results are\nvalidated by two numerical examples.\n","authors":["Kedi Xie","Martin Guay","Shimin Wang","Fang Deng","Maobin Lu"],"pdf_url":"https://arxiv.org/pdf/2503.06226v2.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.01926v2","updated":"2025-03-11T18:21:46Z","published":"2025-01-03T17:56:28Z","title":"Mitigating Hallucination for Large Vision Language Model by\n  Inter-Modality Correlation Calibration Decoding","summary":"  Large vision-language models (LVLMs) have shown remarkable capabilities in\nvisual-language understanding for downstream multi-modal tasks. Despite their\nsuccess, LVLMs still suffer from generating hallucinations in complex\ngeneration tasks, leading to inconsistencies between visual inputs and\ngenerated content. To address this issue, some approaches have introduced\ninference-time interventions, such as contrastive decoding and attention\nrectification, to reduce overreliance on language priors. However, these\napproaches overlook hallucinations stemming from spurious inter-modality\ncorrelations. In this paper, we propose an Inter-Modality Correlation\nCalibration Decoding (IMCCD) method to mitigate hallucinations in LVLMs in a\ntraining-free manner. In this method, we design a Cross-Modal Value-Enhanced\nDecoding(CMVED) module to alleviate hallucination by a novel contrastive\ndecoding mechanism. During the estimation of distorted distribution, CMVED\nmasks the value vectors associated with significant cross-modal attention\nweights, which address both uni-modality overreliance and misleading\ninter-modality correlations. Additionally, a Content-Driven Attention\nRefinement(CDAR) module refines cross-modal attention weights, guiding LVLMs to\nfocus on important visual content. Experimental results on diverse\nhallucination benchmarks validate the superiority of our method over existing\nstate-of-the-art techniques in reducing hallucinations in LVLM text generation.\nOur code will be available at https://github.com/lijm48/IMCCD.\n","authors":["Jiaming Li","Jiacheng Zhang","Zequn Jie","Lin Ma","Guanbin Li"],"pdf_url":"https://arxiv.org/pdf/2501.01926v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00374v3","updated":"2025-03-11T18:19:56Z","published":"2024-08-01T08:32:03Z","title":"Conformal Trajectory Prediction with Multi-View Data Integration in\n  Cooperative Driving","summary":"  Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\nhttps://github.com/xichennn/V2I_trajectory_prediction.\n","authors":["Xi Chen","Rahul Bhadani","Larry Head"],"pdf_url":"https://arxiv.org/pdf/2408.00374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08796v1","updated":"2025-03-11T18:15:26Z","published":"2025-03-11T18:15:26Z","title":"Robust Multi-Objective Controlled Decoding of Large Language Models","summary":"  Test-time alignment of Large Language Models (LLMs) to human preferences\noffers a flexible way to generate responses aligned to diverse objectives\nwithout extensive retraining of LLMs. Existing methods achieve alignment to\nmultiple objectives simultaneously (e.g., instruction-following, helpfulness,\nconciseness) by optimizing their corresponding reward functions. However, they\noften rely on predefined weights or optimize for averages, sacrificing one\nobjective for another and leading to unbalanced outcomes. To address this, we\nintroduce Robust Multi-Objective Decoding (RMOD), a novel inference-time\nalgorithm that optimizes for improving worst-case rewards. RMOD formalizes the\nrobust decoding problem as a maximin two-player game between reward weights and\nthe sampling policy, solving for the Nash equilibrium. We show that the game\nreduces to a convex optimization problem to find the worst-case weights, while\nthe best response policy can be computed analytically. We also introduce a\npractical RMOD variant designed for efficient decoding with contemporary LLMs,\nincurring minimal computational overhead compared to non-robust Multi-Objective\nDecoding (MOD) methods. Our experimental results showcase the effectiveness of\nRMOD in generating responses equitably aligned with diverse objectives,\noutperforming baselines up to 20%.\n","authors":["Seongho Son","William Bankes","Sangwoong Yoon","Shyam Sundhar Ramesh","Xiaohang Tang","Ilija Bogunovic"],"pdf_url":"https://arxiv.org/pdf/2503.08796v1.pdf","comment":"24 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.08786v1","updated":"2025-03-11T18:00:23Z","published":"2025-03-11T18:00:23Z","title":"Combining Local Symmetry Exploitation and Reinforcement Learning for\n  Optimised Probabilistic Inference -- A Work In Progress","summary":"  Efficient probabilistic inference by variable elimination in graphical models\nrequires an optimal elimination order. However, finding an optimal order is a\nchallenging combinatorial optimisation problem for models with a large number\nof random variables. Most recently, a reinforcement learning approach has been\nproposed to find efficient contraction orders in tensor networks. Due to the\nduality between graphical models and tensor networks, we adapt this approach to\nprobabilistic inference in graphical models. Furthermore, we incorporate\nstructure exploitation into the process of finding an optimal order. Currently,\nthe agent's cost function is formulated in terms of intermediate result sizes\nwhich are exponential in the number of indices (i.e., random variables). We\nshow that leveraging specific structures during inference allows for\nintroducing compact encodings of intermediate results which can be\nsignificantly smaller. By considering the compact encoding sizes for the cost\nfunction instead, we enable the agent to explore more efficient contraction\norders. The structure we consider in this work is the presence of local\nsymmetries (i.e., symmetries within a model's factors).\n","authors":["Sagad Hamid","Tanya Braun"],"pdf_url":"https://arxiv.org/pdf/2503.08786v1.pdf","comment":"Contributed to: Sixth Data Science Meets Optimisation (DSO) Workshop\n  at IJCAI 2024"},{"id":"http://arxiv.org/abs/2503.08764v1","updated":"2025-03-11T17:57:29Z","published":"2025-03-11T17:57:29Z","title":"Towards Interpretable Protein Structure Prediction with Sparse\n  Autoencoders","summary":"  Protein language models have revolutionized structure prediction, but their\nnonlinear nature obscures how sequence representations inform structure\nprediction. While sparse autoencoders (SAEs) offer a path to interpretability\nhere by learning linear representations in high-dimensional space, their\napplication has been limited to smaller protein language models unable to\nperform structure prediction. In this work, we make two key advances: (1) we\nscale SAEs to ESM2-3B, the base model for ESMFold, enabling mechanistic\ninterpretability of protein structure prediction for the first time, and (2) we\nadapt Matryoshka SAEs for protein language models, which learn hierarchically\norganized features by forcing nested groups of latents to reconstruct inputs\nindependently. We demonstrate that our Matryoshka SAEs achieve comparable or\nbetter performance than standard architectures. Through comprehensive\nevaluations, we show that SAEs trained on ESM2-3B significantly outperform\nthose trained on smaller models for both biological concept discovery and\ncontact map prediction. Finally, we present an initial case study demonstrating\nhow our approach enables targeted steering of ESMFold predictions, increasing\nstructure solvent accessibility while fixing the input sequence. To facilitate\nfurther investigation by the broader community, we open-source our code,\ndataset, pretrained models https://github.com/johnyang101/reticular-sae , and\nvisualizer https://sae.reticular.ai .\n","authors":["Nithin Parsan","David J. Yang","John J. Yang"],"pdf_url":"https://arxiv.org/pdf/2503.08764v1.pdf","comment":"Published at the GEMBio ICLR 2025 Workshop"}]},"2025-03-12T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.09600v1","updated":"2025-03-12T17:59:42Z","published":"2025-03-12T17:59:42Z","title":"MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented\n  Generation System","summary":"  Retrieval-Augmented Generation (RAG), while serving as a viable complement to\nlarge language models (LLMs), often overlooks the crucial aspect of text\nchunking within its pipeline. This paper initially introduces a dual-metric\nevaluation method, comprising Boundary Clarity and Chunk Stickiness, to enable\nthe direct quantification of chunking quality. Leveraging this assessment\nmethod, we highlight the inherent limitations of traditional and semantic\nchunking in handling complex contextual nuances, thereby substantiating the\nnecessity of integrating LLMs into chunking process. To address the inherent\ntrade-off between computational efficiency and chunking precision in LLM-based\napproaches, we devise the granularity-aware Mixture-of-Chunkers (MoC)\nframework, which consists of a three-stage processing mechanism. Notably, our\nobjective is to guide the chunker towards generating a structured list of\nchunking regular expressions, which are subsequently employed to extract chunks\nfrom the original text. Extensive experiments demonstrate that both our\nproposed metrics and the MoC framework effectively settle challenges of the\nchunking task, revealing the chunking kernel while enhancing the performance of\nthe RAG system.\n","authors":["Jihao Zhao","Zhiyuan Ji","Zhaoxin Fan","Hanyu Wang","Simin Niu","Bo Tang","Feiyu Xiong","Zhiyu Li"],"pdf_url":"https://arxiv.org/pdf/2503.09600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09598v1","updated":"2025-03-12T17:59:18Z","published":"2025-03-12T17:59:18Z","title":"How to Protect Yourself from 5G Radiation? Investigating LLM Responses\n  to Implicit Misinformation","summary":"  As Large Language Models (LLMs) are widely deployed in diverse scenarios, the\nextent to which they could tacitly spread misinformation emerges as a critical\nsafety concern. Current research primarily evaluates LLMs on explicit false\nstatements, overlooking how misinformation often manifests subtly as\nunchallenged premises in real-world user interactions. We curated ECHOMIST, the\nfirst comprehensive benchmark for implicit misinformation, where the\nmisinformed assumptions are embedded in a user query to LLMs. ECHOMIST is based\non rigorous selection criteria and carefully curated data from diverse sources,\nincluding real-world human-AI conversations and social media interactions. We\nalso introduce a new evaluation metric to measure whether LLMs can recognize\nand counter false information rather than amplify users' misconceptions.\nThrough an extensive empirical study on a wide range of LLMs, including GPT-4,\nClaude, and Llama, we find that current models perform alarmingly poorly on\nthis task, often failing to detect false premises and generating misleading\nexplanations. Our findings underscore the critical need for an increased focus\non implicit misinformation in LLM safety research.\n","authors":["Ruohao Guo","Wei Xu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2503.09598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09579v1","updated":"2025-03-12T17:50:42Z","published":"2025-03-12T17:50:42Z","title":"Cost-Optimal Grouped-Query Attention for Long-Context LLMs","summary":"  Building effective and efficient Transformer-based large language models\n(LLMs) has recently become a research focus, requiring maximizing model\nlanguage capabilities and minimizing training and deployment costs. Existing\nefforts have primarily described complex relationships among model performance,\nparameter size, and data size, as well as searched for the optimal compute\nallocation to train LLMs. However, they overlook the impacts of context length\nand attention head configuration (the number of query and key-value heads in\ngrouped-query attention) on training and inference. In this paper, we\nsystematically compare models with different parameter sizes, context lengths,\nand attention head configurations in terms of model performance, computational\ncost, and memory cost. Then, we extend the existing scaling methods, which are\nbased solely on parameter size and training compute, to guide the construction\nof cost-optimal LLMs during both training and inference. Our quantitative\nscaling studies show that, when processing sufficiently long sequences, a\nlarger model with fewer attention heads can achieve a lower loss while\nincurring lower computational and memory costs. Our findings provide valuable\ninsights for developing practical LLMs, especially in long-context processing\nscenarios. We will publicly release our code and data.\n","authors":["Yingfa Chen","Yutong Wu","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2503.09579v1.pdf","comment":"16 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.09572v1","updated":"2025-03-12T17:40:52Z","published":"2025-03-12T17:40:52Z","title":"Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks","summary":"  Large language models (LLMs) have shown remarkable advancements in enabling\nlanguage agents to tackle simple tasks. However, applying them for complex,\nmulti-step, long-horizon tasks remains a challenge. Recent work have found\nsuccess by separating high-level planning from low-level execution, which\nenables the model to effectively balance high-level planning objectives and\nlow-level execution details. However, generating accurate plans remains\ndifficult since LLMs are not inherently trained for this task. To address this,\nwe propose Plan-and-Act, a novel framework that incorporates explicit planning\ninto LLM-based agents and introduces a scalable method to enhance plan\ngeneration through a novel synthetic data generation method. Plan-and-Act\nconsists of a Planner model which generates structured, high-level plans to\nachieve user goals, and an Executor model that translates these plans into\nenvironment-specific actions. To train the Planner effectively, we introduce a\nsynthetic data generation method that annotates ground-truth trajectories with\nfeasible plans, augmented with diverse and extensive examples to enhance\ngeneralization. We evaluate Plan-and-Act using web navigation as a\nrepresentative long-horizon planning environment, demonstrating a state-of\nthe-art 54% success rate on the WebArena-Lite benchmark.\n","authors":["Lutfi Eren Erdogan","Nicholas Lee","Sehoon Kim","Suhong Moon","Hiroki Furuta","Gopala Anumanchipalli","Kurt Keutzer","Amir Gholami"],"pdf_url":"https://arxiv.org/pdf/2503.09572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09567v1","updated":"2025-03-12T17:35:03Z","published":"2025-03-12T17:35:03Z","title":"Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning\n  Large Language Models","summary":"  Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"test-time scaling.\" This survey seeks to\nfill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and test-time scaling, offering\ninsights into how these processes manifest in practice. (4) Finally, we\nidentify significant research gaps and highlight promising future directions,\nincluding the integration of multi-modal reasoning, efficiency improvements,\nand enhanced knowledge frameworks. By providing a structured overview, this\nsurvey aims to inspire future research and further the development of logical\nreasoning in artificial intelligence.\n","authors":["Qiguang Chen","Libo Qin","Jinhao Liu","Dengyun Peng","Jiannan Guan","Peng Wang","Mengkang Hu","Yuhang Zhou","Te Gao","Wangxiang Che"],"pdf_url":"https://arxiv.org/pdf/2503.09567v1.pdf","comment":"Paper are available at https://long-cot.github.io/"},{"id":"http://arxiv.org/abs/2503.09543v1","updated":"2025-03-12T16:59:30Z","published":"2025-03-12T16:59:30Z","title":"PolyPythias: Stability and Outliers across Fifty Language Model\n  Pre-Training Runs","summary":"  The stability of language model pre-training and its effects on downstream\nperformance are still understudied. Prior work shows that the training process\ncan yield significantly different results in response to slight variations in\ninitial conditions, e.g., the random seed. Crucially, the research community\nstill lacks sufficient resources and tools to systematically investigate\npre-training stability, particularly for decoder-only language models. We\nintroduce the PolyPythias, a set of 45 new training runs for the Pythia model\nsuite: 9 new seeds across 5 model sizes, from 14M to 410M parameters, resulting\nin about 7k new checkpoints that we release. Using these new 45 training runs,\nin addition to the 5 already available, we study the effects of different\ninitial conditions determined by the seed -- i.e., parameters' initialisation\nand data order -- on (i) downstream performance, (ii) learned linguistic\nrepresentations, and (iii) emergence of training phases. In addition to common\nscaling behaviours, our analyses generally reveal highly consistent training\ndynamics across both model sizes and initial conditions. Further, the new seeds\nfor each model allow us to identify outlier training runs and delineate their\ncharacteristics. Our findings show the potential of using these methods to\npredict training stability.\n","authors":["Oskar van der Wal","Pietro Lesci","Max Muller-Eberstein","Naomi Saphra","Hailey Schoelkopf","Willem Zuidema","Stella Biderman"],"pdf_url":"https://arxiv.org/pdf/2503.09543v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.04025v2","updated":"2025-03-12T16:57:27Z","published":"2024-11-06T16:20:37Z","title":"Prompt Engineering Using GPT for Word-Level Code-Mixed Language\n  Identification in Low-Resource Dravidian Languages","summary":"  Language Identification (LI) is crucial for various natural language\nprocessing tasks, serving as a foundational step in applications such as\nsentiment analysis, machine translation, and information retrieval. In\nmultilingual societies like India, particularly among the youth engaging on\nsocial media, text often exhibits code-mixing, blending local languages with\nEnglish at different linguistic levels. This phenomenon presents formidable\nchallenges for LI systems, especially when languages intermingle within single\nwords. Dravidian languages, prevalent in southern India, possess rich\nmorphological structures yet suffer from under-representation in digital\nplatforms, leading to the adoption of Roman or hybrid scripts for\ncommunication. This paper introduces a prompt based method for a shared task\naimed at addressing word-level LI challenges in Dravidian languages. In this\nwork, we leveraged GPT-3.5 Turbo to understand whether the large language\nmodels is able to correctly classify words into correct categories. Our\nfindings show that the Kannada model consistently outperformed the Tamil model\nacross most metrics, indicating a higher accuracy and reliability in\nidentifying and categorizing Kannada language instances. In contrast, the Tamil\nmodel showed moderate performance, particularly needing improvement in\nprecision and recall.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.04025v2.pdf","comment":"Updated and Final Version"},{"id":"http://arxiv.org/abs/2503.09532v1","updated":"2025-03-12T16:49:02Z","published":"2025-03-12T16:49:02Z","title":"SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language\n  Model Interpretability","summary":"  Sparse autoencoders (SAEs) are a popular technique for interpreting language\nmodel activations, and there is extensive recent work on improving SAE\neffectiveness. However, most prior work evaluates progress using unsupervised\nproxy metrics with unclear practical relevance. We introduce SAEBench, a\ncomprehensive evaluation suite that measures SAE performance across seven\ndiverse metrics, spanning interpretability, feature disentanglement and\npractical applications like unlearning. To enable systematic comparison, we\nopen-source a suite of over 200 SAEs across eight recently proposed SAE\narchitectures and training algorithms. Our evaluation reveals that gains on\nproxy metrics do not reliably translate to better practical performance. For\ninstance, while Matryoshka SAEs slightly underperform on existing proxy\nmetrics, they substantially outperform other architectures on feature\ndisentanglement metrics; moreover, this advantage grows with SAE scale. By\nproviding a standardized framework for measuring progress in SAE development,\nSAEBench enables researchers to study scaling trends and make nuanced\ncomparisons between different SAE architectures and training methodologies. Our\ninteractive interface enables researchers to flexibly visualize relationships\nbetween metrics across hundreds of open-source SAEs at: https://saebench.xyz\n","authors":["Adam Karvonen","Can Rager","Johnny Lin","Curt Tigges","Joseph Bloom","David Chanin","Yeu-Tong Lau","Eoin Farrell","Callum McDougall","Kola Ayonrinde","Matthew Wearden","Arthur Conmy","Samuel Marks","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2503.09532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18798v3","updated":"2025-03-12T16:27:59Z","published":"2025-02-26T04:10:18Z","title":"ANPMI: Assessing the True Comprehension Capabilities of LLMs for\n  Multiple Choice Questions","summary":"  Multiple-choice benchmarks, consisting of various prompts and choices, are\namong the most widely used methods to assess a language model's natural\nlanguage understanding capability. Given a specific prompt, we typically\ncompute $P(Choice|Prompt)$ to evaluate how likely a language model is to\ngenerate the correct choice compared to incorrect ones. However, we observe\nthat performance measured using this approach reflects not only the model's\ncomprehension of the prompt but also its inherent biases for certain choices\nregardless of the prompt. This issue makes it challenging to accurately measure\na model's natural language understanding, as models may select the answer\nwithout fully understanding the prompt. To address this limitation, we propose\na novel metric called ANPMI, which normalizes Pointwise Mutual Information\n(PMI) by $-\\log P(Choice)$. ANPMI provides a more accurate assessment of the\nmodel's natural language understanding by ensuring that it is challenging to\nanswer a question without properly understanding the prompt.\n","authors":["Gyeongje Cho","Yeonkyoung So","Jaejin Lee"],"pdf_url":"https://arxiv.org/pdf/2502.18798v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09516v1","updated":"2025-03-12T16:26:39Z","published":"2025-03-12T16:26:39Z","title":"Search-R1: Training LLMs to Reason and Leverage Search Engines with\n  Reinforcement Learning","summary":"  Efficiently acquiring external knowledge and up-to-date information is\nessential for effective reasoning and text generation in large language models\n(LLMs). Retrieval augmentation and tool-use training approaches where a search\nengine is treated as a tool lack complex multi-turn retrieval flexibility or\nrequire large-scale supervised data. Prompting advanced LLMs with reasoning\ncapabilities during inference to use search engines is not optimal, since the\nLLM does not learn how to optimally interact with the search engine. This paper\nintroduces Search-R1, an extension of the DeepSeek-R1 model where the LLM\nlearns -- solely through reinforcement learning (RL) -- to autonomously\ngenerate (multiple) search queries during step-by-step reasoning with real-time\nretrieval. Search-R1 optimizes LLM rollouts with multi-turn search\ninteractions, leveraging retrieved token masking for stable RL training and a\nsimple outcome-based reward function. Experiments on seven question-answering\ndatasets show that Search-R1 improves performance by 26% (Qwen2.5-7B), 21%\n(Qwen2.5-3B), and 10% (LLaMA3.2-3B) over SOTA baselines. This paper further\nprovides empirical insights into RL optimization methods, LLM choices, and\nresponse length dynamics in retrieval-augmented reasoning. The code and model\ncheckpoints are available at https://github.com/PeterGriffinJin/Search-R1.\n","authors":["Bowen Jin","Hansi Zeng","Zhenrui Yue","Dong Wang","Hamed Zamani","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2503.09516v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2503.09512v1","updated":"2025-03-12T16:22:28Z","published":"2025-03-12T16:22:28Z","title":"Reinforcement Learning is all You Need","summary":"  Inspired by the success of DeepSeek R1 in reasoning via reinforcement\nlearning without human feedback, we train a 3B language model using the\nCountdown Game with pure reinforcement learning. Our model outperforms\nbaselines on four of five benchmarks, demonstrating improved generalization\nbeyond its training data. Notably, response length does not correlate with\nreasoning quality, and while \"aha moments\" emerge, they do not always yield\ncorrect answers. These findings highlight the potential of RL-only training for\nreasoning enhancement and suggest future work on refining reward structures to\nbridge emergent insights with accuracy.\n","authors":["Yongsheng Lian"],"pdf_url":"https://arxiv.org/pdf/2503.09512v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.09511v1","updated":"2025-03-12T16:20:31Z","published":"2025-03-12T16:20:31Z","title":"TRACE: Real-Time Multimodal Common Ground Tracking in Situated\n  Collaborative Dialogues","summary":"  We present TRACE, a novel system for live *common ground* tracking in\nsituated collaborative tasks. With a focus on fast, real-time performance,\nTRACE tracks the speech, actions, gestures, and visual attention of\nparticipants, uses these multimodal inputs to determine the set of\ntask-relevant propositions that have been raised as the dialogue progresses,\nand tracks the group's epistemic position and beliefs toward them as the task\nunfolds. Amid increased interest in AI systems that can mediate collaborations,\nTRACE represents an important step forward for agents that can engage with\nmultiparty, multimodal discourse.\n","authors":["Hannah VanderHoeven","Brady Bhalla","Ibrahim Khebour","Austin Youngren","Videep Venkatesha","Mariah Bradford","Jack Fitzgerald","Carlos Mabrey","Jingxuan Tu","Yifan Zhu","Kenneth Lai","Changsoo Jung","James Pustejovsky","Nikhil Krishnaswamy"],"pdf_url":"https://arxiv.org/pdf/2503.09511v1.pdf","comment":"11 pages, 4 tables, 4 figures, to appear at NAACL 2025 Demos program,\n  Albuquerque, NM, USA"},{"id":"http://arxiv.org/abs/2502.15996v2","updated":"2025-03-12T16:17:01Z","published":"2025-02-21T23:17:31Z","title":"Med-gte-hybrid: A contextual embedding transformer model for extracting\n  actionable information from clinical texts","summary":"  We introduce a novel contextual embedding model med-gte-hybrid that was\nderived from the gte-large sentence transformer to extract information from\nunstructured clinical narratives. Our model tuning strategy for med-gte-hybrid\ncombines contrastive learning and a denoising autoencoder. To evaluate the\nperformance of med-gte-hybrid, we investigate several clinical prediction tasks\nin large patient cohorts extracted from the MIMIC-IV dataset, including Chronic\nKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate\n(eGFR) prediction, and patient mortality prediction. Furthermore, we\ndemonstrate that the med-gte-hybrid model improves patient stratification,\nclustering, and text retrieval, thus outperforms current state-of-the-art\nmodels on the Massive Text Embedding Benchmark (MTEB). While some of our\nevaluations focus on CKD, our hybrid tuning of sentence transformers could be\ntransferred to other medical domains and has the potential to improve clinical\ndecision-making and personalised treatment pathways in various healthcare\napplications.\n","authors":["Aditya Kumar","Simon Rauch","Mario Cypko","Oliver Amft"],"pdf_url":"https://arxiv.org/pdf/2502.15996v2.pdf","comment":"22 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.09501v1","updated":"2025-03-12T16:05:31Z","published":"2025-03-12T16:05:31Z","title":"ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement\n  Learning","summary":"  Recent research on Reasoning of Large Language Models (LLMs) has sought to\nfurther enhance their performance by integrating meta-thinking -- enabling\nmodels to monitor, evaluate, and control their reasoning processes for more\nadaptive and effective problem-solving. However, current single-agent work\nlacks a specialized design for acquiring meta-thinking, resulting in low\nefficacy. To address this challenge, we introduce Reinforced Meta-thinking\nAgents (ReMA), a novel framework that leverages Multi-Agent Reinforcement\nLearning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think\nabout thinking. ReMA decouples the reasoning process into two hierarchical\nagents: a high-level meta-thinking agent responsible for generating strategic\noversight and plans, and a low-level reasoning agent for detailed executions.\nThrough iterative reinforcement learning with aligned objectives, these agents\nexplore and learn collaboration, leading to improved generalization and\nrobustness. Experimental results demonstrate that ReMA outperforms single-agent\nRL baselines on complex reasoning tasks, including competitive-level\nmathematical benchmarks and LLM-as-a-Judge benchmarks. Comprehensive ablation\nstudies further illustrate the evolving dynamics of each distinct agent,\nproviding valuable insights into how the meta-thinking reasoning process\nenhances the reasoning capabilities of LLMs.\n","authors":["Ziyu Wan","Yunxiang Li","Yan Song","Hanjing Wang","Linyi Yang","Mark Schmidt","Jun Wang","Weinan Zhang","Shuyue Hu","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2503.09501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09499v1","updated":"2025-03-12T16:03:03Z","published":"2025-03-12T16:03:03Z","title":"MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging\n  Questions","summary":"  Large vision-language models (VLMs) face challenges in achieving robust,\ntransferable reasoning abilities due to reliance on labor-intensive manual\ninstruction datasets or computationally expensive self-supervised methods. To\naddress these issues, we introduce MindGYM, a framework that enhances VLMs\nthrough synthetic self-challenging questions, consisting of three stages: (1)\nSeed Single-Hop Question Synthesis, generating cognitive questions across\ntextual (e.g., logical deduction) and multimodal contexts (e.g., diagram-based\nqueries) spanning eight semantic areas like ethical analysis; (2) Challenging\nMulti-Hop Question Synthesis, combining seed questions via diverse principles\nlike bridging, visual-textual alignment, to create multi-step problems\ndemanding deeper reasoning; and (3) Thinking-Induced Curriculum Fine-Tuning, a\nstructured pipeline that progressively trains the model from scaffolded\nreasoning to standalone inference. By leveraging the model's self-synthesis\ncapability, MindGYM achieves high data efficiency (e.g., +16% gains on\nMathVision-Mini with only 400 samples), computational efficiency (reducing both\ntraining and inference costs), and robust generalization across tasks.\nExtensive evaluations on seven benchmarks demonstrate superior performance over\nstrong baselines, with notable improvements (+15.77% win rates) in reasoning\ndepth and breadth validated via GPT-based scoring. MindGYM underscores the\nviability of self-challenging for refining VLM capabilities while minimizing\nhuman intervention and resource demands. Code and data are released to advance\nmultimodal reasoning research.\n","authors":["Zhe Xu","Daoyuan Chen","Zhenqing Ling","Yaliang Li","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2503.09499v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2502.12292v2","updated":"2025-03-12T15:58:01Z","published":"2025-02-17T20:01:08Z","title":"Independence Tests for Language Models","summary":"  We consider the following problem: given the weights of two models, can we\ntest whether they were trained independently -- i.e., from independent random\ninitializations? We consider two settings: constrained and unconstrained. In\nthe constrained setting, we make assumptions about model architecture and\ntraining and propose a family of statistical tests that yield exact p-values\nwith respect to the null hypothesis that the models are trained from\nindependent random initializations. These p-values are valid regardless of the\ncomposition of either model's training data; we compute them by simulating\nexchangeable copies of each model under our assumptions and comparing various\nsimilarity measures of weights and activations between the original two models\nversus these copies. We report the p-values from these tests on pairs of 21\nopen-weight models (210 total pairs) and correctly identify all pairs of\nnon-independent models. Our tests remain effective even if one model was\nfine-tuned for many tokens. In the unconstrained setting, where we make no\nassumptions about training procedures, can change model architecture, and allow\nfor adversarial evasion attacks, the previous tests no longer work. Instead, we\npropose a new test which matches hidden activations between two models, and\nwhich is robust to adversarial transformations and to changes in model\narchitecture. The test can also do localized testing: identifying specific\nnon-independent components of models. Though we no longer obtain exact p-values\nfrom this, empirically we find it behaves as one and reliably identifies\nnon-independent models. Notably, we can use the test to identify specific parts\nof one model that are derived from another (e.g., how Llama 3.1-8B was pruned\nto initialize Llama 3.2-3B, or shared layers between Mistral-7B and\nStripedHyena-7B), and it is even robust to retraining individual layers of\neither model from scratch.\n","authors":["Sally Zhu","Ahmed Ahmed","Rohith Kuditipudi","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2502.12292v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20129v2","updated":"2025-03-12T15:47:08Z","published":"2025-02-27T14:24:51Z","title":"Finite State Automata Inside Transformers with Chain-of-Thought: A\n  Mechanistic Study on State Tracking","summary":"  Chain-of-Thought (CoT) significantly enhances the performance of large\nlanguage models (LLMs) across a wide range of tasks, and prior research shows\nthat CoT can theoretically increase expressiveness. However, there is limited\nmechanistic understanding of the algorithms that Transformer+CoT can learn. In\nthis work, we (1) evaluate the state tracking capabilities of Transformer+CoT\nand its variants, confirming the effectiveness of CoT. (2) Next, we identify\nthe circuit, a subset of model components, responsible for tracking the world\nstate, finding that late-layer MLP neurons play a key role. We propose two\nmetrics, compression and distinction, and show that the neuron sets for each\nstate achieve nearly 100% accuracy, providing evidence of an implicit finite\nstate automaton (FSA) embedded within the model. (3) Additionally, we explore\nthree realistic settings: skipping intermediate steps, introducing data noise,\nand testing length generalization. Our results demonstrate that Transformer+CoT\nlearns robust algorithms (FSA), highlighting its resilience in challenging\nscenarios.\n","authors":["Yifan Zhang","Wenyu Du","Dongming Jin","Jie Fu","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2502.20129v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09481v1","updated":"2025-03-12T15:36:50Z","published":"2025-03-12T15:36:50Z","title":"BAMBI: Developing Baby Language Models for Italian","summary":"  This paper presents BAMBI (BAby language Models Boostrapped for Italian), a\nseries of Baby Language Models (BabyLMs) trained on data that mimic the\nlinguistic input received by a five-year-old Italian-speaking child. The BAMBI\nmodels are tested using a benchmark specifically designed to evaluate language\nmodels, which takes into account the amount of training input the models\nreceived. The BAMBI models are compared against a large language model (LLM)\nand a multimodal language model (VLM) to study the contribution of\nextralinguistic information for language acquisition. The results of our\nevaluation align with the existing literature on English language models,\nconfirming that while reduced training data support the development of\nrelatively robust syntactic competence, they are insufficient for fostering\nsemantic understanding. However, the gap between the training resources (data\nand computation) of the BAMBI models and the LLMs is not fully reflected in\ntheir performance: despite LLMs' massive training, their performance is not\nmuch better than that of BAMBI models. This suggests that strategies beyond\nscaling training resources, such as data curation, inclusion of multimodal\ninput, and other training strategies such as curriculum learning, could play a\ncrucial role in shaping model performance.\n","authors":["Alice Suozzi","Luca Capone","Gianluca E. Lebani","Alessandro Lenci"],"pdf_url":"https://arxiv.org/pdf/2503.09481v1.pdf","comment":"20 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.05891v3","updated":"2025-03-12T15:02:43Z","published":"2025-03-07T19:24:59Z","title":"MastermindEval: A Simple But Scalable Reasoning Benchmark","summary":"  Recent advancements in large language models (LLMs) have led to remarkable\nperformance across a wide range of language understanding and mathematical\ntasks. As a result, increasing attention has been given to assessing the true\nreasoning capabilities of LLMs, driving research into commonsense, numerical,\nlogical, and qualitative reasoning. However, with the rapid progress of\nreasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been\na growing demand for reasoning benchmarks that can keep pace with ongoing model\ndevelopments. In this paper, we introduce MastermindEval, a simple, scalable,\nand interpretable deductive reasoning benchmark inspired by the board game\nMastermind. Our benchmark supports two evaluation paradigms: (1) agentic\nevaluation, in which the model autonomously plays the game, and (2) deductive\nreasoning evaluation, in which the model is given a pre-played game state with\nonly one possible valid code to infer. In our experimental results we (1) find\nthat even easy Mastermind instances are difficult for current models and (2)\ndemonstrate that the benchmark is scalable to possibly more advanced models in\nthe future Furthermore, we investigate possible reasons why models cannot\ndeduce the final solution and find that current models are limited in deducing\nthe concealed code as the number of statement to combine information from is\nincreasing.\n","authors":["Jonas Golde","Patrick Haller","Fabio Barth","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2503.05891v3.pdf","comment":"9 pages, 2 figures, 4 tables. In: ICLR 2025 Workshop on Reasoning and\n  Planning for Large Language Models"},{"id":"http://arxiv.org/abs/2503.09454v1","updated":"2025-03-12T14:57:08Z","published":"2025-03-12T14:57:08Z","title":"Explicit Learning and the LLM in Machine Translation","summary":"  This study explores the capacity of large language models (LLMs) for explicit\nlearning, a process involving the assimilation of metalinguistic explanations\nto carry out language tasks. Using constructed languages generated by\ncryptographic means as controlled test environments, we designed experiments to\nassess an LLM's ability to explicitly learn and apply grammar rules. Our\nresults demonstrate that while LLMs possess a measurable capacity for explicit\nlearning, this ability diminishes as the complexity of the linguistic phenomena\nat hand increases. Supervised fine-tuning on chains of thought significantly\nenhances LLM performance but struggles to generalize to typologically novel or\nmore complex linguistic features. These findings point to the need for more\ndiverse training sets and alternative fine-tuning strategies to further improve\nexplicit learning by LLMs.\n","authors":["Malik Marmonier","Rachel Bawden","Benoît Sagot"],"pdf_url":"https://arxiv.org/pdf/2503.09454v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04789v2","updated":"2025-03-12T14:42:18Z","published":"2025-02-28T06:46:53Z","title":"Ext2Gen: Alignment through Unified Extraction and Generation for Robust\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances LLMs by integrating external\nknowledge, but generation remains fragile due to the uncertain placement of\nrelevant chunks and retrieval-induced information overload, leading to\nhallucinations. We propose Ext2Gen, a novel extract-then-generate model that\nenhances RAG robustness by first extracting query-relevant sentences before\ngenerating answers. To optimize this model, we employ preference alignment\nthrough pairwise feedback learning, enabling the model to generate robust\nanswers regardless of variations in retrieval results. Extensive experiments\ndemonstrate that Ext2Gen effectively identifies query-relevant sentences with\nhigh precision and recall, leading to highly reliable answers. Furthermore,\ndeploying our model in a RAG environment reveals that it not only boosts the\nperformance of the base LLM but also synergizes with advanced retrieval\nstrategies like query expansion. The model is available at\nhttps://huggingface.co/DISLab/Ext2Gen-8B-R2.\n","authors":["Hwanjun Song","Jeonghwan Choi","Minseok Kim"],"pdf_url":"https://arxiv.org/pdf/2503.04789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09443v1","updated":"2025-03-12T14:41:10Z","published":"2025-03-12T14:41:10Z","title":"Florenz: Scaling Laws for Systematic Generalization in Vision-Language\n  Models","summary":"  Cross-lingual transfer enables vision-language models (VLMs) to perform\nvision tasks in various languages with training data only in one language.\nCurrent approaches rely on large pre-trained multilingual language models.\nHowever, they face the curse of multilinguality, sacrificing downstream task\nperformance for multilingual capabilities, struggling with lexical ambiguities,\nand falling behind recent advances. In this work, we study the scaling laws of\nsystematic generalization with monolingual VLMs for multilingual tasks,\nfocusing on the impact of model size and seen training samples. We propose\nFlorenz, a monolingual encoder-decoder VLM with 0.4B to 11.2B parameters\ncombining the pre-trained VLM Florence-2 and the large language model Gemma-2.\nFlorenz is trained with varying compute budgets on a synthetic dataset that\nfeatures intentionally incomplete language coverage for image captioning, thus,\ntesting generalization from the fully covered translation task. We show that\nnot only does indirectly learning unseen task-language pairs adhere to a\nscaling law, but also that with our data generation pipeline and the proposed\nFlorenz model family, image captioning abilities can emerge in a specific\nlanguage even when only data for the translation task is available. Fine-tuning\non a mix of downstream datasets yields competitive performance and demonstrates\npromising scaling trends in multimodal machine translation (Multi30K, CoMMuTE),\nlexical disambiguation (CoMMuTE), and image captioning (Multi30K, XM3600, COCO\nKarpathy).\n","authors":["Julian Spravil","Sebastian Houben","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2503.09443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09417v1","updated":"2025-03-12T14:15:57Z","published":"2025-03-12T14:15:57Z","title":"Towards Generating Automatic Anaphora Annotations","summary":"  Training models that can perform well on various NLP tasks require large\namounts of data, and this becomes more apparent with nuanced tasks such as\nanaphora and conference resolution. To combat the prohibitive costs of creating\nmanual gold annotated data, this paper explores two methods to automatically\ncreate datasets with coreferential annotations; direct conversion from existing\ndatasets, and parsing using multilingual models capable of handling new and\nunseen languages. The paper details the current progress on those two fronts,\nas well as the challenges the efforts currently face, and our approach to\novercoming these challenges.\n","authors":["Dima Taji","Daniel Zeman"],"pdf_url":"https://arxiv.org/pdf/2503.09417v1.pdf","comment":"6 pages, 0 figures, 2 tables"},{"id":"http://arxiv.org/abs/2501.06557v2","updated":"2025-03-12T13:59:29Z","published":"2025-01-11T14:33:57Z","title":"A Survey on Spoken Italian Datasets and Corpora","summary":"  Spoken language datasets are vital for advancing linguistic research, Natural\nLanguage Processing, and speech technology. However, resources dedicated to\nItalian, a linguistically rich and diverse Romance language, remain\nunderexplored compared to major languages like English or Mandarin. This survey\nprovides a comprehensive analysis of 66 spoken Italian datasets, highlighting\ntheir characteristics, methodologies, and applications. The datasets are\ncategorized by speech type, source and context, and demographic and linguistic\nfeatures, with a focus on their utility in fields such as Automatic Speech\nRecognition, emotion detection, and education. Challenges related to dataset\nscarcity, representativeness, and accessibility are discussed alongside\nrecommendations for enhancing dataset creation and utilization. The full\ndataset inventory is publicly accessible via GitHub and archived on Zenodo,\nserving as a valuable resource for researchers and developers. By addressing\ncurrent gaps and proposing future directions, this work aims to support the\nadvancement of Italian speech technologies and linguistic research.\n","authors":["Marco Giordano","Claudia Rinaldi"],"pdf_url":"https://arxiv.org/pdf/2501.06557v2.pdf","comment":"Published on IEEE Access Journal on Feb 2025"},{"id":"http://arxiv.org/abs/2503.09407v1","updated":"2025-03-12T13:58:43Z","published":"2025-03-12T13:58:43Z","title":"Got Compute, but No Data: Lessons From Post-training a Finnish LLM","summary":"  As LLMs gain more popularity as chatbots and general assistants, methods have\nbeen developed to enable LLMs to follow instructions and align with human\npreferences. These methods have found success in the field, but their\neffectiveness has not been demonstrated outside of high-resource languages. In\nthis work, we discuss our experiences in post-training an LLM for\ninstruction-following for English and Finnish. We use a multilingual LLM to\ntranslate instruction and preference datasets from English to Finnish. We\nperform instruction tuning and preference optimization in English and Finnish\nand evaluate the instruction-following capabilities of the model in both\nlanguages. Our results show that with a few hundred Finnish instruction samples\nwe can obtain competitive performance in Finnish instruction-following. We also\nfound that although preference optimization in English offers some\ncross-lingual benefits, we obtain our best results by using preference data\nfrom both languages. We release our model, datasets, and recipes under open\nlicenses at https://huggingface.co/LumiOpen/Poro-34B-chat-OpenAssistant\n","authors":["Elaine Zosa","Ville Komulainen","Sampo Pyysalo"],"pdf_url":"https://arxiv.org/pdf/2503.09407v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2412.07923v3","updated":"2025-03-12T13:48:12Z","published":"2024-12-10T21:09:12Z","title":"Asking Again and Again: Exploring LLM Robustness to Repeated Questions","summary":"  This study investigates whether repeating questions within prompts influences\nthe performance of large language models (LLMs). We hypothesize that\nreiterating a question within a single prompt might enhance the model's focus\non key elements of the query. We evaluate five recent LLMs -- including\nGPT-4o-mini, DeepSeek-V3, and smaller open-source models -- on three reading\ncomprehension datasets under different prompt settings, varying question\nrepetition levels (1, 3, or 5 times per prompt). Our results demonstrate that\nquestion repetition can increase models' accuracy by up to $6\\%$. However,\nacross all models, settings, and datasets, we do not find the result\nstatistically significant. These findings provide insights into prompt design\nand LLM behavior, suggesting that repetition alone does not significantly\nimpact output quality.\n","authors":["Sagi Shaier","Mario Sanz-Guerrero","Katharina von der Wense"],"pdf_url":"https://arxiv.org/pdf/2412.07923v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06552v2","updated":"2025-03-12T13:42:46Z","published":"2025-03-09T10:48:47Z","title":"Multimodal Programming in Computer Science with Interactive Assistance\n  Powered by Large Language Model","summary":"  LLM chatbot interfaces allow students to get instant, interactive assistance\nwith homework, but doing so carelessly may not advance educational objectives.\nIn this study, an interactive homework help system based on DeepSeek R1 is\ndeveloped and first implemented for students enrolled in a large computer\nscience beginning programming course. In addition to an assist button in a\nwell-known code editor, our assistant also has a feedback option in our\ncommand-line automatic evaluator. It wraps student work in a personalized\nprompt that advances our educational objectives without offering answers\nstraight away. We have discovered that our assistant can recognize students'\nconceptual difficulties and provide ideas, plans, and template code in\npedagogically appropriate ways. However, among other mistakes, it occasionally\nincorrectly labels the correct student code as incorrect or encourages students\nto use correct-but-lesson-inappropriate approaches, which can lead to long and\nfrustrating journeys for the students. After discussing many development and\ndeployment issues, we provide our conclusions and future actions.\n","authors":["Rajan Das Gupta","Md. Tanzib Hosain","M. F. Mridha","Salah Uddin Ahmed"],"pdf_url":"https://arxiv.org/pdf/2503.06552v2.pdf","comment":"Accepted in Proceedings of the 27th International Conference on.\n  Human-Computer Interaction, 2025"},{"id":"http://arxiv.org/abs/2501.01046v3","updated":"2025-03-12T13:36:32Z","published":"2025-01-02T04:11:23Z","title":"FED: Fast and Efficient Dataset Deduplication Framework with GPU\n  Acceleration","summary":"  Dataset deduplication plays a crucial role in enhancing data quality,\nultimately improving the training performance and efficiency of large language\nmodels. A commonly used method for data deduplication is the MinHash LSH\nalgorithm. Recently, NVIDIA introduced a GPU-based MinHash LSH deduplication\nmethod, but it remains suboptimal, leaving room for further improvement in\nprocessing efficiency. This paper proposes a GPU-accelerated deduplication\nframework, FED, that optimizes MinHash LSH for GPU clusters and leverages\ncomputationally efficient, partially reusable non-cryptographic hash functions.\nFED significantly outperforms the CPU-based deduplication tool in SlimPajama\n(using 64 logical CPU cores) by up to 107.2 times and the GPU-based tool in\nNVIDIA NeMo Curator by up to 6.3 times when processing 30 million documents on\na node with four GPUs. Notably, our method dramatically accelerates the\npreviously time-consuming MinHash signature generation phase, achieving\nspeed-ups of up to 260 compared to the CPU baseline. Despite these gains in\nefficiency, FED maintains high deduplication quality, with the duplicate\ndocument sets reaching a Jaccard similarity of over 0.96 compared to those\nidentified by the standard MinHash algorithm. In large-scale experiments, the\ndeduplication of 1.2 trillion tokens is completed in just 6 hours in a\nfour-node, 16-GPU environment. The related code is publicly available on GitHub\n(\\href{https://github.com/mcrl/FED}{https://github.com/mcrl/FED}).\n","authors":["Youngjun Son","Chaewon Kim","Jaejin Lee"],"pdf_url":"https://arxiv.org/pdf/2501.01046v3.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.19649v3","updated":"2025-03-12T13:31:36Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18444v2","updated":"2025-03-12T13:18:04Z","published":"2024-10-24T05:40:07Z","title":"Evaluating Automatic Speech Recognition Systems for Korean\n  Meteorological Experts","summary":"  This paper explores integrating Automatic Speech Recognition (ASR) into\nnatural language query systems to improve weather forecasting efficiency for\nKorean meteorologists. We address challenges in developing ASR systems for the\nKorean weather domain, specifically specialized vocabulary and Korean\nlinguistic intricacies. To tackle these issues, we constructed an evaluation\ndataset of spoken queries recorded by native Korean speakers. Using this\ndataset, we assessed various configurations of a multilingual ASR model family,\nidentifying performance limitations related to domain-specific terminology. We\nthen implemented a simple text-to-speech-based data augmentation method, which\nimproved the recognition of specialized terms while maintaining general-domain\nperformance. Our contributions include creating a domain-specific dataset,\ncomprehensive ASR model evaluations, and an effective augmentation technique.\nWe believe our work provides a foundation for future advancements in ASR for\nthe Korean weather forecasting domain.\n","authors":["ChaeHun Park","Hojun Cho","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2410.18444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17448v2","updated":"2025-03-12T13:14:22Z","published":"2024-10-22T21:50:52Z","title":"In Context Learning and Reasoning for Symbolic Regression with Large\n  Language Models","summary":"  Large Language Models (LLMs) are transformer-based machine learning models\nthat have shown remarkable performance in tasks for which they were not\nexplicitly trained. Here, we explore the potential of LLMs to perform symbolic\nregression -- a machine-learning method for finding simple and accurate\nequations from datasets. We prompt GPT-4 to suggest expressions from data,\nwhich are then optimized and evaluated using external Python tools. These\nresults are fed back to GPT-4, which proposes improved expressions while\noptimizing for complexity and loss. Using chain-of-thought prompting, we\ninstruct GPT-4 to analyze the data, prior expressions, and the scientific\ncontext (expressed in natural language) for each problem before generating new\nexpressions. We evaluated the workflow in rediscovery of five well-known\nscientific equations from experimental data, and on an additional dataset\nwithout a known equation. GPT-4 successfully rediscovered all five equations,\nand in general, performed better when prompted to use a scratchpad and consider\nscientific context. We demonstrate how strategic prompting improves the model's\nperformance and how the natural language interface simplifies integrating\ntheory with data. We also observe how theory can sometimes offset noisy data\nand, in other cases, data can make up for poor context. Although this approach\ndoes not outperform established SR programs where target equations are more\ncomplex, LLMs can nonetheless iterate toward improved solutions while following\ninstructions and incorporating scientific context in natural language.\n","authors":["Samiha Sharlin","Tyler R. Josephson"],"pdf_url":"https://arxiv.org/pdf/2410.17448v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09358v1","updated":"2025-03-12T13:00:57Z","published":"2025-03-12T13:00:57Z","title":"RetSTA: An LLM-Based Approach for Standardizing Clinical Fundus Image\n  Reports","summary":"  Standardization of clinical reports is crucial for improving the quality of\nhealthcare and facilitating data integration. The lack of unified standards,\nincluding format, terminology, and style, is a great challenge in clinical\nfundus diagnostic reports, which increases the difficulty for large language\nmodels (LLMs) to understand the data. To address this, we construct a bilingual\nstandard terminology, containing fundus clinical terms and commonly used\ndescriptions in clinical diagnosis. Then, we establish two models,\nRetSTA-7B-Zero and RetSTA-7B. RetSTA-7B-Zero, fine-tuned on an augmented\ndataset simulating clinical scenarios, demonstrates powerful standardization\nbehaviors. However, it encounters a challenge of limitation to cover a wider\nrange of diseases. To further enhance standardization performance, we build\nRetSTA-7B, which integrates a substantial amount of standardized data generated\nby RetSTA-7B-Zero along with corresponding English data, covering diverse\ncomplex clinical scenarios and achieving report-level standardization for the\nfirst time. Experimental results demonstrate that RetSTA-7B outperforms other\ncompared LLMs in bilingual standardization task, which validates its superior\nperformance and generalizability. The checkpoints are available at\nhttps://github.com/AB-Story/RetSTA-7B.\n","authors":["Jiushen Cai","Weihang Zhang","Hanruo Liu","Ningli Wang","Huiqi Li"],"pdf_url":"https://arxiv.org/pdf/2503.09358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09348v1","updated":"2025-03-12T12:49:31Z","published":"2025-03-12T12:49:31Z","title":"MOAT: Evaluating LMMs for Capability Integration and Instruction\n  Grounding","summary":"  Large multimodal models (LMMs) have demonstrated significant potential as\ngeneralists in vision-language (VL) tasks. However, there remains a significant\ngap between state-of-the-art LMMs and human performance when it comes to\ncomplex tasks that require a combination of fundamental VL capabilities, as\nwell as tasks involving the grounding of complex instructions. To thoroughly\ninvestigate the human-LMM gap and its underlying causes, we propose MOAT, a\ndiverse benchmark with complex real-world VL tasks that are challenging for\nLMMs. Specifically, the tasks in MOAT require LMMs to engage in generalist\nproblem solving by integrating fundamental VL capabilities such as reading\ntext, counting, understanding spatial relations, grounding textual and visual\ninstructions, etc. All these abilities fit into a taxonomy proposed by us that\ncontains 10 fundamental VL capabilities, enabling MOAT to provide a\nfine-grained view of LMMs' strengths and weaknesses. Besides, MOAT is the first\nbenchmark to explicitly evaluate LMMs' ability to ground complex text and\nvisual instructions, which is essential to many real-world applications. We\nevaluate over 20 proprietary and open source LMMs, as well as humans, on MOAT,\nand found that humans achieved 82.7% accuracy while the best performing LMM\n(OpenAI o1) achieved only 38.8%. To guide future model development, we analyze\ncommon trends in our results and discuss the underlying causes of observed\nperformance gaps between LMMs and humans, focusing on which VL capability forms\nthe bottleneck in complex tasks, whether test time scaling improves performance\non MOAT, and how tiling harms LMMs' capability to count. Code and data are\navailable at https://cambrian-yzt.github.io/MOAT.\n","authors":["Zhoutong Ye","Mingze Sun","Huan-ang Gao","Chun Yu","Yuanchun Shi"],"pdf_url":"https://arxiv.org/pdf/2503.09348v1.pdf","comment":"Project page: https://cambrian-yzt.github.io/MOAT"},{"id":"http://arxiv.org/abs/2503.09347v1","updated":"2025-03-12T12:49:02Z","published":"2025-03-12T12:49:02Z","title":"Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts","summary":"  Large Language Models (LLMs) are increasingly employed as automated\nevaluators to assess the safety of generated content, yet their reliability in\nthis role remains uncertain. This study evaluates a diverse set of 11 LLM judge\nmodels across critical safety domains, examining three key aspects:\nself-consistency in repeated judging tasks, alignment with human judgments, and\nsusceptibility to input artifacts such as apologetic or verbose phrasing. Our\nfindings reveal that biases in LLM judges can significantly distort the final\nverdict on which content source is safer, undermining the validity of\ncomparative evaluations. Notably, apologetic language artifacts alone can skew\nevaluator preferences by up to 98\\%. Contrary to expectations, larger models do\nnot consistently exhibit greater robustness, while smaller models sometimes\nshow higher resistance to specific artifacts. To mitigate LLM evaluator\nrobustness issues, we investigate jury-based evaluations aggregating decisions\nfrom multiple models. Although this approach both improves robustness and\nenhances alignment to human judgements, artifact sensitivity persists even with\nthe best jury configurations. These results highlight the urgent need for\ndiversified, artifact-resistant methodologies to ensure reliable safety\nassessments.\n","authors":["Hongyu Chen","Seraphina Goldfarb-Tarrant"],"pdf_url":"https://arxiv.org/pdf/2503.09347v1.pdf","comment":"8 pages, preprint"},{"id":"http://arxiv.org/abs/2503.09341v1","updated":"2025-03-12T12:36:45Z","published":"2025-03-12T12:36:45Z","title":"An Evaluation of LLMs for Detecting Harmful Computing Terms","summary":"  Detecting harmful and non-inclusive terminology in technical contexts is\ncritical for fostering inclusive environments in computing. This study explores\nthe impact of model architecture on harmful language detection by evaluating a\ncurated database of technical terms, each paired with specific use cases. We\ntested a range of encoder, decoder, and encoder-decoder language models,\nincluding BERT-base-uncased, RoBERTa large-mnli, Gemini Flash 1.5 and 2.0,\nGPT-4, Claude AI Sonnet 3.5, T5-large, and BART-large-mnli. Each model was\npresented with a standardized prompt to identify harmful and non-inclusive\nlanguage across 64 terms. Results reveal that decoder models, particularly\nGemini Flash 2.0 and Claude AI, excel in nuanced contextual analysis, while\nencoder models like BERT exhibit strong pattern recognition but struggle with\nclassification certainty. We discuss the implications of these findings for\nimproving automated detection tools and highlight model-specific strengths and\nlimitations in fostering inclusive communication in technical domains.\n","authors":["Joshua Jacas","Hana Winchester","Alicia Boyd","Brittany Johnson"],"pdf_url":"https://arxiv.org/pdf/2503.09341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09338v1","updated":"2025-03-12T12:33:20Z","published":"2025-03-12T12:33:20Z","title":"Investigating User Perspectives on Differentially Private Text\n  Privatization","summary":"  Recent literature has seen a considerable uptick in $\\textit{Differentially\nPrivate Natural Language Processing}$ (DP NLP). This includes DP text\nprivatization, where potentially sensitive input texts are transformed under DP\nto achieve privatized output texts that ideally mask sensitive information\n$\\textit{and}$ maintain original semantics. Despite continued work to address\nthe open challenges in DP text privatization, there remains a scarcity of work\naddressing user perceptions of this technology, a crucial aspect which serves\nas the final barrier to practical adoption. In this work, we conduct a survey\nstudy with 721 laypersons around the globe, investigating how the factors of\n$\\textit{scenario}$, $\\textit{data sensitivity}$, $\\textit{mechanism type}$,\nand $\\textit{reason for data collection}$ impact user preferences for text\nprivatization. We learn that while all these factors play a role in influencing\nprivacy decisions, users are highly sensitive to the utility and coherence of\nthe private output texts. Our findings highlight the socio-technical factors\nthat must be considered in the study of DP NLP, opening the door to further\nuser-based investigations going forward.\n","authors":["Stephen Meisenbacher","Alexandra Klymenko","Alexander Karpp","Florian Matthes"],"pdf_url":"https://arxiv.org/pdf/2503.09338v1.pdf","comment":"20 pages, 5 figures, 10 tables. Accepted to PrivateNLP 2025"},{"id":"http://arxiv.org/abs/2503.09326v1","updated":"2025-03-12T12:20:31Z","published":"2025-03-12T12:20:31Z","title":"A Survey on Enhancing Causal Reasoning Ability of Large Language Models","summary":"  Large language models (LLMs) have recently shown remarkable performance in\nlanguage tasks and beyond. However, due to their limited inherent causal\nreasoning ability, LLMs still face challenges in handling tasks that require\nrobust causal reasoning ability, such as health-care and economic analysis. As\na result, a growing body of research has focused on enhancing the causal\nreasoning ability of LLMs. Despite the booming research, there lacks a survey\nto well review the challenges, progress and future directions in this area. To\nbridge this significant gap, we systematically review literature on how to\nstrengthen LLMs' causal reasoning ability in this paper. We start from the\nintroduction of background and motivations of this topic, followed by the\nsummarisation of key challenges in this area. Thereafter, we propose a novel\ntaxonomy to systematically categorise existing methods, together with detailed\ncomparisons within and between classes of methods. Furthermore, we summarise\nexisting benchmarks and evaluation metrics for assessing LLMs' causal reasoning\nability. Finally, we outline future research directions for this emerging\nfield, offering insights and inspiration to researchers and practitioners in\nthe area.\n","authors":["Xin Li","Zhuo Cai","Shoujin Wang","Kun Yu","Fang Chen"],"pdf_url":"https://arxiv.org/pdf/2503.09326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09313v1","updated":"2025-03-12T12:04:05Z","published":"2025-03-12T12:04:05Z","title":"xVLM2Vec: Adapting LVLM-based embedding models to multilinguality using\n  Self-Knowledge Distillation","summary":"  In the current literature, most embedding models are based on the\nencoder-only transformer architecture to extract a dense and meaningful\nrepresentation of the given input, which can be a text, an image, and more.\nWith the recent advances in language modeling thanks to the introduction of\nLarge Language Models, the possibility of extracting embeddings from these\nlarge and extensively trained models has been explored. However, current\nstudies focus on textual embeddings in English, which is also the main language\non which these models have been trained. Furthermore, there are very few models\nthat consider multimodal and multilingual input. In light of this, we propose\nan adaptation methodology for Large Vision-Language Models trained on English\nlanguage data to improve their performance in extracting multilingual and\nmultimodal embeddings. Finally, we design and introduce a benchmark to evaluate\nthe effectiveness of multilingual and multimodal embedding models.\n","authors":["Elio Musacchio","Lucia Siciliani","Pierpaolo Basile","Giovanni Semeraro"],"pdf_url":"https://arxiv.org/pdf/2503.09313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13329v2","updated":"2025-03-12T11:59:18Z","published":"2024-07-18T09:29:33Z","title":"CiteFusion: An Ensemble Framework for Citation Intent Classification\n  Harnessing Dual-Model Binary Couples and SHAP Analyses","summary":"  Understanding the motivations underlying scholarly citations is critical for\nevaluating research impact and fostering transparent scholarly communication.\nThis study introduces CiteFusion, an ensemble framework designed to address the\nmulticlass Citation Intent Classification (CIC) task on benchmark datasets,\nSciCite and ACL-ARC. The framework decomposes the task into binary\nclassification subtasks, utilizing complementary pairs of SciBERT and XLNet\nmodels fine-tuned independently for each citation intent. These base models are\naggregated through a feedforward neural network meta-classifier, ensuring\nrobust performance in imbalanced and data-scarce scenarios. To enhance\ninterpretability, SHAP (SHapley Additive exPlanations) is employed to analyze\ntoken-level contributions and interactions among base models, providing\ntransparency into classification dynamics. We further investigate the semantic\nrole of structural context by incorporating section titles into input\nsentences, demonstrating their significant impact on classification accuracy\nand model reliability. Experimental results show that CiteFusion achieves\nstate-of-the-art performance, with Macro-F1 scores of 89.60% on SciCite and\n76.24% on ACL-ARC. The original intents from both datasets are mapped to\nCitation Typing Ontology (CiTO) object properties to ensure interoperability\nand reusability. This mapping highlights overlaps between the two datasets\nlabels, enhancing their understandability and reusability. Finally, we release\na web-based application that classifies citation intents leveraging CiteFusion\nmodels developed on SciCite.\n","authors":["Lorenzo Paolini","Sahar Vahdati","Angelo Di Iorio","Robert Wardenga","Ivan Heibi","Silvio Peroni"],"pdf_url":"https://arxiv.org/pdf/2407.13329v2.pdf","comment":"Submitted to Scientometrics Journal"},{"id":"http://arxiv.org/abs/2503.07996v2","updated":"2025-03-12T11:41:45Z","published":"2025-03-11T02:52:39Z","title":"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic","summary":"  Recent advancements in Text-to-SQL systems have improved the conversion of\nnatural language queries into SQL, but challenges remain in ensuring accuracy\nand reliability. While self-correction techniques refine outputs, they often\nintroduce new errors. Existing methods focused on execution feedback mainly\naddress syntax issues, leaving semantic errors -- where the query's logic fails\nto align with the user's intent -- largely unaddressed. We propose a novel\napproach combining structured execution feedback with a trained critic agent\nthat provides detailed, interpretable critiques. This method effectively\nidentifies and corrects both syntactic and semantic errors, enhancing accuracy\nand interpretability. Experimental results show significant improvements on two\nmajor Text-to-SQL benchmarks, Spider and BIRD, demonstrating the effectiveness\nof our approach.\n","authors":["Jikai Chen","Leilei Gan"],"pdf_url":"https://arxiv.org/pdf/2503.07996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09289v1","updated":"2025-03-12T11:35:04Z","published":"2025-03-12T11:35:04Z","title":"Unmask It! AI-Generated Product Review Detection in Dravidian Languages","summary":"  The rise of Generative AI has led to a surge in AI-generated reviews, often\nposing a serious threat to the credibility of online platforms. Reviews serve\nas the primary source of information about products and services. Authentic\nreviews play a vital role in consumer decision-making. The presence of\nfabricated content misleads consumers, undermines trust and facilitates\npotential fraud in digital marketplaces. This study focuses on detecting\nAI-generated product reviews in Tamil and Malayalam, two low-resource languages\nwhere research in this domain is relatively under-explored. We worked on a\nrange of approaches - from traditional machine learning methods to advanced\ntransformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and\nMalayalamBERT. Our findings highlight the effectiveness of leveraging the\nstate-of-the-art transformers in accurately identifying AI-generated content,\ndemonstrating the potential in enhancing the detection of fake reviews in\nlow-resource language settings.\n","authors":["Somsubhra De","Advait Vats"],"pdf_url":"https://arxiv.org/pdf/2503.09289v1.pdf","comment":"10 pages, 9 figures, Accepted to DravidianLangTech Workshop\n  proceedings at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08102v2","updated":"2025-03-12T11:31:31Z","published":"2025-03-11T07:05:52Z","title":"AI-native Memory 2.0: Second Me","summary":"  Human interaction with the external world fundamentally involves the exchange\nof personal memory, whether with other individuals, websites, applications, or,\nin the future, AI agents. A significant portion of this interaction is\nredundant, requiring users to repeatedly provide the same information across\ndifferent contexts. Existing solutions, such as browser-stored credentials,\nautofill mechanisms, and unified authentication systems, have aimed to mitigate\nthis redundancy by serving as intermediaries that store and retrieve commonly\nused user data. The advent of large language models (LLMs) presents an\nopportunity to redefine memory management through an AI-native paradigm: SECOND\nME. SECOND ME acts as an intelligent, persistent memory offload system that\nretains, organizes, and dynamically utilizes user-specific knowledge. By\nserving as an intermediary in user interactions, it can autonomously generate\ncontext-aware responses, prefill required information, and facilitate seamless\ncommunication with external systems, significantly reducing cognitive load and\ninteraction friction. Unlike traditional memory storage solutions, SECOND ME\nextends beyond static data retention by leveraging LLM-based memory\nparameterization. This enables structured organization, contextual reasoning,\nand adaptive knowledge retrieval, facilitating a more systematic and\nintelligent approach to memory management. As AI-driven personal agents like\nSECOND ME become increasingly integrated into digital ecosystems, SECOND ME\nfurther represents a critical step toward augmenting human-world interaction\nwith persistent, contextually aware, and self-optimizing memory systems. We\nhave open-sourced the fully localizable deployment system at GitHub:\nhttps://github.com/Mindverse/Second-Me.\n","authors":["Jiale Wei","Xiang Ying","Tao Gao","Fangyi Bao","Felix Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09249v1","updated":"2025-03-12T10:43:33Z","published":"2025-03-12T10:43:33Z","title":"Considering Length Diversity in Retrieval-Augmented Summarization","summary":"  This study investigates retrieval-augmented summarization by specifically\nexamining the impact of exemplar summary lengths under length constraints, not\ncovered by previous work. We propose a Diverse Length-aware Maximal Marginal\nRelevance (DL-MMR) algorithm to better control summary lengths. This algorithm\ncombines the query relevance with diverse target lengths in retrieval-augmented\nsummarization. Unlike previous methods that necessitate exhaustive exemplar\nexemplar relevance comparisons using MMR, DL-MMR considers the exemplar target\nlength as well and avoids comparing exemplars to each other, thereby reducing\ncomputational cost and conserving memory during the construction of an exemplar\npool. Experimental results showed the effectiveness of DL-MMR, which considers\nlength diversity, compared to the original MMR algorithm. DL-MMR additionally\nshowed the effectiveness in memory saving of 781,513 times and computational\ncost reduction of 500,092 times, while maintaining the same level of\ninformativeness.\n","authors":[" Juseon-Do","Jaesung Hwang","Jingun Kwon","Hidetaka Kamigaito","Manabu Okumura"],"pdf_url":"https://arxiv.org/pdf/2503.09249v1.pdf","comment":"12 pages, accepted to NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2410.23746v3","updated":"2025-03-12T10:08:22Z","published":"2024-10-31T09:01:25Z","title":"DetectRL: Benchmarking LLM-Generated Text Detection in Real-World\n  Scenarios","summary":"  Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xinyi Yang","Yulin Yuan","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2410.23746v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)"},{"id":"http://arxiv.org/abs/2503.09219v1","updated":"2025-03-12T10:06:03Z","published":"2025-03-12T10:06:03Z","title":"Rethinking Prompt-based Debiasing in Large Language Models","summary":"  Investigating bias in large language models (LLMs) is crucial for developing\ntrustworthy AI. While prompt-based through prompt engineering is common, its\neffectiveness relies on the assumption that models inherently understand\nbiases. Our study systematically analyzed this assumption using the BBQ and\nStereoSet benchmarks on both open-source models as well as commercial GPT\nmodel. Experimental results indicate that prompt-based is often superficial;\nfor instance, the Llama2-7B-Chat model misclassified over 90% of unbiased\ncontent as biased, despite achieving high accuracy in identifying bias issues\non the BBQ dataset. Additionally, specific evaluation and question settings in\nbias benchmarks often lead LLMs to choose \"evasive answers\", disregarding the\ncore of the question and the relevance of the response to the context.\nMoreover, the apparent success of previous methods may stem from flawed\nevaluation metrics. Our research highlights a potential \"false prosperity\" in\nprompt-base efforts and emphasizes the need to rethink bias metrics to ensure\ntruly trustworthy AI.\n","authors":["Xinyi Yang","Runzhe Zhan","Derek F. Wong","Shu Yang","Junchao Wu","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2503.09219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09218v1","updated":"2025-03-12T10:05:05Z","published":"2025-03-12T10:05:05Z","title":"N2C2: Nearest Neighbor Enhanced Confidence Calibration for Cross-Lingual\n  In-Context Learning","summary":"  Recent advancements of in-context learning (ICL) show language models can\nsignificantly improve their performance when demonstrations are provided.\nHowever, little attention has been paid to model calibration and prediction\nconfidence of ICL in cross-lingual scenarios. To bridge this gap, we conduct a\nthorough analysis of ICL for cross-lingual sentiment classification. Our\nfindings suggest that ICL performs poorly in cross-lingual scenarios,\nexhibiting low accuracy and presenting high calibration errors. In response, we\npropose a novel approach, N2C2, which employs a -nearest neighbors augmented\nclassifier for prediction confidence calibration. N2C2 narrows the prediction\ngap by leveraging a datastore of cached few-shot instances. Specifically, N2C2\nintegrates the predictions from the datastore and incorporates confidence-aware\ndistribution, semantically consistent retrieval representation, and adaptive\nneighbor combination modules to effectively utilize the limited number of\nsupporting instances. Evaluation on two multilingual sentiment classification\ndatasets demonstrates that N2C2 outperforms traditional ICL. It surpasses fine\ntuning, prompt tuning and recent state-of-the-art methods in terms of accuracy\nand calibration errors.\n","authors":["Jie He","Simon Yu","Deyi Xiong","Víctor Gutiérrez-Basulto","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2503.09218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09211v1","updated":"2025-03-12T10:00:09Z","published":"2025-03-12T10:00:09Z","title":"Why LLMs Cannot Think and How to Fix It","summary":"  This paper elucidates that current state-of-the-art Large Language Models\n(LLMs) are fundamentally incapable of making decisions or developing \"thoughts\"\nwithin the feature space due to their architectural constraints. We establish a\ndefinition of \"thought\" that encompasses traditional understandings of that\nterm and adapt it for application to LLMs. We demonstrate that the\narchitectural design and language modeling training methodology of contemporary\nLLMs inherently preclude them from engaging in genuine thought processes. Our\nprimary focus is on this theoretical realization rather than practical insights\nderived from experimental data. Finally, we propose solutions to enable thought\nprocesses within the feature space and discuss the broader implications of\nthese architectural modifications.\n","authors":["Marius Jahrens","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2503.09211v1.pdf","comment":"Original conference submission for neurips 2024"},{"id":"http://arxiv.org/abs/2410.01824v2","updated":"2025-03-12T09:55:22Z","published":"2024-09-16T16:03:08Z","title":"AI Conversational Interviewing: Transforming Surveys with LLMs as\n  Adaptive Interviewers","summary":"  Traditional methods for eliciting people's opinions face a trade-off between\ndepth and scale: structured surveys enable large-scale data collection but\nlimit respondents' ability to voice their opinions in their own words, while\nconversational interviews provide deeper insights but are resource-intensive.\nThis study explores the potential of replacing human interviewers with large\nlanguage models (LLMs) to conduct scalable conversational interviews. Our goal\nis to assess the performance of AI Conversational Interviewing and to identify\nopportunities for improvement in a controlled environment. We conducted a\nsmall-scale, in-depth study with university students who were randomly assigned\nto a conversational interview by either AI or human interviewers, both\nemploying identical questionnaires on political topics. Various quantitative\nand qualitative measures assessed interviewer adherence to guidelines, response\nquality, participant engagement, and overall interview efficacy. The findings\nindicate the viability of AI Conversational Interviewing in producing quality\ndata comparable to traditional methods, with the added benefit of scalability.\nWe publish our data and materials for re-use and present specific\nrecommendations for effective implementation.\n","authors":["Alexander Wuttke","Matthias Aßenmacher","Christopher Klamm","Max M. Lang","Quirin Würschinger","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2410.01824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09205v1","updated":"2025-03-12T09:48:38Z","published":"2025-03-12T09:48:38Z","title":"Quality Over Quantity? LLM-Based Curation for a Data-Efficient\n  Audio-Video Foundation Model","summary":"  Integrating audio and visual data for training multimodal foundational models\nremains challenging. We present Audio-Video Vector Alignment (AVVA), which\naligns audiovisual (AV) scene content beyond mere temporal synchronization via\na Large Language Model (LLM)-based data curation pipeline. Specifically, AVVA\nscores and selects high-quality training clips using Whisper (speech-based\naudio foundation model) for audio and DINOv2 for video within a dual-encoder\ncontrastive learning framework. Evaluations on AudioCaps, VALOR, and VGGSound\ndemonstrate that this approach can achieve significant accuracy gains with\nsubstantially less curated data. For instance, AVVA yields a 7.6% improvement\nin top-1 accuracy for audio-to-video retrieval on VGGSound compared to\nImageBind, despite training on only 192 hours of carefully filtered data (vs.\n5800+ hours). Moreover, an ablation study highlights that trading data quantity\nfor data quality improves performance, yielding respective top-3 accuracy\nincreases of 47.8, 48.4, and 58.0 percentage points on AudioCaps, VALOR, and\nVGGSound over uncurated baselines. While these results underscore AVVA's data\nefficiency, we also discuss the overhead of LLM-driven curation and how it may\nbe scaled or approximated in larger domains. Overall, AVVA provides a viable\npath toward more robust, text-free audiovisual learning with improved retrieval\naccuracy.\n","authors":["Ali Vosoughi","Dimitra Emmanouilidou","Hannes Gamper"],"pdf_url":"https://arxiv.org/pdf/2503.09205v1.pdf","comment":"5 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.09202v1","updated":"2025-03-12T09:46:59Z","published":"2025-03-12T09:46:59Z","title":"Token Weighting for Long-Range Language Modeling","summary":"  Many applications of large language models (LLMs) require long-context\nunderstanding, but models continue to struggle with such tasks. We hypothesize\nthat conventional next-token prediction training could contribute to this,\nbecause each token is assigned equal weight. Yet, intuitively, the amount of\ncontext needed to predict the next token accurately varies greatly across\ndifferent data. To reflect this, we propose various novel token-weighting\nschemes that assign different weights to each training token in the loss,\nthereby generalizing existing works. For this, we categorize token-weighting\nmethods using a two-step framework which compares the confidences of a\nlong-context and short-context model to score tokens. We evaluate all methods\non multiple long-context understanding tasks and show that non-uniform loss\nweights are helpful to improve the long-context abilities of LLMs. Different\nshort-context models can be used effectively for token scoring, including\nmodels that are much smaller than the long-context model that is trained. All\nin all, this work contributes to a better understanding of the trade-offs\nlong-context language modeling faces and provides guidelines for model steering\nvia loss-weighting based on empirical evidence. The code can be found on\nGithub.\n","authors":["Falko Helm","Nico Daheim","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.09202v1.pdf","comment":"Accepted to NAACL 2025 (Findings). For the code, see\n  https://github.com/UKPLab/naacl2025-token-weighting"},{"id":"http://arxiv.org/abs/2405.04620v4","updated":"2025-03-12T09:13:15Z","published":"2024-05-07T19:05:26Z","title":"Folded Context Condensation in Path Integral Formalism for Infinite\n  Context Transformers","summary":"  In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.\n","authors":["Won-Gi Paeng","Daesuk Kwon","Kyungwon Jeong","Honggyo Suh"],"pdf_url":"https://arxiv.org/pdf/2405.04620v4.pdf","comment":"10 pages, 12 figures"},{"id":"http://arxiv.org/abs/2503.01478v4","updated":"2025-03-12T08:49:58Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v4.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2501.12106v2","updated":"2025-03-12T08:48:46Z","published":"2025-01-21T12:56:47Z","title":"Can open source large language models be used for tumor documentation in\n  Germany? -- An evaluation on urological doctors' notes","summary":"  Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.\n","authors":["Stefan Lenz","Arsenij Ustjanzew","Marco Jeray","Torsten Panholzer"],"pdf_url":"https://arxiv.org/pdf/2501.12106v2.pdf","comment":"48 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.05712v2","updated":"2025-03-12T08:45:28Z","published":"2025-01-10T05:07:27Z","title":"Multi-Step Reasoning in Korean and the Emergent Mirage","summary":"  We introduce HRMCR (HAE-RAE Multi-Step Commonsense Reasoning), a benchmark\ndesigned to evaluate large language models' ability to perform multi-step\nreasoning in culturally specific contexts, focusing on Korean. The questions\nare automatically generated via templates and algorithms, requiring LLMs to\nintegrate Korean cultural knowledge into sequential reasoning steps. Consistent\nwith prior observations on emergent abilities, our experiments reveal that\nmodels trained on fewer than \\(2 \\cdot 10^{25}\\) training FLOPs struggle to\nsolve any questions, showing near-zero performance. Beyond this threshold,\nperformance improves sharply. State-of-the-art models (e.g., O1) still score\nunder 50\\%, underscoring the difficulty of our tasks. Notably, stepwise\nanalysis suggests the observed emergent behavior may stem from compounding\nerrors across multiple steps rather than reflecting a genuinely new capability.\nWe publicly release the benchmark and commit to regularly updating the dataset\nto prevent contamination.\n","authors":["Guijin Son","Hyunwoo Ko","Dasol Choi"],"pdf_url":"https://arxiv.org/pdf/2501.05712v2.pdf","comment":"C3NLP @ NAACL 2025"},{"id":"http://arxiv.org/abs/2503.09153v1","updated":"2025-03-12T08:29:59Z","published":"2025-03-12T08:29:59Z","title":"Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News\n  Detection","summary":"  The questionable responses caused by knowledge hallucination may lead to\nLLMs' unstable ability in decision-making. However, it has never been\ninvestigated whether the LLMs' hallucination is possibly usable to generate\nnegative reasoning for facilitating the detection of fake news. This study\nproposes a novel supervised self-reinforced reasoning rectification approach -\nSR$^3$ that yields both common reasonable reasoning and wrong understandings\n(negative reasoning) for news via LLMs reflection for semantic consistency\nlearning. Upon that, we construct a negative reasoning-based news learning\nmodel called - \\emph{NRFE}, which leverages positive or negative news-reasoning\npairs for learning the semantic consistency between them. To avoid the impact\nof label-implicated reasoning, we deploy a student model - \\emph{NRFE-D} that\nonly takes news content as input to inspect the performance of our method by\ndistilling the knowledge from \\emph{NRFE}. The experimental results verified on\nthree popular fake news datasets demonstrate the superiority of our method\ncompared with three kinds of baselines including prompting on LLMs, fine-tuning\non pre-trained SLMs, and other representative fake news detection methods.\n","authors":["Chaowei Zhang","Zongling Feng","Zewei Zhang","Jipeng Qiang","Guandong Xu","Yun Li"],"pdf_url":"https://arxiv.org/pdf/2503.09153v1.pdf","comment":"9 pages, 12 figures, conference"},{"id":"http://arxiv.org/abs/2402.03848v9","updated":"2025-03-12T08:02:54Z","published":"2024-02-06T09:50:08Z","title":"ANLS* -- A Universal Document Processing Metric for Generative Large\n  Language Models","summary":"  Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, and more than 20 different GLLMs\ntogether with 3 different prompting methods using the ANLS* metric is also\nprovided, demonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In almost all cases, SFT\noutperforms other techniques and improves the state-of-the-art, sometimes by as\nmuch as $10$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric\n","authors":["David Peer","Philemon Schöpf","Volckmar Nebendahl","Alexander Rietzler","Sebastian Stabinger"],"pdf_url":"https://arxiv.org/pdf/2402.03848v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03199v4","updated":"2025-03-12T07:57:44Z","published":"2024-05-24T13:33:11Z","title":"Bayesian WeakS-to-Strong from Text Classification to Generation","summary":"  Advances in large language models raise the question of how alignment\ntechniques will adapt as models become increasingly complex and humans will\nonly be able to supervise them weakly. Weak-to-Strong mimics such a scenario\nwhere weak model supervision attempts to harness the full capabilities of a\nmuch stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by\nexploring an ensemble of weak models which simulate the variability in human\nopinions. Confidence scores are estimated using a Bayesian approach to guide\nthe WeakS-to-Strong generalization. Furthermore, we extend the application of\nWeakS-to-Strong from text classification tasks to text generation tasks where\nmore advanced strategies are investigated for supervision. Moreover, direct\npreference optimization is applied to advance the student model's preference\nlearning, beyond the basic learning framework of teacher forcing. Results\ndemonstrate the effectiveness of the proposed approach for the reliability of a\nstrong student model, showing potential for superalignment.\n","authors":["Ziyun Cui","Ziyang Zhang","Guangzhi Sun","Wen Wu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.03199v4.pdf","comment":"Accepted by ICLR2025"},{"id":"http://arxiv.org/abs/2503.02233v2","updated":"2025-03-12T07:42:04Z","published":"2025-03-04T03:16:02Z","title":"Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling","summary":"  Large language models (LLMs) frequently hallucinate due to misaligned\nself-awareness, generating erroneous outputs when addressing queries beyond\ntheir knowledge boundaries. While existing approaches mitigate hallucinations\nvia uncertainty estimation or query rejection, they suffer from computational\ninefficiency or sacrificed helpfulness. To address these issues, we propose the\nExplicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and\nslow reasoning systems to harmonize reliability and usability. The framework\nfirst employs a fast-thinking model to generate confidence-labeled responses,\nenabling immediate use of high-confidence outputs. For uncertain predictions, a\nslow refinement model conducts targeted reasoning to improve accuracy. To align\nmodel behavior with our proposed object, we propose a hybrid training pipeline,\nenhancing self-awareness without degrading task performance. Evaluations on\ndialogue state tracking tasks demonstrate that EKBM achieves superior model\nreliability over uncertainty-based baselines. Further analysis reveals that\nrefinement substantially boosts accuracy while maintaining low computational\noverhead. Our work establishes a scalable paradigm for advancing LLM\nreliability and balancing accuracy and practical utility in error-sensitive\napplications.\n","authors":["Hang Zheng","Hongshen Xu","Yuncong Liu","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02233v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09129v1","updated":"2025-03-12T07:39:27Z","published":"2025-03-12T07:39:27Z","title":"Specification languages for computational laws versus basic legal\n  principles","summary":"  We speak of a \\textit{computational law} when that law is intended to be\nenforced by software through an automated decision-making process. As digital\ntechnologies evolve to offer more solutions for public administrations, we see\nan ever-increasing number of computational laws. Traditionally, law is written\nin natural language. Computational laws, however, suffer various complications\nwhen written in natural language, such as underspecification and ambiguity\nwhich lead to a diversity of possible interpretations to be made by the coder.\nThese could potentially result into an uneven application of the law. Thus,\nresorting to formal languages to write computational laws is tempting. However,\nwriting laws in a formal language leads to further complications, for example,\nincomprehensibility for non-experts, lack of explicit motivation of the\ndecisions made, or difficulties in retrieving the data leading to the outcome.\nIn this paper, we investigate how certain legal principles fare in both\nscenarios: computational law written in natural language or written in formal\nlanguage. We use a running example from the European Union's road transport\nregulation to showcase the tensions arising, and the benefits from each\nlanguage.\n","authors":["Petia Guintchev","Joost J. Joosten","Sofia Santiago Fernández","Eric Sancho Adamson","Aleix Solé Sánchez","Marta Soria Heredia"],"pdf_url":"https://arxiv.org/pdf/2503.09129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09117v1","updated":"2025-03-12T07:08:54Z","published":"2025-03-12T07:08:54Z","title":"GRU: Mitigating the Trade-off between Unlearning and Retention for Large\n  Language Models","summary":"  Large language model (LLM) unlearning has demonstrated its essential role in\nremoving privacy and copyright-related responses, crucial for their legal and\nsafe applications. However, the pursuit of complete unlearning often comes with\nsubstantial costs due to its compromises in their general functionality,\nleading to a notorious trade-off between unlearning and retention. In examining\nthe update process for unlearning dynamically, we find gradients hold essential\ninformation for revealing this trade-off. In particular, we look at the varying\nrelationship between retention performance and directional disparities between\ngradients during unlearning. It motivates the sculpting of an update mechanism\nderived from gradients from two sources, i.e., harmful for retention and useful\nfor unlearning. Accordingly, we propose Gradient Rectified Unlearning (GRU), an\nenhanced unlearning framework controlling the updating gradients in a\ngeometry-focused and optimization-driven manner such that their side impacts on\nother, unrelated responses can be minimized. Specifically, GRU derives a\nclosed-form solution to project the unlearning gradient onto the orthogonal\nspace of that gradient harmful for retention, ensuring minimal deviation from\nits original direction under the condition that overall performance is\nretained. Comprehensive experiments are conducted to demonstrate that GRU, as a\ngeneral framework, is straightforward to implement and efficiently enhances a\nrange of baseline methods through its adaptable and compatible characteristics.\nAdditionally, experimental results show its broad effectiveness across a\ndiverse set of benchmarks for LLM unlearning.\n","authors":["Yue Wang","Qizhou Wang","Feng Liu","Wei Huang","Yali Du","Xiaojiang Du","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2503.09117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09103v1","updated":"2025-03-12T06:43:25Z","published":"2025-03-12T06:43:25Z","title":"VaxGuard: A Multi-Generator, Multi-Type, and Multi-Role Dataset for\n  Detecting LLM-Generated Vaccine Misinformation","summary":"  Recent advancements in Large Language Models (LLMs) have significantly\nimproved text generation capabilities. However, they also present challenges,\nparticularly in generating vaccine-related misinformation, which poses risks to\npublic health. Despite research on human-authored misinformation, a notable gap\nremains in understanding how LLMs contribute to vaccine misinformation and how\nbest to detect it. Existing benchmarks often overlook vaccine-specific\nmisinformation and the diverse roles of misinformation spreaders. This paper\nintroduces VaxGuard, a novel dataset designed to address these challenges.\nVaxGuard includes vaccine-related misinformation generated by multiple LLMs and\nprovides a comprehensive framework for detecting misinformation across various\nroles. Our findings show that GPT-3.5 and GPT-4o consistently outperform other\nLLMs in detecting misinformation, especially when dealing with subtle or\nemotionally charged narratives. On the other hand, PHI3 and Mistral show lower\nperformance, struggling with precision and recall in fear-driven contexts.\nAdditionally, detection performance tends to decline as input text length\nincreases, indicating the need for improved methods to handle larger content.\nThese results highlight the importance of role-specific detection strategies\nand suggest that VaxGuard can serve as a key resource for improving the\ndetection of LLM-generated vaccine misinformation.\n","authors":["Syed Talal Ahmad","Haohui Lu","Sidong Liu","Annie Lau","Amin Beheshti","Mark Dras","Usman Naseem"],"pdf_url":"https://arxiv.org/pdf/2503.09103v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.08454v2","updated":"2025-03-12T06:41:38Z","published":"2025-03-11T14:04:24Z","title":"Stick to Facts: Towards Fidelity-oriented Product Description Generation","summary":"  Different from other text generation tasks, in product description\ngeneration, it is of vital importance to generate faithful descriptions that\nstick to the product attribute information. However, little attention has been\npaid to this problem. To bridge this gap, we propose a model named\nFidelity-oriented Product Description Generator (FPDG). FPDG takes the entity\nlabel of each word into account, since the product attribute information is\nalways conveyed by entity words. Specifically, we first propose a Recurrent\nNeural Network (RNN) decoder based on the Entity-label-guided Long Short-Term\nMemory (ELSTM) cell, taking both the embedding and the entity label of each\nword as input. Second, we establish a keyword memory that stores the entity\nlabels as keys and keywords as values, allowing FPDG to attend to keywords by\nattending to their entity labels. Experiments conducted on a large-scale\nreal-world product description dataset show that our model achieves\nstate-of-the-art performance in terms of both traditional generation metrics\nand human evaluations. Specifically, FPDG increases the fidelity of the\ngenerated descriptions by 25%.\n","authors":["Zhangming Chan","Xiuying Chen","Yongliang Wang","Juntao Li","Zhiqiang Zhang","Kun Gai","Dongyan Zhao","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2503.08454v2.pdf","comment":"Accepted by EMNLP 2019"},{"id":"http://arxiv.org/abs/2402.15131v3","updated":"2025-03-12T06:15:34Z","published":"2024-02-23T06:32:18Z","title":"Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question\n  Answering with Large Language Models","summary":"  This study explores the realm of knowledge base question answering (KBQA).\nKBQA is considered a challenging task, particularly in parsing intricate\nquestions into executable logical forms. Traditional semantic parsing\n(SP)-based methods require extensive data annotations, which result in\nsignificant costs. Recently, the advent of few-shot in-context learning,\npowered by large language models (LLMs), has showcased promising capabilities.\nHowever, fully leveraging LLMs to parse questions into logical forms in\nlow-resource scenarios poses a substantial challenge. To tackle these hurdles,\nwe introduce Interactive-KBQA, a framework designed to generate logical forms\nthrough direct interaction with knowledge bases (KBs). Within this framework,\nwe have developed three generic APIs for KB interaction. For each category of\ncomplex question, we devised exemplars to guide LLMs through the reasoning\nprocesses. Our method achieves competitive results on the WebQuestionsSP,\nComplexWebQuestions, KQA Pro, and MetaQA datasets with a minimal number of\nexamples (shots). Importantly, our approach supports manual intervention,\nallowing for the iterative refinement of LLM outputs. By annotating a dataset\nwith step-wise reasoning processes, we showcase our model's adaptability and\nhighlight its potential for contributing significant enhancements to the field.\n","authors":["Guanming Xiong","Junwei Bao","Wen Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.15131v3.pdf","comment":"This work has been accepted by the ACL 2024 main conference. Code and\n  data are available at: https://github.com/JimXiongGM/Interactive-KBQA"},{"id":"http://arxiv.org/abs/2503.09094v1","updated":"2025-03-12T06:15:33Z","published":"2025-03-12T06:15:33Z","title":"Domain Adaptation for Japanese Sentence Embeddings with Contrastive\n  Learning based on Synthetic Sentence Generation","summary":"  Several backbone models pre-trained on general domain datasets can encode a\nsentence into a widely useful embedding. Such sentence embeddings can be\nfurther enhanced by domain adaptation that adapts a backbone model to a\nspecific domain. However, domain adaptation for low-resource languages like\nJapanese is often difficult due to the scarcity of large-scale labeled\ndatasets. To overcome this, this paper introduces SDJC (Self-supervised Domain\nadaptation for Japanese sentence embeddings with Contrastive learning) that\nutilizes a data generator to generate sentences, which have the same syntactic\nstructure to a sentence in an unlabeled specific domain corpus but convey\ndifferent semantic meanings. Generated sentences are then used to boost\ncontrastive learning that adapts a backbone model to accurately discriminate\nsentences in the specific domain. In addition, the components of SDJC like a\nbackbone model and a method to adapt it need to be carefully selected, but no\nbenchmark dataset is available for Japanese. Thus, a comprehensive Japanese STS\n(Semantic Textual Similarity) benchmark dataset is constructed by combining\ndatasets machine-translated from English with existing datasets. The\nexperimental results validates the effectiveness of SDJC on two domain-specific\ndownstream tasks as well as the usefulness of the constructed dataset.\nDatasets, codes and backbone models adapted by SDJC are available on our github\nrepository https://github.com/ccilab-doshisha/SDJC.\n","authors":["Zihao Chen","Hisashi Handa","Miho Ohsaki","Kimiaki Shirahama"],"pdf_url":"https://arxiv.org/pdf/2503.09094v1.pdf","comment":"39 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.08161v2","updated":"2025-03-12T06:04:42Z","published":"2025-03-11T08:26:37Z","title":"OASIS: Order-Augmented Strategy for Improved Code Search","summary":"  Code embeddings capture the semantic representations of code and are crucial\nfor various code-related large language model (LLM) applications, such as code\nsearch. Previous training primarily relies on optimizing the InfoNCE loss by\ncomparing positive natural language (NL)-code pairs with in-batch negatives.\nHowever, due to the sparse nature of code contexts, training solely by\ncomparing the major differences between positive and negative pairs may fail to\ncapture deeper semantic nuances. To address this issue, we propose a novel\norder-augmented strategy for improved code search (OASIS). It leverages\norder-based similarity labels to train models to capture subtle differences in\nsimilarity among negative pairs. Extensive benchmark evaluations demonstrate\nthat our OASIS model significantly outperforms previous state-of-the-art models\nfocusing solely on major positive-negative differences. It underscores the\nvalue of exploiting subtle differences among negative pairs with order labels\nfor effective code embedding training.\n","authors":["Zuchen Gao","Zizheng Zhan","Xianming Li","Erxin Yu","Haotian Zhang","Bin Chen","Yuqun Zhang","Jing Li"],"pdf_url":"https://arxiv.org/pdf/2503.08161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09089v1","updated":"2025-03-12T05:55:01Z","published":"2025-03-12T05:55:01Z","title":"LocAgent: Graph-Guided LLM Agents for Code Localization","summary":"  Code localization--identifying precisely where in a codebase changes need to\nbe made--is a fundamental yet challenging task in software maintenance.\nExisting approaches struggle to efficiently navigate complex codebases when\nidentifying relevant code sections. The challenge lies in bridging natural\nlanguage problem descriptions with the appropriate code elements, often\nrequiring reasoning across hierarchical structures and multiple dependencies.\nWe introduce LocAgent, a framework that addresses code localization through\ngraph-based representation. By parsing codebases into directed heterogeneous\ngraphs, LocAgent creates a lightweight representation that captures code\nstructures (files, classes, functions) and their dependencies (imports,\ninvocations, inheritance), enabling LLM agents to effectively search and locate\nrelevant entities through powerful multi-hop reasoning. Experimental results on\nreal-world benchmarks demonstrate that our approach significantly enhances\naccuracy in code localization. Notably, our method with the fine-tuned\nQwen-2.5-Coder-Instruct-32B model achieves comparable results to SOTA\nproprietary models at greatly reduced cost (approximately 86% reduction),\nreaching up to 92.7% accuracy on file-level localization while improving\ndownstream GitHub issue resolution success rates by 12% for multiple attempts\n(Pass@10). Our code is available at https://github.com/gersteinlab/LocAgent.\n","authors":["Zhaoling Chen","Xiangru Tang","Gangda Deng","Fang Wu","Jialong Wu","Zhiwei Jiang","Viktor Prasanna","Arman Cohan","Xingyao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.09089v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00936v4","updated":"2025-03-12T05:48:32Z","published":"2024-07-01T03:37:35Z","title":"Large Language Model Enhanced Knowledge Representation Learning: A\n  Survey","summary":"  Knowledge Representation Learning (KRL) is crucial for enabling applications\nof symbolic knowledge from Knowledge Graphs (KGs) to downstream tasks by\nprojecting knowledge facts into vector spaces. Despite their effectiveness in\nmodeling KG structural information, KRL methods are suffering from the\nsparseness of KGs. The rise of Large Language Models (LLMs) built on the\nTransformer architecture presents promising opportunities for enhancing KRL by\nincorporating textual information to address information sparsity in KGs.\nLLM-enhanced KRL methods, including three key approaches, encoder-based methods\nthat leverage detailed contextual information, encoder-decoder-based methods\nthat utilize a unified Seq2Seq model for comprehensive encoding and decoding,\nand decoder-based methods that utilize extensive knowledge from large corpora,\nhave significantly advanced the effectiveness and generalization of KRL in\naddressing a wide range of downstream tasks. This work provides a broad\noverview of downstream tasks while simultaneously identifying emerging research\ndirections in these evolving domains.\n","authors":["Xin Wang","Zirui Chen","Haofen Wang","Leong Hou U","Zhao Li","Wenbin Guo"],"pdf_url":"https://arxiv.org/pdf/2407.00936v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11551v4","updated":"2025-03-12T05:09:10Z","published":"2025-01-20T15:39:39Z","title":"PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation","summary":"  Despite notable advancements in Retrieval-Augmented Generation (RAG) systems\nthat expand large language model (LLM) capabilities through external retrieval,\nthese systems often struggle to meet the complex and diverse needs of\nreal-world industrial applications. The reliance on retrieval alone proves\ninsufficient for extracting deep, domain-specific knowledge performing in\nlogical reasoning from specialized corpora. To address this, we introduce\nsPecIalized KnowledgE and Rationale Augmentation Generation (PIKE-RAG),\nfocusing on extracting, understanding, and applying specialized knowledge,\nwhile constructing coherent rationale to incrementally steer LLMs toward\naccurate responses. Recognizing the diverse challenges of industrial tasks, we\nintroduce a new paradigm that classifies tasks based on their complexity in\nknowledge extraction and application, allowing for a systematic evaluation of\nRAG systems' problem-solving capabilities. This strategic approach offers a\nroadmap for the phased development and enhancement of RAG systems, tailored to\nmeet the evolving demands of industrial applications. Furthermore, we propose\nknowledge atomizing and knowledge-aware task decomposition to effectively\nextract multifaceted knowledge from the data chunks and iteratively construct\nthe rationale based on original query and the accumulated knowledge,\nrespectively, showcasing exceptional performance across various benchmarks.\n","authors":["Jinyu Wang","Jingjing Fu","Rui Wang","Lei Song","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2501.11551v4.pdf","comment":"38 pages, 18 figures, technique report"},{"id":"http://arxiv.org/abs/2407.08952v5","updated":"2025-03-12T04:46:47Z","published":"2024-07-12T03:15:01Z","title":"Detect, Investigate, Judge and Determine: A Knowledge-guided Framework\n  for Few-shot Fake News Detection","summary":"  Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news\nfrom real ones in extremely low-resource scenarios. This task has garnered\nincreased attention due to the widespread dissemination and harmful impact of\nfake news on social media. Large Language Models (LLMs) have demonstrated\ncompetitive performance with the help of their rich prior knowledge and\nexcellent in-context learning abilities. However, existing methods face\nsignificant limitations, such as the Understanding Ambiguity and Information\nScarcity, which significantly undermine the potential of LLMs. To address these\nshortcomings, we propose a Dual-perspective Knowledge-guided Fake News\nDetection (DKFND) model, designed to enhance LLMs from both inside and outside\nperspectives. Specifically, DKFND first identifies the knowledge concepts of\neach news article through a Detection Module. Subsequently, DKFND creatively\ndesigns an Investigation Module to retrieve inside and outside valuable\ninformation concerning to the current news, followed by another Judge Module to\nevaluate the relevance and confidence of them. Finally, a Determination Module\nfurther derives two respective predictions and obtain the final result.\nExtensive experiments on two public datasets show the efficacy of our proposed\nmethod, particularly in low-resource settings.\n","authors":["Ye Liu","Jiajun Zhu","Xukai Liu","Haoyu Tang","Yanghai Zhang","Kai Zhang","Xiaofang Zhou","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2407.08952v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11402v3","updated":"2025-03-12T04:37:42Z","published":"2024-06-17T10:45:36Z","title":"Are Small Language Models Ready to Compete with Large Language Models\n  for Practical Applications?","summary":"  The rapid rise of Language Models (LMs) has expanded their use in several\napplications. Yet, due to constraints of model size, associated cost, or\nproprietary restrictions, utilizing state-of-the-art (SOTA) LLMs is not always\nfeasible. With open, smaller LMs emerging, more applications can leverage their\ncapabilities, but selecting the right LM can be challenging as smaller LMs do\nnot perform well universally. This work tries to bridge this gap by proposing a\nframework to experimentally evaluate small, open LMs in practical settings\nthrough measuring semantic correctness of outputs across three practical\naspects: task types, application domains, and reasoning types, using diverse\nprompt styles. It also conducts an in-depth comparison of 10 small, open LMs to\nidentify the best LM and prompt style depending on specific application\nrequirements using the proposed framework. We also show that if selected\nappropriately, they can outperform SOTA LLMs like DeepSeek-v2, GPT-4o,\nGPT-4o-mini, Gemini-1.5-Pro, and even compete with GPT-4o.\n","authors":["Neelabh Sinha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2406.11402v3.pdf","comment":"Accepted at The Fifth Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025) in Annual Conference of the Nations of the\n  Americas Chapter of the Association for Computational Linguistics (NAACL),\n  2025. 8 pages + references + Appendix"},{"id":"http://arxiv.org/abs/2410.01380v3","updated":"2025-03-12T04:17:41Z","published":"2024-10-02T09:49:45Z","title":"Knowledge Entropy Decay during Language Model Pretraining Hinders New\n  Knowledge Acquisition","summary":"  In this work, we investigate how a model's tendency to broadly integrate its\nparametric knowledge evolves throughout pretraining, and how this behavior\naffects overall performance, particularly in terms of knowledge acquisition and\nforgetting. We introduce the concept of knowledge entropy, which quantifies the\nrange of memory sources the model engages with; high knowledge entropy\nindicates that the model utilizes a wide range of memory sources, while low\nknowledge entropy suggests reliance on specific sources with greater certainty.\nOur analysis reveals a consistent decline in knowledge entropy as pretraining\nadvances. We also find that the decline is closely associated with a reduction\nin the model's ability to acquire and retain knowledge, leading us to conclude\nthat diminishing knowledge entropy (smaller number of active memory sources)\nimpairs the model's knowledge acquisition and retention capabilities. We find\nfurther support for this by demonstrating that increasing the activity of\ninactive memory sources enhances the model's capacity for knowledge acquisition\nand retention.\n","authors":["Jiyeon Kim","Hyunji Lee","Hyowon Cho","Joel Jang","Hyeonbin Hwang","Seungpil Won","Youbin Ahn","Dohaeng Lee","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2410.01380v3.pdf","comment":"ICLR 2025, Oral"},{"id":"http://arxiv.org/abs/2501.07244v2","updated":"2025-03-12T04:10:33Z","published":"2025-01-13T11:52:55Z","title":"Can Vision-Language Models Evaluate Handwritten Math?","summary":"  Recent advancements in Vision-Language Models (VLMs) have opened new\npossibilities in automatic grading of handwritten student responses,\nparticularly in mathematics. However, a comprehensive study to test the ability\nof VLMs to evaluate and reason over handwritten content remains absent. To\naddress this gap, we introduce FERMAT, a benchmark designed to assess the\nability of VLMs to detect, localize and correct errors in handwritten\nmathematical content. FERMAT spans four key error dimensions - computational,\nconceptual, notational, and presentation - and comprises over 2,200 handwritten\nmath solutions derived from 609 manually curated problems from grades 7-12 with\nintentionally introduced perturbations. Using FERMAT we benchmark nine VLMs\nacross three tasks: error detection, localization, and correction. Our results\nreveal significant shortcomings in current VLMs in reasoning over handwritten\ntext, with Gemini-1.5-Pro achieving the highest error correction rate (77%). We\nalso observed that some models struggle with processing handwritten content, as\ntheir accuracy improves when handwritten inputs are replaced with printed text\nor images. These findings highlight the limitations of current VLMs and reveal\nnew avenues for improvement. We release FERMAT and all the associated resources\nin the open-source to drive further research.\n","authors":["Oikantik Nath","Hanani Bathina","Mohammed Safi Ur Rahman Khan","Mitesh M. Khapra"],"pdf_url":"https://arxiv.org/pdf/2501.07244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09032v1","updated":"2025-03-12T03:45:53Z","published":"2025-03-12T03:45:53Z","title":"Teaching LLMs How to Learn with Contextual Fine-Tuning","summary":"  Prompting Large Language Models (LLMs), or providing context on the expected\nmodel of operation, is an effective way to steer the outputs of such models to\nsatisfy human desiderata after they have been trained. But in rapidly evolving\ndomains, there is often need to fine-tune LLMs to improve either the kind of\nknowledge in their memory or their abilities to perform open ended reasoning in\nnew domains. When human's learn new concepts, we often do so by linking the new\nmaterial that we are studying to concepts we have already learned before. To\nthat end, we ask, \"can prompting help us teach LLMs how to learn\". In this\nwork, we study a novel generalization of instruction tuning, called contextual\nfine-tuning, to fine-tune LLMs. Our method leverages instructional prompts\ndesigned to mimic human cognitive strategies in learning and problem-solving to\nguide the learning process during training, aiming to improve the model's\ninterpretation and understanding of domain-specific knowledge. We empirically\ndemonstrate that this simple yet effective modification improves the ability of\nLLMs to be fine-tuned rapidly on new datasets both within the medical and\nfinancial domains.\n","authors":["Younwoo Choi","Muhammad Adil Asif","Ziwen Han","John Willes","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.09032v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09029v1","updated":"2025-03-12T03:36:45Z","published":"2025-03-12T03:36:45Z","title":"DAST: Difficulty-Aware Self-Training on Large Language Models","summary":"  Present Large Language Models (LLM) self-training methods always under-sample\non challenging queries, leading to inadequate learning on difficult problems\nwhich limits LLMs' ability. Therefore, this work proposes a difficulty-aware\nself-training (DAST) framework that focuses on improving both the quantity and\nquality of self-generated responses on challenging queries during\nself-training. DAST is specified in three components: 1) sampling-based\ndifficulty level estimation, 2) difficulty-aware data augmentation, and 3) the\nself-training algorithm using SFT and DPO respectively. Experiments on\nmathematical tasks demonstrate the effectiveness and generalization of DAST,\nhighlighting the critical role of difficulty-aware strategies in advancing LLM\nself-training.\n","authors":["Boyang Xue","Qi Zhu","Hongru Wang","Rui Wang","Sheng Wang","Hongling Xu","Fei Mi","Yasheng Wang","Lifeng Shang","Qun Liu","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2503.09029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15232v2","updated":"2025-03-12T03:28:09Z","published":"2024-11-21T19:13:04Z","title":"BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models","summary":"  Recent advancements in vision-language models (VLMs), such as CLIP, have\ndemonstrated substantial success in self-supervised representation learning for\nvision tasks. However, effectively adapting VLMs to downstream applications\nremains challenging, as their accuracy often depends on time-intensive and\nexpertise-demanding prompt engineering, while full model fine-tuning is costly.\nThis is particularly true for biomedical images, which, unlike natural images,\ntypically suffer from limited annotated datasets, unintuitive image contrasts,\nand nuanced visual features. Recent prompt learning techniques, such as Context\nOptimization (CoOp) intend to tackle these issues, but still fall short in\ngeneralizability. Meanwhile, explorations in prompt learning for biomedical\nimage analysis are still highly limited. In this work, we propose BiomedCoOp, a\nnovel prompt learning framework that enables efficient adaptation of BiomedCLIP\nfor accurate and highly generalizable few-shot biomedical image classification.\nOur approach achieves effective prompt context learning by leveraging semantic\nconsistency with average prompt ensembles from Large Language Models (LLMs) and\nknowledge distillation with a statistics-based prompt selection strategy. We\nconducted comprehensive validation of our proposed framework on 11 medical\ndatasets across 9 modalities and 10 organs against existing state-of-the-art\nmethods, demonstrating significant improvements in both accuracy and\ngeneralizability. The code is publicly available at\nhttps://github.com/HealthX-Lab/BiomedCoOp.\n","authors":["Taha Koleilat","Hojat Asgariandehkordi","Hassan Rivaz","Yiming Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.15232v2.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.09025v1","updated":"2025-03-12T03:24:44Z","published":"2025-03-12T03:24:44Z","title":"Aligning to What? Limits to RLHF Based Alignment","summary":"  Reinforcement Learning from Human Feedback (RLHF) is increasingly used to\nalign large language models (LLMs) with human preferences. However, the\neffectiveness of RLHF in addressing underlying biases remains unclear. This\nstudy investigates the relationship between RLHF and both covert and overt\nbiases in LLMs, particularly focusing on biases against African Americans. We\napplied various RLHF techniques (DPO, ORPO, and RLOO) to Llama 3 8B and\nevaluated the covert and overt biases of the resulting models using\nmatched-guise probing and explicit bias testing. We performed additional tests\nwith DPO on different base models and datasets; among several implications, we\nfound that SFT before RLHF calcifies model biases. Additionally, we extend the\ntools for measuring biases to multi-modal models. Through our experiments we\ncollect evidence that indicates that current alignment techniques are\ninadequate for nebulous tasks such as mitigating covert biases, highlighting\nthe need for capable datasets, data curating techniques, or alignment tools.\n","authors":["Logan Barnhart","Reza Akbarian Bafghi","Stephen Becker","Maziar Raissi"],"pdf_url":"https://arxiv.org/pdf/2503.09025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07513v2","updated":"2025-03-12T03:18:36Z","published":"2025-03-10T16:33:14Z","title":"Language Models Fail to Introspect About Their Knowledge of Language","summary":"  There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.\n","authors":["Siyuan Song","Jennifer Hu","Kyle Mahowald"],"pdf_url":"https://arxiv.org/pdf/2503.07513v2.pdf","comment":"Corrected Fig 5a and removed unused figures from source files"},{"id":"http://arxiv.org/abs/2312.10321v4","updated":"2025-03-12T03:16:27Z","published":"2023-12-16T05:01:23Z","title":"LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?","summary":"  Judging the equivalence between two SQL queries is a fundamental problem with\nmany practical applications in data management and SQL generation (i.e.,\nevaluating the quality of generated SQL queries in text-to-SQL task). While the\nresearch community has reasoned about SQL equivalence for decades, it poses\nconsiderable difficulties and no complete solutions exist. Recently, Large\nLanguage Models (LLMs) have shown strong reasoning capability in conversation,\nquestion answering and solving mathematics challenges. In this paper, we study\nif LLMs can be used to determine the equivalence between SQL queries under two\nnotions of SQL equivalence (semantic equivalence and relaxed equivalence). To\nassist LLMs in generating high quality responses, we present two prompting\ntechniques: Miniature & Mull and Explain & Compare. The former technique is\nused to evaluate the semantic equivalence in which it asks LLMs to execute a\nquery on a simple database instance and then explore if a counterexample exists\nby modifying the database. The latter technique is used to evaluate the relaxed\nequivalence in which it asks LLMs to explain the queries and then compare if\nthey contain significant logical differences. Our experiments demonstrate using\nour techniques, LLMs is a promising tool to help data engineers in writing\nsemantically equivalent SQL queries, however challenges still persist, and is a\nbetter metric for evaluating SQL generation than the popular execution\naccuracy.\n","authors":["Fuheng Zhao","Jiayue Chen","Lawrence Lim","Ishtiyaque Ahmad","Divyakant Agrawal","Amr El Abbadi"],"pdf_url":"https://arxiv.org/pdf/2312.10321v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18913v2","updated":"2025-03-12T03:06:01Z","published":"2025-02-26T07:59:55Z","title":"CS-Dialogue: A 104-Hour Dataset of Spontaneous Mandarin-English\n  Code-Switching Dialogues for Speech Recognition","summary":"  Code-switching (CS), the alternation between two or more languages within a\nsingle conversation, presents significant challenges for automatic speech\nrecognition (ASR) systems. Existing Mandarin-English code-switching datasets\noften suffer from limitations in size, spontaneity, and the lack of full-length\ndialogue recordings with transcriptions, hindering the development of robust\nASR models for real-world conversational scenarios. This paper introduces\nCS-Dialogue, a novel large-scale Mandarin-English code-switching speech dataset\ncomprising 104 hours of spontaneous conversations from 200 speakers. Unlike\nprevious datasets, CS-Dialogue provides full-length dialogue recordings with\ncomplete transcriptions, capturing naturalistic code-switching patterns in\ncontinuous speech. We describe the data collection and annotation processes,\npresent detailed statistics of the dataset, and establish benchmark ASR\nperformance using state-of-the-art models. Our experiments, using Transformer,\nConformer, and Branchformer, demonstrate the challenges of code-switching ASR,\nand show that existing pre-trained models such as Whisper still have the space\nto improve. The CS-Dialogue dataset will be made freely available for all\nacademic purposes.\n","authors":["Jiaming Zhou","Yujie Guo","Shiwan Zhao","Haoqin Sun","Hui Wang","Jiabei He","Aobo Kong","Shiyao Wang","Xi Yang","Yequan Wang","Yonghua Lin","Yong Qin"],"pdf_url":"https://arxiv.org/pdf/2502.18913v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09011v1","updated":"2025-03-12T02:59:41Z","published":"2025-03-12T02:59:41Z","title":"Word2winners at SemEval-2025 Task 7: Multilingual and Crosslingual\n  Fact-Checked Claim Retrieval","summary":"  This paper describes our system for SemEval 2025 Task 7: Previously\nFact-Checked Claim Retrieval. The task requires retrieving relevant fact-checks\nfor a given input claim from the extensive, multilingual MultiClaim dataset,\nwhich comprises social media posts and fact-checks in several languages. To\naddress this challenge, we first evaluated zero-shot performance using\nstate-of-the-art English and multilingual retrieval models and then fine-tuned\nthe most promising systems, leveraging machine translation to enhance\ncrosslingual retrieval. Our best model achieved an accuracy of 85% on\ncrosslingual data and 92% on monolingual data.\n","authors":["Amirmohammad Azadi","Sina Zamani","Mohammadmostafa Rostamkhani","Sauleh Eetemadi"],"pdf_url":"https://arxiv.org/pdf/2503.09011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09003v1","updated":"2025-03-12T02:33:33Z","published":"2025-03-12T02:33:33Z","title":"Leveraging Retrieval Augmented Generative LLMs For Automated Metadata\n  Description Generation to Enhance Data Catalogs","summary":"  Data catalogs serve as repositories for organizing and accessing diverse\ncollection of data assets, but their effectiveness hinges on the ease with\nwhich business users can look-up relevant content. Unfortunately, many data\ncatalogs within organizations suffer from limited searchability due to\ninadequate metadata like asset descriptions. Hence, there is a need of content\ngeneration solution to enrich and curate metadata in a scalable way. This paper\nexplores the challenges associated with metadata creation and proposes a unique\nprompt enrichment idea of leveraging existing metadata content using retrieval\nbased few-shot technique tied with generative large language models (LLM). The\nliterature also considers finetuning an LLM on existing content and studies the\nbehavior of few-shot pretrained LLM (Llama, GPT3.5) vis-\\`a-vis few-shot\nfinetuned LLM (Llama2-7b) by evaluating their performance based on accuracy,\nfactual grounding, and toxicity. Our preliminary results exhibit more than 80%\nRouge-1 F1 for the generated content. This implied 87%- 88% of instances\naccepted as is or curated with minor edits by data stewards. By automatically\ngenerating descriptions for tables and columns in most accurate way, the\nresearch attempts to provide an overall framework for enterprises to\neffectively scale metadata curation and enrich its data catalog thereby vastly\nimproving the data catalog searchability and overall usability.\n","authors":["Mayank Singh","Abhijeet Kumar","Sasidhar Donaparthi","Gayatri Karambelkar"],"pdf_url":"https://arxiv.org/pdf/2503.09003v1.pdf","comment":"Presented in 5th International Conference on NLP & Text Mining (NLTM\n  2025)"},{"id":"http://arxiv.org/abs/2407.12358v2","updated":"2025-03-12T02:20:28Z","published":"2024-07-17T07:29:59Z","title":"ProcTag: Process Tagging for Assessing the Efficacy of Document\n  Instruction Data","summary":"  Recently, large language models (LLMs) and multimodal large language models\n(MLLMs) have demonstrated promising results on document visual question\nanswering (VQA) task, particularly after training on document instruction\ndatasets. An effective evaluation method for document instruction data is\ncrucial in constructing instruction data with high efficacy, which, in turn,\nfacilitates the training of LLMs and MLLMs for document VQA. However, most\nexisting evaluation methods for instruction data are limited to the textual\ncontent of the instructions themselves, thereby hindering the effective\nassessment of document instruction datasets and constraining their\nconstruction. In this paper, we propose ProcTag, a data-oriented method that\nassesses the efficacy of document instruction data. ProcTag innovatively\nperforms tagging on the execution process of instructions rather than the\ninstruction text itself. By leveraging the diversity and complexity of these\ntags to assess the efficacy of the given dataset, ProcTag enables selective\nsampling or filtering of document instructions. Furthermore, DocLayPrompt, a\nnovel semi-structured layout-aware document prompting strategy, is proposed for\neffectively representing documents. Experiments demonstrate that sampling\nexisting open-sourced and generated document VQA/instruction datasets with\nProcTag significantly outperforms current methods for evaluating instruction\ndata. Impressively, with ProcTag-based sampling in the generated document\ndatasets, only 30.5\\% of the document instructions are required to achieve\n100\\% efficacy compared to the complete dataset. The code is publicly available\nat\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/ProcTag.\n","authors":["Yufan Shen","Chuwei Luo","Zhaoqing Zhu","Yang Chen","Qi Zheng","Zhi Yu","Jiajun Bu","Cong Yao"],"pdf_url":"https://arxiv.org/pdf/2407.12358v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2501.17202v2","updated":"2025-03-12T02:01:46Z","published":"2025-01-27T22:47:51Z","title":"Audio Large Language Models Can Be Descriptive Speech Quality Evaluators","summary":"  An ideal multimodal agent should be aware of the quality of its input\nmodalities. Recent advances have enabled large language models (LLMs) to\nincorporate auditory systems for handling various speech-related tasks.\nHowever, most audio LLMs remain unaware of the quality of the speech they\nprocess. This limitation arises because speech quality evaluation is typically\nexcluded from multi-task training due to the lack of suitable datasets. To\naddress this, we introduce the first natural language-based speech evaluation\ncorpus, generated from authentic human ratings. In addition to the overall Mean\nOpinion Score (MOS), this corpus offers detailed analysis across multiple\ndimensions and identifies causes of quality degradation. It also enables\ndescriptive comparisons between two speech samples (A/B tests) with human-like\njudgment. Leveraging this corpus, we propose an alignment approach with LLM\ndistillation (ALLD) to guide the audio LLM in extracting relevant information\nfrom raw speech and generating meaningful responses. Experimental results\ndemonstrate that ALLD outperforms the previous state-of-the-art regression\nmodel in MOS prediction, with a mean square error of 0.17 and an A/B test\naccuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of\n25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific\nmodels. This work advances the comprehensive perception of speech signals by\naudio LLMs, contributing to the development of real-world auditory and sensory\nintelligent agents.\n","authors":["Chen Chen","Yuchen Hu","Siyin Wang","Helin Wang","Zhehuai Chen","Chao Zhang","Chao-Han Huck Yang","Eng Siong Chng"],"pdf_url":"https://arxiv.org/pdf/2501.17202v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.12001v2","updated":"2025-03-12T02:00:49Z","published":"2025-02-17T16:39:28Z","title":"Merging Language and Domain Specific Models: The Impact on Technical\n  Vocabulary Acquisition","summary":"  Advancements in Natural Language Processing have enabled specialized language\nmodels, but integrating domain-specific knowledge into general-purpose models\nin multilingual settings remains challenging, particularly for technical\nvocabulary. This paper investigates the integration of technical vocabulary in\nmerged language models and explores the knowledge transfer mechanisms involved\nwhen combining a general-purpose language-specific model with a domain-specific\nmodel, focusing on the resulting model's comprehension of technical jargon. Our\nexperiments analyze the impact of this merging process on the target model's\nproficiency in handling specialized terminology. We present a quantitative\nevaluation of the performance of the merged model, comparing it with that of\nthe individual constituent models. The findings offer insights into the\neffectiveness of different model merging methods for enhancing domain-specific\nknowledge and highlight potential challenges and future directions in\nleveraging these methods for cross-lingual knowledge transfer in Natural\nLanguage Processing.\n","authors":["Thibault Rousset","Taisei Kakibuchi","Yusuke Sasaki","Yoshihide Nomura"],"pdf_url":"https://arxiv.org/pdf/2502.12001v2.pdf","comment":"Presented at the 263rd IPSJ-NL Workshop, Accepted at NLCAI 2025"},{"id":"http://arxiv.org/abs/2503.08990v1","updated":"2025-03-12T01:52:17Z","published":"2025-03-12T01:52:17Z","title":"JBFuzz: Jailbreaking LLMs Efficiently and Effectively Using Fuzzing","summary":"  Large language models (LLMs) have shown great promise as language\nunderstanding and decision making tools, and they have permeated various\naspects of our everyday life. However, their widespread availability also comes\nwith novel risks, such as generating harmful, unethical, or offensive content,\nvia an attack called jailbreaking. Despite extensive efforts from LLM\ndevelopers to align LLMs using human feedback, they are still susceptible to\njailbreak attacks. To tackle this issue, researchers often employ red-teaming\nto understand and investigate jailbreak prompts. However, existing red-teaming\napproaches lack effectiveness, scalability, or both. To address these issues,\nwe propose JBFuzz, a novel effective, automated, and scalable red-teaming\ntechnique for jailbreaking LLMs.\n  JBFuzz is inspired by the success of fuzzing for detecting\nbugs/vulnerabilities in software. We overcome three challenges related to\neffectiveness and scalability by devising novel seed prompts, a lightweight\nmutation engine, and a lightweight and accurate evaluator for guiding the\nfuzzer. Assimilating all three solutions results in a potent fuzzer that only\nrequires black-box access to the target LLM. We perform extensive experimental\nevaluation of JBFuzz using nine popular and widely-used LLMs. We find that\nJBFuzz successfully jailbreaks all LLMs for various harmful/unethical\nquestions, with an average attack success rate of 99%. We also find that JBFuzz\nis extremely efficient as it jailbreaks a given LLM for a given question in 60\nseconds on average. Our work highlights the susceptibility of the\nstate-of-the-art LLMs to jailbreak attacks even after safety alignment, and\nserves as a valuable red-teaming tool for LLM developers.\n","authors":["Vasudev Gohil"],"pdf_url":"https://arxiv.org/pdf/2503.08990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08980v1","updated":"2025-03-12T01:21:17Z","published":"2025-03-12T01:21:17Z","title":"I Predict Therefore I Am: Is Next Token Prediction Enough to Learn\n  Human-Interpretable Concepts from Data?","summary":"  The remarkable achievements of large language models (LLMs) have led many to\nconclude that they exhibit a form of intelligence. This is as opposed to\nexplanations of their capabilities based on their ability to perform relatively\nsimple manipulations of vast volumes of data. To illuminate the distinction\nbetween these explanations, we introduce a novel generative model that\ngenerates tokens on the basis of human interpretable concepts represented as\nlatent discrete variables. Under mild conditions, even when the mapping from\nthe latent space to the observed space is non-invertible, we establish an\nidentifiability result: the representations learned by LLMs through next-token\nprediction can be approximately modeled as the logarithm of the posterior\nprobabilities of these latent discrete concepts, up to an invertible linear\ntransformation. This theoretical finding not only provides evidence that LLMs\ncapture underlying generative factors, but also strongly reinforces the linear\nrepresentation hypothesis, which posits that LLMs learn linear representations\nof human-interpretable concepts. Empirically, we validate our theoretical\nresults through evaluations on both simulation data and the Pythia, Llama, and\nDeepSeek model families.\n","authors":["Yuhang Liu","Dong Gong","Erdun Gao","Zhen Zhang","Biwei Huang","Mingming Gong","Anton van den Hengel","Javen Qinfeng Shi"],"pdf_url":"https://arxiv.org/pdf/2503.08980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08979v1","updated":"2025-03-12T01:00:05Z","published":"2025-03-12T01:00:05Z","title":"Agentic AI for Scientific Discovery: A Survey of Progress, Challenges,\n  and Future Directions","summary":"  The integration of Agentic AI into scientific discovery marks a new frontier\nin research automation. These AI systems, capable of reasoning, planning, and\nautonomous decision-making, are transforming how scientists perform literature\nreview, generate hypotheses, conduct experiments, and analyze results. This\nsurvey provides a comprehensive overview of Agentic AI for scientific\ndiscovery, categorizing existing systems and tools, and highlighting recent\nprogress across fields such as chemistry, biology, and materials science. We\ndiscuss key evaluation metrics, implementation frameworks, and commonly used\ndatasets to offer a detailed understanding of the current state of the field.\nFinally, we address critical challenges, such as literature review automation,\nsystem reliability, and ethical concerns, while outlining future research\ndirections that emphasize human-AI collaboration and enhanced system\ncalibration.\n","authors":["Mourad Gridach","Jay Nanavati","Khaldoun Zine El Abidine","Lenon Mendes","Christina Mack"],"pdf_url":"https://arxiv.org/pdf/2503.08979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20140v2","updated":"2025-03-12T00:52:23Z","published":"2025-02-27T14:31:42Z","title":"Telephone Surveys Meet Conversational AI: Evaluating a LLM-Based\n  Telephone Survey System at Scale","summary":"  Telephone surveys remain a valuable tool for gathering insights but typically\nrequire substantial resources in training and coordinating human interviewers.\nThis work presents an AI-driven telephone survey system integrating\ntext-to-speech (TTS), a large language model (LLM), and speech-to-text (STT)\nthat mimics the versatility of human-led interviews (full-duplex dialogues) at\nscale.\n  We tested the system across two populations, a pilot study in the United\nStates (n = 75) and a large-scale deployment in Peru (n = 2,739), inviting\nparticipants via web-based links and contacting them via direct phone calls.\nThe AI agent successfully administered open-ended and closed-ended questions,\nhandled basic clarifications, and dynamically navigated branching logic,\nallowing fast large-scale survey deployment without interviewer recruitment or\ntraining.\n  Our findings demonstrate that while the AI system's probing for qualitative\ndepth was more limited than human interviewers, overall data quality approached\nhuman-led standards for structured items. This study represents one of the\nfirst successful large-scale deployments of an LLM-based telephone interviewer\nin a real-world survey context. The AI-powered telephone survey system has the\npotential for expanding scalable, consistent data collecting across market\nresearch, social science, and public opinion studies, thus improving\noperational efficiency while maintaining appropriate data quality for research.\n","authors":["Max M. Lang","Sol Eskenazi"],"pdf_url":"https://arxiv.org/pdf/2502.20140v2.pdf","comment":"Accepted at 80th AAPOR Conference 2025"},{"id":"http://arxiv.org/abs/2502.00987v2","updated":"2025-03-12T00:43:45Z","published":"2025-02-03T01:59:45Z","title":"RandLoRA: Full-rank parameter-efficient fine-tuning of large models","summary":"  Low-Rank Adaptation (LoRA) and its variants have shown impressive results in\nreducing the number of trainable parameters and memory requirements of large\ntransformer networks while maintaining fine-tuning performance. The low-rank\nnature of the weight update inherently limits the representation power of\nfine-tuned models, however, thus potentially compromising performance on\ncomplex tasks. This raises a critical question: when a performance gap between\nLoRA and standard fine-tuning is observed, is it due to the reduced number of\ntrainable parameters or the rank deficiency? This paper aims to answer this\nquestion by introducing RandLoRA, a parameter-efficient method that performs\nfull-rank updates using a learned linear combinations of low-rank,\nnon-trainable random matrices. Our method limits the number of trainable\nparameters by restricting optimization to diagonal scaling matrices applied to\nthe fixed random matrices. This allows us to effectively overcome the low-rank\nlimitations while maintaining parameter and memory efficiency during training.\nThrough extensive experimentation across vision, language, and vision-language\nbenchmarks, we systematically evaluate the limitations of LoRA and existing\nrandom basis methods. Our findings reveal that full-rank updates are beneficial\nacross vision and language tasks individually, and even more so for\nvision-language tasks, where RandLoRA significantly reduces -- and sometimes\neliminates -- the performance gap between standard fine-tuning and LoRA,\ndemonstrating its efficacy.\n","authors":["Paul Albert","Frederic Z. Zhang","Hemanth Saratchandran","Cristian Rodriguez-Opazo","Anton van den Hengel","Ehsan Abbasnejad"],"pdf_url":"https://arxiv.org/pdf/2502.00987v2.pdf","comment":"To appear at the International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2412.00071v2","updated":"2025-03-12T00:36:08Z","published":"2024-11-26T03:50:52Z","title":"COAP: Memory-Efficient Training with Correlation-Aware Gradient\n  Projection","summary":"  Training large-scale neural networks in vision, and multimodal domains\ndemands substantial memory resources, primarily due to the storage of optimizer\nstates. While LoRA, a popular parameter-efficient method, reduces memory usage,\nit often suffers from suboptimal performance due to the constraints of low-rank\nupdates. Low-rank gradient projection methods (e.g., GaLore, Flora) reduce\noptimizer memory by projecting gradients and moment estimates into low-rank\nspaces via singular value decomposition or random projection. However, they\nfail to account for inter-projection correlation, causing performance\ndegradation, and their projection strategies often incur high computational\ncosts. In this paper, we present COAP (Correlation-Aware Gradient Projection),\na memory-efficient method that minimizes computational overhead while\nmaintaining training performance. Evaluated across various vision, language,\nand multimodal tasks, COAP outperforms existing methods in both training speed\nand model performance. For LLaMA-1B, it reduces optimizer memory by 61% with\nonly 2% additional time cost, achieving the same PPL as AdamW. With 8-bit\nquantization, COAP cuts optimizer memory by 81% and achieves 4x speedup over\nGaLore for LLaVA-v1.5-7B fine-tuning, while delivering higher accuracy.\n","authors":["Jinqi Xiao","Shen Sang","Tiancheng Zhi","Jing Liu","Qing Yan","Yuqian Zhang","Linjie Luo","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2412.00071v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2410.02056v2","updated":"2025-03-12T00:25:08Z","published":"2024-10-02T22:05:36Z","title":"Synthio: Augmenting Small-Scale Audio Classification Datasets with\n  Synthetic Data","summary":"  We present Synthio, a novel approach for augmenting small-scale audio\nclassification datasets with synthetic data. Our goal is to improve audio\nclassification accuracy with limited labeled data. Traditional data\naugmentation techniques, which apply artificial transformations (e.g., adding\nrandom noise or masking segments), struggle to create data that captures the\ntrue diversity present in real-world audios. To address this shortcoming, we\npropose to augment the dataset with synthetic audio generated from\ntext-to-audio (T2A) diffusion models. However, synthesizing effective\naugmentations is challenging because not only should the generated data be\nacoustically consistent with the underlying small-scale dataset, but they\nshould also have sufficient compositional diversity. To overcome the first\nchallenge, we align the generations of the T2A model with the small-scale\ndataset using preference optimization. This ensures that the acoustic\ncharacteristics of the generated data remain consistent with the small-scale\ndataset. To address the second challenge, we propose a novel caption generation\ntechnique that leverages the reasoning capabilities of Large Language Models to\n(1) generate diverse and meaningful audio captions and (2) iteratively refine\ntheir quality. The generated captions are then used to prompt the aligned T2A\nmodel. We extensively evaluate Synthio on ten datasets and four simulated\nlimited-data settings. Results indicate our method consistently outperforms all\nbaselines by 0.1%-39% using a T2A model trained only on weakly-captioned\nAudioSet.\n","authors":["Sreyan Ghosh","Sonal Kumar","Zhifeng Kong","Rafael Valle","Bryan Catanzaro","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2410.02056v2.pdf","comment":"Accepted at ICLR 2025. Code and Checkpoints available here:\n  https://github.com/Sreyan88/Synthio"},{"id":"http://arxiv.org/abs/2503.09905v1","updated":"2025-03-12T23:50:35Z","published":"2025-03-12T23:50:35Z","title":"Quantization for OpenAI's Whisper Models: A Comparative Analysis","summary":"  Automated speech recognition (ASR) models have gained prominence for\napplications such as captioning, speech translation, and live transcription.\nThis paper studies Whisper and two model variants: one optimized for live\nspeech streaming and another for offline transcription. Notably, these models\nhave been found to generate hallucinated content, reducing transcription\nreliability. Furthermore, larger model variants exhibit increased latency and\npose challenges for deployment on resource-constrained devices. This study\nanalyzes the similarities and differences between three Whisper models,\nqualitatively examining their distinct capabilities. Next, this study\nquantifies the impact of model quantization on latency and evaluates its\nviability for edge deployment. Using the open source LibriSpeech dataset, this\npaper evaluates the word error rate (WER) along with latency analysis of\nwhispercpp using 3 quantization methods (INT4, INT5, INT8). Results show that\nquantization reduces latency by 19\\% and model size by 45\\%, while preserving\ntranscription accuracy. These findings provide insights into the optimal use\ncases of different Whisper models and edge device deployment possibilities. All\ncode, datasets, and implementation details are available in a public GitHub\nrepository: https://github.com/allisonandreyev/WhisperQuantization.git\n","authors":["Allison Andreyev"],"pdf_url":"https://arxiv.org/pdf/2503.09905v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2410.14211v4","updated":"2025-03-12T23:45:13Z","published":"2024-10-18T06:57:19Z","title":"Paths-over-Graph: Knowledge Graph Empowered Large Language Model\n  Reasoning","summary":"  Large Language Models (LLMs) have achieved impressive results in various\ntasks but struggle with hallucination problems and lack of relevant knowledge,\nespecially in deep complex reasoning and knowledge-intensive tasks. Knowledge\nGraphs (KGs), which capture vast amounts of facts in a structured format, offer\na reliable source of knowledge for reasoning. However, existing KG-based LLM\nreasoning methods face challenges like handling multi-hop reasoning,\nmulti-entity questions, and effectively utilizing graph structures. To address\nthese issues, we propose Paths-over-Graph (PoG), a novel method that enhances\nLLM reasoning by integrating knowledge reasoning paths from KGs, improving the\ninterpretability and faithfulness of LLM outputs. PoG tackles multi-hop and\nmulti-entity questions through a three-phase dynamic multi-hop path\nexploration, which combines the inherent knowledge of LLMs with factual\nknowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant\ninformation from the graph exploration first and introduces efficient\nthree-step pruning techniques that incorporate graph structures, LLM prompting,\nand a pre-trained language model (e.g., SBERT) to effectively narrow down the\nexplored candidate paths. This ensures all reasoning paths contain highly\nrelevant information captured from KGs, making the reasoning faithful and\ninterpretable in problem-solving. PoG innovatively utilizes graph structure to\nprune the irrelevant noise and represents the first method to implement\nmulti-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive\nexperiments on five benchmark KGQA datasets demonstrate PoG outperforms the\nstate-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an\naverage accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo\nsurpasses ToG with GPT-4 by up to 23.9%.\n","authors":["Xingyu Tan","Xiaoyang Wang","Qing Liu","Xiwei Xu","Xin Yuan","Wenjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.14211v4.pdf","comment":"Accepted by The Web Conference 2025 (WWW, 2025)"},{"id":"http://arxiv.org/abs/2503.09896v1","updated":"2025-03-12T23:29:08Z","published":"2025-03-12T23:29:08Z","title":"A Rule Based Solution to Co-reference Resolution in Clinical Text","summary":"  Objective: The aim of this study was to build an effective co-reference\nresolution system tailored for the biomedical domain. Materials and Methods:\nExperiment materials used in this study is provided by the 2011 i2b2 Natural\nLanguage Processing Challenge. The 2011 i2b2 challenge involves coreference\nresolution in medical documents. Concept mentions have been annotated in\nclinical texts, and the mentions that co-refer in each document are to be\nlinked by coreference chains. Normally, there are two ways of constructing a\nsystem to automatically discover co-referent links. One is to manually build\nrules for co-reference resolution, and the other category of approaches is to\nuse machine learning systems to learn automatically from training datasets and\nthen perform the resolution task on testing datasets. Results: Experiments show\nthe existing co-reference resolution systems are able to find some of the\nco-referent links, and our rule based system performs well finding the majority\nof the co-referent links. Our system achieved 89.6% overall performance on\nmultiple medical datasets. Conclusion: The experiment results show that\nmanually crafted rules based on observation of training data is a valid way to\naccomplish high performance in this coreference resolution task for the\ncritical biomedical domain.\n","authors":["Ping Chen","David Hinote","Guoqing Chen"],"pdf_url":"https://arxiv.org/pdf/2503.09896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09894v1","updated":"2025-03-12T23:24:40Z","published":"2025-03-12T23:24:40Z","title":"What's In Your Field? Mapping Scientific Research with Knowledge Graphs\n  and Large Language Models","summary":"  The scientific literature's exponential growth makes it increasingly\nchallenging to navigate and synthesize knowledge across disciplines. Large\nlanguage models (LLMs) are powerful tools for understanding scientific text,\nbut they fail to capture detailed relationships across large bodies of work.\nUnstructured approaches, like retrieval augmented generation, can sift through\nsuch corpora to recall relevant facts; however, when millions of facts\ninfluence the answer, unstructured approaches become cost prohibitive.\nStructured representations offer a natural complement -- enabling systematic\nanalysis across the whole corpus. Recent work enhances LLMs with unstructured\nor semistructured representations of scientific concepts; to complement this,\nwe try extracting structured representations using LLMs. By combining LLMs'\nsemantic understanding with a schema of scientific concepts, we prototype a\nsystem that answers precise questions about the literature as a whole. Our\nschema applies across scientific fields and we extract concepts from it using\nonly 20 manually annotated abstracts. To demonstrate the system, we extract\nconcepts from 30,000 papers on arXiv spanning astrophysics, fluid dynamics, and\nevolutionary biology. The resulting database highlights emerging trends and, by\nvisualizing the knowledge graph, offers new ways to explore the ever-growing\nlandscape of scientific knowledge. Demo: abby101/surveyor-0 on HF Spaces. Code:\nhttps://github.com/chiral-carbon/kg-for-science.\n","authors":["Abhipsha Das","Nicholas Lourie","Siavash Golkar","Mariel Pettee"],"pdf_url":"https://arxiv.org/pdf/2503.09894v1.pdf","comment":"9 pages, 5 pdf figures"},{"id":"http://arxiv.org/abs/2503.04848v2","updated":"2025-03-12T22:08:01Z","published":"2025-03-05T22:47:09Z","title":"Three tiers of computation in transformers and in brain architectures","summary":"  Human language and logic abilities are computationally quantified within the\nwell-studied grammar-automata hierarchy. We identify three hierarchical tiers\nand two corresponding transitions and show their correspondence to specific\nabilities in transformer-based language models (LMs). These emergent abilities\nhave often been described in terms of scaling; we show that it is the\ntransition between tiers, rather than scaled size itself, that determines a\nsystem's capabilities. Specifically, humans effortlessly process language yet\nrequire critical training to perform arithmetic or logical reasoning tasks; and\nLMs possess language abilities absent from predecessor systems, yet still\nstruggle with logical processing. We submit a novel benchmark of computational\npower, provide empirical evaluations of humans and fifteen LMs, and, most\nsignificantly, provide a theoretically grounded framework to promote careful\nthinking about these crucial topics. The resulting principled analyses provide\nexplanatory accounts of the abilities and shortfalls of LMs, and suggest\nactionable insights into the expansion of their logic abilities.\n","authors":["E Graham","R Granger"],"pdf_url":"https://arxiv.org/pdf/2503.04848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12480v2","updated":"2025-03-12T22:04:34Z","published":"2024-06-18T10:36:21Z","title":"The Power of LLM-Generated Synthetic Data for Stance Detection in Online\n  Political Discussions","summary":"  Stance detection holds great potential to improve online political\ndiscussions through its deployment in discussion platforms for purposes such as\ncontent moderation, topic summarization or to facilitate more balanced\ndiscussions. Typically, transformer-based models are employed directly for\nstance detection, requiring vast amounts of data. However, the wide variety of\ndebate topics in online political discussions makes data collection\nparticularly challenging. LLMs have revived stance detection, but their online\ndeployment in online political discussions faces challenges like inconsistent\noutputs, biases, and vulnerability to adversarial attacks. We show how\nLLM-generated synthetic data can improve stance detection for online political\ndiscussions by using reliable traditional stance detection models for online\ndeployment, while leveraging the text generation capabilities of LLMs for\nsynthetic data generation in a secure offline environment. To achieve this, (i)\nwe generate synthetic data for specific debate questions by prompting a\nMistral-7B model and show that fine-tuning with the generated synthetic data\ncan substantially improve the performance of stance detection, while remaining\ninterpretable and aligned with real world data. (ii) Using the synthetic data\nas a reference, we can improve performance even further by identifying the most\ninformative samples in an unlabelled dataset, i.e., those samples which the\nstance detection model is most uncertain about and can benefit from the most.\nBy fine-tuning with both synthetic data and the most informative samples, we\nsurpass the performance of the baseline model that is fine-tuned on all true\nlabels, while labelling considerably less data.\n","authors":["Stefan Sylvius Wagner","Maike Behrendt","Marc Ziegele","Stefan Harmeling"],"pdf_url":"https://arxiv.org/pdf/2406.12480v2.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2412.08099v4","updated":"2025-03-12T21:35:52Z","published":"2024-12-11T04:53:15Z","title":"Adversarial Vulnerabilities in Large Language Models for Time Series\n  Forecasting","summary":"  Large Language Models (LLMs) have recently demonstrated significant potential\nin time series forecasting, offering impressive capabilities in handling\ncomplex temporal data. However, their robustness and reliability in real-world\napplications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like LLMTime with GPT-3.5, GPT-4, LLaMa, and\nMistral, TimeGPT, and TimeLLM show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications. The code repository can be found at\nhttps://github.com/JohnsonJiang1996/AdvAttack_LLM4TS.\n","authors":["Fuqiang Liu","Sicong Jiang","Luis Miranda-Moreno","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2412.08099v4.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.09853v1","updated":"2025-03-12T21:24:22Z","published":"2025-03-12T21:24:22Z","title":"Who Are You Behind the Screen? Implicit MBTI and Gender Detection Using\n  Artificial Intelligence","summary":"  In personalized technology and psychological research, precisely detecting\ndemographic features and personality traits from digital interactions becomes\never more important. This work investigates implicit categorization, inferring\npersonality and gender variables directly from linguistic patterns in Telegram\nconversation data, while conventional personality prediction techniques mostly\ndepend on explicitly self-reported labels. We refine a Transformer-based\nlanguage model (RoBERTa) to capture complex linguistic cues indicative of\npersonality traits and gender differences using a dataset comprising 138,866\nmessages from 1,602 users annotated with MBTI types and 195,016 messages from\n2,598 users annotated with gender. Confidence levels help to greatly raise\nmodel accuracy to 86.16\\%, hence proving RoBERTa's capacity to consistently\nidentify implicit personality types from conversational text data. Our results\nhighlight the usefulness of Transformer topologies for implicit personality and\ngender classification, hence stressing their efficiency and stressing important\ntrade-offs between accuracy and coverage in realistic conversational\nenvironments. With regard to gender classification, the model obtained an\naccuracy of 74.4\\%, therefore capturing gender-specific language patterns.\nPersonality dimension analysis showed that people with introverted and\nintuitive preferences are especially more active in text-based interactions.\nThis study emphasizes practical issues in balancing accuracy and data coverage\nas Transformer-based models show their efficiency in implicit personality and\ngender prediction tasks from conversational texts.\n","authors":["Kourosh Shahnazari","Seyed Moein Ayyoubzadeh"],"pdf_url":"https://arxiv.org/pdf/2503.09853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12634v3","updated":"2025-03-12T21:16:45Z","published":"2023-12-19T22:33:17Z","title":"MotionScript: Natural Language Descriptions for Expressive 3D Human\n  Motions","summary":"  We introduce MotionScript, a novel framework for generating highly detailed,\nnatural language descriptions of 3D human motions. Unlike existing motion\ndatasets that rely on broad action labels or generic captions, MotionScript\nprovides fine-grained, structured descriptions that capture the full complexity\nof human movement including expressive actions (e.g., emotions, stylistic\nwalking) and interactions beyond standard motion capture datasets. MotionScript\nserves as both a descriptive tool and a training resource for text-to-motion\nmodels, enabling the synthesis of highly realistic and diverse human motions\nfrom text. By augmenting motion datasets with MotionScript captions, we\ndemonstrate significant improvements in out-of-distribution motion generation,\nallowing large language models (LLMs) to generate motions that extend beyond\nexisting data. Additionally, MotionScript opens new applications in animation,\nvirtual human simulation, and robotics, providing an interpretable bridge\nbetween intuitive descriptions and motion synthesis. To the best of our\nknowledge, this is the first attempt to systematically translate 3D motion into\nstructured natural language without requiring training data.\n","authors":["Payam Jome Yazdian","Rachel Lagasse","Hamid Mohammadi","Eric Liu","Li Cheng","Angelica Lim"],"pdf_url":"https://arxiv.org/pdf/2312.12634v3.pdf","comment":"Project webpage: https://pjyazdian.github.io/MotionScript"},{"id":"http://arxiv.org/abs/2503.09837v1","updated":"2025-03-12T20:58:16Z","published":"2025-03-12T20:58:16Z","title":"On the Limitations of Vision-Language Models in Understanding Image\n  Transforms","summary":"  Vision Language Models (VLMs) have demonstrated significant potential in\nvarious downstream tasks, including Image/Video Generation, Visual Question\nAnswering, Multimodal Chatbots, and Video Understanding. However, these models\noften struggle with basic image transformations. This paper investigates the\nimage-level understanding of VLMs, specifically CLIP by OpenAI and SigLIP by\nGoogle. Our findings reveal that these models lack comprehension of multiple\nimage-level augmentations. To facilitate this study, we created an augmented\nversion of the Flickr8k dataset, pairing each image with a detailed description\nof the applied transformation. We further explore how this deficiency impacts\ndownstream tasks, particularly in image editing, and evaluate the performance\nof state-of-the-art Image2Image models on simple transformations.\n","authors":["Ahmad Mustafa Anis","Hasnain Ali","Saquib Sarfraz"],"pdf_url":"https://arxiv.org/pdf/2503.09837v1.pdf","comment":"8 pages, 15 images"},{"id":"http://arxiv.org/abs/2409.11295v5","updated":"2025-03-12T20:54:00Z","published":"2024-09-17T15:49:44Z","title":"EIA: Environmental Injection Attack on Generalist Web Agents for Privacy\n  Leakage","summary":"  Generalist web agents have demonstrated remarkable potential in autonomously\ncompleting a wide range of tasks on real websites, significantly boosting human\nproductivity. However, web tasks, such as booking flights, usually involve\nusers' PII, which may be exposed to potential privacy risks if web agents\naccidentally interact with compromised websites, a scenario that remains\nlargely unexplored in the literature. In this work, we narrow this gap by\nconducting the first study on the privacy risks of generalist web agents in\nadversarial environments. First, we present a realistic threat model for\nattacks on the website, where we consider two adversarial targets: stealing\nusers' specific PII or the entire user request. Then, we propose a novel attack\nmethod, termed Environmental Injection Attack (EIA). EIA injects malicious\ncontent designed to adapt well to environments where the agents operate and our\nwork instantiates EIA specifically for privacy scenarios in web environments.\nWe collect 177 action steps that involve diverse PII categories on realistic\nwebsites from the Mind2Web, and conduct experiments using one of the most\ncapable generalist web agent frameworks to date. The results demonstrate that\nEIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user\nrequest. Additionally, by accessing the stealthiness and experimenting with a\ndefensive system prompt, we indicate that EIA is hard to detect and mitigate.\nNotably, attacks that are not well adapted for a webpage can be detected via\nhuman inspection, leading to our discussion about the trade-off between\nsecurity and autonomy. However, extra attackers' efforts can make EIA\nseamlessly adapted, rendering such supervision ineffective. Thus, we further\ndiscuss the defenses at the pre- and post-deployment stages of the websites\nwithout relying on human supervision and call for more advanced defense\nstrategies.\n","authors":["Zeyi Liao","Lingbo Mo","Chejian Xu","Mintong Kang","Jiawei Zhang","Chaowei Xiao","Yuan Tian","Bo Li","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2409.11295v5.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09822v1","updated":"2025-03-12T20:40:09Z","published":"2025-03-12T20:40:09Z","title":"Generative AI for Named Entity Recognition in Low-Resource Language\n  Nepali","summary":"  Generative Artificial Intelligence (GenAI), particularly Large Language\nModels (LLMs), has significantly advanced Natural Language Processing (NLP)\ntasks, such as Named Entity Recognition (NER), which involves identifying\nentities like person, location, and organization names in text. LLMs are\nespecially promising for low-resource languages due to their ability to learn\nfrom limited data. However, the performance of GenAI models for Nepali, a\nlow-resource language, has not been thoroughly evaluated. This paper\ninvestigates the application of state-of-the-art LLMs for Nepali NER,\nconducting experiments with various prompting techniques to assess their\neffectiveness. Our results provide insights into the challenges and\nopportunities of using LLMs for NER in low-resource settings and offer valuable\ncontributions to the advancement of NLP research in languages like Nepali.\n","authors":["Sameer Neupane","Jeevan Chapagain","Nobal B. Niraula","Diwa Koirala"],"pdf_url":"https://arxiv.org/pdf/2503.09822v1.pdf","comment":"This paper has been accepted in the FLAIRS Conference 2025"},{"id":"http://arxiv.org/abs/2503.09819v1","updated":"2025-03-12T20:34:14Z","published":"2025-03-12T20:34:14Z","title":"Attention Reveals More Than Tokens: Training-Free Long-Context Reasoning\n  with Attention-guided Retrieval","summary":"  Large Language Models (LLMs) often exhibit substantially shorter effective\ncontext lengths than their claimed capacities, especially when handling complex\nreasoning tasks that require integrating information from multiple parts of a\nlong context and performing multi-step reasoning. Although Chain-of-Thought\n(CoT) prompting has shown promise in reducing task complexity, our empirical\nanalysis reveals that it does not fully resolve this limitation. Through\ncontrolled experiments, we identify poor recall of implicit facts as the\nprimary cause of failure, which significantly hampers reasoning performance.\nInterestingly, we observe that the internal attention weights from the\ngenerated CoT tokens can effectively ground implicit facts, even when these\nfacts are not explicitly recalled. Building on this insight, we propose a novel\ntraining-free algorithm, Attrieval, which leverages attention weights to\nretrieve relevant facts from the long context and incorporates them into the\nreasoning process. Additionally, we find that selecting context tokens from CoT\ntokens further improves performance. Our results demonstrate that Attrieval\nenhances long-context reasoning capability notably on both synthetic and\nreal-world QA datasets with various models.\n","authors":["Yuwei Zhang","Jayanth Srinivasa","Gaowen Liu","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.09819v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2502.20167v2","updated":"2025-03-12T20:21:05Z","published":"2025-02-27T15:05:00Z","title":"Similarity-Distance-Magnitude Universal Verification","summary":"  We address the neural network robustness problem by adding Similarity (i.e.,\ncorrectly predicted depth-matches into training)-awareness and\nDistance-to-training-distribution-awareness to the existing output Magnitude\n(i.e., decision-boundary)-awareness of the softmax function. The resulting sdm\nactivation function provides strong signals of the relative epistemic\n(reducible) predictive uncertainty. We use this novel behavior to further\naddress the complementary HCI problem of mapping the output to\nhuman-interpretable summary statistics over relevant partitions of a held-out\ncalibration set. Estimates of prediction-conditional uncertainty are obtained\nvia a parsimonious learned transform over the class-conditional empirical CDFs\nof the output of a final-layer sdm activation function. For decision-making and\nas an intrinsic model check, estimates of class-conditional accuracy are\nobtained by further partitioning the high-probability regions of this\ncalibrated output into class-conditional, region-specific CDFs. The uncertainty\nestimates from sdm calibration are remarkably robust to test-time distribution\nshifts and out-of-distribution inputs; incorporate awareness of the effective\nsample size; provide estimates of uncertainty from the learning and data\nsplitting processes; and are well-suited for selective classification and\nconditional branching for additional test-time compute based on the predictive\nuncertainty, as for selective LLM generation, routing, and composition over\nmultiple models and retrieval. Finally, we construct sdm networks, LLMs with\nuncertainty-aware verification and interpretability-by-exemplar as intrinsic\nproperties. We provide open-source software implementing these results.\n","authors":["Allen Schmaltz"],"pdf_url":"https://arxiv.org/pdf/2502.20167v2.pdf","comment":"35 pages (8 Tables, 4 Algorithms, 5 Listings)"},{"id":"http://arxiv.org/abs/2305.08982v2","updated":"2025-03-12T20:18:39Z","published":"2023-05-15T19:48:59Z","title":"Helping the Helper: Supporting Peer Counselors via AI-Empowered Practice\n  and Feedback","summary":"  Millions of users come to online peer counseling platforms to seek support.\nHowever, studies show that online peer support groups are not always as\neffective as expected, largely due to users' negative experiences with\nunhelpful counselors. Peer counselors are key to the success of online peer\ncounseling platforms, but most often do not receive appropriate training.Hence,\nwe introduce CARE: an AI-based tool to empower and train peer counselors\nthrough practice and feedback. Concretely, CARE helps diagnose which counseling\nstrategies are needed in a given situation and suggests example responses to\ncounselors during their practice sessions. Building upon the Motivational\nInterviewing framework, CARE utilizes large-scale counseling conversation data\nwith text generation techniques to enable these functionalities. We demonstrate\nthe efficacy of CARE by performing quantitative evaluations and qualitative\nuser studies through simulated chats and semi-structured interviews, finding\nthat CARE especially helps novice counselors in challenging situations. The\ncode is available at https://github.com/SALT-NLP/CARE\n","authors":["Shang-Ling Hsu","Raj Sanjay Shah","Prathik Senthil","Zahra Ashktorab","Casey Dugan","Werner Geyer","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2305.08982v2.pdf","comment":"45 pages, 14 figures, CSCW 2025"},{"id":"http://arxiv.org/abs/2503.09799v1","updated":"2025-03-12T20:04:38Z","published":"2025-03-12T20:04:38Z","title":"Communication-Efficient Language Model Training Scales Reliably and\n  Robustly: Scaling Laws for DiLoCo","summary":"  As we scale to more massive machine learning models, the frequent\nsynchronization demands inherent in data-parallel approaches create significant\nslowdowns, posing a critical challenge to further scaling. Recent work develops\nan approach (DiLoCo) that relaxes synchronization demands without compromising\nmodel quality. However, these works do not carefully analyze how DiLoCo's\nbehavior changes with model size. In this work, we study the scaling law\nbehavior of DiLoCo when training LLMs under a fixed compute budget. We focus on\nhow algorithmic factors, including number of model replicas, hyperparameters,\nand token budget affect training in ways that can be accurately predicted via\nscaling laws. We find that DiLoCo scales both predictably and robustly with\nmodel size. When well-tuned, DiLoCo scales better than data-parallel training\nwith model size, and can outperform data-parallel training even at small model\nsizes. Our results showcase a more general set of benefits of DiLoCo than\npreviously documented, including increased optimal batch sizes, improved\ndownstream generalization with scale, and improved evaluation loss for a fixed\ntoken budget.\n","authors":["Zachary Charles","Gabriel Teston","Lucio Dery","Keith Rush","Nova Fallen","Zachary Garrett","Arthur Szlam","Arthur Douillard"],"pdf_url":"https://arxiv.org/pdf/2503.09799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07237v2","updated":"2025-03-12T19:50:34Z","published":"2024-08-13T23:58:45Z","title":"Neural embedding of beliefs reveals the role of relative dissonance in\n  human decision-making","summary":"  Beliefs form the foundation of human cognition and decision-making, guiding\nour actions and social connections. A model encapsulating beliefs and their\ninterrelationships is crucial for understanding their influence on our actions.\nHowever, research on belief interplay has often been limited to beliefs related\nto specific issues and relied heavily on surveys. We propose a method to study\nthe nuanced interplay between thousands of beliefs by leveraging an online user\ndebate data and mapping beliefs onto a neural embedding space constructed using\na fine-tuned large language model (LLM). This belief space captures the\ninterconnectedness and polarization of diverse beliefs across social issues.\nOur findings show that positions within this belief space predict new beliefs\nof individuals and estimate cognitive dissonance based on the distance between\nexisting and new beliefs. This study demonstrates how LLMs, combined with\ncollective online records of human beliefs, can offer insights into the\nfundamental principles that govern human decision-making.\n","authors":["Byunghwee Lee","Rachith Aiyappa","Yong-Yeol Ahn","Haewoon Kwak","Jisun An"],"pdf_url":"https://arxiv.org/pdf/2408.07237v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05858v2","updated":"2025-03-12T19:50:21Z","published":"2025-03-08T10:20:57Z","title":"Bimodal Connection Attention Fusion for Speech Emotion Recognition","summary":"  Multi-modal emotion recognition is challenging due to the difficulty of\nextracting features that capture subtle emotional differences. Understanding\nmulti-modal interactions and connections is key to building effective bimodal\nspeech emotion recognition systems. In this work, we propose Bimodal Connection\nAttention Fusion (BCAF) method, which includes three main modules: the\ninteractive connection network, the bimodal attention network, and the\ncorrelative attention network. The interactive connection network uses an\nencoder-decoder architecture to model modality connections between audio and\ntext while leveraging modality-specific features. The bimodal attention network\nenhances semantic complementation and exploits intra- and inter-modal\ninteractions. The correlative attention network reduces cross-modal noise and\ncaptures correlations between audio and text. Experiments on the MELD and\nIEMOCAP datasets demonstrate that the proposed BCAF method outperforms existing\nstate-of-the-art baselines.\n","authors":["Jiachen Luo","Huy Phan","Lin Wang","Joshua D. Reiss"],"pdf_url":"https://arxiv.org/pdf/2503.05858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09790v1","updated":"2025-03-12T19:48:12Z","published":"2025-03-12T19:48:12Z","title":"Constrained Language Generation with Discrete Diffusion Models","summary":"  Constraints are critical in text generation as LLM outputs are often\nunreliable when it comes to ensuring generated outputs adhere to user defined\ninstruction or general safety guidelines. To address this gap, we present\nConstrained Discrete Diffusion (CDD), a novel method for enforcing constraints\non natural language by integrating discrete diffusion models with\ndifferentiable optimization. Unlike conventional text generators, which often\nrely on post-hoc filtering or model retraining for controllable generation, we\npropose imposing constraints directly into the discrete diffusion sampling\nprocess. We illustrate how this technique can be applied to satisfy a variety\nof natural language constraints, including (i) toxicity mitigation by\npreventing harmful content from emerging, (ii) character and sequence level\nlexical constraints, and (iii) novel molecule sequence generation with specific\nproperty adherence. Experimental results show that our constraint-aware\nprocedure achieves high fidelity in meeting these requirements while preserving\nfluency and semantic coherence, outperforming auto-regressive and existing\ndiscrete diffusion approaches.\n","authors":["Michael Cardei","Jacob K Christopher","Thomas Hartvigsen","Brian R. Bartoldson","Bhavya Kailkhura","Ferdinando Fioretto"],"pdf_url":"https://arxiv.org/pdf/2503.09790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14678v3","updated":"2025-03-12T19:31:41Z","published":"2024-06-20T18:58:11Z","title":"Evaluating Contextualized Representations of (Spanish) Ambiguous Words:\n  A New Lexical Resource and Empirical Analysis","summary":"  Lexical ambiguity -- where a single wordform takes on distinct,\ncontext-dependent meanings -- serves as a useful tool to compare across\ndifferent language models' (LMs') ability to form distinct, contextualized\nrepresentations of the same stimulus. Few studies have systematically compared\nLMs' contextualized word embeddings for languages beyond English. Here, we\nevaluate semantic representations of Spanish ambiguous nouns in context in a\nsuite of Spanish-language monolingual and multilingual BERT-based models. We\ndevelop a novel dataset of minimal-pair sentences evoking the same or different\nsense for a target ambiguous noun. In a pre-registered study, we collect\ncontextualized human relatedness judgments for each sentence pair. We find that\nvarious BERT-based LMs' contextualized semantic representations capture some\nvariance in human judgments but fall short of the human benchmark. In\nexploratory work, we find that performance scales with model size. We also\nidentify stereotyped trajectories of target noun disambiguation as a proportion\nof traversal through a given LM family's architecture, which we partially\nreplicate in English. We contribute (1) a dataset of controlled, Spanish\nsentence stimuli with human relatedness norms, and (2) to our evolving\nunderstanding of the impact that LM specification (architectures, training\nprotocols) exerts on contextualized embeddings.\n","authors":["Pamela D. Rivière","Anne L. Beatty-Martínez","Sean Trott"],"pdf_url":"https://arxiv.org/pdf/2406.14678v3.pdf","comment":"17 pages, 12 figures, accepted at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.09774v1","updated":"2025-03-12T19:20:33Z","published":"2025-03-12T19:20:33Z","title":"Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein\n  Feature Alignment","summary":"  Automatic scoring of student responses enhances efficiency in education, but\ndeploying a separate neural network for each task increases storage demands,\nmaintenance efforts, and redundant computations. To address these challenges,\nthis paper introduces the Gromov-Wasserstein Scoring Model Merging (GW-SMM)\nmethod, which merges models based on feature distribution similarities measured\nvia the Gromov-Wasserstein distance. Our approach begins by extracting features\nfrom student responses using individual models, capturing both item-specific\ncontext and unique learned representations. The Gromov-Wasserstein distance\nthen quantifies the similarity between these feature distributions, identifying\nthe most compatible models for merging. Models exhibiting the smallest pairwise\ndistances, typically in pairs or trios, are merged by combining only the shared\nlayers preceding the classification head. This strategy results in a unified\nfeature extractor while preserving separate classification heads for\nitem-specific scoring. We validated our approach against human expert knowledge\nand a GPT-o1-based merging method. GW-SMM consistently outperformed both,\nachieving a higher micro F1 score, macro F1 score, exact match accuracy, and\nper-label accuracy. The improvements in micro F1 and per-label accuracy were\nstatistically significant compared to GPT-o1-based merging (p=0.04, p=0.01).\nAdditionally, GW-SMM reduced storage requirements by half without compromising\nmuch accuracy, demonstrating its computational efficiency alongside reliable\nscoring performance.\n","authors":["Luyang Fang","Ehsan Latif","Haoran Lu","Yifan Zhou","Ping Ma","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2503.09774v1.pdf","comment":"Submitted to AIED2025"},{"id":"http://arxiv.org/abs/2503.09763v1","updated":"2025-03-12T19:01:41Z","published":"2025-03-12T19:01:41Z","title":"BiasConnect: Investigating Bias Interactions in Text-to-Image Models","summary":"  The biases exhibited by Text-to-Image (TTI) models are often treated as if\nthey are independent, but in reality, they may be deeply interrelated.\nAddressing bias along one dimension, such as ethnicity or age, can\ninadvertently influence another dimension, like gender, either mitigating or\nexacerbating existing disparities. Understanding these interdependencies is\ncrucial for designing fairer generative models, yet measuring such effects\nquantitatively remains a challenge. In this paper, we aim to address these\nquestions by introducing BiasConnect, a novel tool designed to analyze and\nquantify bias interactions in TTI models. Our approach leverages a\ncounterfactual-based framework to generate pairwise causal graphs that reveals\nthe underlying structure of bias interactions for the given text prompt.\nAdditionally, our method provides empirical estimates that indicate how other\nbias dimensions shift toward or away from an ideal distribution when a given\nbias is modified. Our estimates have a strong correlation (+0.69) with the\ninterdependency observations post bias mitigation. We demonstrate the utility\nof BiasConnect for selecting optimal bias mitigation axes, comparing different\nTTI models on the dependencies they learn, and understanding the amplification\nof intersectional societal biases in TTI models.\n","authors":["Pushkar Shukla","Aditya Chinchure","Emily Diana","Alexander Tolbert","Kartik Hosanagar","Vineeth N. Balasubramanian","Leonid Sigal","Matthew A. Turk"],"pdf_url":"https://arxiv.org/pdf/2503.09763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09743v1","updated":"2025-03-12T18:42:43Z","published":"2025-03-12T18:42:43Z","title":"Review GIDE -- Restaurant Review Gastrointestinal Illness Detection and\n  Extraction with Large Language Models","summary":"  Foodborne gastrointestinal (GI) illness is a common cause of ill health in\nthe UK. However, many cases do not interact with the healthcare system, posing\nsignificant challenges for traditional surveillance methods. The growth of\npublicly available online restaurant reviews and advancements in large language\nmodels (LLMs) present potential opportunities to extend disease surveillance by\nidentifying public reports of GI illness. In this study, we introduce a novel\nannotation schema, developed with experts in GI illness, applied to the Yelp\nOpen Dataset of reviews. Our annotations extend beyond binary disease\ndetection, to include detailed extraction of information on symptoms and foods.\nWe evaluate the performance of open-weight LLMs across these three tasks: GI\nillness detection, symptom extraction, and food extraction. We compare this\nperformance to RoBERTa-based classification models fine-tuned specifically for\nthese tasks. Our results show that using prompt-based approaches, LLMs achieve\nmicro-F1 scores of over 90% for all three of our tasks. Using prompting alone,\nwe achieve micro-F1 scores that exceed those of smaller fine-tuned models. We\nfurther demonstrate the robustness of LLMs in GI illness detection across three\nbias-focused experiments. Our results suggest that publicly available review\ntext and LLMs offer substantial potential for public health surveillance of GI\nillness by enabling highly effective extraction of key information. While LLMs\nappear to exhibit minimal bias in processing, the inherent limitations of\nrestaurant review data highlight the need for cautious interpretation of\nresults.\n","authors":["Timothy Laurence","Joshua Harris","Leo Loman","Amy Douglas","Yung-Wai Chan","Luke Hounsome","Lesley Larkin","Michael Borowitz"],"pdf_url":"https://arxiv.org/pdf/2503.09743v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2503.04844v2","updated":"2025-03-12T18:26:37Z","published":"2025-03-05T18:29:15Z","title":"Universal Narrative Model: an Author-centric Storytelling Framework for\n  Generative AI","summary":"  Generative AI promises to finally realize dynamic, personalized storytelling\ntechnologies across a range of media. To date, experimentation with generative\nAI in the field of procedural narrative generation has been quite promising\nfrom a technical perspective. However, fundamental narrative dilemmas remain,\nsuch as the balance between player agency and narrative coherence, and no\nrigorous narrative standard has been proposed to specifically leverage the\nstrengths of generative AI. In this paper, we propose the Universal Narrative\nModel (UNM), an open and extensible standard designed to place writers at the\ncenter of future narrative design workflows and enable interoperability across\nauthoring platforms. By encoding an author's intent according to an objective\nnarrative model, the UNM enables narrative portability as well as intent-based\nconstraints for generative systems.\n","authors":["Hank Gerba"],"pdf_url":"https://arxiv.org/pdf/2503.04844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14327v3","updated":"2025-03-12T18:22:25Z","published":"2024-02-22T06:47:44Z","title":"Subobject-level Image Tokenization","summary":"  Patch-based image tokenization ignores the morphology of the visual world,\nlimiting effective and efficient learning of image understanding. Inspired by\nsubword tokenization, we introduce subobject-level adaptive token segmentation\nand explore several approaches, including superpixel, SAM, and a proposed\nEfficient and PanOptiC (EPOC) image tokenizer. Our EPOC combines boundary\ndetection -- a simple task that can be handled well by a compact model -- with\nwatershed segmentation, which inherently guarantees no pixels are left\nunsegmented. Intrinsic evaluations across 5 datasets demonstrate that EPOC's\nsegmentation aligns well with human annotations of both object- and part-level\nvisual morphology, producing more monosemantic tokens and offering substantial\nefficiency advantages. For extrinsic evaluation, we designed a token embedding\nthat handles arbitrary-shaped tokens, and trained VLMs with different\ntokenizers on 4 datasets of object recognition and detailed captioning. The\nresults reveal that subobject tokenization enables faster convergence and\nbetter generalization while using fewer visual tokens.\n","authors":["Delong Chen","Samuel Cahyawijaya","Jianfeng Liu","Baoyuan Wang","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2402.14327v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11996v3","updated":"2025-03-12T18:21:04Z","published":"2024-10-15T19:04:13Z","title":"Holistic Reasoning with Long-Context LMs: A Benchmark for Database\n  Operations on Massive Textual Data","summary":"  The rapid increase in textual information means we need more efficient\nmethods to sift through, organize, and understand it all. While\nretrieval-augmented generation (RAG) models excel in accessing information from\nlarge document collections, they struggle with complex tasks that require\naggregation and reasoning over information spanning across multiple\ndocuments--what we call holistic reasoning. Long-context language models\n(LCLMs) have great potential for managing large-scale documents, but their\nholistic reasoning capabilities remain unclear. In this work, we introduce\nHoloBench, a novel framework that brings database reasoning operations into\ntext-based contexts, making it easier to systematically evaluate how LCLMs\nhandle holistic reasoning across large documents. Our approach adjusts key\nfactors such as context length, information density, distribution of\ninformation, and query complexity to evaluate LCLMs comprehensively. Our\nexperiments show that the amount of information in the context has a bigger\ninfluence on LCLM performance than the actual context length. Furthermore, the\ncomplexity of queries affects performance more than the amount of information,\nparticularly for different types of queries. Interestingly, queries that\ninvolve finding maximum or minimum values are easier for LCLMs and are less\naffected by context length, even though they pose challenges for RAG systems.\nHowever, tasks requiring the aggregation of multiple pieces of information show\na noticeable drop in accuracy as context length increases. Additionally, we\nfind that while grouping relevant information generally improves performance,\nthe optimal positioning varies across models. Our findings surface both the\nadvancements and the ongoing challenges in achieving a holistic understanding\nof long contexts.\n","authors":["Seiji Maekawa","Hayate Iso","Nikita Bhutani"],"pdf_url":"https://arxiv.org/pdf/2410.11996v3.pdf","comment":"ICLR2025"},{"id":"http://arxiv.org/abs/2503.09730v1","updated":"2025-03-12T18:20:47Z","published":"2025-03-12T18:20:47Z","title":"Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem\n  Proving","summary":"  The most promising recent methods for AI reasoning require applying variants\nof reinforcement learning (RL) either on rolled out trajectories from the\nmodel, even for the step-wise rewards, or large quantities of human annotated\ntrajectory data. The reliance on the rolled-out trajectory renders the compute\ncost and time prohibitively high. In particular, the correctness of a reasoning\ntrajectory can typically only be judged at its completion, leading to sparse\nrewards in RL or requiring expensive synthetic data generation in expert\niteration-like methods. In this work, we focus on the Automatic Theorem Proving\n(ATP) task and propose a novel verifier-in-the-loop design, which unlike\nexisting approaches that leverage feedback on the entire reasoning trajectory,\nemploys an automated verifier to give intermediate feedback at each step of the\nreasoning process. Using Lean as the verifier, we empirically show that the\nstep-by-step local verification produces a global improvement in the model's\nreasoning accuracy and efficiency.\n","authors":["Sara Rajaee","Kumar Pratik","Gabriele Cesa","Arash Behboodi"],"pdf_url":"https://arxiv.org/pdf/2503.09730v1.pdf","comment":"Accepted at ICLR 2025 Workshop on Reasoning and Planning for Large\n  Language Models"},{"id":"http://arxiv.org/abs/2503.01564v2","updated":"2025-03-12T18:12:59Z","published":"2025-03-03T14:09:13Z","title":"Attention Condensation via Sparsity Induced Regularized Training","summary":"  As the context window expands, self-attention increasingly dominates the\ntransformer's inference time. Therefore, accelerating attention computation\nwhile minimizing performance degradation is essential for the efficient\ndeployment of Large Language Models (LLMs). In this study we extend a\ntheoretical framework of attention sparsity in LLMs. A customized loss function\nis designed to enforce the sparsity by restricting the number of top elements\nin the attention matrix. We perform an initial set of evaluations with GPT-2 to\nshow the effectiveness of our sparsification approach. The attention matrices\nof the models trained with the proposed loss are both sparse and effective in\ncapturing relevant input dependencies. We now continue working to demonstrate\nthe value of our approach on larger models and different architectures.\n","authors":["Eli Sason","Darya Frolova","Boris Nazarov","Felix Goldberd"],"pdf_url":"https://arxiv.org/pdf/2503.01564v2.pdf","comment":"The loss described in the section 3 (pg 4, expression (2)) has an\n  error and needs to be corrected. The experiments should be re-run according\n  to the modified loss. This loss correction doesn't affect the general idea of\n  the paper, and the paper will be resubmitted after the new corrected\n  experimental results are obtained"},{"id":"http://arxiv.org/abs/2503.09701v1","updated":"2025-03-12T18:00:04Z","published":"2025-03-12T18:00:04Z","title":"Have LLMs Made Active Learning Obsolete? Surveying the NLP Community","summary":"  Supervised learning relies on annotated data, which is expensive to obtain. A\nlongstanding strategy to reduce annotation costs is active learning, an\niterative process, in which a human annotates only data instances deemed\ninformative by a model. Large language models (LLMs) have pushed the\neffectiveness of active learning, but have also improved methods such as few-\nor zero-shot learning, and text synthesis - thereby introducing potential\nalternatives. This raises the question: has active learning become obsolete? To\nanswer this fully, we must look beyond literature to practical experiences. We\nconduct an online survey in the NLP community to collect previously intangible\ninsights on the perceived relevance of data annotation, particularly focusing\non active learning, including best practices, obstacles and expected future\ndevelopments. Our findings show that annotated data remains a key factor, and\nactive learning continues to be relevant. While the majority of active learning\nusers find it effective, a comparison with a community survey from over a\ndecade ago reveals persistent challenges: setup complexity, estimation of cost\nreduction, and tooling. We publish an anonymized version of the collected\ndataset\n","authors":["Julia Romberg","Christopher Schröder","Julius Gonsior","Katrin Tomanek","Fredrik Olsson"],"pdf_url":"https://arxiv.org/pdf/2503.09701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19314v2","updated":"2025-03-12T18:00:00Z","published":"2024-10-25T05:59:44Z","title":"Revealing and Reducing Gender Biases in Vision and Language Assistants\n  (VLAs)","summary":"  Pre-trained large language models (LLMs) have been reliably integrated with\nvisual input for multimodal tasks. The widespread adoption of instruction-tuned\nimage-to-text vision-language assistants (VLAs) like LLaVA and InternVL\nnecessitates evaluating gender biases. We study gender bias in 22 popular\nopen-source VLAs with respect to personality traits, skills, and occupations.\nOur results show that VLAs replicate human biases likely present in the data,\nsuch as real-world occupational imbalances. Similarly, they tend to attribute\nmore skills and positive personality traits to women than to men, and we see a\nconsistent tendency to associate negative personality traits with men. To\neliminate the gender bias in these models, we find that fine-tuning-based\ndebiasing methods achieve the best trade-off between debiasing and retaining\nperformance on downstream tasks. We argue for pre-deploying gender bias\nassessment in VLAs and motivate further development of debiasing strategies to\nensure equitable societal outcomes. Code is available at\nhttps://github.com/ExplainableML/vla-gender-bias.\n","authors":["Leander Girrbach","Stephan Alaniz","Yiran Huang","Trevor Darrell","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2410.19314v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10298v1","updated":"2025-03-12T17:58:57Z","published":"2025-03-12T17:58:57Z","title":"Proceedings of the ISCA/ITG Workshop on Diversity in Large Speech and\n  Language Models","summary":"  Machine learning techniques have conquered many different tasks in speech and\nnatural language processing, such as speech recognition, information\nextraction, text and speech generation, and human machine interaction using\nnatural language or speech (chatbots). Modern techniques typically rely on\nlarge models for representing general knowledge of one or several languages\n(Large Language Models, LLMs), or for representing speech and general audio\ncharacteristics. These models have been trained with large amounts of speech\nand language data, typically including web content. When humans interact with\nsuch technologies, the effectiveness of the interaction will be influenced by\nhow far humans make use of the same type of language the models have been\ntrained on or, in other words, if the models are able to generalize to the\nlanguage used by humans when interacting with the technology. This may lead to\nsome gradual forms of adaptation in human speech and language production, and\nusers who do not adapt may be excluded from efficient use of such technologies.\nOn top of this, as commercial model development follows market needs,\nunder-represented languages and dialects/sociolects may decrease in terms of\npriorities. Furthermore, for many lesser spoken languages the necessary data is\nnot available, which will worsen a digital divide in speech and language\ntechnology usage. The workshop sets out to discuss this problem based on\nscientific contributions from the perspective of computer science and\nlinguistics (including computational linguistics and NLP).\n","authors":["Sebastian Möller","Pia Knoeferle","Britta Schulte","Nils Feldhus"],"pdf_url":"https://arxiv.org/pdf/2503.10298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09674v1","updated":"2025-03-12T17:41:25Z","published":"2025-03-12T17:41:25Z","title":"Probabilistic Reasoning with LLMs for k-anonymity Estimation","summary":"  Probabilistic reasoning is a key aspect of both human and artificial\nintelligence that allows for handling uncertainty and ambiguity in\ndecision-making. In this paper, we introduce a novel numerical reasoning task\nunder uncertainty, focusing on estimating the k-anonymity of user-generated\ndocuments containing privacy-sensitive information. We propose BRANCH, which\nuses LLMs to factorize a joint probability distribution to estimate the\nk-value-the size of the population matching the given information-by modeling\nindividual pieces of textual information as random variables. The probability\nof each factor occurring within a population is estimated using standalone LLMs\nor retrieval-augmented generation systems, and these probabilities are combined\ninto a final k-value. Our experiments show that this method successfully\nestimates the correct k-value 67% of the time, an 11% increase compared to\nGPT-4o chain-of-thought reasoning. Additionally, we leverage LLM uncertainty to\ndevelop prediction intervals for k-anonymity, which include the correct value\nin nearly 92% of cases.\n","authors":["Jonathan Zheng","Sauvik Das","Alan Ritter","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2503.09674v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2503.09656v1","updated":"2025-03-12T11:45:11Z","published":"2025-03-12T11:45:11Z","title":"LLM-PS: Empowering Large Language Models for Time Series Forecasting\n  with Temporal Patterns and Semantics","summary":"  Time Series Forecasting (TSF) is critical in many real-world domains like\nfinancial planning and health monitoring. Recent studies have revealed that\nLarge Language Models (LLMs), with their powerful in-contextual modeling\ncapabilities, hold significant potential for TSF. However, existing LLM-based\nmethods usually perform suboptimally because they neglect the inherent\ncharacteristics of time series data. Unlike the textual data used in LLM\npre-training, the time series data is semantically sparse and comprises\ndistinctive temporal patterns. To address this problem, we propose LLM-PS to\nempower the LLM for TSF by learning the fundamental \\textit{Patterns} and\nmeaningful \\textit{Semantics} from time series data. Our LLM-PS incorporates a\nnew multi-scale convolutional neural network adept at capturing both short-term\nfluctuations and long-term trends within the time series. Meanwhile, we\nintroduce a time-to-text module for extracting valuable semantics across\ncontinuous time intervals rather than isolated time points. By integrating\nthese patterns and semantics, LLM-PS effectively models temporal dependencies,\nenabling a deep comprehension of time series and delivering accurate forecasts.\nIntensive experimental results demonstrate that LLM-PS achieves\nstate-of-the-art performance in both short- and long-term forecasting tasks, as\nwell as in few- and zero-shot settings.\n","authors":["Jialiang Tang","Shuo Chen","Chen Gong","Jing Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2503.09656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09645v1","updated":"2025-03-12T07:25:32Z","published":"2025-03-12T07:25:32Z","title":"Global Position Aware Group Choreography using Large Language Model","summary":"  Dance serves as a profound and universal expression of human culture,\nconveying emotions and stories through movements synchronized with music.\nAlthough some current works have achieved satisfactory results in the task of\nsingle-person dance generation, the field of multi-person dance generation\nremains relatively novel. In this work, we present a group choreography\nframework that leverages recent advancements in Large Language Models (LLM) by\nmodeling the group dance generation problem as a sequence-to-sequence\ntranslation task. Our framework consists of a tokenizer that transforms\ncontinuous features into discrete tokens, and an LLM that is fine-tuned to\npredict motion tokens given the audio tokens. We show that by proper\ntokenization of input modalities and careful design of the LLM training\nstrategies, our framework can generate realistic and diverse group dances while\nmaintaining strong music correlation and dancer-wise consistency. Extensive\nexperiments and evaluations demonstrate that our framework achieves\nstate-of-the-art performance.\n","authors":["Haozhou Pang","Tianwei Ding","Lanshan He","Qi Gan"],"pdf_url":"https://arxiv.org/pdf/2503.09645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09639v1","updated":"2025-03-12T02:54:15Z","published":"2025-03-12T02:54:15Z","title":"Can A Society of Generative Agents Simulate Human Behavior and Inform\n  Public Health Policy? A Case Study on Vaccine Hesitancy","summary":"  Can we simulate a sandbox society with generative agents to model human\nbehavior, thereby reducing the over-reliance on real human trials for assessing\npublic policies? In this work, we investigate the feasibility of simulating\nhealth-related decision-making, using vaccine hesitancy, defined as the delay\nin acceptance or refusal of vaccines despite the availability of vaccination\nservices (MacDonald, 2015), as a case study. To this end, we introduce the\nVacSim framework with 100 generative agents powered by Large Language Models\n(LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1)\ninstantiate a population of agents with demographics based on census data; 2)\nconnect the agents via a social network and model vaccine attitudes as a\nfunction of social dynamics and disease-related information; 3) design and\nevaluate various public health interventions aimed at mitigating vaccine\nhesitancy. To align with real-world results, we also introduce simulation\nwarmup and attitude modulation to adjust agents' attitudes. We propose a series\nof evaluations to assess the reliability of various LLM simulations.\nExperiments indicate that models like Llama and Qwen can simulate aspects of\nhuman behavior but also highlight real-world alignment challenges, such as\ninconsistent responses with demographic profiles. This early exploration of\nLLM-driven simulations is not meant to serve as definitive policy guidance;\ninstead, it serves as a call for action to examine social simulation for policy\ndevelopment.\n","authors":["Abe Bohan Hou","Hongru Du","Yichen Wang","Jingyu Zhang","Zixiao Wang","Paul Pu Liang","Daniel Khashabi","Lauren Gardner","Tianxing He"],"pdf_url":"https://arxiv.org/pdf/2503.09639v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.09592v1","updated":"2025-03-12T17:57:48Z","published":"2025-03-12T17:57:48Z","title":"Parsing the Language of Expression: Enhancing Symbolic Regression with\n  Domain-Aware Symbolic Priors","summary":"  Symbolic regression is essential for deriving interpretable expressions that\nelucidate complex phenomena by exposing the underlying mathematical and\nphysical relationships in data. In this paper, we present an advanced symbolic\nregression method that integrates symbol priors from diverse scientific domains\n- including physics, biology, chemistry, and engineering - into the regression\nprocess. By systematically analyzing domain-specific expressions, we derive\nprobability distributions of symbols to guide expression generation. We propose\nnovel tree-structured recurrent neural networks (RNNs) that leverage these\nsymbol priors, enabling domain knowledge to steer the learning process.\nAdditionally, we introduce a hierarchical tree structure for representing\nexpressions, where unary and binary operators are organized to facilitate more\nefficient learning. To further accelerate training, we compile characteristic\nexpression blocks from each domain and include them in the operator dictionary,\nproviding relevant building blocks. Experimental results demonstrate that\nleveraging symbol priors significantly enhances the performance of symbolic\nregression, resulting in faster convergence and higher accuracy.\n","authors":["Sikai Huang","Yixin Berry Wen","Tara Adusumilli","Kusum Choudhary","Haizhao Yang"],"pdf_url":"https://arxiv.org/pdf/2503.09592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09587v1","updated":"2025-03-12T17:56:28Z","published":"2025-03-12T17:56:28Z","title":"Fair Federated Medical Image Classification Against Quality Shift via\n  Inter-Client Progressive State Matching","summary":"  Despite the potential of federated learning in medical applications,\ninconsistent imaging quality across institutions-stemming from lower-quality\ndata from a minority of clients-biases federated models toward more common\nhigh-quality images. This raises significant fairness concerns. Existing fair\nfederated learning methods have demonstrated some effectiveness in solving this\nproblem by aligning a single 0th- or 1st-order state of convergence (e.g.,\ntraining loss or sharpness). However, we argue in this work that fairness based\non such a single state is still not an adequate surrogate for fairness during\ntesting, as these single metrics fail to fully capture the convergence\ncharacteristics, making them suboptimal for guiding fair learning. To address\nthis limitation, we develop a generalized framework. Specifically, we propose\nassessing convergence using multiple states, defined as sharpness or perturbed\nloss computed at varying search distances. Building on this comprehensive\nassessment, we propose promoting fairness for these states across clients to\nachieve our ultimate fairness objective. This is accomplished through the\nproposed method, FedISM+. In FedISM+, the search distance evolves over time,\nprogressively focusing on different states. We then incorporate two components\nin local training and global aggregation to ensure cross-client fairness for\neach state. This gradually makes convergence equitable for all states, thereby\nimproving fairness during testing. Our empirical evaluations, performed on the\nwell-known RSNA ICH and ISIC 2019 datasets, demonstrate the superiority of\nFedISM+ over existing state-of-the-art methods for fair federated learning. The\ncode is available at https://github.com/wnn2000/FFL4MIA.\n","authors":["Nannan Wu","Zhuo Kuang","Zengqiang Yan","Ping Wang","Li Yu"],"pdf_url":"https://arxiv.org/pdf/2503.09587v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.09583v1","updated":"2025-03-12T17:51:29Z","published":"2025-03-12T17:51:29Z","title":"Minimax Optimality of the Probability Flow ODE for Diffusion Models","summary":"  Score-based diffusion models have become a foundational paradigm for modern\ngenerative modeling, demonstrating exceptional capability in generating samples\nfrom complex high-dimensional distributions. Despite the dominant adoption of\nprobability flow ODE-based samplers in practice due to their superior sampling\nefficiency and precision, rigorous statistical guarantees for these methods\nhave remained elusive in the literature. This work develops the first\nend-to-end theoretical framework for deterministic ODE-based samplers that\nestablishes near-minimax optimal guarantees under mild assumptions on target\ndata distributions. Specifically, focusing on subgaussian distributions with\n$\\beta$-H\\\"older smooth densities for $\\beta\\leq 2$, we propose a smooth\nregularized score estimator that simultaneously controls both the $L^2$ score\nerror and the associated mean Jacobian error. Leveraging this estimator within\na refined convergence analysis of the ODE-based sampling process, we\ndemonstrate that the resulting sampler achieves the minimax rate in total\nvariation distance, modulo logarithmic factors. Notably, our theory\ncomprehensively accounts for all sources of error in the sampling process and\ndoes not require strong structural conditions such as density lower bounds or\nLipschitz/smooth scores on target distributions, thereby covering a broad range\nof practical data distributions.\n","authors":["Changxiao Cai","Gen Li"],"pdf_url":"https://arxiv.org/pdf/2503.09583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09579v1","updated":"2025-03-12T17:50:42Z","published":"2025-03-12T17:50:42Z","title":"Cost-Optimal Grouped-Query Attention for Long-Context LLMs","summary":"  Building effective and efficient Transformer-based large language models\n(LLMs) has recently become a research focus, requiring maximizing model\nlanguage capabilities and minimizing training and deployment costs. Existing\nefforts have primarily described complex relationships among model performance,\nparameter size, and data size, as well as searched for the optimal compute\nallocation to train LLMs. However, they overlook the impacts of context length\nand attention head configuration (the number of query and key-value heads in\ngrouped-query attention) on training and inference. In this paper, we\nsystematically compare models with different parameter sizes, context lengths,\nand attention head configurations in terms of model performance, computational\ncost, and memory cost. Then, we extend the existing scaling methods, which are\nbased solely on parameter size and training compute, to guide the construction\nof cost-optimal LLMs during both training and inference. Our quantitative\nscaling studies show that, when processing sufficiently long sequences, a\nlarger model with fewer attention heads can achieve a lower loss while\nincurring lower computational and memory costs. Our findings provide valuable\ninsights for developing practical LLMs, especially in long-context processing\nscenarios. We will publicly release our code and data.\n","authors":["Yingfa Chen","Yutong Wu","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2503.09579v1.pdf","comment":"16 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.09576v1","updated":"2025-03-12T17:44:40Z","published":"2025-03-12T17:44:40Z","title":"Manify: A Python Library for Learning Non-Euclidean Representations","summary":"  We present Manify, an open-source Python library for non-Euclidean\nrepresentation learning. Leveraging manifold learning techniques, Manify\nprovides tools for learning embeddings in (products of) non-Euclidean spaces,\nperforming classification and regression with data that lives in such spaces,\nand estimating the curvature of a manifold. Manify aims to advance research and\napplications in machine learning by offering a comprehensive suite of tools for\nmanifold-based data analysis. Our source code, examples, datasets, results, and\ndocumentation are available at https://github.com/pchlenski/manify\n","authors":["Philippe Chlenski","Kaizhu Du","Dylan Satow","Itsik Pe'er"],"pdf_url":"https://arxiv.org/pdf/2503.09576v1.pdf","comment":"30 pages, 4 figures, 4 tables. Preprint"},{"id":"http://arxiv.org/abs/2503.09573v1","updated":"2025-03-12T17:43:40Z","published":"2025-03-12T17:43:40Z","title":"Block Diffusion: Interpolating Between Autoregressive and Diffusion\n  Language Models","summary":"  Diffusion language models offer unique benefits over autoregressive models\ndue to their potential for parallelized generation and controllability, yet\nthey lag in likelihood modeling and are limited to fixed-length generation. In\nthis work, we introduce a class of block diffusion language models that\ninterpolate between discrete denoising diffusion and autoregressive models.\nBlock diffusion overcomes key limitations of both approaches by supporting\nflexible-length generation and improving inference efficiency with KV caching\nand parallel token sampling. We propose a recipe for building effective block\ndiffusion models that includes an efficient training algorithm, estimators of\ngradient variance, and data-driven noise schedules to minimize the variance.\nBlock diffusion sets a new state-of-the-art performance among diffusion models\non language modeling benchmarks and enables generation of arbitrary-length\nsequences. We provide the code, along with the model weights and blog post on\nthe project page: https://m-arriola.com/bd3lms/\n","authors":["Marianne Arriola","Aaron Gokaslan","Justin T Chiu","Zhihan Yang","Zhixuan Qi","Jiaqi Han","Subham Sekhar Sahoo","Volodymyr Kuleshov"],"pdf_url":"https://arxiv.org/pdf/2503.09573v1.pdf","comment":"ICLR 2025 Oral. We provide the code at\n  https://github.com/kuleshov-group/bd3lms"},{"id":"http://arxiv.org/abs/2503.09565v1","updated":"2025-03-12T17:33:13Z","published":"2025-03-12T17:33:13Z","title":"Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width\n  Neural Networks under $μ$P Parametrization","summary":"  Despite deep neural networks' powerful representation learning capabilities,\ntheoretical understanding of how networks can simultaneously achieve meaningful\nfeature learning and global convergence remains elusive. Existing approaches\nlike the neural tangent kernel (NTK) are limited because features stay close to\ntheir initialization in this parametrization, leaving open questions about\nfeature properties during substantial evolution. In this paper, we investigate\nthe training dynamics of infinitely wide, $L$-layer neural networks using the\ntensor program (TP) framework. Specifically, we show that, when trained with\nstochastic gradient descent (SGD) under the Maximal Update parametrization\n($\\mu$P) and mild conditions on the activation function, SGD enables these\nnetworks to learn linearly independent features that substantially deviate from\ntheir initial values. This rich feature space captures relevant data\ninformation and ensures that any convergent point of the training process is a\nglobal minimum. Our analysis leverages both the interactions among features\nacross layers and the properties of Gaussian random variables, providing new\ninsights into deep representation learning. We further validate our theoretical\nfindings through experiments on real-world datasets.\n","authors":["Zixiang Chen","Greg Yang","Qingyue Zhao","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2503.09565v1.pdf","comment":"29 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.04766v2","updated":"2025-03-12T17:30:41Z","published":"2024-12-06T04:18:49Z","title":"DAWN-FM: Data-Aware and Noise-Informed Flow Matching for Solving Inverse\n  Problems","summary":"  Inverse problems, which involve estimating parameters from incomplete or\nnoisy observations, arise in various fields such as medical imaging,\ngeophysics, and signal processing. These problems are often ill-posed,\nrequiring regularization techniques to stabilize the solution. In this work, we\nemploy Flow Matching (FM), a generative framework that integrates a\ndeterministic processes to map a simple reference distribution, such as a\nGaussian, to the target distribution. Our method DAWN-FM: Data-AWare and\nNoise-informed Flow Matching incorporates data and noise embedding, allowing\nthe model to access representations about the measured data explicitly and also\naccount for noise in the observations, making it particularly robust in\nscenarios where data is noisy or incomplete. By learning a time-dependent\nvelocity field, FM not only provides accurate solutions but also enables\nuncertainty quantification by generating multiple plausible outcomes. Unlike\npre-trained diffusion models, which may struggle in highly ill-posed settings,\nour approach is trained specifically for each inverse problem and adapts to\nvarying noise levels. We validate the effectiveness and robustness of our\nmethod through extensive numerical experiments on tasks such as image\ndeblurring and tomography.\n","authors":["Shadab Ahamed","Eldad Haber"],"pdf_url":"https://arxiv.org/pdf/2412.04766v2.pdf","comment":"27 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.09561v1","updated":"2025-03-12T17:25:52Z","published":"2025-03-12T17:25:52Z","title":"Strategyproof Reinforcement Learning from Human Feedback","summary":"  We study Reinforcement Learning from Human Feedback (RLHF), where multiple\nindividuals with diverse preferences provide feedback strategically to sway the\nfinal policy in their favor. We show that existing RLHF methods are not\nstrategyproof, which can result in learning a substantially misaligned policy\neven when only one out of $k$ individuals reports their preferences\nstrategically. In turn, we also find that any strategyproof RLHF algorithm must\nperform $k$-times worse than the optimal policy, highlighting an inherent\ntrade-off between incentive alignment and policy alignment. We then propose a\npessimistic median algorithm that, under appropriate coverage assumptions, is\napproximately strategyproof and converges to the optimal policy as the number\nof individuals and samples increases.\n","authors":["Thomas Kleine Buening","Jiarui Gan","Debmalya Mandal","Marta Kwiatkowska"],"pdf_url":"https://arxiv.org/pdf/2503.09561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09559v1","updated":"2025-03-12T17:24:47Z","published":"2025-03-12T17:24:47Z","title":"The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic\n  Resonance Imaging","summary":"  We introduce the R2D2 Deep Neural Network (DNN) series paradigm for fast and\nscalable image reconstruction from highly-accelerated non-Cartesian k-space\nacquisitions in Magnetic Resonance Imaging (MRI). While unrolled DNN\narchitectures provide a robust image formation approach via data-consistency\nlayers, embedding non-uniform fast Fourier transform operators in a DNN can\nbecome impractical to train at large scale, e.g in 2D MRI with a large number\nof coils, or for higher-dimensional imaging. Plug-and-play approaches that\nalternate a learned denoiser blind to the measurement setting with a\ndata-consistency step are not affected by this limitation but their highly\niterative nature implies slow reconstruction. To address this scalability\nchallenge, we leverage the R2D2 paradigm that was recently introduced to enable\nultra-fast reconstruction for large-scale Fourier imaging in radio astronomy.\nR2D2's reconstruction is formed as a series of residual images iteratively\nestimated as outputs of DNN modules taking the previous iteration's data\nresidual as input. The method can be interpreted as a learned version of the\nMatching Pursuit algorithm. A series of R2D2 DNN modules were sequentially\ntrained in a supervised manner on the fastMRI dataset and validated for 2D\nmulti-coil MRI in simulation and on real data, targeting highly under-sampled\nradial k-space sampling. Results suggest that a series with only few DNNs\nachieves superior reconstruction quality over its unrolled incarnation R2D2-Net\n(whose training is also much less scalable), and over the state-of-the-art\ndiffusion-based \"Decomposed Diffusion Sampler\" approach (also characterised by\na slower reconstruction process).\n","authors":["Yiwei Chen","Amir Aghabiglou","Shijie Chen","Motahare Torki","Chao Tang","Ruud B. van Heeswijk","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2503.09559v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.11977v4","updated":"2025-03-12T17:10:33Z","published":"2024-10-15T18:33:42Z","title":"Generative AI Policies under the Microscope: How CS Conferences Are\n  Navigating the New Frontier in Scholarly Writing","summary":"  As the use of Generative AI (Gen-AI) in scholarly writing and peer reviews\ncontinues to rise, it is essential for the computing field to establish and\nadopt clear Gen-AI policies. This study examines the landscape of Gen-AI\npolicies across 64 major Computer Science conferences and offers\nrecommendations for promoting more effective and responsible use of Gen-AI in\nthe field.\n","authors":["Mahjabin Nahar","Sian Lee","Rebekah Guillen","Dongwon Lee"],"pdf_url":"https://arxiv.org/pdf/2410.11977v4.pdf","comment":"Accepted and to appear in Communications of the ACM (CACM) in 2025"},{"id":"http://arxiv.org/abs/2409.13671v2","updated":"2025-03-12T17:08:05Z","published":"2024-09-20T17:26:38Z","title":"A Generative Framework for Predictive Modeling of Multiple Chronic\n  Conditions Using Graph Variational Autoencoder and Bandit-Optimized Graph\n  Neural Network","summary":"  Predicting the emergence of multiple chronic conditions (MCC) is crucial for\nearly intervention and personalized healthcare, as MCC significantly impacts\npatient outcomes and healthcare costs. Graph neural networks (GNNs) are\neffective methods for modeling complex graph data, such as those found in MCC.\nHowever, a significant challenge with GNNs is their reliance on an existing\ngraph structure, which is not readily available for MCC. To address this\nchallenge, we propose a novel generative framework for GNNs that constructs a\nrepresentative underlying graph structure by utilizing the distribution of the\ndata to enhance predictive analytics for MCC. Our framework employs a graph\nvariational autoencoder (GVAE) to capture the complex relationships in patient\ndata. This allows for a comprehensive understanding of individual health\ntrajectories and facilitates the creation of diverse patient stochastic\nsimilarity graphs while preserving the original feature set. These variations\nof patient stochastic similarity graphs, generated from the GVAE decoder, are\nthen processed by a GNN using a novel Laplacian regularization technique to\nrefine the graph structure over time and improves the prediction accuracy of\nMCC. A contextual Bandit is designed to evaluate the stochastically generated\ngraphs and identify the best-performing graph for the GNN model iteratively\nuntil model convergence. We validate the performance of the proposed contextual\nBandit algorithm against $\\varepsilon$-Greedy and multi-armed Bandit algorithms\non a large cohort (n = 1,592) of patients with MCC. These advancements\nhighlight the potential of the proposed approach to transform predictive\nhealthcare analytics, enabling a more personalized and proactive approach to\nMCC management.\n","authors":["Julian Carvajal Rico","Adel Alaeddini","Syed Hasib Akhter Faruqui","Susan P Fisher-Hoch","Joseph B Mccormick"],"pdf_url":"https://arxiv.org/pdf/2409.13671v2.pdf","comment":"Submitted for review in IEEE Journal of Biomedical and Health\n  Informatics"},{"id":"http://arxiv.org/abs/2411.07223v2","updated":"2025-03-12T17:03:25Z","published":"2024-11-11T18:43:44Z","title":"Grounding Video Models to Actions through Goal Conditioned Exploration","summary":"  Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.\n","authors":["Yunhao Luo","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2411.07223v2.pdf","comment":"ICLR 2025 (Spotlight). Project page:\n  https://video-to-action.github.io/"},{"id":"http://arxiv.org/abs/2503.09543v1","updated":"2025-03-12T16:59:30Z","published":"2025-03-12T16:59:30Z","title":"PolyPythias: Stability and Outliers across Fifty Language Model\n  Pre-Training Runs","summary":"  The stability of language model pre-training and its effects on downstream\nperformance are still understudied. Prior work shows that the training process\ncan yield significantly different results in response to slight variations in\ninitial conditions, e.g., the random seed. Crucially, the research community\nstill lacks sufficient resources and tools to systematically investigate\npre-training stability, particularly for decoder-only language models. We\nintroduce the PolyPythias, a set of 45 new training runs for the Pythia model\nsuite: 9 new seeds across 5 model sizes, from 14M to 410M parameters, resulting\nin about 7k new checkpoints that we release. Using these new 45 training runs,\nin addition to the 5 already available, we study the effects of different\ninitial conditions determined by the seed -- i.e., parameters' initialisation\nand data order -- on (i) downstream performance, (ii) learned linguistic\nrepresentations, and (iii) emergence of training phases. In addition to common\nscaling behaviours, our analyses generally reveal highly consistent training\ndynamics across both model sizes and initial conditions. Further, the new seeds\nfor each model allow us to identify outlier training runs and delineate their\ncharacteristics. Our findings show the potential of using these methods to\npredict training stability.\n","authors":["Oskar van der Wal","Pietro Lesci","Max Muller-Eberstein","Naomi Saphra","Hailey Schoelkopf","Willem Zuidema","Stella Biderman"],"pdf_url":"https://arxiv.org/pdf/2503.09543v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09541v1","updated":"2025-03-12T16:58:52Z","published":"2025-03-12T16:58:52Z","title":"Neural Network-Based Change Point Detection for Large-Scale\n  Time-Evolving Data","summary":"  The paper studies the problem of detecting and locating change points in\nmultivariate time-evolving data. The problem has a long history in statistics\nand signal processing and various algorithms have been developed primarily for\nsimple parametric models. In this work, we focus on modeling the data through\nfeed-forward neural networks and develop a detection strategy based on the\nfollowing two-step procedure. In the first step, the neural network is trained\nover a prespecified window of the data, and its test error function is\ncalibrated over another prespecified window. Then, the test error function is\nused over a moving window to identify the change point. Once a change point is\ndetected, the procedure involving these two steps is repeated until all change\npoints are identified. The proposed strategy yields consistent estimates for\nboth the number and the locations of the change points under temporal\ndependence of the data-generating process. The effectiveness of the proposed\nstrategy is illustrated on synthetic data sets that provide insights on how to\nselect in practice tuning parameters of the algorithm and in real data sets.\nFinally, we note that although the detection strategy is general and can work\nwith different neural network architectures, the theoretical guarantees\nprovided are specific to feed-forward neural architectures.\n","authors":["Jialiang Geng","George Michailidis"],"pdf_url":"https://arxiv.org/pdf/2503.09541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09538v1","updated":"2025-03-12T16:54:23Z","published":"2025-03-12T16:54:23Z","title":"Differentially Private Equilibrium Finding in Polymatrix Games","summary":"  We study equilibrium finding in polymatrix games under differential privacy\nconstraints. To start, we show that high accuracy and asymptotically vanishing\ndifferential privacy budget (as the number of players goes to infinity) cannot\nbe achieved simultaneously under either of the two settings: (i) We seek to\nestablish equilibrium approximation guarantees in terms of Euclidean distance\nto the equilibrium set, and (ii) the adversary has access to all communication\nchannels. Then, assuming the adversary has access to a constant number of\ncommunication channels, we develop a novel distributed algorithm that recovers\nstrategies with simultaneously vanishing Nash gap (in expected utility, also\nreferred to as exploitability and privacy budget as the number of players\nincreases.\n","authors":["Mingyang Liu","Gabriele Farina","Asuman Ozdaglar"],"pdf_url":"https://arxiv.org/pdf/2503.09538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09533v1","updated":"2025-03-12T16:49:56Z","published":"2025-03-12T16:49:56Z","title":"Large Language Models for Multi-Facility Location Mechanism Design","summary":"  Designing strategyproof mechanisms for multi-facility location that optimize\nsocial costs based on agent preferences had been challenging due to the\nextensive domain knowledge required and poor worst-case guarantees. Recently,\ndeep learning models have been proposed as alternatives. However, these models\nrequire some domain knowledge and extensive hyperparameter tuning as well as\nlacking interpretability, which is crucial in practice when transparency of the\nlearned mechanisms is mandatory. In this paper, we introduce a novel approach,\nnamed LLMMech, that addresses these limitations by incorporating large language\nmodels (LLMs) into an evolutionary framework for generating interpretable,\nhyperparameter-free, empirically strategyproof, and nearly optimal mechanisms.\nOur experimental results, evaluated on various problem settings where the\nsocial cost is arbitrarily weighted across agents and the agent preferences may\nnot be uniformly distributed, demonstrate that the LLM-generated mechanisms\ngenerally outperform existing handcrafted baselines and deep learning models.\nFurthermore, the mechanisms exhibit impressive generalizability to\nout-of-distribution agent preferences and to larger instances with more agents.\n","authors":["Nguyen Thach","Fei Liu","Houyu Zhou","Hau Chan"],"pdf_url":"https://arxiv.org/pdf/2503.09533v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.09532v1","updated":"2025-03-12T16:49:02Z","published":"2025-03-12T16:49:02Z","title":"SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language\n  Model Interpretability","summary":"  Sparse autoencoders (SAEs) are a popular technique for interpreting language\nmodel activations, and there is extensive recent work on improving SAE\neffectiveness. However, most prior work evaluates progress using unsupervised\nproxy metrics with unclear practical relevance. We introduce SAEBench, a\ncomprehensive evaluation suite that measures SAE performance across seven\ndiverse metrics, spanning interpretability, feature disentanglement and\npractical applications like unlearning. To enable systematic comparison, we\nopen-source a suite of over 200 SAEs across eight recently proposed SAE\narchitectures and training algorithms. Our evaluation reveals that gains on\nproxy metrics do not reliably translate to better practical performance. For\ninstance, while Matryoshka SAEs slightly underperform on existing proxy\nmetrics, they substantially outperform other architectures on feature\ndisentanglement metrics; moreover, this advantage grows with SAE scale. By\nproviding a standardized framework for measuring progress in SAE development,\nSAEBench enables researchers to study scaling trends and make nuanced\ncomparisons between different SAE architectures and training methodologies. Our\ninteractive interface enables researchers to flexibly visualize relationships\nbetween metrics across hundreds of open-source SAEs at: https://saebench.xyz\n","authors":["Adam Karvonen","Can Rager","Johnny Lin","Curt Tigges","Joseph Bloom","David Chanin","Yeu-Tong Lau","Eoin Farrell","Callum McDougall","Kola Ayonrinde","Matthew Wearden","Arthur Conmy","Samuel Marks","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2503.09532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05126v3","updated":"2025-03-12T16:43:00Z","published":"2025-03-07T04:13:02Z","title":"Multi-Task Reinforcement Learning Enables Parameter Scaling","summary":"  Multi-task reinforcement learning (MTRL) aims to endow a single agent with\nthe ability to perform well on multiple tasks. Recent works have focused on\ndeveloping novel sophisticated architectures to improve performance, often\nresulting in larger models; it is unclear, however, whether the performance\ngains are a consequence of the architecture design itself or the extra\nparameters. We argue that gains are mostly due to scale by demonstrating that\nnaively scaling up a simple MTRL baseline to match parameter counts outperforms\nthe more sophisticated architectures, and these gains benefit most from scaling\nthe critic over the actor. Additionally, we explore the training stability\nadvantages that come with task diversity, demonstrating that increasing the\nnumber of tasks can help mitigate plasticity loss. Our findings suggest that\nMTRL's simultaneous training across multiple tasks provides a natural framework\nfor beneficial parameter scaling in reinforcement learning, challenging the\nneed for complex architectural innovations.\n","authors":["Reginald McLean","Evangelos Chatzaroulas","Jordan Terry","Isaac Woungang","Nariman Farsad","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2503.05126v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16238v2","updated":"2025-03-12T16:31:39Z","published":"2024-12-19T13:01:21Z","title":"Algebraic Evaluation Theorems","summary":"  Majority voting (MV) is the prototypical ``wisdom of the crowd'' algorithm.\nTheorems considering when MV is optimal for group decisions date back to\nCondorcet's 1785 jury \\emph{decision} theorem. The same error independence\nassumption underlying the theorem can be used to prove a jury \\emph{evaluation}\ntheorem that does purely algebraic evaluation (AE) of juror performance based\non a batch of their decisions. Three or more binary jurors are enough to obtain\nthe only two possible statistics of their correctness on a test they took. AE\nis superior to MV in three ways. First, its empirical assumptions are looser\nand can handle jurors less than 50\\% accurate in making decisions. Second, it\nhas point-like precision in evaluating them given its assumption of error\nindependence. This precision enables a multi-accuracy approach that has higher\nlabeling accuracy than MV and comes with empirical uncertainty bounds. And,\nthird, it is self-alarming about the failure of its error independence\nassumption. Experiments using demographic data from the American Community\nSurvey confirm the practical utility of AE over MV. Two implications of the\ntheorem for AI safety are discussed - a principled way to terminate infinite\nmonitoring chains (who grades the graders?) and the super-alignment problem\n(how do we evaluate agents doing tasks we do not understand?).\n","authors":["Andrés Corrada-Emmanuel"],"pdf_url":"https://arxiv.org/pdf/2412.16238v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2503.06001v2","updated":"2025-03-12T16:22:51Z","published":"2025-03-08T01:12:27Z","title":"Analyzing the Role of Permutation Invariance in Linear Mode Connectivity","summary":"  It was empirically observed in Entezari et al. (2021) that when accounting\nfor the permutation invariance of neural networks, there is likely no loss\nbarrier along the linear interpolation between two SGD solutions -- a\nphenomenon known as linear mode connectivity (LMC) modulo permutation. This\nphenomenon has sparked significant attention due to both its theoretical\ninterest and practical relevance in applications such as model merging. In this\npaper, we provide a fine-grained analysis of this phenomenon for two-layer ReLU\nnetworks under a teacher-student setup. We show that as the student network\nwidth $m$ increases, the LMC loss barrier modulo permutation exhibits a double\ndescent behavior. Particularly, when $m$ is sufficiently large, the barrier\ndecreases to zero at a rate $O(m^{-1/2})$. Notably, this rate does not suffer\nfrom the curse of dimensionality and demonstrates how substantial permutation\ncan reduce the LMC loss barrier. Moreover, we observe a sharp transition in the\nsparsity of GD/SGD solutions when increasing the learning rate and investigate\nhow this sparsity preference affects the LMC loss barrier modulo permutation.\nExperiments on both synthetic and MNIST datasets corroborate our theoretical\npredictions and reveal a similar trend for more complex network architectures.\n","authors":["Keyao Zhan","Puheng Li","Lei Wu"],"pdf_url":"https://arxiv.org/pdf/2503.06001v2.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.09512v1","updated":"2025-03-12T16:22:28Z","published":"2025-03-12T16:22:28Z","title":"Reinforcement Learning is all You Need","summary":"  Inspired by the success of DeepSeek R1 in reasoning via reinforcement\nlearning without human feedback, we train a 3B language model using the\nCountdown Game with pure reinforcement learning. Our model outperforms\nbaselines on four of five benchmarks, demonstrating improved generalization\nbeyond its training data. Notably, response length does not correlate with\nreasoning quality, and while \"aha moments\" emerge, they do not always yield\ncorrect answers. These findings highlight the potential of RL-only training for\nreasoning enhancement and suggest future work on refining reward structures to\nbridge emergent insights with accuracy.\n","authors":["Yongsheng Lian"],"pdf_url":"https://arxiv.org/pdf/2503.09512v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.09504v1","updated":"2025-03-12T16:13:50Z","published":"2025-03-12T16:13:50Z","title":"Double-Stage Feature-Level Clustering-Based Mixture of Experts Framework","summary":"  The Mixture-of-Experts (MoE) model has succeeded in deep learning (DL).\nHowever, its complex architecture and advantages over dense models in image\nclassification remain unclear. In previous studies, MoE performance has often\nbeen affected by noise and outliers in the input space. Some approaches\nincorporate input clustering for training MoE models, but most clustering\nalgorithms lack access to labeled data, limiting their effectiveness. This\npaper introduces the Double-stage Feature-level Clustering and\nPseudo-labeling-based Mixture of Experts (DFCP-MoE) framework, which consists\nof input feature extraction, feature-level clustering, and a computationally\nefficient pseudo-labeling strategy. This approach reduces the impact of noise\nand outliers while leveraging a small subset of labeled data to label a large\nportion of unlabeled inputs. We propose a conditional end-to-end joint training\nmethod that improves expert specialization by training the MoE model on\nwell-labeled, clustered inputs. Unlike traditional MoE and dense models, the\nDFCP-MoE framework effectively captures input space diversity, leading to\ncompetitive inference results. We validate our approach on three benchmark\ndatasets for multi-class classification tasks.\n","authors":["Bakary Badjie","José Cecílio","António Casimiro"],"pdf_url":"https://arxiv.org/pdf/2503.09504v1.pdf","comment":"14 Pages, 1 Figure, and 3 Tables"},{"id":"http://arxiv.org/abs/2503.09501v1","updated":"2025-03-12T16:05:31Z","published":"2025-03-12T16:05:31Z","title":"ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement\n  Learning","summary":"  Recent research on Reasoning of Large Language Models (LLMs) has sought to\nfurther enhance their performance by integrating meta-thinking -- enabling\nmodels to monitor, evaluate, and control their reasoning processes for more\nadaptive and effective problem-solving. However, current single-agent work\nlacks a specialized design for acquiring meta-thinking, resulting in low\nefficacy. To address this challenge, we introduce Reinforced Meta-thinking\nAgents (ReMA), a novel framework that leverages Multi-Agent Reinforcement\nLearning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think\nabout thinking. ReMA decouples the reasoning process into two hierarchical\nagents: a high-level meta-thinking agent responsible for generating strategic\noversight and plans, and a low-level reasoning agent for detailed executions.\nThrough iterative reinforcement learning with aligned objectives, these agents\nexplore and learn collaboration, leading to improved generalization and\nrobustness. Experimental results demonstrate that ReMA outperforms single-agent\nRL baselines on complex reasoning tasks, including competitive-level\nmathematical benchmarks and LLM-as-a-Judge benchmarks. Comprehensive ablation\nstudies further illustrate the evolving dynamics of each distinct agent,\nproviding valuable insights into how the meta-thinking reasoning process\nenhances the reasoning capabilities of LLMs.\n","authors":["Ziyu Wan","Yunxiang Li","Yan Song","Hanjing Wang","Linyi Yang","Mark Schmidt","Jun Wang","Weinan Zhang","Shuyue Hu","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2503.09501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12739v2","updated":"2025-03-12T16:05:08Z","published":"2025-01-22T09:13:47Z","title":"Multiscale Stochastic Gradient Descent: Efficiently Training\n  Convolutional Neural Networks","summary":"  Stochastic Gradient Descent (SGD) is the foundation of modern deep learning\noptimization but becomes increasingly inefficient when training convolutional\nneural networks (CNNs) on high-resolution data. This paper introduces\nMultiscale Stochastic Gradient Descent (Multiscale-SGD), a novel optimization\napproach that exploits coarse-to-fine training strategies to estimate the\ngradient at a fraction of the cost, improving the computational efficiency of\nSGD type methods while preserving model accuracy. We derive theoretical\ncriteria for Multiscale-SGD to be effective, and show that while standard\nconvolutions can be used, they can be suboptimal for noisy data. This leads us\nto introduce a new class of learnable, scale-independent Mesh-Free Convolutions\n(MFCs) that ensure consistent gradient behavior across resolutions, making them\nwell-suited for multiscale training. Through extensive empirical validation, we\ndemonstrate that in practice, (i) our Multiscale-SGD approach can be used to\ntrain various architectures for a variety of tasks, and (ii) when the noise is\nnot significant, standard convolutions benefit from our multiscale training\nframework. Our results establish a new paradigm for the efficient training of\ndeep networks, enabling practical scalability in high-resolution and multiscale\nlearning tasks.\n","authors":["Niloufar Zakariaei","Shadab Ahamed","Eldad Haber","Moshe Eliasof"],"pdf_url":"https://arxiv.org/pdf/2501.12739v2.pdf","comment":"24 pages, 16 figures, 11 tables"},{"id":"http://arxiv.org/abs/2503.09498v1","updated":"2025-03-12T16:03:00Z","published":"2025-03-12T16:03:00Z","title":"Towards Robust Multimodal Representation: A Unified Approach with\n  Adaptive Experts and Alignment","summary":"  Healthcare relies on multiple types of data, such as medical images, genetic\ninformation, and clinical records, to improve diagnosis and treatment. However,\nmissing data is a common challenge due to privacy restrictions, cost, and\ntechnical issues, making many existing multi-modal models unreliable. To\naddress this, we propose a new multi-model model called Mixture of Experts,\nSymmetric Aligning, and Reconstruction (MoSARe), a deep learning framework that\nhandles incomplete multimodal data while maintaining high accuracy. MoSARe\nintegrates expert selection, cross-modal attention, and contrastive learning to\nimprove feature representation and decision-making. Our results show that\nMoSARe outperforms existing models in situations when the data is complete.\nFurthermore, it provides reliable predictions even when some data are missing.\nThis makes it especially useful in real-world healthcare settings, including\nresource-limited environments. Our code is publicly available at\nhttps://github.com/NazaninMn/MoSARe.\n","authors":["Nazanin Moradinasab","Saurav Sengupta","Jiebei Liu","Sana Syed","Donald E. Brown"],"pdf_url":"https://arxiv.org/pdf/2503.09498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09497v1","updated":"2025-03-12T16:01:34Z","published":"2025-03-12T16:01:34Z","title":"Federated Smoothing ADMM for Localization","summary":"  This paper addresses the challenge of localization in federated settings,\nwhich are characterized by distributed data, non-convexity, and non-smoothness.\nTo tackle the scalability and outlier issues inherent in such environments, we\npropose a robust algorithm that employs an $\\ell_1$-norm formulation within a\nnovel federated ADMM framework. This approach addresses the problem by\nintegrating an iterative smooth approximation for the total variation consensus\nterm and employing a Moreau envelope approximation for the convex function that\nappears in a subtracted form. This transformation ensures that the problem is\nsmooth and weakly convex in each iteration, which results in enhanced\ncomputational efficiency and improved estimation accuracy. The proposed\nalgorithm supports asynchronous updates and multiple client updates per\niteration, which ensures its adaptability to real-world federated systems. To\nvalidate the reliability of the proposed algorithm, we show that the method\nconverges to a stationary point, and numerical simulations highlight its\nsuperior performance in convergence speed and outlier resilience compared to\nexisting state-of-the-art localization methods.\n","authors":["Reza Mirzaeifard","Ashkan Moradi","Masahiro Yukawa","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2503.09497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12292v2","updated":"2025-03-12T15:58:01Z","published":"2025-02-17T20:01:08Z","title":"Independence Tests for Language Models","summary":"  We consider the following problem: given the weights of two models, can we\ntest whether they were trained independently -- i.e., from independent random\ninitializations? We consider two settings: constrained and unconstrained. In\nthe constrained setting, we make assumptions about model architecture and\ntraining and propose a family of statistical tests that yield exact p-values\nwith respect to the null hypothesis that the models are trained from\nindependent random initializations. These p-values are valid regardless of the\ncomposition of either model's training data; we compute them by simulating\nexchangeable copies of each model under our assumptions and comparing various\nsimilarity measures of weights and activations between the original two models\nversus these copies. We report the p-values from these tests on pairs of 21\nopen-weight models (210 total pairs) and correctly identify all pairs of\nnon-independent models. Our tests remain effective even if one model was\nfine-tuned for many tokens. In the unconstrained setting, where we make no\nassumptions about training procedures, can change model architecture, and allow\nfor adversarial evasion attacks, the previous tests no longer work. Instead, we\npropose a new test which matches hidden activations between two models, and\nwhich is robust to adversarial transformations and to changes in model\narchitecture. The test can also do localized testing: identifying specific\nnon-independent components of models. Though we no longer obtain exact p-values\nfrom this, empirically we find it behaves as one and reliably identifies\nnon-independent models. Notably, we can use the test to identify specific parts\nof one model that are derived from another (e.g., how Llama 3.1-8B was pruned\nto initialize Llama 3.2-3B, or shared layers between Mistral-7B and\nStripedHyena-7B), and it is even robust to retraining individual layers of\neither model from scratch.\n","authors":["Sally Zhu","Ahmed Ahmed","Rohith Kuditipudi","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2502.12292v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09494v1","updated":"2025-03-12T15:54:37Z","published":"2025-03-12T15:54:37Z","title":"Representation Retrieval Learning for Heterogeneous Data Integration","summary":"  In the era of big data, large-scale, multi-modal datasets are increasingly\nubiquitous, offering unprecedented opportunities for predictive modeling and\nscientific discovery. However, these datasets often exhibit complex\nheterogeneity, such as covariate shift, posterior drift, and missing\nmodalities, that can hinder the accuracy of existing prediction algorithms. To\naddress these challenges, we propose a novel Representation Retrieval ($R^2$)\nframework, which integrates a representation learning module (the representer)\nwith a sparsity-induced machine learning model (the learner). Moreover, we\nintroduce the notion of \"integrativeness\" for representers, characterized by\nthe effective data sources used in learning representers, and propose a\nSelective Integration Penalty (SIP) to explicitly improve the property.\nTheoretically, we demonstrate that the $R^2$ framework relaxes the conventional\nfull-sharing assumption in multi-task learning, allowing for partially shared\nstructures, and that SIP can improve the convergence rate of the excess risk\nbound. Extensive simulation studies validate the empirical performance of our\nframework, and applications to two real-world datasets further confirm its\nsuperiority over existing approaches.\n","authors":["Qi Xu","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2503.09494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09492v1","updated":"2025-03-12T15:52:51Z","published":"2025-03-12T15:52:51Z","title":"Learning Cascade Ranking as One Network","summary":"  Cascade Ranking is a prevalent architecture in large-scale top-k selection\nsystems like recommendation and advertising platforms. Traditional training\nmethods focus on single-stage optimization, neglecting interactions between\nstages. Recent advances such as RankFlow and FS-LTR have introduced\ninteraction-aware training paradigms but still struggle to 1) align training\nobjectives with the goal of the entire cascade ranking (i.e., end-to-end\nrecall) and 2) learn effective collaboration patterns for different stages. To\naddress these challenges, we propose LCRON, which introduces a novel surrogate\nloss function derived from the lower bound probability that ground truth items\nare selected by cascade ranking, ensuring alignment with the overall objective\nof the system. According to the properties of the derived bound, we further\ndesign an auxiliary loss for each stage to drive the reduction of this bound,\nleading to a more robust and effective top-k selection. LCRON enables\nend-to-end training of the entire cascade ranking system as a unified network.\nExperimental results demonstrate that LCRON achieves significant improvement\nover existing methods on public benchmarks and industrial applications,\naddressing key limitations in cascade ranking training and significantly\nenhancing system performance.\n","authors":["Yunli Wang","Zhen Zhang","Zhiqiang Wang","Zixuan Yang","Yu Li","Jian Yang","Shiyang Wen","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2503.09492v1.pdf","comment":"16 pages, 2 figures"},{"id":"http://arxiv.org/abs/2405.08971v2","updated":"2025-03-12T15:51:20Z","published":"2024-05-14T21:31:11Z","title":"Computation-Aware Kalman Filtering and Smoothing","summary":"  Kalman filtering and smoothing are the foundational mechanisms for efficient\ninference in Gauss-Markov models. However, their time and memory complexities\nscale prohibitively with the size of the state space. This is particularly\nproblematic in spatiotemporal regression problems, where the state dimension\nscales with the number of spatial observations. Existing approximate frameworks\nleverage low-rank approximations of the covariance matrix. But since they do\nnot model the error introduced by the computational approximation, their\npredictive uncertainty estimates can be overly optimistic. In this work, we\npropose a probabilistic numerical method for inference in high-dimensional\nGauss-Markov models which mitigates these scaling issues. Our matrix-free\niterative algorithm leverages GPU acceleration and crucially enables a tunable\ntrade-off between computational cost and predictive uncertainty. Finally, we\ndemonstrate the scalability of our method on a large-scale climate dataset.\n","authors":["Marvin Pförtner","Jonathan Wenger","Jon Cockayne","Philipp Hennig"],"pdf_url":"https://arxiv.org/pdf/2405.08971v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20129v2","updated":"2025-03-12T15:47:08Z","published":"2025-02-27T14:24:51Z","title":"Finite State Automata Inside Transformers with Chain-of-Thought: A\n  Mechanistic Study on State Tracking","summary":"  Chain-of-Thought (CoT) significantly enhances the performance of large\nlanguage models (LLMs) across a wide range of tasks, and prior research shows\nthat CoT can theoretically increase expressiveness. However, there is limited\nmechanistic understanding of the algorithms that Transformer+CoT can learn. In\nthis work, we (1) evaluate the state tracking capabilities of Transformer+CoT\nand its variants, confirming the effectiveness of CoT. (2) Next, we identify\nthe circuit, a subset of model components, responsible for tracking the world\nstate, finding that late-layer MLP neurons play a key role. We propose two\nmetrics, compression and distinction, and show that the neuron sets for each\nstate achieve nearly 100% accuracy, providing evidence of an implicit finite\nstate automaton (FSA) embedded within the model. (3) Additionally, we explore\nthree realistic settings: skipping intermediate steps, introducing data noise,\nand testing length generalization. Our results demonstrate that Transformer+CoT\nlearns robust algorithms (FSA), highlighting its resilience in challenging\nscenarios.\n","authors":["Yifan Zhang","Wenyu Du","Dongming Jin","Jie Fu","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2502.20129v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09485v1","updated":"2025-03-12T15:42:39Z","published":"2025-03-12T15:42:39Z","title":"A Novel Approach for Intrinsic Dimension Estimation","summary":"  The real-life data have a complex and non-linear structure due to their\nnature. These non-linearities and the large number of features can usually\ncause problems such as the empty-space phenomenon and the well-known curse of\ndimensionality. Finding the nearly optimal representation of the dataset in a\nlower-dimensional space (i.e. dimensionality reduction) offers an applicable\nmechanism for improving the success of machine learning tasks. However,\nestimating the required data dimension for the nearly optimal representation\n(intrinsic dimension) can be very costly, particularly if one deals with big\ndata. We propose a highly efficient and robust intrinsic dimension estimation\napproach that only relies on matrix-vector products for dimensionality\nreduction methods. An experimental study is also conducted to compare the\nperformance of proposed method with state of the art approaches.\n","authors":["Kadir Özçoban","Murat Manguoğlu","Emrullah Fatih Yetkin"],"pdf_url":"https://arxiv.org/pdf/2503.09485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09483v1","updated":"2025-03-12T15:38:11Z","published":"2025-03-12T15:38:11Z","title":"Learning Spatially Adaptive $\\ell_1$-Norms Weights for Convolutional\n  Synthesis Regularization","summary":"  We propose an unrolled algorithm approach for learning spatially adaptive\nparameter maps in the framework of convolutional synthesis-based $\\ell_1$\nregularization. More precisely, we consider a family of pre-trained\nconvolutional filters and estimate deeply parametrized spatially varying\nparameters applied to the sparse feature maps by means of unrolling a FISTA\nalgorithm to solve the underlying sparse estimation problem. The proposed\napproach is evaluated for image reconstruction of low-field MRI and compared to\nspatially adaptive and non-adaptive analysis-type procedures relying on Total\nVariation regularization and to a well-established model-based deep learning\napproach. We show that the proposed approach produces visually and\nquantitatively comparable results with the latter approaches and at the same\ntime remains highly interpretable. In particular, the inferred parameter maps\nquantify\n  the local contribution of each filter in the reconstruction, which provides\nvaluable insight into the algorithm mechanism and could potentially be used to\ndiscard unsuited filters.\n","authors":["Andreas Kofler","Luca Calatroni","Christoph Kolbitsch","Kostas Papafitsoros"],"pdf_url":"https://arxiv.org/pdf/2503.09483v1.pdf","comment":"To be submitted to the EUSIPCO 2025 conference"},{"id":"http://arxiv.org/abs/2503.09477v1","updated":"2025-03-12T15:31:33Z","published":"2025-03-12T15:31:33Z","title":"Neural reservoir control of a soft bio-hybrid arm","summary":"  A long-standing engineering problem, the control of soft robots is difficult\nbecause of their highly non-linear, heterogeneous, anisotropic, and distributed\nnature. Here, bridging engineering and biology, a neural reservoir is employed\nfor the dynamic control of a bio-hybrid model arm made of multiple\nmuscle-tendon groups enveloping an elastic spine. We show how the use of\nreservoirs facilitates simultaneous control and self-modeling across a set of\nchallenging tasks, outperforming classic neural network approaches. Further, by\nimplementing a spiking reservoir on neuromorphic hardware, energy efficiency is\nachieved, with nearly two-orders of magnitude improvement relative to standard\nCPUs, with implications for the on-board control of untethered, small-scale\nsoft robots.\n","authors":["Noel Naughton","Arman Tekinalp","Keshav Shivam","Seung Hung Kim","Volodymyr Kindratenko","Mattia Gazzola"],"pdf_url":"https://arxiv.org/pdf/2503.09477v1.pdf","comment":"12 pages; 4 figures"},{"id":"http://arxiv.org/abs/2407.13268v2","updated":"2025-03-12T15:25:11Z","published":"2024-07-18T08:21:31Z","title":"Mixture of Experts based Multi-task Supervise Learning from Crowds","summary":"  Existing truth inference methods in crowdsourcing aim to map redundant labels\nand items to the ground truth. They treat the ground truth as hidden variables\nand use statistical or deep learning-based worker behavior models to infer the\nground truth. However, worker behavior models that rely on ground truth hidden\nvariables overlook workers' behavior at the item feature level, leading to\nimprecise characterizations and negatively impacting the quality of truth\ninference. This paper proposes a new paradigm of multi-task supervised learning\nfrom crowds, which eliminates the need for modeling of items's ground truth in\nworker behavior models. Within this paradigm, we propose a worker behavior\nmodel at the item feature level called Mixture of Experts based Multi-task\nSupervised Learning from Crowds (MMLC). Two truth inference strategies are\nproposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering\nmethods in the worker spectral space to identify the projection vector of the\noracle worker. Subsequently, the labels generated based on this vector are\nconsidered as the inferred truth. The second strategy, called MMLC-df, employs\nthe MMLC model to fill the crowdsourced data, which can enhance the\neffectiveness of existing truth inference methods. Experimental results\ndemonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df\nenhances the quality of existing truth inference methods.\n","authors":["Tao Han","Huaixuan Shi","Xinyi Ding","Xiao Ma","Huamao Gu","Yili Fang"],"pdf_url":"https://arxiv.org/pdf/2407.13268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03231v4","updated":"2025-03-12T15:23:13Z","published":"2024-06-05T13:06:52Z","title":"CommonPower: A Framework for Safe Data-Driven Smart Grid Control","summary":"  The growing complexity of power system management has led to an increased\ninterest in reinforcement learning (RL). To validate their effectiveness, RL\nalgorithms have to be evaluated across multiple case studies. Case study design\nis an arduous task requiring the consideration of many aspects, among them the\ninfluence of available forecasts and the level of decentralization in the\ncontrol structure. Furthermore, vanilla RL controllers cannot themselves ensure\nthe satisfaction of system constraints, which makes devising a safeguarding\nmechanism a necessary task for every case study before deploying the system. To\naddress these shortcomings, we introduce the Python tool CommonPower, the first\ngeneral framework for the modeling and simulation of power system management\ntailored towards machine learning. Its modular architecture enables users to\nfocus on specific elements without having to implement a simulation\nenvironment. Another unique contribution of CommonPower is the automatic\nsynthesis of model predictive controllers and safeguards. Beyond offering a\nunified interface for single-agent RL, multi-agent RL, and optimal control,\nCommonPower includes a training pipeline for machine-learning-based forecasters\nas well as a flexible mechanism for incorporating feedback of safeguards into\nthe learning updates of RL controllers.\n","authors":["Michael Eichelbeck","Hannah Markgraf","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2406.03231v4.pdf","comment":"For the corresponding code repository, see\n  https://github.com/TUMcps/commonpower"},{"id":"http://arxiv.org/abs/2410.04722v2","updated":"2025-03-12T15:04:03Z","published":"2024-10-07T03:23:23Z","title":"A Strategy for Label Alignment in Deep Neural Networks","summary":"  One recent research demonstrated successful application of the label\nalignment property for unsupervised domain adaptation in a linear regression\nsettings. Instead of regularizing representation learning to be domain\ninvariant, the research proposed to regularize the linear regression model to\nalign with the top singular vectors of the data matrix from the target domain.\nIn this work we expand upon this idea and generalize it to the case of deep\nlearning, where we derive an alternative formulation of the original adaptation\nalgorithm exploiting label alignment suitable for deep neural network. We also\nperform experiments to demonstrate that our approach achieves comparable\nperformance to mainstream unsupervised domain adaptation methods while having\nstabler convergence. All experiments and implementations in our work can be\nfound at the following codebase:\nhttps://github.com/xuanrui-work/DeepLabelAlignment.\n","authors":["Xuanrui Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.04722v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07148v2","updated":"2025-03-12T15:02:50Z","published":"2025-03-10T10:22:13Z","title":"Hierarchical Neuro-Symbolic Decision Transformer","summary":"  We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.\n","authors":["Ali Baheri","Cecilia O. Alm"],"pdf_url":"https://arxiv.org/pdf/2503.07148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09456v1","updated":"2025-03-12T15:00:32Z","published":"2025-03-12T15:00:32Z","title":"SO(3)-Equivariant Neural Networks for Learning Vector Fields on Spheres","summary":"  Analyzing vector fields on the sphere, such as wind speed and direction on\nEarth, is a difficult task. Models should respect both the rotational\nsymmetries of the sphere and the inherent symmetries of the vector fields. In\nthis paper, we introduce a deep learning architecture that respects both\nsymmetry types using novel techniques based on group convolutions in the\n3-dimensional rotation group. This architecture is suitable for scalar and\nvector fields on the sphere as they can be described as equivariant signals on\nthe 3-dimensional rotation group. Experiments show that our architecture\nachieves lower prediction and reconstruction error when tested on rotated data\ncompared to both standard CNNs and spherical CNNs.\n","authors":["Francesco Ballerin","Nello Blaser","Erlend Grong"],"pdf_url":"https://arxiv.org/pdf/2503.09456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09453v1","updated":"2025-03-12T14:54:58Z","published":"2025-03-12T14:54:58Z","title":"How Well Does Your Tabular Generator Learn the Structure of Tabular\n  Data?","summary":"  Heterogeneous tabular data poses unique challenges in generative modelling\ndue to its fundamentally different underlying data structure compared to\nhomogeneous modalities, such as images and text. Although previous research has\nsought to adapt the successes of generative modelling in homogeneous modalities\nto the tabular domain, defining an effective generator for tabular data remains\nan open problem. One major reason is that the evaluation criteria inherited\nfrom other modalities often fail to adequately assess whether tabular\ngenerative models effectively capture or utilise the unique structural\ninformation encoded in tabular data. In this paper, we carefully examine the\nlimitations of the prevailing evaluation framework and introduce\n$\\textbf{TabStruct}$, a novel evaluation benchmark that positions structural\nfidelity as a core evaluation dimension. Specifically, TabStruct evaluates the\nalignment of causal structures in real and synthetic data, providing a direct\nmeasure of how effectively tabular generative models learn the structure of\ntabular data. Through extensive experiments using generators from eight\ncategories on seven datasets with expert-validated causal graphical structures,\nwe show that structural fidelity offers a task-independent, domain-agnostic\nevaluation dimension. Our findings highlight the importance of tabular data\nstructure and offer practical guidance for developing more effective and robust\ntabular generative models. Code is available at\nhttps://github.com/SilenceX12138/TabStruct.\n","authors":["Xiangjian Jiang","Nikola Simidjievski","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2503.09453v1.pdf","comment":"Accepted by ICLR 2025 workshops (DeLTa and SynthData)"},{"id":"http://arxiv.org/abs/2407.13493v4","updated":"2025-03-12T14:54:13Z","published":"2024-07-18T13:23:16Z","title":"Training Foundation Models as Data Compression: On Information, Model\n  Weights and Copyright Law","summary":"  The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights can be considered a reproduction\nor, more likely, a derivative work of a potentially protected set of works. We\ninvestigate the technical and legal challenges that emerge from this framing of\nthe copyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.\n","authors":["Giorgio Franceschelli","Claudia Cevenini","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2407.13493v4.pdf","comment":"Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law"},{"id":"http://arxiv.org/abs/2502.09298v2","updated":"2025-03-12T14:53:07Z","published":"2025-02-13T13:12:16Z","title":"Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep\n  Reinforcement Learning","summary":"  We present a novel method for Deep Reinforcement Learning (DRL),\nincorporating the convex property of the value function over the belief space\nin Partially Observable Markov Decision Processes (POMDPs). We introduce hard-\nand soft-enforced convexity as two different approaches, and compare their\nperformance against standard DRL on two well-known POMDP environments, namely\nthe Tiger and FieldVisionRockSample problems. Our findings show that including\nthe convexity feature can substantially increase performance of the agents, as\nwell as increase robustness over the hyperparameter space, especially when\ntesting on out-of-distribution domains. The source code for this work can be\nfound at https://github.com/Dakout/Convex_DRL.\n","authors":["Daniel Koutas","Daniel Hettegger","Kostas G. Papakonstantinou","Daniel Straub"],"pdf_url":"https://arxiv.org/pdf/2502.09298v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09443v1","updated":"2025-03-12T14:41:10Z","published":"2025-03-12T14:41:10Z","title":"Florenz: Scaling Laws for Systematic Generalization in Vision-Language\n  Models","summary":"  Cross-lingual transfer enables vision-language models (VLMs) to perform\nvision tasks in various languages with training data only in one language.\nCurrent approaches rely on large pre-trained multilingual language models.\nHowever, they face the curse of multilinguality, sacrificing downstream task\nperformance for multilingual capabilities, struggling with lexical ambiguities,\nand falling behind recent advances. In this work, we study the scaling laws of\nsystematic generalization with monolingual VLMs for multilingual tasks,\nfocusing on the impact of model size and seen training samples. We propose\nFlorenz, a monolingual encoder-decoder VLM with 0.4B to 11.2B parameters\ncombining the pre-trained VLM Florence-2 and the large language model Gemma-2.\nFlorenz is trained with varying compute budgets on a synthetic dataset that\nfeatures intentionally incomplete language coverage for image captioning, thus,\ntesting generalization from the fully covered translation task. We show that\nnot only does indirectly learning unseen task-language pairs adhere to a\nscaling law, but also that with our data generation pipeline and the proposed\nFlorenz model family, image captioning abilities can emerge in a specific\nlanguage even when only data for the translation task is available. Fine-tuning\non a mix of downstream datasets yields competitive performance and demonstrates\npromising scaling trends in multimodal machine translation (Multi30K, CoMMuTE),\nlexical disambiguation (CoMMuTE), and image captioning (Multi30K, XM3600, COCO\nKarpathy).\n","authors":["Julian Spravil","Sebastian Houben","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2503.09443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07892v2","updated":"2025-03-12T14:32:31Z","published":"2024-06-12T05:49:53Z","title":"A Finite-Sample Analysis of an Actor-Critic Algorithm for Mean-Variance\n  Optimization in a Discounted MDP","summary":"  Motivated by applications in risk-sensitive reinforcement learning, we study\nmean-variance optimization in a discounted reward Markov Decision Process\n(MDP). Specifically, we analyze a Temporal Difference (TD) learning algorithm\nwith linear function approximation (LFA) for policy evaluation. We derive\nfinite-sample bounds that hold (i) in the mean-squared sense and (ii) with high\nprobability under tail iterate averaging, both with and without regularization.\nOur bounds exhibit an exponentially decaying dependence on the initial error\nand a convergence rate of $O(1/t)$ after $t$ iterations. Moreover, for the\nregularized TD variant, our bound holds for a universal step size. Next, we\nintegrate a Simultaneous Perturbation Stochastic Approximation (SPSA)-based\nactor update with an LFA critic and establish an $O(n^{-1/4})$ convergence\nguarantee, where $n$ denotes the iterations of the SPSA-based actor-critic\nalgorithm. These results establish finite-sample theoretical guarantees for\nrisk-sensitive actor-critic methods in reinforcement learning, with a focus on\nvariance as a risk measure.\n","authors":["Tejaram Sangadi","L. A. Prashanth","Krishna Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2406.07892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09427v1","updated":"2025-03-12T14:26:16Z","published":"2025-03-12T14:26:16Z","title":"Multimodal Language Modeling for High-Accuracy Single Cell\n  Transcriptomics Analysis and Generation","summary":"  Pre-trained language models (PLMs) have revolutionized scientific research,\nyet their application to single-cell analysis remains limited. Text PLMs cannot\nprocess single-cell RNA sequencing data, while cell PLMs lack the ability to\nhandle free text, restricting their use in multimodal tasks. Existing efforts\nto bridge these modalities often suffer from information loss or inadequate\nsingle-modal pre-training, leading to suboptimal performances. To address these\nchallenges, we propose Single-Cell MultiModal Generative Pre-trained\nTransformer (scMMGPT), a unified PLM for joint cell and text modeling. scMMGPT\neffectively integrates the state-of-the-art cell and text PLMs, facilitating\ncross-modal knowledge sharing for improved performance. To bridge the text-cell\nmodality gap, scMMGPT leverages dedicated cross-modal projectors, and undergoes\nextensive pre-training on 27 million cells -- the largest dataset for\nmultimodal cell-text PLMs to date. This large-scale pre-training enables\nscMMGPT to excel in joint cell-text tasks, achieving an 84\\% relative\nimprovement of textual discrepancy for cell description generation, 20.5\\%\nhigher accuracy for cell type annotation, and 4\\% improvement in $k$-NN\naccuracy for text-conditioned pseudo-cell generation, outperforming baselines.\n","authors":["Yaorui Shi","Jiaqi Yang","Sihang Li","Junfeng Fang","Xiang Wang","Zhiyuan Liu","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19482v2","updated":"2025-03-12T14:25:10Z","published":"2024-10-25T11:37:04Z","title":"Measuring memorization in language models via probabilistic extraction","summary":"  Large language models (LLMs) are susceptible to memorizing training data,\nraising concerns about the potential extraction of sensitive information at\ngeneration time. Discoverable extraction is the most common method for\nmeasuring this issue: split a training example into a prefix and suffix, then\nprompt the LLM with the prefix, and deem the example extractable if the LLM\ngenerates the matching suffix using greedy sampling. This definition yields a\nyes-or-no determination of whether extraction was successful with respect to a\nsingle query. Though efficient to compute, we show that this definition is\nunreliable because it does not account for non-determinism present in more\nrealistic (non-greedy) sampling schemes, for which LLMs produce a range of\noutputs for the same prompt. We introduce probabilistic discoverable\nextraction, which, without additional cost, relaxes discoverable extraction by\nconsidering multiple queries to quantify the probability of extracting a target\nsequence. We evaluate our probabilistic measure across different models,\nsampling schemes, and training-data repetitions, and find that this measure\nprovides more nuanced information about extraction risk compared to traditional\ndiscoverable extraction.\n","authors":["Jamie Hayes","Marika Swanberg","Harsh Chaudhari","Itay Yona","Ilia Shumailov","Milad Nasr","Christopher A. Choquette-Choo","Katherine Lee","A. Feder Cooper"],"pdf_url":"https://arxiv.org/pdf/2410.19482v2.pdf","comment":"NAACL 25"},{"id":"http://arxiv.org/abs/2408.14225v2","updated":"2025-03-12T14:18:23Z","published":"2024-08-26T12:41:41Z","title":"Provable Imbalanced Point Clustering","summary":"  We suggest efficient and provable methods to compute an approximation for\nimbalanced point clustering, that is, fitting $k$-centers to a set of points in\n$\\mathbb{R}^d$, for any $d,k\\geq 1$. To this end, we utilize \\emph{coresets},\nwhich, in the context of the paper, are essentially weighted sets of points in\n$\\mathbb{R}^d$ that approximate the fitting loss for every model in a given\nset, up to a multiplicative factor of $1\\pm\\varepsilon$. We provide [Section 3\nand Section E in the appendix] experiments that show the empirical contribution\nof our suggested methods for real images (novel and reference), synthetic data,\nand real-world data. We also propose choice clustering, which by combining\nclustering algorithms yields better performance than each one separately.\n","authors":["David Denisov","Dan Feldman","Shlomi Dolev","Michael Segal"],"pdf_url":"https://arxiv.org/pdf/2408.14225v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09418v1","updated":"2025-03-12T14:16:27Z","published":"2025-03-12T14:16:27Z","title":"Efficient dynamic modal load reconstruction using physics-informed\n  Gaussian processes based on frequency-sparse Fourier basis functions","summary":"  Knowledge of the force time history of a structure is essential to assess its\nbehaviour, ensure safety and maintain reliability. However, direct measurement\nof external forces is often challenging due to sensor limitations, unknown\nforce characteristics, or inaccessible load points. This paper presents an\nefficient dynamic load reconstruction method using physics-informed Gaussian\nprocesses (GP) based on frequency-sparse Fourier basis functions. The GP's\ncovariance matrices are built using the description of the system dynamics, and\nthe model is trained using structural response measurements. This provides\nsupport and interpretability to the machine learning model, in contrast to\npurely data-driven methods. In addition, the model filters out irrelevant\ncomponents in the Fourier basis function by leveraging the sparsity of\nstructural responses in the frequency domain, thereby reducing computational\ncomplexity during optimization. The trained model for structural responses is\nthen integrated with the differential equation for a harmonic oscillator,\ncreating a probabilistic dynamic load model that predicts load patterns without\nrequiring force data during training. The model's effectiveness is validated\nthrough two case studies: a numerical model of a wind-excited 76-story building\nand an experiment using a physical scale model of the Lilleb{\\ae}lt Bridge in\nDenmark, excited by a servo motor. For both cases, validation of the\nreconstructed forces is provided using comparison metrics for several signal\nproperties. The developed model holds potential for applications in structural\nhealth monitoring, damage prognosis, and load model validation.\n","authors":["Gledson Rodrigo Tondo","Igor Kavrakov","Guido Morgenthal"],"pdf_url":"https://arxiv.org/pdf/2503.09418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09414v1","updated":"2025-03-12T14:10:35Z","published":"2025-03-12T14:10:35Z","title":"Mitigating Membership Inference Vulnerability in Personalized Federated\n  Learning","summary":"  Federated Learning (FL) has emerged as a promising paradigm for collaborative\nmodel training without the need to share clients' personal data, thereby\npreserving privacy. However, the non-IID nature of the clients' data introduces\nmajor challenges for FL, highlighting the importance of personalized federated\nlearning (PFL) methods. In PFL, models are trained to cater to specific feature\ndistributions present in the population data. A notable method for PFL is the\nIterative Federated Clustering Algorithm (IFCA), which mitigates the concerns\nassociated with the non-IID-ness by grouping clients with similar data\ndistributions. While it has been shown that IFCA enhances both accuracy and\nfairness, its strategy of dividing the population into smaller clusters\nincreases vulnerability to Membership Inference Attacks (MIA), particularly\namong minorities with limited training samples. In this paper, we introduce\nIFCA-MIR, an improved version of IFCA that integrates MIA risk assessment into\nthe clustering process. Allowing clients to select clusters based on both model\nperformance and MIA vulnerability, IFCA-MIR achieves an improved performance\nwith respect to accuracy, fairness, and privacy. We demonstrate that IFCA-MIR\nsignificantly reduces MIA risk while maintaining comparable model accuracy and\nfairness as the original IFCA.\n","authors":["Kangsoo Jung","Sayan Biswas","Catuscia Palamidessi"],"pdf_url":"https://arxiv.org/pdf/2503.09414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09411v1","updated":"2025-03-12T14:06:34Z","published":"2025-03-12T14:06:34Z","title":"Benefits of Learning Rate Annealing for Tuning-Robustness in Stochastic\n  Optimization","summary":"  The learning rate in stochastic gradient methods is a critical hyperparameter\nthat is notoriously costly to tune via standard grid search, especially for\ntraining modern large-scale models with billions of parameters. We identify a\ntheoretical advantage of learning rate annealing schemes that decay the\nlearning rate to zero at a polynomial rate, such as the widely-used cosine\nschedule, by demonstrating their increased robustness to initial parameter\nmisspecification due to a coarse grid search. We present an analysis in a\nstochastic convex optimization setup demonstrating that the convergence rate of\nstochastic gradient descent with annealed schedules depends sublinearly on the\nmultiplicative misspecification factor $\\rho$ (i.e., the grid resolution),\nachieving a rate of $O(\\rho^{1/(2p+1)}/\\sqrt{T})$ where $p$ is the degree of\npolynomial decay and $T$ is the number of steps, in contrast to the\n$O(\\rho/\\sqrt{T})$ rate that arises with fixed stepsizes and exhibits a linear\ndependence on $\\rho$. Experiments confirm the increased robustness compared to\ntuning with a fixed stepsize, that has significant implications for the\ncomputational overhead of hyperparameter search in practical training\nscenarios.\n","authors":["Amit Attia","Tomer Koren"],"pdf_url":"https://arxiv.org/pdf/2503.09411v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2407.15620v2","updated":"2025-03-12T14:06:24Z","published":"2024-07-22T13:27:51Z","title":"Dual Test-time Training for Out-of-distribution Recommender System","summary":"  Deep learning has been widely applied in recommender systems, which has\nachieved revolutionary progress recently. However, most existing learning-based\nmethods assume that the user and item distributions remain unchanged between\nthe training phase and the test phase. However, the distribution of user and\nitem features can naturally shift in real-world scenarios, potentially\nresulting in a substantial decrease in recommendation performance. This\nphenomenon can be formulated as an Out-Of-Distribution (OOD) recommendation\nproblem. To address this challenge, we propose a novel Dual Test-Time-Training\nframework for OOD Recommendation, termed DT3OR. In DT3OR, we incorporate a\nmodel adaptation mechanism during the test-time phase to carefully update the\nrecommendation model, allowing the model to specially adapt to the shifting\nuser and item features. To be specific, we propose a self-distillation task and\na contrastive task to assist the model learning both the user's invariant\ninterest preferences and the variant user/item characteristics during the\ntest-time phase, thus facilitating a smooth adaptation to the shifting\nfeatures. Furthermore, we provide theoretical analysis to support the rationale\nbehind our dual test-time training framework. To the best of our knowledge,\nthis paper is the first work to address OOD recommendation via a\ntest-time-training strategy. We conduct experiments on three datasets with\nvarious backbones. Comprehensive experimental results have demonstrated the\neffectiveness of DT3OR compared to other state-of-the-art baselines.\n","authors":["Xihong Yang","Yiqi Wang","Jin Chen","Wenqi Fan","Xiangyu Zhao","En Zhu","Xinwang Liu","Defu Lian"],"pdf_url":"https://arxiv.org/pdf/2407.15620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18857v3","updated":"2025-03-12T14:03:31Z","published":"2024-10-24T15:42:25Z","title":"Probabilistic Language-Image Pre-Training","summary":"  Vision-language models (VLMs) embed aligned image-text pairs into a joint\nspace but often rely on deterministic embeddings, assuming a one-to-one\ncorrespondence between images and texts. This oversimplifies real-world\nrelationships, which are inherently many-to-many, with multiple captions\ndescribing a single image and vice versa. We introduce Probabilistic\nLanguage-Image Pre-training (ProLIP), the first probabilistic VLM pre-trained\non a billion-scale image-text dataset using only probabilistic objectives,\nachieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shot\naccuracy with ViT-B/16). ProLIP efficiently estimates uncertainty by an\n\"uncertainty token\" without extra parameters. We also introduce a novel\ninclusion loss that enforces distributional inclusion relationships between\nimage-text pairs and between original and masked inputs. Experiments\ndemonstrate that, by leveraging uncertainty estimates, ProLIP benefits\ndownstream tasks and aligns with intuitive notions of uncertainty, e.g.,\nshorter texts being more uncertain and more general inputs including specific\nones. Utilizing text uncertainties, we further improve ImageNet accuracy from\n74.6% to 75.8% (under a few-shot setting), supporting the practical advantages\nof our probabilistic approach. The code is available at\nhttps://github.com/naver-ai/prolip\n","authors":["Sanghyuk Chun","Wonjae Kim","Song Park","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2410.18857v3.pdf","comment":"Code: https://github.com/naver-ai/prolip HuggingFace Hub:\n  https://huggingface.co/collections/SanghyukChun/prolip-6712595dfc87fd8597350291\n  33 pages, 4.8 MB; LongProLIP paper: arXiv:2503.08048"},{"id":"http://arxiv.org/abs/2503.09409v1","updated":"2025-03-12T13:59:26Z","published":"2025-03-12T13:59:26Z","title":"AI-based Framework for Robust Model-Based Connector Mating in Robotic\n  Wire Harness Installation","summary":"  Despite the widespread adoption of industrial robots in automotive assembly,\nwire harness installation remains a largely manual process, as it requires\nprecise and flexible manipulation. To address this challenge, we design a novel\nAI-based framework that automates cable connector mating by integrating force\ncontrol with deep visuotactile learning. Our system optimizes\nsearch-and-insertion strategies using first-order optimization over a\nmultimodal transformer architecture trained on visual, tactile, and\nproprioceptive data. Additionally, we design a novel automated data collection\nand optimization pipeline that minimizes the need for machine learning\nexpertise. The framework optimizes robot programs that run natively on standard\nindustrial controllers, permitting human experts to audit and certify them.\nExperimental validations on a center console assembly task demonstrate\nsignificant improvements in cycle times and robustness compared to conventional\nrobot programming approaches. Videos are available under\nhttps://claudius-kienle.github.io/AppMuTT.\n","authors":["Claudius Kienle","Benjamin Alt","Finn Schneider","Tobias Pertlwieser","Rainer Jäkel","Rania Rayyes"],"pdf_url":"https://arxiv.org/pdf/2503.09409v1.pdf","comment":"6 pages, 6 figures, 4 tables, submitted to the 2025 IEEE 21st\n  International Conference on Automation Science and Engineering"},{"id":"http://arxiv.org/abs/2503.09399v1","updated":"2025-03-12T13:49:45Z","published":"2025-03-12T13:49:45Z","title":"ForAug: Recombining Foregrounds and Backgrounds to Improve Vision\n  Transformer Training with Bias Mitigation","summary":"  Transformers, particularly Vision Transformers (ViTs), have achieved\nstate-of-the-art performance in large-scale image classification. However, they\noften require large amounts of data and can exhibit biases that limit their\nrobustness and generalizability. This paper introduces ForAug, a novel data\naugmentation scheme that addresses these challenges and explicitly includes\ninductive biases, which commonly are part of the neural network architecture,\ninto the training data. ForAug is constructed by using pretrained foundation\nmodels to separate and recombine foreground objects with different backgrounds,\nenabling fine-grained control over image composition during training. It thus\nincreases the data diversity and effective number of training samples. We\ndemonstrate that training on ForNet, the application of ForAug to ImageNet,\nsignificantly improves the accuracy of ViTs and other architectures by up to\n4.5 percentage points (p.p.) on ImageNet and 7.3 p.p. on downstream tasks.\nImportantly, ForAug enables novel ways of analyzing model behavior and\nquantifying biases. Namely, we introduce metrics for background robustness,\nforeground focus, center bias, and size bias and show that training on ForNet\nsubstantially reduces these biases compared to training on ImageNet. In\nsummary, ForAug provides a valuable tool for analyzing and mitigating biases,\nenabling the development of more robust and reliable computer vision models.\nOur code and dataset are publicly available at https://github.com/tobna/ForAug.\n","authors":["Tobias Christian Nauen","Brian Moser","Federico Raue","Stanislav Frolov","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2503.09399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09398v1","updated":"2025-03-12T13:48:34Z","published":"2025-03-12T13:48:34Z","title":"Precoder Learning by Leveraging Unitary Equivariance Property","summary":"  Incorporating mathematical properties of a wireless policy to be learned into\nthe design of deep neural networks (DNNs) is effective for enhancing learning\nefficiency. Multi-user precoding policy in multi-antenna system, which is the\nmapping from channel matrix to precoding matrix, possesses a permutation\nequivariance property, which has been harnessed to design the parameter sharing\nstructure of the weight matrix of DNNs. In this paper, we study a stronger\nproperty than permutation equivariance, namely unitary equivariance, for\nprecoder learning. We first show that a DNN with unitary equivariance designed\nby further introducing parameter sharing into a permutation equivariant DNN is\nunable to learn the optimal precoder. We proceed to develop a novel non-linear\nweighting process satisfying unitary equivariance and then construct a joint\nunitary and permutation equivariant DNN. Simulation results demonstrate that\nthe proposed DNN not only outperforms existing learning methods in learning\nperformance and generalizability but also reduces training complexity.\n","authors":["Yilun Ge","Shuyao Liao","Shengqian Han","Chenyang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.09398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09395v1","updated":"2025-03-12T13:42:13Z","published":"2025-03-12T13:42:13Z","title":"Adjusted Count Quantification Learning on Graphs","summary":"  Quantification learning is the task of predicting the label distribution of a\nset of instances. We study this problem in the context of graph-structured\ndata, where the instances are vertices. Previously, this problem has only been\naddressed via node clustering methods. In this paper, we extend the popular\nAdjusted Classify & Count (ACC) method to graphs. We show that the prior\nprobability shift assumption upon which ACC relies is often not fulfilled and\npropose two novel graph quantification techniques: Structural importance\nsampling (SIS) makes ACC applicable in graph domains with covariate shift.\nNeighborhood-aware ACC improves quantification in the presence of\nnon-homophilic edges. We show the effectiveness of our techniques on multiple\ngraph quantification tasks.\n","authors":["Clemens Damke","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2503.09395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.19778v2","updated":"2025-03-12T13:38:59Z","published":"2024-12-27T18:19:26Z","title":"Symbolic Approximations to Ricci-flat Metrics Via Extrinsic Symmetries\n  of Calabi-Yau Hypersurfaces","summary":"  Ever since Yau's non-constructive existence proof of Ricci-flat metrics on\nCalabi-Yau manifolds, finding their explicit construction remains a major\nobstacle to development of both string theory and algebraic geometry. Recent\ncomputational approaches employ machine learning to create novel neural\nrepresentations for approximating these metrics, offering high accuracy but\nlimited interpretability. In this paper, we analyse machine learning\napproximations to flat metrics of Fermat Calabi-Yau n-folds and some of their\none-parameter deformations in three dimensions in order to discover their new\nproperties. We formalise cases in which the flat metric has more symmetries\nthan the underlying manifold, and prove that these symmetries imply that the\nflat metric admits a surprisingly compact representation for certain choices of\ncomplex structure moduli. We show that such symmetries uniquely determine the\nflat metric on certain loci, for which we present an analytic form. We also\nincorporate our theoretical results into neural networks to reduce Ricci\ncurvature for multiple Calabi--Yau manifolds compared to previous machine\nlearning approaches. We conclude by distilling the ML models to obtain for the\nfirst time closed form expressions for Kahler metrics with near-zero scalar\ncurvature.\n","authors":["Viktor Mirjanić","Challenger Mishra"],"pdf_url":"https://arxiv.org/pdf/2412.19778v2.pdf","comment":"41 pages, 14 figures; v2: minor corrections in background chapter,\n  minor rearrangement in chapters 3-5 to improve flow, added more references\n  and results"},{"id":"http://arxiv.org/abs/2503.09391v1","updated":"2025-03-12T13:37:19Z","published":"2025-03-12T13:37:19Z","title":"Context-aware Constrained Reinforcement Learning Based Energy-Efficient\n  Power Scheduling for Non-stationary XR Data Traffic","summary":"  In XR downlink transmission, energy-efficient power scheduling (EEPS) is\nessential for conserving power resource while delivering large data packets\nwithin hard-latency constraints. Traditional constrained reinforcement learning\n(CRL) algorithms show promise in EEPS but still struggle with non-convex\nstochastic constraints, non-stationary data traffic, and sparse delayed packet\ndropout feedback (rewards) in XR. To overcome these challenges, this paper\nmodels the EEPS in XR as a dynamic parameter-constrained Markov decision\nprocess (DP-CMDP) with a varying transition function linked to the\nnon-stationary data traffic and solves it by a proposed context-aware\nconstrained reinforcement learning (CACRL) algorithm, which consists of a\ncontext inference (CI) module and a CRL module. The CI module trains an encoder\nand multiple potential networks to characterize the current transition function\nand reshape the packet dropout rewards according to the context, transforming\nthe original DP-CMDP into a general CMDP with immediate dense rewards. The CRL\nmodule employs a policy network to make EEPS decisions under this CMDP and\noptimizes the policy using a constrained stochastic successive convex\napproximation (CSSCA) method, which is better suited for non-convex stochastic\nconstraints. Finally, theoretical analyses provide deep insights into the CADAC\nalgorithm, while extensive simulations demonstrate that it outperforms advanced\nbaselines in both power conservation and satisfying packet dropout constraints.\n","authors":["Kexuan Wang","An Liu"],"pdf_url":"https://arxiv.org/pdf/2503.09391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09388v1","updated":"2025-03-12T13:33:07Z","published":"2025-03-12T13:33:07Z","title":"Evaluating Reinforcement Learning Safety and Trustworthiness in\n  Cyber-Physical Systems","summary":"  Cyber-Physical Systems (CPS) often leverage Reinforcement Learning (RL)\ntechniques to adapt dynamically to changing environments and optimize\nperformance. However, it is challenging to construct safety cases for RL\ncomponents. We therefore propose the SAFE-RL (Safety and Accountability\nFramework for Evaluating Reinforcement Learning) for supporting the\ndevelopment, validation, and safe deployment of RL-based CPS. We adopt a design\nscience approach to construct the framework and demonstrate its use in three RL\napplications in small Uncrewed Aerial systems (sUAS)\n","authors":["Katherine Dearstyne"," Pedro","Alarcon Granadeno","Theodore Chambers","Jane Cleland-Huang"],"pdf_url":"https://arxiv.org/pdf/2503.09388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19649v3","updated":"2025-03-12T13:31:36Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09384v1","updated":"2025-03-12T13:29:33Z","published":"2025-03-12T13:29:33Z","title":"Revisiting Agnostic Boosting","summary":"  Boosting is a key method in statistical learning, allowing for converting\nweak learners into strong ones. While well studied in the realizable case, the\nstatistical properties of weak-to-strong learning remains less understood in\nthe agnostic setting, where there are no assumptions on the distribution of the\nlabels. In this work, we propose a new agnostic boosting algorithm with\nsubstantially improved sample complexity compared to prior works under very\ngeneral assumptions. Our approach is based on a reduction to the realizable\ncase, followed by a margin-based filtering step to select high-quality\nhypotheses. We conjecture that the error rate achieved by our proposed method\nis optimal up to logarithmic factors.\n","authors":["Arthur da Cunha","Mikael Møller Høgsgaard","Andrea Paudice","Yuxin Sun"],"pdf_url":"https://arxiv.org/pdf/2503.09384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.00020v3","updated":"2025-03-12T13:15:56Z","published":"2024-12-16T11:35:40Z","title":"Magnetic Field Data Calibration with Transformer Model Using Physical\n  Constraints: A Scalable Method for Satellite Missions, Illustrated by\n  Tianwen-1","summary":"  This study introduces a novel approach that integrates the magnetic field\ndata correction from the Tianwen-1 Mars mission with a neural network\narchitecture constrained by physical principles derived from Maxwell's equation\nequations. By employing a Transformer based model capable of efficiently\nhandling sequential data, the method corrects measurement anomalies caused by\nsatellite dynamics, instrument interference, and environmental noise. As a\nresult, it significantly improves both the accuracy and the physical\nconsistency of the calibrated data. Compared to traditional methods that\nrequire long data segments and manual intervention often taking weeks or even\nmonths to complete this new approach can finish calibration in just minutes to\nhours, and predictions are made within seconds. This innovation not only\naccelerates the process of space weather modeling and planetary magnetospheric\nstudies but also provides a robust framework for future planetary exploration\nand solar wind interaction research.\n","authors":["Beibei Li","Yutian Chi","Yuming Wang"],"pdf_url":"https://arxiv.org/pdf/2501.00020v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09363v1","updated":"2025-03-12T13:04:05Z","published":"2025-03-12T13:04:05Z","title":"Towards Graph Foundation Models: A Transferability Perspective","summary":"  In recent years, Graph Foundation Models (GFMs) have gained significant\nattention for their potential to generalize across diverse graph domains and\ntasks. Some works focus on Domain-Specific GFMs, which are designed to address\na variety of tasks within a specific domain, while others aim to create\nGeneral-Purpose GFMs that extend the capabilities of domain-specific models to\nmultiple domains. Regardless of the type, transferability is crucial for\napplying GFMs across different domains and tasks. However, achieving strong\ntransferability is a major challenge due to the structural, feature, and\ndistributional variations in graph data. To date, there has been no systematic\nresearch examining and analyzing GFMs from the perspective of transferability.\nTo bridge the gap, we present the first comprehensive taxonomy that categorizes\nand analyzes existing GFMs through the lens of transferability, structuring\nGFMs around their application scope (domain-specific vs. general-purpose) and\ntheir approaches to knowledge acquisition and transfer. We provide a structured\nperspective on current progress and identify potential pathways for advancing\nGFM generalization across diverse graph datasets and tasks. We aims to shed\nlight on the current landscape of GFMs and inspire future research directions\nin GFM development.\n","authors":["Yuxiang Wang","Wenqi Fan","Suhang Wang","Yao Ma"],"pdf_url":"https://arxiv.org/pdf/2503.09363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16442v2","updated":"2025-03-12T13:02:27Z","published":"2024-02-26T09:38:39Z","title":"On Distributed Larger-Than-Memory Subset Selection With Pairwise\n  Submodular Functions","summary":"  Modern datasets span billions of samples, making training on all available\ndata infeasible. Selecting a high quality subset helps in reducing training\ncosts and enhancing model quality. Submodularity, a discrete analogue of\nconvexity, is commonly used for solving such subset selection problems.\nHowever, existing algorithms for optimizing submodular functions are\nsequential, and the prior distributed methods require at least one central\nmachine to fit the target subset in DRAM. At billion datapoint scale, even the\nsubset may not fit a single machine, and the sequential algorithms are\nprohibitively slow. In this paper, we relax the requirement of having a central\nmachine for the target subset by proposing a novel distributed bounding\nalgorithm with provable approximation guarantees. The algorithm iteratively\nbounds the minimum and maximum utility values to select high quality points and\ndiscard the unimportant ones. When bounding does not find the complete subset,\nwe use a multi-round, partition-based distributed greedy algorithm to identify\nthe remaining subset. We discuss how to implement these algorithms in a\ndistributed data processing framework and empirically analyze different\nconfigurations. We find high quality subsets on CIFAR-100 and ImageNet with\nmarginal or no loss in quality compared to centralized methods, and scale to a\ndataset with 13 billion points.\n","authors":["Maximilian Böther","Abraham Sebastian","Pranjal Awasthi","Ana Klimovic","Srikumar Ramalingam"],"pdf_url":"https://arxiv.org/pdf/2402.16442v2.pdf","comment":"accepted at MLSys 2025"},{"id":"http://arxiv.org/abs/2503.09357v1","updated":"2025-03-12T13:00:29Z","published":"2025-03-12T13:00:29Z","title":"Automatic Operator-level Parallelism Planning for Distributed Deep\n  Learning -- A Mixed-Integer Programming Approach","summary":"  As the artificial intelligence community advances into the era of large\nmodels with billions of parameters, distributed training and inference have\nbecome essential. While various parallelism strategies-data, model, sequence,\nand pipeline-have been successfully implemented for popular neural networks on\nmain-stream hardware, optimizing the distributed deployment schedule requires\nextensive expertise and manual effort. Further more, while existing frameworks\nwith most simple chain-like structures, they struggle with complex non-linear\narchitectures. Mixture-of-experts and multi-modal models feature intricate MIMO\nand branch-rich topologies that require fine-grained operator-level\nparallelization beyond the capabilities of existing frameworks. We propose\nformulating parallelism planning as a scheduling optimization problem using\nmixed-integer programming. We propose a bi-level solution framework balancing\noptimality with computational efficiency, automatically generating effective\ndistributed plans that capture both the heterogeneous structure of modern\nneural networks and the underlying hardware constraints. In experiments\ncomparing against expert-designed strategies like DeepSeek's DualPipe, our\nframework achieves comparable or superior performance, reducing computational\nbubbles by half under the same memory constraints. The framework's versatility\nextends beyond throughput optimization to incorporate hardware utilization\nmaximization, memory capacity constraints, and other considerations or\npotential strategies. Such capabilities position our solution as both a\nvaluable research tool for exploring optimal parallelization strategies and a\npractical industrial solution for large-scale AI deployment.\n","authors":["Ruifeng She","Bowen Pang","Kai Li","Zehua Liu","Tao Zhong"],"pdf_url":"https://arxiv.org/pdf/2503.09357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08760v2","updated":"2025-03-12T12:50:29Z","published":"2024-11-13T16:47:34Z","title":"Energy Dissipation Preserving Physics Informed Neural Network for\n  Allen-Cahn Equations","summary":"  This paper investigates a numerical solution of Allen-Cahn equation with\nconstant and degenerate mobility, with polynomial and logarithmic energy\nfunctionals, with deterministic and random initial functions, and with\nadvective term in one, two, and three spatial dimensions, based on the\nphysics-informed neural network (PINN). To improve the learning capacity of the\nPINN, we incorporate the energy dissipation property of the Allen-Cahn equation\nas a penalty term into the loss function of the network. To facilitate the\nlearning process of random initials, we employ a continuous analogue of the\ninitial random condition by utilizing the Fourier series expansion. Adaptive\nmethods from traditional numerical analysis are also integrated to enhance the\neffectiveness of the proposed PINN. Numerical results indicate a consistent\ndecrease in the discrete energy, while also revealing phenomena such as phase\nseparation and metastability.\n","authors":["Mustafa Kütük","Hamdullah Yücel"],"pdf_url":"https://arxiv.org/pdf/2411.08760v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00897v4","updated":"2025-03-12T12:43:07Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09337v1","updated":"2025-03-12T12:31:29Z","published":"2025-03-12T12:31:29Z","title":"Online multidimensional dictionary learning","summary":"  Dictionary learning is a widely used technique in signal processing and\nmachine learning that aims to represent data as a linear combination of a few\nelements from an overcomplete dictionary. In this work, we propose a\ngeneralization of the dictionary learning technique using the t-product\nframework, enabling efficient handling of multidimensional tensor data. We\naddress the dictionary learning problem through online methods suitable for\ntensor structures. To effectively address the sparsity problem, we utilize an\naccelerated Iterative Shrinkage-Thresholding Algorithm (ISTA) enhanced with an\nextrapolation technique known as Anderson acceleration. This approach\nsignificantly improves signal reconstruction results. Extensive experiments\nprove that our proposed method outperforms existing acceleration techniques,\nparticularly in applications such as data completion. These results suggest\nthat our approach can be highly beneficial for large-scale tensor data analysis\nin various domains.\n","authors":["Ferdaous Ait Addi","Abdeslem Hafid Bentbib","Khalide Jbilou"],"pdf_url":"https://arxiv.org/pdf/2503.09337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09330v1","updated":"2025-03-12T12:24:05Z","published":"2025-03-12T12:24:05Z","title":"Group-robust Machine Unlearning","summary":"  Machine unlearning is an emerging paradigm to remove the influence of\nspecific training data (i.e., the forget set) from a model while preserving its\nknowledge of the rest of the data (i.e., the retain set). Previous approaches\nassume the forget data to be uniformly distributed from all training\ndatapoints. However, if the data to unlearn is dominant in one group, we\nempirically show that performance for this group degrades, leading to fairness\nissues. This work tackles the overlooked problem of non-uniformly distributed\nforget sets, which we call group-robust machine unlearning, by presenting a\nsimple, effective strategy that mitigates the performance loss in dominant\ngroups via sample distribution reweighting. Moreover, we present MIU (Mutual\nInformation-aware Machine Unlearning), the first approach for group robustness\nin approximate machine unlearning. MIU minimizes the mutual information between\nmodel features and group information, achieving unlearning while reducing\nperformance degradation in the dominant group of the forget set. Additionally,\nMIU exploits sample distribution reweighting and mutual information calibration\nwith the original model to preserve group robustness. We conduct experiments on\nthree datasets and show that MIU outperforms standard methods, achieving\nunlearning without compromising model robustness. Source code available at\nhttps://github.com/tdemin16/group-robust_machine_unlearning.\n","authors":["Thomas De Min","Subhankar Roy","Stéphane Lathuilière","Elisa Ricci","Massimiliano Mancini"],"pdf_url":"https://arxiv.org/pdf/2503.09330v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.09329v1","updated":"2025-03-12T12:23:15Z","published":"2025-03-12T12:23:15Z","title":"Energy Optimized Piecewise Polynomial Approximation Utilizing Modern\n  Machine Learning Optimizers","summary":"  This work explores an extension of ML-optimized piecewise polynomial\napproximation by incorporating energy optimization as an additional objective.\nTraditional closed-form solutions enable continuity and approximation targets\nbut lack flexibility in accommodating complex optimization goals. By leveraging\nmodern gradient descent optimizers within TensorFlow, we introduce a framework\nthat minimizes total curvature in cam profiles, leading to smoother motion and\nreduced energy consumption for input data that is unfavorable for sole\napproximation and continuity optimization. Experimental results confirm the\neffectiveness of this approach, demonstrating its potential to improve\nefficiency in scenarios where input data is noisy or suboptimal for\nconventional methods.\n","authors":["Hannes Waclawek","Stefan Huber"],"pdf_url":"https://arxiv.org/pdf/2503.09329v1.pdf","comment":"Submitted to Austrian Robotics Workshop 2025 (2 page student paper)"},{"id":"http://arxiv.org/abs/2503.09321v1","updated":"2025-03-12T12:12:46Z","published":"2025-03-12T12:12:46Z","title":"DAVE: Diagnostic benchmark for Audio Visual Evaluation","summary":"  Audio-visual understanding is a rapidly evolving field that seeks to\nintegrate and interpret information from both auditory and visual modalities.\nDespite recent advances in multi-modal learning, existing benchmarks often\nsuffer from strong visual bias -- where answers can be inferred from visual\ndata alone -- and provide only aggregate scores that conflate multiple sources\nof error. This makes it difficult to determine whether models struggle with\nvisual understanding, audio interpretation, or audio-visual alignment. In this\nwork, we introduce DAVE (Diagnostic Audio Visual Evaluation), a novel benchmark\ndataset designed to systematically evaluate audio-visual models across\ncontrolled challenges. DAVE alleviates existing limitations by (i) ensuring\nboth modalities are necessary to answer correctly and (ii) decoupling\nevaluation into atomic subcategories. Our detailed analysis of state-of-the-art\nmodels reveals specific failure modes and provides targeted insights for\nimprovement. By offering this standardized diagnostic framework, we aim to\nfacilitate more robust development of audio-visual models. The dataset is\nreleased: https://github.com/gorjanradevski/dave\n","authors":["Gorjan Radevski","Teodora Popordanoska","Matthew B. Blaschko","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2503.09321v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2503.09320v1","updated":"2025-03-12T12:12:07Z","published":"2025-03-12T12:12:07Z","title":"2HandedAfforder: Learning Precise Actionable Bimanual Affordances from\n  Human Videos","summary":"  When interacting with objects, humans effectively reason about which regions\nof objects are viable for an intended action, i.e., the affordance regions of\nthe object. They can also account for subtle differences in object regions\nbased on the task to be performed and whether one or two hands need to be used.\nHowever, current vision-based affordance prediction methods often reduce the\nproblem to naive object part segmentation. In this work, we propose a framework\nfor extracting affordance data from human activity video datasets. Our\nextracted 2HANDS dataset contains precise object affordance region\nsegmentations and affordance class-labels as narrations of the activity\nperformed. The data also accounts for bimanual actions, i.e., two hands\nco-ordinating and interacting with one or more objects. We present a VLM-based\naffordance prediction model, 2HandedAfforder, trained on the dataset and\ndemonstrate superior performance over baselines in affordance region\nsegmentation for various activities. Finally, we show that our predicted\naffordance regions are actionable, i.e., can be used by an agent performing a\ntask, through demonstration in robotic manipulation scenarios.\n","authors":["Marvin Heidinger","Snehal Jauhri","Vignesh Prasad","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2503.09320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01293v3","updated":"2025-03-12T12:08:55Z","published":"2024-11-02T16:02:47Z","title":"Diffusion Models as Cartoonists: The Curious Case of High Density\n  Regions","summary":"  We investigate what kind of images lie in the high-density regions of\ndiffusion models. We introduce a theoretical mode-tracking process capable of\npinpointing the exact mode of the denoising distribution, and we propose a\npractical high-density sampler that consistently generates images of higher\nlikelihood than usual samplers. Our empirical findings reveal the existence of\nsignificantly higher likelihood samples that typical samplers do not produce,\noften manifesting as cartoon-like drawings or blurry images depending on the\nnoise level. Curiously, these patterns emerge in datasets devoid of such\nexamples. We also present a novel approach to track sample likelihoods in\ndiffusion SDEs, which remarkably incurs no additional computational cost.\n","authors":["Rafał Karczewski","Markus Heinonen","Vikas Garg"],"pdf_url":"https://arxiv.org/pdf/2411.01293v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09315v1","updated":"2025-03-12T12:05:03Z","published":"2025-03-12T12:05:03Z","title":"ShuffleGate: An Efficient and Self-Polarizing Feature Selection Method\n  for Large-Scale Deep Models in Industry","summary":"  Deep models in industrial applications rely on thousands of features for\naccurate predictions, such as deep recommendation systems. While new features\nare introduced to capture evolving user behavior, outdated or redundant\nfeatures often remain, significantly increasing storage and computational\ncosts. To address this issue, feature selection methods are widely adopted to\nidentify and remove less important features. However, existing approaches face\ntwo major challenges: (1) they often require complex Hyperparameter (Hp)\ntuning, making them difficult to employ in practice, and (2) they fail to\nproduce well-separated feature importance scores, which complicates\nstraightforward feature removal. Moreover, the impact of removing unimportant\nfeatures can only be evaluated through retraining the model, a time-consuming\nand resource-intensive process that severely hinders efficient feature\nselection.\n  To solve these challenges, we propose a novel feature selection approach,\nShuffle-Gate. In particular, it shuffles all feature values across instances\nsimultaneously and uses a gating mechanism that allows the model to dynamically\nlearn the weights for combining the original and shuffled inputs. Notably, it\ncan generate well-separated feature importance scores and estimate the\nperformance without retraining the model, while introducing only a single Hp.\nExperiments on four public datasets show that our approach outperforms\nstate-of-the-art methods in selecting the top half of the feature set for model\nretraining. Moreover, it has been successfully integrated into the daily\niteration of Bilibili's search models across various scenarios, where it\nsignificantly reduces feature set size and computational resource usage, while\nmaintaining comparable performance.\n","authors":["Yihong Huang"],"pdf_url":"https://arxiv.org/pdf/2503.09315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09312v1","updated":"2025-03-12T12:03:26Z","published":"2025-03-12T12:03:26Z","title":"Terrier: A Deep Learning Repeat Classifier","summary":"  Repetitive DNA sequences underpin genome architecture and evolutionary\nprocesses, yet they remain challenging to classify accurately. Terrier is a\ndeep learning model designed to overcome these challenges by classifying\nrepetitive DNA sequences using a publicly available, curated repeat sequence\nlibrary trained under the RepeatMasker schema. Existing tools often struggle to\nclassify divergent taxa due to biases in reference libraries, limiting our\nunderstanding of repeat evolution and function. Terrier overcomes these\nchallenges by leveraging deep learning for improved accuracy. Trained on\nRepBase, which includes over 100,000 repeat families -- four times more than\nDfam -- Terrier maps 97.1% of RepBase sequences to RepeatMasker categories,\noffering the most comprehensive classification system available. When\nbenchmarked against DeepTE, TERL, and TEclass2 in model organisms (rice and\nfruit flies), Terrier achieved superior accuracy while classifying a broader\nrange of sequences. Further validation in non-model amphibian and flatworm\ngenomes highlights its effectiveness in improving classification in non-model\nspecies, facilitating research on repeat-driven evolution, genomic instability,\nand phenotypic variation.\n","authors":["Robert Turnbull","Neil D. Young","Edoardo Tescari","Lee F. Skerratt","Tiffany A. Kosch"],"pdf_url":"https://arxiv.org/pdf/2503.09312v1.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.09311v1","updated":"2025-03-12T12:02:36Z","published":"2025-03-12T12:02:36Z","title":"Adaptive political surveys and GPT-4: Tackling the cold start problem\n  with simulated user interactions","summary":"  Adaptive questionnaires dynamically select the next question for a survey\nparticipant based on their previous answers. Due to digitalisation, they have\nbecome a viable alternative to traditional surveys in application areas such as\npolitical science. One limitation, however, is their dependency on data to\ntrain the model for question selection. Often, such training data (i.e., user\ninteractions) are unavailable a priori. To address this problem, we (i) test\nwhether Large Language Models (LLM) can accurately generate such interaction\ndata and (ii) explore if these synthetic data can be used to pre-train the\nstatistical model of an adaptive political survey. To evaluate this approach,\nwe utilise existing data from the Swiss Voting Advice Application (VAA)\nSmartvote in two ways: First, we compare the distribution of LLM-generated\nsynthetic data to the real distribution to assess its similarity. Second, we\ncompare the performance of an adaptive questionnaire that is randomly\ninitialised with one pre-trained on synthetic data to assess their suitability\nfor training. We benchmark these results against an \"oracle\" questionnaire with\nperfect prior knowledge. We find that an off-the-shelf LLM (GPT-4) accurately\ngenerates answers to the Smartvote questionnaire from the perspective of\ndifferent Swiss parties. Furthermore, we demonstrate that initialising the\nstatistical model with synthetic data can (i) significantly reduce the error in\npredicting user responses and (ii) increase the candidate recommendation\naccuracy of the VAA. Our work emphasises the considerable potential of LLMs to\ncreate training data to improve the data collection process in adaptive\nquestionnaires in LLM-affine areas such as political surveys.\n","authors":["Fynn Bachmann","Daan van der Weijden","Lucien Heitz","Cristina Sarasua","Abraham Bernstein"],"pdf_url":"https://arxiv.org/pdf/2503.09311v1.pdf","comment":"23 pages. Under review at PLOS One"},{"id":"http://arxiv.org/abs/2503.09309v1","updated":"2025-03-12T12:02:02Z","published":"2025-03-12T12:02:02Z","title":"Steering No-Regret Agents in MFGs under Model Uncertainty","summary":"  Incentive design is a popular framework for guiding agents' learning dynamics\ntowards desired outcomes by providing additional payments beyond intrinsic\nrewards. However, most existing works focus on a finite, small set of agents or\nassume complete knowledge of the game, limiting their applicability to\nreal-world scenarios involving large populations and model uncertainty. To\naddress this gap, we study the design of steering rewards in Mean-Field Games\n(MFGs) with density-independent transitions, where both the transition dynamics\nand intrinsic reward functions are unknown. This setting presents non-trivial\nchallenges, as the mediator must incentivize the agents to explore for its\nmodel learning under uncertainty, while simultaneously steer them to converge\nto desired behaviors without incurring excessive incentive payments. Assuming\nagents exhibit no(-adaptive) regret behaviors, we contribute novel optimistic\nexploration algorithms. Theoretically, we establish sub-linear regret\nguarantees for the cumulative gaps between the agents' behaviors and the\ndesired ones. In terms of the steering cost, we demonstrate that our total\nincentive payments incur only sub-linear excess, competing with a baseline\nsteering strategy that stabilizes the target policy as an equilibrium. Our work\npresents an effective framework for steering agents behaviors in\nlarge-population systems under uncertainty.\n","authors":["Leo Widmer","Jiawei Huang","Niao He"],"pdf_url":"https://arxiv.org/pdf/2503.09309v1.pdf","comment":"AISTATS 2025; 34 Pages"},{"id":"http://arxiv.org/abs/2406.08226v2","updated":"2025-03-12T11:58:36Z","published":"2024-06-12T13:55:12Z","title":"DistilDoc: Knowledge Distillation for Visually-Rich Document\n  Applications","summary":"  This work explores knowledge distillation (KD) for visually-rich document\n(VRD) applications such as document layout analysis (DLA) and document image\nclassification (DIC). While VRD research is dependent on increasingly\nsophisticated and cumbersome models, the field has neglected to study\nefficiency via model compression. Here, we design a KD experimentation\nmethodology for more lean, performant models on document understanding (DU)\ntasks that are integral within larger task pipelines. We carefully selected KD\nstrategies (response-based, feature-based) for distilling knowledge to and from\nbackbones with different architectures (ResNet, ViT, DiT) and capacities (base,\nsmall, tiny). We study what affects the teacher-student knowledge gap and find\nthat some methods (tuned vanilla KD, MSE, SimKD with an apt projector) can\nconsistently outperform supervised student training. Furthermore, we design\ndownstream task setups to evaluate covariate shift and the robustness of\ndistilled DLA models on zero-shot layout-aware document visual question\nanswering (DocVQA). DLA-KD experiments result in a large mAP knowledge gap,\nwhich unpredictably translates to downstream robustness, accentuating the need\nto further explore how to efficiently obtain more semantic document layout\nawareness.\n","authors":["Jordy Van Landeghem","Subhajit Maity","Ayan Banerjee","Matthew Blaschko","Marie-Francine Moens","Josep Lladós","Sanket Biswas"],"pdf_url":"https://arxiv.org/pdf/2406.08226v2.pdf","comment":"Accepted to ICDAR 2024 (Athens, Greece)"},{"id":"http://arxiv.org/abs/1905.09884v4","updated":"2025-03-12T11:57:25Z","published":"2019-05-23T19:30:51Z","title":"Naive Feature Selection: a Nearly Tight Convex Relaxation for Sparse\n  Naive Bayes","summary":"  Due to its linear complexity, naive Bayes classification remains an\nattractive supervised learning method, especially in very large-scale settings.\nWe propose a sparse version of naive Bayes, which can be used for feature\nselection. This leads to a combinatorial maximum-likelihood problem, for which\nwe provide an exact solution in the case of binary data, or a bound in the\nmultinomial case. We prove that our convex relaxation bounds becomes tight as\nthe marginal contribution of additional features decreases, using a priori\nduality gap bounds dervied from the Shapley-Folkman theorem. We show how to\nproduce primal solutions satisfying these bounds. Both binary and multinomial\nsparse models are solvable in time almost linear in problem size, representing\na very small extra relative cost compared to the classical naive Bayes.\nNumerical experiments on text data show that the naive Bayes feature selection\nmethod is as statistically effective as state-of-the-art feature selection\nmethods such as recursive feature elimination, $l_1$-penalized logistic\nregression and LASSO, while being orders of magnitude faster.\n","authors":["Armin Askari","Alexandre d'Aspremont","Laurent El Ghaoui"],"pdf_url":"https://arxiv.org/pdf/1905.09884v4.pdf","comment":"Fixed some cosmetic issues"},{"id":"http://arxiv.org/abs/2503.09304v1","updated":"2025-03-12T11:56:01Z","published":"2025-03-12T11:56:01Z","title":"Priority-Aware Preemptive Scheduling for Mixed-Priority Workloads in MoE\n  Inference","summary":"  Large Language Models have revolutionized natural language processing, yet\nserving them efficiently in data centers remains challenging due to mixed\nworkloads comprising latency-sensitive (LS) and best-effort (BE) jobs. Existing\ninference systems employ iteration-level first-come-first-served scheduling,\ncausing head-of-line blocking when BE jobs delay LS jobs. We introduce QLLM, a\nnovel inference system designed for Mixture of Experts (MoE) models, featuring\na fine-grained, priority-aware preemptive scheduler. QLLM enables expert-level\npreemption, deferring BE job execution while minimizing LS time-to-first-token\n(TTFT). Our approach removes iteration-level scheduling constraints, enabling\nthe scheduler to preempt jobs at any layer based on priority. Evaluations on an\nNvidia A100 GPU show that QLLM significantly improves performance. It reduces\nLS TTFT by an average of $65.5\\times$ and meets the SLO at up to $7$\nrequests/sec, whereas the baseline fails to do so under the tested workload.\nAdditionally, it cuts LS turnaround time by up to $12.8\\times$ without\nimpacting throughput. QLLM is modular, extensible, and seamlessly integrates\nwith Hugging Face MoE models.\n","authors":["Mohammad Siavashi","Faezeh Keshmiri Dindarloo","Dejan Kostic","Marco Chiesa"],"pdf_url":"https://arxiv.org/pdf/2503.09304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09289v1","updated":"2025-03-12T11:35:04Z","published":"2025-03-12T11:35:04Z","title":"Unmask It! AI-Generated Product Review Detection in Dravidian Languages","summary":"  The rise of Generative AI has led to a surge in AI-generated reviews, often\nposing a serious threat to the credibility of online platforms. Reviews serve\nas the primary source of information about products and services. Authentic\nreviews play a vital role in consumer decision-making. The presence of\nfabricated content misleads consumers, undermines trust and facilitates\npotential fraud in digital marketplaces. This study focuses on detecting\nAI-generated product reviews in Tamil and Malayalam, two low-resource languages\nwhere research in this domain is relatively under-explored. We worked on a\nrange of approaches - from traditional machine learning methods to advanced\ntransformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and\nMalayalamBERT. Our findings highlight the effectiveness of leveraging the\nstate-of-the-art transformers in accurately identifying AI-generated content,\ndemonstrating the potential in enhancing the detection of fake reviews in\nlow-resource language settings.\n","authors":["Somsubhra De","Advait Vats"],"pdf_url":"https://arxiv.org/pdf/2503.09289v1.pdf","comment":"10 pages, 9 figures, Accepted to DravidianLangTech Workshop\n  proceedings at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.09271v1","updated":"2025-03-12T11:15:34Z","published":"2025-03-12T11:15:34Z","title":"DitHub: A Modular Framework for Incremental Open-Vocabulary Object\n  Detection","summary":"  Open-Vocabulary object detectors can recognize a wide range of categories\nusing simple textual prompts. However, improving their ability to detect rare\nclasses or specialize in certain domains remains a challenge. While most recent\nmethods rely on a single set of model weights for adaptation, we take a\ndifferent approach by using modular deep learning. We introduce DitHub, a\nframework designed to create and manage a library of efficient adaptation\nmodules. Inspired by Version Control Systems, DitHub organizes expert modules\nlike branches that can be fetched and merged as needed. This modular approach\nenables a detailed study of how adaptation modules combine, making it the first\nmethod to explore this aspect in Object Detection. Our approach achieves\nstate-of-the-art performance on the ODinW-13 benchmark and ODinW-O, a newly\nintroduced benchmark designed to evaluate how well models adapt when previously\nseen classes reappear. For more details, visit our project page:\nhttps://aimagelab.github.io/DitHub/\n","authors":["Chiara Cappellino","Gianluca Mancusi","Matteo Mosconi","Angelo Porrello","Simone Calderara","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2503.09271v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09270v1","updated":"2025-03-12T11:13:08Z","published":"2025-03-12T11:13:08Z","title":"Rule-Guided Reinforcement Learning Policy Evaluation and Improvement","summary":"  We consider the challenging problem of using domain knowledge to improve deep\nreinforcement learning policies. To this end, we propose LEGIBLE, a novel\napproach, following a multi-step process, which starts by mining rules from a\ndeep RL policy, constituting a partially symbolic representation. These rules\ndescribe which decisions the RL policy makes and which it avoids making. In the\nsecond step, we generalize the mined rules using domain knowledge expressed as\nmetamorphic relations. We adapt these relations from software testing to RL to\nspecify expected changes of actions in response to changes in observations. The\nthird step is evaluating generalized rules to determine which generalizations\nimprove performance when enforced. These improvements show weaknesses in the\npolicy, where it has not learned the general rules and thus can be improved by\nrule guidance. LEGIBLE supported by metamorphic relations provides a principled\nway of expressing and enforcing domain knowledge about RL environments. We show\nthe efficacy of our approach by demonstrating that it effectively finds\nweaknesses, accompanied by explanations of these weaknesses, in eleven RL\nenvironments and by showcasing that guiding policy execution with rules\nimproves performance w.r.t. gained reward.\n","authors":["Martin Tappler","Ignacio D. Lopez-Miguel","Sebastian Tschiatschek","Ezio Bartocci"],"pdf_url":"https://arxiv.org/pdf/2503.09270v1.pdf","comment":"11 pages, 3 figures, accompanying source code available at\n  https://doi.org/10.6084/m9.figshare.28569017.v1"},{"id":"http://arxiv.org/abs/2503.09269v1","updated":"2025-03-12T11:12:05Z","published":"2025-03-12T11:12:05Z","title":"Single-Qudit Quantum Neural Networks for Multiclass Classification","summary":"  This paper proposes a single-qudit quantum neural network for multiclass\nclassification, by using the enhanced representational capacity of\nhigh-dimensional qudit states. Our design employs an $d$-dimensional unitary\noperator, where $d$ corresponds to the number of classes, constructed using the\nCayley transform of a skew-symmetric matrix, to efficiently encode and process\nclass information. This architecture enables a direct mapping between class\nlabels and quantum measurement outcomes, reducing circuit depth and\ncomputational overhead. To optimize network parameters, we introduce a hybrid\ntraining approach that combines an extended activation function -- derived from\na truncated multivariable Taylor series expansion -- with support vector\nmachine optimization for weight determination. We evaluate our model on the\nMNIST and EMNIST datasets, demonstrating competitive accuracy while maintaining\na compact single-qudit quantum circuit. Our findings highlight the potential of\nqudit-based QNNs as scalable alternatives to classical deep learning models,\nparticularly for multiclass classification. However, practical implementation\nremains constrained by current quantum hardware limitations. This research\nadvances quantum machine learning by demonstrating the feasibility of\nhigher-dimensional quantum systems for efficient learning tasks.\n","authors":["Leandro C. Souza","Renato Portugal"],"pdf_url":"https://arxiv.org/pdf/2503.09269v1.pdf","comment":"24 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.09260v1","updated":"2025-03-12T11:00:16Z","published":"2025-03-12T11:00:16Z","title":"Neural Normalized Cut: A Differential and Generalizable Approach for\n  Spectral Clustering","summary":"  Spectral clustering, as a popular tool for data clustering, requires an\neigen-decomposition step on a given affinity to obtain the spectral embedding.\nNevertheless, such a step suffers from the lack of generalizability and\nscalability. Moreover, the obtained spectral embeddings can hardly provide a\ngood approximation to the ground-truth partition and thus a k-means step is\nadopted to quantize the embedding. In this paper, we propose a simple yet\neffective scalable and generalizable approach, called Neural Normalized Cut\n(NeuNcut), to learn the clustering membership for spectral clustering directly.\nIn NeuNcut, we properly reparameterize the unknown cluster membership via a\nneural network, and train the neural network via stochastic gradient descent\nwith a properly relaxed normalized cut loss. As a result, our NeuNcut enjoys a\ndesired generalization ability to directly infer clustering membership for\nout-of-sample unseen data and hence brings us an efficient way to handle\nclustering task with ultra large-scale data. We conduct extensive experiments\non both synthetic data and benchmark datasets and experimental results validate\nthe effectiveness and the superiority of our approach. Our code is available\nat: https://github.com/hewei98/NeuNcut.\n","authors":["Wei He","Shangzhi Zhang","Chun-Guang Li","Xianbiao Qi","Rong Xiao","Jun Guo"],"pdf_url":"https://arxiv.org/pdf/2503.09260v1.pdf","comment":"5 figures, 8 tables, accepted by Pattern Recognition (2025-03-11)"},{"id":"http://arxiv.org/abs/2503.09252v1","updated":"2025-03-12T10:51:29Z","published":"2025-03-12T10:51:29Z","title":"Large-scale Regional Traffic Signal Control Based on Single-Agent\n  Reinforcement Learning","summary":"  In the context of global urbanization and motorization, traffic congestion\nhas become a significant issue, severely affecting the quality of life,\nenvironment, and economy. This paper puts forward a single-agent reinforcement\nlearning (RL)-based regional traffic signal control (TSC) model. Different from\nmulti - agent systems, this model can coordinate traffic signals across a large\narea, with the goals of alleviating regional traffic congestion and minimizing\nthe total travel time. The TSC environment is precisely defined through\nspecific state space, action space, and reward functions. The state space\nconsists of the current congestion state, which is represented by the queue\nlengths of each link, and the current signal phase scheme of intersections. The\naction space is designed to select an intersection first and then adjust its\nphase split. Two reward functions are meticulously crafted. One focuses on\nalleviating congestion and the other aims to minimize the total travel time\nwhile considering the congestion level. The experiments are carried out with\nthe SUMO traffic simulation software. The performance of the TSC model is\nevaluated by comparing it with a base case where no signal-timing adjustments\nare made. The results show that the model can effectively control congestion.\nFor example, the queuing length is significantly reduced in the scenarios\ntested. Moreover, when the reward is set to both alleviate congestion and\nminimize the total travel time, the average travel time is remarkably\ndecreased, which indicates that the model can effectively improve traffic\nconditions. This research provides a new approach for large-scale regional\ntraffic signal control and offers valuable insights for future urban traffic\nmanagement.\n","authors":["Qiang Li","Jin Niu","Qin Luo","Lina Yu"],"pdf_url":"https://arxiv.org/pdf/2503.09252v1.pdf","comment":"16 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2503.02279"},{"id":"http://arxiv.org/abs/2410.12459v2","updated":"2025-03-12T10:51:14Z","published":"2024-10-16T11:16:47Z","title":"HELM: Hierarchical Encoding for mRNA Language Modeling","summary":"  Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its\ncodon structure directly impacting biological properties. While Language Models\n(LMs) have shown promise in analyzing biological sequences, existing approaches\nfail to account for the hierarchical nature of mRNA's codon structure. We\nintroduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel\npre-training strategy that incorporates codon-level hierarchical structure into\nlanguage model training. HELM modulates the loss function based on codon\nsynonymity, aligning the model's learning process with the biological reality\nof mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks,\ndemonstrating that HELM outperforms standard language model pre-training as\nwell as existing foundation model baselines on seven diverse downstream\nproperty prediction tasks and an antibody region annotation tasks on average by\naround 8%. Additionally, HELM enhances the generative capabilities of language\nmodel, producing diverse mRNA sequences that better align with the underlying\ntrue data distribution compared to non-hierarchical baselines.\n","authors":["Mehdi Yazdani-Jahromi","Mangal Prakash","Tommaso Mansi","Artem Moskalev","Rui Liao"],"pdf_url":"https://arxiv.org/pdf/2410.12459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18752v3","updated":"2025-03-12T10:46:46Z","published":"2024-11-27T20:56:43Z","title":"Locally Differentially Private Online Federated Learning With Correlated\n  Noise","summary":"  We introduce a locally differentially private (LDP) algorithm for online\nfederated learning that employs temporally correlated noise to improve utility\nwhile preserving privacy. To address challenges posed by the correlated noise\nand local updates with streaming non-IID data, we develop a perturbed iterate\nanalysis that controls the impact of the noise on the utility. Moreover, we\ndemonstrate how the drift errors from local updates can be effectively managed\nfor several classes of nonconvex loss functions. Subject to an\n$(\\epsilon,\\delta)$-LDP budget, we establish a dynamic regret bound that\nquantifies the impact of key parameters and the intensity of changes in the\ndynamic environment on the learning performance. Numerical experiments confirm\nthe efficacy of the proposed algorithm.\n","authors":["Jiaojiao Zhang","Linglingzhi Zhu","Dominik Fay","Mikael Johansson"],"pdf_url":"https://arxiv.org/pdf/2411.18752v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.16542"},{"id":"http://arxiv.org/abs/2503.09251v1","updated":"2025-03-12T10:46:25Z","published":"2025-03-12T10:46:25Z","title":"SCOPE-DTI: Semi-Inductive Dataset Construction and Framework\n  Optimization for Practical Usability Enhancement in Deep Learning-Based Drug\n  Target Interaction Prediction","summary":"  Deep learning-based drug-target interaction (DTI) prediction methods have\ndemonstrated strong performance; however, real-world applicability remains\nconstrained by limited data diversity and modeling complexity. To address these\nchallenges, we propose SCOPE-DTI, a unified framework combining a large-scale,\nbalanced semi-inductive human DTI dataset with advanced deep learning modeling.\nConstructed from 13 public repositories, the SCOPE dataset expands data volume\nby up to 100-fold compared to common benchmarks such as the Human dataset. The\nSCOPE model integrates three-dimensional protein and compound representations,\ngraph neural networks, and bilinear attention mechanisms to effectively capture\ncross domain interaction patterns, significantly outperforming state-of-the-art\nmethods across various DTI prediction tasks. Additionally, SCOPE-DTI provides a\nuser-friendly interface and database. We further validate its effectiveness by\nexperimentally identifying anticancer targets of Ginsenoside Rh1. By offering\ncomprehensive data, advanced modeling, and accessible tools, SCOPE-DTI\naccelerates drug discovery research.\n","authors":["Yigang Chen","Xiang Ji","Ziyue Zhang","Yuming Zhou","Yang-Chi-Dung Lin","Hsi-Yuan Huang","Tao Zhang","Yi Lai","Ke Chen","Chang Su","Xingqiao Lin","Zihao Zhu","Yanggyi Zhang","Kangping Wei","Jiehui Fu","Yixian Huang","Shidong Cui","Shih-Chung Yen","Ariel Warshel","Hsien-Da Huang"],"pdf_url":"https://arxiv.org/pdf/2503.09251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16991v2","updated":"2025-03-12T10:41:49Z","published":"2024-09-25T14:57:07Z","title":"What is the relation between Slow Feature Analysis and the Successor\n  Representation?","summary":"  Slow feature analysis (SFA) is an unsupervised method for extracting\nrepresentations from time series data. The successor representation (SR) is a\nmethod for representing states in a Markov decision process (MDP) based on\ntransition statistics. While SFA and SR stem from distinct areas of machine\nlearning, they share important properties, both in terms of their mathematics\nand the types of information they are sensitive to. This work studies their\nconnection along these two axes. In particular, both SFA and SR are explored\nanalytically, and in the setting of a one-hot encoded MDP, a formal equivalence\nis demonstrated in terms of the grid-like representations that occur as\nsolutions/eigenvectors. Moreover, it is shown that the columns of the matrices\ninvolved in SFA contain place-like representations, which are formally distinct\nfrom place-cell models that have already been defined using SFA.\n","authors":["Eddie Seabrook","Laurenz Wiskott"],"pdf_url":"https://arxiv.org/pdf/2409.16991v2.pdf","comment":"52 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.03241v2","updated":"2025-03-12T10:24:40Z","published":"2025-03-05T07:47:57Z","title":"Structural Entropy Guided Unsupervised Graph Out-Of-Distribution\n  Detection","summary":"  With the emerging of huge amount of unlabeled data, unsupervised\nout-of-distribution (OOD) detection is vital for ensuring the reliability of\ngraph neural networks (GNNs) by identifying OOD samples from in-distribution\n(ID) ones during testing, where encountering novel or unknown data is\ninevitable. Existing methods often suffer from compromised performance due to\nredundant information in graph structures, which impairs their ability to\neffectively differentiate between ID and OOD data. To address this challenge,\nwe propose SEGO, an unsupervised framework that integrates structural entropy\ninto OOD detection regarding graph classification. Specifically, within the\narchitecture of contrastive learning, SEGO introduces an anchor view in the\nform of coding tree by minimizing structural entropy. The obtained coding tree\neffectively removes redundant information from graphs while preserving\nessential structural information, enabling the capture of distinct graph\npatterns between ID and OOD samples. Furthermore, we present a multi-grained\ncontrastive learning scheme at local, global, and tree levels using triplet\nviews, where coding trees with essential information serve as the anchor view.\nExtensive experiments on real-world datasets validate the effectiveness of\nSEGO, demonstrating superior performance over state-of-the-art baselines in OOD\ndetection. Specifically, our method achieves the best performance on 9 out of\n10 dataset pairs, with an average improvement of 3.7\\% on OOD detection\ndatasets, significantly surpassing the best competitor by 10.8\\% on the\nFreeSolv/ToxCast dataset pair.\n","authors":["Yue Hou","He Zhu","Ruomei Liu","Yingke Su","Jinxiang Xia","Junran Wu","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03241v2.pdf","comment":"Accepted by AAAI 2025 (The 39th Annual AAAI Conference on Artificial\n  Intelligence)"},{"id":"http://arxiv.org/abs/2503.09226v1","updated":"2025-03-12T10:17:54Z","published":"2025-03-12T10:17:54Z","title":"Towards Regulatory-Confirmed Adaptive Clinical Trials: Machine Learning\n  Opportunities and Solutions","summary":"  Randomized Controlled Trials (RCTs) are the gold standard for evaluating the\neffect of new medical treatments. Treatments must pass stringent regulatory\nconditions in order to be approved for widespread use, yet even after the\nregulatory barriers are crossed, real-world challenges might arise: Who should\nget the treatment? What is its true clinical utility? Are there discrepancies\nin the treatment effectiveness across diverse and under-served populations? We\nintroduce two new objectives for future clinical trials that integrate\nregulatory constraints and treatment policy value for both the entire\npopulation and under-served populations, thus answering some of the questions\nabove in advance. Designed to meet these objectives, we formulate Randomize\nFirst Augment Next (RFAN), a new framework for designing Phase III clinical\ntrials. Our framework consists of a standard randomized component followed by\nan adaptive one, jointly meant to efficiently and safely acquire and assign\npatients into treatment arms during the trial. Then, we propose strategies for\nimplementing RFAN based on causal, deep Bayesian active learning. Finally, we\nempirically evaluate the performance of our framework using synthetic and\nreal-world semi-synthetic datasets.\n","authors":["Omer Noy Klein","Alihan Hüyük","Ron Shamir","Uri Shalit","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2503.09226v1.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.10153v3","updated":"2025-03-12T10:05:37Z","published":"2024-11-15T12:52:02Z","title":"A unifying framework for generalised Bayesian online learning in\n  non-stationary environments","summary":"  We propose a unifying framework for methods that perform probabilistic online\nlearning in non-stationary environments. We call the framework BONE, which\nstands for generalised (B)ayesian (O)nline learning in (N)on-stationary\n(E)nvironments. BONE provides a common structure to tackle a variety of\nproblems, including online continual learning, prequential forecasting, and\ncontextual bandits. The framework requires specifying three modelling choices:\n(i) a model for measurements (e.g., a neural network), (ii) an auxiliary\nprocess to model non-stationarity (e.g., the time since the last changepoint),\nand (iii) a conditional prior over model parameters (e.g., a multivariate\nGaussian). The framework also requires two algorithmic choices, which we use to\ncarry out approximate inference under this framework: (i) an algorithm to\nestimate beliefs (posterior distribution) about the model parameters given the\nauxiliary variable, and (ii) an algorithm to estimate beliefs about the\nauxiliary variable. We show how the modularity of our framework allows for many\nexisting methods to be reinterpreted as instances of BONE, and it allows us to\npropose new methods. We compare experimentally existing methods with our\nproposed new method on several datasets, providing insights into the situations\nthat make each method more suitable for a specific task. We provide a Jax open\nsource library to facilitate the adoption of this framework.\n","authors":["Gerardo Duran-Martin","Leandro Sánchez-Betancourt","Alexander Y. Shestopaloff","Kevin Murphy"],"pdf_url":"https://arxiv.org/pdf/2411.10153v3.pdf","comment":"Published in Transactions on Machine Learning Research (03/2025)"},{"id":"http://arxiv.org/abs/2503.09211v1","updated":"2025-03-12T10:00:09Z","published":"2025-03-12T10:00:09Z","title":"Why LLMs Cannot Think and How to Fix It","summary":"  This paper elucidates that current state-of-the-art Large Language Models\n(LLMs) are fundamentally incapable of making decisions or developing \"thoughts\"\nwithin the feature space due to their architectural constraints. We establish a\ndefinition of \"thought\" that encompasses traditional understandings of that\nterm and adapt it for application to LLMs. We demonstrate that the\narchitectural design and language modeling training methodology of contemporary\nLLMs inherently preclude them from engaging in genuine thought processes. Our\nprimary focus is on this theoretical realization rather than practical insights\nderived from experimental data. Finally, we propose solutions to enable thought\nprocesses within the feature space and discuss the broader implications of\nthese architectural modifications.\n","authors":["Marius Jahrens","Thomas Martinetz"],"pdf_url":"https://arxiv.org/pdf/2503.09211v1.pdf","comment":"Original conference submission for neurips 2024"},{"id":"http://arxiv.org/abs/2503.09206v1","updated":"2025-03-12T09:52:04Z","published":"2025-03-12T09:52:04Z","title":"Robust Asymmetric Heterogeneous Federated Learning with Corrupted\n  Clients","summary":"  This paper studies a challenging robust federated learning task with model\nheterogeneous and data corrupted clients, where the clients have different\nlocal model structures. Data corruption is unavoidable due to factors such as\nrandom noise, compression artifacts, or environmental conditions in real-world\ndeployment, drastically crippling the entire federated system. To address these\nissues, this paper introduces a novel Robust Asymmetric Heterogeneous Federated\nLearning (RAHFL) framework. We propose a Diversity-enhanced supervised\nContrastive Learning technique to enhance the resilience and adaptability of\nlocal models on various data corruption patterns. Its basic idea is to utilize\ncomplex augmented samples obtained by the mixed-data augmentation strategy for\nsupervised contrastive learning, thereby enhancing the ability of the model to\nlearn robust and diverse feature representations. Furthermore, we design an\nAsymmetric Heterogeneous Federated Learning strategy to resist corrupt feedback\nfrom external clients. The strategy allows clients to perform selective one-way\nlearning during collaborative learning phase, enabling clients to refrain from\nincorporating lower-quality information from less robust or underperforming\ncollaborators. Extensive experimental results demonstrate the effectiveness and\nrobustness of our approach in diverse, challenging federated learning\nenvironments. Our code and models are public available at\nhttps://github.com/FangXiuwen/RAHFL.\n","authors":["Xiuwen Fang","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2503.09206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16370v3","updated":"2025-03-12T09:51:17Z","published":"2024-11-25T13:26:09Z","title":"A Review of Bayesian Uncertainty Quantification in Deep Probabilistic\n  Image Segmentation","summary":"  Advancements in image segmentation play an integral role within the broad\nscope of Deep Learning-based Computer Vision. Furthermore, their widespread\napplicability in critical real-world tasks has resulted in challenges related\nto the reliability of such algorithms. Hence, uncertainty quantification has\nbeen extensively studied within this context, enabling the expression of model\nignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to\nprevent uninformed decision-making. Due to the rapid adoption of Convolutional\nNeural Network (CNN)-based segmentation models in high-stake applications, a\nsubstantial body of research has been published on this very topic, causing its\nswift expansion into a distinct field. This work provides a comprehensive\noverview of probabilistic segmentation, by discussing fundamental concepts of\nuncertainty quantification, governing advancements in the field as well as the\napplication to various tasks. Moreover, literature on both types of\nuncertainties trace back to four key applications: (1) to quantify statistical\ninconsistencies in the annotation process due ambiguous images, (2) correlating\nprediction error with uncertainty, (3) expanding the model hypothesis space for\nbetter generalization, and (4) Active Learning. An extensive discussion follows\nthat includes an overview of utilized datasets for each of the applications and\nevaluation of the available methods. We also highlight challenges related to\narchitectures, uncertainty quantification methods, standardization and\nbenchmarking, and finally end with recommendations for future work such as\nmethods based on single forward passes and models that appropriately leverage\nvolumetric data.\n","authors":["M. M. A. Valiuddin","R. J. G. van Sloun","C. G. A. Viviers","P. H. N. de With","F. van der Sommen"],"pdf_url":"https://arxiv.org/pdf/2411.16370v3.pdf","comment":"20 pages, revised"},{"id":"http://arxiv.org/abs/2503.09203v1","updated":"2025-03-12T09:47:58Z","published":"2025-03-12T09:47:58Z","title":"MarineGym: A High-Performance Reinforcement Learning Platform for\n  Underwater Robotics","summary":"  This work presents the MarineGym, a high-performance reinforcement learning\n(RL) platform specifically designed for underwater robotics. It aims to address\nthe limitations of existing underwater simulation environments in terms of RL\ncompatibility, training efficiency, and standardized benchmarking. MarineGym\nintegrates a proposed GPU-accelerated hydrodynamic plugin based on Isaac Sim,\nachieving a rollout speed of 250,000 frames per second on a single NVIDIA RTX\n3060 GPU. It also provides five models of unmanned underwater vehicles (UUVs),\nmultiple propulsion systems, and a set of predefined tasks covering core\nunderwater control challenges. Additionally, the DR toolkit allows flexible\nadjustments of simulation and task parameters during training to improve\nSim2Real transfer. Further benchmark experiments demonstrate that MarineGym\nimproves training efficiency over existing platforms and supports robust policy\nadaptation under various perturbations. We expect this platform could drive\nfurther advancements in RL research for underwater robotics. For more details\nabout MarineGym and its applications, please visit our project page:\nhttps://marine-gym.com/.\n","authors":["Shuguang Chu","Zebin Huang","Yutong Li","Mingwei Lin","Ignacio Carlucho","Yvan R. Petillot","Canjun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.09203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09200v1","updated":"2025-03-12T09:44:15Z","published":"2025-03-12T09:44:15Z","title":"Time-EAPCR: A Deep Learning-Based Novel Approach for Anomaly Detection\n  Applied to the Environmental Field","summary":"  As human activities intensify, environmental systems such as aquatic\necosystems and water treatment systems face increasingly complex pressures,\nimpacting ecological balance, public health, and sustainable development,\nmaking intelligent anomaly monitoring essential. However, traditional\nmonitoring methods suffer from delayed responses, insufficient data processing\ncapabilities, and weak generalisation, making them unsuitable for complex\nenvironmental monitoring needs.In recent years, machine learning has been\nwidely applied to anomaly detection, but the multi-dimensional features and\nspatiotemporal dynamics of environmental ecological data, especially the\nlong-term dependencies and strong variability in the time dimension, limit the\neffectiveness of traditional methods.Deep learning, with its ability to\nautomatically learn features, captures complex nonlinear relationships,\nimproving detection performance. However, its application in environmental\nmonitoring is still in its early stages and requires further exploration.This\npaper introduces a new deep learning method, Time-EAPCR\n(Time-Embedding-Attention-Permutated CNN-Residual), and applies it to\nenvironmental science. The method uncovers feature correlations, captures\ntemporal evolution patterns, and enables precise anomaly detection in\nenvironmental systems.We validated Time-EAPCR's high accuracy and robustness\nacross four publicly available environmental datasets. Experimental results\nshow that the method efficiently handles multi-source data, improves detection\naccuracy, and excels across various scenarios with strong adaptability and\ngeneralisation. Additionally, a real-world river monitoring dataset confirmed\nthe feasibility of its deployment, providing reliable technical support for\nenvironmental monitoring.\n","authors":["Lei Liu","Yuchao Lu","Ling An","Huajie Liang","Chichun Zhou","Zhenyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09199v1","updated":"2025-03-12T09:43:48Z","published":"2025-03-12T09:43:48Z","title":"GENEOnet: Statistical analysis supporting explainability and\n  trustworthiness","summary":"  Group Equivariant Non-Expansive Operators (GENEOs) have emerged as\nmathematical tools for constructing networks for Machine Learning and\nArtificial Intelligence. Recent findings suggest that such models can be\ninserted within the domain of eXplainable Artificial Intelligence (XAI) due to\ntheir inherent interpretability. In this study, we aim to verify this claim\nwith respect to GENEOnet, a GENEO network developed for an application in\ncomputational biochemistry by employing various statistical analyses and\nexperiments. Such experiments first allow us to perform a sensitivity analysis\non GENEOnet's parameters to test their significance. Subsequently, we show that\nGENEOnet exhibits a significantly higher proportion of equivariance compared to\nother methods. Lastly, we demonstrate that GENEOnet is on average robust to\nperturbations arising from molecular dynamics. These results collectively serve\nas proof of the explainability, trustworthiness, and robustness of GENEOnet and\nconfirm the beneficial use of GENEOs in the context of Trustworthy Artificial\nIntelligence.\n","authors":["Giovanni Bocchi","Patrizio Frosini","Alessandra Micheletti","Alessandro Pedretti","Carmen Gratteri","Filippo Lunghini","Andrea Rosario Beccari","Carmine Talarico"],"pdf_url":"https://arxiv.org/pdf/2503.09199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09194v1","updated":"2025-03-12T09:38:40Z","published":"2025-03-12T09:38:40Z","title":"Addressing pitfalls in implicit unobserved confounding synthesis using\n  explicit block hierarchical ancestral sampling","summary":"  Unbiased data synthesis is crucial for evaluating causal discovery algorithms\nin the presence of unobserved confounding, given the scarcity of real-world\ndatasets. A common approach, implicit parameterization, encodes unobserved\nconfounding by modifying the off-diagonal entries of the idiosyncratic\ncovariance matrix while preserving positive definiteness. Within this approach,\nstate-of-the-art protocols have two distinct issues that hinder unbiased\nsampling from the complete space of causal models: first, the use of diagonally\ndominant constructions, which restrict the spectrum of partial correlation\nmatrices; and second, the restriction of possible graphical structures when\nsampling bidirected edges, unnecessarily ruling out valid causal models. To\naddress these limitations, we propose an improved explicit modeling approach\nfor unobserved confounding, leveraging block-hierarchical ancestral generation\nof ground truth causal graphs. Algorithms for converting the ground truth DAG\ninto ancestral graph is provided so that the output of causal discovery\nalgorithms could be compared with. We prove that our approach fully covers the\nspace of causal models, including those generated by the implicit\nparameterization, thus enabling more robust evaluation of methods for causal\ndiscovery and inference.\n","authors":["Xudong Sun","Alex Markham","Pratik Misra","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2503.09194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09192v1","updated":"2025-03-12T09:34:05Z","published":"2025-03-12T09:34:05Z","title":"Differential Privacy Personalized Federated Learning Based on\n  Dynamically Sparsified Client Updates","summary":"  Personalized federated learning is extensively utilized in scenarios\ncharacterized by data heterogeneity, facilitating more efficient and automated\nlocal training on data-owning terminals. This includes the automated selection\nof high-performance model parameters for upload, thereby enhancing the overall\ntraining process. However, it entails significant risks of privacy leakage.\nExisting studies have attempted to mitigate these risks by utilizing\ndifferential privacy. Nevertheless, these studies present two major\nlimitations: (1) The integration of differential privacy into personalized\nfederated learning lacks sufficient personalization, leading to the\nintroduction of excessive noise into the model. (2) It fails to adequately\ncontrol the spatial scope of model update information, resulting in a\nsuboptimal balance between data privacy and model effectiveness in differential\nprivacy federated learning. In this paper, we propose a differentially private\npersonalized federated learning approach that employs dynamically sparsified\nclient updates through reparameterization and adaptive norm(DP-pFedDSU).\nReparameterization training effectively selects personalized client update\ninformation, thereby reducing the quantity of updates. This approach minimizes\nthe introduction of noise to the greatest extent possible. Additionally,\ndynamic adaptive norm refers to controlling the norm space of model updates\nduring the training process, mitigating the negative impact of clipping on the\nupdate information. These strategies substantially enhance the effective\nintegration of differential privacy and personalized federated learning.\nExperimental results on EMNIST, CIFAR-10, and CIFAR-100 demonstrate that our\nproposed scheme achieves superior performance and is well-suited for more\ncomplex personalized federated learning scenarios.\n","authors":["Chuanyin Wang","Yifei Zhang","Neng Gao","Qiang Luo"],"pdf_url":"https://arxiv.org/pdf/2503.09192v1.pdf","comment":"10 pages,2 figures"},{"id":"http://arxiv.org/abs/2503.09186v1","updated":"2025-03-12T09:28:41Z","published":"2025-03-12T09:28:41Z","title":"Rethinking Bimanual Robotic Manipulation: Learning with Decoupled\n  Interaction Framework","summary":"  Bimanual robotic manipulation is an emerging and critical topic in the\nrobotics community. Previous works primarily rely on integrated control models\nthat take the perceptions and states of both arms as inputs to directly predict\ntheir actions. However, we think bimanual manipulation involves not only\ncoordinated tasks but also various uncoordinated tasks that do not require\nexplicit cooperation during execution, such as grasping objects with the\nclosest hand, which integrated control frameworks ignore to consider due to\ntheir enforced cooperation in the early inputs. In this paper, we propose a\nnovel decoupled interaction framework that considers the characteristics of\ndifferent tasks in bimanual manipulation. The key insight of our framework is\nto assign an independent model to each arm to enhance the learning of\nuncoordinated tasks, while introducing a selective interaction module that\nadaptively learns weights from its own arm to improve the learning of\ncoordinated tasks. Extensive experiments on seven tasks in the RoboTwin dataset\ndemonstrate that: (1) Our framework achieves outstanding performance, with a\n23.5% boost over the SOTA method. (2) Our framework is flexible and can be\nseamlessly integrated into existing methods. (3) Our framework can be\neffectively extended to multi-agent manipulation tasks, achieving a 28% boost\nover the integrated control SOTA. (4) The performance boost stems from the\ndecoupled design itself, surpassing the SOTA by 16.5% in success rate with only\n1/6 of the model size.\n","authors":["Jian-Jian Jiang","Xiao-Ming Wu","Yi-Xiang He","Ling-An Zeng","Yi-Lin Wei","Dandan Zhang","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.09186v1.pdf","comment":"14 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.09184v1","updated":"2025-03-12T09:24:31Z","published":"2025-03-12T09:24:31Z","title":"Exploiting Unstructured Sparsity in Fully Homomorphic Encrypted DNNs","summary":"  The deployment of deep neural networks (DNNs) in privacy-sensitive\nenvironments is constrained by computational overheads in fully homomorphic\nencryption (FHE). This paper explores unstructured sparsity in FHE matrix\nmultiplication schemes as a means of reducing this burden while maintaining\nmodel accuracy requirements. We demonstrate that sparsity can be exploited in\narbitrary matrix multiplication, providing runtime benefits compared to a\nbaseline naive algorithm at all sparsity levels. This is a notable departure\nfrom the plaintext domain, where there is a trade-off between sparsity and the\noverhead of the sparse multiplication algorithm. In addition, we propose three\nsparse multiplication schemes in FHE based on common plaintext sparse\nencodings. We demonstrate the performance gain is scheme-invariant; however,\nsome sparse schemes vastly reduce the memory storage requirements of the\nencrypted matrix at high sparsity values. Our proposed sparse schemes yield an\naverage performance gain of 2.5x at 50% unstructured sparsity, with our\nmulti-threading scheme providing a 32.5x performance increase over the\nequivalent single-threaded sparse computation when utilizing 64 cores.\n","authors":["Aidan Ferguson","Perry Gibson","Lara D'Agata","Parker McLeod","Ferhat Yaman","Amitabh Das","Ian Colbert","José Cano"],"pdf_url":"https://arxiv.org/pdf/2503.09184v1.pdf","comment":"Accepted to 5th Workshop on Machine Learning and Systems (EuroMLSys)\n  co-located with EuroSys '25"},{"id":"http://arxiv.org/abs/2412.10663v2","updated":"2025-03-12T09:19:31Z","published":"2024-12-14T03:32:54Z","title":"Memory-Efficient 4-bit Preconditioned Stochastic Optimization","summary":"  Preconditioned stochastic optimization algorithms, exemplified by Shampoo,\noutperform first-order optimizers by offering theoretical convergence benefits\nand practical gains in large-scale neural network training. However, they incur\nsubstantial memory overhead due to the storage demands of non-diagonal\npreconditioning matrices. To address this, we introduce 4-bit quantization for\nShampoo's preconditioners. We introduce two key methods: First, we apply\nCholesky decomposition followed by quantization of the Cholesky factors,\nreducing memory usage by leveraging their lower triangular structure while\nbetter preserving spectral properties to minimize information loss. To our\nknowledge, this is the first quantization approach applied to Cholesky factors\nof preconditioners. Second, we incorporate error feedback in the quantization\nprocess, efficiently storing Cholesky factor and error state in the lower and\nupper triangular parts of the same matrix. Through extensive experiments, we\ndemonstrate that combining Cholesky quantization with error feedback enhances\nmemory efficiency and algorithm performance in large-scale deep-learning tasks.\nTheoretically, we also provide convergence proofs for quantized Shampoo under\nboth smooth and non-smooth stochastic optimization settings.\n","authors":["Jingyang Li","Kuangyu Ding","Kim-Chuan Toh","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.10663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09181v1","updated":"2025-03-12T09:13:21Z","published":"2025-03-12T09:13:21Z","title":"Dynamic Feature Selection from Variable Feature Sets Using Features of\n  Features","summary":"  Machine learning models usually assume that a set of feature values used to\nobtain an output is fixed in advance. However, in many real-world problems, a\ncost is associated with measuring these features. To address the issue of\nreducing measurement costs, various methods have been proposed to dynamically\nselect which features to measure, but existing methods assume that the set of\nmeasurable features remains constant, which makes them unsuitable for cases\nwhere the set of measurable features varies from instance to instance. To\novercome this limitation, we define a new problem setting for Dynamic Feature\nSelection (DFS) with variable feature sets and propose a deep learning method\nthat utilizes prior information about each feature, referred to as ''features\nof features''. Experimental results on several datasets demonstrate that the\nproposed method effectively selects features based on the prior information,\neven when the set of measurable features changes from instance to instance.\n","authors":["Katsumi Takahashi","Koh Takeuchi","Hisashi Kashima"],"pdf_url":"https://arxiv.org/pdf/2503.09181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04620v4","updated":"2025-03-12T09:13:15Z","published":"2024-05-07T19:05:26Z","title":"Folded Context Condensation in Path Integral Formalism for Infinite\n  Context Transformers","summary":"  In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.\n","authors":["Won-Gi Paeng","Daesuk Kwon","Kyungwon Jeong","Honggyo Suh"],"pdf_url":"https://arxiv.org/pdf/2405.04620v4.pdf","comment":"10 pages, 12 figures"},{"id":"http://arxiv.org/abs/2411.17489v2","updated":"2025-03-12T09:04:43Z","published":"2024-11-26T14:57:30Z","title":"Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for\n  Artifact Detection in 3D Scene Reconstructions","summary":"  Modern reconstruction techniques can effectively model complex 3D scenes from\nsparse 2D views. However, automatically assessing the quality of novel views\nand identifying artifacts is challenging due to the lack of ground truth images\nand the limitations of No-Reference image metrics in predicting reliable\nartifact maps. The absence of such metrics hinders the assessment of the\nquality of novel views and limits the adoption of post-processing techniques,\nsuch as inpainting, to enhance reconstruction quality. To tackle this, recent\nwork has established a new category of metrics (Cross-Reference), predicting\nimage quality solely by leveraging context from alternate viewpoint captures\n(arXiv:2404.14409). In this work, we propose a new Cross-Reference metric,\nPuzzle Similarity, which is designed to localize artifacts in novel views. Our\napproach utilizes image patch statistics from the input views to establish a\nscene-specific distribution, later used to identify poorly reconstructed\nregions in the novel views. Given the lack of good measures to evaluate\nCross-Reference methods in the context of 3D reconstruction, we collected a\nnovel human-labeled dataset of artifact and distortion maps in unseen\nreconstructed views. Through this dataset, we demonstrate that our method\nachieves state-of-the-art localization of artifacts in novel views, correlating\nwith human assessment, even without aligned references. We can leverage our new\nmetric to enhance applications like automatic image restoration, guided\nacquisition, or 3D reconstruction from sparse inputs. Find the project page at\nhttps://nihermann.github.io/puzzlesim/ .\n","authors":["Nicolai Hermann","Jorge Condor","Piotr Didyk"],"pdf_url":"https://arxiv.org/pdf/2411.17489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20086v2","updated":"2025-03-12T09:02:55Z","published":"2024-05-30T14:16:32Z","title":"Analysis of a multi-target linear shrinkage covariance estimator","summary":"  Multi-target linear shrinkage is an extension of the standard single-target\nlinear shrinkage for covariance estimation. We combine several constant\nmatrices - the targets - with the sample covariance matrix. We derive the\noracle and a \\textit{bona fide} multi-target linear shrinkage estimator with\nexact and empirical mean. In both settings, we proved its convergence towards\nthe oracle under Kolmogorov asymptotics. Finally, we show empirically that it\noutperforms other standard estimators in various situations.\n","authors":["Benoit Oriol"],"pdf_url":"https://arxiv.org/pdf/2405.20086v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02542v2","updated":"2025-03-12T09:02:44Z","published":"2024-12-03T16:34:49Z","title":"Unveiling Concept Attribution in Diffusion Models","summary":"  Diffusion models have shown remarkable abilities in generating realistic and\nhigh-quality images from text prompts. However, a trained model remains largely\nblack-box; little do we know about the roles of its components in exhibiting a\nconcept such as objects or styles. Recent works employ causal tracing to\nlocalize knowledge-storing layers in generative models without showing how\nother layers contribute to the target concept. In this work, we approach\ndiffusion models' interpretability problem from a more general perspective and\npose a question: \\textit{``How do model components work jointly to demonstrate\nknowledge?''}. To answer this question, we decompose diffusion models using\ncomponent attribution, systematically unveiling the importance of each\ncomponent (specifically the model parameter) in generating a concept. The\nproposed framework, called \\textbf{C}omponent \\textbf{A}ttribution for\n\\textbf{D}iffusion Model (CAD), discovers the localization of concept-inducing\n(positive) components, while interestingly uncovers another type of components\nthat contribute negatively to generating a concept, which is missing in the\nprevious knowledge localization work. Based on this holistic understanding of\ndiffusion models, we introduce two fast, inference-time model editing\nalgorithms, CAD-Erase and CAD-Amplify; in particular, CAD-Erase enables erasure\nand CAD-Amplify allows amplification of a generated concept by ablating the\npositive and negative components, respectively, while retaining knowledge of\nother concepts. Extensive experimental results validate the significance of\nboth positive and negative components pinpointed by our framework,\ndemonstrating the potential of providing a complete view of interpreting\ngenerative models. Our code is available\n\\href{https://github.com/mail-research/CAD-attribution4diffusion}{here}.\n","authors":["Quang H. Nguyen","Hoang Phan","Khoa D. Doan"],"pdf_url":"https://arxiv.org/pdf/2412.02542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08717v3","updated":"2025-03-12T09:00:23Z","published":"2024-04-12T07:32:57Z","title":"State-space systems as dynamic generative models","summary":"  A probabilistic framework to study the dependence structure induced by\ndeterministic discrete-time state-space systems between input and output\nprocesses is introduced. General sufficient conditions are formulated under\nwhich output processes exist and are unique once an input process has been\nfixed, a property that in the deterministic state-space literature is known as\nthe echo state property. When those conditions are satisfied, the given\nstate-space system becomes a generative model for probabilistic dependences\nbetween two sequence spaces. Moreover, those conditions guarantee that the\noutput depends continuously on the input when using the Wasserstein metric. The\noutput processes whose existence is proved are shown to be causal in a specific\nsense and to generalize those studied in purely deterministic situations. The\nresults in this paper constitute a significant stochastic generalization of\nsufficient conditions for the deterministic echo state property to hold, in the\nsense that the stochastic echo state property can be satisfied under\ncontractivity conditions that are strictly weaker than those in deterministic\nsituations. This means that state-space systems can induce a purely\nprobabilistic dependence structure between input and output sequence spaces\neven when there is no functional relation between those two spaces.\n","authors":["Juan-Pablo Ortega","Florian Rossmannek"],"pdf_url":"https://arxiv.org/pdf/2404.08717v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09170v1","updated":"2025-03-12T08:58:28Z","published":"2025-03-12T08:58:28Z","title":"Effective Feature Selection for Predicting Spreading Factor with ML in\n  Large LoRaWAN-based Mobile IoT Networks","summary":"  LoRaWAN is a low-power long-range protocol that enables reliable and robust\ncommunication. This paper addresses the challenge of predicting the spreading\nfactor (SF) in LoRaWAN networks using machine learning (ML) techniques. Optimal\nSF allocation is crucial for optimizing data transmission in IoT-enabled mobile\ndevices, yet it remains a challenging task due to the fluctuation in\nenvironment and network conditions. We evaluated ML model performance across a\nlarge publicly available dataset to explore the best feature across key LoRaWAN\nfeatures such as RSSI, SNR, frequency, distance between end devices and\ngateways, and antenna height of the end device, further, we also experimented\nwith 31 different combinations possible for 5 features. We trained and\nevaluated the model using k-nearest neighbors (k-NN), Decision Tree Classifier\n(DTC), Random Forest (RF), and Multinomial Logistic Regression (MLR)\nalgorithms. The combination of RSSI and SNR was identified as the best feature\nset. The finding of this paper provides valuable information for reducing the\noverall cost of dataset collection for ML model training and extending the\nbattery life of LoRaWAN devices. This work contributes to a more reliable\nLoRaWAN system by understanding the importance of specific feature sets for\noptimized SF allocation.\n","authors":["Aman Prakash","Nikumani Choudhury","Anakhi Hazarika","Alekhya Gorrela"],"pdf_url":"https://arxiv.org/pdf/2503.09170v1.pdf","comment":"Accepted at 31st National Conference on Communications"},{"id":"http://arxiv.org/abs/2503.01478v4","updated":"2025-03-12T08:49:58Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v4.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.09159v1","updated":"2025-03-12T08:41:49Z","published":"2025-03-12T08:41:49Z","title":"Unreflected Use of Tabular Data Repositories Can Undermine Research\n  Quality","summary":"  Data repositories have accumulated a large number of tabular datasets from\nvarious domains. Machine Learning researchers are actively using these datasets\nto evaluate novel approaches. Consequently, data repositories have an important\nstanding in tabular data research. They not only host datasets but also provide\ninformation on how to use them in supervised learning tasks. In this paper, we\nargue that, despite great achievements in usability, the unreflected usage of\ndatasets from data repositories may have led to reduced research quality and\nscientific rigor. We present examples from prominent recent studies that\nillustrate the problematic use of datasets from OpenML, a large data repository\nfor tabular data. Our illustrations help users of data repositories avoid\nfalling into the traps of (1) using suboptimal model selection strategies, (2)\noverlooking strong baselines, and (3) inappropriate preprocessing. In response,\nwe discuss possible solutions for how data repositories can prevent the\ninappropriate use of datasets and become the cornerstones for improved overall\nquality of empirical research studies.\n","authors":["Andrej Tschalzev","Lennart Purucker","Stefan Lüdtke","Frank Hutter","Christian Bartelt","Heiner Stuckenschmidt"],"pdf_url":"https://arxiv.org/pdf/2503.09159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17516v4","updated":"2025-03-12T08:31:10Z","published":"2024-02-27T14:00:08Z","title":"QUCE: The Minimisation and Quantification of Path-Based Uncertainty for\n  Generative Counterfactual Explanations","summary":"  Deep Neural Networks (DNNs) stand out as one of the most prominent approaches\nwithin the Machine Learning (ML) domain. The efficacy of DNNs has surged\nalongside recent increases in computational capacity, allowing these approaches\nto scale to significant complexities for addressing predictive challenges in\nbig data. However, as the complexity of DNN models rises, interpretability\ndiminishes. In response to this challenge, explainable models such as\nAdversarial Gradient Integration (AGI) leverage path-based gradients provided\nby DNNs to elucidate their decisions. Yet the performance of path-based\nexplainers can be compromised when gradients exhibit irregularities during\nout-of-distribution path traversal. In this context, we introduce Quantified\nUncertainty Counterfactual Explanations (QUCE), a method designed to mitigate\nout-of-distribution traversal by minimizing path uncertainty. QUCE not only\nquantifies uncertainty when presenting explanations but also generates more\ncertain counterfactual examples. We showcase the performance of the QUCE method\nby comparing it with competing methods for both path-based explanations and\ngenerative counterfactual examples.\n","authors":["Jamie Duell","Monika Seisenberger","Hsuan Fu","Xiuyi Fan"],"pdf_url":"https://arxiv.org/pdf/2402.17516v4.pdf","comment":"Final version published in ICDM 2024, International Conference on\n  Data Mining"},{"id":"http://arxiv.org/abs/2202.04348v2","updated":"2025-03-12T08:15:57Z","published":"2022-02-09T08:59:16Z","title":"MBCT: Tree-Based Feature-Aware Binning for Individual Uncertainty\n  Calibration","summary":"  Most machine learning classifiers only concern classification accuracy, while\ncertain applications (such as medical diagnosis, meteorological forecasting,\nand computation advertising) require the model to predict the true probability,\nknown as a calibrated estimate. In previous work, researchers have developed\nseveral calibration methods to post-process the outputs of a predictor to\nobtain calibrated values, such as binning and scaling methods. Compared with\nscaling, binning methods are shown to have distribution-free theoretical\nguarantees, which motivates us to prefer binning methods for calibration.\nHowever, we notice that existing binning methods have several drawbacks: (a)\nthe binning scheme only considers the original prediction values, thus limiting\nthe calibration performance; and (b) the binning approach is non-individual,\nmapping multiple samples in a bin to the same value, and thus is not suitable\nfor order-sensitive applications. In this paper, we propose a feature-aware\nbinning framework, called Multiple Boosting Calibration Trees (MBCT), along\nwith a multi-view calibration loss to tackle the above issues. Our MBCT\noptimizes the binning scheme by the tree structures of features, and adopts a\nlinear function in a tree node to achieve individual calibration. Our MBCT is\nnon-monotonic, and has the potential to improve order accuracy, due to its\nlearnable binning scheme and the individual calibration. We conduct\ncomprehensive experiments on three datasets in different fields. Results show\nthat our method outperforms all competing models in terms of both calibration\nerror and order accuracy. We also conduct simulation experiments, justifying\nthat the proposed multi-view calibration loss is a better metric in modeling\ncalibration error.\n","authors":["Siguang Huang","Yunli Wang","Lili Mou","Huayue Zhang","Han Zhu","Chuan Yu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2202.04348v2.pdf","comment":"WWW 2022. The new version fixed an error in Eq13"},{"id":"http://arxiv.org/abs/2412.18263v5","updated":"2025-03-12T08:15:14Z","published":"2024-12-24T08:25:38Z","title":"High-Rank Irreducible Cartesian Tensor Decomposition and Bases of\n  Equivariant Spaces","summary":"  Irreducible Cartesian tensors (ICTs) play a crucial role in the design of\nequivariant graph neural networks, as well as in theoretical chemistry and\nchemical physics. Meanwhile, the design space of available linear operations on\ntensors that preserve symmetry presents a significant challenge. The ICT\ndecomposition and a basis of this equivariant space are difficult to obtain for\nhigh-rank tensors. After decades of research, Bonvicini (2024) recently\nachieves an explicit ICT decomposition for $n=5$ with factorial time/space\ncomplexity. In this work we, for the first time, obtains decomposition matrices\nfor ICTs up to rank $n=9$ with reduced and affordable complexity, by\nconstructing what we call path matrices. The path matrices are obtained via\nperforming chain-like contractions with Clebsch-Gordan matrices following the\nparentage scheme. We prove and leverage that the concatenation of path matrices\nis an orthonormal change-of-basis matrix between the Cartesian tensor product\nspace and the spherical direct sum spaces. Furthermore, we identify a complete\northogonal basis for the equivariant space, rather than a spanning set\n(Pearce-Crump, 2023), through this path matrices technique. To the best of our\nknowledge, this is also the first analytic, rather than numerical, method for\ntheoretically obtaining arbitrary rank orthogonal ICT decomposition matrices\nand orthogonal equivariant bases. We further extend our result to the arbitrary\ntensor product and direct sum spaces, enabling free design between different\nspaces while keeping symmetry. The Python code is available at\nhttps://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where\nthe $n=6,\\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and\n4m32s on 28-cores Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.\n","authors":["Shihao Shao","Yikang Li","Zhouchen Lin","Qinghua Cui"],"pdf_url":"https://arxiv.org/pdf/2412.18263v5.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2503.09144v1","updated":"2025-03-12T08:13:39Z","published":"2025-03-12T08:13:39Z","title":"Efficient UAV Swarm-Based Multi-Task Federated Learning with Dynamic\n  Task Knowledge Sharing","summary":"  UAV swarms are widely used in emergency communications, area monitoring, and\ndisaster relief. Coordinated by control centers, they are ideal for federated\nlearning (FL) frameworks. However, current UAV-assisted FL methods primarily\nfocus on single tasks, overlooking the need for multi-task training. In\ndisaster relief scenarios, UAVs perform tasks such as crowd detection, road\nfeasibility analysis, and disaster assessment, which exhibit time-varying\ndemands and potential correlations. In order to meet the time-varying\nrequirements of tasks and complete multiple tasks efficiently under resource\nconstraints, in this paper, we propose a UAV swarm based multi-task FL\nframework, where ground emergency vehicles (EVs) collaborate with UAVs to\naccomplish multiple tasks efficiently under constrained energy and bandwidth\nresources. Through theoretical analysis, we identify key factors affecting task\nperformance and introduce a task attention mechanism to dynamically evaluate\ntask importance, thereby achieving efficient resource allocation. Additionally,\nwe propose a task affinity (TA) metric to capture the dynamic correlation among\ntasks, thereby promoting task knowledge sharing to accelerate training and\nimprove the generalization ability of the model in different scenarios. To\noptimize resource allocation, we formulate a two-layer optimization problem to\njointly optimize UAV transmission power, computation frequency, bandwidth\nallocation, and UAV-EV associations. For the inner problem, we derive\nclosed-form solutions for transmission power, computation frequency, and\nbandwidth allocation and apply a block coordinate descent method for\noptimization. For the outer problem, a two-stage algorithm is designed to\ndetermine optimal UAV-EV associations. Furthermore, theoretical analysis\nreveals a trade-off between UAV energy consumption and multi-task performance.\n","authors":["Yubo Yang","Tao Yang","Xiaofeng Wu","Ziyu Guo","Bo Hu"],"pdf_url":"https://arxiv.org/pdf/2503.09144v1.pdf","comment":"Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file"},{"id":"http://arxiv.org/abs/2503.02880v2","updated":"2025-03-12T08:13:04Z","published":"2025-03-04T18:58:15Z","title":"A New $\\sim 5σ$ Tension at Characteristic Redshift from DESI-DR1\n  BAO and DES-SN5YR Observations","summary":"  We perform a model-independent reconstruction of the angular diameter\ndistance ($D_{A}$) using the Multi-Task Gaussian Process (MTGP) framework with\nDESI-DR1 BAO and DES-SN5YR datasets. We calibrate the comoving sound horizon at\nthe baryon drag epoch $r_d$ to the Planck best-fit value, ensuring consistency\nwith early-universe physics. With the reconstructed $D_A$ at two key redshifts,\n$z\\sim 1.63$ (where $D_{A}^{\\prime} =0$) and at $z\\sim 0.512$ (where\n$D_{A}^{\\prime} = D_{A}$), we derive the expansion rate of the Universe $H(z)$\nat these redshifts. Our findings reveal that at $z\\sim 1.63$, the $H(z)$ is\nfully consistent with the Planck-2018 $\\Lambda$CDM prediction, confirming no\nnew physics at that redshift. However, at $z \\sim 0.512$, the derived $H(z)$\nshows a more than $5\\sigma$ discrepancy with the Planck-2018 $\\Lambda$CDM\nprediction, suggesting a possible breakdown of the $\\Lambda$CDM model as\nconstrained by Planck-2018 at this lower redshift. This emerging $\\sim 5\\sigma$\ntension at $z\\sim 0.512$, distinct from the existing ``Hubble Tension'', may\nsignal the first strong evidence for new physics at low redshifts.\n","authors":["Purba Mukherjee","Anjan A Sen"],"pdf_url":"https://arxiv.org/pdf/2503.02880v2.pdf","comment":"4 pages, 1 table, 3 figures. Comments are welcome. New References\n  added"},{"id":"http://arxiv.org/abs/2406.03199v4","updated":"2025-03-12T07:57:44Z","published":"2024-05-24T13:33:11Z","title":"Bayesian WeakS-to-Strong from Text Classification to Generation","summary":"  Advances in large language models raise the question of how alignment\ntechniques will adapt as models become increasingly complex and humans will\nonly be able to supervise them weakly. Weak-to-Strong mimics such a scenario\nwhere weak model supervision attempts to harness the full capabilities of a\nmuch stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by\nexploring an ensemble of weak models which simulate the variability in human\nopinions. Confidence scores are estimated using a Bayesian approach to guide\nthe WeakS-to-Strong generalization. Furthermore, we extend the application of\nWeakS-to-Strong from text classification tasks to text generation tasks where\nmore advanced strategies are investigated for supervision. Moreover, direct\npreference optimization is applied to advance the student model's preference\nlearning, beyond the basic learning framework of teacher forcing. Results\ndemonstrate the effectiveness of the proposed approach for the reliability of a\nstrong student model, showing potential for superalignment.\n","authors":["Ziyun Cui","Ziyang Zhang","Guangzhi Sun","Wen Wu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.03199v4.pdf","comment":"Accepted by ICLR2025"},{"id":"http://arxiv.org/abs/2503.09134v1","updated":"2025-03-12T07:44:11Z","published":"2025-03-12T07:44:11Z","title":"Clustering by Nonparametric Smoothing","summary":"  A novel formulation of the clustering problem is introduced in which the task\nis expressed as an estimation problem, where the object to be estimated is a\nfunction which maps a point to its distribution of cluster membership. Unlike\nexisting approaches which implicitly estimate such a function, like Gaussian\nMixture Models (GMMs), the proposed approach bypasses any explicit modelling\nassumptions and exploits the flexible estimation potential of nonparametric\nsmoothing. An intuitive approach for selecting the tuning parameters governing\nestimation is provided, which allows the proposed method to automatically\ndetermine both an appropriate level of flexibility and also the number of\nclusters to extract from a given data set. Experiments on a large collection of\npublicly available data sets are used to document the strong performance of the\nproposed approach, in comparison with relevant benchmarks from the literature.\nR code to implement the proposed approach is available from\nhttps://github.com/DavidHofmeyr/ CNS\n","authors":["David P. Hofmeyr"],"pdf_url":"https://arxiv.org/pdf/2503.09134v1.pdf","comment":"Under submission for possible publication by IEEE"},{"id":"http://arxiv.org/abs/2503.02233v2","updated":"2025-03-12T07:42:04Z","published":"2025-03-04T03:16:02Z","title":"Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling","summary":"  Large language models (LLMs) frequently hallucinate due to misaligned\nself-awareness, generating erroneous outputs when addressing queries beyond\ntheir knowledge boundaries. While existing approaches mitigate hallucinations\nvia uncertainty estimation or query rejection, they suffer from computational\ninefficiency or sacrificed helpfulness. To address these issues, we propose the\nExplicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and\nslow reasoning systems to harmonize reliability and usability. The framework\nfirst employs a fast-thinking model to generate confidence-labeled responses,\nenabling immediate use of high-confidence outputs. For uncertain predictions, a\nslow refinement model conducts targeted reasoning to improve accuracy. To align\nmodel behavior with our proposed object, we propose a hybrid training pipeline,\nenhancing self-awareness without degrading task performance. Evaluations on\ndialogue state tracking tasks demonstrate that EKBM achieves superior model\nreliability over uncertainty-based baselines. Further analysis reveals that\nrefinement substantially boosts accuracy while maintaining low computational\noverhead. Our work establishes a scalable paradigm for advancing LLM\nreliability and balancing accuracy and practical utility in error-sensitive\napplications.\n","authors":["Hang Zheng","Hongshen Xu","Yuncong Liu","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02233v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09128v1","updated":"2025-03-12T07:33:44Z","published":"2025-03-12T07:33:44Z","title":"Urban Region Representation Learning: A Flexible Approach","summary":"  The increasing availability of urban data offers new opportunities for\nlearning region representations, which can be used as input to machine learning\nmodels for downstream tasks such as check-in or crime prediction. While\nexisting solutions have produced promising results, an issue is their fixed\nformation of regions and fixed input region features, which may not suit the\nneeds of different downstream tasks. To address this limitation, we propose a\nmodel named FlexiReg for urban region representation learning that is flexible\nwith both the formation of urban regions and the input region features.\nFlexiReg is based on a spatial grid partitioning over the spatial area of\ninterest. It learns representations for the grid cells, leveraging publicly\naccessible data, including POI, land use, satellite imagery, and street view\nimagery. We propose adaptive aggregation to fuse the cell representations and\nprompt learning techniques to tailor the representations towards different\ntasks, addressing the needs of varying formations of urban regions and\ndownstream tasks. Extensive experiments on five real-world datasets demonstrate\nthat FlexiReg outperforms state-of-the-art models by up to 202% in term of the\naccuracy of four diverse downstream tasks using the produced urban region\nrepresentations.\n","authors":["Fengze Sun","Yanchuan Chang","Egemen Tanin","Shanika Karunasekera","Jianzhong Qi"],"pdf_url":"https://arxiv.org/pdf/2503.09128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08198v2","updated":"2025-03-12T07:26:16Z","published":"2024-12-11T08:41:41Z","title":"Adaptive$^2$: Adaptive Domain Mining for Fine-grained Domain Adaptation\n  Modeling","summary":"  Advertising systems often face the multi-domain challenge, where data\ndistributions vary significantly across scenarios. Existing domain adaptation\nmethods primarily focus on building domain-adaptive neural networks but often\nrely on hand-crafted domain information, e.g., advertising placement, which may\nbe sub-optimal. We think that fine-grained \"domain\" patterns exist that are\ndifficult to hand-craft in online advertisement. Thus, we propose Adaptive$^2$,\na novel framework that first learns domains adaptively using a domain mining\nmodule by self-supervision and then employs a shared&specific network to model\nshared and conflicting information. As a practice, we use VQ-VAE as the domain\nmining module and conduct extensive experiments on public benchmarks. Results\nshow that traditional domain adaptation methods with hand-crafted domains\nperform no better than single-domain models under fair FLOPS conditions,\nhighlighting the importance of domain definition. In contrast, Adaptive$^2$\noutperforms existing approaches, emphasizing the effectiveness of our method\nand the significance of domain mining. We also deployed Adaptive$^2$ in the\nlive streaming scenario of Kuaishou Advertising System, demonstrating its\ncommercial value and potential for automatic domain identification. To the best\nof our knowledge, Adaptive$^2$ is the first approach to automatically learn\nboth domain identification and adaptation in online advertising, opening new\nresearch directions for this area.\n","authors":["Wenxuan Sun","Zixuan Yang","Yunli Wang","Zhen Zhang","Zhiqiang Wang","Yu Li","Jian Yang","Yiming Yang","Shiyang Wen","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2412.08198v2.pdf","comment":"10 pages, 6 figures. Fixed some typos"},{"id":"http://arxiv.org/abs/2503.09124v1","updated":"2025-03-12T07:22:39Z","published":"2025-03-12T07:22:39Z","title":"AdvAD: Exploring Non-Parametric Diffusion for Imperceptible Adversarial\n  Attacks","summary":"  Imperceptible adversarial attacks aim to fool DNNs by adding imperceptible\nperturbation to the input data. Previous methods typically improve the\nimperceptibility of attacks by integrating common attack paradigms with\nspecifically designed perception-based losses or the capabilities of generative\nmodels. In this paper, we propose Adversarial Attacks in Diffusion (AdvAD), a\nnovel modeling framework distinct from existing attack paradigms. AdvAD\ninnovatively conceptualizes attacking as a non-parametric diffusion process by\ntheoretically exploring basic modeling approach rather than using the denoising\nor generation abilities of regular diffusion models requiring neural networks.\nAt each step, much subtler yet effective adversarial guidance is crafted using\nonly the attacked model without any additional network, which gradually leads\nthe end of diffusion process from the original image to a desired imperceptible\nadversarial example. Grounded in a solid theoretical foundation of the proposed\nnon-parametric diffusion process, AdvAD achieves high attack efficacy and\nimperceptibility with intrinsically lower overall perturbation strength.\nAdditionally, an enhanced version AdvAD-X is proposed to evaluate the extreme\nof our novel framework under an ideal scenario. Extensive experiments\ndemonstrate the effectiveness of the proposed AdvAD and AdvAD-X. Compared with\nstate-of-the-art imperceptible attacks, AdvAD achieves an average of 99.9$\\%$\n(+17.3$\\%$) ASR with 1.34 (-0.97) $l_2$ distance, 49.74 (+4.76) PSNR and 0.9971\n(+0.0043) SSIM against four prevalent DNNs with three different architectures\non the ImageNet-compatible dataset. Code is available at\nhttps://github.com/XianguiKang/AdvAD.\n","authors":["Jin Li","Ziqiang He","Anwei Luo","Jian-Fang Hu","Z. Jane Wang","Xiangui Kang"],"pdf_url":"https://arxiv.org/pdf/2503.09124v1.pdf","comment":"Accept by NeurIPS 2024. Please cite this paper using the following\n  format: J. Li, Z. He, A. Luo, J. Hu, Z. Wang, X. Kang*, \"AdvAD: Exploring\n  Non-Parametric Diffusion for Imperceptible Adversarial Attacks\", the 38th\n  Annual Conference on Neural Information Processing Systems (NeurIPS),\n  Vancouver, Canada, Dec 9-15, 2024. Code: https://github.com/XianguiKang/AdvAD"},{"id":"http://arxiv.org/abs/2503.08085v2","updated":"2025-03-12T07:22:25Z","published":"2025-03-11T06:37:54Z","title":"PRISM: Privacy-Preserving Improved Stochastic Masking for Federated\n  Generative Models","summary":"  Despite recent advancements in federated learning (FL), the integration of\ngenerative models into FL has been limited due to challenges such as high\ncommunication costs and unstable training in heterogeneous data environments.\nTo address these issues, we propose PRISM, a FL framework tailored for\ngenerative models that ensures (i) stable performance in heterogeneous data\ndistributions and (ii) resource efficiency in terms of communication cost and\nfinal model size. The key of our method is to search for an optimal stochastic\nbinary mask for a random network rather than updating the model weights,\nidentifying a sparse subnetwork with high generative performance; i.e., a\n``strong lottery ticket''. By communicating binary masks in a stochastic\nmanner, PRISM minimizes communication overhead. This approach, combined with\nthe utilization of maximum mean discrepancy (MMD) loss and a mask-aware dynamic\nmoving average aggregation method (MADA) on the server side, facilitates stable\nand strong generative capabilities by mitigating local divergence in FL\nscenarios. Moreover, thanks to its sparsifying characteristic, PRISM yields a\nlightweight model without extra pruning or quantization, making it ideal for\nenvironments such as edge devices. Experiments on MNIST, FMNIST, CelebA, and\nCIFAR10 demonstrate that PRISM outperforms existing methods, while maintaining\nprivacy with minimal communication costs. PRISM is the first to successfully\ngenerate images under challenging non-IID and privacy-preserving FL\nenvironments on complex datasets, where previous methods have struggled.\n","authors":["Kyeongkook Seo","Dong-Jun Han","Jaejun Yoo"],"pdf_url":"https://arxiv.org/pdf/2503.08085v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01797v4","updated":"2025-03-12T07:18:59Z","published":"2023-11-03T09:20:20Z","title":"On the Generalization Properties of Diffusion Models","summary":"  Diffusion models are a class of generative models that serve to establish a\nstochastic transport map between an empirically observed, yet unknown, target\ndistribution and a known prior. Despite their remarkable success in real-world\napplications, a theoretical understanding of their generalization capabilities\nremains underdeveloped. This work embarks on a comprehensive theoretical\nexploration of the generalization attributes of diffusion models. We establish\ntheoretical estimates of the generalization gap that evolves in tandem with the\ntraining dynamics of score-based diffusion models, suggesting a polynomially\nsmall generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$\nand the model capacity $m$, evading the curse of dimensionality (i.e., not\nexponentially large in the data dimension) when early-stopped. Furthermore, we\nextend our quantitative analysis to a data-dependent scenario, wherein target\ndistributions are portrayed as a succession of densities with progressively\nincreasing distances between modes. This precisely elucidates the adverse\neffect of \"modes shift\" in ground truths on the model generalization. Moreover,\nthese estimates are not solely theoretical constructs but have also been\nconfirmed through numerical simulations. Our findings contribute to the\nrigorous understanding of diffusion models' generalization properties and\nprovide insights that may guide practical applications.\n","authors":["Puheng Li","Zhong Li","Huishuai Zhang","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2311.01797v4.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2211.15072v5","updated":"2025-03-12T07:17:23Z","published":"2022-11-28T05:16:20Z","title":"FaiREE: Fair Classification with Finite-Sample and Distribution-Free\n  Guarantee","summary":"  Algorithmic fairness plays an increasingly critical role in machine learning\nresearch. Several group fairness notions and algorithms have been proposed.\nHowever, the fairness guarantee of existing fair classification methods mainly\ndepends on specific data distributional assumptions, often requiring large\nsample sizes, and fairness could be violated when there is a modest number of\nsamples, which is often the case in practice. In this paper, we propose FaiREE,\na fair classification algorithm that can satisfy group fairness constraints\nwith finite-sample and distribution-free theoretical guarantees. FaiREE can be\nadapted to satisfy various group fairness notions (e.g., Equality of\nOpportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal\naccuracy. These theoretical guarantees are further supported by experiments on\nboth synthetic and real data. FaiREE is shown to have favorable performance\nover state-of-the-art algorithms.\n","authors":["Puheng Li","James Zou","Linjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.15072v5.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2503.09120v1","updated":"2025-03-12T07:12:34Z","published":"2025-03-12T07:12:34Z","title":"On the Internal Representations of Graph Metanetworks","summary":"  Weight space learning is an emerging paradigm in the deep learning community.\nThe primary goal of weight space learning is to extract informative features\nfrom a set of parameters using specially designed neural networks, often\nreferred to as \\emph{metanetworks}. However, it remains unclear how these\nmetanetworks learn solely from parameters. To address this, we take the first\nstep toward understanding \\emph{representations} of metanetworks, specifically\ngraph metanetworks (GMNs), which achieve state-of-the-art results in this\nfield, using centered kernel alignment (CKA). Through various experiments, we\nreveal that GMNs and general neural networks (\\textit{e.g.,} multi-layer\nperceptrons (MLPs) and convolutional neural networks (CNNs)) differ in terms of\ntheir representation space.\n","authors":["Taesun Yeom","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2503.09120v1.pdf","comment":"ICLR 2025 Workshop on Weight Space Learning"},{"id":"http://arxiv.org/abs/2503.09117v1","updated":"2025-03-12T07:08:54Z","published":"2025-03-12T07:08:54Z","title":"GRU: Mitigating the Trade-off between Unlearning and Retention for Large\n  Language Models","summary":"  Large language model (LLM) unlearning has demonstrated its essential role in\nremoving privacy and copyright-related responses, crucial for their legal and\nsafe applications. However, the pursuit of complete unlearning often comes with\nsubstantial costs due to its compromises in their general functionality,\nleading to a notorious trade-off between unlearning and retention. In examining\nthe update process for unlearning dynamically, we find gradients hold essential\ninformation for revealing this trade-off. In particular, we look at the varying\nrelationship between retention performance and directional disparities between\ngradients during unlearning. It motivates the sculpting of an update mechanism\nderived from gradients from two sources, i.e., harmful for retention and useful\nfor unlearning. Accordingly, we propose Gradient Rectified Unlearning (GRU), an\nenhanced unlearning framework controlling the updating gradients in a\ngeometry-focused and optimization-driven manner such that their side impacts on\nother, unrelated responses can be minimized. Specifically, GRU derives a\nclosed-form solution to project the unlearning gradient onto the orthogonal\nspace of that gradient harmful for retention, ensuring minimal deviation from\nits original direction under the condition that overall performance is\nretained. Comprehensive experiments are conducted to demonstrate that GRU, as a\ngeneral framework, is straightforward to implement and efficiently enhances a\nrange of baseline methods through its adaptable and compatible characteristics.\nAdditionally, experimental results show its broad effectiveness across a\ndiverse set of benchmarks for LLM unlearning.\n","authors":["Yue Wang","Qizhou Wang","Feng Liu","Wei Huang","Yali Du","Xiaojiang Du","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2503.09117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09116v1","updated":"2025-03-12T07:05:30Z","published":"2025-03-12T07:05:30Z","title":"Drift-Aware Federated Learning: A Causal Perspective","summary":"  Federated learning (FL) facilitates collaborative model training among\nmultiple clients while preserving data privacy, often resulting in enhanced\nperformance compared to models trained by individual clients. However, factors\nsuch as communication frequency and data distribution can contribute to feature\ndrift, hindering the attainment of optimal training performance. This paper\nexamine the relationship between model update drift and global as well as local\noptimizer from causal perspective. The influence of the global optimizer on\nfeature drift primarily arises from the participation frequency of certain\nclients in server updates, whereas the effect of the local optimizer is\ntypically associated with imbalanced data distributions.To mitigate this drift,\nwe propose a novel framework termed Causal drift-Aware Federated lEarning\n(CAFE). CAFE exploits the causal relationship between feature-invariant\ncomponents and classification outcomes to independently calibrate local client\nsample features and classifiers during the training phase. In the inference\nphase, it eliminated the drifts in the global model that favor frequently\ncommunicating clients.Experimental results demonstrate that CAFE's integration\nof feature calibration, parameter calibration, and historical information\neffectively reduces both drift towards majority classes and tendencies toward\nfrequently communicating nodes.\n","authors":["Yunjie Fang","Sheng Wu","Tao Yang","Xiaofeng Wu","Bo Hu"],"pdf_url":"https://arxiv.org/pdf/2503.09116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00111v4","updated":"2025-03-12T07:04:21Z","published":"2023-11-30T18:35:29Z","title":"Multimodal Foundation Models for Material Property Prediction and\n  Discovery","summary":"  Artificial intelligence is transforming computational materials science,\nimproving the prediction of material properties, and accelerating the discovery\nof novel materials. Recently, publicly available material data repositories\nhave grown rapidly. This growth encompasses not only more materials but also a\ngreater variety and quantity of their associated properties. Existing machine\nlearning efforts in materials science focus primarily on single-modality tasks,\ni.e. relationships between materials and a single physical property, thus not\ntaking advantage of the rich and multimodal set of material properties. Here,\nwe introduce Multimodal Learning for Materials (MultiMat), which enables\nself-supervised multi-modality training of foundation models for materials. We\ndemonstrate our framework's potential using data from the Materials Project\ndatabase on multiple axes: (i) MultiMat achieves state-of-the-art performance\nfor challenging material property prediction tasks; (ii) MultiMat enables novel\nand accurate material discovery via latent space similarity, enabling screening\nfor stable materials with desired properties; and (iii) MultiMat encodes\ninterpretable emergent features that may provide novel scientific insights.\n","authors":["Viggo Moro","Charlotte Loh","Rumen Dangovski","Ali Ghorashi","Andrew Ma","Zhuo Chen","Samuel Kim","Peter Y. Lu","Thomas Christensen","Marin Soljačić"],"pdf_url":"https://arxiv.org/pdf/2312.00111v4.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.09114v1","updated":"2025-03-12T07:01:34Z","published":"2025-03-12T07:01:34Z","title":"Sometimes Painful but Certainly Promising: Feasibility and Trade-offs of\n  Language Model Inference at the Edge","summary":"  The rapid rise of Language Models (LMs) has expanded the capabilities of\nnatural language processing, powering applications from text generation to\ncomplex decision-making. While state-of-the-art LMs often boast hundreds of\nbillions of parameters and are primarily deployed in data centers, recent\ntrends show a growing focus on compact models-typically under 10 billion\nparameters-enabled by techniques such as quantization and other model\ncompression techniques. This shift paves the way for LMs on edge devices,\noffering potential benefits such as enhanced privacy, reduced latency, and\nimproved data sovereignty. However, the inherent complexity of even these\nsmaller models, combined with the limited computing resources of edge hardware,\nraises critical questions about the practical trade-offs in executing LM\ninference outside the cloud. To address these challenges, we present a\ncomprehensive evaluation of generative LM inference on representative CPU-based\nand GPU-accelerated edge devices. Our study measures key performance\nindicators-including memory usage, inference speed, and energy\nconsumption-across various device configurations. Additionally, we examine\nthroughput-energy trade-offs, cost considerations, and usability, alongside an\nassessment of qualitative model performance. While quantization helps mitigate\nmemory overhead, it does not fully eliminate resource bottlenecks, especially\nfor larger models. Our findings quantify the memory and energy constraints that\nmust be considered for practical real-world deployments, offering concrete\ninsights into the trade-offs between model size, inference performance, and\nefficiency. The exploration of LMs at the edge is still in its early stages. We\nhope this study provides a foundation for future research, guiding the\nrefinement of models, the enhancement of inference efficiency, and the\nadvancement of edge-centric AI systems.\n","authors":["Maximilian Abstreiter","Sasu Tarkoma","Roberto Morabito"],"pdf_url":"https://arxiv.org/pdf/2503.09114v1.pdf","comment":"This paper is currently under review for publication in an ACM\n  journal. If accepted, the copyright will be transferred to ACM"},{"id":"http://arxiv.org/abs/2503.09113v1","updated":"2025-03-12T07:01:27Z","published":"2025-03-12T07:01:27Z","title":"Constraint-Guided Learning of Data-driven Health Indicator Models: An\n  Application on the Pronostia Bearing Dataset","summary":"  This paper presents a constraint-guided deep learning framework for\ndeveloping physically consistent health indicators in bearing prognostics and\nhealth management. Conventional data-driven methods often lack physical\nplausibility, while physics-based models are limited by incomplete system\nknowledge. To address this, we integrate domain knowledge into deep learning\nusing constraints to enforce monotonicity, bound output values between 1 and 0\n(representing healthy to failed states), and ensure consistency between signal\nenergy trends and health indicator estimates. This eliminates the need for\ncomplex loss term balancing. We implement constraint-guided gradient descent\nwithin an autoencoder architecture, creating a constrained autoencoder.\nHowever, the framework is adaptable to other architectures. Using\ntime-frequency representations of accelerometer signals from the Pronostia\ndataset, our constrained model generates smoother, more reliable degradation\nprofiles compared to conventional methods, aligning with expected physical\nbehavior. Performance is assessed using three metrics: trendability,\nrobustness, and consistency. Compared to a conventional baseline, the\nconstrained model improves all three. Another baseline, incorporating\nmonotonicity via a soft-ranking loss function, outperforms in trendability but\nfalls short in robustness and consistency. An ablation study confirms that the\nmonotonicity constraint enhances trendability, the boundary constraint ensures\nconsistency, and the energy-health consistency constraint improves robustness.\nThese findings highlight the effectiveness of constraint-guided deep learning\nin producing reliable, physically meaningful health indicators, offering a\npromising direction for future prognostic applications.\n","authors":["Yonas Tefera","Quinten Van Baelen","Maarten Meire","Stijn Luca","Peter Karsmakers"],"pdf_url":"https://arxiv.org/pdf/2503.09113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14997v4","updated":"2025-03-12T06:59:50Z","published":"2022-11-28T01:51:16Z","title":"A Comprehensive Survey on Enterprise Financial Risk Analysis from Big\n  Data Perspective","summary":"  Enterprise financial risk analysis aims at predicting the future financial\nrisk of enterprises. Due to its wide and significant application, enterprise\nfinancial risk analysis has always been the core research topic in the fields\nof Finance and Management. Based on advanced computer science and artificial\nintelligence technologies, enterprise risk analysis research is experiencing\nrapid developments and making significant progress. Therefore, it is both\nnecessary and challenging to comprehensively review the relevant studies.\nAlthough there are already some valuable and impressive surveys on enterprise\nrisk analysis from the perspective of Finance and Management, these surveys\nintroduce approaches in a relatively isolated way and lack recent advances in\nenterprise financial risk analysis. In contrast, this paper attempts to provide\na systematic literature survey of enterprise risk analysis approaches from Big\nData perspective, which reviews more than 250 representative articles in the\npast almost 50 years (from 1968 to 2023). To the best of our knowledge, this is\nthe first and only survey work on enterprise financial risk from Big Data\nperspective. Specifically, this survey connects and systematizes the existing\nenterprise financial risk studies, i.e. to summarize and interpret the\nproblems, methods, and spotlights in a comprehensive way. In particular, we\nfirst introduce the issues of enterprise financial risks in terms of their\ntypes,granularity, intelligence, and evaluation metrics, and summarize the\ncorresponding representative works. Then, we compare the analysis methods used\nto learn enterprise financial risk, and finally summarize the spotlights of the\nmost representative works. Our goal is to clarify current cutting-edge research\nand its possible future directions to model enterprise risk, aiming to fully\nunderstand the mechanisms of enterprise risk generation and contagion.\n","authors":["Huaming Du","Xingyan Chen","Yu Zhao","Qing Li","Fuzhen Zhuang","Fuji Ren","Gang Kou"],"pdf_url":"https://arxiv.org/pdf/2211.14997v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09101v1","updated":"2025-03-12T06:37:43Z","published":"2025-03-12T06:37:43Z","title":"The Shape of Attraction in UMAP: Exploring the Embedding Forces in\n  Dimensionality Reduction","summary":"  Uniform manifold approximation and projection (UMAP) is among the most\npopular neighbor embedding methods. The method relies on attractive and\nrepulsive forces among high-dimensional data points to obtain a low-dimensional\nembedding. In this paper, we analyze the forces to reveal their effects on\ncluster formations and visualization. Repulsion emphasizes differences,\ncontrolling cluster boundaries and inter-cluster distance. Attraction is more\nsubtle, as attractive tension between points can manifest simultaneously as\nattraction and repulsion in the lower-dimensional mapping. This explains the\nneed for learning rate annealing and motivates the different treatments between\nattractive and repulsive terms. Moreover, by modifying attraction, we improve\nthe consistency of cluster formation under random initialization. Overall, our\nanalysis makes UMAP and similar embedding methods more interpretable, more\nrobust, and more accurate.\n","authors":["Mohammad Tariqul Islam","Jason W. Fleischer"],"pdf_url":"https://arxiv.org/pdf/2503.09101v1.pdf","comment":"9 page + appendix"},{"id":"http://arxiv.org/abs/2410.14634v3","updated":"2025-03-12T06:28:50Z","published":"2024-10-18T17:35:33Z","title":"Parallel Backpropagation for Inverse of a Convolution with Application\n  to Normalizing Flows","summary":"  The inverse of an invertible convolution is an important operation that comes\nup in Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse of Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use the Inverse of Convolutions in the forward (image to latent\nvector) pass of the Normalizing flow. Since the sampling pass is the inverse of\nthe forward pass, it will use convolutions only, resulting in efficient\nsampling times. We use our parallel backpropagation algorithm to optimize the\ninverse of the convolution layer, resulting in fast training times. We\nimplement this approach in various Normalizing Flow backbones, resulting in our\nInverse-Flow models. We benchmark Inverse-Flow on standard datasets and show\nsignificantly improved sampling times with similar bits per dimension compared\nto previous models.\n","authors":["Sandeep Nagar","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2410.14634v3.pdf","comment":"28th International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2025"},{"id":"http://arxiv.org/abs/2503.09097v1","updated":"2025-03-12T06:24:35Z","published":"2025-03-12T06:24:35Z","title":"Self-Consistent Equation-guided Neural Networks for Censored\n  Time-to-Event Data","summary":"  In survival analysis, estimating the conditional survival function given\npredictors is often of interest. There is a growing trend in the development of\ndeep learning methods for analyzing censored time-to-event data, especially\nwhen dealing with high-dimensional predictors that are complexly interrelated.\nMany existing deep learning approaches for estimating the conditional survival\nfunctions extend the Cox regression models by replacing the linear function of\npredictor effects by a shallow feed-forward neural network while maintaining\nthe proportional hazards assumption. Their implementation can be\ncomputationally intensive due to the use of the full dataset at each iteration\nbecause the use of batch data may distort the at-risk set of the partial\nlikelihood function. To overcome these limitations, we propose a novel deep\nlearning approach to non-parametric estimation of the conditional survival\nfunctions using the generative adversarial networks leveraging self-consistent\nequations. The proposed method is model-free and does not require any\nparametric assumptions on the structure of the conditional survival function.\nWe establish the convergence rate of our proposed estimator of the conditional\nsurvival function. In addition, we evaluate the performance of the proposed\nmethod through simulation studies and demonstrate its application on a\nreal-world dataset.\n","authors":["Sehwan Kim","Rui Wang","Wenbin Lu"],"pdf_url":"https://arxiv.org/pdf/2503.09097v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07964v3","updated":"2025-03-12T06:12:01Z","published":"2025-01-14T09:35:49Z","title":"Derivation of Output Correlation Inferences for Multi-Output (aka\n  Multi-Task) Gaussian Process","summary":"  Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients.\n","authors":["Shuhei Watanabe"],"pdf_url":"https://arxiv.org/pdf/2501.07964v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10182v2","updated":"2025-03-12T06:03:20Z","published":"2024-10-14T06:08:26Z","title":"Hamiltonian Neural Networks for Robust Out-of-Time Credit Scoring","summary":"  This paper presents a novel credit scoring approach using neural networks to\naddress class imbalance and out-of-time prediction challenges. We develop a\nspecific optimizer and loss function inspired by Hamiltonian mechanics that\nbetter captures credit risk dynamics. Testing on the Freddie Mac Single-Family\nLoan-Level Dataset shows our model achieves superior discriminative power (AUC)\nin out-of-time scenarios compared to conventional methods. The approach has\nconsistent performance between in-sample and future test sets, maintaining\nreliability across time periods. This interdisciplinary method spans physical\nsystems theory and financial risk management, offering practical advantages for\nlong-term model stability.\n","authors":["Javier Marín"],"pdf_url":"https://arxiv.org/pdf/2410.10182v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08301v2","updated":"2025-03-12T06:00:27Z","published":"2025-03-11T11:13:11Z","title":"Large Language Model as Meta-Surrogate for Data-Driven Many-Task\n  Optimization: A Proof-of-Principle Study","summary":"  In many-task optimization scenarios, surrogate models are valuable for\nmitigating the computational burden of repeated fitness evaluations across\ntasks. This study proposes a novel meta-surrogate framework to assist many-task\noptimization, by leveraging the knowledge transfer strengths and emergent\ncapabilities of large language models (LLMs). We formulate a unified framework\nfor many-task fitness prediction, by defining a universal model with metadata\nto fit a group of problems. Fitness prediction is performed on metadata and\ndecision variables, enabling efficient knowledge sharing across tasks and\nadaptability to new tasks. The LLM-based meta-surrogate treats fitness\nprediction as conditional probability estimation, employing a unified token\nsequence representation for task metadata, inputs, and outputs. This approach\nfacilitates efficient inter-task knowledge sharing through shared token\nembeddings and captures complex task dependencies via multi-task model\ntraining. Experimental results demonstrate the model's emergent generalization\nability, including zero-shot performance on problems with unseen dimensions.\nWhen integrated into evolutionary transfer optimization (ETO), our framework\nsupports dual-level knowledge transfer -- at both the surrogate and individual\nlevels -- enhancing optimization efficiency and robustness. This work\nestablishes a novel foundation for applying LLMs in surrogate modeling,\noffering a versatile solution for many-task optimization.\n","authors":["Xian-Rong Zhang","Yue-Jiao Gong","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08301v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/1810.01683v2","updated":"2025-03-12T05:59:48Z","published":"2018-10-03T10:55:08Z","title":"Safe RuleFit: Learning Optimal Sparse Rule Model by Meta Safe Screening","summary":"  We consider the problem of learning a sparse rule model, a prediction model\nin the form of a sparse linear combination of rules, where a rule is an\nindicator function defined over a hyper-rectangle in the input space. Since the\nnumber of all possible such rules is extremely large, it has been\ncomputationally intractable to select the optimal set of active rules. In this\npaper, to solve this difficulty for learning the optimal sparse rule model, we\npropose Safe RuleFit (SRF). Our basic idea is to develop meta safe screening\n(mSS), which is a non-trivial extension of well-known safe screening (SS)\ntechniques. While SS is used for screening out one feature, mSS can be used for\nscreening out multiple features by exploiting the inclusion-relations of\nhyper-rectangles in the input space. SRF provides a general framework for\nfitting sparse rule models for regression and classification, and it can be\nextended to handle more general sparse regularizations such as group\nregularization. We demonstrate the advantages of SRF through intensive\nnumerical experiments.\n","authors":["Hiroki Kato","Hiroyuki Hanada","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/1810.01683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09085v1","updated":"2025-03-12T05:36:12Z","published":"2025-03-12T05:36:12Z","title":"Differentiable Folding for Nearest Neighbor Model Optimization","summary":"  The Nearest Neighbor model is the $\\textit{de facto}$ thermodynamic model of\nRNA secondary structure formation and is a cornerstone of RNA structure\nprediction and sequence design. The current functional form (Turner 2004)\ncontains $\\approx13,000$ underlying thermodynamic parameters, and fitting these\nto both experimental and structural data is computationally challenging. Here,\nwe leverage recent advances in $\\textit{differentiable folding}$, a method for\ndirectly computing gradients of the RNA folding algorithms, to devise an\nefficient, scalable, and flexible means of parameter optimization that uses\nknown RNA structures and thermodynamic experiments. Our method yields a\nsignificantly improved parameter set that outperforms existing baselines on all\nmetrics, including an increase in the average predicted probability of\nground-truth sequence-structure pairs for a single RNA family by over 23 orders\nof magnitude. Our framework provides a path towards drastically improved RNA\nmodels, enabling the flexible incorporation of new experimental data,\ndefinition of novel loss terms, large training sets, and even treatment as a\nmodule in larger deep learning pipelines. We make available a new database,\nRNAometer, with experimentally-determined stabilities for small RNA model\nsystems.\n","authors":["Ryan K. Krueger","Sharon Aviran","David H. Mathews","Jeffrey Zuber","Max Ward"],"pdf_url":"https://arxiv.org/pdf/2503.09085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13981v2","updated":"2025-03-12T05:09:21Z","published":"2024-10-17T19:18:28Z","title":"On the Learn-to-Optimize Capabilities of Transformers in In-Context\n  Sparse Recovery","summary":"  An intriguing property of the Transformer is its ability to perform\nin-context learning (ICL), where the Transformer can solve different inference\ntasks without parameter updating based on the contextual information provided\nby the corresponding input-output demonstration pairs. It has been\ntheoretically proved that ICL is enabled by the capability of Transformers to\nperform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al.,\n2024). This work takes a step further and shows that Transformers can perform\nlearning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse\nrecovery (formulated as LASSO) tasks, we show that a K-layer Transformer can\nperform an L2O algorithm with a provable convergence rate linear in K. This\nprovides a new perspective explaining the superior ICL capability of\nTransformers, even with only a few layers, which cannot be achieved by the\nstandard gradient-descent algorithms. Moreover, unlike the conventional L2O\nalgorithms that require the measurement matrix involved in training to match\nthat in testing, the trained Transformer is able to solve sparse recovery\nproblems generated with different measurement matrices. Besides, Transformers\nas an L2O algorithm can leverage structural information embedded in the\ntraining tasks to accelerate its convergence during ICL, and generalize across\ndifferent lengths of demonstration pairs, where conventional L2O algorithms\ntypically struggle or fail. Such theoretical findings are supported by our\nexperimental results.\n","authors":["Renpu Liu","Ruida Zhou","Cong Shen","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13981v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09069v1","updated":"2025-03-12T05:07:07Z","published":"2025-03-12T05:07:07Z","title":"Theoretical Guarantees for High Order Trajectory Refinement in\n  Generative Flows","summary":"  Flow matching has emerged as a powerful framework for generative modeling,\noffering computational advantages over diffusion models by leveraging\ndeterministic Ordinary Differential Equations (ODEs) instead of stochastic\ndynamics. While prior work established the worst case optimality of standard\nflow matching under Wasserstein distances, the theoretical guarantees for\nhigher-order flow matching - which incorporates acceleration terms to refine\nsample trajectories - remain unexplored. In this paper, we bridge this gap by\nproving that higher-order flow matching preserves worst case optimality as a\ndistribution estimator. We derive upper bounds on the estimation error for\nsecond-order flow matching, demonstrating that the convergence rates depend\npolynomially on the smoothness of the target distribution (quantified via Besov\nspaces) and key parameters of the ODE dynamics. Our analysis employs neural\nnetwork approximations with carefully controlled depth, width, and sparsity to\nbound acceleration errors across both small and large time intervals,\nultimately unifying these results into a general worst case optimal bound for\nall time steps.\n","authors":["Chengyue Gong","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song","Yu Tian"],"pdf_url":"https://arxiv.org/pdf/2503.09069v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2410.11261"},{"id":"http://arxiv.org/abs/2503.09068v1","updated":"2025-03-12T05:05:58Z","published":"2025-03-12T05:05:58Z","title":"Probing Network Decisions: Capturing Uncertainties and Unveiling\n  Vulnerabilities Without Label Information","summary":"  To improve trust and transparency, it is crucial to be able to interpret the\ndecisions of Deep Neural classifiers (DNNs). Instance-level examinations, such\nas attribution techniques, are commonly employed to interpret the model\ndecisions. However, when interpreting misclassified decisions, human\nintervention may be required. Analyzing the attribu tions across each class\nwithin one instance can be particularly labor intensive and influenced by the\nbias of the human interpreter. In this paper, we present a novel framework to\nuncover the weakness of the classifier via counterfactual examples. A prober is\nintroduced to learn the correctness of the classifier's decision in terms of\nbinary code-hit or miss. It enables the creation of the counterfactual example\nconcerning the prober's decision. We test the performance of our prober's\nmisclassification detection and verify its effectiveness on the image\nclassification benchmark datasets. Furthermore, by generating counterfactuals\nthat penetrate the prober, we demonstrate that our framework effectively\nidentifies vulnerabilities in the target classifier without relying on label\ninformation on the MNIST dataset.\n","authors":["Youngju Joung","Sehyun Lee","Jaesik Choi"],"pdf_url":"https://arxiv.org/pdf/2503.09068v1.pdf","comment":"ICPRAI 2024"},{"id":"http://arxiv.org/abs/2503.07565v3","updated":"2025-03-12T05:00:02Z","published":"2025-03-10T17:37:39Z","title":"Inductive Moment Matching","summary":"  Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.\n","authors":["Linqi Zhou","Stefano Ermon","Jiaming Song"],"pdf_url":"https://arxiv.org/pdf/2503.07565v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09066v1","updated":"2025-03-12T04:59:22Z","published":"2025-03-12T04:59:22Z","title":"Probing Latent Subspaces in LLM for AI Security: Identifying and\n  Manipulating Adversarial States","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they remain vulnerable to adversarial manipulations such as\njailbreaking via prompt injection attacks. These attacks bypass safety\nmechanisms to generate restricted or harmful content. In this study, we\ninvestigated the underlying latent subspaces of safe and jailbroken states by\nextracting hidden activations from a LLM. Inspired by attractor dynamics in\nneuroscience, we hypothesized that LLM activations settle into semi stable\nstates that can be identified and perturbed to induce state transitions. Using\ndimensionality reduction techniques, we projected activations from safe and\njailbroken responses to reveal latent subspaces in lower dimensional spaces. We\nthen derived a perturbation vector that when applied to safe representations,\nshifted the model towards a jailbreak state. Our results demonstrate that this\ncausal intervention results in statistically significant jailbreak responses in\na subset of prompts. Next, we probed how these perturbations propagate through\nthe model's layers, testing whether the induced state change remains localized\nor cascades throughout the network. Our findings indicate that targeted\nperturbations induced distinct shifts in activations and model responses. Our\napproach paves the way for potential proactive defenses, shifting from\ntraditional guardrail based methods to preemptive, model agnostic techniques\nthat neutralize adversarial states at the representation level.\n","authors":["Xin Wei Chia","Jonathan Pan"],"pdf_url":"https://arxiv.org/pdf/2503.09066v1.pdf","comment":"4 figures"},{"id":"http://arxiv.org/abs/2402.01900v3","updated":"2025-03-12T04:52:57Z","published":"2024-02-02T20:59:29Z","title":"Distributional Off-policy Evaluation with Bellman Residual Minimization","summary":"  We study distributional off-policy evaluation (OPE), of which the goal is to\nlearn the distribution of the return for a target policy using offline data\ngenerated by a different policy. The theoretical foundation of many existing\nwork relies on the supremum-extended statistical distances such as\nsupremum-Wasserstein distance, which are hard to estimate. In contrast, we\nstudy the more manageable expectation-extended statistical distances and\nprovide a novel theoretical justification on their validity for learning the\nreturn distribution. Based on this attractive property, we propose a new method\ncalled Energy Bellman Residual Minimizer (EBRM) for distributional OPE. We\nprovide corresponding in-depth theoretical analyses. We establish a\nfinite-sample error bound for the EBRM estimator under the realizability\nassumption. Furthermore, we introduce a variant of our method based on a\nmulti-step extension which improves the error bound for non-realizable\nsettings. Notably, unlike prior distributional OPE methods, the theoretical\nguarantees of our method do not require the completeness assumption.\n","authors":["Sungee Hong","Zhengling Qi","Raymond K. W. Wong"],"pdf_url":"https://arxiv.org/pdf/2402.01900v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09058v1","updated":"2025-03-12T04:46:53Z","published":"2025-03-12T04:46:53Z","title":"Implicit Contrastive Representation Learning with Guided Stop-gradient","summary":"  In self-supervised representation learning, Siamese networks are a natural\narchitecture for learning transformation-invariance by bringing representations\nof positive pairs closer together. But it is prone to collapse into a\ndegenerate solution. To address the issue, in contrastive learning, a\ncontrastive loss is used to prevent collapse by moving representations of\nnegative pairs away from each other. But it is known that algorithms with\nnegative sampling are not robust to a reduction in the number of negative\nsamples. So, on the other hand, there are algorithms that do not use negative\npairs. Many positive-only algorithms adopt asymmetric network architecture\nconsisting of source and target encoders as a key factor in coping with\ncollapse. By exploiting the asymmetric architecture, we introduce a methodology\nto implicitly incorporate the idea of contrastive learning. As its\nimplementation, we present a novel method guided stop-gradient. We apply our\nmethod to benchmark algorithms SimSiam and BYOL and show that our method\nstabilizes training and boosts performance. We also show that the algorithms\nwith our method work well with small batch sizes and do not collapse even when\nthere is no predictor. The code is available at\nhttps://github.com/bych-lee/gsg.\n","authors":["Byeongchan Lee","Sehyun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.09058v1.pdf","comment":"Neurips 2023"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.18914v2","updated":"2025-03-12T17:59:18Z","published":"2024-12-25T14:14:31Z","title":"PRISM: Efficient Long-Range Reasoning With Short-Context LLMs","summary":"  Long-range tasks demand reasoning over long inputs. Current solutions require\nlarge compute budgets, training data, model weight access, or complex\ntask-specific designs. We introduce PRISM, which processes information as a\nstream of chunks while maintaining a structured in-context memory specified\nwith a typed hierarchical schema. PRISM outperforms baselines on diverse tasks\nwhile using at least 4x shorter contexts than long-context models. This\napproach is token-efficient, producing concise outputs and efficiently\nleveraging key-value (KV) caches to reduce costs by up to 54% compared to\nalternative short-context methods. PRISM scales down to tiny chunks (<500\ntokens) without increasing encoding costs or sacrificing quality, and\ngeneralizes to new tasks with minimal effort by automatically generating\nschemas from task descriptions.\n","authors":["Dulhan Jayalath","James Bradley Wendt","Nicholas Monath","Sandeep Tata","Beliz Gunel"],"pdf_url":"https://arxiv.org/pdf/2412.18914v2.pdf","comment":"28 pages, 7 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.09598v1","updated":"2025-03-12T17:59:18Z","published":"2025-03-12T17:59:18Z","title":"How to Protect Yourself from 5G Radiation? Investigating LLM Responses\n  to Implicit Misinformation","summary":"  As Large Language Models (LLMs) are widely deployed in diverse scenarios, the\nextent to which they could tacitly spread misinformation emerges as a critical\nsafety concern. Current research primarily evaluates LLMs on explicit false\nstatements, overlooking how misinformation often manifests subtly as\nunchallenged premises in real-world user interactions. We curated ECHOMIST, the\nfirst comprehensive benchmark for implicit misinformation, where the\nmisinformed assumptions are embedded in a user query to LLMs. ECHOMIST is based\non rigorous selection criteria and carefully curated data from diverse sources,\nincluding real-world human-AI conversations and social media interactions. We\nalso introduce a new evaluation metric to measure whether LLMs can recognize\nand counter false information rather than amplify users' misconceptions.\nThrough an extensive empirical study on a wide range of LLMs, including GPT-4,\nClaude, and Llama, we find that current models perform alarmingly poorly on\nthis task, often failing to detect false premises and generating misleading\nexplanations. Our findings underscore the critical need for an increased focus\non implicit misinformation in LLM safety research.\n","authors":["Ruohao Guo","Wei Xu","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2503.09598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09586v1","updated":"2025-03-12T17:54:18Z","published":"2025-03-12T17:54:18Z","title":"Auspex: Building Threat Modeling Tradecraft into an Artificial\n  Intelligence-based Copilot","summary":"  We present Auspex - a threat modeling system built using a specialized\ncollection of generative artificial intelligence-based methods that capture\nthreat modeling tradecraft. This new approach, called tradecraft prompting,\ncenters on encoding the on-the-ground knowledge of threat modelers within the\nprompts that drive a generative AI-based threat modeling system. Auspex employs\ntradecraft prompts in two processing stages. The first stage centers on\ningesting and processing system architecture information using prompts that\nencode threat modeling tradecraft knowledge pertaining to system decomposition\nand description. The second stage centers on chaining the resulting system\nanalysis through a collection of prompts that encode tradecraft knowledge on\nthreat identification, classification, and mitigation. The two-stage process\nyields a threat matrix for a system that specifies threat scenarios, threat\ntypes, information security categorizations and potential mitigations. Auspex\nproduces formalized threat model output in minutes, relative to the weeks or\nmonths a manual process takes. More broadly, the focus on bespoke tradecraft\nprompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a\nlightweight, flexible, modular, and extensible foundational system capable of\naddressing the complexity, resource, and standardization limitations of both\nexisting manual and automated threat modeling processes. In this connection, we\nestablish the baseline value of Auspex to threat modelers through an evaluation\nprocedure based on feedback collected from cybersecurity subject matter experts\nmeasuring the quality and utility of threat models generated by Auspex on real\nbanking systems. We conclude with a discussion of system performance and plans\nfor enhancements to Auspex.\n","authors":["Andrew Crossman","Andrew R. Plummer","Chandra Sekharudu","Deepak Warrier","Mohammad Yekrangian"],"pdf_url":"https://arxiv.org/pdf/2503.09586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09579v1","updated":"2025-03-12T17:50:42Z","published":"2025-03-12T17:50:42Z","title":"Cost-Optimal Grouped-Query Attention for Long-Context LLMs","summary":"  Building effective and efficient Transformer-based large language models\n(LLMs) has recently become a research focus, requiring maximizing model\nlanguage capabilities and minimizing training and deployment costs. Existing\nefforts have primarily described complex relationships among model performance,\nparameter size, and data size, as well as searched for the optimal compute\nallocation to train LLMs. However, they overlook the impacts of context length\nand attention head configuration (the number of query and key-value heads in\ngrouped-query attention) on training and inference. In this paper, we\nsystematically compare models with different parameter sizes, context lengths,\nand attention head configurations in terms of model performance, computational\ncost, and memory cost. Then, we extend the existing scaling methods, which are\nbased solely on parameter size and training compute, to guide the construction\nof cost-optimal LLMs during both training and inference. Our quantitative\nscaling studies show that, when processing sufficiently long sequences, a\nlarger model with fewer attention heads can achieve a lower loss while\nincurring lower computational and memory costs. Our findings provide valuable\ninsights for developing practical LLMs, especially in long-context processing\nscenarios. We will publicly release our code and data.\n","authors":["Yingfa Chen","Yutong Wu","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2503.09579v1.pdf","comment":"16 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.09573v1","updated":"2025-03-12T17:43:40Z","published":"2025-03-12T17:43:40Z","title":"Block Diffusion: Interpolating Between Autoregressive and Diffusion\n  Language Models","summary":"  Diffusion language models offer unique benefits over autoregressive models\ndue to their potential for parallelized generation and controllability, yet\nthey lag in likelihood modeling and are limited to fixed-length generation. In\nthis work, we introduce a class of block diffusion language models that\ninterpolate between discrete denoising diffusion and autoregressive models.\nBlock diffusion overcomes key limitations of both approaches by supporting\nflexible-length generation and improving inference efficiency with KV caching\nand parallel token sampling. We propose a recipe for building effective block\ndiffusion models that includes an efficient training algorithm, estimators of\ngradient variance, and data-driven noise schedules to minimize the variance.\nBlock diffusion sets a new state-of-the-art performance among diffusion models\non language modeling benchmarks and enables generation of arbitrary-length\nsequences. We provide the code, along with the model weights and blog post on\nthe project page: https://m-arriola.com/bd3lms/\n","authors":["Marianne Arriola","Aaron Gokaslan","Justin T Chiu","Zhihan Yang","Zhixuan Qi","Jiaqi Han","Subham Sekhar Sahoo","Volodymyr Kuleshov"],"pdf_url":"https://arxiv.org/pdf/2503.09573v1.pdf","comment":"ICLR 2025 Oral. We provide the code at\n  https://github.com/kuleshov-group/bd3lms"},{"id":"http://arxiv.org/abs/2503.09567v1","updated":"2025-03-12T17:35:03Z","published":"2025-03-12T17:35:03Z","title":"Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning\n  Large Language Models","summary":"  Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"test-time scaling.\" This survey seeks to\nfill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and test-time scaling, offering\ninsights into how these processes manifest in practice. (4) Finally, we\nidentify significant research gaps and highlight promising future directions,\nincluding the integration of multi-modal reasoning, efficiency improvements,\nand enhanced knowledge frameworks. By providing a structured overview, this\nsurvey aims to inspire future research and further the development of logical\nreasoning in artificial intelligence.\n","authors":["Qiguang Chen","Libo Qin","Jinhao Liu","Dengyun Peng","Jiannan Guan","Peng Wang","Mengkang Hu","Yuhang Zhou","Te Gao","Wangxiang Che"],"pdf_url":"https://arxiv.org/pdf/2503.09567v1.pdf","comment":"Paper are available at https://long-cot.github.io/"},{"id":"http://arxiv.org/abs/2503.09565v1","updated":"2025-03-12T17:33:13Z","published":"2025-03-12T17:33:13Z","title":"Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width\n  Neural Networks under $μ$P Parametrization","summary":"  Despite deep neural networks' powerful representation learning capabilities,\ntheoretical understanding of how networks can simultaneously achieve meaningful\nfeature learning and global convergence remains elusive. Existing approaches\nlike the neural tangent kernel (NTK) are limited because features stay close to\ntheir initialization in this parametrization, leaving open questions about\nfeature properties during substantial evolution. In this paper, we investigate\nthe training dynamics of infinitely wide, $L$-layer neural networks using the\ntensor program (TP) framework. Specifically, we show that, when trained with\nstochastic gradient descent (SGD) under the Maximal Update parametrization\n($\\mu$P) and mild conditions on the activation function, SGD enables these\nnetworks to learn linearly independent features that substantially deviate from\ntheir initial values. This rich feature space captures relevant data\ninformation and ensures that any convergent point of the training process is a\nglobal minimum. Our analysis leverages both the interactions among features\nacross layers and the properties of Gaussian random variables, providing new\ninsights into deep representation learning. We further validate our theoretical\nfindings through experiments on real-world datasets.\n","authors":["Zixiang Chen","Greg Yang","Qingyue Zhao","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2503.09565v1.pdf","comment":"29 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.04766v2","updated":"2025-03-12T17:30:41Z","published":"2024-12-06T04:18:49Z","title":"DAWN-FM: Data-Aware and Noise-Informed Flow Matching for Solving Inverse\n  Problems","summary":"  Inverse problems, which involve estimating parameters from incomplete or\nnoisy observations, arise in various fields such as medical imaging,\ngeophysics, and signal processing. These problems are often ill-posed,\nrequiring regularization techniques to stabilize the solution. In this work, we\nemploy Flow Matching (FM), a generative framework that integrates a\ndeterministic processes to map a simple reference distribution, such as a\nGaussian, to the target distribution. Our method DAWN-FM: Data-AWare and\nNoise-informed Flow Matching incorporates data and noise embedding, allowing\nthe model to access representations about the measured data explicitly and also\naccount for noise in the observations, making it particularly robust in\nscenarios where data is noisy or incomplete. By learning a time-dependent\nvelocity field, FM not only provides accurate solutions but also enables\nuncertainty quantification by generating multiple plausible outcomes. Unlike\npre-trained diffusion models, which may struggle in highly ill-posed settings,\nour approach is trained specifically for each inverse problem and adapts to\nvarying noise levels. We validate the effectiveness and robustness of our\nmethod through extensive numerical experiments on tasks such as image\ndeblurring and tomography.\n","authors":["Shadab Ahamed","Eldad Haber"],"pdf_url":"https://arxiv.org/pdf/2412.04766v2.pdf","comment":"27 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.11977v4","updated":"2025-03-12T17:10:33Z","published":"2024-10-15T18:33:42Z","title":"Generative AI Policies under the Microscope: How CS Conferences Are\n  Navigating the New Frontier in Scholarly Writing","summary":"  As the use of Generative AI (Gen-AI) in scholarly writing and peer reviews\ncontinues to rise, it is essential for the computing field to establish and\nadopt clear Gen-AI policies. This study examines the landscape of Gen-AI\npolicies across 64 major Computer Science conferences and offers\nrecommendations for promoting more effective and responsible use of Gen-AI in\nthe field.\n","authors":["Mahjabin Nahar","Sian Lee","Rebekah Guillen","Dongwon Lee"],"pdf_url":"https://arxiv.org/pdf/2410.11977v4.pdf","comment":"Accepted and to appear in Communications of the ACM (CACM) in 2025"},{"id":"http://arxiv.org/abs/2411.07223v2","updated":"2025-03-12T17:03:25Z","published":"2024-11-11T18:43:44Z","title":"Grounding Video Models to Actions through Goal Conditioned Exploration","summary":"  Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.\n","authors":["Yunhao Luo","Yilun Du"],"pdf_url":"https://arxiv.org/pdf/2411.07223v2.pdf","comment":"ICLR 2025 (Spotlight). Project page:\n  https://video-to-action.github.io/"},{"id":"http://arxiv.org/abs/2503.03774v2","updated":"2025-03-12T17:02:38Z","published":"2025-03-04T10:14:19Z","title":"Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous\n  Racing Systems","summary":"  Autonomous racing has gained significant attention as a platform for\nhigh-speed decision-making and motion control. While existing methods primarily\nfocus on trajectory planning and overtaking strategies, the role of\nsportsmanship in ensuring fair competition remains largely unexplored. In human\nracing, rules such as the one-motion rule and the enough-space rule prevent\ndangerous and unsportsmanlike behavior. However, autonomous racing systems\noften lack mechanisms to enforce these principles, potentially leading to\nunsafe maneuvers. This paper introduces a bi-level game-theoretic framework to\nintegrate sportsmanship (SPS) into versus racing. At the high level, we model\nracing intentions using a Stackelberg game, where Monte Carlo Tree Search\n(MCTS) is employed to derive optimal strategies. At the low level, vehicle\ninteractions are formulated as a Generalized Nash Equilibrium Problem (GNEP),\nensuring that all agents follow sportsmanship constraints while optimizing\ntheir trajectories. Simulation results demonstrate the effectiveness of the\nproposed approach in enforcing sportsmanship rules while maintaining\ncompetitive performance. We analyze different scenarios where attackers and\ndefenders adhere to or disregard sportsmanship rules and show how knowledge of\nthese constraints influences strategic decision-making. This work highlights\nthe importance of balancing competition and fairness in autonomous racing and\nprovides a foundation for developing ethical and safe AI-driven racing systems.\n","authors":["Zhenmin Huang","Ce Hao","Wei Zhan","Jun Ma","Masayoshi Tomizuka"],"pdf_url":"https://arxiv.org/pdf/2503.03774v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09545v1","updated":"2025-03-12T17:00:37Z","published":"2025-03-12T17:00:37Z","title":"The Value of Goal Commitment in Planning","summary":"  In this paper, we revisit the concept of goal commitment from early planners\nin the presence of current forward chaining heuristic planners. We present a\ncompilation that extends the original planning task with commit actions that\nenforce the persistence of specific goals once achieved, thereby committing to\nthem in the search sub-tree. This approach imposes a specific goal achievement\norder in parts of the search tree, potentially introducing dead-end states.\nThis can reduce search effort if the goal achievement order is correct.\nOtherwise, the search algorithm can expand nodes in the open list where goals\ndo not persist. Experimental results demonstrate that the reformulated tasks\nsuit state-of-the-art agile planners, enabling them to find better\n","authors":["Alberto Pozanco","Marianela Morales","Daniel Borrajo","Manuela Veloso"],"pdf_url":"https://arxiv.org/pdf/2503.09545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09538v1","updated":"2025-03-12T16:54:23Z","published":"2025-03-12T16:54:23Z","title":"Differentially Private Equilibrium Finding in Polymatrix Games","summary":"  We study equilibrium finding in polymatrix games under differential privacy\nconstraints. To start, we show that high accuracy and asymptotically vanishing\ndifferential privacy budget (as the number of players goes to infinity) cannot\nbe achieved simultaneously under either of the two settings: (i) We seek to\nestablish equilibrium approximation guarantees in terms of Euclidean distance\nto the equilibrium set, and (ii) the adversary has access to all communication\nchannels. Then, assuming the adversary has access to a constant number of\ncommunication channels, we develop a novel distributed algorithm that recovers\nstrategies with simultaneously vanishing Nash gap (in expected utility, also\nreferred to as exploitability and privacy budget as the number of players\nincreases.\n","authors":["Mingyang Liu","Gabriele Farina","Asuman Ozdaglar"],"pdf_url":"https://arxiv.org/pdf/2503.09538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09537v1","updated":"2025-03-12T16:53:58Z","published":"2025-03-12T16:53:58Z","title":"GenHPE: Generative Counterfactuals for 3D Human Pose Estimation with\n  Radio Frequency Signals","summary":"  Human pose estimation (HPE) detects the positions of human body joints for\nvarious applications. Compared to using cameras, HPE using radio frequency (RF)\nsignals is non-intrusive and more robust to adverse conditions, exploiting the\nsignal variations caused by human interference. However, existing studies focus\non single-domain HPE confined by domain-specific confounders, which cannot\ngeneralize to new domains and result in diminished HPE performance.\nSpecifically, the signal variations caused by different human body parts are\nentangled, containing subject-specific confounders. RF signals are also\nintertwined with environmental noise, involving environment-specific\nconfounders. In this paper, we propose GenHPE, a 3D HPE approach that generates\ncounterfactual RF signals to eliminate domain-specific confounders. GenHPE\ntrains generative models conditioned on human skeleton labels, learning how\nhuman body parts and confounders interfere with RF signals. We manipulate\nskeleton labels (i.e., removing body parts) as counterfactual conditions for\ngenerative models to synthesize counterfactual RF signals. The differences\nbetween counterfactual signals approximately eliminate domain-specific\nconfounders and regularize an encoder-decoder model to learn domain-independent\nrepresentations. Such representations help GenHPE generalize to new\nsubjects/environments for cross-domain 3D HPE. We evaluate GenHPE on three\npublic datasets from WiFi, ultra-wideband, and millimeter wave. Experimental\nresults show that GenHPE outperforms state-of-the-art methods and reduces\nestimation errors by up to 52.2mm for cross-subject HPE and 10.6mm for\ncross-environment HPE.\n","authors":["Shuokang Huang","Julie A. McCann"],"pdf_url":"https://arxiv.org/pdf/2503.09537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09535v1","updated":"2025-03-12T16:52:52Z","published":"2025-03-12T16:52:52Z","title":"Evaluating Visual Explanations of Attention Maps for Transformer-based\n  Medical Imaging","summary":"  Although Vision Transformers (ViTs) have recently demonstrated superior\nperformance in medical imaging problems, they face explainability issues\nsimilar to previous architectures such as convolutional neural networks. Recent\nresearch efforts suggest that attention maps, which are part of decision-making\nprocess of ViTs can potentially address the explainability issue by identifying\nregions influencing predictions, especially in models pretrained with\nself-supervised learning. In this work, we compare the visual explanations of\nattention maps to other commonly used methods for medical imaging problems. To\ndo so, we employ four distinct medical imaging datasets that involve the\nidentification of (1) colonic polyps, (2) breast tumors, (3) esophageal\ninflammation, and (4) bone fractures and hardware implants. Through large-scale\nexperiments on the aforementioned datasets using various supervised and\nself-supervised pretrained ViTs, we find that although attention maps show\npromise under certain conditions and generally surpass GradCAM in\nexplainability, they are outperformed by transformer-specific interpretability\nmethods. Our findings indicate that the efficacy of attention maps as a method\nof interpretability is context-dependent and may be limited as they do not\nconsistently provide the comprehensive insights required for robust medical\ndecision-making.\n","authors":["Minjae Chung","Jong Bum Won","Ganghyun Kim","Yujin Kim","Utku Ozbulak"],"pdf_url":"https://arxiv.org/pdf/2503.09535v1.pdf","comment":"Accepted for publication in MICCAI 2024 Workshop on Interpretability\n  of Machine Intelligence in Medical Image Computing (iMIMIC)"},{"id":"http://arxiv.org/abs/2503.05126v3","updated":"2025-03-12T16:43:00Z","published":"2025-03-07T04:13:02Z","title":"Multi-Task Reinforcement Learning Enables Parameter Scaling","summary":"  Multi-task reinforcement learning (MTRL) aims to endow a single agent with\nthe ability to perform well on multiple tasks. Recent works have focused on\ndeveloping novel sophisticated architectures to improve performance, often\nresulting in larger models; it is unclear, however, whether the performance\ngains are a consequence of the architecture design itself or the extra\nparameters. We argue that gains are mostly due to scale by demonstrating that\nnaively scaling up a simple MTRL baseline to match parameter counts outperforms\nthe more sophisticated architectures, and these gains benefit most from scaling\nthe critic over the actor. Additionally, we explore the training stability\nadvantages that come with task diversity, demonstrating that increasing the\nnumber of tasks can help mitigate plasticity loss. Our findings suggest that\nMTRL's simultaneous training across multiple tasks provides a natural framework\nfor beneficial parameter scaling in reinforcement learning, challenging the\nneed for complex architectural innovations.\n","authors":["Reginald McLean","Evangelos Chatzaroulas","Jordan Terry","Isaac Woungang","Nariman Farsad","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2503.05126v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09527v1","updated":"2025-03-12T16:42:26Z","published":"2025-03-12T16:42:26Z","title":"CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in\n  3D Action Role-Playing Games","summary":"  Recent advances in Vision-Language-Action models (VLAs) have expanded the\ncapabilities of embodied intelligence. However, significant challenges remain\nin real-time decision-making in complex 3D environments, which demand\nsecond-level responses, high-resolution perception, and tactical reasoning\nunder dynamic conditions. To advance the field, we introduce CombatVLA, an\nefficient VLA model optimized for combat tasks in 3D action role-playing\ngames(ARPGs). Specifically, our CombatVLA is a 3B model trained on video-action\npairs collected by an action tracker, where the data is formatted as\naction-of-thought (AoT) sequences. Thereafter, CombatVLA seamlessly integrates\ninto an action execution framework, allowing efficient inference through our\ntruncated AoT strategy. Experimental results demonstrate that CombatVLA not\nonly outperforms all existing models on the combat understanding benchmark but\nalso achieves a 50-fold acceleration in game combat. Moreover, it has a higher\ntask success rate than human players. We will open-source all resources,\nincluding the action tracker, dataset, benchmark, model weights, training code,\nand the implementation of the framework at https://combatvla.github.io/.\n","authors":["Peng Chen","Pi Bu","Yingyao Wang","Xinyi Wang","Ziming Wang","Jie Guo","Yingxiu Zhao","Qi Zhu","Jun Song","Siran Yang","Jiamang Wang","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.09527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09521v1","updated":"2025-03-12T16:38:22Z","published":"2025-03-12T16:38:22Z","title":"PairVDN - Pair-wise Decomposed Value Functions","summary":"  Extending deep Q-learning to cooperative multi-agent settings is challenging\ndue to the exponential growth of the joint action space, the non-stationary\nenvironment, and the credit assignment problem. Value decomposition allows deep\nQ-learning to be applied at the joint agent level, at the cost of reduced\nexpressivity. Building on past work in this direction, our paper proposes\nPairVDN, a novel method for decomposing the value function into a collection of\npair-wise, rather than per-agent, functions, improving expressivity at the cost\nof requiring a more complex (but still efficient) dynamic programming\nmaximisation algorithm. Our method enables the representation of value\nfunctions which cannot be expressed as a monotonic combination of per-agent\nfunctions, unlike past approaches such as VDN and QMIX. We implement a novel\nmany-agent cooperative environment, Box Jump, and demonstrate improved\nperformance over these baselines in this setting. We open-source our code and\nenvironment at https://github.com/zzbuzzard/PairVDN.\n","authors":["Zak Buzzard"],"pdf_url":"https://arxiv.org/pdf/2503.09521v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.04747v2","updated":"2025-03-12T16:37:23Z","published":"2025-01-08T10:31:16Z","title":"Discovering new robust local search algorithms with neuro-evolution","summary":"  This paper explores a novel approach aimed at overcoming existing challenges\nin the realm of local search algorithms. Our aim is to improve the decision\nprocess that takes place within a local search algorithm so as to make the best\npossible transitions in the neighborhood at each iteration. To improve this\nprocess, we propose to use a neural network that has the same input information\nas conventional local search algorithms. In this paper, which is an extension\nof the work presented at EvoCOP2024, we investigate different ways of\nrepresenting this information so as to make the algorithm as efficient as\npossible but also robust to monotonic transformations of the problem objective\nfunction. To assess the efficiency of this approach, we develop an experimental\nsetup centered around NK landscape problems, offering the flexibility to adjust\nproblem size and ruggedness. This approach offers a promising avenue for the\nemergence of new local search algorithms and the improvement of their\nproblem-solving capabilities for black-box problems. The last version of this\narticle is published in the journal SN Computer Science (Springer).\n","authors":["Mohamed Salim Amri Sakhri","Adrien Goëffon","Olivier Goudet","Frédéric Saubion","Chaïmaâ Touhami"],"pdf_url":"https://arxiv.org/pdf/2501.04747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16238v2","updated":"2025-03-12T16:31:39Z","published":"2024-12-19T13:01:21Z","title":"Algebraic Evaluation Theorems","summary":"  Majority voting (MV) is the prototypical ``wisdom of the crowd'' algorithm.\nTheorems considering when MV is optimal for group decisions date back to\nCondorcet's 1785 jury \\emph{decision} theorem. The same error independence\nassumption underlying the theorem can be used to prove a jury \\emph{evaluation}\ntheorem that does purely algebraic evaluation (AE) of juror performance based\non a batch of their decisions. Three or more binary jurors are enough to obtain\nthe only two possible statistics of their correctness on a test they took. AE\nis superior to MV in three ways. First, its empirical assumptions are looser\nand can handle jurors less than 50\\% accurate in making decisions. Second, it\nhas point-like precision in evaluating them given its assumption of error\nindependence. This precision enables a multi-accuracy approach that has higher\nlabeling accuracy than MV and comes with empirical uncertainty bounds. And,\nthird, it is self-alarming about the failure of its error independence\nassumption. Experiments using demographic data from the American Community\nSurvey confirm the practical utility of AE over MV. Two implications of the\ntheorem for AI safety are discussed - a principled way to terminate infinite\nmonitoring chains (who grades the graders?) and the super-alignment problem\n(how do we evaluate agents doing tasks we do not understand?).\n","authors":["Andrés Corrada-Emmanuel"],"pdf_url":"https://arxiv.org/pdf/2412.16238v2.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2411.01228v2","updated":"2025-03-12T16:29:28Z","published":"2024-11-02T12:32:36Z","title":"The Interaction Layer: An Exploration for Co-Designing User-LLM\n  Interactions in Parental Wellbeing Support Systems","summary":"  Parenting brings emotional and physical challenges, from balancing work,\nchildcare, and finances to coping with exhaustion and limited personal time.\nYet, one in three parents never seek support. AI systems potentially offer\nstigma-free, accessible, and affordable solutions. Yet, user adoption often\nfails due to issues with explainability and reliability. To see if these issues\ncould be solved using a co-design approach, we developed and tested NurtureBot,\na wellbeing support assistant for new parents. 32 parents co-designed the\nsystem through Asynchronous Remote Communities method, identifying the key\nchallenge as achieving a \"successful chat.\" As part of co-design, parents\nrole-played as NurtureBot, rewriting its dialogues to improve user\nunderstanding, control, and outcomes. The refined prototype, featuring an\nInteraction Layer, was evaluated by 32 initial and 46 new parents, showing\nimproved user experience and usability, with final CUQ score of 91.3/100,\ndemonstrating successful interaction patterns. Our process revealed useful\ninteraction design lessons for effective AI parenting support.\n","authors":["Sruthi Viswanathan","Seray Ibrahim","Ravi Shankar","Reuben Binns","Max Van Kleek","Petr Slovak"],"pdf_url":"https://arxiv.org/pdf/2411.01228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18798v3","updated":"2025-03-12T16:27:59Z","published":"2025-02-26T04:10:18Z","title":"ANPMI: Assessing the True Comprehension Capabilities of LLMs for\n  Multiple Choice Questions","summary":"  Multiple-choice benchmarks, consisting of various prompts and choices, are\namong the most widely used methods to assess a language model's natural\nlanguage understanding capability. Given a specific prompt, we typically\ncompute $P(Choice|Prompt)$ to evaluate how likely a language model is to\ngenerate the correct choice compared to incorrect ones. However, we observe\nthat performance measured using this approach reflects not only the model's\ncomprehension of the prompt but also its inherent biases for certain choices\nregardless of the prompt. This issue makes it challenging to accurately measure\na model's natural language understanding, as models may select the answer\nwithout fully understanding the prompt. To address this limitation, we propose\na novel metric called ANPMI, which normalizes Pointwise Mutual Information\n(PMI) by $-\\log P(Choice)$. ANPMI provides a more accurate assessment of the\nmodel's natural language understanding by ensuring that it is challenging to\nanswer a question without properly understanding the prompt.\n","authors":["Gyeongje Cho","Yeonkyoung So","Jaejin Lee"],"pdf_url":"https://arxiv.org/pdf/2502.18798v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09516v1","updated":"2025-03-12T16:26:39Z","published":"2025-03-12T16:26:39Z","title":"Search-R1: Training LLMs to Reason and Leverage Search Engines with\n  Reinforcement Learning","summary":"  Efficiently acquiring external knowledge and up-to-date information is\nessential for effective reasoning and text generation in large language models\n(LLMs). Retrieval augmentation and tool-use training approaches where a search\nengine is treated as a tool lack complex multi-turn retrieval flexibility or\nrequire large-scale supervised data. Prompting advanced LLMs with reasoning\ncapabilities during inference to use search engines is not optimal, since the\nLLM does not learn how to optimally interact with the search engine. This paper\nintroduces Search-R1, an extension of the DeepSeek-R1 model where the LLM\nlearns -- solely through reinforcement learning (RL) -- to autonomously\ngenerate (multiple) search queries during step-by-step reasoning with real-time\nretrieval. Search-R1 optimizes LLM rollouts with multi-turn search\ninteractions, leveraging retrieved token masking for stable RL training and a\nsimple outcome-based reward function. Experiments on seven question-answering\ndatasets show that Search-R1 improves performance by 26% (Qwen2.5-7B), 21%\n(Qwen2.5-3B), and 10% (LLaMA3.2-3B) over SOTA baselines. This paper further\nprovides empirical insights into RL optimization methods, LLM choices, and\nresponse length dynamics in retrieval-augmented reasoning. The code and model\ncheckpoints are available at https://github.com/PeterGriffinJin/Search-R1.\n","authors":["Bowen Jin","Hansi Zeng","Zhenrui Yue","Dong Wang","Hamed Zamani","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2503.09516v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2503.09513v1","updated":"2025-03-12T16:23:14Z","published":"2025-03-12T16:23:14Z","title":"RESTRAIN: Reinforcement Learning-Based Secure Framework for\n  Trigger-Action IoT Environment","summary":"  Internet of Things (IoT) platforms with trigger-action capability allow event\nconditions to trigger actions in IoT devices autonomously by creating a chain\nof interactions. Adversaries exploit this chain of interactions to maliciously\ninject fake event conditions into IoT hubs, triggering unauthorized actions on\ntarget IoT devices to implement remote injection attacks. Existing defense\nmechanisms focus mainly on the verification of event transactions using\nphysical event fingerprints to enforce the security policies to block unsafe\nevent transactions. These approaches are designed to provide offline defense\nagainst injection attacks. The state-of-the-art online defense mechanisms offer\nreal-time defense, but extensive reliability on the inference of attack impacts\non the IoT network limits the generalization capability of these approaches. In\nthis paper, we propose a platform-independent multi-agent online defense\nsystem, namely RESTRAIN, to counter remote injection attacks at runtime.\nRESTRAIN allows the defense agent to profile attack actions at runtime and\nleverages reinforcement learning to optimize a defense policy that complies\nwith the security requirements of the IoT network. The experimental results\nshow that the defense agent effectively takes real-time defense actions against\ncomplex and dynamic remote injection attacks and maximizes the security gain\nwith minimal computational overhead.\n","authors":["Md Morshed Alam","Lokesh Chandra Das","Sandip Roy","Sachin Shetty","Weichao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.09513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15996v2","updated":"2025-03-12T16:17:01Z","published":"2025-02-21T23:17:31Z","title":"Med-gte-hybrid: A contextual embedding transformer model for extracting\n  actionable information from clinical texts","summary":"  We introduce a novel contextual embedding model med-gte-hybrid that was\nderived from the gte-large sentence transformer to extract information from\nunstructured clinical narratives. Our model tuning strategy for med-gte-hybrid\ncombines contrastive learning and a denoising autoencoder. To evaluate the\nperformance of med-gte-hybrid, we investigate several clinical prediction tasks\nin large patient cohorts extracted from the MIMIC-IV dataset, including Chronic\nKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate\n(eGFR) prediction, and patient mortality prediction. Furthermore, we\ndemonstrate that the med-gte-hybrid model improves patient stratification,\nclustering, and text retrieval, thus outperforms current state-of-the-art\nmodels on the Massive Text Embedding Benchmark (MTEB). While some of our\nevaluations focus on CKD, our hybrid tuning of sentence transformers could be\ntransferred to other medical domains and has the potential to improve clinical\ndecision-making and personalised treatment pathways in various healthcare\napplications.\n","authors":["Aditya Kumar","Simon Rauch","Mario Cypko","Oliver Amft"],"pdf_url":"https://arxiv.org/pdf/2502.15996v2.pdf","comment":"22 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.09504v1","updated":"2025-03-12T16:13:50Z","published":"2025-03-12T16:13:50Z","title":"Double-Stage Feature-Level Clustering-Based Mixture of Experts Framework","summary":"  The Mixture-of-Experts (MoE) model has succeeded in deep learning (DL).\nHowever, its complex architecture and advantages over dense models in image\nclassification remain unclear. In previous studies, MoE performance has often\nbeen affected by noise and outliers in the input space. Some approaches\nincorporate input clustering for training MoE models, but most clustering\nalgorithms lack access to labeled data, limiting their effectiveness. This\npaper introduces the Double-stage Feature-level Clustering and\nPseudo-labeling-based Mixture of Experts (DFCP-MoE) framework, which consists\nof input feature extraction, feature-level clustering, and a computationally\nefficient pseudo-labeling strategy. This approach reduces the impact of noise\nand outliers while leveraging a small subset of labeled data to label a large\nportion of unlabeled inputs. We propose a conditional end-to-end joint training\nmethod that improves expert specialization by training the MoE model on\nwell-labeled, clustered inputs. Unlike traditional MoE and dense models, the\nDFCP-MoE framework effectively captures input space diversity, leading to\ncompetitive inference results. We validate our approach on three benchmark\ndatasets for multi-class classification tasks.\n","authors":["Bakary Badjie","José Cecílio","António Casimiro"],"pdf_url":"https://arxiv.org/pdf/2503.09504v1.pdf","comment":"14 Pages, 1 Figure, and 3 Tables"},{"id":"http://arxiv.org/abs/2503.09501v1","updated":"2025-03-12T16:05:31Z","published":"2025-03-12T16:05:31Z","title":"ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement\n  Learning","summary":"  Recent research on Reasoning of Large Language Models (LLMs) has sought to\nfurther enhance their performance by integrating meta-thinking -- enabling\nmodels to monitor, evaluate, and control their reasoning processes for more\nadaptive and effective problem-solving. However, current single-agent work\nlacks a specialized design for acquiring meta-thinking, resulting in low\nefficacy. To address this challenge, we introduce Reinforced Meta-thinking\nAgents (ReMA), a novel framework that leverages Multi-Agent Reinforcement\nLearning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think\nabout thinking. ReMA decouples the reasoning process into two hierarchical\nagents: a high-level meta-thinking agent responsible for generating strategic\noversight and plans, and a low-level reasoning agent for detailed executions.\nThrough iterative reinforcement learning with aligned objectives, these agents\nexplore and learn collaboration, leading to improved generalization and\nrobustness. Experimental results demonstrate that ReMA outperforms single-agent\nRL baselines on complex reasoning tasks, including competitive-level\nmathematical benchmarks and LLM-as-a-Judge benchmarks. Comprehensive ablation\nstudies further illustrate the evolving dynamics of each distinct agent,\nproviding valuable insights into how the meta-thinking reasoning process\nenhances the reasoning capabilities of LLMs.\n","authors":["Ziyu Wan","Yunxiang Li","Yan Song","Hanjing Wang","Linyi Yang","Mark Schmidt","Jun Wang","Weinan Zhang","Shuyue Hu","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2503.09501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09499v1","updated":"2025-03-12T16:03:03Z","published":"2025-03-12T16:03:03Z","title":"MindGYM: Enhancing Vision-Language Models via Synthetic Self-Challenging\n  Questions","summary":"  Large vision-language models (VLMs) face challenges in achieving robust,\ntransferable reasoning abilities due to reliance on labor-intensive manual\ninstruction datasets or computationally expensive self-supervised methods. To\naddress these issues, we introduce MindGYM, a framework that enhances VLMs\nthrough synthetic self-challenging questions, consisting of three stages: (1)\nSeed Single-Hop Question Synthesis, generating cognitive questions across\ntextual (e.g., logical deduction) and multimodal contexts (e.g., diagram-based\nqueries) spanning eight semantic areas like ethical analysis; (2) Challenging\nMulti-Hop Question Synthesis, combining seed questions via diverse principles\nlike bridging, visual-textual alignment, to create multi-step problems\ndemanding deeper reasoning; and (3) Thinking-Induced Curriculum Fine-Tuning, a\nstructured pipeline that progressively trains the model from scaffolded\nreasoning to standalone inference. By leveraging the model's self-synthesis\ncapability, MindGYM achieves high data efficiency (e.g., +16% gains on\nMathVision-Mini with only 400 samples), computational efficiency (reducing both\ntraining and inference costs), and robust generalization across tasks.\nExtensive evaluations on seven benchmarks demonstrate superior performance over\nstrong baselines, with notable improvements (+15.77% win rates) in reasoning\ndepth and breadth validated via GPT-based scoring. MindGYM underscores the\nviability of self-challenging for refining VLM capabilities while minimizing\nhuman intervention and resource demands. Code and data are released to advance\nmultimodal reasoning research.\n","authors":["Zhe Xu","Daoyuan Chen","Zhenqing Ling","Yaliang Li","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2503.09499v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2407.13268v2","updated":"2025-03-12T15:25:11Z","published":"2024-07-18T08:21:31Z","title":"Mixture of Experts based Multi-task Supervise Learning from Crowds","summary":"  Existing truth inference methods in crowdsourcing aim to map redundant labels\nand items to the ground truth. They treat the ground truth as hidden variables\nand use statistical or deep learning-based worker behavior models to infer the\nground truth. However, worker behavior models that rely on ground truth hidden\nvariables overlook workers' behavior at the item feature level, leading to\nimprecise characterizations and negatively impacting the quality of truth\ninference. This paper proposes a new paradigm of multi-task supervised learning\nfrom crowds, which eliminates the need for modeling of items's ground truth in\nworker behavior models. Within this paradigm, we propose a worker behavior\nmodel at the item feature level called Mixture of Experts based Multi-task\nSupervised Learning from Crowds (MMLC). Two truth inference strategies are\nproposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering\nmethods in the worker spectral space to identify the projection vector of the\noracle worker. Subsequently, the labels generated based on this vector are\nconsidered as the inferred truth. The second strategy, called MMLC-df, employs\nthe MMLC model to fill the crowdsourced data, which can enhance the\neffectiveness of existing truth inference methods. Experimental results\ndemonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df\nenhances the quality of existing truth inference methods.\n","authors":["Tao Han","Huaixuan Shi","Xinyi Ding","Xiao Ma","Huamao Gu","Yili Fang"],"pdf_url":"https://arxiv.org/pdf/2407.13268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07148v2","updated":"2025-03-12T15:02:50Z","published":"2025-03-10T10:22:13Z","title":"Hierarchical Neuro-Symbolic Decision Transformer","summary":"  We present a hierarchical neuro-symbolic control framework that couples\nclassical symbolic planning with transformer-based policies to address complex,\nlong-horizon decision-making tasks. At the high level, a symbolic planner\nconstructs an interpretable sequence of operators based on logical\npropositions, ensuring systematic adherence to global constraints and goals. At\nthe low level, each symbolic operator is translated into a sub-goal token that\nconditions a decision transformer to generate a fine-grained sequence of\nactions in uncertain, high-dimensional environments. We provide theoretical\nanalysis showing how approximation errors from both the symbolic planner and\nthe neural execution layer accumulate. Empirical evaluations in grid-worlds\nwith multiple keys, locked doors, and item-collection tasks show that our\nhierarchical approach outperforms purely end-to-end neural approach in success\nrates and policy efficiency.\n","authors":["Ali Baheri","Cecilia O. Alm"],"pdf_url":"https://arxiv.org/pdf/2503.07148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13493v4","updated":"2025-03-12T14:54:13Z","published":"2024-07-18T13:23:16Z","title":"Training Foundation Models as Data Compression: On Information, Model\n  Weights and Copyright Law","summary":"  The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights can be considered a reproduction\nor, more likely, a derivative work of a potentially protected set of works. We\ninvestigate the technical and legal challenges that emerge from this framing of\nthe copyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.\n","authors":["Giorgio Franceschelli","Claudia Cevenini","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2407.13493v4.pdf","comment":"Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law"},{"id":"http://arxiv.org/abs/2503.09447v1","updated":"2025-03-12T14:49:24Z","published":"2025-03-12T14:49:24Z","title":"Online Language Splatting","summary":"  To enable AI agents to interact seamlessly with both humans and 3D\nenvironments, they must not only perceive the 3D world accurately but also\nalign human language with 3D spatial representations. While prior work has made\nsignificant progress by integrating language features into geometrically\ndetailed 3D scene representations using 3D Gaussian Splatting (GS), these\napproaches rely on computationally intensive offline preprocessing of language\nfeatures for each input image, limiting adaptability to new environments. In\nthis work, we introduce Online Language Splatting, the first framework to\nachieve online, near real-time, open-vocabulary language mapping within a\n3DGS-SLAM system without requiring pre-generated language features. The key\nchallenge lies in efficiently fusing high-dimensional language features into 3D\nrepresentations while balancing the computation speed, memory usage, rendering\nquality and open-vocabulary capability. To this end, we innovatively design:\n(1) a high-resolution CLIP embedding module capable of generating detailed\nlanguage feature maps in 18ms per frame, (2) a two-stage online auto-encoder\nthat compresses 768-dimensional CLIP features to 15 dimensions while preserving\nopen-vocabulary capabilities, and (3) a color-language disentangled\noptimization approach to improve rendering quality. Experimental results show\nthat our online method not only surpasses the state-of-the-art offline methods\nin accuracy but also achieves more than 40x efficiency boost, demonstrating the\npotential for dynamic and interactive AI applications.\n","authors":["Saimouli Katragadda","Cho-Ying Wu","Yuliang Guo","Xinyu Huang","Guoquan Huang","Liu Ren"],"pdf_url":"https://arxiv.org/pdf/2503.09447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09446v1","updated":"2025-03-12T14:46:40Z","published":"2025-03-12T14:46:40Z","title":"Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in\n  Text-to-Image Diffusion Models","summary":"  Text-to-image (T2I) diffusion models have achieved remarkable progress in\ngenerating high-quality images but also raise people's concerns about\ngenerating harmful or misleading content. While extensive approaches have been\nproposed to erase unwanted concepts without requiring retraining from scratch,\nthey inadvertently degrade performance on normal generation tasks. In this\nwork, we propose Interpret then Deactivate (ItD), a novel framework to enable\nprecise concept removal in T2I diffusion models while preserving overall\nperformance. ItD first employs a sparse autoencoder (SAE) to interpret each\nconcept as a combination of multiple features. By permanently deactivating the\nspecific features associated with target concepts, we repurpose SAE as a\nzero-shot classifier that identifies whether the input prompt includes target\nconcepts, allowing selective concept erasure in diffusion models. Moreover, we\ndemonstrate that ItD can be easily extended to erase multiple concepts without\nrequiring further training. Comprehensive experiments across celebrity\nidentities, artistic styles, and explicit content demonstrate ItD's\neffectiveness in eliminating targeted concepts without interfering with normal\nconcept generation. Additionally, ItD is also robust against adversarial\nprompts designed to circumvent content filters. Code is available at:\nhttps://github.com/NANSirun/Interpret-then-deactivate.\n","authors":["Zhihua Tian","Sirun Nan","Ming Xu","Shengfang Zhai","Wenjie Qu","Jian Liu","Kui Ren","Ruoxi Jia","Jiaheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09446v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.09445v1","updated":"2025-03-12T14:44:52Z","published":"2025-03-12T14:44:52Z","title":"Astrea: A MOE-based Visual Understanding Model with Progressive\n  Alignment","summary":"  Vision-Language Models (VLMs) based on Mixture-of-Experts (MoE) architectures\nhave emerged as a pivotal paradigm in multimodal understanding, offering a\npowerful framework for integrating visual and linguistic information. However,\nthe increasing complexity and diversity of tasks present significant challenges\nin coordinating load balancing across heterogeneous visual experts, where\noptimizing one specialist's performance often compromises others' capabilities.\nTo address task heterogeneity and expert load imbalance, we propose Astrea, a\nnovel multi-expert collaborative VLM architecture based on progressive\npre-alignment. Astrea introduces three key innovations: 1) A heterogeneous\nexpert coordination mechanism that integrates four specialized models\n(detection, segmentation, classification, captioning) into a comprehensive\nexpert matrix covering essential visual comprehension elements; 2) A dynamic\nknowledge fusion strategy featuring progressive pre-alignment to harmonize\nexperts within the VLM latent space through contrastive learning, complemented\nby probabilistically activated stochastic residual connections to preserve\nknowledge continuity; 3) An enhanced optimization framework utilizing momentum\ncontrastive learning for long-range dependency modeling and adaptive weight\nallocators for real-time expert contribution calibration. Extensive evaluations\nacross 12 benchmark tasks spanning VQA, image captioning, and cross-modal\nretrieval demonstrate Astrea's superiority over state-of-the-art models,\nachieving an average performance gain of +4.7\\%. This study provides the first\nempirical demonstration that progressive pre-alignment strategies enable VLMs\nto overcome task heterogeneity limitations, establishing new methodological\nfoundations for developing general-purpose multimodal agents.\n","authors":["Xiaoda Yang","JunYu Lu","Hongshun Qiu","Sijing Li","Hao Li","Shengpeng Ji","Xudong Tang","Jiayang Xu","Jiaqi Duan","Ziyue Jiang","Cong Lin","Sihang Cai","Zejian Xie","Zhuoyang Song","Songxin Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04789v2","updated":"2025-03-12T14:42:18Z","published":"2025-02-28T06:46:53Z","title":"Ext2Gen: Alignment through Unified Extraction and Generation for Robust\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances LLMs by integrating external\nknowledge, but generation remains fragile due to the uncertain placement of\nrelevant chunks and retrieval-induced information overload, leading to\nhallucinations. We propose Ext2Gen, a novel extract-then-generate model that\nenhances RAG robustness by first extracting query-relevant sentences before\ngenerating answers. To optimize this model, we employ preference alignment\nthrough pairwise feedback learning, enabling the model to generate robust\nanswers regardless of variations in retrieval results. Extensive experiments\ndemonstrate that Ext2Gen effectively identifies query-relevant sentences with\nhigh precision and recall, leading to highly reliable answers. Furthermore,\ndeploying our model in a RAG environment reveals that it not only boosts the\nperformance of the base LLM but also synergizes with advanced retrieval\nstrategies like query expansion. The model is available at\nhttps://huggingface.co/DISLab/Ext2Gen-8B-R2.\n","authors":["Hwanjun Song","Jeonghwan Choi","Minseok Kim"],"pdf_url":"https://arxiv.org/pdf/2503.04789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10488v3","updated":"2025-03-12T14:34:11Z","published":"2024-12-13T15:24:11Z","title":"SVGBuilder: Component-Based Colored SVG Generation with Text-Guided\n  Autoregressive Transformers","summary":"  Scalable Vector Graphics (SVG) are essential XML-based formats for versatile\ngraphics, offering resolution independence and scalability. Unlike raster\nimages, SVGs use geometric shapes and support interactivity, animation, and\nmanipulation via CSS and JavaScript. Current SVG generation methods face\nchallenges related to high computational costs and complexity. In contrast,\nhuman designers use component-based tools for efficient SVG creation. Inspired\nby this, SVGBuilder introduces a component-based, autoregressive model for\ngenerating high-quality colored SVGs from textual input. It significantly\nreduces computational overhead and improves efficiency compared to traditional\nmethods. Our model generates SVGs up to 604 times faster than\noptimization-based approaches. To address the limitations of existing SVG\ndatasets and support our research, we introduce ColorSVG-100K, the first\nlarge-scale dataset of colored SVGs, comprising 100,000 graphics. This dataset\nfills the gap in color information for SVG generation models and enhances\ndiversity in model training. Evaluation against state-of-the-art models\ndemonstrates SVGBuilder's superior performance in practical applications,\nhighlighting its efficiency and quality in generating complex SVG graphics.\n","authors":["Zehao Chen","Rong Pan"],"pdf_url":"https://arxiv.org/pdf/2412.10488v3.pdf","comment":"Project: https://svgbuilder.github.io"},{"id":"http://arxiv.org/abs/2406.07892v2","updated":"2025-03-12T14:32:31Z","published":"2024-06-12T05:49:53Z","title":"A Finite-Sample Analysis of an Actor-Critic Algorithm for Mean-Variance\n  Optimization in a Discounted MDP","summary":"  Motivated by applications in risk-sensitive reinforcement learning, we study\nmean-variance optimization in a discounted reward Markov Decision Process\n(MDP). Specifically, we analyze a Temporal Difference (TD) learning algorithm\nwith linear function approximation (LFA) for policy evaluation. We derive\nfinite-sample bounds that hold (i) in the mean-squared sense and (ii) with high\nprobability under tail iterate averaging, both with and without regularization.\nOur bounds exhibit an exponentially decaying dependence on the initial error\nand a convergence rate of $O(1/t)$ after $t$ iterations. Moreover, for the\nregularized TD variant, our bound holds for a universal step size. Next, we\nintegrate a Simultaneous Perturbation Stochastic Approximation (SPSA)-based\nactor update with an LFA critic and establish an $O(n^{-1/4})$ convergence\nguarantee, where $n$ denotes the iterations of the SPSA-based actor-critic\nalgorithm. These results establish finite-sample theoretical guarantees for\nrisk-sensitive actor-critic methods in reinforcement learning, with a focus on\nvariance as a risk measure.\n","authors":["Tejaram Sangadi","L. A. Prashanth","Krishna Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2406.07892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09436v1","updated":"2025-03-12T14:31:50Z","published":"2025-03-12T14:31:50Z","title":"PromptMap: An Alternative Interaction Style for AI-Based Image\n  Generation","summary":"  Recent technological advances popularized the use of image generation among\nthe general public. Crafting effective prompts can, however, be difficult for\nnovice users. To tackle this challenge, we developed PromptMap, a new\ninteraction style for text-to-image AI that allows users to freely explore a\nvast collection of synthetic prompts through a map-like view with semantic\nzoom. PromptMap groups images visually by their semantic similarity, allowing\nusers to discover relevant examples. We evaluated PromptMap in a\nbetween-subject online study ($n=60$) and a qualitative within-subject study\n($n=12$). We found that PromptMap supported users in crafting prompts by\nproviding them with examples. We also demonstrated the feasibility of using\nLLMs to create vast example collections. Our work contributes a new interaction\nstyle that supports users unfamiliar with prompting in achieving a satisfactory\nimage output.\n","authors":["Krzysztof Adamkiewicz","Paweł W. Woźniak","Julia Dominiak","Andrzej Romanowski","Jakob Karolus","Stanislav Frolov"],"pdf_url":"https://arxiv.org/pdf/2503.09436v1.pdf","comment":"To be published in the proceedings of 30th International Conference\n  on Intelligent User Interfaces (IUI '25), March 24-27, 2025, Cagliari, Italy"},{"id":"http://arxiv.org/abs/2503.09433v1","updated":"2025-03-12T14:30:05Z","published":"2025-03-12T14:30:05Z","title":"CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards\n  CWE Detection","summary":"  Identifying vulnerabilities in source code is crucial, especially in critical\nsoftware components. Existing methods such as static analysis, dynamic\nanalysis, formal verification, and recently Large Language Models are widely\nused to detect security flaws. This paper introduces CASTLE (CWE Automated\nSecurity Testing and Low-Level Evaluation), a benchmarking framework for\nevaluating the vulnerability detection capabilities of different methods. We\nassess 13 static analysis tools, 10 LLMs, and 2 formal verification tools using\na hand-crafted dataset of 250 micro-benchmark programs covering 25 common CWEs.\nWe propose the CASTLE Score, a novel evaluation metric to ensure fair\ncomparison. Our results reveal key differences: ESBMC (a formal verification\ntool) minimizes false positives but struggles with vulnerabilities beyond model\nchecking, such as weak cryptography or SQL injection. Static analyzers suffer\nfrom high false positives, increasing manual validation efforts for developers.\nLLMs perform exceptionally well in the CASTLE dataset when identifying\nvulnerabilities in small code snippets. However, their accuracy declines, and\nhallucinations increase as the code size grows. These results suggest that LLMs\ncould play a pivotal role in future security solutions, particularly within\ncode completion frameworks, where they can provide real-time guidance to\nprevent vulnerabilities. The dataset is accessible at\nhttps://github.com/CASTLE-Benchmark.\n","authors":["Richard A. Dubniczky","Krisztofer Zoltán Horvát","Tamás Bisztray","Mohamed Amine Ferrag","Lucas C. Cordeiro","Norbert Tihanyi"],"pdf_url":"https://arxiv.org/pdf/2503.09433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09427v1","updated":"2025-03-12T14:26:16Z","published":"2025-03-12T14:26:16Z","title":"Multimodal Language Modeling for High-Accuracy Single Cell\n  Transcriptomics Analysis and Generation","summary":"  Pre-trained language models (PLMs) have revolutionized scientific research,\nyet their application to single-cell analysis remains limited. Text PLMs cannot\nprocess single-cell RNA sequencing data, while cell PLMs lack the ability to\nhandle free text, restricting their use in multimodal tasks. Existing efforts\nto bridge these modalities often suffer from information loss or inadequate\nsingle-modal pre-training, leading to suboptimal performances. To address these\nchallenges, we propose Single-Cell MultiModal Generative Pre-trained\nTransformer (scMMGPT), a unified PLM for joint cell and text modeling. scMMGPT\neffectively integrates the state-of-the-art cell and text PLMs, facilitating\ncross-modal knowledge sharing for improved performance. To bridge the text-cell\nmodality gap, scMMGPT leverages dedicated cross-modal projectors, and undergoes\nextensive pre-training on 27 million cells -- the largest dataset for\nmultimodal cell-text PLMs to date. This large-scale pre-training enables\nscMMGPT to excel in joint cell-text tasks, achieving an 84\\% relative\nimprovement of textual discrepancy for cell description generation, 20.5\\%\nhigher accuracy for cell type annotation, and 4\\% improvement in $k$-NN\naccuracy for text-conditioned pseudo-cell generation, outperforming baselines.\n","authors":["Yaorui Shi","Jiaqi Yang","Sihang Li","Junfeng Fang","Xiang Wang","Zhiyuan Liu","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06557v2","updated":"2025-03-12T13:59:29Z","published":"2025-01-11T14:33:57Z","title":"A Survey on Spoken Italian Datasets and Corpora","summary":"  Spoken language datasets are vital for advancing linguistic research, Natural\nLanguage Processing, and speech technology. However, resources dedicated to\nItalian, a linguistically rich and diverse Romance language, remain\nunderexplored compared to major languages like English or Mandarin. This survey\nprovides a comprehensive analysis of 66 spoken Italian datasets, highlighting\ntheir characteristics, methodologies, and applications. The datasets are\ncategorized by speech type, source and context, and demographic and linguistic\nfeatures, with a focus on their utility in fields such as Automatic Speech\nRecognition, emotion detection, and education. Challenges related to dataset\nscarcity, representativeness, and accessibility are discussed alongside\nrecommendations for enhancing dataset creation and utilization. The full\ndataset inventory is publicly accessible via GitHub and archived on Zenodo,\nserving as a valuable resource for researchers and developers. By addressing\ncurrent gaps and proposing future directions, this work aims to support the\nadvancement of Italian speech technologies and linguistic research.\n","authors":["Marco Giordano","Claudia Rinaldi"],"pdf_url":"https://arxiv.org/pdf/2501.06557v2.pdf","comment":"Published on IEEE Access Journal on Feb 2025"},{"id":"http://arxiv.org/abs/2503.09409v1","updated":"2025-03-12T13:59:26Z","published":"2025-03-12T13:59:26Z","title":"AI-based Framework for Robust Model-Based Connector Mating in Robotic\n  Wire Harness Installation","summary":"  Despite the widespread adoption of industrial robots in automotive assembly,\nwire harness installation remains a largely manual process, as it requires\nprecise and flexible manipulation. To address this challenge, we design a novel\nAI-based framework that automates cable connector mating by integrating force\ncontrol with deep visuotactile learning. Our system optimizes\nsearch-and-insertion strategies using first-order optimization over a\nmultimodal transformer architecture trained on visual, tactile, and\nproprioceptive data. Additionally, we design a novel automated data collection\nand optimization pipeline that minimizes the need for machine learning\nexpertise. The framework optimizes robot programs that run natively on standard\nindustrial controllers, permitting human experts to audit and certify them.\nExperimental validations on a center console assembly task demonstrate\nsignificant improvements in cycle times and robustness compared to conventional\nrobot programming approaches. Videos are available under\nhttps://claudius-kienle.github.io/AppMuTT.\n","authors":["Claudius Kienle","Benjamin Alt","Finn Schneider","Tobias Pertlwieser","Rainer Jäkel","Rania Rayyes"],"pdf_url":"https://arxiv.org/pdf/2503.09409v1.pdf","comment":"6 pages, 6 figures, 4 tables, submitted to the 2025 IEEE 21st\n  International Conference on Automation Science and Engineering"},{"id":"http://arxiv.org/abs/2503.09403v1","updated":"2025-03-12T13:53:57Z","published":"2025-03-12T13:53:57Z","title":"Multi-Agent Image Restoration","summary":"  Image restoration (IR) is challenging due to the complexity of real-world\ndegradations. While many specialized and all-in-one IR models have been\ndeveloped, they fail to effectively handle complex, mixed degradations. Recent\nagentic methods RestoreAgent and AgenticIR leverage intelligent, autonomous\nworkflows to alleviate this issue, yet they suffer from suboptimal results and\ninefficiency due to their resource-intensive finetunings, and ineffective\nsearches and tool execution trials for satisfactory outputs. In this paper, we\npropose MAIR, a novel Multi-Agent approach for complex IR problems. We\nintroduce a real-world degradation prior, categorizing degradations into three\ntypes: (1) scene, (2) imaging, and (3) compression, which are observed to occur\nsequentially in real world, and reverse them in the opposite order. Built upon\nthis three-stage restoration framework, MAIR emulates a team of collaborative\nhuman specialists, including a \"scheduler\" for overall planning and multiple\n\"experts\" dedicated to specific degradations. This design minimizes search\nspace and trial efforts, improving image quality while reducing inference\ncosts. In addition, a registry mechanism is introduced to enable easy\nintegration of new tools. Experiments on both synthetic and real-world datasets\nshow that proposed MAIR achieves competitive performance and improved\nefficiency over the previous agentic IR system. Code and models will be made\navailable.\n","authors":["Xu Jiang","Gehui Li","Bin Chen","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06170v2","updated":"2025-03-12T13:52:50Z","published":"2025-03-08T11:17:37Z","title":"Object-Centric World Model for Language-Guided Manipulation","summary":"  A world model is essential for an agent to predict the future and plan in\ndomains such as autonomous driving and robotics. To achieve this, recent\nadvancements have focused on video generation, which has gained significant\nattention due to the impressive success of diffusion models. However, these\nmodels require substantial computational resources. To address these\nchallenges, we propose a world model leveraging object-centric representation\nspace using slot attention, guided by language instructions. Our model\nperceives the current state as an object-centric representation and predicts\nfuture states in this representation space conditioned on natural language\ninstructions. This approach results in a more compact and computationally\nefficient model compared to diffusion-based generative alternatives.\nFurthermore, it flexibly predicts future states based on language instructions,\nand offers a significant advantage in manipulation tasks where object\nrecognition is crucial. In this paper, we demonstrate that our latent\npredictive world model surpasses generative world models in visuo-linguo-motor\ncontrol tasks, achieving superior sample and computation efficiency. We also\ninvestigate the generalization performance of the proposed method and explore\nvarious strategies for predicting actions using object-centric representations.\n","authors":["Youngjoon Jeong","Junha Chun","Soonwoo Cha","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2503.06170v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09399v1","updated":"2025-03-12T13:49:45Z","published":"2025-03-12T13:49:45Z","title":"ForAug: Recombining Foregrounds and Backgrounds to Improve Vision\n  Transformer Training with Bias Mitigation","summary":"  Transformers, particularly Vision Transformers (ViTs), have achieved\nstate-of-the-art performance in large-scale image classification. However, they\noften require large amounts of data and can exhibit biases that limit their\nrobustness and generalizability. This paper introduces ForAug, a novel data\naugmentation scheme that addresses these challenges and explicitly includes\ninductive biases, which commonly are part of the neural network architecture,\ninto the training data. ForAug is constructed by using pretrained foundation\nmodels to separate and recombine foreground objects with different backgrounds,\nenabling fine-grained control over image composition during training. It thus\nincreases the data diversity and effective number of training samples. We\ndemonstrate that training on ForNet, the application of ForAug to ImageNet,\nsignificantly improves the accuracy of ViTs and other architectures by up to\n4.5 percentage points (p.p.) on ImageNet and 7.3 p.p. on downstream tasks.\nImportantly, ForAug enables novel ways of analyzing model behavior and\nquantifying biases. Namely, we introduce metrics for background robustness,\nforeground focus, center bias, and size bias and show that training on ForNet\nsubstantially reduces these biases compared to training on ImageNet. In\nsummary, ForAug provides a valuable tool for analyzing and mitigating biases,\nenabling the development of more robust and reliable computer vision models.\nOur code and dataset are publicly available at https://github.com/tobna/ForAug.\n","authors":["Tobias Christian Nauen","Brian Moser","Federico Raue","Stanislav Frolov","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2503.09399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09396v1","updated":"2025-03-12T13:44:00Z","published":"2025-03-12T13:44:00Z","title":"Close-up-GS: Enhancing Close-Up View Synthesis in 3D Gaussian Splatting\n  with Progressive Self-Training","summary":"  3D Gaussian Splatting (3DGS) has demonstrated impressive performance in\nsynthesizing novel views after training on a given set of viewpoints. However,\nits rendering quality deteriorates when the synthesized view deviates\nsignificantly from the training views. This decline occurs due to (1) the\nmodel's difficulty in generalizing to out-of-distribution scenarios and (2)\nchallenges in interpolating fine details caused by substantial resolution\nchanges and occlusions. A notable case of this limitation is close-up view\ngeneration--producing views that are significantly closer to the object than\nthose in the training set. To tackle this issue, we propose a novel approach\nfor close-up view generation based by progressively training the 3DGS model\nwith self-generated data. Our solution is based on three key ideas. First, we\nleverage the See3D model, a recently introduced 3D-aware generative model, to\nenhance the details of rendered views. Second, we propose a strategy to\nprogressively expand the ``trust regions'' of the 3DGS model and update a set\nof reference views for See3D. Finally, we introduce a fine-tuning strategy to\ncarefully update the 3DGS model with training data generated from the above\nschemes. We further define metrics for close-up views evaluation to facilitate\nbetter research on this problem. By conducting evaluations on specifically\nselected scenarios for close-up views, our proposed approach demonstrates a\nclear advantage over competitive solutions.\n","authors":["Jiatong Xia","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2503.09396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09382v1","updated":"2025-03-12T13:28:23Z","published":"2025-03-12T13:28:23Z","title":"Towards Next-Generation Recommender Systems: A Benchmark for\n  Personalized Recommendation Assistant with LLMs","summary":"  Recommender systems (RecSys) are widely used across various modern digital\nplatforms and have garnered significant attention. Traditional recommender\nsystems usually focus only on fixed and simple recommendation scenarios, making\nit difficult to generalize to new and unseen recommendation tasks in an\ninteractive paradigm. Recently, the advancement of large language models (LLMs)\nhas revolutionized the foundational architecture of RecSys, driving their\nevolution into more intelligent and interactive personalized recommendation\nassistants. However, most existing studies rely on fixed task-specific prompt\ntemplates to generate recommendations and evaluate the performance of\npersonalized assistants, which limits the comprehensive assessments of their\ncapabilities. This is because commonly used datasets lack high-quality textual\nuser queries that reflect real-world recommendation scenarios, making them\nunsuitable for evaluating LLM-based personalized recommendation assistants. To\naddress this gap, we introduce RecBench+, a new dataset benchmark designed to\naccess LLMs' ability to handle intricate user recommendation needs in the era\nof LLMs. RecBench+ encompasses a diverse set of queries that span both hard\nconditions and soft preferences, with varying difficulty levels. We evaluated\ncommonly used LLMs on RecBench+ and uncovered below findings: 1) LLMs\ndemonstrate preliminary abilities to act as recommendation assistants, 2) LLMs\nare better at handling queries with explicitly stated conditions, while facing\nchallenges with queries that require reasoning or contain misleading\ninformation. Our dataset has been released at\nhttps://github.com/jiani-huang/RecBench.git.\n","authors":["Jiani Huang","Shijie Wang","Liang-bo Ning","Wenqi Fan","Shuaiqiang Wang","Dawei Yin","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2503.09382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09378v1","updated":"2025-03-12T13:27:29Z","published":"2025-03-12T13:27:29Z","title":"Pig behavior dataset and Spatial-temporal perception and enhancement\n  networks based on the attention mechanism for pig behavior recognition","summary":"  The recognition of pig behavior plays a crucial role in smart farming and\nwelfare assurance for pigs. Currently, in the field of pig behavior\nrecognition, the lack of publicly available behavioral datasets not only limits\nthe development of innovative algorithms but also hampers model robustness and\nalgorithm optimization.This paper proposes a dataset containing 13 pig\nbehaviors that significantly impact welfare.Based on this dataset, this paper\nproposes a spatial-temporal perception and enhancement networks based on the\nattention mechanism to model the spatiotemporal features of pig behaviors and\ntheir associated interaction areas in video data. The network is composed of a\nspatiotemporal perception network and a spatiotemporal feature enhancement\nnetwork. The spatiotemporal perception network is responsible for establishing\nconnections between the pigs and the key regions of their behaviors in the\nvideo data. The spatiotemporal feature enhancement network further strengthens\nthe important spatial features of individual pigs and captures the long-term\ndependencies of the spatiotemporal features of individual behaviors by\nremodeling these connections, thereby enhancing the model's perception of\nspatiotemporal changes in pig behaviors. Experimental results demonstrate that\non the dataset established in this paper, our proposed model achieves a MAP\nscore of 75.92%, which is an 8.17% improvement over the best-performing\ntraditional model. This study not only improces the accuracy and\ngeneralizability of individual pig behavior recognition but also provides new\ntechnological tools for modern smart farming. The dataset and related code will\nbe made publicly available alongside this paper.\n","authors":["Fangzheng Qi","Zhenjie Hou","En Lin","Xing Li","iuzhen Liang","Xinwen Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.09378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07813v2","updated":"2025-03-12T13:17:27Z","published":"2025-02-08T17:19:43Z","title":"CryptoX : Compositional Reasoning Evaluation of Large Language Models","summary":"  The compositional reasoning capacity has long been regarded as critical to\nthe generalization and intelligence emergence of large language models LLMs.\nHowever, despite numerous reasoning-related benchmarks, the compositional\nreasoning capacity of LLMs is rarely studied or quantified in the existing\nbenchmarks. In this paper, we introduce CryptoX, an evaluation framework that,\nfor the first time, combines existing benchmarks and cryptographic, to quantify\nthe compositional reasoning capacity of LLMs. Building upon CryptoX, we\nconstruct CryptoBench, which integrates these principles into several\nbenchmarks for systematic evaluation. We conduct detailed experiments on widely\nused open-source and closed-source LLMs using CryptoBench, revealing a huge gap\nbetween open-source and closed-source LLMs. We further conduct thorough\nmechanical interpretability experiments to reveal the inner mechanism of LLMs'\ncompositional reasoning, involving subproblem decomposition, subproblem\ninference, and summarizing subproblem conclusions. Through analysis based on\nCryptoBench, we highlight the value of independently studying compositional\nreasoning and emphasize the need to enhance the compositional reasoning\ncapabilities of LLMs.\n","authors":["Jiajun Shi","Chaoren Wei","Liqun Yang","Zekun Moore Wang","Chenghao Yang","Ge Zhang","Stephen Huang","Tao Peng","Jian Yang","Zhoufutu Wen"],"pdf_url":"https://arxiv.org/pdf/2502.07813v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09370v1","updated":"2025-03-12T13:16:42Z","published":"2025-03-12T13:16:42Z","title":"Revisiting Medical Image Retrieval via Knowledge Consolidation","summary":"  As artificial intelligence and digital medicine increasingly permeate\nhealthcare systems, robust governance frameworks are essential to ensure\nethical, secure, and effective implementation. In this context, medical image\nretrieval becomes a critical component of clinical data management, playing a\nvital role in decision-making and safeguarding patient information. Existing\nmethods usually learn hash functions using bottleneck features, which fail to\nproduce representative hash codes from blended embeddings. Although contrastive\nhashing has shown superior performance, current approaches often treat image\nretrieval as a classification task, using category labels to create\npositive/negative pairs. Moreover, many methods fail to address the\nout-of-distribution (OOD) issue when models encounter external OOD queries or\nadversarial attacks. In this work, we propose a novel method to consolidate\nknowledge of hierarchical features and optimisation functions. We formulate the\nknowledge consolidation by introducing Depth-aware Representation Fusion (DaRF)\nand Structure-aware Contrastive Hashing (SCH). DaRF adaptively integrates\nshallow and deep representations into blended features, and SCH incorporates\nimage fingerprints to enhance the adaptability of positive/negative pairings.\nThese blended features further facilitate OOD detection and content-based\nrecommendation, contributing to a secure AI-driven healthcare environment.\nMoreover, we present a content-guided ranking to improve the robustness and\nreproducibility of retrieval results. Our comprehensive assessments demonstrate\nthat the proposed method could effectively recognise OOD samples and\nsignificantly outperform existing approaches in medical image retrieval\n(p<0.05). In particular, our method achieves a 5.6-38.9% improvement in mean\nAverage Precision on the anatomical radiology dataset.\n","authors":["Yang Nan","Huichi Zhou","Xiaodan Xing","Giorgos Papanastasiou","Lei Zhu","Zhifan Gao","Alejandro F Fangi","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.09370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17448v2","updated":"2025-03-12T13:14:22Z","published":"2024-10-22T21:50:52Z","title":"In Context Learning and Reasoning for Symbolic Regression with Large\n  Language Models","summary":"  Large Language Models (LLMs) are transformer-based machine learning models\nthat have shown remarkable performance in tasks for which they were not\nexplicitly trained. Here, we explore the potential of LLMs to perform symbolic\nregression -- a machine-learning method for finding simple and accurate\nequations from datasets. We prompt GPT-4 to suggest expressions from data,\nwhich are then optimized and evaluated using external Python tools. These\nresults are fed back to GPT-4, which proposes improved expressions while\noptimizing for complexity and loss. Using chain-of-thought prompting, we\ninstruct GPT-4 to analyze the data, prior expressions, and the scientific\ncontext (expressed in natural language) for each problem before generating new\nexpressions. We evaluated the workflow in rediscovery of five well-known\nscientific equations from experimental data, and on an additional dataset\nwithout a known equation. GPT-4 successfully rediscovered all five equations,\nand in general, performed better when prompted to use a scratchpad and consider\nscientific context. We demonstrate how strategic prompting improves the model's\nperformance and how the natural language interface simplifies integrating\ntheory with data. We also observe how theory can sometimes offset noisy data\nand, in other cases, data can make up for poor context. Although this approach\ndoes not outperform established SR programs where target equations are more\ncomplex, LLMs can nonetheless iterate toward improved solutions while following\ninstructions and incorporating scientific context in natural language.\n","authors":["Samiha Sharlin","Tyler R. Josephson"],"pdf_url":"https://arxiv.org/pdf/2410.17448v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09365v1","updated":"2025-03-12T13:09:43Z","published":"2025-03-12T13:09:43Z","title":"Membership Inference Attacks fueled by Few-Short Learning to detect\n  privacy leakage tackling data integrity","summary":"  Deep learning models have an intrinsic privacy issue as they memorize parts\nof their training data, creating a privacy leakage. Membership Inference\nAttacks (MIA) exploit it to obtain confidential information about the data used\nfor training, aiming to steal information. They can be repurposed as a\nmeasurement of data integrity by inferring whether it was used to train a\nmachine learning model. While state-of-the-art attacks achieve a significant\nprivacy leakage, their requirements are not feasible enough, hindering their\nrole as practical tools to assess the magnitude of the privacy risk. Moreover,\nthe most appropriate evaluation metric of MIA, the True Positive Rate at low\nFalse Positive Rate lacks interpretability. We claim that the incorporation of\nFew-Shot Learning techniques to the MIA field and a proper qualitative and\nquantitative privacy evaluation measure should deal with these issues. In this\ncontext, our proposal is twofold. We propose a Few-Shot learning based MIA,\ncoined as the FeS-MIA model, which eases the evaluation of the privacy breach\nof a deep learning model by significantly reducing the number of resources\nrequired for the purpose. Furthermore, we propose an interpretable quantitative\nand qualitative measure of privacy, referred to as Log-MIA measure. Jointly,\nthese proposals provide new tools to assess the privacy leakage and to ease the\nevaluation of the training data integrity of deep learning models, that is, to\nanalyze the privacy breach of a deep learning model. Experiments carried out\nwith MIA over image classification and language modeling tasks and its\ncomparison to the state-of-the-art show that our proposals excel at reporting\nthe privacy leakage of a deep learning model with little extra information.\n","authors":["Daniel Jiménez-López","Nuria Rodríguez-Barroso","M. Victoria Luzón","Francisco Herrera"],"pdf_url":"https://arxiv.org/pdf/2503.09365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16442v2","updated":"2025-03-12T13:02:27Z","published":"2024-02-26T09:38:39Z","title":"On Distributed Larger-Than-Memory Subset Selection With Pairwise\n  Submodular Functions","summary":"  Modern datasets span billions of samples, making training on all available\ndata infeasible. Selecting a high quality subset helps in reducing training\ncosts and enhancing model quality. Submodularity, a discrete analogue of\nconvexity, is commonly used for solving such subset selection problems.\nHowever, existing algorithms for optimizing submodular functions are\nsequential, and the prior distributed methods require at least one central\nmachine to fit the target subset in DRAM. At billion datapoint scale, even the\nsubset may not fit a single machine, and the sequential algorithms are\nprohibitively slow. In this paper, we relax the requirement of having a central\nmachine for the target subset by proposing a novel distributed bounding\nalgorithm with provable approximation guarantees. The algorithm iteratively\nbounds the minimum and maximum utility values to select high quality points and\ndiscard the unimportant ones. When bounding does not find the complete subset,\nwe use a multi-round, partition-based distributed greedy algorithm to identify\nthe remaining subset. We discuss how to implement these algorithms in a\ndistributed data processing framework and empirically analyze different\nconfigurations. We find high quality subsets on CIFAR-100 and ImageNet with\nmarginal or no loss in quality compared to centralized methods, and scale to a\ndataset with 13 billion points.\n","authors":["Maximilian Böther","Abraham Sebastian","Pranjal Awasthi","Ana Klimovic","Srikumar Ramalingam"],"pdf_url":"https://arxiv.org/pdf/2402.16442v2.pdf","comment":"accepted at MLSys 2025"},{"id":"http://arxiv.org/abs/2503.09358v1","updated":"2025-03-12T13:00:57Z","published":"2025-03-12T13:00:57Z","title":"RetSTA: An LLM-Based Approach for Standardizing Clinical Fundus Image\n  Reports","summary":"  Standardization of clinical reports is crucial for improving the quality of\nhealthcare and facilitating data integration. The lack of unified standards,\nincluding format, terminology, and style, is a great challenge in clinical\nfundus diagnostic reports, which increases the difficulty for large language\nmodels (LLMs) to understand the data. To address this, we construct a bilingual\nstandard terminology, containing fundus clinical terms and commonly used\ndescriptions in clinical diagnosis. Then, we establish two models,\nRetSTA-7B-Zero and RetSTA-7B. RetSTA-7B-Zero, fine-tuned on an augmented\ndataset simulating clinical scenarios, demonstrates powerful standardization\nbehaviors. However, it encounters a challenge of limitation to cover a wider\nrange of diseases. To further enhance standardization performance, we build\nRetSTA-7B, which integrates a substantial amount of standardized data generated\nby RetSTA-7B-Zero along with corresponding English data, covering diverse\ncomplex clinical scenarios and achieving report-level standardization for the\nfirst time. Experimental results demonstrate that RetSTA-7B outperforms other\ncompared LLMs in bilingual standardization task, which validates its superior\nperformance and generalizability. The checkpoints are available at\nhttps://github.com/AB-Story/RetSTA-7B.\n","authors":["Jiushen Cai","Weihang Zhang","Hanruo Liu","Ningli Wang","Huiqi Li"],"pdf_url":"https://arxiv.org/pdf/2503.09358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09357v1","updated":"2025-03-12T13:00:29Z","published":"2025-03-12T13:00:29Z","title":"Automatic Operator-level Parallelism Planning for Distributed Deep\n  Learning -- A Mixed-Integer Programming Approach","summary":"  As the artificial intelligence community advances into the era of large\nmodels with billions of parameters, distributed training and inference have\nbecome essential. While various parallelism strategies-data, model, sequence,\nand pipeline-have been successfully implemented for popular neural networks on\nmain-stream hardware, optimizing the distributed deployment schedule requires\nextensive expertise and manual effort. Further more, while existing frameworks\nwith most simple chain-like structures, they struggle with complex non-linear\narchitectures. Mixture-of-experts and multi-modal models feature intricate MIMO\nand branch-rich topologies that require fine-grained operator-level\nparallelization beyond the capabilities of existing frameworks. We propose\nformulating parallelism planning as a scheduling optimization problem using\nmixed-integer programming. We propose a bi-level solution framework balancing\noptimality with computational efficiency, automatically generating effective\ndistributed plans that capture both the heterogeneous structure of modern\nneural networks and the underlying hardware constraints. In experiments\ncomparing against expert-designed strategies like DeepSeek's DualPipe, our\nframework achieves comparable or superior performance, reducing computational\nbubbles by half under the same memory constraints. The framework's versatility\nextends beyond throughput optimization to incorporate hardware utilization\nmaximization, memory capacity constraints, and other considerations or\npotential strategies. Such capabilities position our solution as both a\nvaluable research tool for exploring optimal parallelization strategies and a\npractical industrial solution for large-scale AI deployment.\n","authors":["Ruifeng She","Bowen Pang","Kai Li","Zehua Liu","Tao Zhong"],"pdf_url":"https://arxiv.org/pdf/2503.09357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09348v1","updated":"2025-03-12T12:49:31Z","published":"2025-03-12T12:49:31Z","title":"MOAT: Evaluating LMMs for Capability Integration and Instruction\n  Grounding","summary":"  Large multimodal models (LMMs) have demonstrated significant potential as\ngeneralists in vision-language (VL) tasks. However, there remains a significant\ngap between state-of-the-art LMMs and human performance when it comes to\ncomplex tasks that require a combination of fundamental VL capabilities, as\nwell as tasks involving the grounding of complex instructions. To thoroughly\ninvestigate the human-LMM gap and its underlying causes, we propose MOAT, a\ndiverse benchmark with complex real-world VL tasks that are challenging for\nLMMs. Specifically, the tasks in MOAT require LMMs to engage in generalist\nproblem solving by integrating fundamental VL capabilities such as reading\ntext, counting, understanding spatial relations, grounding textual and visual\ninstructions, etc. All these abilities fit into a taxonomy proposed by us that\ncontains 10 fundamental VL capabilities, enabling MOAT to provide a\nfine-grained view of LMMs' strengths and weaknesses. Besides, MOAT is the first\nbenchmark to explicitly evaluate LMMs' ability to ground complex text and\nvisual instructions, which is essential to many real-world applications. We\nevaluate over 20 proprietary and open source LMMs, as well as humans, on MOAT,\nand found that humans achieved 82.7% accuracy while the best performing LMM\n(OpenAI o1) achieved only 38.8%. To guide future model development, we analyze\ncommon trends in our results and discuss the underlying causes of observed\nperformance gaps between LMMs and humans, focusing on which VL capability forms\nthe bottleneck in complex tasks, whether test time scaling improves performance\non MOAT, and how tiling harms LMMs' capability to count. Code and data are\navailable at https://cambrian-yzt.github.io/MOAT.\n","authors":["Zhoutong Ye","Mingze Sun","Huan-ang Gao","Chun Yu","Yuanchun Shi"],"pdf_url":"https://arxiv.org/pdf/2503.09348v1.pdf","comment":"Project page: https://cambrian-yzt.github.io/MOAT"},{"id":"http://arxiv.org/abs/2503.09347v1","updated":"2025-03-12T12:49:02Z","published":"2025-03-12T12:49:02Z","title":"Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts","summary":"  Large Language Models (LLMs) are increasingly employed as automated\nevaluators to assess the safety of generated content, yet their reliability in\nthis role remains uncertain. This study evaluates a diverse set of 11 LLM judge\nmodels across critical safety domains, examining three key aspects:\nself-consistency in repeated judging tasks, alignment with human judgments, and\nsusceptibility to input artifacts such as apologetic or verbose phrasing. Our\nfindings reveal that biases in LLM judges can significantly distort the final\nverdict on which content source is safer, undermining the validity of\ncomparative evaluations. Notably, apologetic language artifacts alone can skew\nevaluator preferences by up to 98\\%. Contrary to expectations, larger models do\nnot consistently exhibit greater robustness, while smaller models sometimes\nshow higher resistance to specific artifacts. To mitigate LLM evaluator\nrobustness issues, we investigate jury-based evaluations aggregating decisions\nfrom multiple models. Although this approach both improves robustness and\nenhances alignment to human judgements, artifact sensitivity persists even with\nthe best jury configurations. These results highlight the urgent need for\ndiversified, artifact-resistant methodologies to ensure reliable safety\nassessments.\n","authors":["Hongyu Chen","Seraphina Goldfarb-Tarrant"],"pdf_url":"https://arxiv.org/pdf/2503.09347v1.pdf","comment":"8 pages, preprint"},{"id":"http://arxiv.org/abs/2503.00897v4","updated":"2025-03-12T12:43:07Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00418v2","updated":"2025-03-12T12:33:46Z","published":"2024-11-30T10:05:03Z","title":"Mixture of Experts for Node Classification","summary":"  Nodes in the real-world graphs exhibit diverse patterns in numerous aspects,\nsuch as degree and homophily. However, most existent node predictors fail to\ncapture a wide range of node patterns or to make predictions based on distinct\nnode patterns, resulting in unsatisfactory classification performance. In this\npaper, we reveal that different node predictors are good at handling nodes with\nspecific patterns and only apply one node predictor uniformly could lead to\nsuboptimal result. To mitigate this gap, we propose a mixture of experts\nframework, MoE-NP, for node classification. Specifically, MoE-NP combines a\nmixture of node predictors and strategically selects models based on node\npatterns. Experimental results from a range of real-world datasets demonstrate\nsignificant performance improvements from MoE-NP.\n","authors":["Yu Shi","Yiqi Wang","WeiXuan Lang","Jiaxin Zhang","Pan Dong","Aiping Li"],"pdf_url":"https://arxiv.org/pdf/2412.00418v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09335v1","updated":"2025-03-12T12:30:18Z","published":"2025-03-12T12:30:18Z","title":"NVP-HRI: Zero Shot Natural Voice and Posture-based Human-Robot\n  Interaction via Large Language Model","summary":"  Effective Human-Robot Interaction (HRI) is crucial for future service robots\nin aging societies. Existing solutions are biased toward only well-trained\nobjects, creating a gap when dealing with new objects. Currently, HRI systems\nusing predefined gestures or language tokens for pretrained objects pose\nchallenges for all individuals, especially elderly ones. These challenges\ninclude difficulties in recalling commands, memorizing hand gestures, and\nlearning new names. This paper introduces NVP-HRI, an intuitive multi-modal HRI\nparadigm that combines voice commands and deictic posture. NVP-HRI utilizes the\nSegment Anything Model (SAM) to analyze visual cues and depth data, enabling\nprecise structural object representation. Through a pre-trained SAM network,\nNVP-HRI allows interaction with new objects via zero-shot prediction, even\nwithout prior knowledge. NVP-HRI also integrates with a large language model\n(LLM) for multimodal commands, coordinating them with object selection and\nscene distribution in real time for collision-free trajectory solutions. We\nalso regulate the action sequence with the essential control syntax to reduce\nLLM hallucination risks. The evaluation of diverse real-world tasks using a\nUniversal Robot showcased up to 59.2\\% efficiency improvement over traditional\ngesture control, as illustrated in the video https://youtu.be/EbC7al2wiAc. Our\ncode and design will be openly available at\nhttps://github.com/laiyuzhi/NVP-HRI.git.\n","authors":["Yuzhi Lai","Shenghai Yuan","Youssef Nassar","Mingyu Fan","Thomas Weber","Matthias Rätsch"],"pdf_url":"https://arxiv.org/pdf/2503.09335v1.pdf","comment":"This work has been accepted for publication in ESWA @ 2025 Elsevier.\n  Personal use of this material is permitted. Permission from Elsevier must be\n  obtained for all other uses, including reprinting/redistribution, creating\n  new works, or reuse of any copyrighted components of this work in other media"},{"id":"http://arxiv.org/abs/2503.09334v1","updated":"2025-03-12T12:29:27Z","published":"2025-03-12T12:29:27Z","title":"CyberLLMInstruct: A New Dataset for Analysing Safety of Fine-Tuned LLMs\n  Using Cyber Security Data","summary":"  The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. To address these challenges, we developed CyberLLMInstruct, a\ndataset of 54,928 instruction-response pairs spanning cyber security tasks such\nas malware analysis, phishing simulations, and zero-day vulnerabilities. The\ndataset was constructed through a multi-stage process. This involved sourcing\ndata from multiple resources, filtering and structuring it into\ninstruction-response pairs, and aligning it with real-world scenarios to\nenhance its applicability. Seven open-source LLMs were chosen to test the\nusefulness of CyberLLMInstruct: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama\n3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. In our primary example, we\nrigorously assess the safety of fine-tuned models using the OWASP top 10\nframework, finding that fine-tuning reduces safety resilience across all tested\nLLMs and every adversarial attack (e.g., the security score of Llama 3.1 8B\nagainst prompt injection drops from 0.95 to 0.15). In our second example, we\nshow that these same fine-tuned models can also achieve up to 92.50 percent\naccuracy on the CyberMetric benchmark. These findings highlight a trade-off\nbetween performance and safety, showing the importance of adversarial testing\nand further research into fine-tuning methodologies that can mitigate safety\nrisks while still improving performance across diverse datasets and domains.\nAll scripts required to reproduce the dataset, along with examples and relevant\nresources for replicating our results, will be made available upon the paper's\nacceptance.\n","authors":["Adel ElZemity","Budi Arief","Shujun Li"],"pdf_url":"https://arxiv.org/pdf/2503.09334v1.pdf","comment":"The paper is submitted to \"The 48th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval\" and is\n  currently under review"},{"id":"http://arxiv.org/abs/2503.09332v1","updated":"2025-03-12T12:25:58Z","published":"2025-03-12T12:25:58Z","title":"SDD-4DGS: Static-Dynamic Aware Decoupling in Gaussian Splatting for 4D\n  Scene Reconstruction","summary":"  Dynamic and static components in scenes often exhibit distinct properties,\nyet most 4D reconstruction methods treat them indiscriminately, leading to\nsuboptimal performance in both cases. This work introduces SDD-4DGS, the first\nframework for static-dynamic decoupled 4D scene reconstruction based on\nGaussian Splatting. Our approach is built upon a novel probabilistic dynamic\nperception coefficient that is naturally integrated into the Gaussian\nreconstruction pipeline, enabling adaptive separation of static and dynamic\ncomponents. With carefully designed implementation strategies to realize this\ntheoretical framework, our method effectively facilitates explicit learning of\nmotion patterns for dynamic elements while maintaining geometric stability for\nstatic structures. Extensive experiments on five benchmark datasets demonstrate\nthat SDD-4DGS consistently outperforms state-of-the-art methods in\nreconstruction fidelity, with enhanced detail restoration for static structures\nand precise modeling of dynamic motions. The code will be released.\n","authors":["Dai Sun","Huhao Guan","Kun Zhang","Xike Xie","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.09332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09330v1","updated":"2025-03-12T12:24:05Z","published":"2025-03-12T12:24:05Z","title":"Group-robust Machine Unlearning","summary":"  Machine unlearning is an emerging paradigm to remove the influence of\nspecific training data (i.e., the forget set) from a model while preserving its\nknowledge of the rest of the data (i.e., the retain set). Previous approaches\nassume the forget data to be uniformly distributed from all training\ndatapoints. However, if the data to unlearn is dominant in one group, we\nempirically show that performance for this group degrades, leading to fairness\nissues. This work tackles the overlooked problem of non-uniformly distributed\nforget sets, which we call group-robust machine unlearning, by presenting a\nsimple, effective strategy that mitigates the performance loss in dominant\ngroups via sample distribution reweighting. Moreover, we present MIU (Mutual\nInformation-aware Machine Unlearning), the first approach for group robustness\nin approximate machine unlearning. MIU minimizes the mutual information between\nmodel features and group information, achieving unlearning while reducing\nperformance degradation in the dominant group of the forget set. Additionally,\nMIU exploits sample distribution reweighting and mutual information calibration\nwith the original model to preserve group robustness. We conduct experiments on\nthree datasets and show that MIU outperforms standard methods, achieving\nunlearning without compromising model robustness. Source code available at\nhttps://github.com/tdemin16/group-robust_machine_unlearning.\n","authors":["Thomas De Min","Subhankar Roy","Stéphane Lathuilière","Elisa Ricci","Massimiliano Mancini"],"pdf_url":"https://arxiv.org/pdf/2503.09330v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.09326v1","updated":"2025-03-12T12:20:31Z","published":"2025-03-12T12:20:31Z","title":"A Survey on Enhancing Causal Reasoning Ability of Large Language Models","summary":"  Large language models (LLMs) have recently shown remarkable performance in\nlanguage tasks and beyond. However, due to their limited inherent causal\nreasoning ability, LLMs still face challenges in handling tasks that require\nrobust causal reasoning ability, such as health-care and economic analysis. As\na result, a growing body of research has focused on enhancing the causal\nreasoning ability of LLMs. Despite the booming research, there lacks a survey\nto well review the challenges, progress and future directions in this area. To\nbridge this significant gap, we systematically review literature on how to\nstrengthen LLMs' causal reasoning ability in this paper. We start from the\nintroduction of background and motivations of this topic, followed by the\nsummarisation of key challenges in this area. Thereafter, we propose a novel\ntaxonomy to systematically categorise existing methods, together with detailed\ncomparisons within and between classes of methods. Furthermore, we summarise\nexisting benchmarks and evaluation metrics for assessing LLMs' causal reasoning\nability. Finally, we outline future research directions for this emerging\nfield, offering insights and inspiration to researchers and practitioners in\nthe area.\n","authors":["Xin Li","Zhuo Cai","Shoujin Wang","Kun Yu","Fang Chen"],"pdf_url":"https://arxiv.org/pdf/2503.09326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07688v2","updated":"2025-03-12T12:16:13Z","published":"2024-11-12T10:12:12Z","title":"Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with\n  ImageRAG","summary":"  Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000\n$\\times$ 100,000 pixels or more) poses a significant challenge for current\nRemote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize\nthe UHR image to standard input image size, the extensive spatial and\ncontextual information that UHR images contain will be neglected. Otherwise,\nthe original size of these images often exceeds the token limits of standard\nRSMLLMs, making it difficult to process the entire image and capture long-range\ndependencies to answer the query based on the abundant visual context. In this\npaper, we introduce ImageRAG for RS, a training-free framework to address the\ncomplexities of analyzing UHR remote sensing imagery. By transforming UHR\nremote sensing image analysis task to image's long context selection task, we\ndesign an innovative image contextual retrieval mechanism based on the\nRetrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's\ncore innovation lies in its ability to selectively retrieve and focus on the\nmost relevant portions of the UHR image as visual contexts that pertain to a\ngiven query. Fast path and slow path are proposed in this framework to handle\nthis task efficiently and effectively. ImageRAG allows RSMLLMs to manage\nextensive context and spatial information from UHR RSI, ensuring the analysis\nis both accurate and efficient.\n","authors":["Zilun Zhang","Haozhan Shen","Tiancheng Zhao","Yuhao Wang","Bin Chen","Yuxiang Cai","Yongheng Shang","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2411.07688v2.pdf","comment":"full paper"},{"id":"http://arxiv.org/abs/2503.09321v1","updated":"2025-03-12T12:12:46Z","published":"2025-03-12T12:12:46Z","title":"DAVE: Diagnostic benchmark for Audio Visual Evaluation","summary":"  Audio-visual understanding is a rapidly evolving field that seeks to\nintegrate and interpret information from both auditory and visual modalities.\nDespite recent advances in multi-modal learning, existing benchmarks often\nsuffer from strong visual bias -- where answers can be inferred from visual\ndata alone -- and provide only aggregate scores that conflate multiple sources\nof error. This makes it difficult to determine whether models struggle with\nvisual understanding, audio interpretation, or audio-visual alignment. In this\nwork, we introduce DAVE (Diagnostic Audio Visual Evaluation), a novel benchmark\ndataset designed to systematically evaluate audio-visual models across\ncontrolled challenges. DAVE alleviates existing limitations by (i) ensuring\nboth modalities are necessary to answer correctly and (ii) decoupling\nevaluation into atomic subcategories. Our detailed analysis of state-of-the-art\nmodels reveals specific failure modes and provides targeted insights for\nimprovement. By offering this standardized diagnostic framework, we aim to\nfacilitate more robust development of audio-visual models. The dataset is\nreleased: https://github.com/gorjanradevski/dave\n","authors":["Gorjan Radevski","Teodora Popordanoska","Matthew B. Blaschko","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2503.09321v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2503.09311v1","updated":"2025-03-12T12:02:36Z","published":"2025-03-12T12:02:36Z","title":"Adaptive political surveys and GPT-4: Tackling the cold start problem\n  with simulated user interactions","summary":"  Adaptive questionnaires dynamically select the next question for a survey\nparticipant based on their previous answers. Due to digitalisation, they have\nbecome a viable alternative to traditional surveys in application areas such as\npolitical science. One limitation, however, is their dependency on data to\ntrain the model for question selection. Often, such training data (i.e., user\ninteractions) are unavailable a priori. To address this problem, we (i) test\nwhether Large Language Models (LLM) can accurately generate such interaction\ndata and (ii) explore if these synthetic data can be used to pre-train the\nstatistical model of an adaptive political survey. To evaluate this approach,\nwe utilise existing data from the Swiss Voting Advice Application (VAA)\nSmartvote in two ways: First, we compare the distribution of LLM-generated\nsynthetic data to the real distribution to assess its similarity. Second, we\ncompare the performance of an adaptive questionnaire that is randomly\ninitialised with one pre-trained on synthetic data to assess their suitability\nfor training. We benchmark these results against an \"oracle\" questionnaire with\nperfect prior knowledge. We find that an off-the-shelf LLM (GPT-4) accurately\ngenerates answers to the Smartvote questionnaire from the perspective of\ndifferent Swiss parties. Furthermore, we demonstrate that initialising the\nstatistical model with synthetic data can (i) significantly reduce the error in\npredicting user responses and (ii) increase the candidate recommendation\naccuracy of the VAA. Our work emphasises the considerable potential of LLMs to\ncreate training data to improve the data collection process in adaptive\nquestionnaires in LLM-affine areas such as political surveys.\n","authors":["Fynn Bachmann","Daan van der Weijden","Lucien Heitz","Cristina Sarasua","Abraham Bernstein"],"pdf_url":"https://arxiv.org/pdf/2503.09311v1.pdf","comment":"23 pages. Under review at PLOS One"},{"id":"http://arxiv.org/abs/2503.09309v1","updated":"2025-03-12T12:02:02Z","published":"2025-03-12T12:02:02Z","title":"Steering No-Regret Agents in MFGs under Model Uncertainty","summary":"  Incentive design is a popular framework for guiding agents' learning dynamics\ntowards desired outcomes by providing additional payments beyond intrinsic\nrewards. However, most existing works focus on a finite, small set of agents or\nassume complete knowledge of the game, limiting their applicability to\nreal-world scenarios involving large populations and model uncertainty. To\naddress this gap, we study the design of steering rewards in Mean-Field Games\n(MFGs) with density-independent transitions, where both the transition dynamics\nand intrinsic reward functions are unknown. This setting presents non-trivial\nchallenges, as the mediator must incentivize the agents to explore for its\nmodel learning under uncertainty, while simultaneously steer them to converge\nto desired behaviors without incurring excessive incentive payments. Assuming\nagents exhibit no(-adaptive) regret behaviors, we contribute novel optimistic\nexploration algorithms. Theoretically, we establish sub-linear regret\nguarantees for the cumulative gaps between the agents' behaviors and the\ndesired ones. In terms of the steering cost, we demonstrate that our total\nincentive payments incur only sub-linear excess, competing with a baseline\nsteering strategy that stabilizes the target policy as an equilibrium. Our work\npresents an effective framework for steering agents behaviors in\nlarge-population systems under uncertainty.\n","authors":["Leo Widmer","Jiawei Huang","Niao He"],"pdf_url":"https://arxiv.org/pdf/2503.09309v1.pdf","comment":"AISTATS 2025; 34 Pages"},{"id":"http://arxiv.org/abs/2412.04106v2","updated":"2025-03-12T11:59:46Z","published":"2024-12-04T16:34:22Z","title":"MRGen: Segmentation Data Engine For Underrepresented MRI Modalities","summary":"  Training medical image segmentation models for rare yet clinically\nsignificant imaging modalities is challenging due to the scarcity of annotated\ndata, and manual mask annotations can be costly and labor-intensive to acquire.\nThis paper investigates leveraging generative models to synthesize training\ndata, to train segmentation models for underrepresented modalities,\nparticularly on annotation-scarce MRI. Concretely, our contributions are\nthreefold: (i) we introduce MRGen-DB, a large-scale radiology image-text\ndataset comprising extensive samples with rich metadata, including modality\nlabels, attributes, regions, and organs information, with a subset having\npixelwise mask annotations; (ii) we present MRGen, a diffusion-based data\nengine for controllable medical image synthesis, conditioned on text prompts\nand segmentation masks. MRGen can generate realistic images for diverse MRI\nmodalities lacking mask annotations, facilitating segmentation training in\nlow-source domains; (iii) extensive experiments across multiple modalities\ndemonstrate that MRGen significantly improves segmentation performance on\nunannotated modalities by providing high-quality synthetic data. We believe\nthat our method bridges a critical gap in medical image analysis, extending\nsegmentation capabilities to scenarios that are challenging to acquire manual\nannotations.\n","authors":["Haoning Wu","Ziheng Zhao","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2412.04106v2.pdf","comment":"Technical Report; Project Page:\n  https://haoningwu3639.github.io/MRGen/"},{"id":"http://arxiv.org/abs/2406.08226v2","updated":"2025-03-12T11:58:36Z","published":"2024-06-12T13:55:12Z","title":"DistilDoc: Knowledge Distillation for Visually-Rich Document\n  Applications","summary":"  This work explores knowledge distillation (KD) for visually-rich document\n(VRD) applications such as document layout analysis (DLA) and document image\nclassification (DIC). While VRD research is dependent on increasingly\nsophisticated and cumbersome models, the field has neglected to study\nefficiency via model compression. Here, we design a KD experimentation\nmethodology for more lean, performant models on document understanding (DU)\ntasks that are integral within larger task pipelines. We carefully selected KD\nstrategies (response-based, feature-based) for distilling knowledge to and from\nbackbones with different architectures (ResNet, ViT, DiT) and capacities (base,\nsmall, tiny). We study what affects the teacher-student knowledge gap and find\nthat some methods (tuned vanilla KD, MSE, SimKD with an apt projector) can\nconsistently outperform supervised student training. Furthermore, we design\ndownstream task setups to evaluate covariate shift and the robustness of\ndistilled DLA models on zero-shot layout-aware document visual question\nanswering (DocVQA). DLA-KD experiments result in a large mAP knowledge gap,\nwhich unpredictably translates to downstream robustness, accentuating the need\nto further explore how to efficiently obtain more semantic document layout\nawareness.\n","authors":["Jordy Van Landeghem","Subhajit Maity","Ayan Banerjee","Matthew Blaschko","Marie-Francine Moens","Josep Lladós","Sanket Biswas"],"pdf_url":"https://arxiv.org/pdf/2406.08226v2.pdf","comment":"Accepted to ICDAR 2024 (Athens, Greece)"},{"id":"http://arxiv.org/abs/2401.13112v6","updated":"2025-03-12T11:53:06Z","published":"2024-01-23T21:48:52Z","title":"Distributional Counterfactual Explanations With Optimal Transport","summary":"  Counterfactual explanations (CE) are the de facto method for providing\ninsights into black-box decision-making models by identifying alternative\ninputs that lead to different outcomes. However, existing CE approaches,\nincluding group and global methods, focus predominantly on specific input\nmodifications, lacking the ability to capture nuanced distributional\ncharacteristics that influence model outcomes across the entire input-output\nspectrum. This paper proposes distributional counterfactual explanation (DCE),\nshifting focus to the distributional properties of observed and counterfactual\ndata, thus providing broader insights. DCE is particularly beneficial for\nstakeholders making strategic decisions based on statistical data analysis, as\nit makes the statistical distribution of the counterfactual resembles the one\nof the factual when aligning model outputs with a target\ndistribution\\textemdash something that the existing CE methods cannot fully\nachieve. We leverage optimal transport (OT) to formulate a chance-constrained\noptimization problem, deriving a counterfactual distribution aligned with its\nfactual counterpart, supported by statistical confidence. The efficacy of this\napproach is demonstrated through experiments, highlighting its potential to\nprovide deeper insights into decision-making models.\n","authors":["Lei You","Lele Cao","Mattias Nilsson","Bo Zhao","Lei Lei"],"pdf_url":"https://arxiv.org/pdf/2401.13112v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07996v2","updated":"2025-03-12T11:41:45Z","published":"2025-03-11T02:52:39Z","title":"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic","summary":"  Recent advancements in Text-to-SQL systems have improved the conversion of\nnatural language queries into SQL, but challenges remain in ensuring accuracy\nand reliability. While self-correction techniques refine outputs, they often\nintroduce new errors. Existing methods focused on execution feedback mainly\naddress syntax issues, leaving semantic errors -- where the query's logic fails\nto align with the user's intent -- largely unaddressed. We propose a novel\napproach combining structured execution feedback with a trained critic agent\nthat provides detailed, interpretable critiques. This method effectively\nidentifies and corrects both syntactic and semantic errors, enhancing accuracy\nand interpretability. Experimental results show significant improvements on two\nmajor Text-to-SQL benchmarks, Spider and BIRD, demonstrating the effectiveness\nof our approach.\n","authors":["Jikai Chen","Leilei Gan"],"pdf_url":"https://arxiv.org/pdf/2503.07996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09289v1","updated":"2025-03-12T11:35:04Z","published":"2025-03-12T11:35:04Z","title":"Unmask It! AI-Generated Product Review Detection in Dravidian Languages","summary":"  The rise of Generative AI has led to a surge in AI-generated reviews, often\nposing a serious threat to the credibility of online platforms. Reviews serve\nas the primary source of information about products and services. Authentic\nreviews play a vital role in consumer decision-making. The presence of\nfabricated content misleads consumers, undermines trust and facilitates\npotential fraud in digital marketplaces. This study focuses on detecting\nAI-generated product reviews in Tamil and Malayalam, two low-resource languages\nwhere research in this domain is relatively under-explored. We worked on a\nrange of approaches - from traditional machine learning methods to advanced\ntransformer-based models such as Indic-BERT, IndicSBERT, MuRIL, XLM-RoBERTa and\nMalayalamBERT. Our findings highlight the effectiveness of leveraging the\nstate-of-the-art transformers in accurately identifying AI-generated content,\ndemonstrating the potential in enhancing the detection of fake reviews in\nlow-resource language settings.\n","authors":["Somsubhra De","Advait Vats"],"pdf_url":"https://arxiv.org/pdf/2503.09289v1.pdf","comment":"10 pages, 9 figures, Accepted to DravidianLangTech Workshop\n  proceedings at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.08102v2","updated":"2025-03-12T11:31:31Z","published":"2025-03-11T07:05:52Z","title":"AI-native Memory 2.0: Second Me","summary":"  Human interaction with the external world fundamentally involves the exchange\nof personal memory, whether with other individuals, websites, applications, or,\nin the future, AI agents. A significant portion of this interaction is\nredundant, requiring users to repeatedly provide the same information across\ndifferent contexts. Existing solutions, such as browser-stored credentials,\nautofill mechanisms, and unified authentication systems, have aimed to mitigate\nthis redundancy by serving as intermediaries that store and retrieve commonly\nused user data. The advent of large language models (LLMs) presents an\nopportunity to redefine memory management through an AI-native paradigm: SECOND\nME. SECOND ME acts as an intelligent, persistent memory offload system that\nretains, organizes, and dynamically utilizes user-specific knowledge. By\nserving as an intermediary in user interactions, it can autonomously generate\ncontext-aware responses, prefill required information, and facilitate seamless\ncommunication with external systems, significantly reducing cognitive load and\ninteraction friction. Unlike traditional memory storage solutions, SECOND ME\nextends beyond static data retention by leveraging LLM-based memory\nparameterization. This enables structured organization, contextual reasoning,\nand adaptive knowledge retrieval, facilitating a more systematic and\nintelligent approach to memory management. As AI-driven personal agents like\nSECOND ME become increasingly integrated into digital ecosystems, SECOND ME\nfurther represents a critical step toward augmenting human-world interaction\nwith persistent, contextually aware, and self-optimizing memory systems. We\nhave open-sourced the fully localizable deployment system at GitHub:\nhttps://github.com/Mindverse/Second-Me.\n","authors":["Jiale Wei","Xiang Ying","Tao Gao","Fangyi Bao","Felix Tao","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2503.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09277v1","updated":"2025-03-12T11:22:47Z","published":"2025-03-12T11:22:47Z","title":"UniCombine: Unified Multi-Conditional Combination with Diffusion\n  Transformer","summary":"  With the rapid development of diffusion models in image generation, the\ndemand for more powerful and flexible controllable frameworks is increasing.\nAlthough existing methods can guide generation beyond text prompts, the\nchallenge of effectively combining multiple conditional inputs while\nmaintaining consistency with all of them remains unsolved. To address this, we\nintroduce UniCombine, a DiT-based multi-conditional controllable generative\nframework capable of handling any combination of conditions, including but not\nlimited to text prompts, spatial maps, and subject images. Specifically, we\nintroduce a novel Conditional MMDiT Attention mechanism and incorporate a\ntrainable LoRA module to build both the training-free and training-based\nversions. Additionally, we propose a new pipeline to construct\nSubjectSpatial200K, the first dataset designed for multi-conditional generative\ntasks covering both the subject-driven and spatially-aligned conditions.\nExtensive experimental results on multi-conditional generation demonstrate the\noutstanding universality and powerful capability of our approach with\nstate-of-the-art performance.\n","authors":["Haoxuan Wang","Jinlong Peng","Qingdong He","Hao Yang","Ying Jin","Jiafu Wu","Xiaobin Hu","Yanjie Pan","Zhenye Gan","Mingmin Chi","Bo Peng","Yabiao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.09277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09269v1","updated":"2025-03-12T11:12:05Z","published":"2025-03-12T11:12:05Z","title":"Single-Qudit Quantum Neural Networks for Multiclass Classification","summary":"  This paper proposes a single-qudit quantum neural network for multiclass\nclassification, by using the enhanced representational capacity of\nhigh-dimensional qudit states. Our design employs an $d$-dimensional unitary\noperator, where $d$ corresponds to the number of classes, constructed using the\nCayley transform of a skew-symmetric matrix, to efficiently encode and process\nclass information. This architecture enables a direct mapping between class\nlabels and quantum measurement outcomes, reducing circuit depth and\ncomputational overhead. To optimize network parameters, we introduce a hybrid\ntraining approach that combines an extended activation function -- derived from\na truncated multivariable Taylor series expansion -- with support vector\nmachine optimization for weight determination. We evaluate our model on the\nMNIST and EMNIST datasets, demonstrating competitive accuracy while maintaining\na compact single-qudit quantum circuit. Our findings highlight the potential of\nqudit-based QNNs as scalable alternatives to classical deep learning models,\nparticularly for multiclass classification. However, practical implementation\nremains constrained by current quantum hardware limitations. This research\nadvances quantum machine learning by demonstrating the feasibility of\nhigher-dimensional quantum systems for efficient learning tasks.\n","authors":["Leandro C. Souza","Renato Portugal"],"pdf_url":"https://arxiv.org/pdf/2503.09269v1.pdf","comment":"24 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.09257v1","updated":"2025-03-12T10:56:02Z","published":"2025-03-12T10:56:02Z","title":"DeepInnovation AI: A Global Dataset Mapping the AI innovation and\n  technology Transfer from Academic Research to Industrial Patents","summary":"  In the rapidly evolving field of artificial intelligence (AI), mapping\ninnovation patterns and understanding effective technology transfer from\nacademic research to practical applications are essential for economic growth.\nThis paper introduces DeepInnovationAI, the first comprehensive global dataset\ndesigned to bridge the gap between academic papers and industrial patents.\nHowever, existing data infrastructures face three major limitations:\nfragmentation, incomplete coverage, and insufficient evaluative capacity. Here,\nwe present DeepInnovationAI, a comprehensive global dataset documenting AI\ninnovation trajectories. The dataset comprises three structured files:\nDeepPatentAI.csv: Contains 2,356,204 patent records with 8 field-specific\nattributes. DeepDiveAI.csv: Encompasses 3,511,929 academic publications with 13\nmetadata fields. These two datasets employ large language models, multilingual\ntext analysis and dual-layer BERT classifiers to accurately identify AI-related\ncontent and utilizing hypergraph analysis methods to create robust innovation\nmetrics. In addition, DeepCosineAI.csv: By applying semantic vector proximity\nanalysis, this file presents approximately one hundred million calculated\npaper-patent similarity pairs to enhance understanding of how theoretical\nadvancements translate into commercial technologies. This enables researchers,\npolicymakers, and industry leaders to anticipate trends and identify emerging\nareas for collaboration. With its extensive temporal and geographical scope,\nDeepInnovationAI supports detailed analysis of technological development\npatterns and international competition dynamics, providing a robust foundation\nfor modeling AI innovation dynamics and technology transfer processes.\n","authors":["Haixing Gong","Hui Zou","Xingzhou Liang","Shiyuan Meng","Pinlong Cai","Xingcheng Xu","Jingjing Qu"],"pdf_url":"https://arxiv.org/pdf/2503.09257v1.pdf","comment":"32 pages and 8 figures"},{"id":"http://arxiv.org/abs/2503.09251v1","updated":"2025-03-12T10:46:25Z","published":"2025-03-12T10:46:25Z","title":"SCOPE-DTI: Semi-Inductive Dataset Construction and Framework\n  Optimization for Practical Usability Enhancement in Deep Learning-Based Drug\n  Target Interaction Prediction","summary":"  Deep learning-based drug-target interaction (DTI) prediction methods have\ndemonstrated strong performance; however, real-world applicability remains\nconstrained by limited data diversity and modeling complexity. To address these\nchallenges, we propose SCOPE-DTI, a unified framework combining a large-scale,\nbalanced semi-inductive human DTI dataset with advanced deep learning modeling.\nConstructed from 13 public repositories, the SCOPE dataset expands data volume\nby up to 100-fold compared to common benchmarks such as the Human dataset. The\nSCOPE model integrates three-dimensional protein and compound representations,\ngraph neural networks, and bilinear attention mechanisms to effectively capture\ncross domain interaction patterns, significantly outperforming state-of-the-art\nmethods across various DTI prediction tasks. Additionally, SCOPE-DTI provides a\nuser-friendly interface and database. We further validate its effectiveness by\nexperimentally identifying anticancer targets of Ginsenoside Rh1. By offering\ncomprehensive data, advanced modeling, and accessible tools, SCOPE-DTI\naccelerates drug discovery research.\n","authors":["Yigang Chen","Xiang Ji","Ziyue Zhang","Yuming Zhou","Yang-Chi-Dung Lin","Hsi-Yuan Huang","Tao Zhang","Yi Lai","Ke Chen","Chang Su","Xingqiao Lin","Zihao Zhu","Yanggyi Zhang","Kangping Wei","Jiehui Fu","Yixian Huang","Shidong Cui","Shih-Chung Yen","Ariel Warshel","Hsien-Da Huang"],"pdf_url":"https://arxiv.org/pdf/2503.09251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09249v1","updated":"2025-03-12T10:43:33Z","published":"2025-03-12T10:43:33Z","title":"Considering Length Diversity in Retrieval-Augmented Summarization","summary":"  This study investigates retrieval-augmented summarization by specifically\nexamining the impact of exemplar summary lengths under length constraints, not\ncovered by previous work. We propose a Diverse Length-aware Maximal Marginal\nRelevance (DL-MMR) algorithm to better control summary lengths. This algorithm\ncombines the query relevance with diverse target lengths in retrieval-augmented\nsummarization. Unlike previous methods that necessitate exhaustive exemplar\nexemplar relevance comparisons using MMR, DL-MMR considers the exemplar target\nlength as well and avoids comparing exemplars to each other, thereby reducing\ncomputational cost and conserving memory during the construction of an exemplar\npool. Experimental results showed the effectiveness of DL-MMR, which considers\nlength diversity, compared to the original MMR algorithm. DL-MMR additionally\nshowed the effectiveness in memory saving of 781,513 times and computational\ncost reduction of 500,092 times, while maintaining the same level of\ninformativeness.\n","authors":[" Juseon-Do","Jaesung Hwang","Jingun Kwon","Hidetaka Kamigaito","Manabu Okumura"],"pdf_url":"https://arxiv.org/pdf/2503.09249v1.pdf","comment":"12 pages, accepted to NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2503.09241v1","updated":"2025-03-12T10:38:15Z","published":"2025-03-12T10:38:15Z","title":"In-Context Defense in Computer Agents: An Empirical Study","summary":"  Computer agents powered by vision-language models (VLMs) have significantly\nadvanced human-computer interaction, enabling users to perform complex tasks\nthrough natural language instructions. However, these agents are vulnerable to\ncontext deception attacks, an emerging threat where adversaries embed\nmisleading content into the agent's operational environment, such as a pop-up\nwindow containing deceptive instructions. Existing defenses, such as\ninstructing agents to ignore deceptive elements, have proven largely\nineffective. As the first systematic study on protecting computer agents, we\nintroduce textbf{in-context defense}, leveraging in-context learning and\nchain-of-thought (CoT) reasoning to counter such attacks. Our approach involves\naugmenting the agent's context with a small set of carefully curated exemplars\ncontaining both malicious environments and corresponding defensive responses.\nThese exemplars guide the agent to first perform explicit defensive reasoning\nbefore action planning, reducing susceptibility to deceptive attacks.\nExperiments demonstrate the effectiveness of our method, reducing attack\nsuccess rates by 91.2% on pop-up window attacks, 74.6% on average on\nenvironment injection attacks, while achieving 100% successful defenses against\ndistracting advertisements. Our findings highlight that (1) defensive reasoning\nmust precede action planning for optimal performance, and (2) a minimal number\nof exemplars (fewer than three) is sufficient to induce an agent's defensive\nbehavior.\n","authors":["Pei Yang","Hai Ci","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2503.09241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09223v1","updated":"2025-03-12T10:10:30Z","published":"2025-03-12T10:10:30Z","title":"LREF: A Novel LLM-based Relevance Framework for E-commerce","summary":"  Query and product relevance prediction is a critical component for ensuring a\nsmooth user experience in e-commerce search. Traditional studies mainly focus\non BERT-based models to assess the semantic relevance between queries and\nproducts. However, the discriminative paradigm and limited knowledge capacity\nof these approaches restrict their ability to comprehend the relevance between\nqueries and products fully. With the rapid advancement of Large Language Models\n(LLMs), recent research has begun to explore their application to industrial\nsearch systems, as LLMs provide extensive world knowledge and flexible\noptimization for reasoning processes. Nonetheless, directly leveraging LLMs for\nrelevance prediction tasks introduces new challenges, including a high demand\nfor data quality, the necessity for meticulous optimization of reasoning\nprocesses, and an optimistic bias that can result in over-recall. To overcome\nthe above problems, this paper proposes a novel framework called the LLM-based\nRElevance Framework (LREF) aimed at enhancing e-commerce search relevance. The\nframework comprises three main stages: supervised fine-tuning (SFT) with Data\nSelection, Multiple Chain of Thought (Multi-CoT) tuning, and Direct Preference\nOptimization (DPO) for de-biasing. We evaluate the performance of the framework\nthrough a series of offline experiments on large-scale real-world datasets, as\nwell as online A/B testing. The results indicate significant improvements in\nboth offline and online metrics. Ultimately, the model was deployed in a\nwell-known e-commerce application, yielding substantial commercial benefits.\n","authors":["Tian Tang","Zhixing Tian","Zhenyu Zhu","Chenyang Wang","Haiqing Hu","Guoyu Tang","Lin Liu","Sulong Xu"],"pdf_url":"https://arxiv.org/pdf/2503.09223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23746v3","updated":"2025-03-12T10:08:22Z","published":"2024-10-31T09:01:25Z","title":"DetectRL: Benchmarking LLM-Generated Text Detection in Real-World\n  Scenarios","summary":"  Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xinyi Yang","Yulin Yuan","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2410.23746v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)"},{"id":"http://arxiv.org/abs/2503.09217v1","updated":"2025-03-12T10:03:58Z","published":"2025-03-12T10:03:58Z","title":"Evaluating the Generalizability of LLMs in Automated Program Repair","summary":"  LLM-based automated program repair methods have attracted significant\nattention for their state-of-the-art performance. However, they were primarily\nevaluated on a few well known datasets like Defects4J, raising questions about\ntheir effectiveness on new datasets. In this study, we evaluate 11\ntop-performing LLMs on DEFECTS4J-TRANS, a new dataset derived from transforming\nDefects4J while maintaining the original semantics. Results from experiments on\nboth Defects4J and DEFECTS4J-TRANS show that all studied LLMs have limited\ngeneralizability in APR tasks, with the average number of correct and plausible\npatches decreasing by 49.48% and 42.90%, respectively, on DEFECTS4J-TRANS.\nFurther investigation into incorporating additional repair-relevant information\nin repair prompts reveals that, although this information significantly\nenhances the LLMs' capabilities (increasing the number of correct and plausible\npatches by up to 136.67% and 121.82%, respectively), performance still falls\nshort of their original results. This indicates that prompt engineering alone\nis insufficient to substantially enhance LLMs' repair capabilities. Based on\nour study, we also offer several recommendations for future research.\n","authors":["Fengjie Li","Jiajun Jiang","Jiajun Sun","Hongyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09217v1.pdf","comment":"5 pages, 1 figure, to be published in ICSE2025-NIER"},{"id":"http://arxiv.org/abs/2503.09215v1","updated":"2025-03-12T10:02:18Z","published":"2025-03-12T10:02:18Z","title":"Other Vehicle Trajectories Are Also Needed: A Driving World Model\n  Unifies Ego-Other Vehicle Trajectories in Video Latant Space","summary":"  Advanced end-to-end autonomous driving systems predict other vehicles'\nmotions and plan ego vehicle's trajectory. The world model that can foresee the\noutcome of the trajectory has been used to evaluate the end-to-end autonomous\ndriving system. However, existing world models predominantly emphasize the\ntrajectory of the ego vehicle and leave other vehicles uncontrollable. This\nlimitation hinders their ability to realistically simulate the interaction\nbetween the ego vehicle and the driving scenario. In addition, it remains a\nchallenge to match multiple trajectories with each vehicle in the video to\ncontrol the video generation. To address above issues, a driving \\textbf{W}orld\n\\textbf{M}odel named EOT-WM is proposed in this paper, unifying\n\\textbf{E}go-\\textbf{O}ther vehicle \\textbf{T}rajectories in videos.\nSpecifically, we first project ego and other vehicle trajectories in the BEV\nspace into the image coordinate to match each trajectory with its corresponding\nvehicle in the video. Then, trajectory videos are encoded by the\nSpatial-Temporal Variational Auto Encoder to align with driving video latents\nspatially and temporally in the unified visual space. A trajectory-injected\ndiffusion Transformer is further designed to denoise the noisy video latents\nfor video generation with the guidance of ego-other vehicle trajectories. In\naddition, we propose a metric based on control latent similarity to evaluate\nthe controllability of trajectories. Extensive experiments are conducted on the\nnuScenes dataset, and the proposed model outperforms the state-of-the-art\nmethod by 30\\% in FID and 55\\% in FVD. The model can also predict unseen\ndriving scenes with self-produced trajectories.\n","authors":["Jian Zhu","Zhengyu Jia","Tian Gao","Jiaxin Deng","Shidi Li","Fu Liu","Peng Jia","Xianpeng Lang","Xiaolong Sun"],"pdf_url":"https://arxiv.org/pdf/2503.09215v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.07450v2","updated":"2025-03-12T09:57:19Z","published":"2025-03-10T15:30:05Z","title":"From Idea to Implementation: Evaluating the Influence of Large Language\n  Models in Software Development -- An Opinion Paper","summary":"  The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted.\n","authors":["Sargam Yadav","Asifa Mehmood Qureshi","Abhishek Kaushik","Shubham Sharma","Roisin Loughran","Subramaniam Kazhuparambil","Andrew Shaw","Mohammed Sabry","Niamh St John Lynch",". Nikhil Singh","Padraic O'Hara","Pranay Jaiswal","Roshan Chandru","David Lillis"],"pdf_url":"https://arxiv.org/pdf/2503.07450v2.pdf","comment":"The project is partially supported by the DkIT Postgraduate\n  Scholarship, Research Ireland under Grant number 13/RC/2094_2, and Grant\n  number 21/FFP-A/925"},{"id":"http://arxiv.org/abs/2410.01824v2","updated":"2025-03-12T09:55:22Z","published":"2024-09-16T16:03:08Z","title":"AI Conversational Interviewing: Transforming Surveys with LLMs as\n  Adaptive Interviewers","summary":"  Traditional methods for eliciting people's opinions face a trade-off between\ndepth and scale: structured surveys enable large-scale data collection but\nlimit respondents' ability to voice their opinions in their own words, while\nconversational interviews provide deeper insights but are resource-intensive.\nThis study explores the potential of replacing human interviewers with large\nlanguage models (LLMs) to conduct scalable conversational interviews. Our goal\nis to assess the performance of AI Conversational Interviewing and to identify\nopportunities for improvement in a controlled environment. We conducted a\nsmall-scale, in-depth study with university students who were randomly assigned\nto a conversational interview by either AI or human interviewers, both\nemploying identical questionnaires on political topics. Various quantitative\nand qualitative measures assessed interviewer adherence to guidelines, response\nquality, participant engagement, and overall interview efficacy. The findings\nindicate the viability of AI Conversational Interviewing in producing quality\ndata comparable to traditional methods, with the added benefit of scalability.\nWe publish our data and materials for re-use and present specific\nrecommendations for effective implementation.\n","authors":["Alexander Wuttke","Matthias Aßenmacher","Christopher Klamm","Max M. Lang","Quirin Würschinger","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2410.01824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09206v1","updated":"2025-03-12T09:52:04Z","published":"2025-03-12T09:52:04Z","title":"Robust Asymmetric Heterogeneous Federated Learning with Corrupted\n  Clients","summary":"  This paper studies a challenging robust federated learning task with model\nheterogeneous and data corrupted clients, where the clients have different\nlocal model structures. Data corruption is unavoidable due to factors such as\nrandom noise, compression artifacts, or environmental conditions in real-world\ndeployment, drastically crippling the entire federated system. To address these\nissues, this paper introduces a novel Robust Asymmetric Heterogeneous Federated\nLearning (RAHFL) framework. We propose a Diversity-enhanced supervised\nContrastive Learning technique to enhance the resilience and adaptability of\nlocal models on various data corruption patterns. Its basic idea is to utilize\ncomplex augmented samples obtained by the mixed-data augmentation strategy for\nsupervised contrastive learning, thereby enhancing the ability of the model to\nlearn robust and diverse feature representations. Furthermore, we design an\nAsymmetric Heterogeneous Federated Learning strategy to resist corrupt feedback\nfrom external clients. The strategy allows clients to perform selective one-way\nlearning during collaborative learning phase, enabling clients to refrain from\nincorporating lower-quality information from less robust or underperforming\ncollaborators. Extensive experimental results demonstrate the effectiveness and\nrobustness of our approach in diverse, challenging federated learning\nenvironments. Our code and models are public available at\nhttps://github.com/FangXiuwen/RAHFL.\n","authors":["Xiuwen Fang","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2503.09206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16370v3","updated":"2025-03-12T09:51:17Z","published":"2024-11-25T13:26:09Z","title":"A Review of Bayesian Uncertainty Quantification in Deep Probabilistic\n  Image Segmentation","summary":"  Advancements in image segmentation play an integral role within the broad\nscope of Deep Learning-based Computer Vision. Furthermore, their widespread\napplicability in critical real-world tasks has resulted in challenges related\nto the reliability of such algorithms. Hence, uncertainty quantification has\nbeen extensively studied within this context, enabling the expression of model\nignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to\nprevent uninformed decision-making. Due to the rapid adoption of Convolutional\nNeural Network (CNN)-based segmentation models in high-stake applications, a\nsubstantial body of research has been published on this very topic, causing its\nswift expansion into a distinct field. This work provides a comprehensive\noverview of probabilistic segmentation, by discussing fundamental concepts of\nuncertainty quantification, governing advancements in the field as well as the\napplication to various tasks. Moreover, literature on both types of\nuncertainties trace back to four key applications: (1) to quantify statistical\ninconsistencies in the annotation process due ambiguous images, (2) correlating\nprediction error with uncertainty, (3) expanding the model hypothesis space for\nbetter generalization, and (4) Active Learning. An extensive discussion follows\nthat includes an overview of utilized datasets for each of the applications and\nevaluation of the available methods. We also highlight challenges related to\narchitectures, uncertainty quantification methods, standardization and\nbenchmarking, and finally end with recommendations for future work such as\nmethods based on single forward passes and models that appropriately leverage\nvolumetric data.\n","authors":["M. M. A. Valiuddin","R. J. G. van Sloun","C. G. A. Viviers","P. H. N. de With","F. van der Sommen"],"pdf_url":"https://arxiv.org/pdf/2411.16370v3.pdf","comment":"20 pages, revised"},{"id":"http://arxiv.org/abs/2503.09199v1","updated":"2025-03-12T09:43:48Z","published":"2025-03-12T09:43:48Z","title":"GENEOnet: Statistical analysis supporting explainability and\n  trustworthiness","summary":"  Group Equivariant Non-Expansive Operators (GENEOs) have emerged as\nmathematical tools for constructing networks for Machine Learning and\nArtificial Intelligence. Recent findings suggest that such models can be\ninserted within the domain of eXplainable Artificial Intelligence (XAI) due to\ntheir inherent interpretability. In this study, we aim to verify this claim\nwith respect to GENEOnet, a GENEO network developed for an application in\ncomputational biochemistry by employing various statistical analyses and\nexperiments. Such experiments first allow us to perform a sensitivity analysis\non GENEOnet's parameters to test their significance. Subsequently, we show that\nGENEOnet exhibits a significantly higher proportion of equivariance compared to\nother methods. Lastly, we demonstrate that GENEOnet is on average robust to\nperturbations arising from molecular dynamics. These results collectively serve\nas proof of the explainability, trustworthiness, and robustness of GENEOnet and\nconfirm the beneficial use of GENEOs in the context of Trustworthy Artificial\nIntelligence.\n","authors":["Giovanni Bocchi","Patrizio Frosini","Alessandra Micheletti","Alessandro Pedretti","Carmen Gratteri","Filippo Lunghini","Andrea Rosario Beccari","Carmine Talarico"],"pdf_url":"https://arxiv.org/pdf/2503.09199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17954v2","updated":"2025-03-12T09:42:19Z","published":"2024-09-26T15:30:54Z","title":"Enhancing elusive clues in knowledge learning by contrasting attention\n  of language models","summary":"  Causal language models acquire vast amount of knowledge from general text\ncorpus during pretraining, but the efficiency of knowledge learning is known to\nbe unsatisfactory, especially when learning from knowledge-dense and\nsmall-sized corpora. The deficiency can come from long-distance dependencies\nwhich are hard to capture by language models, and overfitting to co-occurrence\npatterns and distracting clues in the training text. To address these issues,\nthe paper proposes a method to enhance knowledge learning during language model\npretraining, by enhancing elusive but important clues in text discovered by the\nlanguage model themselves. We found that larger language models pay more\nattention to non-obvious but important clues, which are often overlooked by\nsmaller language models. Therefore, we can identify these clues by contrasting\nthe attention weights of large and small language models. We use the identified\nclues as a guide to perform token-dropout data augmentation on the training\ntext, and observed a significant boost in both small and large models'\nperformance in fact memorization. This shows that the behavior contrast between\nmore and less-performant language models contains important clues for knowledge\nlearning, and it can be ``amplified\" for a straight-forward improvement in\nknowledge learning efficiency.\n","authors":["Jian Gao","Xiao Zhang","Ji Wu","Miao Li"],"pdf_url":"https://arxiv.org/pdf/2409.17954v2.pdf","comment":"Oral presentation in AAAI 2025"},{"id":"http://arxiv.org/abs/2411.10224v2","updated":"2025-03-12T09:38:02Z","published":"2024-11-15T14:38:13Z","title":"EVOKE: Elevating Chest X-ray Report Generation via Multi-View\n  Contrastive Learning and Patient-Specific Knowledge","summary":"  Radiology reports are crucial for planning treatment strategies and\nfacilitating effective doctor-patient communication. However, the manual\ncreation of these reports places a significant burden on radiologists. While\nautomatic radiology report generation presents a promising solution, existing\nmethods often rely on single-view radiographs, which constrain diagnostic\naccuracy. To address this challenge, we propose \\textbf{EVOKE}, a novel chest\nX-ray report generation framework that incorporates multi-view contrastive\nlearning and patient-specific knowledge. Specifically, we introduce a\nmulti-view contrastive learning method that enhances visual representation by\naligning multi-view radiographs with their corresponding report. After that, we\npresent a knowledge-guided report generation module that integrates available\npatient-specific indications (e.g., symptom descriptions) to trigger the\nproduction of accurate and coherent radiology reports. To support research in\nmulti-view report generation, we construct Multi-view CXR and Two-view CXR\ndatasets using publicly available sources. Our proposed EVOKE surpasses recent\nstate-of-the-art methods across multiple datasets, achieving a 2.9\\%\nF\\textsubscript{1} RadGraph improvement on MIMIC-CXR, a 7.3\\% BLEU-1\nimprovement on MIMIC-ABN, a 3.1\\% BLEU-4 improvement on Multi-view CXR, and an\n8.2\\% F\\textsubscript{1,mic-14} CheXbert improvement on Two-view CXR.\n","authors":["Qiguang Miao","Kang Liu","Zhuoqi Ma","Yunan Li","Xiaolu Kang","Ruixuan Liu","Tianyi Liu","Kun Xie","Zhicheng Jiao"],"pdf_url":"https://arxiv.org/pdf/2411.10224v2.pdf","comment":"The code is available at https://github.com/mk-runner/EVOKE"},{"id":"http://arxiv.org/abs/2503.08460v2","updated":"2025-03-12T09:30:52Z","published":"2025-03-11T14:08:57Z","title":"Status and Future Prospects of the Standardization Framework Industry\n  4.0: A European Perspective","summary":"  The rapid development of Industry 4.0 technologies requires robust and\ncomprehensive standardization to ensure interoperability, safety and efficiency\nin the Industry of the Future. This paper examines the fundamental role and\nfunctionality of standardization, with a particular focus on its importance in\nEurope's regulatory framework. Based on this, selected topics in context of\nstandardization activities in context intelligent manufacturing and digital\ntwins are highlighted and, by that, an overview of the Industry 4.0 standards\nframework is provided. This paper serves both as an informative guide to the\nexisting standards in Industry 4.0 with respect to Artificial Intelligence and\nDigital Twins, and as a call to action for increased cooperation between\nstandardization bodies and the research community. By fostering such\ncollaboration, we aim to facilitate the continued development and\nimplementation of standards that will drive innovation and progress in the\nmanufacturing sector.\n","authors":["Olga Meyer","Marvin Boell","Christoph Legat"],"pdf_url":"https://arxiv.org/pdf/2503.08460v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08581v2","updated":"2025-03-12T09:27:31Z","published":"2025-03-11T16:16:44Z","title":"MsaMIL-Net: An End-to-End Multi-Scale Aware Multiple Instance Learning\n  Network for Efficient Whole Slide Image Classification","summary":"  Bag-based Multiple Instance Learning (MIL) approaches have emerged as the\nmainstream methodology for Whole Slide Image (WSI) classification. However,\nmost existing methods adopt a segmented training strategy, which first extracts\nfeatures using a pre-trained feature extractor and then aggregates these\nfeatures through MIL. This segmented training approach leads to insufficient\ncollaborative optimization between the feature extraction network and the MIL\nnetwork, preventing end-to-end joint optimization and thereby limiting the\noverall performance of the model. Additionally, conventional methods typically\nextract features from all patches of fixed size, ignoring the multi-scale\nobservation characteristics of pathologists. This not only results in\nsignificant computational resource waste when tumor regions represent a minimal\nproportion (as in the Camelyon16 dataset) but may also lead the model to\nsuboptimal solutions.\n  To address these limitations, this paper proposes an end-to-end multi-scale\nWSI classification framework that integrates multi-scale feature extraction\nwith multiple instance learning. Specifically, our approach includes: (1) a\nsemantic feature filtering module to reduce interference from non-lesion areas;\n(2) a multi-scale feature extraction module to capture pathological information\nat different levels; and (3) a multi-scale fusion MIL module for global\nmodeling and feature integration. Through an end-to-end training strategy, we\nsimultaneously optimize both the feature extractor and MIL network, ensuring\nmaximum compatibility between them.\n  Experiments were conducted on three cross-center datasets (DigestPath2019,\nBCNB, and UBC-OCEAN). Results demonstrate that our proposed method outperforms\nexisting state-of-the-art approaches in terms of both accuracy (ACC) and AUC\nmetrics.\n","authors":["Jiangping Wen","Jinyu Wen","Meie Fang"],"pdf_url":"https://arxiv.org/pdf/2503.08581v2.pdf","comment":"summited to ICCV2025"},{"id":"http://arxiv.org/abs/2410.10815v2","updated":"2025-03-12T09:16:59Z","published":"2024-10-14T17:59:46Z","title":"Depth Any Video with Scalable Synthetic Data","summary":"  Video depth estimation has long been hindered by the scarcity of consistent\nand scalable ground truth data, leading to inconsistent and unreliable results.\nIn this paper, we introduce Depth Any Video, a model that tackles the challenge\nthrough two key innovations. First, we develop a scalable synthetic data\npipeline, capturing real-time video depth data from diverse virtual\nenvironments, yielding 40,000 video clips of 5-second duration, each with\nprecise depth annotations. Second, we leverage the powerful priors of\ngenerative video diffusion models to handle real-world videos effectively,\nintegrating advanced techniques such as rotary position encoding and flow\nmatching to further enhance flexibility and efficiency. Unlike previous models,\nwhich are limited to fixed-length video sequences, our approach introduces a\nnovel mixed-duration training strategy that handles videos of varying lengths\nand performs robustly across different frame rates-even on single frames. At\ninference, we propose a depth interpolation method that enables our model to\ninfer high-resolution video depth across sequences of up to 150 frames. Our\nmodel outperforms all previous generative depth models in terms of spatial\naccuracy and temporal consistency. The code and model weights are open-sourced.\n","authors":["Honghui Yang","Di Huang","Wei Yin","Chunhua Shen","Haifeng Liu","Xiaofei He","Binbin Lin","Wanli Ouyang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2410.10815v2.pdf","comment":"Project Page: https://depthanyvideo.github.io/"},{"id":"http://arxiv.org/abs/2405.04620v4","updated":"2025-03-12T09:13:15Z","published":"2024-05-07T19:05:26Z","title":"Folded Context Condensation in Path Integral Formalism for Infinite\n  Context Transformers","summary":"  In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.\n","authors":["Won-Gi Paeng","Daesuk Kwon","Kyungwon Jeong","Honggyo Suh"],"pdf_url":"https://arxiv.org/pdf/2405.04620v4.pdf","comment":"10 pages, 12 figures"},{"id":"http://arxiv.org/abs/2411.17489v2","updated":"2025-03-12T09:04:43Z","published":"2024-11-26T14:57:30Z","title":"Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for\n  Artifact Detection in 3D Scene Reconstructions","summary":"  Modern reconstruction techniques can effectively model complex 3D scenes from\nsparse 2D views. However, automatically assessing the quality of novel views\nand identifying artifacts is challenging due to the lack of ground truth images\nand the limitations of No-Reference image metrics in predicting reliable\nartifact maps. The absence of such metrics hinders the assessment of the\nquality of novel views and limits the adoption of post-processing techniques,\nsuch as inpainting, to enhance reconstruction quality. To tackle this, recent\nwork has established a new category of metrics (Cross-Reference), predicting\nimage quality solely by leveraging context from alternate viewpoint captures\n(arXiv:2404.14409). In this work, we propose a new Cross-Reference metric,\nPuzzle Similarity, which is designed to localize artifacts in novel views. Our\napproach utilizes image patch statistics from the input views to establish a\nscene-specific distribution, later used to identify poorly reconstructed\nregions in the novel views. Given the lack of good measures to evaluate\nCross-Reference methods in the context of 3D reconstruction, we collected a\nnovel human-labeled dataset of artifact and distortion maps in unseen\nreconstructed views. Through this dataset, we demonstrate that our method\nachieves state-of-the-art localization of artifacts in novel views, correlating\nwith human assessment, even without aligned references. We can leverage our new\nmetric to enhance applications like automatic image restoration, guided\nacquisition, or 3D reconstruction from sparse inputs. Find the project page at\nhttps://nihermann.github.io/puzzlesim/ .\n","authors":["Nicolai Hermann","Jorge Condor","Piotr Didyk"],"pdf_url":"https://arxiv.org/pdf/2411.17489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09173v1","updated":"2025-03-12T09:00:45Z","published":"2025-03-12T09:00:45Z","title":"Long-Term Planning Around Humans in Domestic Environments with 3D Scene\n  Graphs","summary":"  Long-term planning for robots operating in domestic environments poses unique\nchallenges due to the interactions between humans, objects, and spaces. Recent\nadvancements in trajectory planning have leveraged vision-language models\n(VLMs) to extract contextual information for robots operating in real-world\nenvironments. While these methods achieve satisfying performance, they do not\nexplicitly model human activities. Such activities influence surrounding\nobjects and reshape spatial constraints. This paper presents a novel approach\nto trajectory planning that integrates human preferences, activities, and\nspatial context through an enriched 3D scene graph (3DSG) representation. By\nincorporating activity-based relationships, our method captures the spatial\nimpact of human actions, leading to more context-sensitive trajectory\nadaptation. Preliminary results demonstrate that our approach effectively\nassigns costs to spaces influenced by human activities, ensuring that the robot\ntrajectory remains contextually appropriate and sensitive to the ongoing\nenvironment. This balance between task efficiency and social appropriateness\nenhances context-aware human-robot interactions in domestic settings. Future\nwork includes implementing a full planning pipeline and conducting user studies\nto evaluate trajectory acceptability.\n","authors":["Ermanno Bartoli","Dennis Rotondi","Kai O. Arras","Iolanda Leite"],"pdf_url":"https://arxiv.org/pdf/2503.09173v1.pdf","comment":"5 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2408.05117v2","updated":"2025-03-12T08:58:41Z","published":"2024-08-09T15:10:34Z","title":"Beyond the Eye: A Relational Model for Early Dementia Detection Using\n  Retinal OCTA Images","summary":"  Early detection of dementia, such as Alzheimer's disease (AD) or mild\ncognitive impairment (MCI), is essential to enable timely intervention and\npotential treatment. Accurate detection of AD/MCI is challenging due to the\nhigh complexity, cost, and often invasive nature of current diagnostic\ntechniques, which limit their suitability for large-scale population screening.\nGiven the shared embryological origins and physiological characteristics of the\nretina and brain, retinal imaging is emerging as a potentially rapid and\ncost-effective alternative for the identification of individuals with or at\nhigh risk of AD. In this paper, we present a novel PolarNet+ that uses retinal\noptical coherence tomography angiography (OCTA) to discriminate early-onset AD\n(EOAD) and MCI subjects from controls. Our method first maps OCTA images from\nCartesian coordinates to polar coordinates, allowing approximate sub-region\ncalculation to implement the clinician-friendly early treatment of diabetic\nretinopathy study (ETDRS) grid analysis. We then introduce a multi-view module\nto serialize and analyze the images along three dimensions for comprehensive,\nclinically useful information extraction. Finally, we abstract the sequence\nembedding into a graph, transforming the detection task into a general graph\nclassification problem. A regional relationship module is applied after the\nmulti-view module to excavate the relationship between the sub-regions. Such\nregional relationship analyses validate known eye-brain links and reveal new\ndiscriminative patterns.\n","authors":["Shouyue Liu","Ziyi Zhang","Yuanyuan Gu","Jinkui Hao","Yonghuai Liu","Huazhu Fu","Xinyu Guo","Hong Song","Shuting Zhang","Yitian Zhao"],"pdf_url":"https://arxiv.org/pdf/2408.05117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01478v4","updated":"2025-03-12T08:49:58Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v4.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.09164v1","updated":"2025-03-12T08:49:03Z","published":"2025-03-12T08:49:03Z","title":"AI-Driven Decision Support in Oncology: Evaluating Data Readiness for\n  Skin Cancer Treatment","summary":"  This research focuses on evaluating and enhancing data readiness for the\ndevelopment of an Artificial Intelligence (AI)-based Clinical Decision Support\nSystem (CDSS) in the context of skin cancer treatment. The study, conducted at\nthe Skin Tumor Center of the University Hospital M\\\"unster, delves into the\nessential role of data quality, availability, and extractability in\nimplementing effective AI applications in oncology. By employing a multifaceted\nmethodology, including literature review, data readiness assessment, and expert\nworkshops, the study addresses the challenges of integrating AI into clinical\ndecision-making. The research identifies crucial data points for skin cancer\ntreatment decisions, evaluates their presence and quality in various\ninformation systems, and highlights the difficulties in extracting information\nfrom unstructured data. The findings underline the significance of\nhigh-quality, accessible data for the success of AI-driven CDSS in medical\nsettings, particularly in the complex field of oncology.\n","authors":["Joscha Grüger","Tobias Geyer","Tobias Brix","Michael Storck","Sonja Leson","Laura Bley","Carsten Weishaupt","Ralph Bergmann","Stephan A. Braun"],"pdf_url":"https://arxiv.org/pdf/2503.09164v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12106v2","updated":"2025-03-12T08:48:46Z","published":"2025-01-21T12:56:47Z","title":"Can open source large language models be used for tumor documentation in\n  Germany? -- An evaluation on urological doctors' notes","summary":"  Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.\n","authors":["Stefan Lenz","Arsenij Ustjanzew","Marco Jeray","Torsten Panholzer"],"pdf_url":"https://arxiv.org/pdf/2501.12106v2.pdf","comment":"48 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.08179v2","updated":"2025-03-12T08:46:33Z","published":"2025-03-11T08:43:05Z","title":"ProtTeX: Structure-In-Context Reasoning and Editing of Proteins with\n  Large Language Models","summary":"  Large language models have made remarkable progress in the field of molecular\nscience, particularly in understanding and generating functional small\nmolecules. This success is largely attributed to the effectiveness of molecular\ntokenization strategies. In protein science, the amino acid sequence serves as\nthe sole tokenizer for LLMs. However, many fundamental challenges in protein\nscience are inherently structure-dependent. The absence of structure-aware\ntokens significantly limits the capabilities of LLMs for comprehensive\nbiomolecular comprehension and multimodal generation. To address these\nchallenges, we introduce a novel framework, ProtTeX, which tokenizes the\nprotein sequences, structures, and textual information into a unified discrete\nspace. This innovative approach enables joint training of the LLM exclusively\nthrough the Next-Token Prediction paradigm, facilitating multimodal protein\nreasoning and generation. ProtTeX enables general LLMs to perceive and process\nprotein structures through sequential text input, leverage structural\ninformation as intermediate reasoning components, and generate or manipulate\nstructures via sequential text output. Experiments demonstrate that our model\nachieves significant improvements in protein function prediction, outperforming\nthe state-of-the-art domain expert model with a twofold increase in accuracy.\nOur framework enables high-quality conformational generation and customizable\nprotein design. For the first time, we demonstrate that by adopting the\nstandard training and inference pipelines from the LLM domain, ProtTeX empowers\ndecoder-only LLMs to effectively address diverse spectrum of protein-related\ntasks.\n","authors":["Zicheng Ma","Chuanliu Fan","Zhicong Wang","Zhenyu Chen","Xiaohan Lin","Yanheng Li","Shihao Feng","Jun Zhang","Ziqiang Cao","Yi Qin Gao"],"pdf_url":"https://arxiv.org/pdf/2503.08179v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2402.17516v4","updated":"2025-03-12T08:31:10Z","published":"2024-02-27T14:00:08Z","title":"QUCE: The Minimisation and Quantification of Path-Based Uncertainty for\n  Generative Counterfactual Explanations","summary":"  Deep Neural Networks (DNNs) stand out as one of the most prominent approaches\nwithin the Machine Learning (ML) domain. The efficacy of DNNs has surged\nalongside recent increases in computational capacity, allowing these approaches\nto scale to significant complexities for addressing predictive challenges in\nbig data. However, as the complexity of DNN models rises, interpretability\ndiminishes. In response to this challenge, explainable models such as\nAdversarial Gradient Integration (AGI) leverage path-based gradients provided\nby DNNs to elucidate their decisions. Yet the performance of path-based\nexplainers can be compromised when gradients exhibit irregularities during\nout-of-distribution path traversal. In this context, we introduce Quantified\nUncertainty Counterfactual Explanations (QUCE), a method designed to mitigate\nout-of-distribution traversal by minimizing path uncertainty. QUCE not only\nquantifies uncertainty when presenting explanations but also generates more\ncertain counterfactual examples. We showcase the performance of the QUCE method\nby comparing it with competing methods for both path-based explanations and\ngenerative counterfactual examples.\n","authors":["Jamie Duell","Monika Seisenberger","Hsuan Fu","Xiuyi Fan"],"pdf_url":"https://arxiv.org/pdf/2402.17516v4.pdf","comment":"Final version published in ICDM 2024, International Conference on\n  Data Mining"},{"id":"http://arxiv.org/abs/2503.09153v1","updated":"2025-03-12T08:29:59Z","published":"2025-03-12T08:29:59Z","title":"Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News\n  Detection","summary":"  The questionable responses caused by knowledge hallucination may lead to\nLLMs' unstable ability in decision-making. However, it has never been\ninvestigated whether the LLMs' hallucination is possibly usable to generate\nnegative reasoning for facilitating the detection of fake news. This study\nproposes a novel supervised self-reinforced reasoning rectification approach -\nSR$^3$ that yields both common reasonable reasoning and wrong understandings\n(negative reasoning) for news via LLMs reflection for semantic consistency\nlearning. Upon that, we construct a negative reasoning-based news learning\nmodel called - \\emph{NRFE}, which leverages positive or negative news-reasoning\npairs for learning the semantic consistency between them. To avoid the impact\nof label-implicated reasoning, we deploy a student model - \\emph{NRFE-D} that\nonly takes news content as input to inspect the performance of our method by\ndistilling the knowledge from \\emph{NRFE}. The experimental results verified on\nthree popular fake news datasets demonstrate the superiority of our method\ncompared with three kinds of baselines including prompting on LLMs, fine-tuning\non pre-trained SLMs, and other representative fake news detection methods.\n","authors":["Chaowei Zhang","Zongling Feng","Zewei Zhang","Jipeng Qiang","Guandong Xu","Yun Li"],"pdf_url":"https://arxiv.org/pdf/2503.09153v1.pdf","comment":"9 pages, 12 figures, conference"},{"id":"http://arxiv.org/abs/2503.09151v1","updated":"2025-03-12T08:26:15Z","published":"2025-03-12T08:26:15Z","title":"Reangle-A-Video: 4D Video Generation as Video-to-Video Translation","summary":"  We introduce Reangle-A-Video, a unified framework for generating synchronized\nmulti-view videos from a single input video. Unlike mainstream approaches that\ntrain multi-view video diffusion models on large-scale 4D datasets, our method\nreframes the multi-view video generation task as video-to-videos translation,\nleveraging publicly available image and video diffusion priors. In essence,\nReangle-A-Video operates in two stages. (1) Multi-View Motion Learning: An\nimage-to-video diffusion transformer is synchronously fine-tuned in a\nself-supervised manner to distill view-invariant motion from a set of warped\nvideos. (2) Multi-View Consistent Image-to-Images Translation: The first frame\nof the input video is warped and inpainted into various camera perspectives\nunder an inference-time cross-view consistency guidance using DUSt3R,\ngenerating multi-view consistent starting images. Extensive experiments on\nstatic view transport and dynamic camera control show that Reangle-A-Video\nsurpasses existing methods, establishing a new solution for multi-view video\ngeneration. We will publicly release our code and data. Project page:\nhttps://hyeonho99.github.io/reangle-a-video/\n","authors":["Hyeonho Jeong","Suhyeon Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2503.09151v1.pdf","comment":"Project page: https://hyeonho99.github.io/reangle-a-video/"},{"id":"http://arxiv.org/abs/2503.09144v1","updated":"2025-03-12T08:13:39Z","published":"2025-03-12T08:13:39Z","title":"Efficient UAV Swarm-Based Multi-Task Federated Learning with Dynamic\n  Task Knowledge Sharing","summary":"  UAV swarms are widely used in emergency communications, area monitoring, and\ndisaster relief. Coordinated by control centers, they are ideal for federated\nlearning (FL) frameworks. However, current UAV-assisted FL methods primarily\nfocus on single tasks, overlooking the need for multi-task training. In\ndisaster relief scenarios, UAVs perform tasks such as crowd detection, road\nfeasibility analysis, and disaster assessment, which exhibit time-varying\ndemands and potential correlations. In order to meet the time-varying\nrequirements of tasks and complete multiple tasks efficiently under resource\nconstraints, in this paper, we propose a UAV swarm based multi-task FL\nframework, where ground emergency vehicles (EVs) collaborate with UAVs to\naccomplish multiple tasks efficiently under constrained energy and bandwidth\nresources. Through theoretical analysis, we identify key factors affecting task\nperformance and introduce a task attention mechanism to dynamically evaluate\ntask importance, thereby achieving efficient resource allocation. Additionally,\nwe propose a task affinity (TA) metric to capture the dynamic correlation among\ntasks, thereby promoting task knowledge sharing to accelerate training and\nimprove the generalization ability of the model in different scenarios. To\noptimize resource allocation, we formulate a two-layer optimization problem to\njointly optimize UAV transmission power, computation frequency, bandwidth\nallocation, and UAV-EV associations. For the inner problem, we derive\nclosed-form solutions for transmission power, computation frequency, and\nbandwidth allocation and apply a block coordinate descent method for\noptimization. For the outer problem, a two-stage algorithm is designed to\ndetermine optimal UAV-EV associations. Furthermore, theoretical analysis\nreveals a trade-off between UAV energy consumption and multi-task performance.\n","authors":["Yubo Yang","Tao Yang","Xiaofeng Wu","Ziyu Guo","Bo Hu"],"pdf_url":"https://arxiv.org/pdf/2503.09144v1.pdf","comment":"Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file"},{"id":"http://arxiv.org/abs/2402.03848v9","updated":"2025-03-12T08:02:54Z","published":"2024-02-06T09:50:08Z","title":"ANLS* -- A Universal Document Processing Metric for Generative Large\n  Language Models","summary":"  Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, and more than 20 different GLLMs\ntogether with 3 different prompting methods using the ANLS* metric is also\nprovided, demonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In almost all cases, SFT\noutperforms other techniques and improves the state-of-the-art, sometimes by as\nmuch as $10$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric\n","authors":["David Peer","Philemon Schöpf","Volckmar Nebendahl","Alexander Rietzler","Sebastian Stabinger"],"pdf_url":"https://arxiv.org/pdf/2402.03848v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03199v4","updated":"2025-03-12T07:57:44Z","published":"2024-05-24T13:33:11Z","title":"Bayesian WeakS-to-Strong from Text Classification to Generation","summary":"  Advances in large language models raise the question of how alignment\ntechniques will adapt as models become increasingly complex and humans will\nonly be able to supervise them weakly. Weak-to-Strong mimics such a scenario\nwhere weak model supervision attempts to harness the full capabilities of a\nmuch stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by\nexploring an ensemble of weak models which simulate the variability in human\nopinions. Confidence scores are estimated using a Bayesian approach to guide\nthe WeakS-to-Strong generalization. Furthermore, we extend the application of\nWeakS-to-Strong from text classification tasks to text generation tasks where\nmore advanced strategies are investigated for supervision. Moreover, direct\npreference optimization is applied to advance the student model's preference\nlearning, beyond the basic learning framework of teacher forcing. Results\ndemonstrate the effectiveness of the proposed approach for the reliability of a\nstrong student model, showing potential for superalignment.\n","authors":["Ziyun Cui","Ziyang Zhang","Guangzhi Sun","Wen Wu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.03199v4.pdf","comment":"Accepted by ICLR2025"},{"id":"http://arxiv.org/abs/2503.09132v1","updated":"2025-03-12T07:42:15Z","published":"2025-03-12T07:42:15Z","title":"Investigation of Frame Differences as Motion Cues for Video Object\n  Segmentation","summary":"  Automatic Video Object Segmentation (AVOS) refers to the task of autonomously\nsegmenting target objects in video sequences without relying on human-provided\nannotations in the first frames. In AVOS, the use of motion information is\ncrucial, with optical flow being a commonly employed method for capturing\nmotion cues. However, the computation of optical flow is resource-intensive,\nmaking it unsuitable for real-time applications, especially on edge devices\nwith limited computational resources. In this study, we propose using frame\ndifferences as an alternative to optical flow for motion cue extraction. We\ndeveloped an extended U-Net-like AVOS model that takes a frame on which\nsegmentation is performed and a frame difference as inputs, and outputs an\nestimated segmentation map. Our experimental results demonstrate that the\nproposed model achieves performance comparable to the model with optical flow\nas an input, particularly when applied to videos captured by stationary\ncameras. Our results suggest the usefulness of employing frame differences as\nmotion cues in cases with limited computational resources.\n","authors":["Sota Kawamura","Hirotada Honda","Shugo Nakamura","Takashi Sano"],"pdf_url":"https://arxiv.org/pdf/2503.09132v1.pdf","comment":"8 pages, 3 figures, 2 tables. Accepted to The 9th International\n  Conference on Machine Learning and Soft Computing (ICMLSC 2025)"},{"id":"http://arxiv.org/abs/2503.02233v2","updated":"2025-03-12T07:42:04Z","published":"2025-03-04T03:16:02Z","title":"Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling","summary":"  Large language models (LLMs) frequently hallucinate due to misaligned\nself-awareness, generating erroneous outputs when addressing queries beyond\ntheir knowledge boundaries. While existing approaches mitigate hallucinations\nvia uncertainty estimation or query rejection, they suffer from computational\ninefficiency or sacrificed helpfulness. To address these issues, we propose the\nExplicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and\nslow reasoning systems to harmonize reliability and usability. The framework\nfirst employs a fast-thinking model to generate confidence-labeled responses,\nenabling immediate use of high-confidence outputs. For uncertain predictions, a\nslow refinement model conducts targeted reasoning to improve accuracy. To align\nmodel behavior with our proposed object, we propose a hybrid training pipeline,\nenhancing self-awareness without degrading task performance. Evaluations on\ndialogue state tracking tasks demonstrate that EKBM achieves superior model\nreliability over uncertainty-based baselines. Further analysis reveals that\nrefinement substantially boosts accuracy while maintaining low computational\noverhead. Our work establishes a scalable paradigm for advancing LLM\nreliability and balancing accuracy and practical utility in error-sensitive\napplications.\n","authors":["Hang Zheng","Hongshen Xu","Yuncong Liu","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02233v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09120v1","updated":"2025-03-12T07:12:34Z","published":"2025-03-12T07:12:34Z","title":"On the Internal Representations of Graph Metanetworks","summary":"  Weight space learning is an emerging paradigm in the deep learning community.\nThe primary goal of weight space learning is to extract informative features\nfrom a set of parameters using specially designed neural networks, often\nreferred to as \\emph{metanetworks}. However, it remains unclear how these\nmetanetworks learn solely from parameters. To address this, we take the first\nstep toward understanding \\emph{representations} of metanetworks, specifically\ngraph metanetworks (GMNs), which achieve state-of-the-art results in this\nfield, using centered kernel alignment (CKA). Through various experiments, we\nreveal that GMNs and general neural networks (\\textit{e.g.,} multi-layer\nperceptrons (MLPs) and convolutional neural networks (CNNs)) differ in terms of\ntheir representation space.\n","authors":["Taesun Yeom","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2503.09120v1.pdf","comment":"ICLR 2025 Workshop on Weight Space Learning"},{"id":"http://arxiv.org/abs/2503.09114v1","updated":"2025-03-12T07:01:34Z","published":"2025-03-12T07:01:34Z","title":"Sometimes Painful but Certainly Promising: Feasibility and Trade-offs of\n  Language Model Inference at the Edge","summary":"  The rapid rise of Language Models (LMs) has expanded the capabilities of\nnatural language processing, powering applications from text generation to\ncomplex decision-making. While state-of-the-art LMs often boast hundreds of\nbillions of parameters and are primarily deployed in data centers, recent\ntrends show a growing focus on compact models-typically under 10 billion\nparameters-enabled by techniques such as quantization and other model\ncompression techniques. This shift paves the way for LMs on edge devices,\noffering potential benefits such as enhanced privacy, reduced latency, and\nimproved data sovereignty. However, the inherent complexity of even these\nsmaller models, combined with the limited computing resources of edge hardware,\nraises critical questions about the practical trade-offs in executing LM\ninference outside the cloud. To address these challenges, we present a\ncomprehensive evaluation of generative LM inference on representative CPU-based\nand GPU-accelerated edge devices. Our study measures key performance\nindicators-including memory usage, inference speed, and energy\nconsumption-across various device configurations. Additionally, we examine\nthroughput-energy trade-offs, cost considerations, and usability, alongside an\nassessment of qualitative model performance. While quantization helps mitigate\nmemory overhead, it does not fully eliminate resource bottlenecks, especially\nfor larger models. Our findings quantify the memory and energy constraints that\nmust be considered for practical real-world deployments, offering concrete\ninsights into the trade-offs between model size, inference performance, and\nefficiency. The exploration of LMs at the edge is still in its early stages. We\nhope this study provides a foundation for future research, guiding the\nrefinement of models, the enhancement of inference efficiency, and the\nadvancement of edge-centric AI systems.\n","authors":["Maximilian Abstreiter","Sasu Tarkoma","Roberto Morabito"],"pdf_url":"https://arxiv.org/pdf/2503.09114v1.pdf","comment":"This paper is currently under review for publication in an ACM\n  journal. If accepted, the copyright will be transferred to ACM"},{"id":"http://arxiv.org/abs/2503.09113v1","updated":"2025-03-12T07:01:27Z","published":"2025-03-12T07:01:27Z","title":"Constraint-Guided Learning of Data-driven Health Indicator Models: An\n  Application on the Pronostia Bearing Dataset","summary":"  This paper presents a constraint-guided deep learning framework for\ndeveloping physically consistent health indicators in bearing prognostics and\nhealth management. Conventional data-driven methods often lack physical\nplausibility, while physics-based models are limited by incomplete system\nknowledge. To address this, we integrate domain knowledge into deep learning\nusing constraints to enforce monotonicity, bound output values between 1 and 0\n(representing healthy to failed states), and ensure consistency between signal\nenergy trends and health indicator estimates. This eliminates the need for\ncomplex loss term balancing. We implement constraint-guided gradient descent\nwithin an autoencoder architecture, creating a constrained autoencoder.\nHowever, the framework is adaptable to other architectures. Using\ntime-frequency representations of accelerometer signals from the Pronostia\ndataset, our constrained model generates smoother, more reliable degradation\nprofiles compared to conventional methods, aligning with expected physical\nbehavior. Performance is assessed using three metrics: trendability,\nrobustness, and consistency. Compared to a conventional baseline, the\nconstrained model improves all three. Another baseline, incorporating\nmonotonicity via a soft-ranking loss function, outperforms in trendability but\nfalls short in robustness and consistency. An ablation study confirms that the\nmonotonicity constraint enhances trendability, the boundary constraint ensures\nconsistency, and the energy-health consistency constraint improves robustness.\nThese findings highlight the effectiveness of constraint-guided deep learning\nin producing reliable, physically meaningful health indicators, offering a\npromising direction for future prognostic applications.\n","authors":["Yonas Tefera","Quinten Van Baelen","Maarten Meire","Stijn Luca","Peter Karsmakers"],"pdf_url":"https://arxiv.org/pdf/2503.09113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14997v4","updated":"2025-03-12T06:59:50Z","published":"2022-11-28T01:51:16Z","title":"A Comprehensive Survey on Enterprise Financial Risk Analysis from Big\n  Data Perspective","summary":"  Enterprise financial risk analysis aims at predicting the future financial\nrisk of enterprises. Due to its wide and significant application, enterprise\nfinancial risk analysis has always been the core research topic in the fields\nof Finance and Management. Based on advanced computer science and artificial\nintelligence technologies, enterprise risk analysis research is experiencing\nrapid developments and making significant progress. Therefore, it is both\nnecessary and challenging to comprehensively review the relevant studies.\nAlthough there are already some valuable and impressive surveys on enterprise\nrisk analysis from the perspective of Finance and Management, these surveys\nintroduce approaches in a relatively isolated way and lack recent advances in\nenterprise financial risk analysis. In contrast, this paper attempts to provide\na systematic literature survey of enterprise risk analysis approaches from Big\nData perspective, which reviews more than 250 representative articles in the\npast almost 50 years (from 1968 to 2023). To the best of our knowledge, this is\nthe first and only survey work on enterprise financial risk from Big Data\nperspective. Specifically, this survey connects and systematizes the existing\nenterprise financial risk studies, i.e. to summarize and interpret the\nproblems, methods, and spotlights in a comprehensive way. In particular, we\nfirst introduce the issues of enterprise financial risks in terms of their\ntypes,granularity, intelligence, and evaluation metrics, and summarize the\ncorresponding representative works. Then, we compare the analysis methods used\nto learn enterprise financial risk, and finally summarize the spotlights of the\nmost representative works. Our goal is to clarify current cutting-edge research\nand its possible future directions to model enterprise risk, aiming to fully\nunderstand the mechanisms of enterprise risk generation and contagion.\n","authors":["Huaming Du","Xingyan Chen","Yu Zhao","Qing Li","Fuzhen Zhuang","Fuji Ren","Gang Kou"],"pdf_url":"https://arxiv.org/pdf/2211.14997v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09106v1","updated":"2025-03-12T06:46:32Z","published":"2025-03-12T06:46:32Z","title":"Freeze and Cluster: A Simple Baseline for Rehearsal-Free Continual\n  Category Discovery","summary":"  This paper addresses the problem of Rehearsal-Free Continual Category\nDiscovery (RF-CCD), which focuses on continuously identifying novel class by\nleveraging knowledge from labeled data. Existing methods typically train from\nscratch, overlooking the potential of base models, and often resort to data\nstorage to prevent forgetting. Moreover, because RF-CCD encompasses both\ncontinual learning and novel class discovery, previous approaches have\nstruggled to effectively integrate advanced techniques from these fields,\nresulting in less convincing comparisons and failing to reveal the unique\nchallenges posed by RF-CCD. To address these challenges, we lead the way in\nintegrating advancements from both domains and conducting extensive experiments\nand analyses. Our findings demonstrate that this integration can achieve\nstate-of-the-art results, leading to the conclusion that in the presence of\npre-trained models, the representation does not improve and may even degrade\nwith the introduction of unlabeled data. To mitigate representation\ndegradation, we propose a straightforward yet highly effective baseline method.\nThis method first utilizes prior knowledge of known categories to estimate the\nnumber of novel classes. It then acquires representations using a model\nspecifically trained on the base classes, generates high-quality pseudo-labels\nthrough k-means clustering, and trains only the classifier layer. We validate\nour conclusions and methods by conducting extensive experiments across multiple\nbenchmarks, including the Stanford Cars, CUB, iNat, and Tiny-ImageNet datasets.\nThe results clearly illustrate our findings, demonstrate the effectiveness of\nour baseline, and pave the way for future advancements in RF-CCD.\n","authors":["Chuyu Zhang","Xueyang Yu","Peiyan Gu","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2503.09106v1.pdf","comment":"Underreview"},{"id":"http://arxiv.org/abs/2503.09101v1","updated":"2025-03-12T06:37:43Z","published":"2025-03-12T06:37:43Z","title":"The Shape of Attraction in UMAP: Exploring the Embedding Forces in\n  Dimensionality Reduction","summary":"  Uniform manifold approximation and projection (UMAP) is among the most\npopular neighbor embedding methods. The method relies on attractive and\nrepulsive forces among high-dimensional data points to obtain a low-dimensional\nembedding. In this paper, we analyze the forces to reveal their effects on\ncluster formations and visualization. Repulsion emphasizes differences,\ncontrolling cluster boundaries and inter-cluster distance. Attraction is more\nsubtle, as attractive tension between points can manifest simultaneously as\nattraction and repulsion in the lower-dimensional mapping. This explains the\nneed for learning rate annealing and motivates the different treatments between\nattractive and repulsive terms. Moreover, by modifying attraction, we improve\nthe consistency of cluster formation under random initialization. Overall, our\nanalysis makes UMAP and similar embedding methods more interpretable, more\nrobust, and more accurate.\n","authors":["Mohammad Tariqul Islam","Jason W. Fleischer"],"pdf_url":"https://arxiv.org/pdf/2503.09101v1.pdf","comment":"9 page + appendix"},{"id":"http://arxiv.org/abs/2402.15131v3","updated":"2025-03-12T06:15:34Z","published":"2024-02-23T06:32:18Z","title":"Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question\n  Answering with Large Language Models","summary":"  This study explores the realm of knowledge base question answering (KBQA).\nKBQA is considered a challenging task, particularly in parsing intricate\nquestions into executable logical forms. Traditional semantic parsing\n(SP)-based methods require extensive data annotations, which result in\nsignificant costs. Recently, the advent of few-shot in-context learning,\npowered by large language models (LLMs), has showcased promising capabilities.\nHowever, fully leveraging LLMs to parse questions into logical forms in\nlow-resource scenarios poses a substantial challenge. To tackle these hurdles,\nwe introduce Interactive-KBQA, a framework designed to generate logical forms\nthrough direct interaction with knowledge bases (KBs). Within this framework,\nwe have developed three generic APIs for KB interaction. For each category of\ncomplex question, we devised exemplars to guide LLMs through the reasoning\nprocesses. Our method achieves competitive results on the WebQuestionsSP,\nComplexWebQuestions, KQA Pro, and MetaQA datasets with a minimal number of\nexamples (shots). Importantly, our approach supports manual intervention,\nallowing for the iterative refinement of LLM outputs. By annotating a dataset\nwith step-wise reasoning processes, we showcase our model's adaptability and\nhighlight its potential for contributing significant enhancements to the field.\n","authors":["Guanming Xiong","Junwei Bao","Wen Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.15131v3.pdf","comment":"This work has been accepted by the ACL 2024 main conference. Code and\n  data are available at: https://github.com/JimXiongGM/Interactive-KBQA"},{"id":"http://arxiv.org/abs/2501.07964v3","updated":"2025-03-12T06:12:01Z","published":"2025-01-14T09:35:49Z","title":"Derivation of Output Correlation Inferences for Multi-Output (aka\n  Multi-Task) Gaussian Process","summary":"  Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients.\n","authors":["Shuhei Watanabe"],"pdf_url":"https://arxiv.org/pdf/2501.07964v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09091v1","updated":"2025-03-12T06:03:33Z","published":"2025-03-12T06:03:33Z","title":"Multi-Modal Foundation Models for Computational Pathology: A Survey","summary":"  Foundation models have emerged as a powerful paradigm in computational\npathology (CPath), enabling scalable and generalizable analysis of\nhistopathological images. While early developments centered on uni-modal models\ntrained solely on visual data, recent advances have highlighted the promise of\nmulti-modal foundation models that integrate heterogeneous data sources such as\ntextual reports, structured domain knowledge, and molecular profiles. In this\nsurvey, we provide a comprehensive and up-to-date review of multi-modal\nfoundation models in CPath, with a particular focus on models built upon\nhematoxylin and eosin (H&E) stained whole slide images (WSIs) and tile-level\nrepresentations. We categorize 32 state-of-the-art multi-modal foundation\nmodels into three major paradigms: vision-language, vision-knowledge graph, and\nvision-gene expression. We further divide vision-language models into\nnon-LLM-based and LLM-based approaches. Additionally, we analyze 28 available\nmulti-modal datasets tailored for pathology, grouped into image-text pairs,\ninstruction datasets, and image-other modality pairs. Our survey also presents\na taxonomy of downstream tasks, highlights training and evaluation strategies,\nand identifies key challenges and future directions. We aim for this survey to\nserve as a valuable resource for researchers and practitioners working at the\nintersection of pathology and AI.\n","authors":["Dong Li","Guihong Wan","Xintao Wu","Xinyu Wu","Xiaohui Chen","Yi He","Christine G. Lian","Peter K. Sorger","Yevgeniy R. Semenov","Chen Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.09091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08301v2","updated":"2025-03-12T06:00:27Z","published":"2025-03-11T11:13:11Z","title":"Large Language Model as Meta-Surrogate for Data-Driven Many-Task\n  Optimization: A Proof-of-Principle Study","summary":"  In many-task optimization scenarios, surrogate models are valuable for\nmitigating the computational burden of repeated fitness evaluations across\ntasks. This study proposes a novel meta-surrogate framework to assist many-task\noptimization, by leveraging the knowledge transfer strengths and emergent\ncapabilities of large language models (LLMs). We formulate a unified framework\nfor many-task fitness prediction, by defining a universal model with metadata\nto fit a group of problems. Fitness prediction is performed on metadata and\ndecision variables, enabling efficient knowledge sharing across tasks and\nadaptability to new tasks. The LLM-based meta-surrogate treats fitness\nprediction as conditional probability estimation, employing a unified token\nsequence representation for task metadata, inputs, and outputs. This approach\nfacilitates efficient inter-task knowledge sharing through shared token\nembeddings and captures complex task dependencies via multi-task model\ntraining. Experimental results demonstrate the model's emergent generalization\nability, including zero-shot performance on problems with unseen dimensions.\nWhen integrated into evolutionary transfer optimization (ETO), our framework\nsupports dual-level knowledge transfer -- at both the surrogate and individual\nlevels -- enhancing optimization efficiency and robustness. This work\nestablishes a novel foundation for applying LLMs in surrogate modeling,\noffering a versatile solution for many-task optimization.\n","authors":["Xian-Rong Zhang","Yue-Jiao Gong","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.08301v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2503.09089v1","updated":"2025-03-12T05:55:01Z","published":"2025-03-12T05:55:01Z","title":"LocAgent: Graph-Guided LLM Agents for Code Localization","summary":"  Code localization--identifying precisely where in a codebase changes need to\nbe made--is a fundamental yet challenging task in software maintenance.\nExisting approaches struggle to efficiently navigate complex codebases when\nidentifying relevant code sections. The challenge lies in bridging natural\nlanguage problem descriptions with the appropriate code elements, often\nrequiring reasoning across hierarchical structures and multiple dependencies.\nWe introduce LocAgent, a framework that addresses code localization through\ngraph-based representation. By parsing codebases into directed heterogeneous\ngraphs, LocAgent creates a lightweight representation that captures code\nstructures (files, classes, functions) and their dependencies (imports,\ninvocations, inheritance), enabling LLM agents to effectively search and locate\nrelevant entities through powerful multi-hop reasoning. Experimental results on\nreal-world benchmarks demonstrate that our approach significantly enhances\naccuracy in code localization. Notably, our method with the fine-tuned\nQwen-2.5-Coder-Instruct-32B model achieves comparable results to SOTA\nproprietary models at greatly reduced cost (approximately 86% reduction),\nreaching up to 92.7% accuracy on file-level localization while improving\ndownstream GitHub issue resolution success rates by 12% for multiple attempts\n(Pass@10). Our code is available at https://github.com/gersteinlab/LocAgent.\n","authors":["Zhaoling Chen","Xiangru Tang","Gangda Deng","Fang Wu","Jialong Wu","Zhiwei Jiang","Viktor Prasanna","Arman Cohan","Xingyao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.09089v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05628v5","updated":"2025-03-12T05:54:44Z","published":"2024-10-08T02:23:53Z","title":"A Unified Framework for Motion Reasoning and Generation in Human\n  Interaction","summary":"  Recent advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural and contextually relevant text,\nenabling more human-like AI interactions. However, generating and understanding\ninteractive human-like motion, where multiple individuals engage in coordinated\nmovements, remains challenging due to the complexity of modeling these\ninteractions. Additionally, a unified and versatile model is needed to handle\ndiverse interactive scenarios, such as chat systems that dynamically adapt to\nuser instructions and assigned roles. To address these challenges, we introduce\nVIM, the Versatile Interactive Motion-language model, which integrates both\nlanguage and motion modalities to effectively understand, generate, and control\ninteractive motions in multi-turn conversational contexts. Unlike previous\nstudies that primarily focus on uni-directional tasks such as text-to-motion or\nmotion-to-text, VIM employs a unified architecture capable of simultaneously\nunderstanding and generating both motion and text modalities. Given the absence\nof an appropriate dataset to support this task, we introduce Inter-MT2, a\nlarge-scale instruction-tuning dataset containing 82.7K multi-turn interactive\nmotion instructions, covering 153K interactive motion samples. Inter-MT2 spans\ndiverse instructional scenarios, including motion editing, question answering,\nand story generation, leveraging off-the-shelf large language models and motion\ndiffusion models to construct a broad set of interactive motion instructions.\nWe extensively evaluate the versatility of VIM across multiple interactive\nmotion-related tasks, including motion-to-text, text-to-motion, reaction\ngeneration, motion editing, and reasoning about motion sequences.\n","authors":["Jeongeun Park","Sungjoon Choi","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2410.05628v5.pdf","comment":"https://vim-motion-language.github.io/"},{"id":"http://arxiv.org/abs/2407.00936v4","updated":"2025-03-12T05:48:32Z","published":"2024-07-01T03:37:35Z","title":"Large Language Model Enhanced Knowledge Representation Learning: A\n  Survey","summary":"  Knowledge Representation Learning (KRL) is crucial for enabling applications\nof symbolic knowledge from Knowledge Graphs (KGs) to downstream tasks by\nprojecting knowledge facts into vector spaces. Despite their effectiveness in\nmodeling KG structural information, KRL methods are suffering from the\nsparseness of KGs. The rise of Large Language Models (LLMs) built on the\nTransformer architecture presents promising opportunities for enhancing KRL by\nincorporating textual information to address information sparsity in KGs.\nLLM-enhanced KRL methods, including three key approaches, encoder-based methods\nthat leverage detailed contextual information, encoder-decoder-based methods\nthat utilize a unified Seq2Seq model for comprehensive encoding and decoding,\nand decoder-based methods that utilize extensive knowledge from large corpora,\nhave significantly advanced the effectiveness and generalization of KRL in\naddressing a wide range of downstream tasks. This work provides a broad\noverview of downstream tasks while simultaneously identifying emerging research\ndirections in these evolving domains.\n","authors":["Xin Wang","Zirui Chen","Haofen Wang","Leong Hou U","Zhao Li","Wenbin Guo"],"pdf_url":"https://arxiv.org/pdf/2407.00936v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09081v1","updated":"2025-03-12T05:28:24Z","published":"2025-03-12T05:28:24Z","title":"Everything Can Be Described in Words: A Simple Unified Multi-Modal\n  Framework with Semantic and Temporal Alignment","summary":"  Long Video Question Answering (LVQA) is challenging due to the need for\ntemporal reasoning and large-scale multimodal data processing. Existing methods\nstruggle with retrieving cross-modal information from long videos, especially\nwhen relevant details are sparsely distributed. We introduce UMaT (Unified\nMulti-modal as Text), a retrieval-augmented generation (RAG) framework that\nefficiently processes extremely long videos while maintaining cross-modal\ncoherence. UMaT converts visual and auditory data into a unified textual\nrepresentation, ensuring semantic and temporal alignment. Short video clips are\nanalyzed using a vision-language model, while automatic speech recognition\n(ASR) transcribes dialogue. These text-based representations are structured\ninto temporally aligned segments, with adaptive filtering to remove redundancy\nand retain salient details. The processed data is embedded into a vector\ndatabase, enabling precise retrieval of dispersed yet relevant content.\nExperiments on a benchmark LVQA dataset show that UMaT outperforms existing\nmethods in multimodal integration, long-form video understanding, and sparse\ninformation retrieval. Its scalability and interpretability allow it to process\nvideos over an hour long while maintaining semantic and temporal coherence.\nThese findings underscore the importance of structured retrieval and multimodal\nsynchronization for advancing LVQA and long-form AI systems.\n","authors":["Xiaowei Bi","Zheyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.09081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.07259v4","updated":"2025-03-12T05:09:37Z","published":"2023-10-11T07:37:13Z","title":"Uncovering Hidden Connections: Iterative Search and Reasoning for\n  Video-grounded Dialog","summary":"  In contrast to conventional visual question answering, video-grounded dialog\nnecessitates a profound understanding of both dialog history and video content\nfor accurate response generation. Despite commendable progress made by existing\napproaches, they still face the challenges of incrementally understanding\ncomplex dialog history and assimilating video information. In response to these\nchallenges, we present an iterative search and reasoning framework, which\nconsists of a textual encoder, a visual encoder, and a generator. Specifically,\nwe devise a path search and aggregation strategy in the textual encoder, mining\ncore cues from dialog history that are pivotal to understanding the posed\nquestions. Concurrently, our visual encoder harnesses an iterative reasoning\nnetwork to extract and emphasize critical visual markers from videos, enhancing\nthe depth of visual comprehension. Finally, we utilize the pre-trained GPT-2\nmodel as our answer generator to decode the mined hidden clues into coherent\nand contextualized answers. Extensive experiments on three public datasets\ndemonstrate the effectiveness and generalizability of our proposed framework.\n","authors":["Haoyu Zhang","Meng Liu","Yisen Feng","Yaowei Wang","Weili Guan","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2310.07259v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13981v2","updated":"2025-03-12T05:09:21Z","published":"2024-10-17T19:18:28Z","title":"On the Learn-to-Optimize Capabilities of Transformers in In-Context\n  Sparse Recovery","summary":"  An intriguing property of the Transformer is its ability to perform\nin-context learning (ICL), where the Transformer can solve different inference\ntasks without parameter updating based on the contextual information provided\nby the corresponding input-output demonstration pairs. It has been\ntheoretically proved that ICL is enabled by the capability of Transformers to\nperform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al.,\n2024). This work takes a step further and shows that Transformers can perform\nlearning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse\nrecovery (formulated as LASSO) tasks, we show that a K-layer Transformer can\nperform an L2O algorithm with a provable convergence rate linear in K. This\nprovides a new perspective explaining the superior ICL capability of\nTransformers, even with only a few layers, which cannot be achieved by the\nstandard gradient-descent algorithms. Moreover, unlike the conventional L2O\nalgorithms that require the measurement matrix involved in training to match\nthat in testing, the trained Transformer is able to solve sparse recovery\nproblems generated with different measurement matrices. Besides, Transformers\nas an L2O algorithm can leverage structural information embedded in the\ntraining tasks to accelerate its convergence during ICL, and generalize across\ndifferent lengths of demonstration pairs, where conventional L2O algorithms\ntypically struggle or fail. Such theoretical findings are supported by our\nexperimental results.\n","authors":["Renpu Liu","Ruida Zhou","Cong Shen","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2410.13981v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09069v1","updated":"2025-03-12T05:07:07Z","published":"2025-03-12T05:07:07Z","title":"Theoretical Guarantees for High Order Trajectory Refinement in\n  Generative Flows","summary":"  Flow matching has emerged as a powerful framework for generative modeling,\noffering computational advantages over diffusion models by leveraging\ndeterministic Ordinary Differential Equations (ODEs) instead of stochastic\ndynamics. While prior work established the worst case optimality of standard\nflow matching under Wasserstein distances, the theoretical guarantees for\nhigher-order flow matching - which incorporates acceleration terms to refine\nsample trajectories - remain unexplored. In this paper, we bridge this gap by\nproving that higher-order flow matching preserves worst case optimality as a\ndistribution estimator. We derive upper bounds on the estimation error for\nsecond-order flow matching, demonstrating that the convergence rates depend\npolynomially on the smoothness of the target distribution (quantified via Besov\nspaces) and key parameters of the ODE dynamics. Our analysis employs neural\nnetwork approximations with carefully controlled depth, width, and sparsity to\nbound acceleration errors across both small and large time intervals,\nultimately unifying these results into a general worst case optimal bound for\nall time steps.\n","authors":["Chengyue Gong","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song","Yu Tian"],"pdf_url":"https://arxiv.org/pdf/2503.09069v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2410.11261"},{"id":"http://arxiv.org/abs/2503.09068v1","updated":"2025-03-12T05:05:58Z","published":"2025-03-12T05:05:58Z","title":"Probing Network Decisions: Capturing Uncertainties and Unveiling\n  Vulnerabilities Without Label Information","summary":"  To improve trust and transparency, it is crucial to be able to interpret the\ndecisions of Deep Neural classifiers (DNNs). Instance-level examinations, such\nas attribution techniques, are commonly employed to interpret the model\ndecisions. However, when interpreting misclassified decisions, human\nintervention may be required. Analyzing the attribu tions across each class\nwithin one instance can be particularly labor intensive and influenced by the\nbias of the human interpreter. In this paper, we present a novel framework to\nuncover the weakness of the classifier via counterfactual examples. A prober is\nintroduced to learn the correctness of the classifier's decision in terms of\nbinary code-hit or miss. It enables the creation of the counterfactual example\nconcerning the prober's decision. We test the performance of our prober's\nmisclassification detection and verify its effectiveness on the image\nclassification benchmark datasets. Furthermore, by generating counterfactuals\nthat penetrate the prober, we demonstrate that our framework effectively\nidentifies vulnerabilities in the target classifier without relying on label\ninformation on the MNIST dataset.\n","authors":["Youngju Joung","Sehyun Lee","Jaesik Choi"],"pdf_url":"https://arxiv.org/pdf/2503.09068v1.pdf","comment":"ICPRAI 2024"},{"id":"http://arxiv.org/abs/2503.07565v3","updated":"2025-03-12T05:00:02Z","published":"2025-03-10T17:37:39Z","title":"Inductive Moment Matching","summary":"  Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.\n","authors":["Linqi Zhou","Stefano Ermon","Jiaming Song"],"pdf_url":"https://arxiv.org/pdf/2503.07565v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09066v1","updated":"2025-03-12T04:59:22Z","published":"2025-03-12T04:59:22Z","title":"Probing Latent Subspaces in LLM for AI Security: Identifying and\n  Manipulating Adversarial States","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they remain vulnerable to adversarial manipulations such as\njailbreaking via prompt injection attacks. These attacks bypass safety\nmechanisms to generate restricted or harmful content. In this study, we\ninvestigated the underlying latent subspaces of safe and jailbroken states by\nextracting hidden activations from a LLM. Inspired by attractor dynamics in\nneuroscience, we hypothesized that LLM activations settle into semi stable\nstates that can be identified and perturbed to induce state transitions. Using\ndimensionality reduction techniques, we projected activations from safe and\njailbroken responses to reveal latent subspaces in lower dimensional spaces. We\nthen derived a perturbation vector that when applied to safe representations,\nshifted the model towards a jailbreak state. Our results demonstrate that this\ncausal intervention results in statistically significant jailbreak responses in\na subset of prompts. Next, we probed how these perturbations propagate through\nthe model's layers, testing whether the induced state change remains localized\nor cascades throughout the network. Our findings indicate that targeted\nperturbations induced distinct shifts in activations and model responses. Our\napproach paves the way for potential proactive defenses, shifting from\ntraditional guardrail based methods to preemptive, model agnostic techniques\nthat neutralize adversarial states at the representation level.\n","authors":["Xin Wei Chia","Jonathan Pan"],"pdf_url":"https://arxiv.org/pdf/2503.09066v1.pdf","comment":"4 figures"},{"id":"http://arxiv.org/abs/2405.04776v3","updated":"2025-03-12T04:56:46Z","published":"2024-05-08T02:48:28Z","title":"Chain of Thoughtlessness? An Analysis of CoT in Planning","summary":"  Large language model (LLM) performance on reasoning problems typically does\nnot generalize out of distribution. Previous work has claimed that this can be\nmitigated with chain of thought prompting-a method of demonstrating solution\nprocedures-with the intuition that it is possible to in-context teach an LLM an\nalgorithm for solving the problem. This paper presents a case study of chain of\nthought on problems from Blocksworld, a classical planning domain, and examines\nthe performance of two state-of-the-art LLMs across two axes: generality of\nexamples given in prompt, and complexity of problems queried with each prompt.\nWhile our problems are very simple, we only find meaningful performance\nimprovements from chain of thought prompts when those prompts are exceedingly\nspecific to their problem class, and that those improvements quickly\ndeteriorate as the size n of the query-specified stack grows past the size of\nstacks shown in the examples. We also create scalable variants of three domains\ncommonly studied in previous CoT papers and demonstrate the existence of\nsimilar failure modes. Our results hint that, contrary to previous claims in\nthe literature, CoT's performance improvements do not stem from the model\nlearning general algorithmic procedures via demonstrations but depend on\ncarefully engineering highly problem specific prompts. This spotlights\ndrawbacks of chain of thought, especially the sharp tradeoff between possible\nperformance gains and the amount of human labor necessary to generate examples\nwith correct reasoning traces.\n","authors":["Kaya Stechly","Karthik Valmeekam","Subbarao Kambhampati"],"pdf_url":"https://arxiv.org/pdf/2405.04776v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2503.09058v1","updated":"2025-03-12T04:46:53Z","published":"2025-03-12T04:46:53Z","title":"Implicit Contrastive Representation Learning with Guided Stop-gradient","summary":"  In self-supervised representation learning, Siamese networks are a natural\narchitecture for learning transformation-invariance by bringing representations\nof positive pairs closer together. But it is prone to collapse into a\ndegenerate solution. To address the issue, in contrastive learning, a\ncontrastive loss is used to prevent collapse by moving representations of\nnegative pairs away from each other. But it is known that algorithms with\nnegative sampling are not robust to a reduction in the number of negative\nsamples. So, on the other hand, there are algorithms that do not use negative\npairs. Many positive-only algorithms adopt asymmetric network architecture\nconsisting of source and target encoders as a key factor in coping with\ncollapse. By exploiting the asymmetric architecture, we introduce a methodology\nto implicitly incorporate the idea of contrastive learning. As its\nimplementation, we present a novel method guided stop-gradient. We apply our\nmethod to benchmark algorithms SimSiam and BYOL and show that our method\nstabilizes training and boosts performance. We also show that the algorithms\nwith our method work well with small batch sizes and do not collapse even when\nthere is no predictor. The code is available at\nhttps://github.com/bych-lee/gsg.\n","authors":["Byeongchan Lee","Sehyun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.09058v1.pdf","comment":"Neurips 2023"},{"id":"http://arxiv.org/abs/2407.08952v5","updated":"2025-03-12T04:46:47Z","published":"2024-07-12T03:15:01Z","title":"Detect, Investigate, Judge and Determine: A Knowledge-guided Framework\n  for Few-shot Fake News Detection","summary":"  Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news\nfrom real ones in extremely low-resource scenarios. This task has garnered\nincreased attention due to the widespread dissemination and harmful impact of\nfake news on social media. Large Language Models (LLMs) have demonstrated\ncompetitive performance with the help of their rich prior knowledge and\nexcellent in-context learning abilities. However, existing methods face\nsignificant limitations, such as the Understanding Ambiguity and Information\nScarcity, which significantly undermine the potential of LLMs. To address these\nshortcomings, we propose a Dual-perspective Knowledge-guided Fake News\nDetection (DKFND) model, designed to enhance LLMs from both inside and outside\nperspectives. Specifically, DKFND first identifies the knowledge concepts of\neach news article through a Detection Module. Subsequently, DKFND creatively\ndesigns an Investigation Module to retrieve inside and outside valuable\ninformation concerning to the current news, followed by another Judge Module to\nevaluate the relevance and confidence of them. Finally, a Determination Module\nfurther derives two respective predictions and obtain the final result.\nExtensive experiments on two public datasets show the efficacy of our proposed\nmethod, particularly in low-resource settings.\n","authors":["Ye Liu","Jiajun Zhu","Xukai Liu","Haoyu Tang","Yanghai Zhang","Kai Zhang","Xiaofang Zhou","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2407.08952v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11525v2","updated":"2025-03-12T04:39:54Z","published":"2024-05-19T11:36:45Z","title":"Overcoming Data and Model Heterogeneities in Decentralized Federated\n  Learning via Synthetic Anchors","summary":"  Conventional Federated Learning (FL) involves collaborative training of a\nglobal model while maintaining user data privacy. One of its branches,\ndecentralized FL, is a serverless network that allows clients to own and\noptimize different local models separately, which results in saving management\nand communication resources. Despite the promising advancements in\ndecentralized FL, it may reduce model generalizability due to lacking a global\nmodel. In this scenario, managing data and model heterogeneity among clients\nbecomes a crucial problem, which poses a unique challenge that must be\novercome: How can every client's local model learn generalizable representation\nin a decentralized manner? To address this challenge, we propose a novel\nDecentralized FL technique by introducing Synthetic Anchors, dubbed as DeSA.\nBased on the theory of domain adaptation and Knowledge Distillation (KD), we\ntheoretically and empirically show that synthesizing global anchors based on\nraw data distribution facilitates mutual knowledge transfer. We further design\ntwo effective regularization terms for local training: 1) REG loss that\nregularizes the distribution of the client's latent embedding with the anchors\nand 2) KD loss that enables clients to learn from others. Through extensive\nexperiments on diverse client data distributions, we showcase the effectiveness\nof DeSA in enhancing both inter- and intra-domain accuracy of each client.\n","authors":["Chun-Yin Huang","Kartik Srinivas","Xin Zhang","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2405.11525v2.pdf","comment":"Paper Accepted at ICML 2024, 23 pages"},{"id":"http://arxiv.org/abs/2406.11402v3","updated":"2025-03-12T04:37:42Z","published":"2024-06-17T10:45:36Z","title":"Are Small Language Models Ready to Compete with Large Language Models\n  for Practical Applications?","summary":"  The rapid rise of Language Models (LMs) has expanded their use in several\napplications. Yet, due to constraints of model size, associated cost, or\nproprietary restrictions, utilizing state-of-the-art (SOTA) LLMs is not always\nfeasible. With open, smaller LMs emerging, more applications can leverage their\ncapabilities, but selecting the right LM can be challenging as smaller LMs do\nnot perform well universally. This work tries to bridge this gap by proposing a\nframework to experimentally evaluate small, open LMs in practical settings\nthrough measuring semantic correctness of outputs across three practical\naspects: task types, application domains, and reasoning types, using diverse\nprompt styles. It also conducts an in-depth comparison of 10 small, open LMs to\nidentify the best LM and prompt style depending on specific application\nrequirements using the proposed framework. We also show that if selected\nappropriately, they can outperform SOTA LLMs like DeepSeek-v2, GPT-4o,\nGPT-4o-mini, Gemini-1.5-Pro, and even compete with GPT-4o.\n","authors":["Neelabh Sinha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2406.11402v3.pdf","comment":"Accepted at The Fifth Workshop on Trustworthy Natural Language\n  Processing (TrustNLP 2025) in Annual Conference of the Nations of the\n  Americas Chapter of the Association for Computational Linguistics (NAACL),\n  2025. 8 pages + references + Appendix"},{"id":"http://arxiv.org/abs/2503.09051v1","updated":"2025-03-12T04:36:28Z","published":"2025-03-12T04:36:28Z","title":"TreeX: Generating Global Graphical GNN Explanations via Critical Subtree\n  Extraction","summary":"  The growing demand for transparency and interpretability in critical domains\nhas driven increased interests in comprehending the explainability of\nMessage-Passing (MP) Graph Neural Networks (GNNs). Although substantial\nresearch efforts have been made to generate explanations for individual graph\ninstances, identifying global explaining concepts for a GNN still poses great\nchallenges, especially when concepts are desired in a graphical form on the\ndataset level. While most prior works treat GNNs as black boxes, in this paper,\nwe propose to unbox GNNs by analyzing and extracting critical subtrees incurred\nby the inner workings of message passing, which correspond to critical\nsubgraphs in the datasets. By aggregating subtrees in an embedding space with\nan efficient algorithm, which does not require complex subgraph matching or\nsearch, we can make intuitive graphical explanations for Message-Passing GNNs\non local, class and global levels. We empirically show that our proposed\napproach not only generates clean subgraph concepts on a dataset level in\ncontrast to existing global explaining methods which generate non-graphical\nrules (e.g., language or embeddings) as explanations, but it is also capable of\nproviding explanations for individual instances with a comparable or even\nsuperior performance as compared to leading local-level GNN explainers.\n","authors":["Shengyao Lu","Jiuding Yang","Baochun Li","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2503.09051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01380v3","updated":"2025-03-12T04:17:41Z","published":"2024-10-02T09:49:45Z","title":"Knowledge Entropy Decay during Language Model Pretraining Hinders New\n  Knowledge Acquisition","summary":"  In this work, we investigate how a model's tendency to broadly integrate its\nparametric knowledge evolves throughout pretraining, and how this behavior\naffects overall performance, particularly in terms of knowledge acquisition and\nforgetting. We introduce the concept of knowledge entropy, which quantifies the\nrange of memory sources the model engages with; high knowledge entropy\nindicates that the model utilizes a wide range of memory sources, while low\nknowledge entropy suggests reliance on specific sources with greater certainty.\nOur analysis reveals a consistent decline in knowledge entropy as pretraining\nadvances. We also find that the decline is closely associated with a reduction\nin the model's ability to acquire and retain knowledge, leading us to conclude\nthat diminishing knowledge entropy (smaller number of active memory sources)\nimpairs the model's knowledge acquisition and retention capabilities. We find\nfurther support for this by demonstrating that increasing the activity of\ninactive memory sources enhances the model's capacity for knowledge acquisition\nand retention.\n","authors":["Jiyeon Kim","Hyunji Lee","Hyowon Cho","Joel Jang","Hyeonbin Hwang","Seungpil Won","Youbin Ahn","Dohaeng Lee","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2410.01380v3.pdf","comment":"ICLR 2025, Oral"},{"id":"http://arxiv.org/abs/2503.09046v1","updated":"2025-03-12T04:10:46Z","published":"2025-03-12T04:10:46Z","title":"Discovering Influential Neuron Path in Vision Transformers","summary":"  Vision Transformer models exhibit immense power yet remain opaque to human\nunderstanding, posing challenges and risks for practical applications. While\nprior research has attempted to demystify these models through input\nattribution and neuron role analysis, there's been a notable gap in considering\nlayer-level information and the holistic path of information flow across\nlayers. In this paper, we investigate the significance of influential neuron\npaths within vision Transformers, which is a path of neurons from the model\ninput to output that impacts the model inference most significantly. We first\npropose a joint influence measure to assess the contribution of a set of\nneurons to the model outcome. And we further provide a layer-progressive neuron\nlocating approach that efficiently selects the most influential neuron at each\nlayer trying to discover the crucial neuron path from input to output within\nthe target model. Our experiments demonstrate the superiority of our method\nfinding the most influential neuron path along which the information flows,\nover the existing baseline solutions. Additionally, the neuron paths have\nillustrated that vision Transformers exhibit some specific inner working\nmechanism for processing the visual information within the same image category.\nWe further analyze the key effects of these neurons on the image classification\ntask, showcasing that the found neuron paths have already preserved the model\ncapability on downstream tasks, which may also shed some lights on real-world\napplications like model pruning. The project website including implementation\ncode is available at https://foundation-model-research.github.io/NeuronPath/.\n","authors":["Yifan Wang","Yifei Liu","Yingdong Shi","Changming Li","Anqi Pang","Sibei Yang","Jingyi Yu","Kan Ren"],"pdf_url":"https://arxiv.org/pdf/2503.09046v1.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2407.20143v3","updated":"2025-03-12T04:10:33Z","published":"2024-07-29T16:18:20Z","title":"ByteCheckpoint: A Unified Checkpointing System for Large Foundation\n  Model Development","summary":"  Checkpointing to preserve training states is crucial during the development\nof Large Foundation Models (LFMs), for training resumption upon various\nfailures or changes in GPU resources and parallelism configurations. In\naddition, saved checkpoints are dispatched to evaluation tasks or transferred\nacross different training stages (e.g., from pre-training to post-training).\nAll these scenarios require resharding distributed checkpoints from one\nparallelism to another. In production environments, different LFMs are trained\nwith various frameworks and storage backends, depending on model sizes and\ntraining scales. A high-performance checkpointing system is needed to enable\nefficient checkpoint management at scale throughout the lifecycle of LFM\ndevelopment. We introduce ByteCheckpoint, an industrial-grade checkpointing\nsystem for large-scale LFM training. ByteCheckpoint features: a\nparallelism-agnostic checkpoint representation that enables efficient load-time\ncheckpoint resharding; a generic checkpoint saving/loading workflow to\naccommodate multiple training frameworks and support different storage\nbackends; full-stack optimizations to ensure high I/O efficiency and\nscalability; a suite of monitoring tools to streamline large-scale performance\nanalysis and bottleneck detection. Compared to existing open-source\ncheckpointing systems [52, 58], ByteCheckpoint significantly reduces runtime\ncheckpoint stalls, achieving an average reduction of 54.20x. For saving and\nloading times, ByteCheckpoint achieves improvements of up to 9.96x and 8.80x,\nrespectively.\n","authors":["Borui Wan","Mingji Han","Yiyao Sheng","Yanghua Peng","Haibin Lin","Mofan Zhang","Zhichao Lai","Menghan Yu","Junda Zhang","Zuquan Song","Xin Liu","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2407.20143v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15723v2","updated":"2025-03-12T03:53:50Z","published":"2025-01-28T06:06:28Z","title":"Balancing Content Size in RAG-Text2SQL System","summary":"  Large Language Models (LLMs) have emerged as a promising solution for\nconverting natural language queries into SQL commands, enabling seamless\ndatabase interaction. However, these Text-to-SQL (Text2SQL) systems face\ninherent limitations, hallucinations, outdated knowledge, and untraceable\nreasoning. To address these challenges, the integration of retrieval-augmented\ngeneration (RAG) with Text2SQL models has gained traction. RAG serves as a\nretrieval mechanism, providing essential contextual information, such as table\nschemas and metadata, to enhance the query generation process. Despite their\npotential, RAG + Text2SQL systems are susceptible to the quality and size of\nretrieved documents. While richer document content can improve schema relevance\nand retrieval accuracy, it also introduces noise, increasing the risk of\nhallucinations and reducing query fidelity as the prompt size of the Text2SQL\nmodel increases. This research investigates the nuanced trade-off between\ndocument size and quality, aiming to strike a balance that optimizes system\nperformance. Key thresholds are identified where performance degradation\noccurs, along with actionable strategies to mitigate these challenges.\nAdditionally, we explore the phenomenon of hallucinations in Text2SQL models,\nemphasizing the critical role of curated document presentation in minimizing\nerrors. Our findings provide a roadmap for enhancing the robustness of RAG +\nText2SQL systems, offering practical insights for real-world applications.\n","authors":["Prakhar Gurawa","Anjali Dharmik"],"pdf_url":"https://arxiv.org/pdf/2502.15723v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09035v1","updated":"2025-03-12T03:51:41Z","published":"2025-03-12T03:51:41Z","title":"ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers","summary":"  The next generation of active safety features in autonomous vehicles should\nbe capable of safely executing evasive hazard-avoidance maneuvers akin to those\nperformed by professional stunt drivers to achieve high-agility motion at the\nlimits of vehicle handling. This paper presents a novel framework, ManeuverGPT,\nfor generating and executing high-dynamic stunt maneuvers in autonomous\nvehicles using large language model (LLM)-based agents as controllers. We\ntarget aggressive maneuvers, such as J-turns, within the CARLA simulation\nenvironment and demonstrate an iterative, prompt-based approach to refine\nvehicle control parameters, starting tabula rasa without retraining model\nweights. We propose an agentic architecture comprised of three specialized\nagents (1) a Query Enricher Agent for contextualizing user commands, (2) a\nDriver Agent for generating maneuver parameters, and (3) a Parameter Validator\nAgent that enforces physics-based and safety constraints. Experimental results\ndemonstrate successful J-turn execution across multiple vehicle models through\ntextual prompts that adapt to differing vehicle dynamics. We evaluate\nperformance via established success criteria and discuss limitations regarding\nnumeric precision and scenario complexity. Our findings underscore the\npotential of LLM-driven control for flexible, high-dynamic maneuvers, while\nhighlighting the importance of hybrid approaches that combine language-based\nreasoning with algorithmic validation.\n","authors":["Shawn Azdam","Pranav Doma","Aliasghar Moj Arab"],"pdf_url":"https://arxiv.org/pdf/2503.09035v1.pdf","comment":"6 Pages, Submitted to IROS"},{"id":"http://arxiv.org/abs/2503.09033v1","updated":"2025-03-12T03:46:09Z","published":"2025-03-12T03:46:09Z","title":"RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and\n  Identification","summary":"  In this paper, we propose RFUAV as a new benchmark dataset for\nradio-frequency based (RF-based) unmanned aerial vehicle (UAV) identification\nand address the following challenges: Firstly, many existing datasets feature a\nrestricted variety of drone types and insufficient volumes of raw data, which\nfail to meet the demands of practical applications. Secondly, existing datasets\noften lack raw data covering a broad range of signal-to-noise ratios (SNR), or\ndo not provide tools for transforming raw data to different SNR levels. This\nlimitation undermines the validity of model training and evaluation. Lastly,\nmany existing datasets do not offer open-access evaluation tools, leading to a\nlack of unified evaluation standards in current research within this field.\nRFUAV comprises approximately 1.3 TB of raw frequency data collected from 37\ndistinct UAVs using the Universal Software Radio Peripheral (USRP) device in\nreal-world environments. Through in-depth analysis of the RF data in RFUAV, we\ndefine a drone feature sequence called RF drone fingerprint, which aids in\ndistinguishing drone signals. In addition to the dataset, RFUAV provides a\nbaseline preprocessing method and model evaluation tools. Rigorous experiments\ndemonstrate that these preprocessing methods achieve state-of-the-art (SOTA)\nperformance using the provided evaluation tools. The RFUAV dataset and baseline\nimplementation are publicly available at https://github.com/kitoweeknd/RFUAV/.\n","authors":["Rui Shi","Xiaodong Yu","Shengming Wang","Yijia Zhang","Lu Xu","Peng Pan","Chunlai Ma"],"pdf_url":"https://arxiv.org/pdf/2503.09033v1.pdf","comment":"23 pages, 13 figures, conference"},{"id":"http://arxiv.org/abs/2503.09032v1","updated":"2025-03-12T03:45:53Z","published":"2025-03-12T03:45:53Z","title":"Teaching LLMs How to Learn with Contextual Fine-Tuning","summary":"  Prompting Large Language Models (LLMs), or providing context on the expected\nmodel of operation, is an effective way to steer the outputs of such models to\nsatisfy human desiderata after they have been trained. But in rapidly evolving\ndomains, there is often need to fine-tune LLMs to improve either the kind of\nknowledge in their memory or their abilities to perform open ended reasoning in\nnew domains. When human's learn new concepts, we often do so by linking the new\nmaterial that we are studying to concepts we have already learned before. To\nthat end, we ask, \"can prompting help us teach LLMs how to learn\". In this\nwork, we study a novel generalization of instruction tuning, called contextual\nfine-tuning, to fine-tune LLMs. Our method leverages instructional prompts\ndesigned to mimic human cognitive strategies in learning and problem-solving to\nguide the learning process during training, aiming to improve the model's\ninterpretation and understanding of domain-specific knowledge. We empirically\ndemonstrate that this simple yet effective modification improves the ability of\nLLMs to be fine-tuned rapidly on new datasets both within the medical and\nfinancial domains.\n","authors":["Younwoo Choi","Muhammad Adil Asif","Ziwen Han","John Willes","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.09032v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2412.17574v2","updated":"2025-03-12T03:42:48Z","published":"2024-12-23T13:45:56Z","title":"HumanVBench: Exploring Human-Centric Video Understanding Capabilities of\n  MLLMs with Synthetic Benchmark Data","summary":"  In the domain of Multimodal Large Language Models (MLLMs), achieving\nhuman-centric video understanding remains a formidable challenge. Existing\nbenchmarks primarily emphasize object and action recognition, often neglecting\nthe intricate nuances of human emotions, behaviors, and speech-visual alignment\nwithin video content. We present HumanVBench, an innovative benchmark\nmeticulously crafted to bridge these gaps in the evaluation of video MLLMs.\nHumanVBench comprises 16 carefully designed tasks that explore two primary\ndimensions: inner emotion and outer manifestations, spanning static and\ndynamic, basic and complex, as well as single-modal and cross-modal aspects.\nWith two advanced automated pipelines for video annotation and\ndistractor-included QA generation, HumanVBench utilizes diverse\nstate-of-the-art (SOTA) techniques to streamline benchmark data synthesis and\nquality assessment, minimizing human annotation dependency tailored to\nhuman-centric multimodal attributes. A comprehensive evaluation across 22 SOTA\nvideo MLLMs reveals notable limitations in current performance, especially in\ncross-modal and emotion perception, underscoring the necessity for further\nrefinement toward achieving more human-like understanding. HumanVBench is\nopen-sourced to facilitate future advancements and real-world applications in\nvideo MLLMs.\n","authors":["Ting Zhou","Daoyuan Chen","Qirui Jiao","Bolin Ding","Yaliang Li","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2412.17574v2.pdf","comment":"22 pages, 23 figures, 7 tables"},{"id":"http://arxiv.org/abs/2501.02749v2","updated":"2025-03-12T03:29:21Z","published":"2025-01-06T03:53:02Z","title":"Intelligent logistics management robot path planning algorithm\n  integrating transformer and GCN network","summary":"  This research delves into advanced route optimization for robots in smart\nlogistics, leveraging a fusion of Transformer architectures, Graph Neural\nNetworks (GNNs), and Generative Adversarial Networks (GANs). The approach\nutilizes a graph-based representation encompassing geographical data, cargo\nallocation, and robot dynamics, addressing both spatial and resource\nlimitations to refine route efficiency. Through extensive testing with\nauthentic logistics datasets, the proposed method achieves notable\nimprovements, including a 15% reduction in travel distance, a 20% boost in time\nefficiency, and a 10% decrease in energy consumption. These findings highlight\nthe algorithm's effectiveness, promoting enhanced performance in intelligent\nlogistics operations.\n","authors":["Hao Luo","Jianjun Wei","Shuchen Zhao","Ankai Liang","Zhongjin Xu","Ruxue Jiang"],"pdf_url":"https://arxiv.org/pdf/2501.02749v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2503.05971v2","updated":"2025-03-12T03:22:04Z","published":"2025-03-07T22:48:46Z","title":"A Real-time Multimodal Transformer Neural Network-powered Wildfire\n  Forecasting System","summary":"  Due to climate change, the extreme wildfire has become one of the most\ndangerous natural hazards to human civilization. Even though, some wildfires\nmay be initially caused by human activity, but the spread of wildfires is\nmainly determined by environmental factors, for examples, (1) weather\nconditions such as temperature, wind direction and intensity, and moisture\nlevels; (2) the amount and types of dry vegetation in a local area, and (3)\ntopographic or local terrian conditions, which affects how much rain an area\ngets and how fire dynamics will be constrained or faciliated. Thus, to\naccurately forecast wildfire occurrence has become one of most urgent and\ntaunting environmental challenges in global scale. In this work, we developed a\nreal-time Multimodal Transformer Neural Network Machine Learning model that\ncombines several advanced artificial intelligence techniques and statistical\nmethods to practically forecast the occurrence of wildfire at the precise\nlocation in real time, which not only utilizes large scale data information\nsuch as hourly weather forecasting data, but also takes into account small\nscale topographical data such as local terrain condition and local vegetation\nconditions collecting from Google Earth images to determine the probabilities\nof wildfire occurrence location at small scale as well as their timing\nsynchronized with weather forecast information. By using the wildfire data in\nthe United States from 1992 to 2015 to train the multimodal transformer neural\nnetwork, it can predict the probabilities of wildfire occurrence according to\nthe real-time weather forecast and the synchronized Google Earth image data to\nprovide the wildfire occurrence probability in any small location ($100m^2$)\nwithin 24 hours ahead.\n","authors":["Qijun Chen","Shaofan Li"],"pdf_url":"https://arxiv.org/pdf/2503.05971v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07513v2","updated":"2025-03-12T03:18:36Z","published":"2025-03-10T16:33:14Z","title":"Language Models Fail to Introspect About Their Knowledge of Language","summary":"  There has been recent interest in whether large language models (LLMs) can\nintrospect about their own internal states. Such abilities would make LLMs more\ninterpretable, and also validate the use of standard introspective methods in\nlinguistics to evaluate grammatical knowledge in models (e.g., asking \"Is this\nsentence grammatical?\"). We systematically investigate emergent introspection\nacross 21 open-source LLMs, in two domains where introspection is of\ntheoretical interest: grammatical knowledge and word prediction. Crucially, in\nboth domains, a model's internal linguistic knowledge can be theoretically\ngrounded in direct measurements of string probability. We then evaluate whether\nmodels' responses to metalinguistic prompts faithfully reflect their internal\nknowledge. We propose a new measure of introspection: the degree to which a\nmodel's prompted responses predict its own string probabilities, beyond what\nwould be predicted by another model with nearly identical internal knowledge.\nWhile both metalinguistic prompting and probability comparisons lead to high\ntask accuracy, we do not find evidence that LLMs have privileged \"self-access\".\nOur findings complicate recent results suggesting that models can introspect,\nand add new evidence to the argument that prompted responses should not be\nconflated with models' linguistic generalizations.\n","authors":["Siyuan Song","Jennifer Hu","Kyle Mahowald"],"pdf_url":"https://arxiv.org/pdf/2503.07513v2.pdf","comment":"Corrected Fig 5a and removed unused figures from source files"},{"id":"http://arxiv.org/abs/2503.09020v1","updated":"2025-03-12T03:15:46Z","published":"2025-03-12T03:15:46Z","title":"Enhancing High-Quality Code Generation in Large Language Models with\n  Comparative Prefix-Tuning","summary":"  Large Language Models (LLMs) have been widely adopted in commercial code\ncompletion engines, significantly enhancing coding efficiency and productivity.\nHowever, LLMs may generate code with quality issues that violate coding\nstandards and best practices, such as poor code style and maintainability, even\nwhen the code is functionally correct. This necessitates additional effort from\ndevelopers to improve the code, potentially negating the efficiency gains\nprovided by LLMs. To address this problem, we propose a novel comparative\nprefix-tuning method for controllable high-quality code generation. Our method\nintroduces a single, property-specific prefix that is prepended to the\nactivations of the LLM, serving as a lightweight alternative to fine-tuning.\nUnlike existing methods that require training multiple prefixes, our approach\ntrains only one prefix and leverages pairs of high-quality and low-quality code\nsamples, introducing a sequence-level ranking loss to guide the model's\ntraining. This comparative approach enables the model to better understand the\ndifferences between high-quality and low-quality code, focusing on aspects that\nimpact code quality. Additionally, we design a data construction pipeline to\ncollect and annotate pairs of high-quality and low-quality code, facilitating\neffective training. Extensive experiments on the Code Llama 7B model\ndemonstrate that our method improves code quality by over 100% in certain task\ncategories, while maintaining functional correctness. We also conduct ablation\nstudies and generalization experiments, confirming the effectiveness of our\nmethod's components and its strong generalization capability.\n","authors":["Yuan Jiang","Yujian Zhang","Liang Lu","Christoph Treude","Xiaohong Su","Shan Huang","Tiantian Wang"],"pdf_url":"https://arxiv.org/pdf/2503.09020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04371v7","updated":"2025-03-12T02:55:36Z","published":"2023-08-08T16:18:20Z","title":"Cumulative Reasoning with Large Language Models","summary":"  Recent advancements in large language models (LLMs) have shown remarkable\nprogress, yet their ability to solve complex problems remains limited. In this\nwork, we introduce Cumulative Reasoning (CR), an approach that utilizes LLMs\ncumulatively and iteratively, mirroring human thought processes for\nproblem-solving. CR decomposes tasks into smaller, manageable components and\nleverages previous propositions for effective composition, significantly\nenhancing problem-solving capabilities. We demonstrate CR's advantage through\nseveral complex reasoning tasks: it outperforms existing methods in logical\ninference tasks with up to a 9.3% improvement, achieving 98.04% accuracy on the\ncurated FOLIO wiki dataset. In the Game of 24, it achieves 98% accuracy,\nmarking a 24% improvement over the prior state-of-the-art. In solving MATH\nproblems, CR achieves a 4.2% increase from previous methods and a 43% relative\nimprovement in the most challenging level 5 problems. When incorporating a code\nenvironment with CR, we further harness LLMs' reasoning capabilities and\noutperform the Program of Thought (PoT) method by 38.8%. The code is available\nat https://github.com/iiis-ai/cumulative-reasoning.\n","authors":["Yifan Zhang","Jingqin Yang","Yang Yuan","Andrew Chi-Chih Yao"],"pdf_url":"https://arxiv.org/pdf/2308.04371v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09008v1","updated":"2025-03-12T02:51:17Z","published":"2025-03-12T02:51:17Z","title":"Towards Quantifying Long-Range Interactions in Graph Machine Learning: a\n  Large Graph Dataset and a Measurement","summary":"  Long-range dependencies are critical for effective graph representation\nlearning, yet most existing datasets focus on small graphs tailored to\ninductive tasks, offering limited insight into long-range interactions. Current\nevaluations primarily compare models employing global attention (e.g., graph\ntransformers) with those using local neighborhood aggregation (e.g.,\nmessage-passing neural networks) without a direct measurement of long-range\ndependency. In this work, we introduce City-Networks, a novel large-scale\ntransductive learning dataset derived from real-world city roads. This dataset\nfeatures graphs with over $10^5$ nodes and significantly larger diameters than\nthose in existing benchmarks, naturally embodying long-range information. We\nannotate the graphs using an eccentricity-based approach, ensuring that the\nclassification task inherently requires information from distant nodes.\nFurthermore, we propose a model-agnostic measurement based on the Jacobians of\nneighbors from distant hops, offering a principled quantification of long-range\ndependencies. Finally, we provide theoretical justifications for both our\ndataset design and the proposed measurement - particularly by focusing on\nover-smoothing and influence score dilution - which establishes a robust\nfoundation for further exploration of long-range interactions in graph neural\nnetworks.\n","authors":["Huidong Liang","Haitz Sáez de Ocáriz Borde","Baskaran Sripathmanathan","Michael Bronstein","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2503.09008v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2503.07878v2","updated":"2025-03-12T02:47:54Z","published":"2025-03-10T21:50:58Z","title":"Measuring directional bias amplification in image captions using\n  predictability","summary":"  When we train models on biased ML datasets, they not only learn these biases\nbut can inflate them at test time - a phenomenon called bias amplification. To\nmeasure bias amplification in ML datasets, many co-occurrence-based metrics\nhave been proposed. Co-occurrence-based metrics are effective in measuring bias\namplification in simple problems like image classification. However, these\nmetrics are ineffective for complex problems like image captioning as they\ncannot capture the semantics of a caption. To measure bias amplification in\ncaptions, prior work introduced a predictability-based metric called Leakage in\nCaptioning (LIC). While LIC captures the semantics and context of captions, it\nhas limitations. LIC cannot identify the direction in which bias is amplified,\npoorly estimates dataset bias due to a weak vocabulary substitution strategy,\nand is highly sensitive to attacker models (a hyperparameter in\npredictability-based metrics). To overcome these issues, we propose Directional\nPredictability Amplification in Captioning (DPAC). DPAC measures directional\nbias amplification in captions, provides a better estimate of dataset bias\nusing an improved substitution strategy, and is less sensitive to attacker\nmodels. Our experiments on the COCO captioning dataset show how DPAC is the\nmost reliable metric to measure bias amplification in captions.\n","authors":["Rahul Nair","Bhanu Tokas","Neel Shah","Hannah Kerner"],"pdf_url":"https://arxiv.org/pdf/2503.07878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17100v3","updated":"2025-03-12T02:32:00Z","published":"2025-02-24T12:31:28Z","title":"Generative Models in Decision Making: A Survey","summary":"  In recent years, the exceptional performance of generative models in\ngenerative tasks has sparked significant interest in their integration into\ndecision-making processes. Due to their ability to handle complex data\ndistributions and their strong model capacity, generative models can be\neffectively incorporated into decision-making systems by generating\ntrajectories that guide agents toward high-reward state-action regions or\nintermediate sub-goals. This paper presents a comprehensive review of the\napplication of generative models in decision-making tasks. We classify seven\nfundamental types of generative models: energy-based models, generative\nadversarial networks, variational autoencoders, normalizing flows, diffusion\nmodels, generative flow networks, and autoregressive models. Regarding their\napplications, we categorize their functions into three main roles: controllers,\nmodelers and optimizers, and discuss how each role contributes to\ndecision-making. Furthermore, we examine the deployment of these models across\nfive critical real-world decision-making scenarios. Finally, we summarize the\nstrengths and limitations of current approaches and propose three key\ndirections for advancing next-generation generative directive models:\nhigh-performance algorithms, large-scale generalized decision-making models,\nand self-evolving and adaptive models.\n","authors":["Yinchuan Li","Xinyu Shao","Jianping Zhang","Haozhi Wang","Leo Maxime Brunswic","Kaiwen Zhou","Jiqian Dong","Kaiyang Guo","Xiu Li","Zhitang Chen","Jun Wang","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2502.17100v3.pdf","comment":"Project\n  page:https://github.com/xyshao23/Awesome-Generative-Models-for-Decision-Making-Taxonomy"},{"id":"http://arxiv.org/abs/2503.09002v1","updated":"2025-03-12T02:30:19Z","published":"2025-03-12T02:30:19Z","title":"KNighter: Transforming Static Analysis with LLM-Synthesized Checkers","summary":"  Static analysis is a powerful technique for bug detection in critical systems\nlike operating system kernels. However, designing and implementing static\nanalyzers is challenging, time-consuming, and typically limited to predefined\nbug patterns. While large language models (LLMs) have shown promise for static\nanalysis, directly applying them to scan large codebases remains impractical\ndue to computational constraints and contextual limitations.\n  We present KNighter, the first approach that unlocks practical LLM-based\nstatic analysis by automatically synthesizing static analyzers from historical\nbug patterns. Rather than using LLMs to directly analyze massive codebases, our\nkey insight is leveraging LLMs to generate specialized static analyzers guided\nby historical patch knowledge. KNighter implements this vision through a\nmulti-stage synthesis pipeline that validates checker correctness against\noriginal patches and employs an automated refinement process to iteratively\nreduce false positives. Our evaluation on the Linux kernel demonstrates that\nKNighter generates high-precision checkers capable of detecting diverse bug\npatterns overlooked by existing human-written analyzers. To date,\nKNighter-synthesized checkers have discovered 70 new bugs/vulnerabilities in\nthe Linux kernel, with 56 confirmed and 41 already fixed. 11 of these findings\nhave been assigned CVE numbers. This work establishes an entirely new paradigm\nfor scalable, reliable, and traceable LLM-based static analysis for real-world\nsystems via checker synthesis.\n","authors":["Chenyuan Yang","Zijie Zhao","Zichen Xie","Haoyu Li","Lingming Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11284v3","updated":"2025-03-12T02:08:24Z","published":"2024-05-18T13:09:33Z","title":"The Logic of Counterfactuals and the Epistemology of Causal Inference","summary":"  The 2021 Nobel Prize in Economics recognized an epistemology of causal\ninference based on the Rubin causal model (Rubin 1974), which merits broader\nattention in philosophy. This model, in fact, presupposes a logical principle\nof counterfactuals, Conditional Excluded Middle (CEM), the locus of a pivotal\ndebate between Stalnaker (1968) and Lewis (1973) on the semantics of\ncounterfactuals. Proponents of CEM should recognize that this connection points\nto a new argument for CEM -- a Quine-Putnam indispensability argument grounded\nin the Nobel-winning applications of the Rubin model in health and social\nsciences. To advance the dialectic, I challenge this argument with an updated\nRubin causal model that retains its successes while dispensing with CEM. This\nnovel approach combines the strengths of the Rubin causal model and a causal\nmodel familiar in philosophy, the causal Bayes net. The takeaway: deductive\nlogic and inductive inference, often studied in isolation, are deeply\ninterconnected.\n","authors":["Hanti Lin"],"pdf_url":"https://arxiv.org/pdf/2405.11284v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08994v1","updated":"2025-03-12T02:07:08Z","published":"2025-03-12T02:07:08Z","title":"DistJoin: A Decoupled Join Cardinality Estimator based on Adaptive\n  Neural Predicate Modulation","summary":"  Research on learned cardinality estimation has achieved significant progress\nin recent years. However, existing methods still face distinct challenges that\nhinder their practical deployment in production environments. We conceptualize\nthese challenges as the \"Trilemma of Cardinality Estimation\", where learned\ncardinality estimation methods struggle to balance generality, accuracy, and\nupdatability. To address these challenges, we introduce DistJoin, a join\ncardinality estimator based on efficient distribution prediction using\nmulti-autoregressive models. Our contributions are threefold: (1) We propose a\nmethod for estimating both equi and non-equi join cardinality by leveraging the\nconditional probability distributions of individual tables in a decoupled\nmanner. (2) To meet the requirements of efficient training and inference for\nDistJoin, we develop Adaptive Neural Predicate Modulation (ANPM), a\nhigh-throughput conditional probability distribution estimation model. (3) We\nformally analyze the variance of existing similar methods and demonstrate that\nsuch approaches suffer from variance accumulation issues. To mitigate this\nproblem, DistJoin employs a selectivity-based approach rather than a\ncount-based approach to infer join cardinality, effectively reducing variance.\nIn summary, DistJoin not only represents the first data-driven method to\neffectively support both equi and non-equi joins but also demonstrates superior\naccuracy while enabling fast and flexible updates. We evaluate DistJoin on\nJOB-light and JOB-light-ranges, extending the evaluation to non-equi join\nconditions. The results demonstrate that our approach achieves the highest\naccuracy, robustness to data updates, generality, and comparable update and\ninference speed relative to existing methods.\n","authors":["Kaixin Zhang","Hongzhi Wang","Ziqi Li","Yabin Lu","Yingze Li","Yu Yan","Yiming Guan"],"pdf_url":"https://arxiv.org/pdf/2503.08994v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08990v1","updated":"2025-03-12T01:52:17Z","published":"2025-03-12T01:52:17Z","title":"JBFuzz: Jailbreaking LLMs Efficiently and Effectively Using Fuzzing","summary":"  Large language models (LLMs) have shown great promise as language\nunderstanding and decision making tools, and they have permeated various\naspects of our everyday life. However, their widespread availability also comes\nwith novel risks, such as generating harmful, unethical, or offensive content,\nvia an attack called jailbreaking. Despite extensive efforts from LLM\ndevelopers to align LLMs using human feedback, they are still susceptible to\njailbreak attacks. To tackle this issue, researchers often employ red-teaming\nto understand and investigate jailbreak prompts. However, existing red-teaming\napproaches lack effectiveness, scalability, or both. To address these issues,\nwe propose JBFuzz, a novel effective, automated, and scalable red-teaming\ntechnique for jailbreaking LLMs.\n  JBFuzz is inspired by the success of fuzzing for detecting\nbugs/vulnerabilities in software. We overcome three challenges related to\neffectiveness and scalability by devising novel seed prompts, a lightweight\nmutation engine, and a lightweight and accurate evaluator for guiding the\nfuzzer. Assimilating all three solutions results in a potent fuzzer that only\nrequires black-box access to the target LLM. We perform extensive experimental\nevaluation of JBFuzz using nine popular and widely-used LLMs. We find that\nJBFuzz successfully jailbreaks all LLMs for various harmful/unethical\nquestions, with an average attack success rate of 99%. We also find that JBFuzz\nis extremely efficient as it jailbreaks a given LLM for a given question in 60\nseconds on average. Our work highlights the susceptibility of the\nstate-of-the-art LLMs to jailbreak attacks even after safety alignment, and\nserves as a valuable red-teaming tool for LLM developers.\n","authors":["Vasudev Gohil"],"pdf_url":"https://arxiv.org/pdf/2503.08990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07963v2","updated":"2025-03-12T01:43:20Z","published":"2025-03-11T01:40:23Z","title":"Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal\n  Manipulation using Tight Convex Relaxations","summary":"  Designing trajectories for manipulation through contact is challenging as it\nrequires reasoning of object \\& robot trajectories as well as complex contact\nsequences simultaneously. In this paper, we present a novel framework for\nsimultaneously designing trajectories of robots, objects, and contacts\nefficiently for contact-rich manipulation. We propose a hierarchical\noptimization framework where Mixed-Integer Linear Program (MILP) selects\noptimal contacts between robot \\& object using approximate dynamical\nconstraints, and then a NonLinear Program (NLP) optimizes trajectory of the\nrobot(s) and object considering full nonlinear constraints. We present a convex\nrelaxation of bilinear constraints using binary encoding technique such that\nMILP can provide tighter solutions with better computational complexity. The\nproposed framework is evaluated on various manipulation tasks where it can\nreason about complex multi-contact interactions while providing computational\nadvantages. We also demonstrate our framework in hardware experiments using a\nbimanual robot system. The video summarizing this paper and hardware\nexperiments is found https://youtu.be/s2S1Eg5RsRE?si=chPkftz_a3NAHxLq\n","authors":["Yuki Shirai","Arvind Raghunathan","Devesh K. Jha"],"pdf_url":"https://arxiv.org/pdf/2503.07963v2.pdf","comment":"2025 IEEE International Conference on Robotics and Automation (2025\n  ICRA)"},{"id":"http://arxiv.org/abs/2303.02278v3","updated":"2025-03-12T01:01:17Z","published":"2023-03-04T00:35:29Z","title":"Federated Learning on Virtual Heterogeneous Data with Local-global\n  Distillation","summary":"  While Federated Learning (FL) is gaining popularity for training machine\nlearning models in a decentralized fashion, numerous challenges persist, such\nas asynchronization, computational expenses, data heterogeneity, and gradient\nand membership privacy attacks. Lately, dataset distillation has emerged as a\npromising solution for addressing the aforementioned challenges by generating a\ncompact synthetic dataset that preserves a model's training efficacy. However,\nwe discover that using distilled local datasets can amplify the heterogeneity\nissue in FL. To address this, we propose Federated Learning on Virtual\nHeterogeneous Data with Local-Global Dataset Distillation (FedLGD), where we\nseamlessly integrate dataset distillation algorithms into FL pipeline and train\nFL using a smaller synthetic dataset (referred as virtual data). Specifically,\nto harmonize the domain shifts, we propose iterative distribution matching to\ninpaint global information to local virtual data and use federated gradient\nmatching to distill global virtual data that serve as anchor points to rectify\nheterogeneous local training, without compromising data privacy. We experiment\non both benchmark and real-world datasets that contain heterogeneous data from\ndifferent sources, and further scale up to an FL scenario that contains a large\nnumber of clients with heterogeneous and class-imbalanced data. Our method\noutperforms state-of-the-art heterogeneous FL algorithms under various\nsettings. Our code is available at https://github.com/ubc-tea/FedLGD.\n","authors":["Chun-Yin Huang","Ruinan Jin","Can Zhao","Daguang Xu","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2303.02278v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00987v2","updated":"2025-03-12T00:43:45Z","published":"2025-02-03T01:59:45Z","title":"RandLoRA: Full-rank parameter-efficient fine-tuning of large models","summary":"  Low-Rank Adaptation (LoRA) and its variants have shown impressive results in\nreducing the number of trainable parameters and memory requirements of large\ntransformer networks while maintaining fine-tuning performance. The low-rank\nnature of the weight update inherently limits the representation power of\nfine-tuned models, however, thus potentially compromising performance on\ncomplex tasks. This raises a critical question: when a performance gap between\nLoRA and standard fine-tuning is observed, is it due to the reduced number of\ntrainable parameters or the rank deficiency? This paper aims to answer this\nquestion by introducing RandLoRA, a parameter-efficient method that performs\nfull-rank updates using a learned linear combinations of low-rank,\nnon-trainable random matrices. Our method limits the number of trainable\nparameters by restricting optimization to diagonal scaling matrices applied to\nthe fixed random matrices. This allows us to effectively overcome the low-rank\nlimitations while maintaining parameter and memory efficiency during training.\nThrough extensive experimentation across vision, language, and vision-language\nbenchmarks, we systematically evaluate the limitations of LoRA and existing\nrandom basis methods. Our findings reveal that full-rank updates are beneficial\nacross vision and language tasks individually, and even more so for\nvision-language tasks, where RandLoRA significantly reduces -- and sometimes\neliminates -- the performance gap between standard fine-tuning and LoRA,\ndemonstrating its efficacy.\n","authors":["Paul Albert","Frederic Z. Zhang","Hemanth Saratchandran","Cristian Rodriguez-Opazo","Anton van den Hengel","Ehsan Abbasnejad"],"pdf_url":"https://arxiv.org/pdf/2502.00987v2.pdf","comment":"To appear at the International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2412.13196v2","updated":"2025-03-12T00:40:43Z","published":"2024-12-17T18:59:51Z","title":"ExBody2: Advanced Expressive Humanoid Whole-Body Control","summary":"  This paper tackles the challenge of enabling real-world humanoid robots to\nperform expressive and dynamic whole-body motions while maintaining overall\nstability and robustness. We propose Advanced Expressive Whole-Body Control\n(Exbody2), a method for producing whole-body tracking controllers that are\ntrained on both human motion capture and simulated data and then transferred to\nthe real world. We introduce a technique for decoupling the velocity tracking\nof the entire body from tracking body landmarks. We use a teacher policy to\nproduce intermediate data that better conforms to the robot's kinematics and to\nautomatically filter away infeasible whole-body motions. This two-step approach\nenabled us to produce a student policy that can be deployed on the robot that\ncan walk, crouch, and dance. We also provide insight into the trade-off between\nversatility and the tracking performance on specific motions. We observed\nsignificant improvement of tracking performance after fine-tuning on a small\namount of data, at the expense of the others.\n","authors":["Mazeyu Ji","Xuanbin Peng","Fangchen Liu","Jialong Li","Ge Yang","Xuxin Cheng","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2412.13196v2.pdf","comment":"website: https://exbody2.github.io"},{"id":"http://arxiv.org/abs/2412.00071v2","updated":"2025-03-12T00:36:08Z","published":"2024-11-26T03:50:52Z","title":"COAP: Memory-Efficient Training with Correlation-Aware Gradient\n  Projection","summary":"  Training large-scale neural networks in vision, and multimodal domains\ndemands substantial memory resources, primarily due to the storage of optimizer\nstates. While LoRA, a popular parameter-efficient method, reduces memory usage,\nit often suffers from suboptimal performance due to the constraints of low-rank\nupdates. Low-rank gradient projection methods (e.g., GaLore, Flora) reduce\noptimizer memory by projecting gradients and moment estimates into low-rank\nspaces via singular value decomposition or random projection. However, they\nfail to account for inter-projection correlation, causing performance\ndegradation, and their projection strategies often incur high computational\ncosts. In this paper, we present COAP (Correlation-Aware Gradient Projection),\na memory-efficient method that minimizes computational overhead while\nmaintaining training performance. Evaluated across various vision, language,\nand multimodal tasks, COAP outperforms existing methods in both training speed\nand model performance. For LLaMA-1B, it reduces optimizer memory by 61% with\nonly 2% additional time cost, achieving the same PPL as AdamW. With 8-bit\nquantization, COAP cuts optimizer memory by 81% and achieves 4x speedup over\nGaLore for LLaVA-v1.5-7B fine-tuning, while delivering higher accuracy.\n","authors":["Jinqi Xiao","Shen Sang","Tiancheng Zhi","Jing Liu","Qing Yan","Yuqian Zhang","Linjie Luo","Bo Yuan"],"pdf_url":"https://arxiv.org/pdf/2412.00071v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2410.02056v2","updated":"2025-03-12T00:25:08Z","published":"2024-10-02T22:05:36Z","title":"Synthio: Augmenting Small-Scale Audio Classification Datasets with\n  Synthetic Data","summary":"  We present Synthio, a novel approach for augmenting small-scale audio\nclassification datasets with synthetic data. Our goal is to improve audio\nclassification accuracy with limited labeled data. Traditional data\naugmentation techniques, which apply artificial transformations (e.g., adding\nrandom noise or masking segments), struggle to create data that captures the\ntrue diversity present in real-world audios. To address this shortcoming, we\npropose to augment the dataset with synthetic audio generated from\ntext-to-audio (T2A) diffusion models. However, synthesizing effective\naugmentations is challenging because not only should the generated data be\nacoustically consistent with the underlying small-scale dataset, but they\nshould also have sufficient compositional diversity. To overcome the first\nchallenge, we align the generations of the T2A model with the small-scale\ndataset using preference optimization. This ensures that the acoustic\ncharacteristics of the generated data remain consistent with the small-scale\ndataset. To address the second challenge, we propose a novel caption generation\ntechnique that leverages the reasoning capabilities of Large Language Models to\n(1) generate diverse and meaningful audio captions and (2) iteratively refine\ntheir quality. The generated captions are then used to prompt the aligned T2A\nmodel. We extensively evaluate Synthio on ten datasets and four simulated\nlimited-data settings. Results indicate our method consistently outperforms all\nbaselines by 0.1%-39% using a T2A model trained only on weakly-captioned\nAudioSet.\n","authors":["Sreyan Ghosh","Sonal Kumar","Zhifeng Kong","Rafael Valle","Bryan Catanzaro","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2410.02056v2.pdf","comment":"Accepted at ICLR 2025. Code and Checkpoints available here:\n  https://github.com/Sreyan88/Synthio"},{"id":"http://arxiv.org/abs/2503.09901v1","updated":"2025-03-12T23:43:57Z","published":"2025-03-12T23:43:57Z","title":"AI Rivalry as a Craft: How Resisting and Embracing Generative AI Reshape\n  Writing Professions","summary":"  Generative AI (GAI) technologies are disrupting professional writing,\nchallenging traditional practices. Recent studies explore GAI adoption\nexperiences of creative practitioners, but we know little about how these\nexperiences evolve into established practices and how GAI resistance alters\nthese practices. To address this gap, we conducted 25 semi-structured\ninterviews with writing professionals who adopted and/or resisted GAI. Using\nthe theoretical lens of Job Crafting, we identify four strategies professionals\nemploy to reshape their roles. Writing professionals employed GAI resisting\nstrategies to maximize human potential, reinforce professional identity, carve\nout a professional niche, and preserve credibility within their networks. In\ncontrast, GAI-enabled strategies allowed writers who embraced GAI to enhance\ndesirable workflows, minimize mundane tasks, and engage in new AI-managerial\nlabor. These strategies amplified their collaborations with GAI while reducing\ntheir reliance on other people. We conclude by discussing implications of GAI\npractices on writers' identity and practices as well as crafting theory.\n","authors":["Rama Adithya Varanasi","Batia Mishan Wiesenfeld","Oded Nov"],"pdf_url":"https://arxiv.org/pdf/2503.09901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21057v3","updated":"2025-03-12T23:39:47Z","published":"2025-02-28T13:58:22Z","title":"Robust Deterministic Policy Gradient for Disturbance Attenuation and Its\n  Application to Quadrotor Control","summary":"  Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.\n","authors":["Taeho Lee","Donghwan Lee"],"pdf_url":"https://arxiv.org/pdf/2502.21057v3.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2503.09896v1","updated":"2025-03-12T23:29:08Z","published":"2025-03-12T23:29:08Z","title":"A Rule Based Solution to Co-reference Resolution in Clinical Text","summary":"  Objective: The aim of this study was to build an effective co-reference\nresolution system tailored for the biomedical domain. Materials and Methods:\nExperiment materials used in this study is provided by the 2011 i2b2 Natural\nLanguage Processing Challenge. The 2011 i2b2 challenge involves coreference\nresolution in medical documents. Concept mentions have been annotated in\nclinical texts, and the mentions that co-refer in each document are to be\nlinked by coreference chains. Normally, there are two ways of constructing a\nsystem to automatically discover co-referent links. One is to manually build\nrules for co-reference resolution, and the other category of approaches is to\nuse machine learning systems to learn automatically from training datasets and\nthen perform the resolution task on testing datasets. Results: Experiments show\nthe existing co-reference resolution systems are able to find some of the\nco-referent links, and our rule based system performs well finding the majority\nof the co-referent links. Our system achieved 89.6% overall performance on\nmultiple medical datasets. Conclusion: The experiment results show that\nmanually crafted rules based on observation of training data is a valid way to\naccomplish high performance in this coreference resolution task for the\ncritical biomedical domain.\n","authors":["Ping Chen","David Hinote","Guoqing Chen"],"pdf_url":"https://arxiv.org/pdf/2503.09896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11360v3","updated":"2025-03-12T22:40:12Z","published":"2024-09-17T17:07:30Z","title":"AI Suggestions Homogenize Writing Toward Western Styles and Diminish\n  Cultural Nuances","summary":"  Large language models (LLMs) are being increasingly integrated into everyday\nproducts and services, such as coding tools and writing assistants. As these\nembedded AI applications are deployed globally, there is a growing concern that\nthe AI models underlying these applications prioritize Western values. This\npaper investigates what happens when a Western-centric AI model provides\nwriting suggestions to users from a different cultural background. We conducted\na cross-cultural controlled experiment with 118 participants from India and the\nUnited States who completed culturally grounded writing tasks with and without\nAI suggestions. Our analysis reveals that AI provided greater efficiency gains\nfor Americans compared to Indians. Moreover, AI suggestions led Indian\nparticipants to adopt Western writing styles, altering not just what is written\nbut also how it is written. These findings show that Western-centric AI models\nhomogenize writing toward Western norms, diminishing nuances that differentiate\ncultural expression.\n","authors":["Dhruv Agarwal","Mor Naaman","Aditya Vashistha"],"pdf_url":"https://arxiv.org/pdf/2409.11360v3.pdf","comment":"Accepted at CHI 2025"},{"id":"http://arxiv.org/abs/2502.19771v2","updated":"2025-03-12T22:35:38Z","published":"2025-02-27T05:14:04Z","title":"The erasure of intensive livestock farming in text-to-image generative\n  AI","summary":"  Generative AI (e.g., ChatGPT) is increasingly integrated into people's daily\nlives. While it is known that AI perpetuates biases against marginalized human\ngroups, their impact on non-human animals remains understudied. We found that\nChatGPT's text-to-image model (DALL-E 3) introduces a strong bias toward\nromanticizing livestock farming as dairy cows on pasture and pigs rooting in\nmud. This bias remained when we requested realistic depictions and was only\nmitigated when the automatic prompt revision was inhibited. Most farmed animal\nin industrialized countries are reared indoors with limited space per animal,\nwhich fail to resonate with societal values. Inhibiting prompt revision\nresulted in images that more closely reflected modern farming practices; for\nexample, cows housed indoors accessing feed through metal headlocks, and pigs\nbehind metal railings on concrete floors in indoor facilities. While OpenAI\nintroduced prompt revision to mitigate bias, in the case of farmed animal\nproduction systems, it paradoxically introduces a strong bias towards\nunrealistic farming practices.\n","authors":["Kehan Sheng","Frank A. M. Tuyttens","Marina A. G. von Keyserlingk"],"pdf_url":"https://arxiv.org/pdf/2502.19771v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09878v1","updated":"2025-03-12T22:18:29Z","published":"2025-03-12T22:18:29Z","title":"CleverDistiller: Simple and Spatially Consistent Cross-modal\n  Distillation","summary":"  Vision foundation models (VFMs) such as DINO have led to a paradigm shift in\n2D camera-based perception towards extracting generalized features to support\nmany downstream tasks. Recent works introduce self-supervised cross-modal\nknowledge distillation (KD) as a way to transfer these powerful generalization\ncapabilities into 3D LiDAR-based models. However, they either rely on highly\ncomplex distillation losses, pseudo-semantic maps, or limit KD to features\nuseful for semantic segmentation only. In this work, we propose\nCleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework\nintroducing a set of simple yet effective design choices: Unlike contrastive\napproaches relying on complex loss design choices, our method employs a direct\nfeature similarity loss in combination with a multi layer perceptron (MLP)\nprojection head to allow the 3D network to learn complex semantic dependencies\nthroughout the projection. Crucially, our approach does not depend on\npseudo-semantic maps, allowing for direct knowledge transfer from a VFM without\nexplicit semantic supervision. Additionally, we introduce the auxiliary\nself-supervised spatial task of occupancy prediction to enhance the semantic\nknowledge, obtained from a VFM through KD, with 3D spatial reasoning\ncapabilities. Experiments on standard autonomous driving benchmarks for\n2D-to-3D KD demonstrate that CleverDistiller achieves state-of-the-art\nperformance in both semantic segmentation and 3D object detection (3DOD) by up\nto 10% mIoU, especially when fine tuning on really low data amounts, showing\nthe effectiveness of our simple yet powerful KD strategy\n","authors":["Hariprasath Govindarajan","Maciej K. Wozniak","Marvin Klingner","Camille Maurice","B Ravi Kiran","Senthil Yogamani"],"pdf_url":"https://arxiv.org/pdf/2503.09878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14831v2","updated":"2025-03-12T22:08:10Z","published":"2025-02-20T18:45:44Z","title":"Improving the Diffusability of Autoencoders","summary":"  Latent diffusion models have emerged as the leading approach for generating\nhigh-quality images and videos, utilizing compressed latent representations to\nreduce the computational burden of the diffusion process. While recent\nadvancements have primarily focused on scaling diffusion backbones and\nimproving autoencoder reconstruction quality, the interaction between these\ncomponents has received comparatively less attention. In this work, we perform\na spectral analysis of modern autoencoders and identify inordinate\nhigh-frequency components in their latent spaces, which are especially\npronounced in the autoencoders with a large bottleneck channel size. We\nhypothesize that this high-frequency component interferes with the\ncoarse-to-fine nature of the diffusion synthesis process and hinders the\ngeneration quality. To mitigate the issue, we propose scale equivariance: a\nsimple regularization strategy that aligns latent and RGB spaces across\nfrequencies by enforcing scale equivariance in the decoder. It requires minimal\ncode changes and only up to 20K autoencoder fine-tuning steps, yet\nsignificantly improves generation quality, reducing FID by 19% for image\ngeneration on ImageNet-1K 256x256 and FVD by at least 44% for video generation\non Kinetics-700 17x256x256.\n","authors":["Ivan Skorokhodov","Sharath Girish","Benran Hu","Willi Menapace","Yanyu Li","Rameen Abdal","Sergey Tulyakov","Aliaksandr Siarohin"],"pdf_url":"https://arxiv.org/pdf/2502.14831v2.pdf","comment":"26 pages, 22 figures, 9 tables"},{"id":"http://arxiv.org/abs/2503.09858v1","updated":"2025-03-12T21:39:38Z","published":"2025-03-12T21:39:38Z","title":"Media and responsible AI governance: a game-theoretic and LLM analysis","summary":"  This paper investigates the complex interplay between AI developers,\nregulators, users, and the media in fostering trustworthy AI systems. Using\nevolutionary game theory and large language models (LLMs), we model the\nstrategic interactions among these actors under different regulatory regimes.\nThe research explores two key mechanisms for achieving responsible governance,\nsafe AI development and adoption of safe AI: incentivising effective regulation\nthrough media reporting, and conditioning user trust on commentariats'\nrecommendation. The findings highlight the crucial role of the media in\nproviding information to users, potentially acting as a form of \"soft\"\nregulation by investigating developers or regulators, as a substitute to\ninstitutional AI regulation (which is still absent in many regions). Both\ngame-theoretic analysis and LLM-based simulations reveal conditions under which\neffective regulation and trustworthy AI development emerge, emphasising the\nimportance of considering the influence of different regulatory regimes from an\nevolutionary game-theoretic perspective. The study concludes that effective\ngovernance requires managing incentives and costs for high quality\ncommentaries.\n","authors":["Nataliya Balabanova","Adeela Bashir","Paolo Bova","Alessio Buscemi","Theodor Cimpeanu","Henrique Correia da Fonseca","Alessandro Di Stefano","Manh Hong Duong","Elias Fernandez Domingos","Antonio Fernandes","The Anh Han","Marcus Krellner","Ndidi Bianca Ogbo","Simon T. Powers","Daniele Proverbio","Fernando P. Santos","Zia Ush Shamszaman","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2503.09858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08099v4","updated":"2025-03-12T21:35:52Z","published":"2024-12-11T04:53:15Z","title":"Adversarial Vulnerabilities in Large Language Models for Time Series\n  Forecasting","summary":"  Large Language Models (LLMs) have recently demonstrated significant potential\nin time series forecasting, offering impressive capabilities in handling\ncomplex temporal data. However, their robustness and reliability in real-world\napplications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like LLMTime with GPT-3.5, GPT-4, LLaMa, and\nMistral, TimeGPT, and TimeLLM show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications. The code repository can be found at\nhttps://github.com/JohnsonJiang1996/AdvAttack_LLM4TS.\n","authors":["Fuqiang Liu","Sicong Jiang","Luis Miranda-Moreno","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2412.08099v4.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2409.10419v2","updated":"2025-03-12T21:30:37Z","published":"2024-09-16T15:50:39Z","title":"HiFi-CS: Towards Open Vocabulary Visual Grounding For Robotic Grasping\n  Using Vision-Language Models","summary":"  Robots interacting with humans through natural language can unlock numerous\napplications such as Referring Grasp Synthesis (RGS). Given a text query, RGS\ndetermines a stable grasp pose to manipulate the referred object in the robot's\nworkspace. RGS comprises two steps: visual grounding and grasp pose estimation.\nRecent studies leverage powerful Vision-Language Models (VLMs) for visually\ngrounding free-flowing natural language in real-world robotic execution.\nHowever, comparisons in complex, cluttered environments with multiple instances\nof the same object are lacking. This paper introduces HiFi-CS, featuring\nhierarchical application of Featurewise Linear Modulation (FiLM) to fuse image\nand text embeddings, enhancing visual grounding for complex attribute rich text\nqueries encountered in robotic grasping. Visual grounding associates an object\nin 2D/3D space with natural language input and is studied in two scenarios:\nClosed and Open Vocabulary. HiFi-CS features a lightweight decoder combined\nwith a frozen VLM and outperforms competitive baselines in closed vocabulary\nsettings while being 100x smaller in size. Our model can effectively guide\nopen-set object detectors like GroundedSAM to enhance open-vocabulary\nperformance. We validate our approach through real-world RGS experiments using\na 7-DOF robotic arm, achieving 90.33\\% visual grounding accuracy in 15 tabletop\nscenes. Our codebase is provided here: https://github.com/vineet2104/hifics\n","authors":["Vineet Bhat","Prashanth Krishnamurthy","Ramesh Karri","Farshad Khorrami"],"pdf_url":"https://arxiv.org/pdf/2409.10419v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09853v1","updated":"2025-03-12T21:24:22Z","published":"2025-03-12T21:24:22Z","title":"Who Are You Behind the Screen? Implicit MBTI and Gender Detection Using\n  Artificial Intelligence","summary":"  In personalized technology and psychological research, precisely detecting\ndemographic features and personality traits from digital interactions becomes\never more important. This work investigates implicit categorization, inferring\npersonality and gender variables directly from linguistic patterns in Telegram\nconversation data, while conventional personality prediction techniques mostly\ndepend on explicitly self-reported labels. We refine a Transformer-based\nlanguage model (RoBERTa) to capture complex linguistic cues indicative of\npersonality traits and gender differences using a dataset comprising 138,866\nmessages from 1,602 users annotated with MBTI types and 195,016 messages from\n2,598 users annotated with gender. Confidence levels help to greatly raise\nmodel accuracy to 86.16\\%, hence proving RoBERTa's capacity to consistently\nidentify implicit personality types from conversational text data. Our results\nhighlight the usefulness of Transformer topologies for implicit personality and\ngender classification, hence stressing their efficiency and stressing important\ntrade-offs between accuracy and coverage in realistic conversational\nenvironments. With regard to gender classification, the model obtained an\naccuracy of 74.4\\%, therefore capturing gender-specific language patterns.\nPersonality dimension analysis showed that people with introverted and\nintuitive preferences are especially more active in text-based interactions.\nThis study emphasizes practical issues in balancing accuracy and data coverage\nas Transformer-based models show their efficiency in implicit personality and\ngender prediction tasks from conversational texts.\n","authors":["Kourosh Shahnazari","Seyed Moein Ayyoubzadeh"],"pdf_url":"https://arxiv.org/pdf/2503.09853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.12634v3","updated":"2025-03-12T21:16:45Z","published":"2023-12-19T22:33:17Z","title":"MotionScript: Natural Language Descriptions for Expressive 3D Human\n  Motions","summary":"  We introduce MotionScript, a novel framework for generating highly detailed,\nnatural language descriptions of 3D human motions. Unlike existing motion\ndatasets that rely on broad action labels or generic captions, MotionScript\nprovides fine-grained, structured descriptions that capture the full complexity\nof human movement including expressive actions (e.g., emotions, stylistic\nwalking) and interactions beyond standard motion capture datasets. MotionScript\nserves as both a descriptive tool and a training resource for text-to-motion\nmodels, enabling the synthesis of highly realistic and diverse human motions\nfrom text. By augmenting motion datasets with MotionScript captions, we\ndemonstrate significant improvements in out-of-distribution motion generation,\nallowing large language models (LLMs) to generate motions that extend beyond\nexisting data. Additionally, MotionScript opens new applications in animation,\nvirtual human simulation, and robotics, providing an interpretable bridge\nbetween intuitive descriptions and motion synthesis. To the best of our\nknowledge, this is the first attempt to systematically translate 3D motion into\nstructured natural language without requiring training data.\n","authors":["Payam Jome Yazdian","Rachel Lagasse","Hamid Mohammadi","Eric Liu","Li Cheng","Angelica Lim"],"pdf_url":"https://arxiv.org/pdf/2312.12634v3.pdf","comment":"Project webpage: https://pjyazdian.github.io/MotionScript"},{"id":"http://arxiv.org/abs/2503.09849v1","updated":"2025-03-12T21:13:34Z","published":"2025-03-12T21:13:34Z","title":"Training Human-Robot Teams by Improving Transparency Through a Virtual\n  Spectator Interface","summary":"  After-action reviews (AARs) are professional discussions that help operators\nand teams enhance their task performance by analyzing completed missions with\npeers and professionals. Previous studies that compared different formats of\nAARs have mainly focused on human teams. However, the inclusion of robotic\nteammates brings along new challenges in understanding teammate intent and\ncommunication. Traditional AAR between human teammates may not be satisfactory\nfor human-robot teams. To address this limitation, we propose a new training\nreview (TR) tool, called the Virtual Spectator Interface (VSI), to enhance\nhuman-robot team performance and situational awareness (SA) in a simulated\nsearch mission. The proposed VSI primarily utilizes visual feedback to review\nsubjects' behavior. To examine the effectiveness of VSI, we took elements from\nAAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with\nexperimental conditions: TR with (1) VSI, (2) screen recording, and (3)\nnon-technology (only verbal descriptions). The results of our experiments\ndemonstrated that the VSI did not result in significantly better team\nperformance than other conditions. However, the TR with VSI led to more\nimprovement in the subjects SA over the other conditions.\n","authors":["Sean Dallas","Hongjiao Qiang","Motaz AbuHijleh","Wonse Jo","Kayla Riegner","Jon Smereka","Lionel Robert","Wing-Yue Louie","Dawn M. Tilbury"],"pdf_url":"https://arxiv.org/pdf/2503.09849v1.pdf","comment":"7 pages, 4 figures, Accepted to ICRA 2025"},{"id":"http://arxiv.org/abs/2503.09837v1","updated":"2025-03-12T20:58:16Z","published":"2025-03-12T20:58:16Z","title":"On the Limitations of Vision-Language Models in Understanding Image\n  Transforms","summary":"  Vision Language Models (VLMs) have demonstrated significant potential in\nvarious downstream tasks, including Image/Video Generation, Visual Question\nAnswering, Multimodal Chatbots, and Video Understanding. However, these models\noften struggle with basic image transformations. This paper investigates the\nimage-level understanding of VLMs, specifically CLIP by OpenAI and SigLIP by\nGoogle. Our findings reveal that these models lack comprehension of multiple\nimage-level augmentations. To facilitate this study, we created an augmented\nversion of the Flickr8k dataset, pairing each image with a detailed description\nof the applied transformation. We further explore how this deficiency impacts\ndownstream tasks, particularly in image editing, and evaluate the performance\nof state-of-the-art Image2Image models on simple transformations.\n","authors":["Ahmad Mustafa Anis","Hasnain Ali","Saquib Sarfraz"],"pdf_url":"https://arxiv.org/pdf/2503.09837v1.pdf","comment":"8 pages, 15 images"},{"id":"http://arxiv.org/abs/2412.05256v3","updated":"2025-03-12T20:57:59Z","published":"2024-12-06T18:41:39Z","title":"Extrapolated Urban View Synthesis Benchmark","summary":"  Photorealistic simulators are essential for the training and evaluation of\nvision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis\n(NVS), a crucial capability that generates diverse unseen viewpoints to\naccommodate the broad and continuous pose distribution of AVs. Recent advances\nin radiance fields, such as 3D Gaussian Splatting, achieve photorealistic\nrendering at real-time speeds and have been widely used in modeling large-scale\ndriving scenes. However, their performance is commonly evaluated using an\ninterpolated setup with highly correlated training and test views. In contrast,\nextrapolation, where test views largely deviate from training views, remains\nunderexplored, limiting progress in generalizable simulation technology. To\naddress this gap, we leverage publicly available AV datasets with multiple\ntraversals, multiple vehicles, and multiple cameras to build the first\nExtrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct both\nquantitative and qualitative evaluations of state-of-the-art NVS methods across\ndifferent evaluation settings. Our results show that current NVS methods are\nprone to overfitting to training views. Besides, incorporating diffusion priors\nand improving geometry cannot fundamentally improve NVS under large view\nchanges, highlighting the need for more robust approaches and large-scale\ntraining. We will release the data to help advance self-driving and urban\nrobotics simulation technology.\n","authors":["Xiangyu Han","Zhen Jia","Boyi Li","Yan Wang","Boris Ivanovic","Yurong You","Lingjie Liu","Yue Wang","Marco Pavone","Chen Feng","Yiming Li"],"pdf_url":"https://arxiv.org/pdf/2412.05256v3.pdf","comment":"Project page: https://ai4ce.github.io/EUVS-Benchmark/"},{"id":"http://arxiv.org/abs/2501.07601v3","updated":"2025-03-12T20:56:35Z","published":"2025-01-10T22:31:53Z","title":"Real-Time Decision-Making for Digital Twin in Additive Manufacturing\n  with Model Predictive Control using Time-Series Deep Neural Networks","summary":"  Digital Twin -- a virtual replica of a physical system enabling real-time\nmonitoring, model updating, prediction, and decision-making -- combined with\nrecent advances in machine learning, offers new opportunities for proactive\ncontrol strategies in autonomous manufacturing. However, achieving real-time\ndecision-making with Digital Twins requires efficient optimization driven by\naccurate predictions of highly nonlinear manufacturing systems. This paper\npresents a simultaneous multi-step Model Predictive Control (MPC) framework for\nreal-time decision-making, using a multivariate deep neural network, named\nTime-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional\nMPC models which only provide one-step ahead prediction, TiDE is capable of\npredicting future states within the prediction horizon in one shot\n(multi-step), significantly accelerating the MPC. Using Directed Energy\nDeposition (DED) additive manufacturing as a case study, we demonstrate the\neffectiveness of the proposed MPC in achieving melt pool temperature tracking\nto ensure part quality, while reducing porosity defects by regulating laser\npower to maintain melt pool depth constraints. In this work, we first show that\nTiDE is capable of accurately predicting melt pool temperature and depth.\nSecond, we demonstrate that the proposed MPC achieves precise temperature\ntracking while satisfying melt pool depth constraints within a targeted\ndilution range (10\\%-30\\%), reducing potential porosity defects. Compared to\nPID controller, the MPC results in smoother and less fluctuating laser power\nprofiles with competitive or superior melt pool temperature control\nperformance. This demonstrates the MPC's proactive control capabilities,\nleveraging time-series prediction and real-time optimization, positioning it as\na powerful tool for future Digital Twin applications and real-time process\noptimization in manufacturing.\n","authors":["Yi-Ping Chen","Vispi Karkaria","Ying-Kuan Tsai","Faith Rolark","Daniel Quispe","Robert X. Gao","Jian Cao","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2501.07601v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11295v5","updated":"2025-03-12T20:54:00Z","published":"2024-09-17T15:49:44Z","title":"EIA: Environmental Injection Attack on Generalist Web Agents for Privacy\n  Leakage","summary":"  Generalist web agents have demonstrated remarkable potential in autonomously\ncompleting a wide range of tasks on real websites, significantly boosting human\nproductivity. However, web tasks, such as booking flights, usually involve\nusers' PII, which may be exposed to potential privacy risks if web agents\naccidentally interact with compromised websites, a scenario that remains\nlargely unexplored in the literature. In this work, we narrow this gap by\nconducting the first study on the privacy risks of generalist web agents in\nadversarial environments. First, we present a realistic threat model for\nattacks on the website, where we consider two adversarial targets: stealing\nusers' specific PII or the entire user request. Then, we propose a novel attack\nmethod, termed Environmental Injection Attack (EIA). EIA injects malicious\ncontent designed to adapt well to environments where the agents operate and our\nwork instantiates EIA specifically for privacy scenarios in web environments.\nWe collect 177 action steps that involve diverse PII categories on realistic\nwebsites from the Mind2Web, and conduct experiments using one of the most\ncapable generalist web agent frameworks to date. The results demonstrate that\nEIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user\nrequest. Additionally, by accessing the stealthiness and experimenting with a\ndefensive system prompt, we indicate that EIA is hard to detect and mitigate.\nNotably, attacks that are not well adapted for a webpage can be detected via\nhuman inspection, leading to our discussion about the trade-off between\nsecurity and autonomy. However, extra attackers' efforts can make EIA\nseamlessly adapted, rendering such supervision ineffective. Thus, we further\ndiscuss the defenses at the pre- and post-deployment stages of the websites\nwithout relying on human supervision and call for more advanced defense\nstrategies.\n","authors":["Zeyi Liao","Lingbo Mo","Chejian Xu","Mintong Kang","Jiawei Zhang","Chaowei Xiao","Yuan Tian","Bo Li","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2409.11295v5.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09822v1","updated":"2025-03-12T20:40:09Z","published":"2025-03-12T20:40:09Z","title":"Generative AI for Named Entity Recognition in Low-Resource Language\n  Nepali","summary":"  Generative Artificial Intelligence (GenAI), particularly Large Language\nModels (LLMs), has significantly advanced Natural Language Processing (NLP)\ntasks, such as Named Entity Recognition (NER), which involves identifying\nentities like person, location, and organization names in text. LLMs are\nespecially promising for low-resource languages due to their ability to learn\nfrom limited data. However, the performance of GenAI models for Nepali, a\nlow-resource language, has not been thoroughly evaluated. This paper\ninvestigates the application of state-of-the-art LLMs for Nepali NER,\nconducting experiments with various prompting techniques to assess their\neffectiveness. Our results provide insights into the challenges and\nopportunities of using LLMs for NER in low-resource settings and offer valuable\ncontributions to the advancement of NLP research in languages like Nepali.\n","authors":["Sameer Neupane","Jeevan Chapagain","Nobal B. Niraula","Diwa Koirala"],"pdf_url":"https://arxiv.org/pdf/2503.09822v1.pdf","comment":"This paper has been accepted in the FLAIRS Conference 2025"},{"id":"http://arxiv.org/abs/2503.09820v1","updated":"2025-03-12T20:38:23Z","published":"2025-03-12T20:38:23Z","title":"Vi-LAD: Vision-Language Attention Distillation for Socially-Aware Robot\n  Navigation in Dynamic Environments","summary":"  We introduce Vision-Language Attention Distillation (Vi-LAD), a novel\napproach for distilling socially compliant navigation knowledge from a large\nVision-Language Model (VLM) into a lightweight transformer model for real-time\nrobotic navigation. Unlike traditional methods that rely on expert\ndemonstrations or human-annotated datasets, Vi-LAD performs knowledge\ndistillation and fine-tuning at the intermediate layer representation level\n(i.e., attention maps) by leveraging the backbone of a pre-trained\nvision-action model. These attention maps highlight key navigational regions in\na given scene, which serve as implicit guidance for socially aware motion\nplanning. Vi-LAD fine-tunes a transformer-based model using intermediate\nattention maps extracted from the pre-trained vision-action model, combined\nwith attention-like semantic maps constructed from a large VLM. To achieve\nthis, we introduce a novel attention-level distillation loss that fuses\nknowledge from both sources, generating augmented attention maps with enhanced\nsocial awareness. These refined attention maps are then utilized as a\ntraversability costmap within a socially aware model predictive controller\n(MPC) for navigation. We validate our approach through real-world experiments\non a Husky wheeled robot, demonstrating significant improvements over\nstate-of-the-art (SOTA) navigation methods. Our results show up to 14.2% - 50%\nimprovement in success rate, which highlights the effectiveness of Vi-LAD in\nenabling socially compliant and efficient robot navigation.\n","authors":["Mohamed Elnoor","Kasun Weerakoon","Gershom Seneviratne","Jing Liang","Vignesh Rajagopal","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2503.09820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09817v1","updated":"2025-03-12T20:30:07Z","published":"2025-03-12T20:30:07Z","title":"Temporal Difference Flows","summary":"  Predictive models of the future are fundamental for an agent's ability to\nreason and plan. A common strategy learns a world model and unrolls it\nstep-by-step at inference, where small errors can rapidly compound. Geometric\nHorizon Models (GHMs) offer a compelling alternative by directly making\npredictions of future states, avoiding cumulative inference errors. While GHMs\ncan be conveniently learned by a generative analog to temporal difference (TD)\nlearning, existing methods are negatively affected by bootstrapping predictions\nat train time and struggle to generate high-quality predictions at long\nhorizons. This paper introduces Temporal Difference Flows (TD-Flow), which\nleverages the structure of a novel Bellman equation on probability paths\nalongside flow-matching techniques to learn accurate GHMs at over 5x the\nhorizon length of prior methods. Theoretically, we establish a new convergence\nresult and primarily attribute TD-Flow's efficacy to reduced gradient variance\nduring training. We further show that similar arguments can be extended to\ndiffusion-based methods. Empirically, we validate TD-Flow across a diverse set\nof domains on both generative metrics and downstream tasks including policy\nevaluation. Moreover, integrating TD-Flow with recent behavior foundation\nmodels for planning over pre-trained policies demonstrates substantial\nperformance gains, underscoring its promise for long-horizon decision-making.\n","authors":["Jesse Farebrother","Matteo Pirotta","Andrea Tirinzoni","Rémi Munos","Alessandro Lazaric","Ahmed Touati"],"pdf_url":"https://arxiv.org/pdf/2503.09817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09808v1","updated":"2025-03-12T20:19:07Z","published":"2025-03-12T20:19:07Z","title":"Fine-tuning Vision Language Models with Graph-based Knowledge for\n  Explainable Medical Image Analysis","summary":"  Accurate staging of Diabetic Retinopathy (DR) is essential for guiding timely\ninterventions and preventing vision loss. However, current staging models are\nhardly interpretable, and most public datasets contain no clinical reasoning or\ninterpretation beyond image-level labels. In this paper, we present a novel\nmethod that integrates graph representation learning with vision-language\nmodels (VLMs) to deliver explainable DR diagnosis. Our approach leverages\noptical coherence tomography angiography (OCTA) images by constructing\nbiologically informed graphs that encode key retinal vascular features such as\nvessel morphology and spatial connectivity. A graph neural network (GNN) then\nperforms DR staging while integrated gradients highlight critical nodes and\nedges and their individual features that drive the classification decisions. We\ncollect this graph-based knowledge which attributes the model's prediction to\nphysiological structures and their characteristics. We then transform it into\ntextual descriptions for VLMs. We perform instruction-tuning with these textual\ndescriptions and the corresponding image to train a student VLM. This final\nagent can classify the disease and explain its decision in a human\ninterpretable way solely based on a single image input. Experimental\nevaluations on both proprietary and public datasets demonstrate that our method\nnot only improves classification accuracy but also offers more clinically\ninterpretable results. An expert study further demonstrates that our method\nprovides more accurate diagnostic explanations and paves the way for precise\nlocalization of pathologies in OCTA images.\n","authors":["Chenjun Li","Laurin Lux","Alexander H. Berger","Martin J. Menten","Mert R. Sabuncu","Johannes C. Paetzold"],"pdf_url":"https://arxiv.org/pdf/2503.09808v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.09805v1","updated":"2025-03-12T20:16:38Z","published":"2025-03-12T20:16:38Z","title":"Un-Straightening Generative AI: How Queer Artists Surface and Challenge\n  the Normativity of Generative AI Models","summary":"  Queer people are often discussed as targets of bias, harm, or discrimination\nin research on generative AI. However, the specific ways that queer people\nengage with generative AI, and thus possible uses that support queer people,\nhave yet to be explored. We conducted a workshop study with 13 queer artists,\nduring which we gave participants access to GPT-4 and DALL-E 3 and facilitated\ngroup sensemaking activities. We found our participants struggled to use these\nmodels due to various normative values embedded in their designs, such as\nhyper-positivity and anti-sexuality. We describe various strategies our\nparticipants developed to overcome these models' limitations and how,\nnevertheless, our participants found value in these highly-normative\ntechnologies. Drawing on queer feminist theory, we discuss implications for the\nconceptualization of \"state-of-the-art\" models and consider how FAccT\nresearchers might support queer alternatives.\n","authors":["Jordan Taylor","Joel Mire","Franchesca Spektor","Alicia DeVrio","Maarten Sap","Haiyi Zhu","Sarah Fox"],"pdf_url":"https://arxiv.org/pdf/2503.09805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09797v1","updated":"2025-03-12T20:01:52Z","published":"2025-03-12T20:01:52Z","title":"SeqSAM: Autoregressive Multiple Hypothesis Prediction for Medical Image\n  Segmentation using SAM","summary":"  Pre-trained segmentation models are a powerful and flexible tool for\nsegmenting images. Recently, this trend has extended to medical imaging. Yet,\noften these methods only produce a single prediction for a given image,\nneglecting inherent uncertainty in medical images, due to unclear object\nboundaries and errors caused by the annotation tool. Multiple Choice Learning\nis a technique for generating multiple masks, through multiple learned\nprediction heads. However, this cannot readily be extended to producing more\noutputs than its initial pre-training hyperparameters, as the sparse,\nwinner-takes-all loss function makes it easy for one prediction head to become\noverly dominant, thus not guaranteeing the clinical relevancy of each mask\nproduced. We introduce SeqSAM, a sequential, RNN-inspired approach to\ngenerating multiple masks, which uses a bipartite matching loss for ensuring\nthe clinical relevancy of each mask, and can produce an arbitrary number of\nmasks. We show notable improvements in quality of each mask produced across two\npublicly available datasets. Our code is available at\nhttps://github.com/BenjaminTowle/SeqSAM.\n","authors":["Benjamin Towle","Xin Chen","Ke Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.09797v1.pdf","comment":"Accepted to ISBI 2025"},{"id":"http://arxiv.org/abs/2503.05858v2","updated":"2025-03-12T19:50:21Z","published":"2025-03-08T10:20:57Z","title":"Bimodal Connection Attention Fusion for Speech Emotion Recognition","summary":"  Multi-modal emotion recognition is challenging due to the difficulty of\nextracting features that capture subtle emotional differences. Understanding\nmulti-modal interactions and connections is key to building effective bimodal\nspeech emotion recognition systems. In this work, we propose Bimodal Connection\nAttention Fusion (BCAF) method, which includes three main modules: the\ninteractive connection network, the bimodal attention network, and the\ncorrelative attention network. The interactive connection network uses an\nencoder-decoder architecture to model modality connections between audio and\ntext while leveraging modality-specific features. The bimodal attention network\nenhances semantic complementation and exploits intra- and inter-modal\ninteractions. The correlative attention network reduces cross-modal noise and\ncaptures correlations between audio and text. Experiments on the MELD and\nIEMOCAP datasets demonstrate that the proposed BCAF method outperforms existing\nstate-of-the-art baselines.\n","authors":["Jiachen Luo","Huy Phan","Lin Wang","Joshua D. Reiss"],"pdf_url":"https://arxiv.org/pdf/2503.05858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.03133v2","updated":"2025-03-12T19:38:21Z","published":"2023-09-06T16:14:32Z","title":"On strategies for risk management and decision making under uncertainty\n  shared across multiple fields","summary":"  Decision theory recognizes two principal approaches to solving problems under\nuncertainty: probabilistic models and cognitive heuristics. However, engineers,\npublic planners and decision-makers in other fields seem to employ solution\nstrategies that do not fall into either field, i.e., strategies such as robust\ndesign and contingency planning. In addition, identical strategies appear in\nseveral fields and disciplines, pointing to an important shared toolkit.\n  The focus of this paper is to develop a systematic understanding of such\nstrategies and develop a framework to better employ them in decision making and\nrisk management. The paper finds more than 110 examples of such strategies and\nthis approach to risk is termed RDOT: Risk-reducing Design and Operations\nToolkit. RDOT strategies fall into six broad categories: structural, reactive,\nformal, adversarial, multi-stage and positive. RDOT strategies provide an\nefficient response even to radical uncertainty or unknown unknowns that are\nchallenging to address with probabilistic methods. RDOT could be incorporated\ninto decision theory using workflows, multi-objective optimization and\nmulti-attribute utility theory.\n  Overall, RDOT represents an overlooked class of versatile responses to\nuncertainty. Because RDOT strategies do not require precise estimation or\nforecasting, they are particularly helpful in decision problems affected by\nuncertainty and for resource-constrained decision making.\n","authors":["Alexander Gutfraind"],"pdf_url":"https://arxiv.org/pdf/2309.03133v2.pdf","comment":"v2: expanded catalog"},{"id":"http://arxiv.org/abs/2503.09780v1","updated":"2025-03-12T19:30:31Z","published":"2025-03-12T19:30:31Z","title":"AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents","summary":"  LLM-powered AI agents are an emerging frontier with tremendous potential to\nincrease human productivity. However, empowering AI agents to take action on\ntheir user's behalf in day-to-day tasks involves giving them access to\npotentially sensitive and private information, which leads to a possible risk\nof inadvertent privacy leakage when the agent malfunctions. In this work, we\npropose one way to address that potential risk, by training AI agents to better\nsatisfy the privacy principle of data minimization. For the purposes of this\nbenchmark, by \"data minimization\" we mean instances where private information\nis shared only when it is necessary to fulfill a specific task-relevant\npurpose. We develop a benchmark called AgentDAM to evaluate how well existing\nand future AI agents can limit processing of potentially private information\nthat we designate \"necessary\" to fulfill the task. Our benchmark simulates\nrealistic web interaction scenarios and is adaptable to all existing web\nnavigation agents. We use AgentDAM to evaluate how well AI agents built on top\nof GPT-4, Llama-3 and Claude can limit processing of potentially private\ninformation when unnecessary, and show that these agents are often prone to\ninadvertent use of unnecessary sensitive information. We finally propose a\nprompting-based approach that reduces this.\n","authors":["Arman Zharmagambetov","Chuan Guo","Ivan Evtimov","Maya Pavlova","Ruslan Salakhutdinov","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2503.09780v1.pdf","comment":"project page: https://github.com/facebookresearch/ai-agent-privacy"},{"id":"http://arxiv.org/abs/2403.17916v3","updated":"2025-03-12T19:03:13Z","published":"2024-03-26T17:53:27Z","title":"CMP: Cooperative Motion Prediction with Multi-Agent Communication","summary":"  The confluence of the advancement of Autonomous Vehicles (AVs) and the\nmaturity of Vehicle-to-Everything (V2X) communication has enabled the\ncapability of cooperative connected and automated vehicles (CAVs). Building on\ntop of cooperative perception, this paper explores the feasibility and\neffectiveness of cooperative motion prediction. Our method, CMP, takes LiDAR\nsignals as model input to enhance tracking and prediction capabilities. Unlike\nprevious work that focuses separately on either cooperative perception or\nmotion prediction, our framework, to the best of our knowledge, is the first to\naddress the unified problem where CAVs share information in both perception and\nprediction modules. Incorporated into our design is the unique capability to\ntolerate realistic V2X transmission delays, while dealing with bulky perception\nrepresentations. We also propose a prediction aggregation module, which unifies\nthe predictions obtained by different CAVs and generates the final prediction.\nThrough extensive experiments and ablation studies on the OPV2V and V2V4Real\ndatasets, we demonstrate the effectiveness of our method in cooperative\nperception, tracking, and motion prediction. In particular, CMP reduces the\naverage prediction error by 12.3% compared with the strongest baseline. Our\nwork marks a significant step forward in the cooperative capabilities of CAVs,\nshowcasing enhanced performance in complex scenarios. More details can be found\non the project website: https://cmp-cooperative-prediction.github.io.\n","authors":["Zehao Wang","Yuping Wang","Zhuoyuan Wu","Hengbo Ma","Zhaowei Li","Hang Qiu","Jiachen Li"],"pdf_url":"https://arxiv.org/pdf/2403.17916v3.pdf","comment":"IEEE Robotics and Automation Letters; Project website:\n  https://cmp-cooperative-prediction.github.io/"},{"id":"http://arxiv.org/abs/2410.02688v2","updated":"2025-03-12T18:52:20Z","published":"2024-10-03T17:15:53Z","title":"User-centric Immersive Communications in 6G: A Data-oriented Framework\n  via Digital Twin","summary":"  In this article, we present a novel user-centric service provision for\nimmersive communications (IC) in 6G to deal with the uncertainty of individual\nuser behaviors while satisfying unique requirements on the quality of\nmulti-sensory experience. To this end, we propose a data-oriented framework for\nnetwork resource management, featuring personalized data management that can\nsupport network modeling tailored to different user demands. Our framework\nleverages the digital twin (DT) technique as a key enabler. Particularly, a DT\nis established for each user, and the data attributes in the DT are customized\nbased on the characteristics of the user. The DT functions, corresponding to\nvarious data operations, are customized in the development, evaluation, and\nupdate of network models to meet unique user demands. A trace-driven case study\ndemonstrates the effectiveness of our framework in achieving user-centric IC\nand the significance of personalized data management in 6G.\n","authors":["Conghao Zhou","Shisheng Hu","Jie Gao","Xinyu Huang","Weihua Zhuang","Xuemin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.02688v2.pdf","comment":"Accepted by IEEE Wireless Communications"},{"id":"http://arxiv.org/abs/2503.09746v1","updated":"2025-03-12T18:45:22Z","published":"2025-03-12T18:45:22Z","title":"Solving Bayesian inverse problems with diffusion priors and off-policy\n  RL","summary":"  This paper presents a practical application of Relative Trajectory Balance\n(RTB), a recently introduced off-policy reinforcement learning (RL) objective\nthat can asymptotically solve Bayesian inverse problems optimally. We extend\nthe original work by using RTB to train conditional diffusion model posteriors\nfrom pretrained unconditional priors for challenging linear and non-linear\ninverse problems in vision, and science. We use the objective alongside\ntechniques such as off-policy backtracking exploration to improve training.\nImportantly, our results show that existing training-free diffusion posterior\nmethods struggle to perform effective posterior inference in latent space due\nto inherent biases.\n","authors":["Luca Scimeca","Siddarth Venkatraman","Moksh Jain","Minsu Kim","Marcin Sendera","Mohsin Hasan","Luke Rowe","Sarthak Mittal","Pablo Lemos","Emmanuel Bengio","Alexandre Adam","Jarrid Rector-Brooks","Yashar Hezaveh","Laurence Perreault-Levasseur","Yoshua Bengio","Glen Berseth","Nikolay Malkin"],"pdf_url":"https://arxiv.org/pdf/2503.09746v1.pdf","comment":"Accepted as workshop paper at DeLTa workshop, ICLR 2025. arXiv admin\n  note: substantial text overlap with arXiv:2405.20971"},{"id":"http://arxiv.org/abs/2502.10236v2","updated":"2025-03-12T18:40:15Z","published":"2025-02-14T15:46:37Z","title":"Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise\n  Control","summary":"  Diffusion Probabilistic Models (DPMs) are powerful generative models that\nhave achieved unparalleled success in a number of generative tasks. In this\nwork, we aim to build inductive biases into the training and sampling of\ndiffusion models to better accommodate the target distribution of the data to\nmodel. For topologically structured data, we devise a frequency-based noising\noperator to purposefully manipulate, and set, these inductive biases. We first\nshow that appropriate manipulations of the noising forward process can lead\nDPMs to focus on particular aspects of the distribution to learn. We show that\ndifferent datasets necessitate different inductive biases, and that appropriate\nfrequency-based noise control induces increased generative performance compared\nto standard diffusion. Finally, we demonstrate the possibility of ignoring\ninformation at particular frequencies while learning. We show this in an image\ncorruption and recovery task, where we train a DPM to recover the original\ntarget distribution after severe noise corruption.\n","authors":["Thomas Jiralerspong","Berton Earnshaw","Jason Hartford","Yoshua Bengio","Luca Scimeca"],"pdf_url":"https://arxiv.org/pdf/2502.10236v2.pdf","comment":"Published as workshop paper at DeLTa and FPI workshops, ICLR 2025"},{"id":"http://arxiv.org/abs/2503.09737v1","updated":"2025-03-12T18:36:55Z","published":"2025-03-12T18:36:55Z","title":"Unveiling Hidden Pivotal Players with GoalNet: A GNN-Based Soccer Player\n  Evaluation System","summary":"  Soccer analysis tools emphasize metrics such as expected goals, leading to an\noverrepresentation of attacking players' contributions and overlooking players\nwho facilitate ball control and link attacks. Examples include Rodri from\nManchester City and Palhinha who just transferred to Bayern Munich. To address\nthis bias, we aim to identify players with pivotal roles in a soccer team,\nincorporating both spatial and temporal features.\n  In this work, we introduce a GNN-based framework that assigns individual\ncredit for changes in expected threat (xT), thus capturing overlooked yet vital\ncontributions in soccer. Our pipeline encodes both spatial and temporal\nfeatures in event-centric graphs, enabling fair attribution of non-scoring\nactions such as defensive or transitional plays. We incorporate centrality\nmeasures into the learned player embeddings, ensuring that ball-retaining\ndefenders and defensive midfielders receive due recognition for their overall\nimpact. Furthermore, we explore diverse GNN variants-including Graph Attention\nNetworks and Transformer-based models-to handle long-range dependencies and\nevolving match contexts, discussing their relative performance and\ncomputational complexity. Experiments on real match data confirm the robustness\nof our approach in highlighting pivotal roles that traditional attacking\nmetrics typically miss, underscoring the model's utility for more comprehensive\nsoccer analytics.\n","authors":["Jacky Hao Jiang","Jerry Cai","Anastasios Kyrillidis"],"pdf_url":"https://arxiv.org/pdf/2503.09737v1.pdf","comment":"14 pages, 4-5 figures"},{"id":"http://arxiv.org/abs/2503.04844v2","updated":"2025-03-12T18:26:37Z","published":"2025-03-05T18:29:15Z","title":"Universal Narrative Model: an Author-centric Storytelling Framework for\n  Generative AI","summary":"  Generative AI promises to finally realize dynamic, personalized storytelling\ntechnologies across a range of media. To date, experimentation with generative\nAI in the field of procedural narrative generation has been quite promising\nfrom a technical perspective. However, fundamental narrative dilemmas remain,\nsuch as the balance between player agency and narrative coherence, and no\nrigorous narrative standard has been proposed to specifically leverage the\nstrengths of generative AI. In this paper, we propose the Universal Narrative\nModel (UNM), an open and extensible standard designed to place writers at the\ncenter of future narrative design workflows and enable interoperability across\nauthoring platforms. By encoding an author's intent according to an objective\nnarrative model, the UNM enables narrative portability as well as intent-based\nconstraints for generative systems.\n","authors":["Hank Gerba"],"pdf_url":"https://arxiv.org/pdf/2503.04844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09730v1","updated":"2025-03-12T18:20:47Z","published":"2025-03-12T18:20:47Z","title":"Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem\n  Proving","summary":"  The most promising recent methods for AI reasoning require applying variants\nof reinforcement learning (RL) either on rolled out trajectories from the\nmodel, even for the step-wise rewards, or large quantities of human annotated\ntrajectory data. The reliance on the rolled-out trajectory renders the compute\ncost and time prohibitively high. In particular, the correctness of a reasoning\ntrajectory can typically only be judged at its completion, leading to sparse\nrewards in RL or requiring expensive synthetic data generation in expert\niteration-like methods. In this work, we focus on the Automatic Theorem Proving\n(ATP) task and propose a novel verifier-in-the-loop design, which unlike\nexisting approaches that leverage feedback on the entire reasoning trajectory,\nemploys an automated verifier to give intermediate feedback at each step of the\nreasoning process. Using Lean as the verifier, we empirically show that the\nstep-by-step local verification produces a global improvement in the model's\nreasoning accuracy and efficiency.\n","authors":["Sara Rajaee","Kumar Pratik","Gabriele Cesa","Arash Behboodi"],"pdf_url":"https://arxiv.org/pdf/2503.09730v1.pdf","comment":"Accepted at ICLR 2025 Workshop on Reasoning and Planning for Large\n  Language Models"},{"id":"http://arxiv.org/abs/2503.07811v2","updated":"2025-03-12T18:18:00Z","published":"2025-03-10T19:51:37Z","title":"A primer on optimal transport for causal inference with observational\n  data","summary":"  The theory of optimal transportation has developed into a powerful and\nelegant framework for comparing probability distributions, with wide-ranging\napplications in all areas of science. The fundamental idea of analyzing\nprobabilities by comparing their underlying state space naturally aligns with\nthe core idea of causal inference, where understanding and quantifying\ncounterfactual states is paramount. Despite this intuitive connection, explicit\nresearch at the intersection of optimal transport and causal inference is only\nbeginning to develop. Yet, many foundational models in causal inference have\nimplicitly relied on optimal transport principles for decades, without\nrecognizing the underlying connection. Therefore, the goal of this review is to\noffer an introduction to the surprisingly deep existing connections between\noptimal transport and the identification of causal effects with observational\ndata -- where optimal transport is not just a set of potential tools, but\nactually builds the foundation of model assumptions. As a result, this review\nis intended to unify the language and notation between different areas of\nstatistics, mathematics, and econometrics, by pointing out these existing\nconnections, and to explore novel problems and directions for future work in\nboth areas derived from this realization.\n","authors":["Florian F Gunsilius"],"pdf_url":"https://arxiv.org/pdf/2503.07811v2.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.09721v1","updated":"2025-03-12T18:11:16Z","published":"2025-03-12T18:11:16Z","title":"Finding the Muses: Identifying Coresets through Loss Trajectories","summary":"  Deep learning models achieve state-of-the-art performance across domains but\nface scalability challenges in real-time or resource-constrained scenarios. To\naddress this, we propose Loss Trajectory Correlation (LTC), a novel metric for\ncoreset selection that identifies critical training samples driving\ngeneralization. $LTC$ quantifies the alignment between training sample loss\ntrajectories and validation set loss trajectories, enabling the construction of\ncompact, representative subsets. Unlike traditional methods with computational\nand storage overheads that are infeasible to scale to large datasets, $LTC$\nachieves superior efficiency as it can be computed as a byproduct of training.\nOur results on CIFAR-100 and ImageNet-1k show that $LTC$ consistently achieves\naccuracy on par with or surpassing state-of-the-art coreset selection methods,\nwith any differences remaining under 1%. LTC also effectively transfers across\nvarious architectures, including ResNet, VGG, DenseNet, and Swin Transformer,\nwith minimal performance degradation (<2%). Additionally, LTC offers insights\ninto training dynamics, such as identifying aligned and conflicting sample\nbehaviors, at a fraction of the computational cost of traditional methods. This\nframework paves the way for scalable coreset selection and efficient dataset\noptimization.\n","authors":["Manish Nagaraj","Deepak Ravikumar","Efstathia Soufleri","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2503.09721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09712v1","updated":"2025-03-12T18:05:32Z","published":"2025-03-12T18:05:32Z","title":"Revisiting Backdoor Attacks on Time Series Classification in the\n  Frequency Domain","summary":"  Time series classification (TSC) is a cornerstone of modern web applications,\npowering tasks such as financial data analysis, network traffic monitoring, and\nuser behavior analysis. In recent years, deep neural networks (DNNs) have\ngreatly enhanced the performance of TSC models in these critical domains.\nHowever, DNNs are vulnerable to backdoor attacks, where attackers can covertly\nimplant triggers into models to induce malicious outcomes. Existing backdoor\nattacks targeting DNN-based TSC models remain elementary. In particular, early\nmethods borrow trigger designs from computer vision, which are ineffective for\ntime series data. More recent approaches utilize generative models for trigger\ngeneration, but at the cost of significant computational complexity. In this\nwork, we analyze the limitations of existing attacks and introduce an enhanced\nmethod, FreqBack. Drawing inspiration from the fact that DNN models inherently\ncapture frequency domain features in time series data, we identify that\nimproper perturbations in the frequency domain are the root cause of\nineffective attacks. To address this, we propose to generate triggers both\neffectively and efficiently, guided by frequency analysis. FreqBack exhibits\nsubstantial performance across five models and eight datasets, achieving an\nimpressive attack success rate of over 90%, while maintaining less than a 3%\ndrop in model accuracy on clean data.\n","authors":["Yuanmin Huang","Mi Zhang","Zhaoxiang Wang","Wenxuan Li","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2503.09712v1.pdf","comment":"WWW 2025 (Oral)"},{"id":"http://arxiv.org/abs/2503.09707v1","updated":"2025-03-12T18:01:10Z","published":"2025-03-12T18:01:10Z","title":"Revisiting semi-supervised learning in the era of foundation models","summary":"  Semi-supervised learning (SSL) leverages abundant unlabeled data alongside\nlimited labeled data to enhance learning. As vision foundation models (VFMs)\nincreasingly serve as the backbone of vision applications, it remains unclear\nhow SSL interacts with these pre-trained models. To address this gap, we\ndevelop new SSL benchmark datasets where frozen VFMs underperform and\nsystematically evaluate representative SSL methods. We make a surprising\nobservation: parameter-efficient fine-tuning (PEFT) using only labeled data\noften matches SSL performance, even without leveraging unlabeled data. This\nmotivates us to revisit self-training, a conceptually simple SSL baseline,\nwhere we use the supervised PEFT model to pseudo-label unlabeled data for\nfurther training. To overcome the notorious issue of noisy pseudo-labels, we\npropose ensembling multiple PEFT approaches and VFM backbones to produce more\nrobust pseudo-labels. Empirical results validate the effectiveness of this\nsimple yet powerful approach, providing actionable insights into SSL with VFMs\nand paving the way for more scalable and practical semi-supervised learning in\nthe era of foundation models.\n","authors":["Ping Zhang","Zheda Mai","Quang-Huy Nguyen","Wei-Lun Chao"],"pdf_url":"https://arxiv.org/pdf/2503.09707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11584v2","updated":"2025-03-12T17:54:11Z","published":"2024-10-15T13:19:16Z","title":"DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object\n  Manipulation via Preference-based Action Alignment","summary":"  In recent years, imitation learning has made progress in the field of robotic\nmanipulation. However, it still faces challenges when addressing complex\nlong-horizon tasks with deformable objects, such as high-dimensional state\nspaces, complex dynamics, and multimodal action distributions. Traditional\nimitation learning methods often require a large amount of data and encounter\ndistributional shifts and accumulative errors in these tasks. To address these\nissues, we propose a data-efficient general learning framework (DeformPAM)\nbased on preference learning and reward-guided action selection. DeformPAM\ndecomposes long-horizon tasks into multiple action primitives, utilizes 3D\npoint cloud inputs and diffusion models to model action distributions, and\ntrains an implicit reward model using human preference data. During the\ninference phase, the reward model scores multiple candidate actions, selecting\nthe optimal action for execution, thereby reducing the occurrence of anomalous\nactions and improving task completion quality. Experiments conducted on three\nchallenging real-world long-horizon deformable object manipulation tasks\ndemonstrate the effectiveness of this method. Results show that DeformPAM\nimproves both task completion quality and efficiency compared to baseline\nmethods even with limited data. Code and data will be available at\nhttps://deform-pam.robotflow.ai.\n","authors":["Wendi Chen","Han Xue","Fangyuan Zhou","Yuan Fang","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2410.11584v2.pdf","comment":"Accepted to ICRA 2025. Project page: https://deform-pam.robotflow.ai"},{"id":"http://arxiv.org/abs/2503.09669v1","updated":"2025-03-12T17:21:57Z","published":"2025-03-12T17:21:57Z","title":"Silent Branding Attack: Trigger-free Data Poisoning Attack on\n  Text-to-Image Diffusion Models","summary":"  Text-to-image diffusion models have achieved remarkable success in generating\nhigh-quality contents from text prompts. However, their reliance on publicly\navailable data and the growing trend of data sharing for fine-tuning make these\nmodels particularly vulnerable to data poisoning attacks. In this work, we\nintroduce the Silent Branding Attack, a novel data poisoning method that\nmanipulates text-to-image diffusion models to generate images containing\nspecific brand logos or symbols without any text triggers. We find that when\ncertain visual patterns are repeatedly in the training data, the model learns\nto reproduce them naturally in its outputs, even without prompt mentions.\nLeveraging this, we develop an automated data poisoning algorithm that\nunobtrusively injects logos into original images, ensuring they blend naturally\nand remain undetected. Models trained on this poisoned dataset generate images\ncontaining logos without degrading image quality or text alignment. We\nexperimentally validate our silent branding attack across two realistic\nsettings on large-scale high-quality image datasets and style personalization\ndatasets, achieving high success rates even without a specific text trigger.\nHuman evaluation and quantitative metrics including logo detection show that\nour method can stealthily embed logos.\n","authors":["Sangwon Jang","June Suk Choi","Jaehyeong Jo","Kimin Lee","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.09669v1.pdf","comment":"CVPR 2025. Project page: https://silent-branding.github.io/"}]},"2025-03-13T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.10633v1","updated":"2025-03-13T17:59:53Z","published":"2025-03-13T17:59:53Z","title":"Charting and Navigating Hugging Face's Model Atlas","summary":"  As there are now millions of publicly available neural networks, searching\nand analyzing large model repositories becomes increasingly important.\nNavigating so many models requires an atlas, but as most models are poorly\ndocumented charting such an atlas is challenging. To explore the hidden\npotential of model repositories, we chart a preliminary atlas representing the\ndocumented fraction of Hugging Face. It provides stunning visualizations of the\nmodel landscape and evolution. We demonstrate several applications of this\natlas including predicting model attributes (e.g., accuracy), and analyzing\ntrends in computer vision models. However, as the current atlas remains\nincomplete, we propose a method for charting undocumented regions.\nSpecifically, we identify high-confidence structural priors based on dominant\nreal-world model training practices. Leveraging these priors, our approach\nenables accurate mapping of previously undocumented areas of the atlas. We\npublicly release our datasets, code, and interactive atlas.\n","authors":["Eliahu Horwitz","Nitzan Kurer","Jonathan Kahana","Liel Amar","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2503.10633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10627v1","updated":"2025-03-13T17:59:32Z","published":"2025-03-13T17:59:32Z","title":"SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of\n  LMMs on Multi-modal Scientific Problems","summary":"  The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io\n","authors":["Ziyu Guo","Ray Zhang","Hao Chen","Jialin Gao","Dongzhi Jiang","Jiaze Wang","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2503.10627v1.pdf","comment":"Initially released in September 2024. Project page:\n  https://sciverse-cuhk.github.io"},{"id":"http://arxiv.org/abs/2503.10622v1","updated":"2025-03-13T17:59:06Z","published":"2025-03-13T17:59:06Z","title":"Transformers without Normalization","summary":"  Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.\n","authors":["Jiachen Zhu","Xinlei Chen","Kaiming He","Yann LeCun","Zhuang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.10622v1.pdf","comment":"CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/"},{"id":"http://arxiv.org/abs/2503.10619v1","updated":"2025-03-13T17:57:32Z","published":"2025-03-13T17:57:32Z","title":"Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with\n  Tree Search","summary":"  We introduce Siege, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Siege expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Siege reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Siege achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.\n","authors":["Andy Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.10619v1.pdf","comment":"Accepted to ICLR 2025 Trustworthy LLM"},{"id":"http://arxiv.org/abs/2503.10620v1","updated":"2025-03-13T17:57:32Z","published":"2025-03-13T17:57:32Z","title":"From TOWER to SPIRE: Adding the Speech Modality to a Text-Only LLM","summary":"  Large language models (LLMs) have shown remarkable performance and\ngeneralization capabilities across multiple languages and tasks, making them\nvery attractive targets for multi-modality integration (e.g., images or\nspeech). In this work, we extend an existing LLM to the speech modality via\nspeech discretization and continued pre-training. In particular, we are\ninterested in multilingual LLMs, such as TOWER, as their pre-training setting\nallows us to treat discretized speech input as an additional translation\nlanguage. The resulting open-source model, SPIRE, is able to transcribe and\ntranslate English speech input while maintaining TOWER's original performance\non translation-related tasks, showcasing that discretized speech input\nintegration as an additional language is feasible during LLM adaptation. We\nmake our code and models available to the community.\n","authors":["Kshitij Ambilduke","Ben Peters","Sonal Sannigrahi","Anil Keshwani","Tsz Kin Lam","Bruno Martins","Marcely Zanon Boito","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2503.10620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10617v1","updated":"2025-03-13T17:57:04Z","published":"2025-03-13T17:57:04Z","title":"Compositional Subspace Representation Fine-tuning for Adaptive Large\n  Language Models","summary":"  Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.\n","authors":["Andy Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.10617v1.pdf","comment":"Accepted to ICLR 2025 SCOPE"},{"id":"http://arxiv.org/abs/2503.08679v2","updated":"2025-03-13T17:49:58Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal non-negligible rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (16.3%), DeepSeek R1 (5.3%) and\nChatGPT-4o (7.0%) all answer a notable proportion of question pairs\nunfaithfully. Specifically, we find that models rationalize their implicit\nbiases in answers to binary questions (\"implicit post-hoc rationalization\").\nFor example, when separately presented with the questions \"Is X bigger than Y?\"\nand \"Is Y bigger than X?\", models sometimes produce superficially coherent\narguments to justify answering Yes to both questions or No to both questions,\ndespite such responses being logically contradictory. We also investigate\nrestoration errors (Dziri et al., 2023), where models make and then silently\ncorrect errors in their reasoning, and unfaithful shortcuts, where models use\nclearly illogical reasoning to simplify solving problems in Putnam questions (a\nhard benchmark). Our findings raise challenges for AI safety work that relies\non monitoring CoT to detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v2.pdf","comment":"Accepted to the Reasoning and Planning for Large Language Models\n  Workshop (ICLR 25), 10 main paper pages, 38 appendix pages"},{"id":"http://arxiv.org/abs/2503.10602v1","updated":"2025-03-13T17:46:06Z","published":"2025-03-13T17:46:06Z","title":"TruthPrInt: Mitigating LVLM Object Hallucination Via Latent\n  Truthful-Guided Pre-Intervention","summary":"  Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.\n","authors":["Jinhao Duan","Fei Kong","Hao Cheng","James Diffenderfer","Bhavya Kailkhura","Lichao Sun","Xiaofeng Zhu","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.10602v1.pdf","comment":"15 pages, 9 figures, the first two authors contributed equally"},{"id":"http://arxiv.org/abs/2503.10582v1","updated":"2025-03-13T17:32:48Z","published":"2025-03-13T17:32:48Z","title":"VisualWebInstruct: Scaling up Multimodal Instruction Data through Web\n  Search","summary":"  Vision-Language Models have made significant progress on many\nperception-focused tasks, however, their progress on reasoning-focused tasks\nseem to be limited due to the lack of high-quality and diverse training data.\nIn this work, we aim to address the scarcity issue of reasoning-focused\nmultimodal datasets. We propose VisualWebInstruct - a novel approach that\nleverages search engine to create a diverse, and high-quality dataset spanning\nmultiple disciplines like math, physics, finance, chemistry, etc. Starting with\nmeticulously selected 30,000 seed images, we employ Google Image search to\nidentify websites containing similar images. We collect and process the HTMLs\nfrom over 700K unique URL sources. Through a pipeline of content extraction,\nfiltering and synthesis, we build a dataset of approximately 900K\nquestion-answer pairs, with 40% being visual QA pairs and the rest as text QA\npairs. Models fine-tuned on VisualWebInstruct demonstrate significant\nperformance gains: (1) training from Llava-OV-mid shows 10-20% absolute point\ngains across benchmarks, (2) training from MAmmoTH-VL shows 5% absoluate gain.\nOur best model MAmmoTH-VL2 shows state-of-the-art performance within the 10B\nparameter class on MMMU-Pro-std (40.7%), MathVerse (42.6%), and DynaMath\n(55.7%). These remarkable results highlight the effectiveness of our dataset in\nenhancing VLMs' reasoning capabilities for complex multimodal tasks.\n","authors":["Yiming Jia","Jiachen Li","Xiang Yue","Bo Li","Ping Nie","Kai Zou","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10582v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.06215v3","updated":"2025-03-13T17:30:48Z","published":"2024-10-08T17:20:37Z","title":"DataEnvGym: Data Generation Agents in Teacher Environments with Student\n  Feedback","summary":"  The process of creating training data to teach models is currently driven by\nhumans, who manually analyze model weaknesses and plan how to create data that\nimproves a student model. Approaches using LLMs as annotators reduce human\neffort, but still require humans to interpret feedback from evaluations and\ncontrol the LLM to produce data the student needs. Automating this\nlabor-intensive process by creating autonomous data generation agents - or\nteachers - is desirable, but requires environments that can simulate the\nfeedback-driven, iterative, closed loop of data creation. To enable rapid,\nscalable testing for such agents and their modules, we introduce DataEnvGym, a\ntestbed of teacher environments for data generation agents. DataEnvGym frames\ndata generation as a sequential decision-making task, involving an agent\nconsisting of a data generation policy (which generates a plan for creating\ntraining data) and a data generation engine (which transforms the plan into\ndata), inside an environment that provides student feedback. The agent's goal\nis to improve student performance. Students are iteratively trained and\nevaluated on generated data, and their feedback (in the form of errors or weak\nskills) is reported to the agent after each iteration. DataEnvGym includes\nmultiple teacher environment instantiations across 3 levels of structure in the\nstate representation and action space. More structured environments are based\non inferred skills and offer more interpretability and curriculum control. We\nsupport 4 domains (math, code, VQA, and tool-use) and test multiple students\nand teachers. Example agents in our teaching environments can iteratively\nimprove students across tasks and settings. Moreover, we show that environments\nteach different skill levels and test variants of key modules, pointing to\nfuture work in improving data generation agents, engines, and feedback\nmechanisms.\n","authors":["Zaid Khan","Elias Stengel-Eskin","Jaemin Cho","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.06215v3.pdf","comment":"ICLR 2025 Spotlight; Project Page: https://DataEnvGym.github.io"},{"id":"http://arxiv.org/abs/2503.10542v1","updated":"2025-03-13T16:56:47Z","published":"2025-03-13T16:56:47Z","title":"Language Models, Graph Searching, and Supervision Adulteration: When\n  More Supervision is Less and How to Make More More","summary":"  This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2503.10542v1.pdf","comment":"A reduced version of this work has been accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025. Full version under review"},{"id":"http://arxiv.org/abs/2503.10533v1","updated":"2025-03-13T16:47:07Z","published":"2025-03-13T16:47:07Z","title":"The Impact of Item-Writing Flaws on Difficulty and Discrimination in\n  Item Response Theory","summary":"  High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.\n","authors":["Robin Schmucker","Steven Moore"],"pdf_url":"https://arxiv.org/pdf/2503.10533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10515v1","updated":"2025-03-13T16:20:25Z","published":"2025-03-13T16:20:25Z","title":"Probing LLMs for Multilingual Discourse Generalization Through a Unified\n  Label Set","summary":"  Discourse understanding is essential for many NLP tasks, yet most existing\nwork remains constrained by framework-dependent discourse representations. This\nwork investigates whether large language models (LLMs) capture discourse\nknowledge that generalizes across languages and frameworks. We address this\nquestion along two dimensions: (1) developing a unified discourse relation\nlabel set to facilitate cross-lingual and cross-framework discourse analysis,\nand (2) probing LLMs to assess whether they encode generalizable discourse\nabstractions. Using multilingual discourse relation classification as a\ntestbed, we examine a comprehensive set of 23 LLMs of varying sizes and\nmultilingual capabilities. Our results show that LLMs, especially those with\nmultilingual training corpora, can generalize discourse information across\nlanguages and frameworks. Further layer-wise analyses reveal that language\ngeneralization at the discourse level is most salient in the intermediate\nlayers. Lastly, our error analysis provides an account of challenging relation\nclasses.\n","authors":["Florian Eichin","Yang Janet Liu","Barbara Plank","Michael A. Hedderich"],"pdf_url":"https://arxiv.org/pdf/2503.10515v1.pdf","comment":"18 pages, 7 figures, 3 tables, code:\n  https://github.com/mainlp/discourse_probes"},{"id":"http://arxiv.org/abs/2411.05039v2","updated":"2025-03-13T16:17:21Z","published":"2024-11-06T17:58:01Z","title":"YouTube Comments Decoded: Leveraging LLMs for Low Resource Language\n  Classification","summary":"  Sarcasm detection is a significant challenge in sentiment analysis,\nparticularly due to its nature of conveying opinions where the intended meaning\ndeviates from the literal expression. This challenge is heightened in social\nmedia contexts where code-mixing, especially in Dravidian languages, is\nprevalent. Code-mixing involves the blending of multiple languages within a\nsingle utterance, often with non-native scripts, complicating the task for\nsystems trained on monolingual data. This shared task introduces a novel gold\nstandard corpus designed for sarcasm and sentiment detection within code-mixed\ntexts, specifically in Tamil-English and Malayalam-English languages. The\nprimary objective of this task is to identify sarcasm and sentiment polarity\nwithin a code-mixed dataset of Tamil-English and Malayalam-English comments and\nposts collected from social media platforms. Each comment or post is annotated\nat the message level for sentiment polarity, with particular attention to the\nchallenges posed by class imbalance, reflecting real-world scenarios.In this\nwork, we experiment with state-of-the-art large language models like GPT-3.5\nTurbo via prompting to classify comments into sarcastic or non-sarcastic\ncategories. We obtained a macro-F1 score of 0.61 for Tamil language. We\nobtained a macro-F1 score of 0.50 for Malayalam language.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.05039v2.pdf","comment":"Updated and Final Version"},{"id":"http://arxiv.org/abs/2410.06846v4","updated":"2025-03-13T16:17:19Z","published":"2024-10-09T13:06:43Z","title":"Joint Fine-tuning and Conversion of Pretrained Speech and Language\n  Models towards Linear Complexity","summary":"  Architectures such as Linformer and Mamba have recently emerged as\ncompetitive linear time replacements for transformers. However, corresponding\nlarge pretrained models are often unavailable, especially in non-text domains.\nTo remedy this, we present a Cross-Architecture Layerwise Distillation (CALD)\napproach that jointly converts a transformer model to a linear time substitute\nand fine-tunes it to a target task. We also compare several means to guide the\nfine-tuning to optimally retain the desired inference capability from the\noriginal model. The methods differ in their use of the target model and the\ntrajectory of the parameters. In a series of empirical studies on language\nprocessing, language modeling, and speech processing, we show that CALD can\neffectively recover the result of the original model, and that the guiding\nstrategy contributes to the result. Some reasons for the variation are\nsuggested.\n","authors":["Mutian He","Philip N. Garner"],"pdf_url":"https://arxiv.org/pdf/2410.06846v4.pdf","comment":"18 pages, 5 figures; ICLR 2025 camera ready. Code:\n  https://github.com/idiap/linearize-distill-pretrained-transformers"},{"id":"http://arxiv.org/abs/2410.13640v2","updated":"2025-03-13T16:16:12Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2412.09165v2","updated":"2025-03-13T16:11:43Z","published":"2024-12-12T10:50:26Z","title":"When Text Embedding Meets Large Language Model: A Comprehensive Survey","summary":"  Text embedding has become a foundational technology in natural language\nprocessing (NLP) during the deep learning era, driving advancements across a\nwide array of downstream tasks. While many natural language understanding\nchallenges can now be modeled using generative paradigms and leverage the\nrobust generative and comprehension capabilities of large language models\n(LLMs), numerous practical applications-such as semantic matching, clustering,\nand information retrieval-continue to rely on text embeddings for their\nefficiency and effectiveness. Therefore, how to combine the LLMs and the text\nembeddings has become one of the hotspots of academic attention in recent\nyears. In this survey, we categorize the interplay between LLMs and text\nembeddings into three overarching themes: (1) LLM-augmented text embedding,\nenhancing traditional embedding methods with LLMs; (2) LLMs as text embedders,\nadapting their innate capabilities for high-quality embedding; and (3) Text\nembedding understanding with LLMs, leveraging LLMs to analyze and interpret\nembeddings. By organizing recent works based on interaction patterns rather\nthan specific downstream applications, we offer a novel and systematic overview\nof contributions from various research and application domains in the era of\nLLMs. Furthermore, we highlight the unresolved challenges that persisted in the\npre-LLM era with pre-trained language models (PLMs) and explore the emerging\nobstacles brought forth by LLMs. Building on this analysis, we outline\nprospective directions for the evolution of text embedding, addressing both\ntheoretical and practical opportunities in the rapidly advancing landscape of\nNLP.\n","authors":["Zhijie Nie","Zhangchi Feng","Mingxin Li","Cunwang Zhang","Yanzhao Zhang","Dingkun Long","Richong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09165v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.06692v2","updated":"2025-03-13T16:00:47Z","published":"2025-03-09T16:59:14Z","title":"InftyThink: Breaking the Length Limits of Long-Context Reasoning in\n  Large Language Models","summary":"  Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.\n","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10497v1","updated":"2025-03-13T15:59:20Z","published":"2025-03-13T15:59:20Z","title":"MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model\n  Evaluation","summary":"  Traditional benchmarks struggle to evaluate increasingly sophisticated\nlanguage models in multilingual and culturally diverse contexts. To address\nthis gap, we introduce MMLU-ProX, a comprehensive multilingual benchmark\ncovering 13 typologically diverse languages with approximately 11,829 questions\nper language. Building on the challenging reasoning-focused design of MMLU-Pro,\nour framework employs a semi-automatic translation process: translations\ngenerated by state-of-the-art large language models (LLMs) are rigorously\nevaluated by expert annotators to ensure conceptual accuracy, terminological\nconsistency, and cultural relevance. We comprehensively evaluate 25\nstate-of-the-art LLMs using 5-shot chain-of-thought (CoT) and zero-shot\nprompting strategies, analyzing their performance across linguistic and\ncultural boundaries. Our experiments reveal consistent performance degradation\nfrom high-resource languages to lower-resource ones, with the best models\nachieving over 70% accuracy on English but dropping to around 40% for languages\nlike Swahili, highlighting persistent gaps in multilingual capabilities despite\nrecent advances. MMLU-ProX is an ongoing project; we are expanding our\nbenchmark by incorporating additional languages and evaluating more language\nmodels to provide a more comprehensive assessment of multilingual capabilities.\n","authors":["Weihao Xuan","Rui Yang","Heli Qi","Qingcheng Zeng","Yunze Xiao","Yun Xing","Junjue Wang","Huitao Li","Xin Li","Kunyu Yu","Nan Liu","Qingyu Chen","Douglas Teodoro","Edison Marrese-Taylor","Shijian Lu","Yusuke Iwasawa","Yutaka Matsuo","Irene Li"],"pdf_url":"https://arxiv.org/pdf/2503.10497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10494v1","updated":"2025-03-13T15:57:50Z","published":"2025-03-13T15:57:50Z","title":"Source-primed Multi-turn Conversation Helps Large Language Models\n  Translate Documents","summary":"  LLMs have paved the way for truly simple document-level machine translation,\nbut challenges such as omission errors remain. In this paper, we study a simple\nmethod for handling document-level machine translation, by leveraging previous\ncontexts in a multi-turn conversational manner. Specifically, by decomposing\ndocuments into segments and iteratively translating them while maintaining\nprevious turns, this method ensures coherent translations without additional\ntraining, and can fully re-use the KV cache of previous turns thus minimizing\ncomputational overhead. We further propose a `source-primed' method that first\nprovides the whole source document before multi-turn translation. We\nempirically show this multi-turn method outperforms both translating entire\ndocuments in a single turn and translating each segment independently according\nto multiple automatic metrics in representative LLMs, establishing a strong\nbaseline for document-level translation using LLMs.\n","authors":["Hanxu Hu","Jannis Vamvas","Rico Sennrich"],"pdf_url":"https://arxiv.org/pdf/2503.10494v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.10486v1","updated":"2025-03-13T15:54:26Z","published":"2025-03-13T15:54:26Z","title":"LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3\n  Mini Across Chronic Health Conditions","summary":"  Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.\n","authors":["Gaurav Kumar Gupta","Pranal Pande"],"pdf_url":"https://arxiv.org/pdf/2503.10486v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.10480v1","updated":"2025-03-13T15:49:56Z","published":"2025-03-13T15:49:56Z","title":"World Modeling Makes a Better Planner: Dual Preference Optimization for\n  Embodied Task Planning","summary":"  Recent advances in large vision-language models (LVLMs) have shown promise\nfor embodied task planning, yet they struggle with fundamental challenges like\ndependency constraints and efficiency. Existing approaches either solely\noptimize action selection or leverage world models during inference,\noverlooking the benefits of learning to model the world as a way to enhance\nplanning capabilities. We propose Dual Preference Optimization (D$^2$PO), a new\nlearning framework that jointly optimizes state prediction and action selection\nthrough preference learning, enabling LVLMs to understand environment dynamics\nfor better planning. To automatically collect trajectories and stepwise\npreference data without human annotation, we introduce a tree search mechanism\nfor extensive exploration via trial-and-error. Extensive experiments on\nVoTa-Bench demonstrate that our D$^2$PO-based method significantly outperforms\nexisting methods and GPT-4o when applied to Qwen2-VL (7B), LLaVA-1.6 (7B), and\nLLaMA-3.2 (11B), achieving superior task success rates with more efficient\nexecution paths.\n","authors":["Siyin Wang","Zhaoye Fei","Qinyuan Cheng","Shiduo Zhang","Panpan Cai","Jinlan Fu","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2503.10480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10470v1","updated":"2025-03-13T15:42:44Z","published":"2025-03-13T15:42:44Z","title":"Statistical Analysis of Sentence Structures through ASCII, Lexical\n  Alignment and PCA","summary":"  While utilizing syntactic tools such as parts-of-speech (POS) tagging has\nhelped us understand sentence structures and their distribution across diverse\ncorpora, it is quite complex and poses a challenge in natural language\nprocessing (NLP). This study focuses on understanding sentence structure\nbalance - usages of nouns, verbs, determiners, etc - harmoniously without\nrelying on such tools. It proposes a novel statistical method that uses\nAmerican Standard Code for Information Interchange (ASCII) codes to represent\ntext of 11 text corpora from various sources and their lexical category\nalignment after using their compressed versions through PCA, and analyzes the\nresults through histograms and normality tests such as Shapiro-Wilk and\nAnderson-Darling Tests. By focusing on ASCII codes, this approach simplifies\ntext processing, although not replacing any syntactic tools but complementing\nthem by offering it as a resource-efficient tool for assessing text balance.\nThe story generated by Grok shows near normality indicating balanced sentence\nstructures in LLM outputs, whereas 4 out of the remaining 10 pass the normality\ntests. Further research could explore potential applications in text quality\nevaluation and style analysis with syntactic integration for more broader\ntasks.\n","authors":["Abhijeet Sahdev"],"pdf_url":"https://arxiv.org/pdf/2503.10470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19363v2","updated":"2025-03-13T15:42:07Z","published":"2025-02-26T18:01:19Z","title":"DataMan: Data Manager for Pre-training Large Language Models","summary":"  The performance emergence of large language models (LLMs) driven by data\nscaling laws makes the selection of pre-training data increasingly important.\nHowever, existing methods rely on limited heuristics and human intuition,\nlacking comprehensive and clear guidelines. To address this, we are inspired by\n``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit\nits performance. As its pre-training capabilities are related to perplexity\n(PPL), we derive 14 quality criteria from the causes of text perplexity\nanomalies and introduce 15 common application domains to support domain mixing.\nIn this paper, we train a Data Manager (DataMan) to learn quality ratings and\ndomain recognition from pointwise rating, and use it to annotate a 447B token\npre-training corpus with 14 quality ratings and domain type. Our experiments\nvalidate our approach, using DataMan to select 30B tokens to train a\n1.3B-parameter language model, demonstrating significant improvements in\nin-context learning (ICL), perplexity, and instruction-following ability over\nthe state-of-the-art baseline. The best-performing model, based on the Overall\nScore l=5 surpasses a model trained with 50% more data using uniform sampling.\nWe continue pre-training with high-rated, domain-specific data annotated by\nDataMan to enhance domain-specific ICL performance and thus verify DataMan's\ndomain mixing ability. Our findings emphasize the importance of quality\nranking, the complementary nature of quality criteria, and their low\ncorrelation with perplexity, analyzing misalignment between PPL and ICL\nperformance. We also thoroughly analyzed our pre-training dataset, examining\nits composition, the distribution of quality ratings, and the original document\nsources.\n","authors":["Ru Peng","Kexin Yang","Yawen Zeng","Junyang Lin","Dayiheng Liu","Junbo Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.19363v2.pdf","comment":"ICLR2025 paper"},{"id":"http://arxiv.org/abs/2503.10460v1","updated":"2025-03-13T15:29:22Z","published":"2025-03-13T15:29:22Z","title":"Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and\n  Beyond","summary":"  This paper presents our work on the Light-R1 series, with models, data, and\ncode all released.\n  We first focus on training long COT models from scratch, specifically\nstarting from models initially lacking long COT capabilities. Using a\ncurriculum training recipe consisting of two-stage SFT and semi-on-policy DPO,\nwe train our model Light-R1-32B from Qwen2.5-32B-Instruct, resulting in\nsuperior math performance compared to DeepSeek-R1-Distill-Qwen-32B. Despite\nbeing trained exclusively on math data, Light-R1-32B shows strong\ngeneralization across other domains. In the subsequent phase of this work, we\nhighlight the significant benefit of the 3k dataset constructed for the second\nSFT stage on enhancing other models. By fine-tuning DeepSeek-R1-Distilled\nmodels using this dataset, we obtain new SOTA models in 7B and 14B, while the\n32B model, Light-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.\n  Furthermore, we extend our work by applying reinforcement learning,\nspecifically GRPO, on long-COT models to further improve reasoning performance.\nWe successfully train our final Light-R1-14B-DS with RL, achieving SOTA\nperformance among 14B parameter models in math. With AIME24 & 25 scores of 74.0\nand 60.2 respectively, Light-R1-14B-DS surpasses even many 32B models and\nDeepSeek-R1-Distill-Llama-70B. Its RL training also exhibits well expected\nbehavior, showing simultaneous increase in response length and reward score.\n  The Light-R1 series of work validates training long-COT models from scratch,\nshowcases the art in SFT data and releases SOTA models from RL.\n","authors":["Liang Wen","Yunke Cai","Fenrui Xiao","Xin He","Qi An","Zhenyu Duan","Yimin Du","Junchen Liu","Lifu Tang","Xiaowei Lv","Haosheng Zou","Yongchao Deng","Shousheng Jia","Xiangzheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10460v1.pdf","comment":"all release at https://github.com/Qihoo360/Light-R1"},{"id":"http://arxiv.org/abs/2503.10452v1","updated":"2025-03-13T15:18:56Z","published":"2025-03-13T15:18:56Z","title":"DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large\n  Language Models in Code Generation","summary":"  The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.\n","authors":["Wenhao Hu","Jinhao Duan","Chunchen Wei","Li Zhang","Yue Zhang","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.10452v1.pdf","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.05891v4","updated":"2025-03-13T14:59:54Z","published":"2025-03-07T19:24:59Z","title":"MastermindEval: A Simple But Scalable Reasoning Benchmark","summary":"  Recent advancements in large language models (LLMs) have led to remarkable\nperformance across a wide range of language understanding and mathematical\ntasks. As a result, increasing attention has been given to assessing the true\nreasoning capabilities of LLMs, driving research into commonsense, numerical,\nlogical, and qualitative reasoning. However, with the rapid progress of\nreasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been\na growing demand for reasoning benchmarks that can keep pace with ongoing model\ndevelopments. In this paper, we introduce MastermindEval, a simple, scalable,\nand interpretable deductive reasoning benchmark inspired by the board game\nMastermind. Our benchmark supports two evaluation paradigms: (1) agentic\nevaluation, in which the model autonomously plays the game, and (2) deductive\nreasoning evaluation, in which the model is given a pre-played game state with\nonly one possible valid code to infer. In our experimental results we (1) find\nthat even easy Mastermind instances are difficult for current models and (2)\ndemonstrate that the benchmark is scalable to possibly more advanced models in\nthe future Furthermore, we investigate possible reasons why models cannot\ndeduce the final solution and find that current models are limited in deducing\nthe concealed code as the number of statement to combine information from is\nincreasing.\n","authors":["Jonas Golde","Patrick Haller","Fabio Barth","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2503.05891v4.pdf","comment":"9 pages, 2 figures, 4 tables. In: ICLR 2025 Workshop on Reasoning and\n  Planning for Large Language Models"},{"id":"http://arxiv.org/abs/2503.10432v1","updated":"2025-03-13T14:55:59Z","published":"2025-03-13T14:55:59Z","title":"BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language\n  Models","summary":"  In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave)\nbeam prediction framework leveraging large language models (LLMs) to address\nthe challenges of high training overhead and latency in mmWave communication\nsystems. By combining computer vision (CV) with LLMs' cross-modal reasoning\ncapabilities, the framework extracts user equipment (UE) positional features\nfrom RGB images and aligns visual-temporal features with LLMs' semantic space\nthrough reprogramming techniques. Evaluated on a realistic\nvehicle-to-infrastructure (V2I) scenario, the proposed method achieves 61.01%\ntop-1 accuracy and 97.39% top-3 accuracy in standard prediction tasks,\nsignificantly outperforming traditional deep learning models. In few-shot\nprediction scenarios, the performance degradation is limited to 12.56% (top-1)\nand 5.55% (top-3) from time sample 1 to 10, demonstrating superior prediction\ncapability.\n","authors":["Can Zheng","Jiguang He","Guofa Cai","Zitong Yu","Chung G. Kang"],"pdf_url":"https://arxiv.org/pdf/2503.10432v1.pdf","comment":"6 pages, 7 figures, conference"},{"id":"http://arxiv.org/abs/2409.18042v3","updated":"2025-03-13T14:51:04Z","published":"2024-09-26T16:44:02Z","title":"EMOVA: Empowering Language Models to See, Hear and Speak with Vivid\n  Emotions","summary":"  GPT-4o, an omni-modal model that enables vocal conversations with diverse\nemotions and tones, marks a milestone for omni-modal foundation models.\nHowever, empowering Large Language Models to perceive and generate images,\ntexts, and speeches end-to-end with publicly available data remains challenging\nfor the open-source community. Existing vision-language models rely on external\ntools for speech processing, while speech-language models still suffer from\nlimited or totally without vision-understanding capabilities. To address this\ngap, we propose the EMOVA (EMotionally Omni-present Voice Assistant), to enable\nLarge Language Models with end-to-end speech abilities while maintaining the\nleading vision-language performance. With a semantic-acoustic disentangled\nspeech tokenizer, we surprisingly notice that omni-modal alignment can further\nenhance vision-language and speech abilities compared with the bi-modal aligned\ncounterparts. Moreover, a lightweight style module is introduced for the\nflexible speech style controls including emotions and pitches. For the first\ntime, EMOVA achieves state-of-the-art performance on both the vision-language\nand speech benchmarks, and meanwhile, supporting omni-modal spoken dialogue\nwith vivid emotions.\n","authors":["Kai Chen","Yunhao Gou","Runhui Huang","Zhili Liu","Daxin Tan","Jing Xu","Chunwei Wang","Yi Zhu","Yihan Zeng","Kuo Yang","Dingdong Wang","Kun Xiang","Haoyuan Li","Haoli Bai","Jianhua Han","Xiaohui Li","Weike Jin","Nian Xie","Yu Zhang","James T. Kwok","Hengshuang Zhao","Xiaodan Liang","Dit-Yan Yeung","Xiao Chen","Zhenguo Li","Wei Zhang","Qun Liu","Jun Yao","Lanqing Hong","Lu Hou","Hang Xu"],"pdf_url":"https://arxiv.org/pdf/2409.18042v3.pdf","comment":"Accepted by CVPR 2025. Project Page: https://emova-ollm.github.io/"},{"id":"http://arxiv.org/abs/2503.10427v1","updated":"2025-03-13T14:49:35Z","published":"2025-03-13T14:49:35Z","title":"VisTai: Benchmarking Vision-Language Models for Traditional Chinese in\n  Taiwan","summary":"  In this paper, we propose a comprehensive evaluation benchmark for Visual\nLanguage Models (VLM) in Traditional Chinese. Our evaluation suite, the first\nof its kind, contains two complementary components: (1) VisTai-MCQ, a\ncollection of manually curated exam multi-choice questions from 21 academic\nsubjects designed to test the broad knowledge and reasoning capabilities of\nVLMs; and (2) VisTai-Dialogue, an open dialogue benchmark comprising 131\nimage-question pairs manually created to evaluate VLMs' ability in free-form\ndialogue generation within Taiwanese cultural contexts. These benchmarks\naddress a critical gap in the evaluation landscape, where existing benchmarks\npredominantly focus on English or Simplified Chinese, neglecting the unique\nlinguistic and cultural aspects of Traditional Chinese used in regions like\nTaiwan and Hong Kong. Our analysis reveals significant performance differences\nacross various VLMs and highlights specific challenges in processing\nTraditional Chinese visual content.\n","authors":["Zhi Rui Tam","Ya-Ting Pai","Yen-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.10427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10408v1","updated":"2025-03-13T14:32:30Z","published":"2025-03-13T14:32:30Z","title":"Understanding the Logical Capabilities of Large Language Models via\n  Out-of-Context Representation Learning","summary":"  We study the capabilities of Large Language Models (LLM) on binary relations,\na ubiquitous concept in math employed in most reasoning, math and logic\nbenchmarks. This work focuses on equality, inequality, and inclusion, along\nwith the properties they satisfy, such as ir/reflexivity, a/symmetry,\ntransitivity, and logical complexity (e.g., number of reasoning ``hops''). We\npropose an alternative to in-context learning that trains only the\nrepresentations of newly introduced tokens, namely out-of-context\nrepresentation learning. This method mitigates linguistic biases already\npresent in a model and, differently from in-context learning, does not rely on\nexternal information or illustrations. We argue out-of-context representation\nlearning as a better alternative to in-context learning and fine-tuning to\nevaluate the capabilities of LLMs on logic tasks that are the building blocks\nof more complex reasoning benchmarks.\n","authors":["Jonathan Shaki","Emanuele La Malfa","Michael Wooldridge","Sarit Kraus"],"pdf_url":"https://arxiv.org/pdf/2503.10408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.09766v3","updated":"2025-03-13T13:56:45Z","published":"2020-12-17T17:22:30Z","title":"MIX : a Multi-task Learning Approach to Solve Open-Domain Question\n  Answering","summary":"  This paper introduces MIX, a multi-task deep learning approach to solve\nopen-ended question-answering. First, we design our system as a multi-stage\npipeline of 3 building blocks: a BM25-based Retriever to reduce the search\nspace, a RoBERTa-based Scorer, and an Extractor to rank retrieved paragraphs\nand extract relevant text spans, respectively. Eventually, we further improve\nthe computational efficiency of our system to deal with the scalability\nchallenge: thanks to multi-task learning, we parallelize the close tasks solved\nby the Scorer and the Extractor. Our system is on par with state-of-the-art\nperformances on the squad-open benchmark while being simpler conceptually.\n","authors":["Sofian Chaybouti","Achraf Saghe","Aymen Shabou"],"pdf_url":"https://arxiv.org/pdf/2012.09766v3.pdf","comment":"8 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.10367v1","updated":"2025-03-13T13:47:03Z","published":"2025-03-13T13:47:03Z","title":"G-Boost: Boosting Private SLMs with General LLMs","summary":"  Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.\n","authors":["Yijiang Fan","Yuren Mao","Longbin Lai","Ying Zhang","Zhengping Qian","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.10367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04070v7","updated":"2025-03-13T13:37:57Z","published":"2024-10-05T08:00:55Z","title":"PAD: Personalized Alignment of LLMs at Decoding-Time","summary":"  Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.\n","authors":["Ruizhe Chen","Xiaotian Zhang","Meng Luo","Wenhao Chai","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04070v7.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10357v1","updated":"2025-03-13T13:37:54Z","published":"2025-03-13T13:37:54Z","title":"Do I look like a `cat.n.01` to you? A Taxonomy Image Generation\n  Benchmark","summary":"  This paper explores the feasibility of using text-to-image models in a\nzero-shot setup to generate images for taxonomy concepts. While text-based\nmethods for taxonomy enrichment are well-established, the potential of the\nvisual dimension remains unexplored. To address this, we propose a\ncomprehensive benchmark for Taxonomy Image Generation that assesses models'\nabilities to understand taxonomy concepts and generate relevant, high-quality\nimages. The benchmark includes common-sense and randomly sampled WordNet\nconcepts, alongside the LLM generated predictions. The 12 models are evaluated\nusing 9 novel taxonomy-related text-to-image metrics and human feedback.\nMoreover, we pioneer the use of pairwise evaluation with GPT-4 feedback for\nimage generation. Experimental results show that the ranking of models differs\nsignificantly from standard T2I tasks. Playground-v2 and FLUX consistently\noutperform across metrics and subsets and the retrieval-based approach performs\npoorly. These findings highlight the potential for automating the curation of\nstructured data resources.\n","authors":["Viktor Moskvoretskii","Alina Lobanova","Ekaterina Neminova","Chris Biemann","Alexander Panchenko","Irina Nikishina"],"pdf_url":"https://arxiv.org/pdf/2503.10357v1.pdf","comment":"Labeled data and generated image Wordnet are published at\n  https://huggingface.co/collections/VityaVitalich/generated-image-wordnet-67d2c868ff1414ec2f8e0d3d"},{"id":"http://arxiv.org/abs/2503.10354v1","updated":"2025-03-13T13:30:54Z","published":"2025-03-13T13:30:54Z","title":"A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent\n  Document Summarization","summary":"  Automatic patent summarization approaches that help in the patent analysis\nand comprehension procedure are in high demand due to the colossal growth of\ninnovations. The development of natural language processing (NLP), text mining,\nand deep learning has notably amplified the efficacy of text summarization\nmodels for abundant types of documents. Summarizing patent text remains a\npertinent challenge due to the labyrinthine writing style of these documents,\nwhich includes technical and legal intricacies. Additionally, these patent\ndocument contents are considerably lengthier than archetypal documents, which\nintricates the process of extracting pertinent information for summarization.\nEmbodying extractive and abstractive text summarization methodologies into a\nhybrid framework, this study proposes a system for efficiently creating\nabstractive summaries of patent records. The procedure involves leveraging the\nLexRank graph-based algorithm to retrieve the important sentences from input\nparent texts, then utilizing a Bidirectional Auto-Regressive Transformer (BART)\nmodel that has been fine-tuned using Low-Ranking Adaptation (LoRA) for\nproducing text summaries. This is accompanied by methodical testing and\nevaluation strategies. Furthermore, the author employed certain meta-learning\ntechniques to achieve Domain Generalization (DG) of the abstractive component\nacross multiple patent fields.\n","authors":["Nevidu Jayatilleke","Ruvan Weerasinghe"],"pdf_url":"https://arxiv.org/pdf/2503.10354v1.pdf","comment":"Accepted Paper in the 8th International Research Conference on Smart\n  Computing and Systems Engineering, University of Kelaniya, Sri Lanka.\n  (Pending Publication)"},{"id":"http://arxiv.org/abs/2503.10351v1","updated":"2025-03-13T13:27:53Z","published":"2025-03-13T13:27:53Z","title":"New Trends for Modern Machine Translation with Large Reasoning Models","summary":"  Recent advances in Large Reasoning Models (LRMs), particularly those\nleveraging Chain-of-Thought reasoning (CoT), have opened brand new possibility\nfor Machine Translation (MT). This position paper argues that LRMs\nsubstantially transformed traditional neural MT as well as LLMs-based MT\nparadigms by reframing translation as a dynamic reasoning task that requires\ncontextual, cultural, and linguistic understanding and reasoning. We identify\nthree foundational shifts: 1) contextual coherence, where LRMs resolve\nambiguities and preserve discourse structure through explicit reasoning over\ncross-sentence and complex context or even lack of context; 2) cultural\nintentionality, enabling models to adapt outputs by inferring speaker intent,\naudience expectations, and socio-linguistic norms; 3) self-reflection, LRMs can\nperform self-reflection during the inference time to correct the potential\nerrors in translation especially extremely noisy cases, showing better\nrobustness compared to simply mapping X->Y translation. We explore various\nscenarios in translation including stylized translation, document-level\ntranslation and multimodal translation by showcasing empirical examples that\ndemonstrate the superiority of LRMs in translation. We also identify several\ninteresting phenomenons for LRMs for MT including auto-pivot translation as\nwell as the critical challenges such as over-localisation in translation and\ninference efficiency. In conclusion, we think that LRMs redefine translation\nsystems not merely as text converters but as multilingual cognitive agents\ncapable of reasoning about meaning beyond the text. This paradigm shift reminds\nus to think of problems in translation beyond traditional translation scenarios\nin a much broader context with LRMs - what we can achieve on top of it.\n","authors":["Sinuo Liu","Chenyang Lyu","Minghao Wu","Longyue Wang","Weihua Luo","Kaifu Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13191v2","updated":"2025-03-13T13:20:17Z","published":"2024-09-20T03:47:54Z","title":"Diabetica: Adapting Large Language Model to Enhance Multiple Medical\n  Tasks in Diabetes Care and Management","summary":"  Diabetes is a chronic disease with a significant global health burden,\nrequiring multi-stakeholder collaboration for optimal management. Large\nlanguage models (LLMs) have shown promise in various healthcare scenarios, but\ntheir effectiveness across diverse diabetes tasks remains unproven. Our study\nintroduced a framework to train and validate diabetes-specific LLMs. We first\ndeveloped a comprehensive data processing pipeline that includes data\ncollection, filtering, augmentation and refinement. This created a\nhigh-quality, diabetes-specific dataset and evaluation benchmarks from scratch.\nFine-tuned on the collected training dataset, our diabetes-specific LLM family\ndemonstrated state-of-the-art proficiency in processing various diabetes tasks\ncompared to other LLMs. Furthermore, clinical studies revealed the potential\napplications of our models in diabetes care, including providing personalized\nhealthcare, assisting medical education, and streamlining clinical tasks.\nGenerally, our introduced framework helps develop diabetes-specific LLMs and\nhighlights their potential to enhance clinical practice and provide\npersonalized, data-driven support for diabetes management across different end\nusers. Our codes, benchmarks and models are available at\nhttps://github.com/waltonfuture/Diabetica.\n","authors":["Lai Wei","Zhen Ying","Muyang He","Yutong Chen","Qian Yang","Yanzhe Hong","Jiaping Lu","Kaipeng Zheng","Shaoting Zhang","Xiaoying Li","Weiran Huang","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2409.13191v2.pdf","comment":"Accepted by ICLR 2025 SCI-FM workshop"},{"id":"http://arxiv.org/abs/2502.07938v3","updated":"2025-03-13T13:19:30Z","published":"2025-02-11T20:35:29Z","title":"Adapting Multilingual Embedding Models to Historical Luxembourgish","summary":"  The growing volume of digitized historical texts requires effective semantic\nsearch using text embeddings. However, pre-trained multilingual models face\nchallenges with historical content due to OCR noise and outdated spellings.\nThis study examines multilingual embeddings for cross-lingual semantic search\nin historical Luxembourgish (LB), a low-resource language. We collect\nhistorical Luxembourgish news articles from various periods and use GPT-4o for\nsentence segmentation and translation, generating 20,000 parallel training\nsentences per language pair. Additionally, we create a semantic search\n(Historical LB Bitext Mining) evaluation set and find that existing models\nperform poorly on cross-lingual search for historical Luxembourgish. Using our\nhistorical and additional modern parallel training data, we adapt several\nmultilingual embedding models through contrastive learning or knowledge\ndistillation and increase accuracy significantly for all models. We release our\nadapted models and historical Luxembourgish-German/French/English bitexts to\nsupport further research.\n","authors":["Andrianos Michail","Corina Julia Raclé","Juri Opitz","Simon Clematide"],"pdf_url":"https://arxiv.org/pdf/2502.07938v3.pdf","comment":"To appear in LaTeCH-CLfL 2025"},{"id":"http://arxiv.org/abs/2503.10337v1","updated":"2025-03-13T13:15:28Z","published":"2025-03-13T13:15:28Z","title":"KV-Distill: Nearly Lossless Learnable Context Compression for LLMs","summary":"  Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.\n","authors":["Vivek Chari","Guanghui Qin","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2503.10337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14614v2","updated":"2025-03-13T13:13:07Z","published":"2025-02-20T14:52:36Z","title":"FIND: Fine-grained Information Density Guided Adaptive\n  Retrieval-Augmented Generation for Disease Diagnosis","summary":"  Retrieval-Augmented Large Language Models (LLMs), which integrate external\nknowledge into LLMs, have shown remarkable performance in various medical\ndomains, including clinical diagnosis. However, existing RAG methods struggle\nto effectively assess task difficulty to make retrieval decisions, thereby\nfailing to meet the clinical requirements for balancing efficiency and\naccuracy. So in this paper, we propose FIND (\\textbf{F}ine-grained\n\\textbf{In}formation \\textbf{D}ensity Guided Adaptive RAG), a novel framework\nthat improves the reliability of RAG in disease diagnosis scenarios. FIND\nincorporates a fine-grained adaptive control module to determine whether\nretrieval is necessary based on the information density of the input. By\noptimizing the retrieval process and implementing a knowledge filtering module,\nFIND ensures that the retrieval is better suited to clinical scenarios.\nExperiments on three Chinese electronic medical record datasets demonstrate\nthat FIND significantly outperforms various baseline methods, highlighting its\neffectiveness in clinical diagnosis tasks.\n","authors":["Mingyi Jia","Junwen Duan","Yan Song","Jianxin Wang"],"pdf_url":"https://arxiv.org/pdf/2502.14614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01727v2","updated":"2025-03-13T13:09:14Z","published":"2024-10-02T16:37:19Z","title":"Automated Knowledge Concept Annotation and Question Representation\n  Learning for Knowledge Tracing","summary":"  Knowledge tracing (KT) is a popular approach for modeling students' learning\nprogress over time, which can enable more personalized and adaptive learning.\nHowever, existing KT approaches face two major limitations: (1) they rely\nheavily on expert-defined knowledge concepts (KCs) in questions, which is\ntime-consuming and prone to errors; and (2) KT methods tend to overlook the\nsemantics of both questions and the given KCs. In this work, we address these\nchallenges and present KCQRL, a framework for automated knowledge concept\nannotation and question representation learning that can improve the\neffectiveness of any existing KT model. First, we propose an automated KC\nannotation process using large language models (LLMs), which generates question\nsolutions and then annotates KCs in each solution step of the questions.\nSecond, we introduce a contrastive learning approach to generate semantically\nrich embeddings for questions and solution steps, aligning them with their\nassociated KCs via a tailored false negative elimination approach. These\nembeddings can be readily integrated into existing KT models, replacing their\nrandomly initialized embeddings. We demonstrate the effectiveness of KCQRL\nacross 15 KT algorithms on two large real-world Math learning datasets, where\nwe achieve consistent performance improvements.\n","authors":["Yilmazcan Ozyurt","Stefan Feuerriegel","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.01727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10331v1","updated":"2025-03-13T13:07:51Z","published":"2025-03-13T13:07:51Z","title":"OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting\n  Conditions","summary":"  Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.\n","authors":["Maxim Popov","Regina Kurkova","Mikhail Iumanov","Jaafar Mahmoud","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2503.10331v1.pdf","comment":"Project page: https://be2rlab.github.io/OSMa-Bench/"},{"id":"http://arxiv.org/abs/2503.07384v2","updated":"2025-03-13T12:37:37Z","published":"2025-03-10T14:32:56Z","title":"Is My Text in Your AI Model? Gradient-based Membership Inference Test\n  applied to LLMs","summary":"  This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.\n","authors":["Gonzalo Mancera","Daniel DeAlcala","Julian Fierrez","Ruben Tolosana","Aythami Morales"],"pdf_url":"https://arxiv.org/pdf/2503.07384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10294v1","updated":"2025-03-13T12:07:35Z","published":"2025-03-13T12:07:35Z","title":"Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy\n  for Analysing Wiki Deletion Discussions","summary":"  Automated content moderation for collaborative knowledge hubs like Wikipedia\nor Wikidata is an important yet challenging task due to multiple factors. In\nthis paper, we construct a database of discussions happening around articles\nmarked for deletion in several Wikis and in three languages, which we then use\nto evaluate a range of LMs on different tasks (from predicting the outcome of\nthe discussion to identifying the implicit policy an individual comment might\nbe pointing to). Our results reveal, among others, that discussions leading to\ndeletion are easier to predict, and that, surprisingly, self-produced tags\n(keep, delete or redirect) don't always help guiding the classifiers,\npresumably because of users' hesitation or deliberation within comments.\n","authors":["Hsuvas Borkakoty","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.10294v1.pdf","comment":"Accepted to WNUT-2025"},{"id":"http://arxiv.org/abs/2503.10291v1","updated":"2025-03-13T12:03:37Z","published":"2025-03-13T12:03:37Z","title":"VisualPRM: An Effective Process Reward Model for Multimodal Reasoning","summary":"  We introduce VisualPRM, an advanced multimodal Process Reward Model (PRM)\nwith 8B parameters, which improves the reasoning abilities of existing\nMultimodal Large Language Models (MLLMs) across different model scales and\nfamilies with Best-of-N (BoN) evaluation strategies. Specifically, our model\nimproves the reasoning performance of three types of MLLMs and four different\nmodel scales. Even when applied to the highly capable InternVL2.5-78B, it\nachieves a 5.9-point improvement across seven multimodal reasoning benchmarks.\nExperimental results show that our model exhibits superior performance compared\nto Outcome Reward Models and Self-Consistency during BoN evaluation. To\nfacilitate the training of multimodal PRMs, we construct a multimodal process\nsupervision dataset VisualPRM400K using an automated data pipeline. For the\nevaluation of multimodal PRMs, we propose VisualProcessBench, a benchmark with\nhuman-annotated step-wise correctness labels, to measure the abilities of PRMs\nto detect erroneous steps in multimodal reasoning tasks. We hope that our work\ncan inspire more future research and contribute to the development of MLLMs.\nOur model, data, and benchmark are released in\nhttps://internvl.github.io/blog/2025-03-13-VisualPRM/.\n","authors":["Weiyun Wang","Zhangwei Gao","Lianjie Chen","Zhe Chen","Jinguo Zhu","Xiangyu Zhao","Yangzhou Liu","Yue Cao","Shenglong Ye","Xizhou Zhu","Lewei Lu","Haodong Duan","Yu Qiao","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2503.10291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10267v1","updated":"2025-03-13T11:24:09Z","published":"2025-03-13T11:24:09Z","title":"An Expanded Massive Multilingual Dataset for High-Performance Language\n  Technologies","summary":"  Training state-of-the-art large language models requires vast amounts of\nclean and diverse textual data. However, building suitable multilingual\ndatasets remains a challenge. In this work, we present HPLT v2, a collection of\nhigh-quality multilingual monolingual and parallel corpora. The monolingual\nportion of the data contains 8T tokens covering 193 languages, while the\nparallel data contains 380M sentence pairs covering 51 languages. We document\nthe entire data pipeline and release the code to reproduce it. We provide\nextensive analysis of the quality and characteristics of our data. Finally, we\nevaluate the performance of language models and machine translation systems\ntrained on HPLT v2, demonstrating its value.\n","authors":["Laurie Burchell","Ona de Gibert","Nikolay Arefyev","Mikko Aulamo","Marta Bañón","and Pinzhen Chen","Mariia Fedorova","Liane Guillou","Barry Haddow","Jan Hajič","and Jindřich Helcl","Erik Henriksson","Mateusz Klimaszewski","Ville Komulainen","and Andrey Kutuzov","Joona Kytöniemi","Veronika Laippala","Petter Mæhlum","and Bhavitvya Malik","Farrokh Mehryary","Vladislav Mikhailov","Nikita Moghe","and Amanda Myntti","Dayyán O'Brien","Stephan Oepen","Proyag Pal","Jousia Piha","and Sampo Pyysalo","Gema Ramírez-Sánchez","David Samuel","Pavel Stepachev","and Jörg Tiedemann","Dušan Variš","Tereza Vojtěchová","Jaume Zaragoza-Bernabeu"],"pdf_url":"https://arxiv.org/pdf/2503.10267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12455v2","updated":"2025-03-13T10:40:09Z","published":"2025-02-18T02:37:26Z","title":"DSMoE: Matrix-Partitioned Experts with Dynamic Routing for\n  Computation-Efficient Dense LLMs","summary":"  As large language models continue to scale, computational costs and resource\nconsumption have emerged as significant challenges. While existing\nsparsification methods like pruning reduce computational overhead, they risk\nlosing model knowledge through parameter removal. This paper proposes DSMoE\n(Dynamic Sparse Mixture-of-Experts), a novel approach that achieves\nsparsification by partitioning pre-trained FFN layers into computational\nblocks. We implement adaptive expert routing using sigmoid activation and\nstraight-through estimators, enabling tokens to flexibly access different\naspects of model knowledge based on input complexity. Additionally, we\nintroduce a sparsity loss term to balance performance and computational\nefficiency. Extensive experiments on LLaMA models demonstrate that under\nequivalent computational constraints, DSMoE achieves superior performance\ncompared to existing pruning and MoE approaches across language modeling and\ndownstream tasks, particularly excelling in generation tasks. Analysis reveals\nthat DSMoE learns distinctive layerwise activation patterns, providing new\ninsights for future MoE architecture design.\n","authors":["Minxuan Lv","Zhenpeng Su","Leiyu Pan","Yizhe Xiong","Zijia Lin","Hui Chen","Wei Zhou","Jungong Han","Guiguang Ding","Cheng Luo","Di Zhang","Kun Gai","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2502.12455v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10242v1","updated":"2025-03-13T10:34:43Z","published":"2025-03-13T10:34:43Z","title":"MinorBench: A hand-built benchmark for content-based risks for children","summary":"  Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.\n","authors":["Shaun Khoo","Gabriel Chua","Rachel Shong"],"pdf_url":"https://arxiv.org/pdf/2503.10242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10233v1","updated":"2025-03-13T10:16:46Z","published":"2025-03-13T10:16:46Z","title":"ARLED: Leveraging LED-based ARMAN Model for Abstractive Summarization of\n  Persian Long Documents","summary":"  The increasing volume of textual data poses challenges in reading and\ncomprehending large documents, particularly for scholars who need to extract\nuseful information from research articles. Automatic text summarization has\nemerged as a powerful tool to condense lengthy documents into concise and\ninformative summaries. Depending on the approach used, text summarization can\nbe categorized as either extractive or abstractive. While extractive methods\nare commonly used due to their simplicity, they often miss important\ninformation. On the other hand, Abstractive Summarization can generate more\ncoherent and informative summaries by understanding the underlying meaning of\nthe text. Abstractive techniques have gained attention in various languages,\nand recent advancements have been achieved through pre-training models such as\nBERT, BART, and T5. However, the challenge of summarizing long documents\nremains, and alternative models like Longformer have been introduced to address\nthis limitation. In this context, this paper focuses on abstractive\nsummarization in the Persian language. The authors introduce a new dataset of\n300,000 full-text Persian papers obtained from the Ensani website and apply the\nARMAN model, based on the Longformer architecture, to generate summaries. The\nexperimental results demonstrate promising performance in Persian text\nsummarization. The paper provides a comprehensive overview of related work,\ndiscusses the methodology, presents the experimental results, and concludes\nwith future research directions.\n","authors":["Samira Zangooei","Amirhossein Darmani","Hossein Farahmand Nezhad","Laya Mahmoudi"],"pdf_url":"https://arxiv.org/pdf/2503.10233v1.pdf","comment":"11 pages, 3 tables"},{"id":"http://arxiv.org/abs/2503.10229v1","updated":"2025-03-13T10:12:34Z","published":"2025-03-13T10:12:34Z","title":"R.U.Psycho? Robust Unified Psychometric Testing of Language Models","summary":"  Generative language models are increasingly being subjected to psychometric\nquestionnaires intended for human testing, in efforts to establish their\ntraits, as benchmarks for alignment, or to simulate participants in social\nscience experiments. While this growing body of work sheds light on the\nlikeness of model responses to those of humans, concerns are warranted\nregarding the rigour and reproducibility with which these experiments may be\nconducted. Instabilities in model outputs, sensitivity to prompt design,\nparameter settings, and a large number of available model versions increase\ndocumentation requirements. Consequently, generalization of findings is often\ncomplex and reproducibility is far from guaranteed. In this paper, we present\nR.U.Psycho, a framework for designing and running robust and reproducible\npsychometric experiments on generative language models that requires limited\ncoding expertise. We demonstrate the capability of our framework on a variety\nof psychometric questionnaires, which lend support to prior findings in the\nliterature. R.U.Psycho is available as a Python package at\nhttps://github.com/julianschelb/rupsycho.\n","authors":["Julian Schelb","Orr Borin","David Garcia","Andreas Spitz"],"pdf_url":"https://arxiv.org/pdf/2503.10229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10220v1","updated":"2025-03-13T10:01:07Z","published":"2025-03-13T10:01:07Z","title":"Assessing the validity of new paradigmatic complexity measures as\n  criterial features for proficiency in L2 writings in English","summary":"  This article addresses Second Language (L2) writing development through an\ninvestigation of new grammatical and structural complexity metrics. We explore\nthe paradigmatic production in learner English by linking language functions to\nspecific grammatical paradigms. Using the EFCAMDAT as a gold standard and a\ncorpus of French learners as an external test set, we employ a supervised\nlearning framework to operationalise and evaluate seven microsystems. We show\nthat learner levels are associated with the seven microsystems (MS). Using\nordinal regression modelling for evaluation, the results show that all MS are\nsignificant but yield a low impact if taken individually. However, their\ninfluence is shown to be impactful if taken as a group. These microsystems and\ntheir measurement method suggest that it is possible to use them as part of\nbroader-purpose CALL systems focused on proficiency assessment.\n","authors":["Cyriel Mallart","Andrew Simpkin","Nicolas Ballier","Paula Lissón","Rémi Venant","Jen-Yu Li","Bernardo Stearns","Thomas Gaillat"],"pdf_url":"https://arxiv.org/pdf/2503.10220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10211v1","updated":"2025-03-13T09:54:35Z","published":"2025-03-13T09:54:35Z","title":"Adaptive Inner Speech-Text Alignment for LLM-based Speech Translation","summary":"  Recent advancement of large language models (LLMs) has led to significant\nbreakthroughs across various tasks, laying the foundation for the development\nof LLM-based speech translation systems. Existing methods primarily focus on\naligning inputs and outputs across modalities while overlooking deeper semantic\nalignment within model representations. To address this limitation, we propose\nan Adaptive Inner Speech-Text Alignment (AI-STA) method to bridge the modality\ngap by explicitly aligning speech and text representations at selected layers\nwithin LLMs. To achieve this, we leverage the optimal transport (OT) theory to\nquantify fine-grained representation discrepancies between speech and text.\nFurthermore, we utilize the cross-modal retrieval technique to identify the\nlayers that are best suited for alignment and perform joint training on these\nlayers. Experimental results on speech translation (ST) tasks demonstrate that\nAI-STA significantly improves the translation performance of large speech-text\nmodels (LSMs), outperforming previous state-of-the-art approaches. Our findings\nhighlight the importance of inner-layer speech-text alignment in LLMs and\nprovide new insights into enhancing cross-modal learning.\n","authors":["Henglyu Liu","Andong Chen","Kehai Chen","Xuefeng Bai","Meizhi Zhong","Yuan Qiu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10211v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.19339v2","updated":"2025-03-13T09:40:42Z","published":"2025-02-26T17:32:07Z","title":"Evaluating LLMs and Pre-trained Models for Text Summarization Across\n  Diverse Datasets","summary":"  Text summarization plays a crucial role in natural language processing by\ncondensing large volumes of text into concise and coherent summaries. As\ndigital content continues to grow rapidly and the demand for effective\ninformation retrieval increases, text summarization has become a focal point of\nresearch in recent years. This study offers a thorough evaluation of four\nleading pre-trained and open-source large language models: BART, FLAN-T5,\nLLaMA-3-8B, and Gemma-7B, across five diverse datasets CNN/DM, Gigaword, News\nSummary, XSum, and BBC News. The evaluation employs widely recognized automatic\nmetrics, including ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR, to assess\nthe models' capabilities in generating coherent and informative summaries. The\nresults reveal the comparative strengths and limitations of these models in\nprocessing various text types.\n","authors":["Tohida Rehman","Soumabha Ghosh","Kuntal Das","Souvik Bhattacharjee","Debarshi Kumar Sanyal","Samiran Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2502.19339v2.pdf","comment":"5 pages, 2 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.10192v1","updated":"2025-03-13T09:27:24Z","published":"2025-03-13T09:27:24Z","title":"Red Teaming Contemporary AI Models: Insights from Spanish and Basque\n  Perspectives","summary":"  The battle for AI leadership is on, with OpenAI in the United States and\nDeepSeek in China as key contenders. In response to these global trends, the\nSpanish government has proposed ALIA, a public and transparent AI\ninfrastructure incorporating small language models designed to support Spanish\nand co-official languages such as Basque. This paper presents the results of\nRed Teaming sessions, where ten participants applied their expertise and\ncreativity to manually test three of the latest models from these\ninitiatives$\\unicode{x2013}$OpenAI o3-mini, DeepSeek R1, and ALIA\nSalamandra$\\unicode{x2013}$focusing on biases and safety concerns. The results,\nbased on 670 conversations, revealed vulnerabilities in all the models under\ntest, with biased or unsafe responses ranging from 29.5% in o3-mini to 50.6% in\nSalamandra. These findings underscore the persistent challenges in developing\nreliable and trustworthy AI systems, particularly those intended to support\nSpanish and Basque languages.\n","authors":["Miguel Romero-Arjona","Pablo Valle","Juan C. Alonso","Ana B. Sánchez","Miriam Ugarte","Antonia Cazalilla","Vicente Cambrón","José A. Parejo","Aitor Arrieta","Sergio Segura"],"pdf_url":"https://arxiv.org/pdf/2503.10192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10177v1","updated":"2025-03-13T08:58:10Z","published":"2025-03-13T08:58:10Z","title":"PRISM: Preference Refinement via Implicit Scene Modeling for 3D\n  Vision-Language Preference-Based Reinforcement Learning","summary":"  We propose PRISM, a novel framework designed to overcome the limitations of\n2D-based Preference-Based Reinforcement Learning (PBRL) by unifying 3D point\ncloud modeling and future-aware preference refinement. At its core, PRISM\nadopts a 3D Point Cloud-Language Model (3D-PC-LLM) to mitigate occlusion and\nviewpoint biases, ensuring more stable and spatially consistent preference\nsignals. Additionally, PRISM leverages Chain-of-Thought (CoT) reasoning to\nincorporate long-horizon considerations, thereby preventing the short-sighted\nfeedback often seen in static preference comparisons. In contrast to\nconventional PBRL techniques, this integration of 3D perception and\nfuture-oriented reasoning leads to significant gains in preference agreement\nrates, faster policy convergence, and robust generalization across unseen\nrobotic environments. Our empirical results, spanning tasks such as robotic\nmanipulation and autonomous navigation, highlight PRISM's potential for\nreal-world applications where precise spatial understanding and reliable\nlong-term decision-making are critical. By bridging 3D geometric awareness with\nCoT-driven preference modeling, PRISM establishes a comprehensive foundation\nfor scalable, human-aligned reinforcement learning.\n","authors":["Yirong Sun","Yanjun Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10167v1","updated":"2025-03-13T08:46:32Z","published":"2025-03-13T08:46:32Z","title":"\"Well, Keep Thinking\": Enhancing LLM Reasoning with Adaptive Injection\n  Decoding","summary":"  Large language models (LLMs) exhibit strong reasoning abilities, often\nattributed to few-shot or zero-shot chain-of-thought (CoT) prompting. While\neffective, these methods require labor-intensive prompt engineering, raising\nthe question of whether reasoning can be induced without reliance on explicit\nprompts. In this work, we unlock the reasoning capabilities of LLMs without\nexplicit prompting. Inspired by zero-shot CoT and CoT-decoding, we propose a\nnovel decoding strategy that systematically nudges LLMs to continue reasoning,\nthereby preventing immature reasoning processes. Specifically, we monitor the\nmodel's generation and inject a designated phrase whenever it is likely to\nconclude its response prematurely, before completing the reasoning process. Our\nexperimental evaluations on diverse reasoning benchmarks demonstrate that our\nproposed strategy substantially improves LLM reasoning capabilities,\nhighlighting the potential of decoding-based interventions as an alternative to\ntraditional prompting techniques.\n","authors":["Hyunbin Jin","Je Won Yeom","Seunghyun Bae","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2503.10167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08426v5","updated":"2025-03-13T08:45:35Z","published":"2024-06-12T17:13:17Z","title":"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL","summary":"  Generating accurate SQL from users' natural language questions (text-to-SQL)\nremains a long-standing challenge due to the complexities involved in user\nquestion understanding, database schema comprehension, and SQL generation.\nTraditional text-to-SQL systems, which combine human engineering and deep\nneural networks, have made significant progress. Subsequently, pre-trained\nlanguage models (PLMs) have been developed for text-to-SQL tasks, achieving\npromising results. However, as modern databases and user questions grow more\ncomplex, PLMs with a limited parameter size often produce incorrect SQL. This\nnecessitates more sophisticated and tailored optimization methods, which\nrestricts the application of PLM-based systems. Recently, large language models\n(LLMs) have shown significant capabilities in natural language understanding as\nmodel scale increases. Thus, integrating LLM-based solutions can bring unique\nopportunities, improvements, and solutions to text-to-SQL research. In this\nsurvey, we provide a comprehensive review of existing LLM-based text-to-SQL\nstudies. Specifically, we offer a brief overview of the technical challenges\nand evolutionary process of text-to-SQL. Next, we introduce the datasets and\nmetrics designed to evaluate text-to-SQL systems. Subsequently, we present a\nsystematic analysis of recent advances in LLM-based text-to-SQL. Finally, we\nmake a summarization and discuss the remaining challenges in this field and\nsuggest expectations for future research directions.\n","authors":["Zijin Hong","Zheng Yuan","Qinggang Zhang","Hao Chen","Junnan Dong","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.08426v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10150v1","updated":"2025-03-13T08:22:31Z","published":"2025-03-13T08:22:31Z","title":"Retrieval-Augmented Generation with Hierarchical Knowledge","summary":"  Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.\n","authors":["Haoyu Huang","Yongfeng Huang","Junjie Yang","Zhenyu Pan","Yongqiang Chen","Kaili Ma","Hongzhi Chen","James Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.10150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04305v2","updated":"2025-03-13T08:04:09Z","published":"2025-03-06T10:46:15Z","title":"Computational Law: Datasets, Benchmarks, and Ontologies","summary":"  Recent developments in computer science and artificial intelligence have also\ncontributed to the legal domain, as revealed by the number and range of related\npublications and applications. Machine and deep learning models require\nconsiderable amount of domain-specific data for training and comparison\npurposes, in order to attain high-performance in the legal domain.\nAdditionally, semantic resources such as ontologies are valuable for building\nlarge-scale computational legal systems, in addition to ensuring\ninteroperability of such systems. Considering these aspects, we present an\nup-to-date review of the literature on datasets, benchmarks, and ontologies\nproposed for computational law. We believe that this comprehensive and recent\nreview will help researchers and practitioners when developing and testing\napproaches and systems for computational law.\n","authors":["Dilek Küçük","Fazli Can"],"pdf_url":"https://arxiv.org/pdf/2503.04305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10135v1","updated":"2025-03-13T07:55:38Z","published":"2025-03-13T07:55:38Z","title":"Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative\n  Decoding","summary":"  Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.\n","authors":["Jinze Li","Yixing Xu","Haiduo Huang","Xuanwu Yin","Dong Li","Edith C. H. Ngai","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2503.10135v1.pdf","comment":"Paper under review"},{"id":"http://arxiv.org/abs/2503.10095v1","updated":"2025-03-13T06:42:37Z","published":"2025-03-13T06:42:37Z","title":"Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for\n  Mental Health Prediction via Online Text","summary":"  Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.\n","authors":["Avinash Patil","Amardeep Kour Gedhu"],"pdf_url":"https://arxiv.org/pdf/2503.10095v1.pdf","comment":"8 pages, 4 Figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.10094v1","updated":"2025-03-13T06:41:26Z","published":"2025-03-13T06:41:26Z","title":"Semantic Synergy: Unlocking Policy Insights and Learning Pathways\n  Through Advanced Skill Mapping","summary":"  This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.\n","authors":["Phoebe Koundouri","Conrad Landis","Georgios Feretzakis"],"pdf_url":"https://arxiv.org/pdf/2503.10094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12854v2","updated":"2025-03-13T06:40:44Z","published":"2024-10-10T22:22:05Z","title":"TPO: Aligning Large Language Models with Multi-branch & Multi-step\n  Preference Trees","summary":"  In the domain of complex reasoning tasks, such as mathematical reasoning,\nrecent advancements have proposed the use of Direct Preference Optimization\n(DPO) to suppress output of dispreferred responses, thereby enhancing the\nlong-chain reasoning capabilities of large language models (LLMs). To this end,\nthese studies employed LLMs to generate preference trees via Tree-of-thoughts\n(ToT) and sample the paired preference responses required by the DPO algorithm.\nHowever, the DPO algorithm based on binary preference optimization is unable to\nlearn multiple responses with varying degrees of preference/dispreference that\nprovided by the preference trees, resulting in incomplete preference learning.\nIn this work, we introduce Tree Preference Optimization (TPO), that does not\nsample paired preference responses from the preference tree; instead, it\ndirectly learns from the entire preference tree during the fine-tuning.\nSpecifically, TPO formulates the language model alignment as a Preference List\nRanking problem, where the policy can potentially learn more effectively from a\nranked preference list of responses given the prompt. In addition, to further\nassist LLMs in identifying discriminative steps within long-chain reasoning and\nincrease the relative reward margin in the preference list, TPO utilizes\nAdaptive Step Reward to adjust the reward values of each step in trajectory for\nperforming fine-grained preference optimization. We carry out extensive\nexperiments on mathematical reasoning tasks to evaluate TPO. The experimental\nresults indicate that TPO consistently outperforms DPO across five public large\nlanguage models on four datasets.\n","authors":["Weibin Liao","Xu Chu","Yasha Wang"],"pdf_url":"https://arxiv.org/pdf/2410.12854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10093v1","updated":"2025-03-13T06:40:34Z","published":"2025-03-13T06:40:34Z","title":"Representation-based Reward Modeling for Efficient Safety Alignment of\n  Large Language Model","summary":"  Reinforcement Learning (RL) algorithms for safety alignment of Large Language\nModels (LLMs), such as Direct Preference Optimization (DPO), encounter the\nchallenge of distribution shift. Current approaches typically address this\nissue through online sampling from the target policy, which requires\nsignificant computational resources. In this paper, we hypothesize that during\noff-policy training, while the ranking order of output generated by policy\nchanges, their overall distribution remains relatively stable. This stability\nallows the transformation of the sampling process from the target policy into a\nre-ranking of preference data. Building on this hypothesis, We propose a new\nframework that leverages the model's intrinsic safety judgment capability to\nextract reward signals, which are then used to calculate label confidence for\npreferences reordering. Extensive experimental results and theoretical analysis\ndemonstrate that the proposed method effectively addresses the distribution\nshift issue, remarkably enhancing the safety performance while reducing about\n300x computational overheads.\n","authors":["Qiyuan Deng","Xuefeng Bai","Kehai Chen","Yaowei Wang","Liqiang Nie","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20657v2","updated":"2025-03-13T06:16:16Z","published":"2024-07-30T08:52:16Z","title":"Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks","summary":"  Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.\n","authors":["Hunmin Yang","Jongoh Jeong","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2407.20657v2.pdf","comment":"Accepted to ECCV 2024 (Oral), Project Page:\n  https://PDCL-Attack.github.io"},{"id":"http://arxiv.org/abs/2503.10084v1","updated":"2025-03-13T06:11:10Z","published":"2025-03-13T06:11:10Z","title":"Why Does Your CoT Prompt (Not) Work? Theoretical Analysis of Prompt\n  Space Complexity, its Interaction with Answer Space During CoT Reasoning with\n  LLMs: A Recurrent Perspective","summary":"  Despite the remarkable successes of Large Language Models (LLMs), their\nfundamental Transformer architecture possesses inherent theoretical limitations\nthat restrict their capability to handle reasoning tasks with increasing\ncomputational complexity. Chain-of-Thought (CoT) prompting has emerged as a\npractical solution, supported by several theoretical studies. However, current\nCoT-based methods (including ToT, GoT, etc.) generally adopt a\n\"one-prompt-fits-all\" strategy, using fixed templates (e.g., \"think step by\nstep\") across diverse reasoning tasks. This method forces models to navigate an\nextremely complex prompt space to identify effective reasoning paths. The\ncurrent prompt designing research are also heavily relying on trial-and-error\nrather than theoretically informed guidance. In this paper, we provide a\nrigorous theoretical analysis of the complexity and interplay between two\ncrucial spaces: the prompt space (the space of potential prompt structures) and\nthe answer space (the space of reasoning solutions generated by LLMs) in CoT\nreasoning. We demonstrate how reliance on a single universal prompt (e.g. think\nstep by step) can negatively impact the theoretical computability of LLMs,\nillustrating that prompt complexity directly influences the structure and\neffectiveness of the navigation in answer space. Our analysis highlights that\nsometimes human supervision is critical for efficiently navigating the prompt\nspace. We theoretically and empirically show that task-specific prompting\nsignificantly outperforms unsupervised prompt generation, emphasizing the\nnecessity of thoughtful human guidance in CoT prompting.\n","authors":["Xiang Zhang","Juntai Cao","Jiaqi Wei","Chenyu You","Dujian Ding"],"pdf_url":"https://arxiv.org/pdf/2503.10084v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.14198"},{"id":"http://arxiv.org/abs/2410.08202v3","updated":"2025-03-13T06:09:17Z","published":"2024-10-10T17:59:22Z","title":"Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large\n  Language Models with Endogenous Visual Pre-training","summary":"  In this paper, we focus on monolithic Multimodal Large Language Models\n(MLLMs) that integrate visual encoding and language decoding into a single LLM.\nIn particular, we identify that existing pre-training strategies for monolithic\nMLLMs often suffer from unstable optimization or catastrophic forgetting. To\naddress this issue, our core idea is to embed a new visual parameter space into\na pre-trained LLM, thereby stably learning visual knowledge from noisy data\nwhile freezing the LLM. Based on this principle, we present Mono-InternVL, a\nnovel monolithic MLLM that seamlessly integrates a set of visual experts via a\nmultimodal mixture-of-experts structure. Moreover, we propose an innovative\npre-training strategy to maximize the visual capability of Mono-InternVL,\nnamely Endogenous Visual Pre-training (EViP). In particular, EViP is designed\nas a progressive learning process for visual experts, which aims to fully\nexploit the visual knowledge from noisy data to high-quality data. To validate\nour approach, we conduct extensive experiments on 16 benchmarks. Experimental\nresults confirm the superior performance of Mono-InternVL than existing\nmonolithic MLLMs on 13 of 16 multimodal benchmarks, e.g., +80 points over Emu3\non OCRBench. Compared to the modular baseline, i.e., InternVL-1.5,\nMono-InternVL still retains comparable multimodal performance while reducing up\nto 67% first token latency. Code and model are released at\nhttps://github.com/OpenGVLab/Mono-InternVL.\n","authors":["Gen Luo","Xue Yang","Wenhan Dou","Zhaokai Wang","Jiawen Liu","Jifeng Dai","Yu Qiao","Xizhou Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.08202v3.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.10079v1","updated":"2025-03-13T05:58:41Z","published":"2025-03-13T05:58:41Z","title":"Information Density Principle for MLLM Benchmarks","summary":"  With the emergence of Multimodal Large Language Models (MLLMs), hundreds of\nbenchmarks have been developed to ensure the reliability of MLLMs in downstream\ntasks. However, the evaluation mechanism itself may not be reliable. For\ndevelopers of MLLMs, questions remain about which benchmark to use and whether\nthe test results meet their requirements. Therefore, we propose a critical\nprinciple of Information Density, which examines how much insight a benchmark\ncan provide for the development of MLLMs. We characterize it from four key\ndimensions: (1) Fallacy, (2) Difficulty, (3) Redundancy, (4) Diversity. Through\na comprehensive analysis of more than 10,000 samples, we measured the\ninformation density of 19 MLLM benchmarks. Experiments show that using the\nlatest benchmarks in testing can provide more insight compared to previous\nones, but there is still room for improvement in their information density. We\nhope this principle can promote the development and application of future MLLM\nbenchmarks. Project page: https://github.com/lcysyzxdxc/bench4bench\n","authors":["Chunyi Li","Xiaozhe Li","Zicheng Zhang","Yuan Tian","Ziheng Jia","Xiaohong Liu","Xiongkuo Min","Jia Wang","Haodong Duan","Kai Chen","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2503.10079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10061v1","updated":"2025-03-13T05:21:22Z","published":"2025-03-13T05:21:22Z","title":"Compute Optimal Scaling of Skills: Knowledge vs Reasoning","summary":"  Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: $\\textbf{scaling laws are\nskill-dependent}$. Next, to understand whether skill-dependent scaling is an\nartefact of the pretraining datamix, we conduct an extensive ablation of\ndifferent datamixes and find that, also when correcting for datamix\ndifferences, $\\textbf{knowledge and code exhibit fundamental differences in\nscaling behaviour}$. We conclude with an analysis of how our findings relate to\nstandard compute-optimal scaling using a validation set, and find that\n$\\textbf{a misspecified validation set can impact compute-optimal parameter\ncount by nearly 50%,}$ depending on its skill composition.\n","authors":["Nicholas Roberts","Niladri Chatterji","Sharan Narang","Mike Lewis","Dieuwke Hupkes"],"pdf_url":"https://arxiv.org/pdf/2503.10061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09567v2","updated":"2025-03-13T04:34:15Z","published":"2025-03-12T17:35:03Z","title":"Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning\n  Large Language Models","summary":"  Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"test-time scaling.\" This survey seeks to\nfill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and test-time scaling, offering\ninsights into how these processes manifest in practice. (4) Finally, we\nidentify significant research gaps and highlight promising future directions,\nincluding the integration of multi-modal reasoning, efficiency improvements,\nand enhanced knowledge frameworks. By providing a structured overview, this\nsurvey aims to inspire future research and further the development of logical\nreasoning in artificial intelligence.\n","authors":["Qiguang Chen","Libo Qin","Jinhao Liu","Dengyun Peng","Jiannan Guan","Peng Wang","Mengkang Hu","Yuhang Zhou","Te Gao","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2503.09567v2.pdf","comment":"Paper are available at https://long-cot.github.io/"},{"id":"http://arxiv.org/abs/2503.10023v1","updated":"2025-03-13T04:04:55Z","published":"2025-03-13T04:04:55Z","title":"Using Context to Improve Word Segmentation","summary":"  An important step in understanding how children acquire languages is studying\nhow infants learn word segmentation. It has been established in previous\nresearch that infants may use statistical regularities in speech to learn word\nsegmentation. The research of Goldwater et al., demonstrated that incorporating\ncontext in models improves their ability to learn word segmentation. We\nimplemented two of their models, a unigram and bigram model, to examine how\ncontext can improve statistical word segmentation. The results are consistent\nwith our hypothesis that the bigram model outperforms the unigram model at\npredicting word segmentation. Extending the work of Goldwater et al., we also\nexplored basic ways to model how young children might use previously learned\nwords to segment new utterances.\n","authors":["Stephanie Hu","Xiaolu Guo"],"pdf_url":"https://arxiv.org/pdf/2503.10023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17599v2","updated":"2025-03-13T04:04:08Z","published":"2025-02-24T19:34:52Z","title":"MEDA: Dynamic KV Cache Allocation for Efficient Multimodal Long-Context\n  Inference","summary":"  Long-context Multimodal Large Language Models (MLLMs) that incorporate long\ntext-image and text-video modalities, demand substantial resources as their\nmultimodal Key-Value (KV) caches grow with increasing input lengths,\nchallenging inference efficiency. Existing methods for KV cache compression, in\nboth text-only and multimodal LLMs, have neglected attention density variations\nacross layers, thus often adopting uniform or progressive reduction strategies\nfor layer-wise cache allocation. In this work, we propose MEDA, a dynamic\nlayer-wise KV cache allocation method for efficient multimodal long-context\ninference. As its core, MEDA utilizes cross-modal attention entropy to\ndetermine the KV cache size at each MLLMs layer. Given the dynamically\nallocated KV cache size at each layer, MEDA also employs a KV pair selection\nscheme to identify which KV pairs to select and a KV pair merging strategy that\nmerges the selected and non-selected ones to preserve information from the\nentire context. MEDA achieves up to 72% KV cache memory reduction and 2.82\ntimes faster decoding speed, while maintaining or enhancing performance on\nvarious multimodal tasks in long-context settings, including multi-images and\nlong-video scenarios. Our code is released at\nhttps://github.com/AIoT-MLSys-Lab/MEDA.\n","authors":["Zhongwei Wan","Hui Shen","Xin Wang","Che Liu","Zheda Mai","Mi Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.17599v2.pdf","comment":"NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2501.14225v2","updated":"2025-03-13T03:55:17Z","published":"2025-01-24T04:09:03Z","title":"Multi-agent KTO: Reinforcing Strategic Interactions of Large Language\n  Model in Language Game","summary":"  Achieving Artificial General Intelligence (AGI) requires AI agents that can\nnot only make stratigic decisions but also engage in flexible and meaningful\ncommunication. Inspired by Wittgenstein's language game theory in Philosophical\nInvestigations, we propose that language agents can learn through in-context\ninteraction rather than traditional multi-stage frameworks that separate\ndecision-making from language expression. Using Werewolf, a social deduction\ngame that tests language understanding, strategic interaction, and\nadaptability, we develop the Multi-agent Kahneman & Tversky's Optimization\n(MaKTO). MaKTO engages diverse models in extensive gameplay to generate\nunpaired desirable and unacceptable responses, then employs KTO to refine the\nmodel's decision-making process. In 9-player Werewolf games, MaKTO achieves a\n61% average win rate across various models, outperforming GPT-4o and two-stage\nRL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,\nMaKTO also demonstrates human-like performance, winning 60% against expert\nplayers and showing only 49% detectability in Turing-style blind tests.\n","authors":["Rong Ye","Yongxin Zhang","Yikai Zhang","Haoyu Kuang","Zhongyu Wei","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2501.14225v2.pdf","comment":"Preprint. Code and data will be available at\n  https://reneeye.github.io/MaKTO.html"},{"id":"http://arxiv.org/abs/2402.08382v3","updated":"2025-03-13T03:32:50Z","published":"2024-02-13T11:22:52Z","title":"Punctuation restoration improves structure understanding without\n  supervision","summary":"  Unsupervised learning objectives like autoregressive and masked language\nmodeling constitute a significant part in producing pre-trained representations\nthat perform various downstream applications from natural language\nunderstanding to conversational tasks. However, despite impressive generative\ncapabilities of recent large language models, their abilities to capture\nsyntactic or semantic structure within text lag behind. We hypothesize that the\nmismatch between linguistic performance and competence in machines is\nattributable to insufficient learning of linguistic structure knowledge via\ncurrently popular pre-training objectives. Working with English, we show that\npunctuation restoration as a learning objective improves performance on\nstructure-related tasks like named entity recognition, open information\nextraction, chunking, and part-of-speech tagging. Punctuation restoration\nresults in $\\blacktriangle$$\\geq2\\%$p improvement in 16 out of 18 experiments,\nacross 6 out of 7 tasks. Our results show that punctuation restoration is an\neffective learning objective that can improve structure understanding and yield\na more robust structure-aware representations of natural language in base-sized\nmodels.\n","authors":["Junghyun Min","Minho Lee","Woochul Lee","Yeonsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2402.08382v3.pdf","comment":"11 pages, 1 figure, 6 tables. RepL4NLP 2025"},{"id":"http://arxiv.org/abs/2503.09532v2","updated":"2025-03-13T03:18:16Z","published":"2025-03-12T16:49:02Z","title":"SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language\n  Model Interpretability","summary":"  Sparse autoencoders (SAEs) are a popular technique for interpreting language\nmodel activations, and there is extensive recent work on improving SAE\neffectiveness. However, most prior work evaluates progress using unsupervised\nproxy metrics with unclear practical relevance. We introduce SAEBench, a\ncomprehensive evaluation suite that measures SAE performance across seven\ndiverse metrics, spanning interpretability, feature disentanglement and\npractical applications like unlearning. To enable systematic comparison, we\nopen-source a suite of over 200 SAEs across eight recently proposed SAE\narchitectures and training algorithms. Our evaluation reveals that gains on\nproxy metrics do not reliably translate to better practical performance. For\ninstance, while Matryoshka SAEs slightly underperform on existing proxy\nmetrics, they substantially outperform other architectures on feature\ndisentanglement metrics; moreover, this advantage grows with SAE scale. By\nproviding a standardized framework for measuring progress in SAE development,\nSAEBench enables researchers to study scaling trends and make nuanced\ncomparisons between different SAE architectures and training methodologies. Our\ninteractive interface enables researchers to flexibly visualize relationships\nbetween metrics across hundreds of open-source SAEs at: https://saebench.xyz\n","authors":["Adam Karvonen","Can Rager","Johnny Lin","Curt Tigges","Joseph Bloom","David Chanin","Yeu-Tong Lau","Eoin Farrell","Callum McDougall","Kola Ayonrinde","Matthew Wearden","Arthur Conmy","Samuel Marks","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2503.09532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13035v3","updated":"2025-03-13T03:16:43Z","published":"2024-06-18T20:01:51Z","title":"D2O: Dynamic Discriminative Operations for Efficient Long-Context\n  Inference of Large Language Models","summary":"  Generative inference in Large Language Models (LLMs) is impeded by the\ngrowing memory demands of Key-Value (KV) cache, especially for longer\nsequences. Traditional KV cache eviction strategies, which discard less\ncritical KV pairs based on attention scores, often degrade generation quality,\nleading to issues such as context loss or hallucinations. In this work, we\nintroduce Dynamic Discriminative Operations (D2O), a KV cache compression\nmethod that optimizes KV cache size dynamically and discriminatively at two\nlevels without fine-tuning, while preserving essential context. At layer level,\nD2O leverages the varying densities of attention weights between shallow and\ndeep layers to dynamically determine which layers should avoid excessive\neviction via a novel dynamic allocation strategy to minimize information loss.\nAt token level, D2O incorporates a compensation mechanism that maintains a\nsimilarity threshold to re-discriminate the importance of currently discarded\ntokens, determining whether they should be recalled and merged with similar\ntokens. We conduct experiments on various benchmarks and LLM architectures. Our\nresults show that D2O not only achieves significant memory savings and enhances\ninference throughput by more than 3$\\times$ but also maintains high-quality\nlong-text generation.\n","authors":["Zhongwei Wan","Xinjian Wu","Yu Zhang","Yi Xin","Chaofan Tao","Zhihong Zhu","Xin Wang","Siqi Luo","Jing Xiong","Longyue Wang","Mi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.13035v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.02948v2","updated":"2025-03-13T03:15:49Z","published":"2024-11-05T09:44:53Z","title":"Grounding Natural Language to SQL Translation with Data-Based\n  Self-Explanations","summary":"  Natural Language Interfaces for Databases empower non-technical users to\ninteract with data using natural language (NL). Advanced approaches, utilizing\neither neural sequence-to-sequence or more recent sophisticated large-scale\nlanguage models, typically implement NL to SQL (NL2SQL) translation in an\nend-to-end fashion. However, like humans, these end-to-end translation models\nmay not always generate the best SQL output on their first try. In this paper,\nwe propose CycleSQL, an iterative framework designed for end-to-end translation\nmodels to autonomously generate the best output through self-evaluation. The\nmain idea of CycleSQL is to introduce data-grounded NL explanations of query\nresults as self-provided feedback, and use the feedback to validate the\ncorrectness of the translation iteratively, hence improving the overall\ntranslation accuracy. Extensive experiments, including quantitative and\nqualitative evaluations, are conducted to study CycleSQL by applying it to\nseven existing translation models on five widely used benchmarks. The results\nshow that 1) the feedback loop introduced in CycleSQL can consistently improve\nthe performance of existing models, and in particular, by applying CycleSQL to\nRESDSQL, obtains a translation accuracy of 82.0% (+2.6%) on the validation set,\nand 81.6% (+3.2%) on the test set of Spider benchmark; 2) the generated NL\nexplanations can also provide insightful information for users, aiding in the\ncomprehension of translation results and consequently enhancing the\ninterpretability of NL2SQL translation.\n","authors":["Yuankai Fan","Tonghui Ren","Can Huang","Zhenying He","X. Sean Wang"],"pdf_url":"https://arxiv.org/pdf/2411.02948v2.pdf","comment":"ICDE2025"},{"id":"http://arxiv.org/abs/2404.14812v2","updated":"2025-03-13T03:03:57Z","published":"2024-04-23T07:50:00Z","title":"Enhancing Chain of Thought Prompting in Large Language Models via\n  Reasoning Patterns","summary":"  Chain of Thought (CoT) prompting can encourage language models to engage in\nmulti-step logical reasoning. The quality of the provided demonstrations\nsignificantly influences the success of downstream inference tasks. Current\nunsupervised CoT methods primarily select examples based on the semantics of\nthe questions, which can introduce noise and lack interpretability. In this\npaper, we propose leveraging reasoning patterns to enhance CoT prompting\neffectiveness. Reasoning patterns represent the process by which language\nmodels arrive at their final results. By utilizing prior knowledge and\nprompt-based methods from large models, we first construct task-specific\npattern sets. We then select diverse demonstrations based on different\nreasoning patterns. This approach not only mitigates the impact of noise but\nalso provides explicit interpretability to help us understand the mechanisms of\nCoT. Extensive experiments demonstrate that our method is more robust and\nconsistently leads to improvements across various reasoning tasks.\n","authors":["Yufeng Zhang","Xuepeng Wang","Lingxiang Wu","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2404.14812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14871v3","updated":"2025-03-13T02:36:28Z","published":"2024-11-22T11:45:33Z","title":"Preference Alignment for Diffusion Model via Explicit Denoised\n  Distribution Estimation","summary":"  Diffusion models have shown remarkable success in text-to-image generation,\nmaking preference alignment for these models increasingly important. The\npreference labels are typically available only at the terminal of denoising\ntrajectories, which poses challenges in optimizing the intermediate denoising\nsteps. In this paper, we propose to conduct Denoised Distribution Estimation\n(DDE) that explicitly connects intermediate steps to the terminal denoised\ndistribution. Therefore, preference labels can be used for the entire\ntrajectory optimization. To this end, we design two estimation strategies for\nour DDE. The first is stepwise estimation, which utilizes the conditional\ndenoised distribution to estimate the model denoised distribution. The second\nis single-shot estimation, which converts the model output into the terminal\ndenoised distribution via DDIM modeling. Analytically and empirically, we\nreveal that DDE equipped with two estimation strategies naturally derives a\nnovel credit assignment scheme that prioritizes optimizing the middle part of\nthe denoising trajectory. Extensive experiments demonstrate that our approach\nachieves superior performance, both quantitatively and qualitatively.\n","authors":["Dingyuan Shi","Yong Wang","Hangyu Li","Xiangxiang Chu"],"pdf_url":"https://arxiv.org/pdf/2411.14871v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18947v3","updated":"2025-03-13T02:29:47Z","published":"2024-12-25T16:51:29Z","title":"MedHallBench: A New Benchmark for Assessing Hallucination in Medical\n  Large Language Models","summary":"  Medical Large Language Models (MLLMs) have demonstrated potential in\nhealthcare applications, yet their propensity for hallucinations -- generating\nmedically implausible or inaccurate information -- presents substantial risks\nto patient care. This paper introduces MedHallBench, a comprehensive benchmark\nframework for evaluating and mitigating hallucinations in MLLMs. Our\nmethodology integrates expert-validated medical case scenarios with established\nmedical databases to create a robust evaluation dataset. The framework employs\na sophisticated measurement system that combines automated ACHMI (Automatic\nCaption Hallucination Measurement in Medical Imaging) scoring with rigorous\nclinical expert evaluations and utilizes reinforcement learning methods to\nachieve automatic annotation. Through an optimized reinforcement learning from\nhuman feedback (RLHF) training pipeline specifically designed for medical\napplications, MedHallBench enables thorough evaluation of MLLMs across diverse\nclinical contexts while maintaining stringent accuracy standards. We conducted\ncomparative experiments involving various models, utilizing the benchmark to\nestablish a baseline for widely adopted large language models (LLMs). Our\nfindings indicate that ACHMI provides a more nuanced understanding of the\neffects of hallucinations compared to traditional metrics, thereby highlighting\nits advantages in hallucination assessment. This research establishes a\nfoundational framework for enhancing MLLMs' reliability in healthcare settings\nand presents actionable strategies for addressing the critical challenge of AI\nhallucinations in medical applications.\n","authors":["Kaiwen Zuo","Yirui Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.18947v3.pdf","comment":"Published to AAAI-25 Bridge Program"},{"id":"http://arxiv.org/abs/2503.09964v1","updated":"2025-03-13T02:10:29Z","published":"2025-03-13T02:10:29Z","title":"ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist\n  Content","summary":"  Large Multimodal Models (LMMs) are increasingly vulnerable to AI-generated\nextremist content, including photorealistic images and text, which can be used\nto bypass safety mechanisms and generate harmful outputs. However, existing\ndatasets for evaluating LMM robustness offer limited exploration of extremist\ncontent, often lacking AI-generated images, diverse image generation models,\nand comprehensive coverage of historical events, which hinders a complete\nassessment of model vulnerabilities. To fill this gap, we introduce\nExtremeAIGC, a benchmark dataset and evaluation framework designed to assess\nLMM vulnerabilities against such content. ExtremeAIGC simulates real-world\nevents and malicious use cases by curating diverse text- and image-based\nexamples crafted using state-of-the-art image generation techniques. Our study\nreveals alarming weaknesses in LMMs, demonstrating that even cutting-edge\nsafety measures fail to prevent the generation of extremist material. We\nsystematically quantify the success rates of various attack strategies,\nexposing critical gaps in current defenses and emphasizing the need for more\nrobust mitigation strategies.\n","authors":["Bhavik Chandna","Mariam Aboujenane","Usman Naseem"],"pdf_url":"https://arxiv.org/pdf/2503.09964v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.09958v1","updated":"2025-03-13T02:01:02Z","published":"2025-03-13T02:01:02Z","title":"Take Off the Training Wheels Progressive In-Context Learning for\n  Effective Alignment","summary":"  Recent studies have explored the working mechanisms of In-Context Learning\n(ICL). However, they mainly focus on classification and simple generation\ntasks, limiting their broader application to more complex generation tasks in\npractice. To address this gap, we investigate the impact of demonstrations on\ntoken representations within the practical alignment tasks. We find that the\ntransformer embeds the task function learned from demonstrations into the\nseparator token representation, which plays an important role in the generation\nof prior response tokens. Once the prior response tokens are determined, the\ndemonstrations become redundant.Motivated by this finding, we propose an\nefficient Progressive In-Context Alignment (PICA) method consisting of two\nstages. In the first few-shot stage, the model generates several prior response\ntokens via standard ICL while concurrently extracting the ICL vector that\nstores the task function from the separator token representation. In the\nfollowing zero-shot stage, this ICL vector guides the model to generate\nresponses without further demonstrations.Extensive experiments demonstrate that\nour PICA not only surpasses vanilla ICL but also achieves comparable\nperformance to other alignment tuning methods. The proposed training-free\nmethod reduces the time cost (e.g., 5.45+) with improved alignment performance\n(e.g., 6.57+). Consequently, our work highlights the application of ICL for\nalignment and calls for a deeper understanding of ICL for complex generations.\nThe code will be available at https://github.com/HITsz-TMG/PICA.\n","authors":["Zhenyu Liu","Dongfang Li","Xinshuo Hu","Xinping Zhao","Yibin Chen","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.09958v1.pdf","comment":"15 pages, 9 figures, published in EMNLP2024"},{"id":"http://arxiv.org/abs/2503.09927v1","updated":"2025-03-13T00:48:48Z","published":"2025-03-13T00:48:48Z","title":"Developing and Evaluating an AI-Assisted Prediction Model for Unplanned\n  Intensive Care Admissions following Elective Neurosurgery using Natural\n  Language Processing within an Electronic Healthcare Record System","summary":"  Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.\n","authors":["Julia Ive","Olatomiwa Olukoya","Jonathan P. Funnell","James Booker","Sze H M Lam","Ugan Reddy","Kawsar Noor","Richard JB Dobson","Astri M. V. Luoma","Hani J Marcus"],"pdf_url":"https://arxiv.org/pdf/2503.09927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09925v1","updated":"2025-03-13T00:45:27Z","published":"2025-03-13T00:45:27Z","title":"PluralLLM: Pluralistic Alignment in LLMs via Federated Learning","summary":"  Ensuring Large Language Models (LLMs) align with diverse human preferences\nwhile preserving privacy and fairness remains a challenge. Existing methods,\nsuch as Reinforcement Learning from Human Feedback (RLHF), rely on centralized\ndata collection, making them computationally expensive and privacy-invasive. We\nintroduce PluralLLM a federated learning-based approach that enables multiple\nuser groups to collaboratively train a transformer-based preference predictor\nwithout sharing sensitive data, which can also serve as a reward model for\naligning LLMs. Our method leverages Federated Averaging (FedAvg) to aggregate\npreference updates efficiently, achieving 46% faster convergence, a 4%\nimprovement in alignment scores, and nearly the same group fairness measure as\nin centralized training. Evaluated on a Q/A preference alignment task,\nPluralLLM demonstrates that federated preference learning offers a scalable and\nprivacy-preserving alternative for aligning LLMs with diverse human values.\n","authors":["Mahmoud Srewa","Tianyu Zhao","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2503.09925v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.10638v1","updated":"2025-03-13T17:59:59Z","published":"2025-03-13T17:59:59Z","title":"Studying Classifier(-Free) Guidance From a Classifier-Centric\n  Perspective","summary":"  Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.\n","authors":["Xiaoming Zhao","Alexander G. Schwing"],"pdf_url":"https://arxiv.org/pdf/2503.10638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10636v1","updated":"2025-03-13T17:59:56Z","published":"2025-03-13T17:59:56Z","title":"The Curse of Conditions: Analyzing and Improving Optimal Transport for\n  Conditional Flow-Based Generation","summary":"  Minibatch optimal transport coupling straightens paths in unconditional flow\nmatching. This leads to computationally less demanding inference as fewer\nintegration steps and less complex numerical solvers can be employed when\nnumerically solving an ordinary differential equation at test time. However, in\nthe conditional setting, minibatch optimal transport falls short. This is\nbecause the default optimal transport mapping disregards conditions, resulting\nin a conditionally skewed prior distribution during training. In contrast, at\ntest time, we have no access to the skewed prior, and instead sample from the\nfull, unbiased prior distribution. This gap between training and testing leads\nto a subpar performance. To bridge this gap, we propose conditional optimal\ntransport C^2OT that adds a conditional weighting term in the cost matrix when\ncomputing the optimal transport assignment. Experiments demonstrate that this\nsimple fix works with both discrete and continuous conditions in\n8gaussians-to-moons, CIFAR-10, ImageNet-32x32, and ImageNet-256x256. Our method\nperforms better overall compared to the existing baselines across different\nfunction evaluation budgets. Code is available at\nhttps://hkchengrex.github.io/C2OT\n","authors":["Ho Kei Cheng","Alexander Schwing"],"pdf_url":"https://arxiv.org/pdf/2503.10636v1.pdf","comment":"Project page: https://hkchengrex.github.io/C2OT"},{"id":"http://arxiv.org/abs/2503.10635v1","updated":"2025-03-13T17:59:55Z","published":"2025-03-13T17:59:55Z","title":"A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90%\n  Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1","summary":"  Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.\n","authors":["Zhaoyi Li","Xiaohan Zhao","Dong-Dong Wu","Jiacheng Cui","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2503.10635v1.pdf","comment":"Code at: https://github.com/VILA-Lab/M-Attack"},{"id":"http://arxiv.org/abs/2503.10633v1","updated":"2025-03-13T17:59:53Z","published":"2025-03-13T17:59:53Z","title":"Charting and Navigating Hugging Face's Model Atlas","summary":"  As there are now millions of publicly available neural networks, searching\nand analyzing large model repositories becomes increasingly important.\nNavigating so many models requires an atlas, but as most models are poorly\ndocumented charting such an atlas is challenging. To explore the hidden\npotential of model repositories, we chart a preliminary atlas representing the\ndocumented fraction of Hugging Face. It provides stunning visualizations of the\nmodel landscape and evolution. We demonstrate several applications of this\natlas including predicting model attributes (e.g., accuracy), and analyzing\ntrends in computer vision models. However, as the current atlas remains\nincomplete, we propose a method for charting undocumented regions.\nSpecifically, we identify high-confidence structural priors based on dominant\nreal-world model training practices. Leveraging these priors, our approach\nenables accurate mapping of previously undocumented areas of the atlas. We\npublicly release our datasets, code, and interactive atlas.\n","authors":["Eliahu Horwitz","Nitzan Kurer","Jonathan Kahana","Liel Amar","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2503.10633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10632v1","updated":"2025-03-13T17:59:52Z","published":"2025-03-13T17:59:52Z","title":"Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision\n  Transformers?","summary":"  Kolmogorov-Arnold networks (KANs) are a remarkable innovation consisting of\nlearnable activation functions with the potential to capture more complex\nrelationships from data. Although KANs are useful in finding symbolic\nrepresentations and continual learning of one-dimensional functions, their\neffectiveness in diverse machine learning (ML) tasks, such as vision, remains\nquestionable. Presently, KANs are deployed by replacing multilayer perceptrons\n(MLPs) in deep network architectures, including advanced architectures such as\nvision Transformers (ViTs). In this paper, we are the first to design a general\nlearnable Kolmogorov-Arnold Attention (KArAt) for vanilla ViTs that can operate\non any choice of basis. However, the computing and memory costs of training\nthem motivated us to propose a more modular version, and we designed particular\nlearnable attention, called Fourier-KArAt. Fourier-KArAt and its variants\neither outperform their ViT counterparts or show comparable performance on\nCIFAR-10, CIFAR-100, and ImageNet-1K datasets. We dissect these architectures'\nperformance and generalization capacity by analyzing their loss landscapes,\nweight distributions, optimizer path, attention visualization, and spectral\nbehavior, and contrast them with vanilla ViTs. The goal of this paper is not to\nproduce parameter- and compute-efficient attention, but to encourage the\ncommunity to explore KANs in conjunction with more advanced architectures that\nrequire a careful understanding of learnable activations. Our open-source code\nand implementation details are available on: https://subhajitmaity.me/KArAt\n","authors":["Subhajit Maity","Killian Hitsman","Xin Li","Aritra Dutta"],"pdf_url":"https://arxiv.org/pdf/2503.10632v1.pdf","comment":"Preprint, Appendix included"},{"id":"http://arxiv.org/abs/2503.10628v1","updated":"2025-03-13T17:59:41Z","published":"2025-03-13T17:59:41Z","title":"Uncertainty in Action: Confidence Elicitation in Embodied Agents","summary":"  Expressing confidence is challenging for embodied agents navigating dynamic\nmultimodal environments, where uncertainty arises from both perception and\ndecision-making processes. We present the first work investigating embodied\nconfidence elicitation in open-ended multimodal environments. We introduce\nElicitation Policies, which structure confidence assessment across inductive,\ndeductive, and abductive reasoning, along with Execution Policies, which\nenhance confidence calibration through scenario reinterpretation, action\nsampling, and hypothetical reasoning. Evaluating agents in calibration and\nfailure prediction tasks within the Minecraft environment, we show that\nstructured reasoning approaches, such as Chain-of-Thoughts, improve confidence\ncalibration. However, our findings also reveal persistent challenges in\ndistinguishing uncertainty, particularly under abductive settings, underscoring\nthe need for more sophisticated embodied confidence elicitation methods.\n","authors":["Tianjiao Yu","Vedant Shah","Muntasir Wahed","Kiet A. Nguyen","Adheesh Juvekar","Tal August","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2503.10628v1.pdf","comment":"Project page: https://plan-lab.github.io/ece/"},{"id":"http://arxiv.org/abs/2503.10626v1","updated":"2025-03-13T17:59:24Z","published":"2025-03-13T17:59:24Z","title":"NIL: No-data Imitation Learning by Leveraging Pre-trained Video\n  Diffusion Models","summary":"  Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.\n","authors":["Mert Albaba","Chenhao Li","Markos Diomataris","Omid Taheri","Andreas Krause","Michael Black"],"pdf_url":"https://arxiv.org/pdf/2503.10626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10622v1","updated":"2025-03-13T17:59:06Z","published":"2025-03-13T17:59:06Z","title":"Transformers without Normalization","summary":"  Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.\n","authors":["Jiachen Zhu","Xinlei Chen","Kaiming He","Yann LeCun","Zhuang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.10622v1.pdf","comment":"CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/"},{"id":"http://arxiv.org/abs/2503.08679v2","updated":"2025-03-13T17:49:58Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal non-negligible rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (16.3%), DeepSeek R1 (5.3%) and\nChatGPT-4o (7.0%) all answer a notable proportion of question pairs\nunfaithfully. Specifically, we find that models rationalize their implicit\nbiases in answers to binary questions (\"implicit post-hoc rationalization\").\nFor example, when separately presented with the questions \"Is X bigger than Y?\"\nand \"Is Y bigger than X?\", models sometimes produce superficially coherent\narguments to justify answering Yes to both questions or No to both questions,\ndespite such responses being logically contradictory. We also investigate\nrestoration errors (Dziri et al., 2023), where models make and then silently\ncorrect errors in their reasoning, and unfaithful shortcuts, where models use\nclearly illogical reasoning to simplify solving problems in Putnam questions (a\nhard benchmark). Our findings raise challenges for AI safety work that relies\non monitoring CoT to detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v2.pdf","comment":"Accepted to the Reasoning and Planning for Large Language Models\n  Workshop (ICLR 25), 10 main paper pages, 38 appendix pages"},{"id":"http://arxiv.org/abs/2503.10594v1","updated":"2025-03-13T17:42:48Z","published":"2025-03-13T17:42:48Z","title":"Poly-MgNet: Polynomial Building Blocks in Multigrid-Inspired ResNets","summary":"  The structural analogies of ResNets and Multigrid (MG) methods such as common\nbuilding blocks like convolutions and poolings where already pointed out by He\net al.\\ in 2016. Multigrid methods are used in the context of scientific\ncomputing for solving large sparse linear systems arising from partial\ndifferential equations. MG methods particularly rely on two main concepts:\nsmoothing and residual restriction / coarsening. Exploiting these analogies, He\nand Xu developed the MgNet framework, which integrates MG schemes into the\ndesign of ResNets. In this work, we introduce a novel neural network building\nblock inspired by polynomial smoothers from MG theory. Our polynomial block\nfrom an MG perspective naturally extends the MgNet framework to Poly-Mgnet and\nat the same time reduces the number of weights in MgNet. We present a\ncomprehensive study of our polynomial block, analyzing the choice of initial\ncoefficients, the polynomial degree, the placement of activation functions, as\nwell as of batch normalizations. Our results demonstrate that constructing\n(quadratic) polynomial building blocks based on real and imaginary polynomial\nroots enhances Poly-MgNet's capacity in terms of accuracy. Furthermore, our\napproach achieves an improved trade-off of model accuracy and number of weights\ncompared to ResNet as well as compared to specific configurations of MgNet.\n","authors":["Antonia van Betteray","Matthias Rottmann","Karsten Kahl"],"pdf_url":"https://arxiv.org/pdf/2503.10594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10587v1","updated":"2025-03-13T17:36:46Z","published":"2025-03-13T17:36:46Z","title":"The Spectral Bias of Shallow Neural Network Learning is Shaped by the\n  Choice of Non-linearity","summary":"  Despite classical statistical theory predicting severe overfitting, modern\nmassively overparameterized neural networks still generalize well. This\nunexpected property is attributed to the network's so-called implicit bias,\nwhich describes its propensity to converge to solutions that generalize\neffectively, among the many possible that correctly label the training data.\nThe aim of our research is to explore this bias from a new perspective,\nfocusing on how non-linear activation functions contribute to shaping it.\nFirst, we introduce a reparameterization which removes a continuous weight\nrescaling symmetry. Second, in the kernel regime, we leverage this\nreparameterization to generalize recent findings that relate shallow Neural\nNetworks to the Radon transform, deriving an explicit formula for the implicit\nbias induced by a broad class of activation functions. Specifically, by\nutilizing the connection between the Radon transform and the Fourier transform,\nwe interpret the kernel regime's inductive bias as minimizing a spectral\nseminorm that penalizes high-frequency components, in a manner dependent on the\nactivation function. Finally, in the adaptive regime, we demonstrate the\nexistence of local dynamical attractors that facilitate the formation of\nclusters of hyperplanes where the input to a neuron's activation function is\nzero, yielding alignment between many neurons' response functions. We confirm\nthese theoretical results with simulations. All together, our work provides a\ndeeper understanding of the mechanisms underlying the generalization\ncapabilities of overparameterized neural networks and its relation with the\nimplicit bias, offering potential pathways for designing more efficient and\nrobust models.\n","authors":["Justin Sahs","Ryan Pyle","Fabio Anselmi","Ankit Patel"],"pdf_url":"https://arxiv.org/pdf/2503.10587v1.pdf","comment":"18 pages, 10 figures in main text"},{"id":"http://arxiv.org/abs/2403.03185v4","updated":"2025-03-13T17:35:13Z","published":"2024-03-05T18:22:15Z","title":"Correlated Proxies: A New Definition and Improved Mitigation for Reward\n  Hacking","summary":"  Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using proxy reward\nfunctions that only approximate the true goal. However, optimizing proxy\nrewards frequently leads to reward hacking: the optimized reward function\nceases to be a good proxy and the resulting policy performs poorly with respect\nto the unspecified true reward. Principled solutions to reward hacking have\nbeen impeded by the lack of a good definition for the problem. To address this\ngap, we introduce a definition of reward hacking based on the correlation\nbetween proxy and true rewards for states and actions seen by a \"reference\npolicy\" that breaks down under optimization. We show that this definition\ncaptures reward hacking behavior across several realistic settings, including\nin reinforcement learning from human feedback (RLHF). Using our formulation, we\nshow theoretically that regularization to the reference policy can effectively\nprevent reward hacking. While the current practice in RLHF applies a KL penalty\nbetween action distributions for this purpose, our theory suggests regularizing\nthe $\\chi^2$ divergence between the policies' occupancy measures can be more\neffective. We intuitively show the benefits of this type of regularization and\ndemonstrate that it better mitigates reward hacking in practice across four\nrealistic settings, including RLHF. Our code is available at\nhttps://github.com/cassidylaidlaw/orpo.\n","authors":["Cassidy Laidlaw","Shivam Singhal","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2403.03185v4.pdf","comment":"Spotlight at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10580v1","updated":"2025-03-13T17:31:51Z","published":"2025-03-13T17:31:51Z","title":"On the Injective Norm of Sums of Random Tensors and the Moments of\n  Gaussian Chaoses","summary":"  We prove an upper bound on the expected $\\ell_p$ injective norm of sums of\nsubgaussian random tensors. Our proof is simple and does not rely on any\nexplicit geometric or chaining arguments. Instead, it follows from a simple\napplication of the PAC-Bayesian lemma, a tool that has proven effective at\ncontrolling the suprema of certain ``smooth'' empirical processes in recent\nyears. Our bound strictly improves a very recent result of Bandeira, Gopi,\nJiang, Lucca, and Rothvoss. In the Euclidean case ($p=2$), our bound sharpens a\nresult of Lata{\\l}a that was central to proving his estimates on the moments of\nGaussian chaoses. As a consequence, we obtain an elementary proof of this\nfundamental result.\n","authors":["Ishaq Aden-Ali"],"pdf_url":"https://arxiv.org/pdf/2503.10580v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.06215v3","updated":"2025-03-13T17:30:48Z","published":"2024-10-08T17:20:37Z","title":"DataEnvGym: Data Generation Agents in Teacher Environments with Student\n  Feedback","summary":"  The process of creating training data to teach models is currently driven by\nhumans, who manually analyze model weaknesses and plan how to create data that\nimproves a student model. Approaches using LLMs as annotators reduce human\neffort, but still require humans to interpret feedback from evaluations and\ncontrol the LLM to produce data the student needs. Automating this\nlabor-intensive process by creating autonomous data generation agents - or\nteachers - is desirable, but requires environments that can simulate the\nfeedback-driven, iterative, closed loop of data creation. To enable rapid,\nscalable testing for such agents and their modules, we introduce DataEnvGym, a\ntestbed of teacher environments for data generation agents. DataEnvGym frames\ndata generation as a sequential decision-making task, involving an agent\nconsisting of a data generation policy (which generates a plan for creating\ntraining data) and a data generation engine (which transforms the plan into\ndata), inside an environment that provides student feedback. The agent's goal\nis to improve student performance. Students are iteratively trained and\nevaluated on generated data, and their feedback (in the form of errors or weak\nskills) is reported to the agent after each iteration. DataEnvGym includes\nmultiple teacher environment instantiations across 3 levels of structure in the\nstate representation and action space. More structured environments are based\non inferred skills and offer more interpretability and curriculum control. We\nsupport 4 domains (math, code, VQA, and tool-use) and test multiple students\nand teachers. Example agents in our teaching environments can iteratively\nimprove students across tasks and settings. Moreover, we show that environments\nteach different skill levels and test variants of key modules, pointing to\nfuture work in improving data generation agents, engines, and feedback\nmechanisms.\n","authors":["Zaid Khan","Elias Stengel-Eskin","Jaemin Cho","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.06215v3.pdf","comment":"ICLR 2025 Spotlight; Project Page: https://DataEnvGym.github.io"},{"id":"http://arxiv.org/abs/2503.10576v1","updated":"2025-03-13T17:28:44Z","published":"2025-03-13T17:28:44Z","title":"Sample and Map from a Single Convex Potential: Generation using\n  Conjugate Moment Measures","summary":"  A common approach to generative modeling is to split model-fitting into two\nblocks: define first how to sample noise (e.g. Gaussian) and choose next what\nto do with it (e.g. using a single map or flows). We explore in this work an\nalternative route that ties sampling and mapping. We find inspiration in moment\nmeasures, a result that states that for any measure $\\rho$ supported on a\ncompact convex set of $\\mathbb{R}^d$, there exists a unique convex potential\n$u$ such that $\\rho=\\nabla u\\,\\sharp\\,e^{-u}$. While this does seem to tie\neffectively sampling (from log-concave distribution $e^{-u}$) and action\n(pushing particles through $\\nabla u$), we observe on simple examples (e.g.,\nGaussians or 1D distributions) that this choice is ill-suited for practical\ntasks. We study an alternative factorization, where $\\rho$ is factorized as\n$\\nabla w^*\\,\\sharp\\,e^{-w}$, where $w^*$ is the convex conjugate of $w$. We\ncall this approach conjugate moment measures, and show far more intuitive\nresults on these examples. Because $\\nabla w^*$ is the Monge map between the\nlog-concave distribution $e^{-w}$ and $\\rho$, we rely on optimal transport\nsolvers to propose an algorithm to recover $w$ from samples of $\\rho$, and\nparameterize $w$ as an input-convex neural network.\n","authors":["Nina Vesseron","Louis Béthune","Marco Cuturi"],"pdf_url":"https://arxiv.org/pdf/2503.10576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10573v1","updated":"2025-03-13T17:23:45Z","published":"2025-03-13T17:23:45Z","title":"Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative\n  Study of Large Language Models","summary":"  With the rapid evolution of Artificial Intelligence (AI), Large Language\nModels (LLMs) have reshaped the frontiers of various fields, spanning\nhealthcare, public health, engineering, science, agriculture, education, arts,\nhumanities, and mathematical reasoning. Among these advancements, DeepSeek\nmodels have emerged as noteworthy contenders, demonstrating promising\ncapabilities that set them apart from their peers. While previous studies have\nconducted comparative analyses of LLMs, few have delivered a comprehensive\nevaluation of mathematical reasoning across a broad spectrum of LLMs. In this\nwork, we aim to bridge this gap by conducting an in-depth comparative study,\nfocusing on the strengths and limitations of DeepSeek models in relation to\ntheir leading counterparts. In particular, our study systematically evaluates\nthe mathematical reasoning performance of two DeepSeek models alongside five\nprominent LLMs across three independent benchmark datasets. The findings reveal\nseveral key insights: 1). DeepSeek-R1 consistently achieved the highest\naccuracy on two of the three datasets, demonstrating strong mathematical\nreasoning capabilities. 2). The distilled variant of LLMs significantly\nunderperformed compared to its peers, highlighting potential drawbacks in using\ndistillation techniques. 3). In terms of response time, Gemini 2.0 Flash\ndemonstrated the fastest processing speed, outperforming other models in\nefficiency, which is a crucial factor for real-time applications. Beyond these\nquantitative assessments, we delve into how architecture, training, and\noptimization impact LLMs' mathematical reasoning. Moreover, our study goes\nbeyond mere performance comparison by identifying key areas for future\nadvancements in LLM-driven mathematical reasoning. This research enhances our\nunderstanding of LLMs' mathematical reasoning and lays the groundwork for\nfuture advancements\n","authors":["Afrar Jahin","Arif Hassan Zidan","Yu Bao","Shizhe Liang","Tianming Liu","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10571v1","updated":"2025-03-13T17:23:10Z","published":"2025-03-13T17:23:10Z","title":"Radar: Fast Long-Context Decoding for Any Transformer","summary":"  Transformer models have demonstrated exceptional performance across a wide\nrange of applications. Though forming the foundation of Transformer models, the\ndot-product attention does not scale well to long-context data since its time\nrequirement grows quadratically with context length. In this work, we propose\nRadar, a training-free approach that accelerates inference by dynamically\nsearching for the most important context tokens. For any pre-trained\nTransformer, Radar can reduce the decoding time complexity without training or\nheuristically evicting tokens. Moreover, we provide theoretical justification\nfor our approach, demonstrating that Radar can reliably identify the most\nimportant tokens with high probability. We conduct extensive comparisons with\nthe previous methods on a wide range of tasks. The results demonstrate that\nRadar achieves the state-of-the-art performance across different architectures\nwith reduced time complexity, offering a practical solution for efficient\nlong-context processing of Transformers.\n","authors":["Yongchang Hao","Mengyao Zhai","Hossein Hajimirsadeghi","Sepidehsadat Hosseini","Frederick Tung"],"pdf_url":"https://arxiv.org/pdf/2503.10571v1.pdf","comment":"Accepted @ ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10567v1","updated":"2025-03-13T17:18:18Z","published":"2025-03-13T17:18:18Z","title":"FedPCA: Noise-Robust Fair Federated Learning via Performance-Capacity\n  Analysis","summary":"  Training a model that effectively handles both common and rare data-i.e.,\nachieving performance fairness-is crucial in federated learning (FL). While\nexisting fair FL methods have shown effectiveness, they remain vulnerable to\nmislabeled data. Ensuring robustness in fair FL is therefore essential.\nHowever, fairness and robustness inherently compete, which causes robust\nstrategies to hinder fairness. In this paper, we attribute this competition to\nthe homogeneity in loss patterns exhibited by rare and mislabeled data clients,\npreventing existing loss-based fair and robust FL methods from effectively\ndistinguishing and handling these two distinct client types. To address this,\nwe propose performance-capacity analysis, which jointly considers model\nperformance on each client and its capacity to handle the dataset, measured by\nloss and a newly introduced feature dispersion score. This allows mislabeled\nclients to be identified by their significantly deviated performance relative\nto capacity while preserving rare data clients. Building on this, we introduce\nFedPCA, an FL method that robustly achieves fairness. FedPCA first identifies\nmislabeled clients via a Gaussian Mixture Model on loss-dispersion pairs, then\napplies fairness and robustness strategies in global aggregation and local\ntraining by adjusting client weights and selectively using reliable data.\nExtensive experiments on three datasets demonstrate FedPCA's effectiveness in\ntackling this complex challenge. Code will be publicly available upon\nacceptance.\n","authors":["Nannan Wu","Zengqiang Yan","Nong Sang","Li Yu","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10567v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.10566v1","updated":"2025-03-13T17:17:17Z","published":"2025-03-13T17:17:17Z","title":"ASIDE: Architectural Separation of Instructions and Data in Language\n  Models","summary":"  Despite their remarkable performance, large language models lack elementary\nsafety features, and this makes them susceptible to numerous malicious attacks.\nIn particular, previous work has identified the absence of an intrinsic\nseparation between instructions and data as a root cause for the success of\nprompt injection attacks. In this work, we propose an architectural change,\nASIDE, that allows the model to clearly separate between instructions and data\nby using separate embeddings for them. Instead of training the embeddings from\nscratch, we propose a method to convert an existing model to ASIDE form by\nusing two copies of the original model's embeddings layer, and applying an\northogonal rotation to one of them. We demonstrate the effectiveness of our\nmethod by showing (1) highly increased instruction-data separation scores\nwithout a loss in model capabilities and (2) competitive results on prompt\ninjection benchmarks, even without dedicated safety training. Additionally, we\nstudy the working mechanism behind our method through an analysis of model\nrepresentations.\n","authors":["Egor Zverev","Evgenii Kortukov","Alexander Panfilov","Soroush Tabesh","Alexandra Volkova","Sebastian Lapuschkin","Wojciech Samek","Christoph H. Lampert"],"pdf_url":"https://arxiv.org/pdf/2503.10566v1.pdf","comment":"ICLR 2025 Workshop on Building Trust in Language Models and\n  Applications"},{"id":"http://arxiv.org/abs/2503.10545v1","updated":"2025-03-13T16:58:40Z","published":"2025-03-13T16:58:40Z","title":"From Linear to Spline-Based Classification:Developing and Enhancing SMPA\n  for Noisy Non-Linear Datasets","summary":"  Building upon the concepts and mechanisms used for the development in Moving\nPoints Algorithm, we will now explore how non linear decision boundaries can be\ndeveloped for classification tasks. First we will look at the classification\nperformance of MPA and some minor developments in the original algorithm. We\nthen discuss the concepts behind using cubic splines for classification with a\nsimilar learning mechanism and finally analyze training results on synthetic\ndatasets with known properties.\n","authors":["Vatsal Srivastava"],"pdf_url":"https://arxiv.org/pdf/2503.10545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10544v1","updated":"2025-03-13T16:58:07Z","published":"2025-03-13T16:58:07Z","title":"DP-GPL: Differentially Private Graph Prompt Learning","summary":"  Graph Neural Networks (GNNs) have shown remarkable performance in various\napplications. Recently, graph prompt learning has emerged as a powerful GNN\ntraining paradigm, inspired by advances in language and vision foundation\nmodels. Here, a GNN is pre-trained on public data and then adapted to sensitive\ntasks using lightweight graph prompts. However, using prompts from sensitive\ndata poses privacy risks. In this work, we are the first to investigate these\npractical risks in graph prompts by instantiating a membership inference attack\nthat reveals significant privacy leakage. We also find that the standard\nprivacy method, DP-SGD, fails to provide practical privacy-utility trade-offs\nin graph prompt learning, likely due to the small number of sensitive data\npoints used to learn the prompts. As a solution, we propose DP-GPL for\ndifferentially private graph prompt learning based on the PATE framework, that\ngenerates a graph prompt with differential privacy guarantees. Our evaluation\nacross various graph prompt learning methods, GNN architectures, and\npre-training strategies demonstrates that our algorithm achieves high utility\nat strong privacy, effectively mitigating privacy concerns while preserving the\npowerful capabilities of prompted GNNs as powerful foundation models in the\ngraph domain.\n","authors":["Jing Xu","Franziska Boenisch","Iyiola Emmanuel Olatunji","Adam Dziedzic"],"pdf_url":"https://arxiv.org/pdf/2503.10544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10542v1","updated":"2025-03-13T16:56:47Z","published":"2025-03-13T16:56:47Z","title":"Language Models, Graph Searching, and Supervision Adulteration: When\n  More Supervision is Less and How to Make More More","summary":"  This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2503.10542v1.pdf","comment":"A reduced version of this work has been accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025. Full version under review"},{"id":"http://arxiv.org/abs/2503.10539v1","updated":"2025-03-13T16:52:43Z","published":"2025-03-13T16:52:43Z","title":"GBSVR: Granular Ball Support Vector Regression","summary":"  Support Vector Regression (SVR) and its variants are widely used to handle\nregression tasks, however, since their solution involves solving an expensive\nquadratic programming problem, it limits its application, especially when\ndealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss\nfunction which is sensitive to outliers and therefore can adversely affect its\nperformance. We propose Granular Ball Support Vector Regression (GBSVR) to\ntackle problem of regression by using granular ball concept. These balls are\nuseful in simplifying complex data spaces for machine learning tasks, however,\nto the best of our knowledge, they have not been sufficiently explored for\nregression problems. Granular balls group the data points into balls based on\ntheir proximity and reduce the computational cost in SVR by replacing the large\nnumber of data points with far fewer granular balls. This work also suggests a\ndiscretization method for continuous-valued attributes to facilitate the\nconstruction of granular balls. The effectiveness of the proposed approach is\nevaluated on several benchmark datasets and it outperforms existing\nstate-of-the-art approaches\n","authors":["Reshma Rastogi","Ankush Bisht","Sanjay Kumar","Suresh Chandra"],"pdf_url":"https://arxiv.org/pdf/2503.10539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10537v1","updated":"2025-03-13T16:51:59Z","published":"2025-03-13T16:51:59Z","title":"Structured Preconditioners in Adaptive Optimization: A Unified Analysis","summary":"  We present a novel unified analysis for a broad class of adaptive\noptimization algorithms with structured (e.g., layerwise, diagonal, and\nkronecker-factored) preconditioners for both online regret minimization and\noffline convex optimization. Our analysis not only provides matching rate to\nseveral important structured preconditioned algorithms including diagonal\nAdaGrad, full-matrix AdaGrad, and AdaGrad-Norm, but also gives an improved\nconvergence rate for a one-sided variant of Shampoo over that of original\nShampoo. Interestingly, more structured preconditioners (e.g., diagonal\nAdagrad, AdaGrad-Norm which use less space and compute) are often presented as\ncomputationally efficient approximations to full-matrix Adagrad, aiming for\nimproved optimization performance through better approximations. Our unified\nanalysis challenges this prevailing view and reveals, perhaps surprisingly,\nthat more structured preconditioners, despite using less space and computation\nper step, can outperform their less structured counterparts. To demonstrate\nthis, we show that one-sided Shampoo, which is relatively much cheaper than\nfull-matrix AdaGrad could outperform it both theoretically and experimentally.\n","authors":["Shuo Xie","Tianhao Wang","Sashank Reddi","Sanjiv Kumar","Zhiyuan Li"],"pdf_url":"https://arxiv.org/pdf/2503.10537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18548v3","updated":"2025-03-13T16:48:34Z","published":"2025-02-25T15:56:56Z","title":"What is the Alignment Objective of GRPO?","summary":"  In this note, we examine the aggregation of preferences achieved by the Group\nPolicy Optimisation (GRPO) algorithm, a reinforcement learning method used to\ntrain advanced artificial intelligence models such as DeepSeek-R1-Zero and\nDeepSeekMath. The GRPO algorithm trains a policy using a reward preference\nmodel, which is computed by sampling a set of outputs for a given context,\nobserving the corresponding rewards, and applying shift-and-scale normalisation\nto these reward values. Additionally, it incorporates a penalty function to\ndiscourage deviations from a reference policy.\n  We present a framework that enables us to characterise the stationary\npolicies of the GRPO algorithm. This analysis reveals that the aggregation of\npreferences differs fundamentally from standard logarithmic pooling, which is\nimplemented by other approaches such as RLHF. The precise form of preference\naggregation arises from the way the reward preference model is defined and from\nthe penalty function, which we show to essentially correspond to the reverse\nKullback-Leibler (KL) divergence between the aggregation policy and the\nreference policy.\n  Interestingly, we demonstrate that for groups of size two, the reward\npreference model corresponds to pairwise comparison preferences, similar to\nthose in other alignment methods based on pairwise comparison feedback. We\nprovide explicit characterisations of the aggregate preference for binary\nquestions, for groups of size two, and in the limit of large group size. This\nprovides insights into the dependence of the aggregate preference on parameters\nsuch as the regularisation constant and the confidence margin of question\nanswers.\n  Finally, we discuss the aggregation of preferences obtained by modifying the\nGRPO algorithm to use direct KL divergence as the penalty or to use rewards\nwithout scale normalisation.\n","authors":["Milan Vojnovic","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2502.18548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09494v2","updated":"2025-03-13T16:39:15Z","published":"2025-03-12T15:54:37Z","title":"Representation Retrieval Learning for Heterogeneous Data Integration","summary":"  In the era of big data, large-scale, multi-modal datasets are increasingly\nubiquitous, offering unprecedented opportunities for predictive modeling and\nscientific discovery. However, these datasets often exhibit complex\nheterogeneity, such as covariate shift, posterior drift, and missing\nmodalities, that can hinder the accuracy of existing prediction algorithms. To\naddress these challenges, we propose a novel Representation Retrieval ($R^2$)\nframework, which integrates a representation learning module (the representer)\nwith a sparsity-induced machine learning model (the learner). Moreover, we\nintroduce the notion of \"integrativeness\" for representers, characterized by\nthe effective data sources used in learning representers, and propose a\nSelective Integration Penalty (SIP) to explicitly improve the property.\nTheoretically, we demonstrate that the $R^2$ framework relaxes the conventional\nfull-sharing assumption in multi-task learning, allowing for partially shared\nstructures, and that SIP can improve the convergence rate of the excess risk\nbound. Extensive simulation studies validate the empirical performance of our\nframework, and applications to two real-world datasets further confirm its\nsuperiority over existing approaches.\n","authors":["Qi Xu","Annie Qu"],"pdf_url":"https://arxiv.org/pdf/2503.09494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10522v1","updated":"2025-03-13T16:30:59Z","published":"2025-03-13T16:30:59Z","title":"AudioX: Diffusion Transformer for Anything-to-Audio Generation","summary":"  Audio and music generation have emerged as crucial tasks in many\napplications, yet existing approaches face significant limitations: they\noperate in isolation without unified capabilities across modalities, suffer\nfrom scarce high-quality, multi-modal training data, and struggle to\neffectively integrate diverse inputs. In this work, we propose AudioX, a\nunified Diffusion Transformer model for Anything-to-Audio and Music Generation.\nUnlike previous domain-specific models, AudioX can generate both general audio\nand music with high quality, while offering flexible natural language control\nand seamless processing of various modalities including text, video, image,\nmusic, and audio. Its key innovation is a multi-modal masked training strategy\nthat masks inputs across modalities and forces the model to learn from masked\ninputs, yielding robust and unified cross-modal representations. To address\ndata scarcity, we curate two comprehensive datasets: vggsound-caps with 190K\naudio captions based on the VGGSound dataset, and V2M-caps with 6 million music\ncaptions derived from the V2M dataset. Extensive experiments demonstrate that\nAudioX not only matches or outperforms state-of-the-art specialized models, but\nalso offers remarkable versatility in handling diverse input modalities and\ngeneration tasks within a unified architecture. The code and datasets will be\navailable at https://zeyuet.github.io/AudioX/\n","authors":["Zeyue Tian","Yizhu Jin","Zhaoyang Liu","Ruibin Yuan","Xu Tan","Qifeng Chen","Wei Xue","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2503.10522v1.pdf","comment":"The code and datasets will be available at\n  https://zeyuet.github.io/AudioX/"},{"id":"http://arxiv.org/abs/2503.10520v1","updated":"2025-03-13T16:29:16Z","published":"2025-03-13T16:29:16Z","title":"CountPath: Automating Fragment Counting in Digital Pathology","summary":"  Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.\n","authors":["Ana Beatriz Vieira","Maria Valente","Diana Montezuma","Tomé Albuquerque","Liliana Ribeiro","Domingos Oliveira","João Monteiro","Sofia Gonçalves","Isabel M. Pinto","Jaime S. Cardoso","Arlindo L. Oliveira"],"pdf_url":"https://arxiv.org/pdf/2503.10520v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.06846v4","updated":"2025-03-13T16:17:19Z","published":"2024-10-09T13:06:43Z","title":"Joint Fine-tuning and Conversion of Pretrained Speech and Language\n  Models towards Linear Complexity","summary":"  Architectures such as Linformer and Mamba have recently emerged as\ncompetitive linear time replacements for transformers. However, corresponding\nlarge pretrained models are often unavailable, especially in non-text domains.\nTo remedy this, we present a Cross-Architecture Layerwise Distillation (CALD)\napproach that jointly converts a transformer model to a linear time substitute\nand fine-tunes it to a target task. We also compare several means to guide the\nfine-tuning to optimally retain the desired inference capability from the\noriginal model. The methods differ in their use of the target model and the\ntrajectory of the parameters. In a series of empirical studies on language\nprocessing, language modeling, and speech processing, we show that CALD can\neffectively recover the result of the original model, and that the guiding\nstrategy contributes to the result. Some reasons for the variation are\nsuggested.\n","authors":["Mutian He","Philip N. Garner"],"pdf_url":"https://arxiv.org/pdf/2410.06846v4.pdf","comment":"18 pages, 5 figures; ICLR 2025 camera ready. Code:\n  https://github.com/idiap/linearize-distill-pretrained-transformers"},{"id":"http://arxiv.org/abs/2503.10512v1","updated":"2025-03-13T16:16:23Z","published":"2025-03-13T16:16:23Z","title":"Conformal Prediction Sets for Deep Generative Models via Reduction to\n  Conformal Regression","summary":"  We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods.\n","authors":["Hooman Shahrokhi","Devjeet Raj Roy","Yan Yan","Venera Arnaoudova","Janaradhan Rao Doppa"],"pdf_url":"https://arxiv.org/pdf/2503.10512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v2","updated":"2025-03-13T16:16:12Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2411.06635v3","updated":"2025-03-13T16:15:37Z","published":"2024-11-11T00:10:48Z","title":"scMEDAL for the interpretable analysis of single-cell transcriptomics\n  data with batch effect visualization using a deep mixed effects autoencoder","summary":"  scRNA-seq data has the potential to provide new insights into cellular\nheterogeneity and data acquisition; however, a major challenge is unraveling\nconfounding from technical and biological batch effects. Existing batch\ncorrection algorithms suppress and discard these effects, rather than\nquantifying and modeling them. Here, we present scMEDAL, a framework for\nsingle-cell Mixed Effects Deep Autoencoder Learning, which separately models\nbatch-invariant and batch-specific effects using two complementary autoencoder\nnetworks. One network is trained through adversarial learning to capture a\nbatch-invariant representation, while a Bayesian autoencoder learns a\nbatch-specific representation. Comprehensive evaluations spanning conditions\n(e.g., autism, leukemia, and cardiovascular), cell types, and technical and\nbiological effects demonstrate that scMEDAL suppresses batch effects while\nmodeling batch-specific variation, enhancing accuracy and interpretability.\nUnlike prior approaches, the framework's fixed- and random-effects autoencoders\nenable retrospective analyses, including predicting a cell's expression as if\nit had been acquired in a different batch via genomap projections at the\ncellular level, revealing the impact of biological (e.g., diagnosis) and\ntechnical (e.g., acquisition) effects. By combining scMEDAL's batch-agnostic\nand batch-specific latent spaces, it enables more accurate predictions of\ndisease status, donor group, and cell type, making scMEDAL a valuable framework\nfor gaining deeper insight into data acquisition and cellular heterogeneity.\n","authors":["Aixa X. Andrade","Son Nguyen","Albert Montillo"],"pdf_url":"https://arxiv.org/pdf/2411.06635v3.pdf","comment":"Main manuscript: 28 pages, including 8 figures and 1 table.\n  Supplemental material: 19 pages"},{"id":"http://arxiv.org/abs/2503.10510v1","updated":"2025-03-13T16:14:08Z","published":"2025-03-13T16:14:08Z","title":"Extreme Learning Machines for Attention-based Multiple Instance Learning\n  in Whole-Slide Image Classification","summary":"  Whole-slide image classification represents a key challenge in computational\npathology and medicine. Attention-based multiple instance learning (MIL) has\nemerged as an effective approach for this problem. However, the effect of\nattention mechanism architecture on model performance is not well-documented\nfor biomedical imagery. In this work, we compare different methods and\nimplementations of MIL, including deep learning variants. We introduce a new\nmethod using higher-dimensional feature spaces for deep MIL. We also develop a\nnovel algorithm for whole-slide image classification where extreme machine\nlearning is combined with attention-based MIL to improve sensitivity and reduce\ntraining complexity. We apply our algorithms to the problem of detecting\ncirculating rare cells (CRCs), such as erythroblasts, in peripheral blood. Our\nresults indicate that nonlinearities play a key role in the classification, as\nremoving them leads to a sharp decrease in stability in addition to a decrease\nin average area under the curve (AUC) of over 4%. We also demonstrate a\nconsiderable increase in robustness of the model with improvements of over 10%\nin average AUC when higher-dimensional feature spaces are leveraged. In\naddition, we show that extreme learning machines can offer clear improvements\nin terms of training efficiency by reducing the number of trained parameters by\na factor of 5 whilst still maintaining the average AUC to within 1.5% of the\ndeep MIL model. Finally, we discuss options of enriching the classical\ncomputing framework with quantum algorithms in the future. This work can thus\nhelp pave the way towards more accurate and efficient single-cell diagnostics,\none of the building blocks of precision medicine.\n","authors":["Rajiv Krishnakumar","Julien Baglio","Frederik F. Flöther","Christian Ruiz","Stefan Habringer","Nicole H. Romano"],"pdf_url":"https://arxiv.org/pdf/2503.10510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10509v1","updated":"2025-03-13T16:10:14Z","published":"2025-03-13T16:10:14Z","title":"SySLLM: Generating Synthesized Policy Summaries for Reinforcement\n  Learning Agents Using Large Language Models","summary":"  Policies generated by Reinforcement Learning (RL) algorithms can be difficult\nto describe to users, as they result from the interplay between complex reward\nstructures and neural network-based representations. This combination often\nleads to unpredictable behaviors, making policies challenging to analyze and\nposing significant obstacles to fostering human trust in real-world\napplications. Global policy summarization methods aim to describe agent\nbehavior through a demonstration of actions in a subset of world-states.\nHowever, users can only watch a limited number of demonstrations, restricting\ntheir understanding of policies. Moreover, those methods overly rely on user\ninterpretation, as they do not synthesize observations into coherent patterns.\nIn this work, we present SySLLM (Synthesized Summary using LLMs), a novel\nmethod that employs synthesis summarization, utilizing large language models'\n(LLMs) extensive world knowledge and ability to capture patterns, to generate\ntextual summaries of policies. Specifically, an expert evaluation demonstrates\nthat the proposed approach generates summaries that capture the main insights\ngenerated by experts while not resulting in significant hallucinations.\nAdditionally, a user study shows that SySLLM summaries are preferred over\ndemonstration-based policy summaries and match or surpass their performance in\nobjective agent identification tasks.\n","authors":["Sahar Admoni","Omer Ben-Porat","Ofra Amir"],"pdf_url":"https://arxiv.org/pdf/2503.10509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06192v9","updated":"2025-03-13T16:06:02Z","published":"2023-06-09T18:45:15Z","title":"Confidence-Controlled Exploration: Efficient Sparse-Reward Policy\n  Learning for Robot Navigation","summary":"  Reinforcement learning (RL) is a promising approach for robotic navigation,\nallowing robots to learn through trial and error. However, real-world robotic\ntasks often suffer from sparse rewards, leading to inefficient exploration and\nsuboptimal policies due to sample inefficiency of RL. In this work, we\nintroduce Confidence-Controlled Exploration (CCE), a novel method that improves\nsample efficiency in RL-based robotic navigation without modifying the reward\nfunction. Unlike existing approaches, such as entropy regularization and reward\nshaping, which can introduce instability by altering rewards, CCE dynamically\nadjusts trajectory length based on policy entropy. Specifically, it shortens\ntrajectories when uncertainty is high to enhance exploration and extends them\nwhen confidence is high to prioritize exploitation. CCE is a principled and\npractical solution inspired by a theoretical connection between policy entropy\nand gradient estimation. It integrates seamlessly with on-policy and off-policy\nRL methods and requires minimal modifications. We validate CCE across\nREINFORCE, PPO, and SAC in both simulated and real-world navigation tasks. CCE\noutperforms fixed-trajectory and entropy-regularized baselines, achieving an\n18\\% higher success rate, 20-38\\% shorter paths, and 9.32\\% lower elevation\ncosts under a fixed training sample budget. Finally, we deploy CCE on a\nClearpath Husky robot, demonstrating its effectiveness in complex outdoor\nenvironments.\n","authors":["Bhrij Patel","Kasun Weerakoon","Wesley A. Suttle","Alec Koppel","Brian M. Sadler","Tianyi Zhou","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2306.06192v9.pdf","comment":"10 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.10503v1","updated":"2025-03-13T16:05:56Z","published":"2025-03-13T16:05:56Z","title":"Sample Compression for Continual Learning","summary":"  Continual learning algorithms aim to learn from a sequence of tasks, making\nthe training distribution non-stationary. The majority of existing continual\nlearning approaches in the literature rely on heuristics and do not provide\nlearning guarantees for the continual learning setup. In this paper, we present\na new method called 'Continual Pick-to-Learn' (CoP2L), which is able to retain\nthe most representative samples for each task in an efficient way. The\nalgorithm is adapted from the Pick-to-Learn algorithm, rooted in the sample\ncompression theory. This allows us to provide high-confidence upper bounds on\nthe generalization loss of the learned predictors, numerically computable after\nevery update of the learned model. We also empirically show on several standard\ncontinual learning benchmarks that our algorithm is able to outperform standard\nexperience replay, significantly mitigating catastrophic forgetting.\n","authors":["Jacob Comeau","Mathieu Bazinet","Pascal Germain","Cem Subakan"],"pdf_url":"https://arxiv.org/pdf/2503.10503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03355v2","updated":"2025-03-13T16:01:32Z","published":"2025-03-05T10:37:51Z","title":"Video Super-Resolution: All You Need is a Video Diffusion Model","summary":"  We present a generic video super-resolution algorithm in this paper, based on\nthe Diffusion Posterior Sampling framework with an unconditional video\ngeneration model in latent space. The video generation model, a diffusion\ntransformer, functions as a space-time model. We argue that a powerful model,\nwhich learns the physics of the real world, can easily handle various kinds of\nmotion patterns as prior knowledge, thus eliminating the need for explicit\nestimation of optical flows or motion parameters for pixel alignment.\nFurthermore, a single instance of the proposed video diffusion transformer\nmodel can adapt to different sampling conditions without re-training. Empirical\nresults on synthetic and real-world datasets demonstrate that our method has\nstrong capabilities to address video super-resolution challenges.\n","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"pdf_url":"https://arxiv.org/pdf/2503.03355v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10496v1","updated":"2025-03-13T15:59:03Z","published":"2025-03-13T15:59:03Z","title":"Explainable Bayesian deep learning through input-skip Latent Binary\n  Bayesian Neural Networks","summary":"  Modeling natural phenomena with artificial neural networks (ANNs) often\nprovides highly accurate predictions. However, ANNs often suffer from\nover-parameterization, complicating interpretation and raising uncertainty\nissues. Bayesian neural networks (BNNs) address the latter by representing\nweights as probability distributions, allowing for predictive uncertainty\nevaluation. Latent binary Bayesian neural networks (LBBNNs) further handle\nstructural uncertainty and sparsify models by removing redundant weights. This\narticle advances LBBNNs by enabling covariates to skip to any succeeding layer\nor be excluded, simplifying networks and clarifying input impacts on\npredictions. Ultimately, a linear model or even a constant can be found to be\noptimal for a specific problem at hand. Furthermore, the input-skip LBBNN\napproach reduces network density significantly compared to standard LBBNNs,\nachieving over 99% reduction for small networks and over 99.9% for larger ones,\nwhile still maintaining high predictive accuracy and uncertainty measurement.\nFor example, on MNIST, we reached 97% accuracy and great calibration with just\n935 weights, reaching state-of-the-art for compression of neural networks.\nFurthermore, the proposed method accurately identifies the true covariates and\nadjusts for system non-linearity. The main contribution is the introduction of\nactive paths, enhancing directly designed global and local explanations within\nthe LBBNN framework, that have theoretical guarantees and do not require post\nhoc external tools for explanations.\n","authors":["Eirik Høyheim","Lars Skaaret-Lund","Solve Sæbø","Aliaksandr Hubin"],"pdf_url":"https://arxiv.org/pdf/2503.10496v1.pdf","comment":"44 pages, 19 tables, 25 figures. Code available at\n  https://github.com/eirihoyh/ISLaB-LBBNN"},{"id":"http://arxiv.org/abs/2503.10492v1","updated":"2025-03-13T15:56:58Z","published":"2025-03-13T15:56:58Z","title":"Meta-learning characteristics and dynamics of quantum systems","summary":"  While machine learning holds great promise for quantum technologies, most\ncurrent methods focus on predicting or controlling a specific quantum system.\nMeta-learning approaches, however, can adapt to new systems for which little\ndata is available, by leveraging knowledge obtained from previous data\nassociated with similar systems. In this paper, we meta-learn dynamics and\ncharacteristics of closed and open two-level systems, as well as the Heisenberg\nmodel. Based on experimental data of a Loss-DiVincenzo spin-qubit hosted in a\nGe/Si core/shell nanowire for different gate voltage configurations, we predict\nqubit characteristics i.e. $g$-factor and Rabi frequency using meta-learning.\nThe algorithm we introduce improves upon previous state-of-the-art\nmeta-learning methods for physics-based systems by introducing novel techniques\nsuch as adaptive learning rates and a global optimizer for improved robustness\nand increased computational efficiency. We benchmark our method against other\nmeta-learning methods, a vanilla transformer, and a multilayer perceptron, and\ndemonstrate improved performance.\n","authors":["Lucas Schorling","Pranav Vaidhyanathan","Jonas Schuff","Miguel J. Carballido","Dominik Zumbühl","Gerard Milburn","Florian Marquardt","Jakob Foerster","Michael A. Osborne","Natalia Ares"],"pdf_url":"https://arxiv.org/pdf/2503.10492v1.pdf","comment":"6+1 pages, 4 figures. L. Schorling and P. Vaidhyanathan contributed\n  equally to this work"},{"id":"http://arxiv.org/abs/2503.10489v1","updated":"2025-03-13T15:55:01Z","published":"2025-03-13T15:55:01Z","title":"Representation Learning, Large-Scale 3D Molecular Pretraining, Molecular\n  Property","summary":"  Molecular pretrained representations (MPR) has emerged as a powerful approach\nfor addressing the challenge of limited supervised data in applications such as\ndrug discovery and material design. While early MPR methods relied on 1D\nsequences and 2D graphs, recent advancements have incorporated 3D\nconformational information to capture rich atomic interactions. However, these\nprior models treat molecules merely as discrete atom sets, overlooking the\nspace surrounding them. We argue from a physical perspective that only modeling\nthese discrete points is insufficient. We first present a simple yet insightful\nobservation: naively adding randomly sampled virtual points beyond atoms can\nsurprisingly enhance MPR performance. In light of this, we propose a principled\nframework that incorporates the entire 3D space spanned by molecules. We\nimplement the framework via a novel Transformer-based architecture, dubbed\nSpaceFormer, with three key components: (1) grid-based space discretization;\n(2) grid sampling/merging; and (3) efficient 3D positional encoding. Extensive\nexperiments show that SpaceFormer significantly outperforms previous 3D MPR\nmodels across various downstream tasks with limited data, validating the\nbenefit of leveraging the additional 3D space beyond atoms in MPR models.\n","authors":["Shuqi Lu","Xiaohong Ji","Bohang Zhang","Lin Yao","Siyuan Liu","Zhifeng Gao","Linfeng Zhang","Guolin Ke"],"pdf_url":"https://arxiv.org/pdf/2503.10489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10488v1","updated":"2025-03-13T15:54:45Z","published":"2025-03-13T15:54:45Z","title":"Streaming Generation of Co-Speech Gestures via Accelerated Rolling\n  Diffusion","summary":"  Generating co-speech gestures in real time requires both temporal coherence\nand efficient sampling. We introduce Accelerated Rolling Diffusion, a novel\nframework for streaming gesture generation that extends rolling diffusion\nmodels with structured progressive noise scheduling, enabling seamless\nlong-sequence motion synthesis while preserving realism and diversity. We\nfurther propose Rolling Diffusion Ladder Acceleration (RDLA), a new approach\nthat restructures the noise schedule into a stepwise ladder, allowing multiple\nframes to be denoised simultaneously. This significantly improves sampling\nefficiency while maintaining motion consistency, achieving up to a 2x speedup\nwith high visual fidelity and temporal coherence. We evaluate our approach on\nZEGGS and BEAT, strong benchmarks for real-world applicability. Our framework\nis universally applicable to any diffusion-based gesture generation model,\ntransforming it into a streaming approach. Applied to three state-of-the-art\nmethods, it consistently outperforms them, demonstrating its effectiveness as a\ngeneralizable and efficient solution for real-time, high-fidelity co-speech\ngesture synthesis.\n","authors":["Evgeniia Vu","Andrei Boiarov","Dmitry Vetrov"],"pdf_url":"https://arxiv.org/pdf/2503.10488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13022v2","updated":"2025-03-13T15:54:28Z","published":"2024-11-20T03:53:41Z","title":"Fast MRI for All: Bridging Equity Gaps via Training without Raw Data\n  Access","summary":"  Physics-driven deep learning (PD-DL) approaches have become popular for\nimproved reconstruction of fast magnetic resonance imaging (MRI) scans. Though\nPD-DL offers higher acceleration rates than existing clinical fast MRI\ntechniques, their use has been limited outside specialized MRI centers. A key\nchallenge is generalization to underrepresented pathologies or populations,\nnoted in multiple studies, with fine-tuning on target populations suggested for\nimprovement. However, current approaches for PD-DL training require access to\nraw k-space measurements, which is typically only available at specialized MRI\ncenters that have research agreements for such data access. This is especially\nan issue for rural and underserved areas, where commercial MRI scanners only\nprovide access to a final reconstructed image. To tackle these challenges, we\npropose Compressibility-inspired Unsupervised Learning via Parallel Imaging\nFidelity (CUPID) for high-quality PD-DL training using only routine clinical\nreconstructed images exported from an MRI scanner. CUPID evaluates output\nquality with a compressibility-based approach while ensuring that the output\nstays consistent with the clinical parallel imaging reconstruction through\nwell-designed perturbations. Our results show CUPID achieves similar quality to\nestablished PD-DL training that requires k-space data while outperforming\ncompressed sensing (CS) and diffusion-based generative methods. We further\ndemonstrate its effectiveness in a zero-shot training setup for retrospectively\nand prospectively sub-sampled acquisitions, attesting to its minimal training\nburden. As an approach that radically deviates from existing strategies, CUPID\npresents an opportunity to provide equitable access to fast MRI for underserved\npopulations in an attempt to reduce the inequalities associated with this\nexpensive imaging modality.\n","authors":["Yaşar Utku Alçalar","Merve Gülle","Mehmet Akçakaya"],"pdf_url":"https://arxiv.org/pdf/2411.13022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04692v2","updated":"2025-03-13T15:52:50Z","published":"2024-10-07T02:12:42Z","title":"A Clifford Algebraic Approach to E(n)-Equivariant High-order Graph\n  Neural Networks","summary":"  Designing neural network architectures that can handle data symmetry is\ncrucial. This is especially important for geometric graphs whose properties are\nequivariance under Euclidean transformations. Current equivariant graph neural\nnetworks (EGNNs), particularly those using message passing, have a limitation\nin expressive power. Recent high-order graph neural networks can overcome this\nlimitation, yet they lack equivariance properties, representing a notable\ndrawback in certain applications in chemistry and physical sciences. In this\npaper, we introduce the Clifford Group Equivariant Graph Neural Networks\n(CG-EGNNs), a novel EGNN that enhances high-order message passing by\nintegrating high-order local structures in the context of Clifford algebras. As\na key benefit of using Clifford algebras, CG-EGNN can learn functions that\ncapture equivariance from positional features. By adopting the high-order\nmessage passing mechanism, CG-EGNN gains richer information from neighbors,\nthus improving model performance. Furthermore, we establish the universality\nproperty of the $k$-hop message passing framework, showcasing greater\nexpressive power of CG-EGNNs with additional $k$-hop message passing mechanism.\nWe empirically validate that CG-EGNNs outperform previous methods on various\nbenchmarks including n-body, CMU motion capture, and MD17, highlighting their\neffectiveness in geometric deep learning.\n","authors":["Viet-Hoang Tran","Thieu N. Vo","Tho Tran Huu","Tan Minh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.04692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10474v1","updated":"2025-03-13T15:45:13Z","published":"2025-03-13T15:45:13Z","title":"Applying Tabular Deep Learning Models to Estimate Crash Injury Types of\n  Young Motorcyclists","summary":"  Young motorcyclists, particularly those aged 15 to 24 years old, face a\nheightened risk of severe crashes due to factors such as speeding, traffic\nviolations, and helmet usage. This study aims to identify key factors\ninfluencing crash severity by analyzing 10,726 young motorcyclist crashes in\nTexas from 2017 to 2022. Two advanced tabular deep learning models, ARMNet and\nMambaNet, were employed, using an advanced resampling technique to address\nclass imbalance. The models were trained to classify crashes into three\nseverity levels, Fatal or Severe, Moderate or Minor, and No Injury. ARMNet\nachieved an accuracy of 87 percent, outperforming 86 percent of Mambanet, with\nboth models excelling in predicting severe and no injury crashes while facing\nchallenges in moderate crash classification. Key findings highlight the\nsignificant influence of demographic, environmental, and behavioral factors on\ncrash outcomes. The study underscores the need for targeted interventions,\nincluding stricter helmet enforcement and educational programs customized to\nyoung motorcyclists. These insights provide valuable guidance for policymakers\nin developing evidence-based strategies to enhance motorcyclist safety and\nreduce crash severity.\n","authors":["Shriyank Somvanshi","Anannya Ghosh Tusti","Rohit Chakraborty","Subasish Das"],"pdf_url":"https://arxiv.org/pdf/2503.10474v1.pdf","comment":"6 pages, 6 figures, accepted at IEEE CAI 2025"},{"id":"http://arxiv.org/abs/2503.10469v1","updated":"2025-03-13T15:42:37Z","published":"2025-03-13T15:42:37Z","title":"Deep Learning based discovery of Integrable Systems","summary":"  We introduce a novel machine learning based framework for discovering\nintegrable models. Our approach first employs a synchronized ensemble of neural\nnetworks to find high-precision numerical solution to the Yang-Baxter equation\nwithin a specified class. Then, using an auxiliary system of algebraic\nequations, [Q_2, Q_3] = 0, and the numerical value of the Hamiltonian obtained\nvia deep learning as a seed, we reconstruct the entire Hamiltonian family,\nforming an algebraic variety. We illustrate our presentation with three- and\nfour-dimensional spin chains of difference form with local interactions.\nRemarkably, all discovered Hamiltonian families form rational varieties.\n","authors":["Shailesh Lal","Suvajit Majumder","Evgeny Sobko"],"pdf_url":"https://arxiv.org/pdf/2503.10469v1.pdf","comment":"11 pages, 2 column text, 3 figures, Mathematica notebook with example\n  Hamiltonians"},{"id":"http://arxiv.org/abs/2503.10468v1","updated":"2025-03-13T15:41:56Z","published":"2025-03-13T15:41:56Z","title":"OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary","summary":"  Out-of-distribution (OOD) detection remains challenging for deep learning\nmodels, particularly when test-time OOD samples differ significantly from\ntraining outliers. We propose OODD, a novel test-time OOD detection method that\ndynamically maintains and updates an OOD dictionary without fine-tuning. Our\napproach leverages a priority queue-based dictionary that accumulates\nrepresentative OOD features during testing, combined with an informative inlier\nsampling strategy for in-distribution (ID) samples. To ensure stable\nperformance during early testing, we propose a dual OOD stabilization mechanism\nthat leverages strategically generated outliers derived from ID data. To our\nbest knowledge, extensive experiments on the OpenOOD benchmark demonstrate that\nOODD significantly outperforms existing methods, achieving a 26.0% improvement\nin FPR95 on CIFAR-100 Far OOD detection compared to the state-of-the-art\napproach. Furthermore, we present an optimized variant of the KNN-based OOD\ndetection framework that achieves a 3x speedup while maintaining detection\nperformance.\n","authors":["Yifeng Yang","Lin Zhu","Zewen Sun","Hengyu Liu","Qinying Gu","Nanyang Ye"],"pdf_url":"https://arxiv.org/pdf/2503.10468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10466v1","updated":"2025-03-13T15:38:25Z","published":"2025-03-13T15:38:25Z","title":"SortingEnv: An Extendable RL-Environment for an Industrial Sorting\n  Process","summary":"  We present a novel reinforcement learning (RL) environment designed to both\noptimize industrial sorting systems and study agent behavior in evolving\nspaces. In simulating material flow within a sorting process our environment\nfollows the idea of a digital twin, with operational parameters like belt speed\nand occupancy level. To reflect real-world challenges, we integrate common\nupgrades to industrial setups, like new sensors or advanced machinery. It thus\nincludes two variants: a basic version focusing on discrete belt speed\nadjustments and an advanced version introducing multiple sorting modes and\nenhanced material composition observations. We detail the observation spaces,\nstate update mechanisms, and reward functions for both environments. We further\nevaluate the efficiency of common RL algorithms like Proximal Policy\nOptimization (PPO), Deep-Q-Networks (DQN), and Advantage Actor Critic (A2C) in\ncomparison to a classical rule-based agent (RBA). This framework not only aids\nin optimizing industrial processes but also provides a foundation for studying\nagent behavior and transferability in evolving environments, offering insights\ninto model performance and practical implications for real-world RL\napplications.\n","authors":["Tom Maus","Nico Zengeler","Tobias Glasmachers"],"pdf_url":"https://arxiv.org/pdf/2503.10466v1.pdf","comment":"Presented at the 12th International Conference on Industrial\n  Engineering and Applications (ICIEA-EU), Munich, 2025. This article has been\n  submitted to AIP Conference Proceedings. After it is published, it will be\n  available in the AIP Digital Library"},{"id":"http://arxiv.org/abs/2409.11697v3","updated":"2025-03-13T15:36:01Z","published":"2024-09-18T04:36:05Z","title":"Monomial Matrix Group Equivariant Neural Functional Networks","summary":"  Neural functional networks (NFNs) have recently gained significant attention\ndue to their diverse applications, ranging from predicting network\ngeneralization and network editing to classifying implicit neural\nrepresentation. Previous NFN designs often depend on permutation symmetries in\nneural networks' weights, which traditionally arise from the unordered\narrangement of neurons in hidden layers. However, these designs do not take\ninto account the weight scaling symmetries of $\\ReLU$ networks, and the weight\nsign flipping symmetries of $\\sin$ or $\\Tanh$ networks. In this paper, we\nextend the study of the group action on the network weights from the group of\npermutation matrices to the group of monomial matrices by incorporating\nscaling/sign-flipping symmetries. Particularly, we encode these\nscaling/sign-flipping symmetries by designing our corresponding equivariant and\ninvariant layers. We name our new family of NFNs the Monomial Matrix Group\nEquivariant Neural Functional Networks (Monomial-NFN). Because of the expansion\nof the symmetries, Monomial-NFN has much fewer independent trainable parameters\ncompared to the baseline NFNs in the literature, thus enhancing the model's\nefficiency. Moreover, for fully connected and convolutional neural networks, we\ntheoretically prove that all groups that leave these networks invariant while\nacting on their weight spaces are some subgroups of the monomial matrix group.\nWe provide empirical evidence to demonstrate the advantages of our model over\nexisting baselines, achieving competitive performance and efficiency.\n","authors":["Viet-Hoang Tran","Thieu N. Vo","Tho H. Tran","An T. Nguyen","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2409.11697v3.pdf","comment":"10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/MathematicalAI-NUS/Monomial-NFN"},{"id":"http://arxiv.org/abs/2503.10460v1","updated":"2025-03-13T15:29:22Z","published":"2025-03-13T15:29:22Z","title":"Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and\n  Beyond","summary":"  This paper presents our work on the Light-R1 series, with models, data, and\ncode all released.\n  We first focus on training long COT models from scratch, specifically\nstarting from models initially lacking long COT capabilities. Using a\ncurriculum training recipe consisting of two-stage SFT and semi-on-policy DPO,\nwe train our model Light-R1-32B from Qwen2.5-32B-Instruct, resulting in\nsuperior math performance compared to DeepSeek-R1-Distill-Qwen-32B. Despite\nbeing trained exclusively on math data, Light-R1-32B shows strong\ngeneralization across other domains. In the subsequent phase of this work, we\nhighlight the significant benefit of the 3k dataset constructed for the second\nSFT stage on enhancing other models. By fine-tuning DeepSeek-R1-Distilled\nmodels using this dataset, we obtain new SOTA models in 7B and 14B, while the\n32B model, Light-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.\n  Furthermore, we extend our work by applying reinforcement learning,\nspecifically GRPO, on long-COT models to further improve reasoning performance.\nWe successfully train our final Light-R1-14B-DS with RL, achieving SOTA\nperformance among 14B parameter models in math. With AIME24 & 25 scores of 74.0\nand 60.2 respectively, Light-R1-14B-DS surpasses even many 32B models and\nDeepSeek-R1-Distill-Llama-70B. Its RL training also exhibits well expected\nbehavior, showing simultaneous increase in response length and reward score.\n  The Light-R1 series of work validates training long-COT models from scratch,\nshowcases the art in SFT data and releases SOTA models from RL.\n","authors":["Liang Wen","Yunke Cai","Fenrui Xiao","Xin He","Qi An","Zhenyu Duan","Yimin Du","Junchen Liu","Lifu Tang","Xiaowei Lv","Haosheng Zou","Yongchao Deng","Shousheng Jia","Xiangzheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10460v1.pdf","comment":"all release at https://github.com/Qihoo360/Light-R1"},{"id":"http://arxiv.org/abs/2503.10457v1","updated":"2025-03-13T15:25:23Z","published":"2025-03-13T15:25:23Z","title":"Sentiment Analysis in SemEval: A Review of Sentiment Identification\n  Approaches","summary":"  Social media platforms are becoming the foundations of social interactions\nincluding messaging and opinion expression. In this regard, Sentiment Analysis\ntechniques focus on providing solutions to ensure the retrieval and analysis of\ngenerated data including sentiments, emotions, and discussed topics.\nInternational competitions such as the International Workshop on Semantic\nEvaluation (SemEval) have attracted many researchers and practitioners with a\nspecial research interest in building sentiment analysis systems. In our work,\nwe study top-ranking systems for each SemEval edition during the 2013-2021\nperiod, a total of 658 teams participated in these editions with increasing\ninterest over years. We analyze the proposed systems marking the evolution of\nresearch trends with a focus on the main components of sentiment analysis\nsystems including data acquisition, preprocessing, and classification. Our\nstudy shows an active use of preprocessing techniques, an evolution of features\nengineering and word representation from lexicon-based approaches to word\nembeddings, and the dominance of neural networks and transformers over the\nclassification phase fostering the use of ready-to-use models. Moreover, we\nprovide researchers with insights based on experimented systems which will\nallow rapid prototyping of new systems and help practitioners build for future\nSemEval editions.\n","authors":["Bousselham El Haddaoui","Raddouane Chiheb","Rdouan Faizi","Abdellatif El Afia"],"pdf_url":"https://arxiv.org/pdf/2503.10457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03363v2","updated":"2025-03-13T15:10:10Z","published":"2023-07-07T03:07:26Z","title":"Class-wise Federated Unlearning: Harnessing Active Forgetting with\n  Teacher-Student Memory Generation","summary":"  Privacy concerns associated with machine learning models have driven research\ninto machine unlearning, which aims to erase the memory of specific target\ntraining data from already trained models. This issue also arises in federated\nlearning, creating the need to address the federated unlearning problem.\nHowever, federated unlearning remains a challenging task. On the one hand,\ncurrent research primarily focuses on unlearning all data from a client,\noverlooking more fine-grained unlearning targets, e.g., class-wise and\nsample-wise removal. On the other hand, existing methods suffer from imprecise\nestimation of data influence and impose significant computational or storage\nburden. To address these issues, we propose a neuro-inspired federated\nunlearning framework based on active forgetting, which is independent of model\narchitectures and suitable for fine-grained unlearning targets. Our framework\ndistinguishes itself from existing methods by utilizing new memories to\noverwrite old ones. These new memories are generated through teacher-student\nlearning. We further utilize refined elastic weight consolidation to mitigate\ncatastrophic forgetting of non-target data. Extensive experiments on benchmark\ndatasets demonstrate the efficiency and effectiveness of our method, achieving\nsatisfactory unlearning completeness against backdoor attacks.\n","authors":["Yuyuan Li","Jiaming Zhang","Yixiu Liu","Chaochao Chen"],"pdf_url":"https://arxiv.org/pdf/2307.03363v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10440v1","updated":"2025-03-13T15:04:27Z","published":"2025-03-13T15:04:27Z","title":"Learning Disease State from Noisy Ordinal Disease Progression Labels","summary":"  Learning from noisy ordinal labels is a key challenge in medical imaging. In\nthis work, we ask whether ordinal disease progression labels (better, worse, or\nstable) can be used to learn a representation allowing to classify disease\nstate. For neovascular age-related macular degeneration (nAMD), we cast the\nproblem of modeling disease progression between medical visits as a\nclassification task with ordinal ranks. To enhance generalization, we tailor\nour model to the problem setting by (1) independent image encoding, (2)\nantisymmetric logit space equivariance, and (3) ordinal scale awareness. In\naddition, we address label noise by learning an uncertainty estimate for loss\nre-weighting. Our approach learns an interpretable disease representation\nenabling strong few-shot performance for the related task of nAMD activity\nclassification from single images, despite being trained only on image pairs\nwith ordinal disease progression labels.\n","authors":["Gustav Schmidt","Holger Heidrich","Philipp Berens","Sarah Müller"],"pdf_url":"https://arxiv.org/pdf/2503.10440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10434v1","updated":"2025-03-13T14:56:17Z","published":"2025-03-13T14:56:17Z","title":"Finetuning Generative Trajectory Model with Reinforcement Learning from\n  Human Feedback","summary":"  Generating human-like and adaptive trajectories is essential for autonomous\ndriving in dynamic environments. While generative models have shown promise in\nsynthesizing feasible trajectories, they often fail to capture the nuanced\nvariability of human driving styles due to dataset biases and distributional\nshifts. To address this, we introduce TrajHF, a human feedback-driven\nfinetuning framework for generative trajectory models, designed to align motion\nplanning with diverse driving preferences. TrajHF incorporates\nmulti-conditional denoiser and reinforcement learning with human feedback to\nrefine multi-modal trajectory generation beyond conventional imitation\nlearning. This enables better alignment with human driving preferences while\nmaintaining safety and feasibility constraints. TrajHF achieves PDMS of 93.95\non NavSim benchmark, significantly exceeding other methods. TrajHF sets a new\nparadigm for personalized and adaptable trajectory generation in autonomous\ndriving.\n","authors":["Derun Li","Jianwei Ren","Yue Wang","Xin Wen","Pengxiang Li","Leimeng Xu","Kun Zhan","Zhongpu Xia","Peng Jia","Xianpeng Lang","Ningyi Xu","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.10434v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.10432v1","updated":"2025-03-13T14:55:59Z","published":"2025-03-13T14:55:59Z","title":"BeamLLM: Vision-Empowered mmWave Beam Prediction with Large Language\n  Models","summary":"  In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave)\nbeam prediction framework leveraging large language models (LLMs) to address\nthe challenges of high training overhead and latency in mmWave communication\nsystems. By combining computer vision (CV) with LLMs' cross-modal reasoning\ncapabilities, the framework extracts user equipment (UE) positional features\nfrom RGB images and aligns visual-temporal features with LLMs' semantic space\nthrough reprogramming techniques. Evaluated on a realistic\nvehicle-to-infrastructure (V2I) scenario, the proposed method achieves 61.01%\ntop-1 accuracy and 97.39% top-3 accuracy in standard prediction tasks,\nsignificantly outperforming traditional deep learning models. In few-shot\nprediction scenarios, the performance degradation is limited to 12.56% (top-1)\nand 5.55% (top-3) from time sample 1 to 10, demonstrating superior prediction\ncapability.\n","authors":["Can Zheng","Jiguang He","Guofa Cai","Zitong Yu","Chung G. Kang"],"pdf_url":"https://arxiv.org/pdf/2503.10432v1.pdf","comment":"6 pages, 7 figures, conference"},{"id":"http://arxiv.org/abs/2503.10428v1","updated":"2025-03-13T14:50:33Z","published":"2025-03-13T14:50:33Z","title":"Langevin Monte-Carlo Provably Learns Depth Two Neural Nets at Any Size\n  and Data","summary":"  In this work, we will establish that the Langevin Monte-Carlo algorithm can\nlearn depth-2 neural nets of any size and for any data and we give\nnon-asymptotic convergence rates for it. We achieve this via showing that under\nTotal Variation distance and q-Renyi divergence, the iterates of Langevin Monte\nCarlo converge to the Gibbs distribution of Frobenius norm regularized losses\nfor any of these nets, when using smooth activations and in both classification\nand regression settings. Most critically, the amount of regularization needed\nfor our results is independent of the size of the net. The key observation of\nours is that two layer neural loss functions can always be regularized by a\nconstant amount such that they satisfy the Villani conditions, and thus their\nGibbs measures satisfy a Poincare inequality.\n","authors":["Dibyakanti Kumar","Samyak Jha","Anirbit Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2503.10428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10426v1","updated":"2025-03-13T14:49:30Z","published":"2025-03-13T14:49:30Z","title":"Improving Medical Waste Classification with Hybrid Capsule Networks","summary":"  The improper disposal and mismanagement of medical waste pose severe\nenvironmental and public health risks, contributing to greenhouse gas emissions\nand the spread of infectious diseases. Efficient and accurate medical waste\nclassification is crucial for mitigating these risks. We explore the\nintegration of capsule networks with a pretrained DenseNet model to improve\nmedical waste classification. To the best of our knowledge, capsule networks\nhave not yet been applied to this task, making this study the first to assess\ntheir effectiveness.\n  A diverse dataset of medical waste images collected from multiple public\nsources, is used to evaluate three model configurations: (1) a pretrained\nDenseNet model as a baseline, (2) a pretrained DenseNet with frozen layers\ncombined with a capsule network, and (3) a pretrained DenseNet with unfrozen\nlayers combined with a capsule network. Experimental results demonstrate that\nincorporating capsule networks improves classification performance, with F1\nscores increasing from 0.89 (baseline) to 0.92 (hybrid model with unfrozen\nlayers). This highlights the potential of capsule networks to address the\nspatial limitations of traditional convolutional models and improve\nclassification robustness.\n  While the capsule-enhanced model demonstrated improved classification\nperformance, direct comparisons with prior studies were challenging due to\ndifferences in dataset size and diversity. Previous studies relied on smaller,\ndomain-specific datasets, which inherently yielded higher accuracy. In\ncontrast, our study employs a significantly larger and more diverse dataset,\nleading to better generalization but introducing additional classification\nchallenges. This highlights the trade-off between dataset complexity and model\nperformance.\n","authors":["Bennet van den Broek","Javad Pourmostafa Roshan Sharami"],"pdf_url":"https://arxiv.org/pdf/2503.10426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17365v3","updated":"2025-03-13T14:48:27Z","published":"2024-04-26T12:30:32Z","title":"Similarity Equivariant Graph Neural Networks for Homogenization of\n  Metamaterials","summary":"  Soft, porous mechanical metamaterials exhibit pattern transformations that\nmay have important applications in soft robotics, sound reduction and\nbiomedicine. To design these innovative materials, it is important to be able\nto simulate them accurately and quickly, in order to tune their mechanical\nproperties. Since conventional simulations using the finite element method\nentail a high computational cost, in this article we aim to develop a machine\nlearning-based approach that scales favorably to serve as a surrogate model. To\nensure that the model is also able to handle various microstructures, including\nthose not encountered during training, we include the microstructure as part of\nthe network input. Therefore, we introduce a graph neural network that predicts\nglobal quantities (energy, stress stiffness) as well as the pattern\ntransformations that occur (the kinematics). To make our model as accurate and\ndata-efficient as possible, various symmetries are incorporated into the model.\nThe starting point is an E(n)-equivariant graph neural network (which respects\ntranslation, rotation and reflection) that has periodic boundary conditions\n(i.e., it is in-/equivariant with respect to the choice of RVE), is scale\nin-/equivariant, can simulate large deformations, and can predict scalars,\nvectors as well as second and fourth order tensors (specifically energy, stress\nand stiffness). The incorporation of scale equivariance makes the model\nequivariant with respect to the similarities group, of which the Euclidean\ngroup E(n) is a subgroup. We show that this network is more accurate and\ndata-efficient than graph neural networks with fewer symmetries. To create an\nefficient graph representation of the finite element discretization, we use\nonly the internal geometrical hole boundaries from the finite element mesh to\nachieve a better speed-up and scaling with the mesh size.\n","authors":["Fleur Hendriks","Vlado Menkovski","Martin Doškář","Marc G. D. Geers","Ondřej Rokoš"],"pdf_url":"https://arxiv.org/pdf/2404.17365v3.pdf","comment":"60 pages, 22 figures. Published in CMAME (Computer Methods in Applied\n  Mechanics and Engineering)"},{"id":"http://arxiv.org/abs/2503.10421v1","updated":"2025-03-13T14:42:44Z","published":"2025-03-13T14:42:44Z","title":"Towards Constraint-Based Adaptive Hypergraph Learning for Solving\n  Vehicle Routing: An End-to-End Solution","summary":"  The application of learning based methods to vehicle routing problems has\nemerged as a pivotal area of research in combinatorial optimization. These\nproblems are characterized by vast solution spaces and intricate constraints,\nmaking traditional approaches such as exact mathematical models or heuristic\nmethods prone to high computational overhead or reliant on the design of\ncomplex heuristic operators to achieve optimal or near optimal solutions.\nMeanwhile, although some recent learning-based methods can produce good\nperformance for VRP with straightforward constraint scenarios, they often fail\nto effectively handle hard constraints that are common in practice. This study\nintroduces a novel end-to-end framework that combines constraint-oriented\nhypergraphs with reinforcement learning to address vehicle routing problems. A\ncentral innovation of this work is the development of a constraint-oriented\ndynamic hyperedge reconstruction strategy within an encoder, which\nsignificantly enhances hypergraph representation learning. Additionally, the\ndecoder leverages a double-pointer attention mechanism to iteratively generate\nsolutions. The proposed model is trained by incorporating asynchronous\nparameter updates informed by hypergraph constraints and optimizing a dual loss\nfunction comprising constraint loss and policy gradient loss. The experiment\nresults on benchmark datasets demonstrate that the proposed approach not only\neliminates the need for sophisticated heuristic operators but also achieves\nsubstantial improvements in solution quality.\n","authors":["Zhenwei Wang","Ruibin Bai","Tiehua Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03636v2","updated":"2025-03-13T14:38:58Z","published":"2024-05-06T16:55:20Z","title":"The Federation Strikes Back: A Survey of Federated Learning Privacy\n  Attacks, Defenses, Applications, and Policy Landscape","summary":"  Deep learning has shown incredible potential across a wide array of tasks,\nand accompanied by this growth has been an insatiable appetite for data.\nHowever, a large amount of data needed for enabling deep learning is stored on\npersonal devices, and recent concerns on privacy have further highlighted\nchallenges for accessing such data. As a result, federated learning (FL) has\nemerged as an important privacy-preserving technology that enables\ncollaborative training of machine learning models without the need to send the\nraw, potentially sensitive, data to a central server. However, the fundamental\npremise that sending model updates to a server is privacy-preserving only holds\nif the updates cannot be \"reverse engineered\" to infer information about the\nprivate training data. It has been shown under a wide variety of settings that\nthis privacy premise does not hold. In this survey paper, we provide a\ncomprehensive literature review of the different privacy attacks and defense\nmethods in FL. We identify the current limitations of these attacks and\nhighlight the settings in which the privacy of ann FL client can be broken. We\nfurther dissect some of the successful industry applications of FL and draw\nlessons for future successful adoption. We survey the emerging landscape of\nprivacy regulation for FL and conclude with future directions for taking FL\ntoward the cherished goal of generating accurate models while preserving the\nprivacy of the data from its participants.\n","authors":["Joshua C. Zhao","Saurabh Bagchi","Salman Avestimehr","Kevin S. Chan","Somali Chaterji","Dimitris Dimitriadis","Jiacheng Li","Ninghui Li","Arash Nourian","Holger R. Roth"],"pdf_url":"https://arxiv.org/pdf/2405.03636v2.pdf","comment":"Accepted to ACM Computing Surveys; 35 pages"},{"id":"http://arxiv.org/abs/2503.10412v1","updated":"2025-03-13T14:35:47Z","published":"2025-03-13T14:35:47Z","title":"dFLMoE: Decentralized Federated Learning via Mixture of Experts for\n  Medical Data Analysis","summary":"  Federated learning has wide applications in the medical field. It enables\nknowledge sharing among different healthcare institutes while protecting\npatients' privacy. However, existing federated learning systems are typically\ncentralized, requiring clients to upload client-specific knowledge to a central\nserver for aggregation. This centralized approach would integrate the knowledge\nfrom each client into a centralized server, and the knowledge would be already\nundermined during the centralized integration before it reaches back to each\nclient. Besides, the centralized approach also creates a dependency on the\ncentral server, which may affect training stability if the server malfunctions\nor connections are unstable. To address these issues, we propose a\ndecentralized federated learning framework named dFLMoE. In our framework,\nclients directly exchange lightweight head models with each other. After\nexchanging, each client treats both local and received head models as\nindividual experts, and utilizes a client-specific Mixture of Experts (MoE)\napproach to make collective decisions. This design not only reduces the\nknowledge damage with client-specific aggregations but also removes the\ndependency on the central server to enhance the robustness of the framework. We\nvalidate our framework on multiple medical tasks, demonstrating that our method\nevidently outperforms state-of-the-art approaches under both model homogeneity\nand heterogeneity settings.\n","authors":["Luyuan Xie","Tianyu Luan","Wenyuan Cai","Guochen Yan","Zhaoyu Chen","Nan Xi","Yuejian Fang","Qingni Shen","Zhonghai Wu","Junsong Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.10412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10408v1","updated":"2025-03-13T14:32:30Z","published":"2025-03-13T14:32:30Z","title":"Understanding the Logical Capabilities of Large Language Models via\n  Out-of-Context Representation Learning","summary":"  We study the capabilities of Large Language Models (LLM) on binary relations,\na ubiquitous concept in math employed in most reasoning, math and logic\nbenchmarks. This work focuses on equality, inequality, and inclusion, along\nwith the properties they satisfy, such as ir/reflexivity, a/symmetry,\ntransitivity, and logical complexity (e.g., number of reasoning ``hops''). We\npropose an alternative to in-context learning that trains only the\nrepresentations of newly introduced tokens, namely out-of-context\nrepresentation learning. This method mitigates linguistic biases already\npresent in a model and, differently from in-context learning, does not rely on\nexternal information or illustrations. We argue out-of-context representation\nlearning as a better alternative to in-context learning and fine-tuning to\nevaluate the capabilities of LLMs on logic tasks that are the building blocks\nof more complex reasoning benchmarks.\n","authors":["Jonathan Shaki","Emanuele La Malfa","Michael Wooldridge","Sarit Kraus"],"pdf_url":"https://arxiv.org/pdf/2503.10408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10404v1","updated":"2025-03-13T14:30:17Z","published":"2025-03-13T14:30:17Z","title":"Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in\n  Neural Architecture Search","summary":"  Neural Architecture Search (NAS) has become an essential tool for designing\neffective and efficient neural networks. In this paper, we investigate the\ngeometric properties of neural architecture spaces commonly used in\ndifferentiable NAS methods, specifically NAS-Bench-201 and DARTS. By defining\nflatness metrics such as neighborhoods and loss barriers along paths in\narchitecture space, we reveal locality and flatness characteristics analogous\nto the well-known properties of neural network loss landscapes in weight space.\nIn particular, we find that highly accurate architectures cluster together in\nflat regions, while suboptimal architectures remain isolated, unveiling the\ndetailed geometrical structure of the architecture search landscape. Building\non these insights, we propose Architecture-Aware Minimization (A$^2$M), a novel\nanalytically derived algorithmic framework that explicitly biases, for the\nfirst time, the gradient of differentiable NAS methods towards flat minima in\narchitecture space. A$^2$M consistently improves generalization over\nstate-of-the-art DARTS-based algorithms on benchmark datasets including\nCIFAR-10, CIFAR-100, and ImageNet16-120, across both NAS-Bench-201 and DARTS\nsearch spaces. Notably, A$^2$M is able to increase the test accuracy, on\naverage across different differentiable NAS methods, by +3.60\\% on CIFAR-10,\n+4.60\\% on CIFAR-100, and +3.64\\% on ImageNet16-120, demonstrating its superior\neffectiveness in practice. A$^2$M can be easily integrated into existing\ndifferentiable NAS frameworks, offering a versatile tool for future research\nand applications in automated machine learning. We open-source our code at\nhttps://github.com/AI-Tech-Research-Lab/AsquaredM.\n","authors":["Matteo Gambella","Fabrizio Pittorino","Manuel Roveri"],"pdf_url":"https://arxiv.org/pdf/2503.10404v1.pdf","comment":"22 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.08210v2","updated":"2025-03-13T14:30:06Z","published":"2023-06-14T02:45:14Z","title":"Uncertainty-Aware Robust Learning on Noisy Graphs","summary":"  Graph neural networks (GNNs) have excelled in various graph learning tasks,\nparticularly node classification. However, their performance is often hampered\nby noisy measurements in real-world graphs, which can corrupt critical patterns\nin the data. To address this, we propose a novel uncertainty-aware graph\nlearning framework inspired by distributionally robust optimization.\nSpecifically, we use a graph neural network-based encoder to embed the node\nfeatures and find the optimal node embeddings by minimizing the worst-case risk\nthrough a minimax formulation. Such an uncertainty-aware learning process leads\nto improved node representations and a more robust graph predictive model that\neffectively mitigates the impact of uncertainty arising from data noise. Our\nexperimental results demonstrate superior predictive performance over baselines\nacross noisy scenarios.\n","authors":["Shuyi Chen","Kaize Ding","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.08210v2.pdf","comment":"ICASSP 2025 camera ready"},{"id":"http://arxiv.org/abs/2306.02766v5","updated":"2025-03-13T14:14:01Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"  We introduce networked communication to the mean-field game framework, in\nparticular to oracle-free settings where $N$ decentralised agents learn along a\nsingle, non-episodic run of the empirical system. We prove that our\narchitecture has sample guarantees bounded between those of the centralised-\nand independent-learning cases. We provide the order of the difference in these\nbounds in terms of network structure and number of communication rounds, and\nalso contribute a policy-update stability guarantee. We discuss how the sample\nguarantees of the three theoretical algorithms do not actually result in\npractical convergence. We therefore show that in practical settings where the\ntheoretical parameters are not observed (leading to poor estimation of the\nQ-function), our communication scheme considerably accelerates learning over\nthe independent case, often performing similarly to a centralised learner while\nremoving the restrictive assumption of the latter. We contribute further\npractical enhancements to all three theoretical algorithms, allowing us to\npresent their first empirical demonstrations. Our experiments confirm that we\ncan remove several of the theoretical assumptions of the algorithms, and\ndisplay the empirical convergence benefits brought by our new networked\ncommunication. We additionally show that our networked approach has significant\nadvantages over both alternatives in terms of robustness to update failures and\nto changes in population size.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2306.02766v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08918v2","updated":"2025-03-13T14:13:52Z","published":"2025-03-11T22:03:54Z","title":"Multilevel Generative Samplers for Investigating Critical Phenomena","summary":"  Investigating critical phenomena or phase transitions is of high interest in\nphysics and chemistry, for which Monte Carlo (MC) simulations, a crucial tool\nfor numerically analyzing macroscopic properties of given systems, are often\nhindered by an emerging divergence of correlation length -- known as scale\ninvariance at criticality (SIC) in the renormalization group theory. SIC causes\nthe system to behave the same at any length scale, from which many existing\nsampling methods suffer: long-range correlations cause critical slowing down in\nMarkov chain Monte Carlo (MCMC), and require intractably large receptive fields\nfor generative samplers. In this paper, we propose a Renormalization-informed\nGenerative Critical Sampler (RiGCS) -- a novel sampler specialized for\nnear-critical systems, where SIC is leveraged as an advantage rather than a\nnuisance. Specifically, RiGCS builds on MultiLevel Monte Carlo (MLMC) with Heat\nBath (HB) algorithms, which perform ancestral sampling from low-resolution to\nhigh-resolution lattice configurations with site-wise-independent conditional\nHB sampling. Although MLMC-HB is highly efficient under exact SIC, it suffers\nfrom a low acceptance rate under slight SIC violation. Notably, SIC violation\nalways occurs in finite-size systems, and may induce long-range and\nhigher-order interactions in the renormalized distributions, which are not\nconsidered by independent HB samplers. RiGCS enhances MLMC-HB by replacing a\npart of the conditional HB sampler with generative models that capture those\nresidual interactions and improve the sampling efficiency. Our experiments show\nthat the effective sample size of RiGCS is a few orders of magnitude higher\nthan state-of-the-art generative model baselines in sampling configurations for\n128x128 two-dimensional Ising systems.\n","authors":["Ankur Singha","Elia Cellini","Kim A. Nicoli","Karl Jansen","Stefan Kühn","Shinichi Nakajima"],"pdf_url":"https://arxiv.org/pdf/2503.08918v2.pdf","comment":"10 pages, 4 figures (main text); 13th International Conference on\n  Learning Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2503.10386v1","updated":"2025-03-13T14:04:04Z","published":"2025-03-13T14:04:04Z","title":"Multi-objective Good Arm Identification with Bandit Feedback","summary":"  We consider a good arm identification problem in a stochastic bandit setting\nwith multi-objectives, where each arm $i\\in[K]$ is associated with $M$\ndistributions $\\mathcal{D}_i^{(1)}, \\ldots, \\mathcal{D}_i^{(M)}$. For each\nround $t$, the player/algorithm pulls one arm $i_t$ and receives a vector\nfeedback, where each component $m$ is sampled according to\n$\\mathcal{D}_i^{(m)}$. The target is twofold, one is finding one arm whose\nmeans are larger than the predefined thresholds $\\xi_1,\\ldots,\\xi_M$ with a\nconfidence bound $\\delta$ and an accuracy rate $\\epsilon$ with a bounded sample\ncomplexity, the other is output $\\bot$ to indicate no such arm exists. We\npropose an algorithm with a sample complexity bound. When $M=1$ and $\\epsilon =\n0$, our bound is the same as the one given in the previous work when and novel\nbounds for $M > 1$. The proposed algorithm attains better numerical performance\nthan other baselines in the experiments on synthetic and real datasets.\n","authors":["Xuanke Jiang","Kohei Hatano","Eiji Takimoto"],"pdf_url":"https://arxiv.org/pdf/2503.10386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10382v1","updated":"2025-03-13T13:57:24Z","published":"2025-03-13T13:57:24Z","title":"Subgroup Performance Analysis in Hidden Stratifications","summary":"  Machine learning (ML) models may suffer from significant performance\ndisparities between patient groups. Identifying such disparities by monitoring\nperformance at a granular level is crucial for safely deploying ML to each\npatient. Traditional subgroup analysis based on metadata can expose performance\ndisparities only if the available metadata (e.g., patient sex) sufficiently\nreflects the main reasons for performance variability, which is not common.\nSubgroup discovery techniques that identify cohesive subgroups based on learned\nfeature representations appear as a potential solution: They could expose\nhidden stratifications and provide more granular subgroup performance reports.\nHowever, subgroup discovery is challenging to evaluate even as a standalone\ntask, as ground truth stratification labels do not exist in real data. Subgroup\ndiscovery has thus neither been applied nor evaluated for the application of\nsubgroup performance monitoring. Here, we apply subgroup discovery for\nperformance monitoring in chest x-ray and skin lesion classification. We\npropose novel evaluation strategies and show that a simplified subgroup\ndiscovery method without access to classification labels or metadata can expose\nlarger performance disparities than traditional metadata-based subgroup\nanalysis. We provide the first compelling evidence that subgroup discovery can\nserve as an important tool for comprehensive performance validation and\nmonitoring of trustworthy AI in medicine.\n","authors":["Alceu Bissoto","Trung-Dung Hoang","Tim Flühmann","Susu Sun","Christian F. Baumgartner","Lisa M. Koch"],"pdf_url":"https://arxiv.org/pdf/2503.10382v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2405.16496v2","updated":"2025-03-13T13:56:43Z","published":"2024-05-26T09:16:34Z","title":"Exploring a Multimodal Fusion-based Deep Learning Network for Detecting\n  Facial Palsy","summary":"  Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessment by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes unstructured data (i.e. an image frame with facial line\nsegments) and structured data (i.e. features of facial expressions) to detect\nfacial palsy. We then contribute to a study to analyze the effect of different\ndata modalities and the benefits of a multimodal fusion-based approach using\nvideos of 21 facial palsy patients. Our experimental results show that among\nvarious data modalities (i.e. unstructured data - RGB images and images of\nfacial line segments and structured data - coordinates of facial landmarks and\nfeatures of facial expressions), the feed-forward neural network using features\nof facial expression achieved the highest precision of 76.22 while the\nResNet-based model using images of facial line segments achieved the highest\nrecall of 83.47. When we leveraged both images of facial line segments and\nfeatures of facial expressions, our multimodal fusion-based deep learning model\nslightly improved the precision score to 77.05 at the expense of a decrease in\nthe recall score.\n","authors":["Heng Yim Nicole Oo","Min Hun Lee","Jeong Hoon Lim"],"pdf_url":"https://arxiv.org/pdf/2405.16496v2.pdf","comment":"IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)"},{"id":"http://arxiv.org/abs/2503.10375v1","updated":"2025-03-13T13:54:24Z","published":"2025-03-13T13:54:24Z","title":"Probabilistic Forecasting via Autoregressive Flow Matching","summary":"  In this work, we propose FlowTime, a generative model for probabilistic\nforecasting of multivariate timeseries data. Given historical measurements and\noptional future covariates, we formulate forecasting as sampling from a learned\nconditional distribution over future trajectories. Specifically, we decompose\nthe joint distribution of future observations into a sequence of conditional\ndensities, each modeled via a shared flow that transforms a simple base\ndistribution into the next observation distribution, conditioned on observed\ncovariates. To achieve this, we leverage the flow matching (FM) framework,\nenabling scalable and simulation-free learning of these transformations. By\ncombining this factorization with the FM objective, FlowTime retains the\nbenefits of autoregressive models -- including strong extrapolation\nperformance, compact model size, and well-calibrated uncertainty estimates --\nwhile also capturing complex multi-modal conditional distributions, as seen in\nmodern transport-based generative models. We demonstrate the effectiveness of\nFlowTime on multiple dynamical systems and real-world forecasting tasks.\n","authors":["Ahmed El-Gazzar","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2503.10375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10371v1","updated":"2025-03-13T13:48:35Z","published":"2025-03-13T13:48:35Z","title":"A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted\n  Features-based Deep Learning Networks for Facial Palsy Detection","summary":"  Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).\n","authors":["Heng Yim Nicole Oo","Min Hun Lee","Jeong Hoon Lim"],"pdf_url":"https://arxiv.org/pdf/2503.10371v1.pdf","comment":"PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496"},{"id":"http://arxiv.org/abs/2503.10370v1","updated":"2025-03-13T13:48:24Z","published":"2025-03-13T13:48:24Z","title":"LUMOS: Language-Conditioned Imitation Learning with World Models","summary":"  We introduce LUMOS, a language-conditioned multi-task imitation learning\nframework for robotics. LUMOS learns skills by practicing them over many\nlong-horizon rollouts in the latent space of a learned world model and\ntransfers these skills zero-shot to a real robot. By learning on-policy in the\nlatent space of the learned world model, our algorithm mitigates policy-induced\ndistribution shift which most offline imitation learning methods suffer from.\nLUMOS learns from unstructured play data with fewer than 1% hindsight language\nannotations but is steerable with language commands at test time. We achieve\nthis coherent long-horizon performance by combining latent planning with both\nimage- and language-based hindsight goal relabeling during training, and by\noptimizing an intrinsic reward defined in the latent space of the world model\nover multiple time steps, effectively reducing covariate shift. In experiments\non the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior\nlearning-based methods with comparable approaches on chained multi-task\nevaluations. To the best of our knowledge, we are the first to learn a\nlanguage-conditioned continuous visuomotor control for a real-world robot\nwithin an offline world model. Videos, dataset and code are available at\nhttp://lumos.cs.uni-freiburg.de.\n","authors":["Iman Nematollahi","Branton DeMoss","Akshay L Chandra","Nick Hawes","Wolfram Burgard","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2503.10370v1.pdf","comment":"Accepted at the 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2503.10362v1","updated":"2025-03-13T13:42:46Z","published":"2025-03-13T13:42:46Z","title":"BioSerenity-E1: a self-supervised EEG model for medical applications","summary":"  Electroencephalography (EEG) serves as an essential diagnostic tool in\nneurology; however, its accurate manual interpretation is a time-intensive\nprocess that demands highly specialized expertise, which remains relatively\nscarce and not consistently accessible. To address these limitations, the\nimplementation of automated pre-screening and analysis systems for EEG data\nholds considerable promise. Advances in self-supervised learning made it\npossible to pre-train complex deep learning architectures on large volumes of\nunlabeled EEG data to learn generalizable representations, that can later be\nused to enhance performance on multiple tasks while needing less downstream\ndata. In the present paper, we introduce BioSerenity-E1, the first of a family\nof self-supervised foundation models for clinical EEG applications that\ncombines spectral tokenization with masked prediction to achieve\nstate-of-the-art performance across relevant diagnostic tasks. The two-phase\nself-supervised pretraining framework initially acquires compressed EEG\nrepresentations via a transformer-based VQ-VAE architecture designed to\nreconstruct log-multitaper spectral projections, then implements extensive (70%\nblock) masked token prediction to force the model to learn complex\nspatiotemporal dependencies in EEG signals. BioSerenity-E1 achieves strong\nperformance across three clinical tasks, either in line or above\nstate-of-the-art methods: seizure detection (AUROC = 0.926, Sensitivity =\n0.909), normal/abnormal classification (AUPRC = 0.970 on proprietary data;\n0.910 on TUH-Abnormal), and multiclass pathology differentiation on unbalanced\ndata (Weighted F1 = 0.730). The utility of BioSerenity-E1 is further confirmed\nin low-data regimes scenarios, showing clear improvements in AUPRC (from +2% to\n17%) when trained on less than 10% of the available data.\n","authors":["Ruggero G. Bettinardi","Mohamed Rahmouni","Ulysse Gimenez"],"pdf_url":"https://arxiv.org/pdf/2503.10362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10358v1","updated":"2025-03-13T13:39:24Z","published":"2025-03-13T13:39:24Z","title":"ConceptGuard: Continual Personalized Text-to-Image Generation with\n  Forgetting and Confusion Mitigation","summary":"  Diffusion customization methods have achieved impressive results with only a\nminimal number of user-provided images. However, existing approaches customize\nconcepts collectively, whereas real-world applications often require sequential\nconcept integration. This sequential nature can lead to catastrophic\nforgetting, where previously learned concepts are lost. In this paper, we\ninvestigate concept forgetting and concept confusion in the continual\ncustomization. To tackle these challenges, we present ConceptGuard, a\ncomprehensive approach that combines shift embedding, concept-binding prompts\nand memory preservation regularization, supplemented by a priority queue which\ncan adaptively update the importance and occurrence order of different\nconcepts. These strategies can dynamically update, unbind and learn the\nrelationship of the previous concepts, thus alleviating concept forgetting and\nconfusion. Through comprehensive experiments, we show that our approach\noutperforms all the baseline methods consistently and significantly in both\nquantitative and qualitative analyses.\n","authors":["Zirun Guo","Tao Jin"],"pdf_url":"https://arxiv.org/pdf/2503.10358v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2411.13163v2","updated":"2025-03-13T13:39:09Z","published":"2024-11-20T09:59:12Z","title":"Unlocking Historical Clinical Trial Data with ALIGN: A Compositional\n  Large Language Model System for Medical Coding","summary":"  The reuse of historical clinical trial data has significant potential to\naccelerate medical research and drug development. However, interoperability\nchallenges, particularly with missing medical codes, hinders effective data\nintegration across studies. While Large Language Models (LLMs) offer a\npromising solution for automated coding without labeled data, current\napproaches face challenges on complex coding tasks. We introduce ALIGN, a novel\ncompositional LLM-based system for automated, zero-shot medical coding. ALIGN\nfollows a three-step process: (1) diverse candidate code generation; (2)\nself-evaluation of codes and (3) confidence scoring and uncertainty estimation\nenabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing\nmedication terms into Anatomical Therapeutic Chemical (ATC) and medical history\nterms into Medical Dictionary for Regulatory Activities (MedDRA) codes\nextracted from 22 immunology trials. ALIGN outperformed the LLM baselines,\nwhile also providing capabilities for trustworthy deployment. For MedDRA\ncoding, ALIGN achieved high accuracy across all levels, matching RAG and\nexcelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN\ndemonstrated superior performance, particularly at lower hierarchy levels (ATC\nLevel 4), with 72-73% overall accuracy and 86-89% accuracy for common\nmedications, outperforming baselines by 7-22%. ALIGN's uncertainty-based\ndeferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably\nenhancing performance on uncommon medications. ALIGN achieves this\ncost-efficiently at \\$0.0007 and \\$0.02 per code for GPT-4o-mini and GPT-4o,\nreducing barriers to clinical adoption. ALIGN advances automated medical coding\nfor clinical trial data, contributing to enhanced data interoperability and\nreusability, positioning it as a promising tool to improve clinical research\nand accelerate drug development.\n","authors":["Nabeel Seedat","Caterina Tozzi","Andrea Hita Ardiaca","Mihaela van der Schaar","James Weatherall","Adam Taylor"],"pdf_url":"https://arxiv.org/pdf/2411.13163v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11607v2","updated":"2025-03-13T13:32:53Z","published":"2024-08-21T13:32:46Z","title":"Networked Communication for Mean-Field Games with Function Approximation\n  and Empirical Mean-Field Estimation","summary":"  Recent algorithms allow decentralised agents, possibly connected via a\ncommunication network, to learn equilibria in Mean-Field Games from a\nnon-episodic run of the empirical system. However, these algorithms are for\ntabular settings: this computationally limits the size of agents' observation\nspace, meaning the algorithms cannot handle anything but small state spaces,\nnor generalise beyond policies depending only on the agent's local state to\nso-called 'population-dependent' policies. We address this limitation by\nintroducing function approximation to the existing setting, drawing on the\nMunchausen Online Mirror Descent method that has previously been employed only\nin finite-horizon, episodic, centralised settings. While this permits us to\ninclude the mean field in the observation for players' policies, it is\nunrealistic to assume decentralised agents have access to this global\ninformation: we therefore also provide new algorithms allowing agents to\nlocally estimate the global empirical distribution, and to improve this\nestimate via inter-agent communication. We show theoretically that exchanging\npolicy information helps networked agents outperform both independent and even\ncentralised agents in function-approximation settings. Our experiments\ndemonstrate this happening empirically, by an even greater margin than in\ntabular settings, and show that the communication network allows decentralised\nagents to estimate the mean field for population-dependent policies.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2408.11607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10352v1","updated":"2025-03-13T13:28:54Z","published":"2025-03-13T13:28:54Z","title":"Safe exploration in reproducing kernel Hilbert spaces","summary":"  Popular safe Bayesian optimization (BO) algorithms learn control policies for\nsafety-critical systems in unknown environments. However, most algorithms make\na smoothness assumption, which is encoded by a known bounded norm in a\nreproducing kernel Hilbert space (RKHS). The RKHS is a potentially\ninfinite-dimensional space, and it remains unclear how to reliably obtain the\nRKHS norm of an unknown function. In this work, we propose a safe BO algorithm\ncapable of estimating the RKHS norm from data. We provide statistical\nguarantees on the RKHS norm estimation, integrate the estimated RKHS norm into\nexisting confidence intervals and show that we retain theoretical guarantees,\nand prove safety of the resulting safe BO algorithm. We apply our algorithm to\nsafely optimize reinforcement learning policies on physics simulators and on a\nreal inverted pendulum, demonstrating improved performance, safety, and\nscalability compared to the state-of-the-art.\n","authors":["Abdullah Tokmak","Kiran G. Krishnan","Thomas B. Schön","Dominik Baumann"],"pdf_url":"https://arxiv.org/pdf/2503.10352v1.pdf","comment":"Accepted to AISTATS 2025"},{"id":"http://arxiv.org/abs/2403.05158v2","updated":"2025-03-13T13:27:47Z","published":"2024-03-08T08:51:37Z","title":"Adaptive Split Learning over Energy-Constrained Wireless Edge Networks","summary":"  Split learning (SL) is a promising approach for training artificial\nintelligence (AI) models, in which devices collaborate with a server to train\nan AI model in a distributed manner, based on a same fixed split point.\nHowever, due to the device heterogeneity and variation of channel conditions,\nthis way is not optimal in training delay and energy consumption. In this\npaper, we design an adaptive split learning (ASL) scheme which can dynamically\nselect split points for devices and allocate computing resource for the server\nin wireless edge networks. We formulate an optimization problem to minimize the\naverage training latency subject to long-term energy consumption constraint.\nThe difficulties in solving this problem are the lack of future information and\nmixed integer programming (MIP). To solve it, we propose an online algorithm\nleveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP\nproblem only with the current information. Then, a two-layer optimization\nmethod is proposed to solve the MIP problem. Extensive simulation results\ndemonstrate that the ASL scheme can reduce the average training delay and\nenergy consumption by 53.7% and 22.1%, respectively, as compared to the\nexisting SL schemes.\n","authors":["Zuguang Li","Wen Wu","Shaohua Wu","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.05158v2.pdf","comment":"6 pages, 5 figures, 20 conferences"},{"id":"http://arxiv.org/abs/2411.04744v3","updated":"2025-03-13T13:26:21Z","published":"2024-11-07T14:27:49Z","title":"Respecting the limit:Bayesian optimization with a bound on the optimal\n  value","summary":"  In many real-world optimization problems, we have prior information about\nwhat objective function values are achievable. In this paper, we study the\nscenario that we have either exact knowledge of the minimum value or a,\npossibly inexact, lower bound on its value. We propose bound-aware Bayesian\noptimization (BABO), a Bayesian optimization method that uses a new surrogate\nmodel and acquisition function to utilize such prior information. We present\nSlogGP, a new surrogate model that incorporates bound information and adapts\nthe Expected Improvement (EI) acquisition function accordingly. Empirical\nresults on a variety of benchmarks demonstrate the benefit of taking prior\ninformation about the optimal value into account, and that the proposed\napproach significantly outperforms existing techniques. Furthermore, we notice\nthat even in the absence of prior information on the bound, the proposed SlogGP\nsurrogate model still performs better than the standard GP model in most cases,\nwhich we explain by its larger expressiveness.\n","authors":["Hanyang Wang","Juergen Branke","Matthias Poloczek"],"pdf_url":"https://arxiv.org/pdf/2411.04744v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07994v2","updated":"2025-03-13T13:25:44Z","published":"2024-10-10T14:51:14Z","title":"Neuroplastic Expansion in Deep Reinforcement Learning","summary":"  The loss of plasticity in learning agents, analogous to the solidification of\nneural pathways in biological brains, significantly impedes learning and\nadaptation in reinforcement learning due to its non-stationary nature. To\naddress this fundamental challenge, we propose a novel approach, {\\it\nNeuroplastic Expansion} (NE), inspired by cortical expansion in cognitive\nscience. NE maintains learnability and adaptability throughout the entire\ntraining process by dynamically growing the network from a smaller initial size\nto its full dimension. Our method is designed with three key components:\n(\\textit{1}) elastic topology generation based on potential gradients,\n(\\textit{2}) dormant neuron pruning to optimize network expressivity, and\n(\\textit{3}) neuron consolidation via experience review to strike a balance in\nthe plasticity-stability dilemma. Extensive experiments demonstrate that NE\neffectively mitigates plasticity loss and outperforms state-of-the-art methods\nacross various tasks in MuJoCo and DeepMind Control Suite environments. NE\nenables more adaptive learning in complex, dynamic environments, which\nrepresents a crucial step towards transitioning deep reinforcement learning\nfrom static, one-time training paradigms to more flexible, continually adapting\nmodels.\n","authors":["Jiashun Liu","Johan Obando-Ceron","Aaron Courville","Ling Pan"],"pdf_url":"https://arxiv.org/pdf/2410.07994v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10345v1","updated":"2025-03-13T13:23:43Z","published":"2025-03-13T13:23:43Z","title":"Mirror Online Conformal Prediction with Intermittent Feedback","summary":"  Online conformal prediction enables the runtime calibration of a pre-trained\nartificial intelligence model using feedback on its performance. Calibration is\nachieved through set predictions that are updated via online rules so as to\nensure long-term coverage guarantees. While recent research has demonstrated\nthe benefits of incorporating prior knowledge into the calibration process,\nthis has come at the cost of replacing coverage guarantees with less tangible\nregret guarantees based on the quantile loss. This work introduces intermittent\nmirror online conformal prediction (IM-OCP), a novel runtime calibration\nframework that integrates prior knowledge, while maintaining long-term coverage\nand achieving sub-linear regret. IM-OCP features closed-form updates with\nminimal memory complexity, and is designed to operate under potentially\nintermittent feedback.\n","authors":["Bowen Wang","Matteo Zecchin","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2503.10345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10646v2","updated":"2025-03-13T13:22:30Z","published":"2025-02-15T02:47:14Z","title":"Dark Deceptions in DHCP: Dismantling Network Defenses","summary":"  This paper explores vulnerabilities in the Dynamic Host Configuration\nProtocol (DHCP) and their implications on the Confidentiality, Integrity, and\nAvailability (CIA) Triad. Through an analysis of various attacks, including\nDHCP Starvation, Rogue DHCP Servers, Replay Attacks, and TunnelVision exploits,\nthe paper provides a taxonomic classification of threats, assesses risks, and\nproposes appropriate controls. The discussion also highlights the dangers of\nVPN decloaking through DHCP exploits and underscores the importance of\nsafeguarding network infrastructures. By bringing awareness to the TunnelVision\nexploit, this paper aims to mitigate risks associated with these prevalent\nvulnerabilities.\n","authors":["Robert Dilworth"],"pdf_url":"https://arxiv.org/pdf/2502.10646v2.pdf","comment":"8 pages, 4 tables"},{"id":"http://arxiv.org/abs/2409.13191v2","updated":"2025-03-13T13:20:17Z","published":"2024-09-20T03:47:54Z","title":"Diabetica: Adapting Large Language Model to Enhance Multiple Medical\n  Tasks in Diabetes Care and Management","summary":"  Diabetes is a chronic disease with a significant global health burden,\nrequiring multi-stakeholder collaboration for optimal management. Large\nlanguage models (LLMs) have shown promise in various healthcare scenarios, but\ntheir effectiveness across diverse diabetes tasks remains unproven. Our study\nintroduced a framework to train and validate diabetes-specific LLMs. We first\ndeveloped a comprehensive data processing pipeline that includes data\ncollection, filtering, augmentation and refinement. This created a\nhigh-quality, diabetes-specific dataset and evaluation benchmarks from scratch.\nFine-tuned on the collected training dataset, our diabetes-specific LLM family\ndemonstrated state-of-the-art proficiency in processing various diabetes tasks\ncompared to other LLMs. Furthermore, clinical studies revealed the potential\napplications of our models in diabetes care, including providing personalized\nhealthcare, assisting medical education, and streamlining clinical tasks.\nGenerally, our introduced framework helps develop diabetes-specific LLMs and\nhighlights their potential to enhance clinical practice and provide\npersonalized, data-driven support for diabetes management across different end\nusers. Our codes, benchmarks and models are available at\nhttps://github.com/waltonfuture/Diabetica.\n","authors":["Lai Wei","Zhen Ying","Muyang He","Yutong Chen","Qian Yang","Yanzhe Hong","Jiaping Lu","Kaipeng Zheng","Shaoting Zhang","Xiaoying Li","Weiran Huang","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2409.13191v2.pdf","comment":"Accepted by ICLR 2025 SCI-FM workshop"},{"id":"http://arxiv.org/abs/2411.19853v2","updated":"2025-03-13T13:19:33Z","published":"2024-11-29T17:09:59Z","title":"Towards Class-wise Robustness Analysis","summary":"  While being very successful in solving many downstream tasks, the application\nof deep neural networks is limited in real-life scenarios because of their\nsusceptibility to domain shifts such as common corruptions, and adversarial\nattacks. The existence of adversarial examples and data corruption\nsignificantly reduces the performance of deep classification models.\nResearchers have made strides in developing robust neural architectures to\nbolster decisions of deep classifiers. However, most of these works rely on\neffective adversarial training methods, and predominantly focus on overall\nmodel robustness, disregarding class-wise differences in robustness, which are\ncritical. Exploiting weakly robust classes is a potential avenue for attackers\nto fool the image recognition models. Therefore, this study investigates\nclass-to-class biases across adversarially trained robust classification models\nto understand their latent space structures and analyze their strong and weak\nclass-wise properties. We further assess the robustness of classes against\ncommon corruptions and adversarial attacks, recognizing that class\nvulnerability extends beyond the number of correct classifications for a\nspecific class. We find that the number of false positives of classes as\nspecific target classes significantly impacts their vulnerability to attacks.\nThrough our analysis on the Class False Positive Score, we assess a fair\nevaluation of how susceptible each class is to misclassification.\n","authors":["Tejaswini Medi","Julia Grabinski","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2411.19853v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01129v3","updated":"2025-03-13T13:17:05Z","published":"2025-02-03T07:49:00Z","title":"Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless\n  Networks","summary":"  This report investigates the application of deep reinforcement learning (DRL)\nalgorithms for dynamic resource allocation in wireless communication systems.\nAn environment that includes a base station, multiple antennas, and user\nequipment is created. Using the RLlib library, various DRL algorithms such as\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.\nThese algorithms are compared based on their ability to optimize resource\nallocation, focusing on the impact of different learning rates and scheduling\npolicies. The findings demonstrate that the choice of algorithm and learning\nrate significantly influences system performance, with DRL providing more\nefficient resource allocation compared to traditional methods.\n","authors":["Shubham Malhotra","Fnu Yashu","Muhammad Saqib","Dipkumar Mehta","Jagdish Jangid","Sachin Dixit"],"pdf_url":"https://arxiv.org/pdf/2502.01129v3.pdf","comment":"Upon further review, we found inconsistencies in our analysis and\n  decided to conduct additional research before resubmitting a revised version"},{"id":"http://arxiv.org/abs/2503.10336v1","updated":"2025-03-13T13:15:04Z","published":"2025-03-13T13:15:04Z","title":"Characterizing Nonlinear Dynamics via Smooth Prototype Equivalences","summary":"  Characterizing dynamical systems given limited measurements is a common\nchallenge throughout the physical and biological sciences. However, this task\nis challenging, especially due to transient variability in systems with\nequivalent long-term dynamics. We address this by introducing smooth prototype\nequivalences (SPE), a framework that fits a diffeomorphism using normalizing\nflows to distinct prototypes - simplified dynamical systems that define\nequivalence classes of behavior. SPE enables classification by comparing the\ndeformation loss of the observed sparse, high-dimensional measurements to the\nprototype dynamics. Furthermore, our approach enables estimation of the\ninvariant sets of the observed dynamics through the learned mapping from\nprototype space to data space. Our method outperforms existing techniques in\nthe classification of oscillatory systems and can efficiently identify\ninvariant structures like limit cycles and fixed points in an equation-free\nmanner, even when only a small, noisy subset of the phase space is observed.\nFinally, we show how our method can be used for the detection of biological\nprocesses like the cell cycle trajectory from high-dimensional single-cell gene\nexpression data.\n","authors":["Roy Friedman","Noa Moriel","Matthew Ricci","Guy Pelc","Yair Weiss","Mor Nitzan"],"pdf_url":"https://arxiv.org/pdf/2503.10336v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.10333v1","updated":"2025-03-13T13:11:59Z","published":"2025-03-13T13:11:59Z","title":"Generative Binary Memory: Pseudo-Replay Class-Incremental Learning on\n  Binarized Embeddings","summary":"  In dynamic environments where new concepts continuously emerge, Deep Neural\nNetworks (DNNs) must adapt by learning new classes while retaining previously\nacquired ones. This challenge is addressed by Class-Incremental Learning (CIL).\nThis paper introduces Generative Binary Memory (GBM), a novel CIL pseudo-replay\napproach which generates synthetic binary pseudo-exemplars. Relying on\nBernoulli Mixture Models (BMMs), GBM effectively models the multi-modal\ncharacteristics of class distributions, in a latent, binary space. With a\nspecifically-designed feature binarizer, our approach applies to any\nconventional DNN. GBM also natively supports Binary Neural Networks (BNNs) for\nhighly-constrained model sizes in embedded systems. The experimental results\ndemonstrate that GBM achieves higher than state-of-the-art average accuracy on\nCIFAR100 (+2.9%) and TinyImageNet (+1.5%) for a ResNet-18 equipped with our\nbinarizer. GBM also outperforms emerging CIL methods for BNNs, with +3.1% in\nfinal accuracy and x4.7 memory reduction, on CORE50.\n","authors":["Yanis Basso-Bert","Anca Molnos","Romain Lemaire","William Guicquero","Antoine Dupret"],"pdf_url":"https://arxiv.org/pdf/2503.10333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01727v2","updated":"2025-03-13T13:09:14Z","published":"2024-10-02T16:37:19Z","title":"Automated Knowledge Concept Annotation and Question Representation\n  Learning for Knowledge Tracing","summary":"  Knowledge tracing (KT) is a popular approach for modeling students' learning\nprogress over time, which can enable more personalized and adaptive learning.\nHowever, existing KT approaches face two major limitations: (1) they rely\nheavily on expert-defined knowledge concepts (KCs) in questions, which is\ntime-consuming and prone to errors; and (2) KT methods tend to overlook the\nsemantics of both questions and the given KCs. In this work, we address these\nchallenges and present KCQRL, a framework for automated knowledge concept\nannotation and question representation learning that can improve the\neffectiveness of any existing KT model. First, we propose an automated KC\nannotation process using large language models (LLMs), which generates question\nsolutions and then annotates KCs in each solution step of the questions.\nSecond, we introduce a contrastive learning approach to generate semantically\nrich embeddings for questions and solution steps, aligning them with their\nassociated KCs via a tailored false negative elimination approach. These\nembeddings can be readily integrated into existing KT models, replacing their\nrandomly initialized embeddings. We demonstrate the effectiveness of KCQRL\nacross 15 KT algorithms on two large real-world Math learning datasets, where\nwe achieve consistent performance improvements.\n","authors":["Yilmazcan Ozyurt","Stefan Feuerriegel","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2410.01727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04891v3","updated":"2025-03-13T13:04:09Z","published":"2024-10-07T10:19:09Z","title":"Low-Rank Continual Personalization of Diffusion Models","summary":"  Recent personalization methods for diffusion models, such as Dreambooth and\nLoRA, allow fine-tuning pre-trained models to generate new concepts. However,\napplying these techniques across consecutive tasks in order to include, e.g.,\nnew objects or styles, leads to a forgetting of previous knowledge due to\nmutual interference between their adapters. In this work, we tackle the problem\nof continual customization under a rigorous regime with no access to past\ntasks' adapters. In such a scenario, we investigate how different adapters'\ninitialization and merging methods can improve the quality of the final model.\nTo that end, we evaluate the naive continual fine-tuning of customized models\nand compare this approach with three methods for consecutive adapters'\ntraining: sequentially merging new adapters, merging orthogonally initialized\nadapters, and updating only relevant task-specific weights. In our experiments,\nwe show that the proposed techniques mitigate forgetting when compared to the\nnaive approach. In our studies, we show different traits of selected techniques\nand their effect on the plasticity and stability of the continually adapted\nmodel. Repository with the code is available at\nhttps://github.com/luk-st/continual-lora.\n","authors":["Łukasz Staniszewski","Katarzyna Zaleska","Kamil Deja"],"pdf_url":"https://arxiv.org/pdf/2410.04891v3.pdf","comment":"SCOPE @ ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10325v1","updated":"2025-03-13T13:03:38Z","published":"2025-03-13T13:03:38Z","title":"Collaborative Speculative Inference for Efficient LLM Inference Serving","summary":"  Speculative inference is a promising paradigm employing small speculative\nmodels (SSMs) as drafters to generate draft tokens, which are subsequently\nverified in parallel by the target large language model (LLM). This approach\nenhances the efficiency of inference serving by reducing LLM inference latency\nand costs while preserving generation quality. However, existing speculative\nmethods face critical challenges, including inefficient resource utilization\nand limited draft acceptance, which constrain their scalability and overall\neffectiveness. To overcome these obstacles, we present CoSine, a novel\nspeculative inference system that decouples sequential speculative decoding\nfrom parallel verification, enabling efficient collaboration among multiple\nnodes. Specifically, CoSine routes inference requests to specialized drafters\nbased on their expertise and incorporates a confidence-based token fusion\nmechanism to synthesize outputs from cooperating drafters, ensuring\nhigh-quality draft generation. Additionally, CoSine dynamically orchestrates\nthe execution of speculative decoding and verification in a pipelined manner,\nemploying batch scheduling to selectively group requests and adaptive\nspeculation control to minimize idle periods. By optimizing parallel workflows\nthrough heterogeneous node collaboration, CoSine balances draft generation and\nverification throughput in real-time, thereby maximizing resource utilization.\nExperimental results demonstrate that CoSine achieves superior performance\ncompared to state-of-the-art speculative approaches. Notably, with equivalent\nresource costs, CoSine achieves up to a 23.2% decrease in latency and a 32.5%\nincrease in throughput compared to baseline methods.\n","authors":["Luyao Gao","Jianchun Liu","Hongli Xu","Liusheng Huang"],"pdf_url":"https://arxiv.org/pdf/2503.10325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08489v2","updated":"2025-03-13T12:57:09Z","published":"2025-03-11T14:42:17Z","title":"A Triple-Inertial Accelerated Alternating Optimization Method for Deep\n  Learning Training","summary":"  The stochastic gradient descent (SGD) algorithm has achieved remarkable\nsuccess in training deep learning models. However, it has several limitations,\nincluding susceptibility to vanishing gradients, sensitivity to input data, and\na lack of robust theoretical guarantees. In recent years, alternating\nminimization (AM) methods have emerged as a promising alternative for model\ntraining by employing gradient-free approaches to iteratively update model\nparameters. Despite their potential, these methods often exhibit slow\nconvergence rates. To address this challenge, we propose a novel\nTriple-Inertial Accelerated Alternating Minimization (TIAM) framework for\nneural network training. The TIAM approach incorporates a triple-inertial\nacceleration strategy with a specialized approximation method, facilitating\ntargeted acceleration of different terms in each sub-problem optimization. This\nintegration improves the efficiency of convergence, achieving superior\nperformance with fewer iterations. Additionally, we provide a convergence\nanalysis of the TIAM algorithm, including its global convergence properties and\nconvergence rate. Extensive experiments validate the effectiveness of the TIAM\nmethod, showing significant improvements in generalization capability and\ncomputational efficiency compared to existing approaches, particularly when\napplied to the rectified linear unit (ReLU) and its variants.\n","authors":["Chengcheng Yan","Jiawei Xu","Qingsong Wang","Zheng Peng"],"pdf_url":"https://arxiv.org/pdf/2503.08489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10318v1","updated":"2025-03-13T12:53:42Z","published":"2025-03-13T12:53:42Z","title":"Enhance Exploration in Safe Reinforcement Learning with Contrastive\n  Representation Learning","summary":"  In safe reinforcement learning, agent needs to balance between exploration\nactions and safety constraints. Following this paradigm, domain transfer\napproaches learn a prior Q-function from the related environments to prevent\nunsafe actions. However, because of the large number of false positives, some\nsafe actions are never executed, leading to inadequate exploration in\nsparse-reward environments. In this work, we aim to learn an efficient state\nrepresentation to balance the exploration and safety-prefer action in a\nsparse-reward environment. Firstly, the image input is mapped to latent\nrepresentation by an auto-encoder. A further contrastive learning objective is\nemployed to distinguish safe and unsafe states. In the learning phase, the\nlatent distance is used to construct an additional safety check, which allows\nthe agent to bias the exploration if it visits an unsafe state. To verify the\neffectiveness of our method, the experiment is carried out in three\nnavigation-based MiniGrid environments. The result highlights that our method\ncan explore the environment better while maintaining a good balance between\nsafety and efficiency.\n","authors":["Duc Kien Doan","Bang Giang Le","Viet Cuong Ta"],"pdf_url":"https://arxiv.org/pdf/2503.10318v1.pdf","comment":"Accepted at ACIIDS 2025"},{"id":"http://arxiv.org/abs/2410.12289v2","updated":"2025-03-13T12:40:48Z","published":"2024-10-16T06:47:53Z","title":"AI-Aided Kalman Filters","summary":"  The Kalman filter (KF) and its variants are among the most celebrated\nalgorithms in signal processing. These methods are used for state estimation of\ndynamic systems by relying on mathematical representations in the form of\nsimple state-space (SS) models, which may be crude and inaccurate descriptions\nof the underlying dynamics. Emerging data-centric artificial intelligence (AI)\ntechniques tackle these tasks using deep neural networks (DNNs), which are\nmodel-agnostic. Recent developments illustrate the possibility of fusing DNNs\nwith classic Kalman-type filtering, obtaining systems that learn to track in\npartially known dynamics. This article provides a tutorial-style overview of\ndesign approaches for incorporating AI in aiding KF-type algorithms. We review\nboth generic and dedicated DNN architectures suitable for state estimation, and\nprovide a systematic presentation of techniques for fusing AI tools with KFs\nand for leveraging partial SS modeling and data, categorizing design approaches\ninto task-oriented and SS model-oriented. The usefulness of each approach in\npreserving the individual strengths of model-based KFs and data-driven DNNs is\ninvestigated in a qualitative and quantitative study, whose code is publicly\navailable, illustrating the gains of hybrid model-based/data-driven designs. We\nalso discuss existing challenges and future research directions that arise from\nfusing AI and Kalman-type algorithms.\n","authors":["Nir Shlezinger","Guy Revach","Anubhab Ghosh","Saikat Chatterjee","Shuo Tang","Tales Imbiriba","Jindrich Dunik","Ondrej Straka","Pau Closas","Yonina C. Eldar"],"pdf_url":"https://arxiv.org/pdf/2410.12289v2.pdf","comment":"Submitted to the IEEE Signal Processing Magazine"},{"id":"http://arxiv.org/abs/2503.10310v1","updated":"2025-03-13T12:39:04Z","published":"2025-03-13T12:39:04Z","title":"Capturing Semantic Flow of ML-based Systems","summary":"  ML-based systems are software systems that incorporates machine learning\ncomponents such as Deep Neural Networks (DNNs) or Large Language Models (LLMs).\nWhile such systems enable advanced features such as high performance computer\nvision, natural language processing, and code generation, their internal\nbehaviour remain largely opaque to traditional dynamic analysis such as\ntesting: existing analysis typically concern only what is observable from the\noutside, such as input similarity or class label changes. We propose semantic\nflow, a concept designed to capture the internal behaviour of ML-based system\nand to provide a platform for traditional dynamic analysis techniques to be\nadapted to. Semantic flow combines the idea of control flow with internal\nstates taken from executions of ML-based systems, such as activation values of\na specific layer in a DNN, or embeddings of LLM responses at a specific\ninference step of LLM agents. The resulting representation, summarised as\nsemantic flow graphs, can capture internal decisions that are not explicitly\nrepresented in the traditional control flow of ML-based systems. We propose the\nidea of semantic flow, introduce two examples using a DNN and an LLM agent, and\nfinally sketch its properties and how it can be used to adapt existing dynamic\nanalysis techniques for use in ML-based software systems.\n","authors":["Shin Yoo","Robert Feldt","Somin Kim","Naryeong Kim"],"pdf_url":"https://arxiv.org/pdf/2503.10310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10304v1","updated":"2025-03-13T12:25:36Z","published":"2025-03-13T12:25:36Z","title":"Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement\n  Learning","summary":"  Many online advertising platforms provide advertisers with auto-bidding\nservices to enhance their advertising performance. However, most existing\nauto-bidding algorithms fail to accurately capture the auto-bidding problem\nformulation that the platform truly faces, let alone solve it. Actually, we\nargue that the platform should try to help optimize each advertiser's\nperformance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium\n($\\epsilon$-NE) a necessary solution concept -- while maximizing the social\nwelfare of all the advertisers for the platform's long-term value. Based on\nthis, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new\nformulation of the auto-bidding problem from the platform's perspective.\nSpecifically, it aims to maximize the social welfare of all advertisers under\nthe $\\epsilon$-NE constraint. However, the NCB problem presents significant\nchallenges due to its constrained bi-level structure and the typically large\nnumber of advertisers involved. To address these challenges, we propose a\n\\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.\nNotably, its computational complexity is independent of the number of\nadvertisers, and the associated gradients are straightforward to compute.\nExtensive simulated and real-world experiments validate the effectiveness of\nthe BPG framework.\n","authors":["Zhiyu Mou","Miao Xu","Rongquan Bai","Zhuoran Yang","Chuan Yu","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.10304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04579v3","updated":"2025-03-13T12:12:17Z","published":"2024-04-30T09:05:17Z","title":"Tackling water table depth modeling via machine learning: From proxy\n  observations to verifiability","summary":"  Spatial patterns of water table depth (WTD) play a crucial role in shaping\necological resilience, hydrological connectivity, and human-centric systems.\nGenerally, a large-scale (e.g., continental or global) continuous map of static\nWTD can be simulated using either physically-based (PB) or machine\nlearning-based (ML) models. We construct three fine-resolution (500 m) ML\nsimulations of WTD, using the XGBoost algorithm and more than 20 million real\nand proxy observations of WTD, across the United States and Canada. The three\nML models were constrained using known physical relations between WTD's drivers\nand WTD and were trained by sequentially adding real and proxy observations of\nWTD. Through an extensive (pixel-by-pixel) evaluation across the study region\nand within ten major ecoregions of North America, we demonstrate that our\nmodels (corr=0.6-0.75) can more accurately predict unseen real and proxy\nobservations of WTD compared to two available PB simulations of WTD\n(corr=0.21-0.40). However, we still argue that currently-available large-scale\nsimulations of static WTD could be uncertain within data-scarce regions such as\nsteep mountainous regions. We reason that biased observational data mainly\ncollected from low-elevation floodplains and the over-flexibility of available\nmodels can negatively affect the verifiability of large-scale simulations of\nWTD. Ultimately, we thoroughly discuss future directions that may help\nhydrogeologists decide how to improve machine learning-based WTD estimations.\nIn particular, we advocate for the use of proxy satellite data, the\nincorporation of physical laws, the implementation of better model verification\nstandards, the development of novel globally-available emergent indices, and\nthe collection of more reliable observations.\n","authors":["Joseph Janssen","Ardalan Tootchi","Ali A. Ameli"],"pdf_url":"https://arxiv.org/pdf/2405.04579v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10294v1","updated":"2025-03-13T12:07:35Z","published":"2025-03-13T12:07:35Z","title":"Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy\n  for Analysing Wiki Deletion Discussions","summary":"  Automated content moderation for collaborative knowledge hubs like Wikipedia\nor Wikidata is an important yet challenging task due to multiple factors. In\nthis paper, we construct a database of discussions happening around articles\nmarked for deletion in several Wikis and in three languages, which we then use\nto evaluate a range of LMs on different tasks (from predicting the outcome of\nthe discussion to identifying the implicit policy an individual comment might\nbe pointing to). Our results reveal, among others, that discussions leading to\ndeletion are easier to predict, and that, surprisingly, self-produced tags\n(keep, delete or redirect) don't always help guiding the classifiers,\npresumably because of users' hesitation or deliberation within comments.\n","authors":["Hsuvas Borkakoty","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.10294v1.pdf","comment":"Accepted to WNUT-2025"},{"id":"http://arxiv.org/abs/2503.10284v1","updated":"2025-03-13T11:52:23Z","published":"2025-03-13T11:52:23Z","title":"PyGDA: A Python Library for Graph Domain Adaptation","summary":"  Graph domain adaptation has emerged as a promising approach to facilitate\nknowledge transfer across different domains. Recently, numerous models have\nbeen proposed to enhance their generalization capabilities in this field.\nHowever, there is still no unified library that brings together existing\ntechniques and simplifies their implementation. To fill this gap, we introduce\nPyGDA, an open-source Python library tailored for graph domain adaptation. As\nthe first comprehensive library in this area, PyGDA covers more than 20 widely\nused graph domain adaptation methods together with different types of graph\ndatasets. Specifically, PyGDA offers modular components, enabling users to\nseamlessly build custom models with a variety of commonly used utility\nfunctions. To handle large-scale graphs, PyGDA includes support for features\nsuch as sampling and mini-batch processing, ensuring efficient computation. In\naddition, PyGDA also includes comprehensive performance benchmarks and\nwell-documented user-friendly API for both researchers and practitioners. To\nfoster convenient accessibility, PyGDA is released under the MIT license at\nhttps://github.com/pygda-team/pygda, and the API documentation is\nhttps://pygda.readthedocs.io/en/stable/.\n","authors":["Zhen Zhang","Meihan Liu","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2503.10284v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.10282v1","updated":"2025-03-13T11:50:28Z","published":"2025-03-13T11:50:28Z","title":"HyperArm Bandit Optimization: A Novel approach to Hyperparameter\n  Optimization and an Analysis of Bandit Algorithms in Stochastic and\n  Adversarial Settings","summary":"  This paper explores the application of bandit algorithms in both stochastic\nand adversarial settings, with a focus on theoretical analysis and practical\napplications. The study begins by introducing bandit problems, distinguishing\nbetween stochastic and adversarial variants, and examining key algorithms such\nas Explore-Then-Commit (ETC), Upper Confidence Bound (UCB), and\nExponential-Weight Algorithm for Exploration and Exploitation (EXP3).\nTheoretical regret bounds are analyzed to compare the performance of these\nalgorithms. The paper then introduces a novel framework, HyperArm Bandit\nOptimization (HABO), which applies EXP3 to hyperparameter tuning in machine\nlearning models. Unlike traditional methods that treat entire configurations as\narms, HABO treats individual hyperparameters as super-arms, and its potential\nconfigurations as sub-arms, enabling dynamic resource allocation and efficient\nexploration. Experimental results demonstrate HABO's effectiveness in\nclassification and regression tasks, outperforming Bayesian Optimization in\nterms of computational efficiency and accuracy. The paper concludes with\ninsights into the convergence guarantees of HABO and its potential for scalable\nand robust hyperparameter optimization.\n","authors":["Samih Karroum","Saad Mazhar"],"pdf_url":"https://arxiv.org/pdf/2503.10282v1.pdf","comment":"41 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.02702v2","updated":"2025-03-13T11:47:44Z","published":"2025-03-04T15:18:40Z","title":"RedChronos: A Large Language Model-Based Log Analysis System for Insider\n  Threat Detection in Enterprises","summary":"  Internal threat detection (IDT) aims to address security threats within\norganizations or enterprises by identifying potential or already occurring\nmalicious threats within vast amounts of logs. Although organizations or\nenterprises have dedicated personnel responsible for reviewing these logs, it\nis impossible to manually examine all logs entirely.In response to the vast\nnumber of logs, we propose a system called RedChronos, which is a Large\nLanguage Model-Based Log Analysis System. This system incorporates innovative\nimprovements over previous research by employing Query-Aware Weighted Voting\nand a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations. On\nthe public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches\nexisting approaches in terms of accuracy, precision, and detection rate.\nMoreover, RedChronos reduces the need for manual intervention in security log\nreviews by approximately 90% in the Xiaohongshu Security Operation Center.\nTherefore, our RedChronos system demonstrates exceptional performance in\nhandling IDT tasks, providing innovative solutions for these challenges. We\nbelieve that future research can continue to enhance the system's performance\nin IDT tasks while also reducing the response time to internal risk events.\n","authors":["Chenyu Li","Zhengjia Zhu","Jiyan He","Xiu Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02702v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10280v1","updated":"2025-03-13T11:46:35Z","published":"2025-03-13T11:46:35Z","title":"Robust Learning-Based Sparse Recovery for Device Activity Detection in\n  Grant-Free Random Access Cell-Free Massive MIMO: Enhancing Resilience to\n  Impairments","summary":"  Massive MIMO is considered a key enabler to support massive machine-type\ncommunication (mMTC). While massive access schemes have been extensively\nanalyzed for co-located massive MIMO arrays, this paper explores activity\ndetection in grant-free random access for mMTC within the context of cell-free\nmassive MIMO systems, employing distributed antenna arrays. This sparse support\nrecovery of device activity status is performed by a finite cluster of access\npoints (APs) from a large number of geographically distributed APs\ncollaborating to serve a larger number of devices. Active devices transmit\nnon-orthogonal pilot sequences to APs, which forward the received signals to a\ncentral processing unit (CPU) for collaborative activity detection. This paper\nproposes a simple and efficient data-driven algorithm tailored for device\nactivity detection, implemented centrally at the CPU. Furthermore, the study\nassesses the algorithm's robustness to input perturbations and examines the\neffects of adopting fixed-point representation on its performance.\n","authors":["Ali Elkeshawy","Haifa Fares","Amor Nafkha"],"pdf_url":"https://arxiv.org/pdf/2503.10280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10279v1","updated":"2025-03-13T11:43:53Z","published":"2025-03-13T11:43:53Z","title":"Numerically robust Gaussian state estimation with singular observation\n  noise","summary":"  This article proposes numerically robust algorithms for Gaussian state\nestimation with singular observation noise. Our approach combines a series of\nbasis changes with Bayes' rule, transforming the singular estimation problem\ninto a nonsingular one with reduced state dimension. In addition to ensuring\nlow runtime and numerical stability, our proposal facilitates\nmarginal-likelihood computations and Gauss-Markov representations of the\nposterior process. We analyse the proposed method's computational savings and\nnumerical robustness and validate our findings in a series of simulations.\n","authors":["Nicholas Krämer","Filip Tronarp"],"pdf_url":"https://arxiv.org/pdf/2503.10279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10278v1","updated":"2025-03-13T11:41:17Z","published":"2025-03-13T11:41:17Z","title":"Climate land use and other drivers impacts on island ecosystem services:\n  a global review","summary":"  Islands are diversity hotspots and vulnerable to environmental degradation,\nclimate variations, land use changes and societal crises. These factors can\nexhibit interactive impacts on ecosystem services. The study reviewed a large\nnumber of papers on the climate change-islands-ecosystem services topic\nworldwide. Potential inclusion of land use changes and other drivers of impacts\non ecosystem services were sequentially also recorded. The study sought to\ninvestigate the impacts of climate change, land use change, and other\nnon-climatic driver changes on island ecosystem services. Explanatory variables\nexamined were divided into two categories: environmental variables and\nmethodological ones. Environmental variables include sea zone geographic\nlocation, ecosystem, ecosystem services, climate, land use, other driver\nvariables, Methodological variables include consideration of policy\ninterventions, uncertainty assessment, cumulative effects of climate change,\nsynergistic effects of climate change with land use change and other\nanthropogenic and environmental drivers, and the diversity of variables used in\nthe analysis. Machine learning and statistical methods were used to analyze\ntheir effects on island ecosystem services. Negative climate change impacts on\necosystem services are better quantified by land use change or other\nnon-climatic driver variables than by climate variables. The synergy of land\nuse together with climate changes is modulating the impact outcome and critical\nfor a better impact assessment. Analyzed together, there is little evidence of\nmore pronounced for a specific sea zone, ecosystem, or ecosystem service.\nClimate change impacts may be underestimated due to the use of a single climate\nvariable deployed in most studies. Policy interventions exhibit low\nclassification accuracy in quantifying impacts indicating insufficient efficacy\nor integration in the studies.\n","authors":["Aristides Moustakas","Shiri Zemah-Shamir","Mirela Tase","Savvas Zotos","Nazli Demirel","Christos Zoumides","Irene Christoforidi","Turgay Dindaroglu","Tamer Albayrak","Cigdem Kaptan Ayhan","Mauro Fois","Paraskevi Manolaki","Attila D. Sandor","Ina Sieber","Valentini Stamatiadou","Elli Tzirkalli","Ioannis N. Vogiatzakis","Ziv Zemah-Shamir","George Zittis"],"pdf_url":"https://arxiv.org/pdf/2503.10278v1.pdf","comment":"Article published in the journal: Science of the Total Environment.\n  Free author's version"},{"id":"http://arxiv.org/abs/2503.10277v1","updated":"2025-03-13T11:38:50Z","published":"2025-03-13T11:38:50Z","title":"Resource efficient data transmission on animals based on machine\n  learning","summary":"  Bio-loggers, electronic devices used to track animal behaviour through\nvarious sensors, have become essential in wildlife research.\n  Despite continuous improvements in their capabilities, bio-loggers still face\nsignificant limitations in storage, processing, and data transmission due to\nthe constraints of size and weight, which are necessary to avoid disturbing the\nanimals.\n  This study aims to explore how selective data transmission, guided by machine\nlearning, can reduce the energy consumption of bio-loggers, thereby extending\ntheir operational lifespan without requiring hardware modifications.\n","authors":["Wilhelm Kerle-Malcharek","Karsten Klein","Martin Wikelski","Falk Schreiber","Timm A. Wild"],"pdf_url":"https://arxiv.org/pdf/2503.10277v1.pdf","comment":"Submitted to Scientific Reports but not published, 23 pages, 5\n  figures, 3 tables"},{"id":"http://arxiv.org/abs/2501.17568v2","updated":"2025-03-13T11:38:47Z","published":"2025-01-29T11:03:02Z","title":"Histogram Approaches for Imbalanced Data Streams Regression","summary":"  Imbalanced domains pose a significant challenge in real-world predictive\nanalytics, particularly in the context of regression. While existing research\nhas primarily focused on batch learning from static datasets, limited attention\nhas been given to imbalanced regression in online learning scenarios. Intending\nto address this gap, in prior work, we proposed sampling strategies based on\nChebyshevs inequality as the first methodologies designed explicitly for data\nstreams. However, these approaches operated under the restrictive assumption\nthat rare instances exclusively reside at distribution extremes. This study\nintroduces histogram-based sampling strategies to overcome this constraint,\nproposing flexible solutions for imbalanced regression in evolving data\nstreams. The proposed techniques -- Histogram-based Undersampling (HistUS) and\nHistogram-based Oversampling (HistOS) -- employ incremental online histograms\nto dynamically detect and prioritize rare instances across arbitrary regions of\nthe target distribution to improve predictions in the rare cases. Comprehensive\nexperiments on synthetic and real-world benchmarks demonstrate that HistUS and\nHistOS substantially improve rare-case prediction accuracy, outperforming\nbaseline models while maintaining competitiveness with Chebyshev-based\napproaches.\n","authors":["Ehsan Aminian","Rita P. Ribeiro","Joao Gama"],"pdf_url":"https://arxiv.org/pdf/2501.17568v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12921v2","updated":"2025-03-13T11:34:18Z","published":"2024-10-16T18:09:09Z","title":"Credal Two-Sample Tests of Epistemic Uncertainty","summary":"  We introduce credal two-sample testing, a new hypothesis testing framework\nfor comparing credal sets -- convex sets of probability measures where each\nelement captures aleatoric uncertainty and the set itself represents epistemic\nuncertainty that arises from the modeller's partial ignorance. Compared to\nclassical two-sample tests, which focus on comparing precise distributions, the\nproposed framework provides a broader and more versatile set of hypotheses.\nThis approach enables the direct integration of epistemic uncertainty,\neffectively addressing the challenges arising from partial ignorance in\nhypothesis testing. By generalising two-sample test to compare credal sets, our\nframework enables reasoning for equality, inclusion, intersection, and mutual\nexclusivity, each offering unique insights into the modeller's epistemic\nbeliefs. As the first work on nonparametric hypothesis testing for comparing\ncredal sets, we focus on finitely generated credal sets derived from i.i.d.\nsamples from multiple distributions -- referred to as credal samples. We\nformalise these tests as two-sample tests with nuisance parameters and\nintroduce the first permutation-based solution for this class of problems,\nsignificantly improving existing methods. Our approach properly incorporates\nthe modeller's epistemic uncertainty into hypothesis testing, leading to more\nrobust and credible conclusions, with kernel-based implementations for\nreal-world applications.\n","authors":["Siu Lun Chau","Antonin Schrab","Arthur Gretton","Dino Sejdinovic","Krikamol Muandet"],"pdf_url":"https://arxiv.org/pdf/2410.12921v2.pdf","comment":"64 pages"},{"id":"http://arxiv.org/abs/2502.07842v2","updated":"2025-03-13T11:32:19Z","published":"2025-02-11T05:32:14Z","title":"Column-wise Quantization of Weights and Partial Sums for Accurate and\n  Efficient Compute-In-Memory Accelerators","summary":"  Compute-in-memory (CIM) is an efficient method for implementing deep neural\nnetworks (DNNs) but suffers from substantial overhead from analog-to-digital\nconverters (ADCs), especially as ADC precision increases. Low-precision ADCs\ncan reduce this overhead but introduce partial-sum quantization errors\ndegrading accuracy. Additionally, low-bit weight constraints, imposed by cell\nlimitations and the need for multiple cells for higher-bit weights, present\nfurther challenges. While fine-grained partial-sum quantization has been\nstudied to lower ADC resolution effectively, weight granularity, which limits\noverall partial-sum quantized accuracy, remains underexplored. This work\naddresses these challenges by aligning weight and partial-sum quantization\ngranularities at the column-wise level. Our method improves accuracy while\nmaintaining dequantization overhead, simplifies training by removing two-stage\nprocesses, and ensures robustness to memory cell variations via independent\ncolumn-wise scale factors. We also propose an open-source CIM-oriented\nconvolution framework to handle fine-grained weights and partial-sums\nefficiently, incorporating a novel tiling method and group convolution.\nExperimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18\n(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,\ncompared to the best-performing related works. Additionally, variation analysis\nreveals the robustness of our method against memory cell variations. These\nfindings highlight the effectiveness of our quantization scheme in enhancing\naccuracy and robustness while maintaining hardware efficiency in CIM-based DNN\nimplementations. Our code is available at\nhttps://github.com/jiyoonkm/ColumnQuant.\n","authors":["Jiyoon Kim","Kang Eun Jeon","Yulhwa Kim","Jong Hwan Ko"],"pdf_url":"https://arxiv.org/pdf/2502.07842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10269v1","updated":"2025-03-13T11:25:25Z","published":"2025-03-13T11:25:25Z","title":"Targeted Data Poisoning for Black-Box Audio Datasets Ownership\n  Verification","summary":"  Protecting the use of audio datasets is a major concern for data owners,\nparticularly with the recent rise of audio deep learning models. While\nwatermarks can be used to protect the data itself, they do not allow to\nidentify a deep learning model trained on a protected dataset. In this paper,\nwe adapt to audio data the recently introduced data taggants approach. Data\ntaggants is a method to verify if a neural network was trained on a protected\nimage dataset with top-$k$ predictions access to the model only. This method\nrelies on a targeted data poisoning scheme by discreetly altering a small\nfraction (1%) of the dataset as to induce a harmless behavior on\nout-of-distribution data called keys. We evaluate our method on the\nSpeechcommands and the ESC50 datasets and state of the art transformer models,\nand show that we can detect the use of the dataset with high confidence without\nloss of performance. We also show the robustness of our method against common\ndata augmentation techniques, making it a practical method to protect audio\ndatasets.\n","authors":["Wassim Bouaziz","El-Mahdi El-Mhamdi","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2503.10269v1.pdf","comment":"Published at ICASSP 2025, 5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.11826v2","updated":"2025-03-13T11:23:03Z","published":"2024-10-15T17:53:07Z","title":"Bayesian Experimental Design via Contrastive Diffusions","summary":"  Bayesian Optimal Experimental Design (BOED) is a powerful tool to reduce the\ncost of running a sequence of experiments. When based on the Expected\nInformation Gain (EIG), design optimization corresponds to the maximization of\nsome intractable expected contrast between prior and posterior distributions.\nScaling this maximization to high dimensional and complex settings has been an\nissue due to BOED inherent computational complexity. In this work, we introduce\na pooled posterior distribution with cost-effective sampling properties and\nprovide a tractable access to the EIG contrast maximization via a new EIG\ngradient expression. Diffusion-based samplers are used to compute the dynamics\nof the pooled posterior and ideas from bi-level optimization are leveraged to\nderive an efficient joint sampling-optimization loop. The resulting efficiency\ngain allows to extend BOED to the well-tested generative capabilities of\ndiffusion models. By incorporating generative models into the BOED framework,\nwe expand its scope and its use in scenarios that were previously impractical.\nNumerical experiments and comparison with state-of-the-art methods show the\npotential of the approach.\n","authors":["Jacopo Iollo","Christophe Heinkelé","Pierre Alliez","Florence Forbes"],"pdf_url":"https://arxiv.org/pdf/2410.11826v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10257v1","updated":"2025-03-13T11:16:42Z","published":"2025-03-13T11:16:42Z","title":"AMR-Transformer: Enabling Efficient Long-range Interaction for Complex\n  Neural Fluid Simulation","summary":"  Accurately and efficiently simulating complex fluid dynamics is a challenging\ntask that has traditionally relied on computationally intensive methods. Neural\nnetwork-based approaches, such as convolutional and graph neural networks, have\npartially alleviated this burden by enabling efficient local feature\nextraction. However, they struggle to capture long-range dependencies due to\nlimited receptive fields, and Transformer-based models, while providing global\ncontext, incur prohibitive computational costs. To tackle these challenges, we\npropose AMR-Transformer, an efficient and accurate neural CFD-solving pipeline\nthat integrates a novel adaptive mesh refinement scheme with a Navier-Stokes\nconstraint-aware fast pruning module. This design encourages long-range\ninteractions between simulation cells and facilitates the modeling of global\nfluid wave patterns, such as turbulence and shockwaves. Experiments show that\nour approach achieves significant gains in efficiency while preserving critical\ndetails, making it suitable for high-resolution physical simulations with\nlong-range dependencies. On CFDBench, PDEBench and a new shockwave dataset, our\npipeline demonstrates up to an order-of-magnitude improvement in accuracy over\nbaseline models. Additionally, compared to ViT, our approach achieves a\nreduction in FLOPs of up to 60 times.\n","authors":["Zeyi Xu","Jinfan Liu","Kuangxu Chen","Ye Chen","Zhangli Hu","Bingbing Ni"],"pdf_url":"https://arxiv.org/pdf/2503.10257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07752v3","updated":"2025-03-13T11:14:49Z","published":"2024-12-10T18:50:37Z","title":"FlashRNN: I/O-Aware Optimization of Traditional RNNs on modern hardware","summary":"  While Transformers and other sequence-parallelizable neural network\narchitectures seem like the current state of the art in sequence modeling, they\nspecifically lack state-tracking capabilities. These are important for\ntime-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,\nas well as modern variants like sLSTM do have these capabilities at the cost of\nstrictly sequential processing. While this is often seen as a strong\nlimitation, we show how fast these networks can get with our\nhardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the\nregister level on modern GPUs. We extend traditional RNNs with a\nparallelization variant that processes multiple RNNs of smaller hidden state in\nparallel, similar to the head-wise processing in Transformers. To enable\nflexibility on different GPU variants, we introduce a new optimization\nframework for hardware-internal cache sizes, memory and compute handling. It\nmodels the hardware in a setting using polyhedral-like constraints, including\nthe notion of divisibility. This speeds up the solution process in our\nConstrINT library for general integer constraint satisfaction problems (integer\nCSPs). We show that our kernels can achieve 50x speed-ups over a vanilla\nPyTorch implementation and allow 40x larger hidden sizes compared to our Triton\nimplementation. Our open-source kernels and the optimization library are\nreleased here to boost research in the direction of state-tracking enabled RNNs\nand sequence modeling: https://github.com/NX-AI/flashrnn\n","authors":["Korbinian Pöppel","Maximilian Beck","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2412.07752v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10253v1","updated":"2025-03-13T11:01:03Z","published":"2025-03-13T11:01:03Z","title":"PIMRL: Physics-Informed Multi-Scale Recurrent Learning for\n  Spatiotemporal Prediction","summary":"  Simulation of spatiotemporal systems governed by partial differential\nequations is widely applied in fields such as biology, chemistry, aerospace\ndynamics, and meteorology. Traditional numerical methods incur high\ncomputational costs due to the requirement of small time steps for accurate\npredictions. While machine learning has reduced these costs, long-term\npredictions remain challenged by error accumulation, particularly in scenarios\nwith insufficient data or varying time scales, where stability and accuracy are\ncompromised. Existing methods often neglect the effective utilization of\nmulti-scale data, leading to suboptimal robustness in predictions. To address\nthese issues, we propose a novel multi-scale learning framework, namely, the\nPhysics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively\nleverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL\nframework comprises two modules: the micro-scale module embeds physical\nknowledge into neural networks via pretraining, and the macro-scale module\nadopts a data-driven approach to learn the temporal evolution of physics in the\nlatent space. Experimental results demonstrate that the PIMRL framework\nconsistently achieves state-of-the-art performance across five benchmark\ndatasets ranging from one to three dimensions, showing average improvements of\nover 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements\nreaching up to 80%.\n","authors":["Han Wan","Qi Wang","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2503.10253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10251v1","updated":"2025-03-13T10:53:17Z","published":"2025-03-13T10:53:17Z","title":"Numerical Error Analysis of Large Language Models","summary":"  Large language models based on transformer architectures have become integral\nto state-of-the-art natural language processing applications. However, their\ntraining remains computationally expensive and exhibits instabilities, some of\nwhich are expected to be caused by finite-precision computations. We provide a\ntheoretical analysis of the impact of round-off errors within the forward pass\nof a transformer architecture which yields fundamental bounds for these\neffects. In addition, we conduct a series of numerical experiments which\ndemonstrate the practical relevance of our bounds. Our results yield concrete\nguidelines for choosing hyperparameters that mitigate round-off errors, leading\nto more robust and stable inference.\n","authors":["Stanislav Budzinskiy","Wenyi Fang","Longbin Zeng","Philipp Petersen"],"pdf_url":"https://arxiv.org/pdf/2503.10251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04653v4","updated":"2025-03-13T10:33:15Z","published":"2024-12-05T22:50:42Z","title":"Hidden in the Noise: Two-Stage Robust Watermarking for Images","summary":"  As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.\n","authors":["Kasra Arabi","Benjamin Feuer","R. Teal Witter","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2412.04653v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10240v1","updated":"2025-03-13T10:32:25Z","published":"2025-03-13T10:32:25Z","title":"Spherical dimension","summary":"  We introduce and study the spherical dimension, a natural topological\nrelaxation of the VC dimension that unifies several results in learning theory\nwhere topology plays a key role in the proofs. The spherical dimension is\ndefined by extending the set of realizable datasets (used to define the VC\ndimension) to the continuous space of realizable distributions. In this space,\na shattered set of size d (in the VC sense) is completed into a continuous\nobject, specifically a d-dimensional sphere of realizable distributions. The\nspherical dimension is then defined as the dimension of the largest sphere in\nthis space. Thus, the spherical dimension is at least the VC dimension.\n  The spherical dimension serves as a common foundation for leveraging the\nBorsuk-Ulam theorem and related topological tools. We demonstrate the utility\nof the spherical dimension in diverse applications, including disambiguations\nof partial concept classes, reductions from classification to stochastic convex\noptimization, stability and replicability, and sample compression schemes.\nPerhaps surprisingly, we show that the open question posed by Alon, Hanneke,\nHolzman, and Moran (FOCS 2021) of whether there exist non-trivial\ndisambiguations for halfspaces with margin is equivalent to the basic open\nquestion of whether the VC and spherical dimensions are finite together.\n","authors":["Bogdan Chornomaz","Shay Moran","Tom Waknine"],"pdf_url":"https://arxiv.org/pdf/2503.10240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04443v2","updated":"2025-03-13T10:26:57Z","published":"2024-06-06T18:49:10Z","title":"Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is\n  Heavy-Tailed","summary":"  Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for\ntraining modern Deep Learning models, especially Large Language Models.\nTypically, the noise in the stochastic gradients is heavy-tailed for the later\nones. Gradient clipping provably helps to achieve good high-probability\nconvergence for such noises. However, despite the similarity between\nAdaGrad/Adam and Clip-SGD, the current understanding of the high-probability\nconvergence of AdaGrad/Adam-type methods is limited in this case. In this work,\nwe prove that AdaGrad/Adam (and their delayed version) can have provably bad\nhigh-probability convergence if the noise is heavy-tailed. We also show that\ngradient clipping fixes this issue, i.e., we derive new high-probability\nconvergence bounds with polylogarithmic dependence on the confidence level for\nAdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth\nconvex/non-convex stochastic optimization with heavy-tailed noise. Our\nempirical evaluations highlight the superiority of clipped versions of\nAdaGrad/Adam-Norm in handling the heavy-tailed noise.\n","authors":["Savelii Chezhegov","Yaroslav Klyukin","Andrei Semenov","Aleksandr Beznosikov","Alexander Gasnikov","Samuel Horváth","Martin Takáč","Eduard Gorbunov"],"pdf_url":"https://arxiv.org/pdf/2406.04443v2.pdf","comment":"63 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.04830v3","updated":"2025-03-13T10:19:32Z","published":"2023-11-08T16:56:16Z","title":"Real-Time Recurrent Reinforcement Learning","summary":"  We introduce a biologically plausible RL framework for solving tasks in\npartially observable Markov decision processes (POMDPs). The proposed algorithm\ncombines three integral parts: (1) A Meta-RL architecture, resembling the\nmammalian basal ganglia; (2) A biologically plausible reinforcement learning\nalgorithm, exploiting temporal difference learning and eligibility traces to\ntrain the policy and the value-function; (3) An online automatic\ndifferentiation algorithm for computing the gradients with respect to\nparameters of a shared recurrent network backbone. Our experimental results\nshow that the method is capable of solving a diverse set of partially\nobservable reinforcement learning tasks. The algorithm we call real-time\nrecurrent reinforcement learning (RTRRL) serves as a model of learning in\nbiological neural networks, mimicking reward pathways in the basal ganglia.\n","authors":["Julian Lemmel","Radu Grosu"],"pdf_url":"https://arxiv.org/pdf/2311.04830v3.pdf","comment":"14 pages, 9 figures, includes Appendix"},{"id":"http://arxiv.org/abs/2503.10232v1","updated":"2025-03-13T10:15:40Z","published":"2025-03-13T10:15:40Z","title":"Flows on convex polytopes","summary":"  We present a framework for modeling complex, high-dimensional distributions\non convex polytopes by leveraging recent advances in discrete and continuous\nnormalizing flows on Riemannian manifolds. We show that any full-dimensional\npolytope is homeomorphic to a unit ball, and our approach harnesses flows\ndefined on the ball, mapping them back to the original polytope. Furthermore,\nwe introduce a strategy to construct flows when only the vertex representation\nof a polytope is available, employing maximum entropy barycentric coordinates\nand Aitchison geometry. Our experiments take inspiration from applications in\nmetabolic flux analysis and demonstrate that our methods achieve competitive\ndensity estimation, sampling accuracy, as well as fast training and inference\ntimes.\n","authors":["Tomek Diederen","Nicola Zamboni"],"pdf_url":"https://arxiv.org/pdf/2503.10232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10228v1","updated":"2025-03-13T10:11:54Z","published":"2025-03-13T10:11:54Z","title":"Policy Teaching via Data Poisoning in Learning from Human Preferences","summary":"  We study data poisoning attacks in learning from human preferences. More\nspecifically, we consider the problem of teaching/enforcing a target policy\n$\\pi^\\dagger$ by synthesizing preference data. We seek to understand the\nsusceptibility of different preference-based learning paradigms to poisoned\npreference data by analyzing the number of samples required by the attacker to\nenforce $\\pi^\\dagger$. We first propose a general data poisoning formulation in\nlearning from human preferences and then study it for two popular paradigms,\nnamely: (a) reinforcement learning from human feedback (RLHF) that operates by\nlearning a reward model using preferences; (b) direct preference optimization\n(DPO) that directly optimizes policy using preferences. We conduct a\ntheoretical analysis of the effectiveness of data poisoning in a setting where\nthe attacker is allowed to augment a pre-existing dataset and also study its\nspecial case where the attacker can synthesize the entire preference dataset\nfrom scratch. As our main results, we provide lower/upper bounds on the number\nof samples required to enforce $\\pi^\\dagger$. Finally, we discuss the\nimplications of our results in terms of the susceptibility of these learning\nparadigms under such data poisoning attacks.\n","authors":["Andi Nika","Jonathan Nöther","Debmalya Mandal","Parameswaran Kamalaruban","Adish Singla","Goran Radanović"],"pdf_url":"https://arxiv.org/pdf/2503.10228v1.pdf","comment":"In AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.07378v3","updated":"2025-03-13T10:04:14Z","published":"2025-03-10T14:31:34Z","title":"Materials Map Integrating Experimental and Computational Data through\n  Graph-Based Machine Learning for Enhanced Materials Discovery","summary":"  Materials informatics (MI), which emerges from the integration of materials\nscience and data science, is expected to greatly streamline the material\ndiscovery and development. The data used for MI are obtained from both\ncomputational and experimental studies, while their integration remains\nchallenging. In our previous study, we reported the integration of these\ndatasets by applying a machine learning model that captures trends hidden in\nthe experimental datasets to compositional data stored in the computational\ndatabase. In this study, we use the obtained data to construct materials maps,\nwhich visualize the relation in the structural features of materials, aiming to\nsupport study by the experimental researchers. The map is constructed using the\nMatDeepLearn (MDL) framework, which implements the graph-based representation\nof material structures, deep learning, and dimensional reduction for the map\nconstruction. We evaluate the obtained materials maps through statistical\nanalysis and found that the MDL using message passing neural network (MPNN)\nenables efficient extraction of features that reflect the structural complexity\nof materials. Moreover, we found that this advantage does not necessarily\ntranslate into improved accuracy in predicting material properties. We\nattribute this unexpected outcome to the high learning performance inherent in\nMPNN, which can contribute to the structuring of data points within the\nmaterials map.\n","authors":["Yusuke Hashimoto","Xue Jia","Hao Li","Takaaki Tomai"],"pdf_url":"https://arxiv.org/pdf/2503.07378v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10220v1","updated":"2025-03-13T10:01:07Z","published":"2025-03-13T10:01:07Z","title":"Assessing the validity of new paradigmatic complexity measures as\n  criterial features for proficiency in L2 writings in English","summary":"  This article addresses Second Language (L2) writing development through an\ninvestigation of new grammatical and structural complexity metrics. We explore\nthe paradigmatic production in learner English by linking language functions to\nspecific grammatical paradigms. Using the EFCAMDAT as a gold standard and a\ncorpus of French learners as an external test set, we employ a supervised\nlearning framework to operationalise and evaluate seven microsystems. We show\nthat learner levels are associated with the seven microsystems (MS). Using\nordinal regression modelling for evaluation, the results show that all MS are\nsignificant but yield a low impact if taken individually. However, their\ninfluence is shown to be impactful if taken as a group. These microsystems and\ntheir measurement method suggest that it is possible to use them as part of\nbroader-purpose CALL systems focused on proficiency assessment.\n","authors":["Cyriel Mallart","Andrew Simpkin","Nicolas Ballier","Paula Lissón","Rémi Venant","Jen-Yu Li","Bernardo Stearns","Thomas Gaillat"],"pdf_url":"https://arxiv.org/pdf/2503.10220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10219v1","updated":"2025-03-13T10:01:00Z","published":"2025-03-13T10:01:00Z","title":"Probability-Flow ODE in Infinite-Dimensional Function Spaces","summary":"  Recent advances in infinite-dimensional diffusion models have demonstrated\ntheir effectiveness and scalability in function generation tasks where the\nunderlying structure is inherently infinite-dimensional. To accelerate\ninference in such models, we derive, for the first time, an analog of the\nprobability-flow ODE (PF-ODE) in infinite-dimensional function spaces.\nLeveraging this newly formulated PF-ODE, we reduce the number of function\nevaluations while maintaining sample quality in function generation tasks,\nincluding applications to PDEs.\n","authors":["Kunwoo Na","Junghyun Lee","Se-Young Yun","Sungbin Lim"],"pdf_url":"https://arxiv.org/pdf/2503.10219v1.pdf","comment":"26 pages, 8 figures. Accepted to the ICLR 2025 DeLTa Workshop"},{"id":"http://arxiv.org/abs/2503.10218v1","updated":"2025-03-13T10:00:58Z","published":"2025-03-13T10:00:58Z","title":"Moss: Proxy Model-based Full-Weight Aggregation in Federated Learning\n  with Heterogeneous Models","summary":"  Modern Federated Learning (FL) has become increasingly essential for handling\nhighly heterogeneous mobile devices. Current approaches adopt a partial model\naggregation paradigm that leads to sub-optimal model accuracy and higher\ntraining overhead. In this paper, we challenge the prevailing notion of\npartial-model aggregation and propose a novel \"full-weight aggregation\" method\nnamed Moss, which aggregates all weights within heterogeneous models to\npreserve comprehensive knowledge. Evaluation across various applications\ndemonstrates that Moss significantly accelerates training, reduces on-device\ntraining time and energy consumption, enhances accuracy, and minimizes network\nbandwidth utilization when compared to state-of-the-art baselines.\n","authors":["Yifeng Cai","Ziqi Zhang","Ding Li","Yao Guo","Xiangqun Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10218v1.pdf","comment":"Accepted by ACM IMWUT/Ubicomp 2025"},{"id":"http://arxiv.org/abs/2503.10217v1","updated":"2025-03-13T09:59:16Z","published":"2025-03-13T09:59:16Z","title":"Efficient Federated Fine-Tuning of Large Language Models with Layer\n  Dropout","summary":"  Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from\ngeneral language comprehension to task-specific expertise. To preserve user\ndata privacy, federated fine-tuning is often employed and has emerged as the de\nfacto paradigm. However, federated fine-tuning is prohibitively inefficient due\nto the tension between LLM complexity and the resource constraint of end\ndevices, incurring unaffordable fine-tuning overhead. Existing literature\nprimarily utilizes parameter-efficient fine-tuning techniques to mitigate\ncommunication costs, yet computational and memory burdens continue to pose\nsignificant challenges for developers. This work proposes DropPEFT, an\ninnovative federated PEFT framework that employs a novel stochastic transformer\nlayer dropout method, enabling devices to deactivate a considerable fraction of\nLLMs layers during training, thereby eliminating the associated computational\nload and memory footprint. In DropPEFT, a key challenge is the proper\nconfiguration of dropout ratios for layers, as overhead and training\nperformance are highly sensitive to this setting. To address this challenge, we\nadaptively assign optimal dropout-ratio configurations to devices through an\nexploration-exploitation strategy, achieving efficient and effective\nfine-tuning. Extensive experiments show that DropPEFT can achieve a\n1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory\nfootprint compared to state-of-the-art methods.\n","authors":["Shilong Wang","Jianchun Liu","Hongli Xu","Jiaming Yan","Xianjun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.10217v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2304.08845v3","updated":"2025-03-13T09:53:02Z","published":"2023-04-18T09:18:37Z","title":"Feasible Policy Iteration for Safe Reinforcement Learning","summary":"  Safety is the priority concern when applying reinforcement learning (RL)\nalgorithms to real-world control problems. While policy iteration provides a\nfundamental algorithm for standard RL, an analogous theoretical algorithm for\nsafe RL remains absent. In this paper, we propose feasible policy iteration\n(FPI), the first foundational dynamic programming algorithm for safe RL. FPI\nalternates between policy evaluation, region identification and policy\nimprovement. This follows actor-critic-scenery (ACS) framework where scenery\nrefers to a feasibility function that represents a feasible region. A\nregion-wise update rule is developed for the policy improvement step, which\nmaximizes state-value function inside the feasible region and minimizes\nfeasibility function outside it. With this update rule, FPI guarantees\nmonotonic expansion of feasible region, monotonic improvement of state-value\nfunction, and geometric convergence to the optimal safe policy. Experimental\nresults demonstrate that FPI achieves strictly zero constraint violation on\nlow-dimensional tasks and outperforms existing methods in constraint adherence\nand reward performance on high-dimensional tasks.\n","authors":["Yujie Yang","Zhilong Zheng","Shengbo Eben Li","Wei Xu","Jingjing Liu","Xianyuan Zhan","Ya-Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.08845v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09559v2","updated":"2025-03-13T09:35:19Z","published":"2025-03-12T17:24:47Z","title":"The R2D2 Deep Neural Network Series for Scalable Non-Cartesian Magnetic\n  Resonance Imaging","summary":"  We introduce the R2D2 Deep Neural Network (DNN) series paradigm for fast and\nscalable image reconstruction from highly-accelerated non-Cartesian k-space\nacquisitions in Magnetic Resonance Imaging (MRI). While unrolled DNN\narchitectures provide a robust image formation approach via data-consistency\nlayers, embedding non-uniform fast Fourier transform operators in a DNN can\nbecome impractical to train at large scale, e.g in 2D MRI with a large number\nof coils, or for higher-dimensional imaging. Plug-and-play approaches that\nalternate a learned denoiser blind to the measurement setting with a\ndata-consistency step are not affected by this limitation but their highly\niterative nature implies slow reconstruction. To address this scalability\nchallenge, we leverage the R2D2 paradigm that was recently introduced to enable\nultra-fast reconstruction for large-scale Fourier imaging in radio astronomy.\nR2D2's reconstruction is formed as a series of residual images iteratively\nestimated as outputs of DNN modules taking the previous iteration's data\nresidual as input. The method can be interpreted as a learned version of the\nMatching Pursuit algorithm. A series of R2D2 DNN modules were sequentially\ntrained in a supervised manner on the fastMRI dataset and validated for 2D\nmulti-coil MRI in simulation and on real data, targeting highly under-sampled\nradial k-space sampling. Results suggest that a series with only few DNNs\nachieves superior reconstruction quality over its unrolled incarnation R2D2-Net\n(whose training is also much less scalable), and over the state-of-the-art\ndiffusion-based \"Decomposed Diffusion Sampler\" approach (also characterised by\na slower reconstruction process).\n","authors":["Yiwei Chen","Amir Aghabiglou","Shijie Chen","Motahare Torki","Chao Tang","Ruud B. van Heeswijk","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2503.09559v2.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.10198v1","updated":"2025-03-13T09:32:01Z","published":"2025-03-13T09:32:01Z","title":"Deep Learning for Time Series Forecasting: A Survey","summary":"  Time series forecasting (TSF) has long been a crucial task in both industry\nand daily life. Most classical statistical models may have certain limitations\nwhen applied to practical scenarios in fields such as energy, healthcare,\ntraffic, meteorology, and economics, especially when high accuracy is required.\nWith the continuous development of deep learning, numerous new models have\nemerged in the field of time series forecasting in recent years. However,\nexisting surveys have not provided a unified summary of the wide range of model\narchitectures in this field, nor have they given detailed summaries of works in\nfeature extraction and datasets. To address this gap, in this review, we\ncomprehensively study the previous works and summarize the general paradigms of\nDeep Time Series Forecasting (DTSF) in terms of model architectures. Besides,\nwe take an innovative approach by focusing on the composition of time series\nand systematically explain important feature extraction methods. Additionally,\nwe provide an overall compilation of datasets from various domains in existing\nworks. Finally, we systematically emphasize the significant challenges faced\nand future research directions in this field.\n","authors":["Xiangjie Kong","Zhenghao Chen","Weiyao Liu","Kaili Ning","Lechao Zhang","Syauqie Muhammad Marier","Yichen Liu","Yuhao Chen","Feng Xia"],"pdf_url":"https://arxiv.org/pdf/2503.10198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07486v2","updated":"2025-03-13T09:26:41Z","published":"2024-09-04T08:16:22Z","title":"MarS: a Financial Market Simulation Engine Powered by Generative\n  Foundation Model","summary":"  Generative models aim to simulate realistic effects of various actions across\ndifferent contexts, from text generation to visual effects. Despite significant\nefforts to build real-world simulators, the application of generative models to\nvirtual worlds, like financial markets, remains under-explored. In financial\nmarkets, generative models can simulate complex market effects of participants\nwith various behaviors, enabling interaction under different market conditions,\nand training strategies without financial risk. This simulation relies on the\nfinest structured data in financial market like orders thus building the finest\nrealistic simulation. We propose Large Market Model (LMM), an order-level\ngenerative foundation model, for financial market simulation, akin to language\nmodeling in the digital world. Our financial Market Simulation engine (MarS),\npowered by LMM, addresses the domain-specific need for realistic, interactive\nand controllable order generation. Key observations include LMM's strong\nscalability across data size and model complexity, and MarS's robust and\npracticable realism in controlled generation with market impact. We showcase\nMarS as a forecast tool, detection system, analysis platform, and agent\ntraining environment, thus demonstrating MarS's \"paradigm shift\" potential for\na variety of financial applications. We release the code of MarS at\nhttps://github.com/microsoft/MarS/.\n","authors":["Junjie Li","Yang Liu","Weiqing Liu","Shikai Fang","Lewen Wang","Chang Xu","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2409.07486v2.pdf","comment":"35 pages, 26 figures, ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10191v1","updated":"2025-03-13T09:26:19Z","published":"2025-03-13T09:26:19Z","title":"Robustness Tokens: Towards Adversarial Robustness of Transformers","summary":"  Recently, large pre-trained foundation models have become widely adopted by\nmachine learning practitioners for a multitude of tasks. Given that such models\nare publicly available, relying on their use as backbone models for downstream\ntasks might result in high vulnerability to adversarial attacks crafted with\nthe same public model. In this work, we propose Robustness Tokens, a novel\napproach specific to the transformer architecture that fine-tunes a few\nadditional private tokens with low computational requirements instead of tuning\nmodel parameters as done in traditional adversarial training. We show that\nRobustness Tokens make Vision Transformer models significantly more robust to\nwhite-box adversarial attacks while also retaining the original downstream\nperformances.\n","authors":["Brian Pulfer","Yury Belousov","Slava Voloshynovskiy"],"pdf_url":"https://arxiv.org/pdf/2503.10191v1.pdf","comment":"This paper has been accepted for publication at the European\n  Conference on Computer Vision (ECCV), 2024"},{"id":"http://arxiv.org/abs/2407.15455v3","updated":"2025-03-13T09:05:34Z","published":"2024-07-22T08:13:13Z","title":"Score matching for bridges without learning time-reversals","summary":"  We propose a new algorithm for learning bridged diffusion processes using\nscore-matching methods. Our method relies on reversing the dynamics of the\nforward process and using this to learn a score function, which, via Doob's\n$h$-transform, yields a bridged diffusion process; that is, a process\nconditioned on an endpoint. In contrast to prior methods, we learn the score\nterm $\\nabla_x \\log p(t, x; T, y)$ directly, for given $t, y$, completely\navoiding first learning a time-reversal. We compare the performance of our\nalgorithm with existing methods and see that it outperforms using the (learned)\ntime-reversals to learn the score term. The code can be found at\nhttps://github.com/libbylbaker/forward_bridge.\n","authors":["Elizabeth L. Baker","Moritz Schauer","Stefan Sommer"],"pdf_url":"https://arxiv.org/pdf/2407.15455v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06518v2","updated":"2025-03-13T08:56:49Z","published":"2024-11-10T16:40:27Z","title":"Causal Representation Learning from Multimodal Biomedical Observations","summary":"  Prevalent in biomedical applications (e.g., human phenotype research),\nmultimodal datasets can provide valuable insights into the underlying\nphysiological mechanisms. However, current machine learning (ML) models\ndesigned to analyze these datasets often lack interpretability and\nidentifiability guarantees, which are essential for biomedical research. Recent\nadvances in causal representation learning have shown promise in identifying\ninterpretable latent causal variables with formal theoretical guarantees.\nUnfortunately, most current work on multimodal distributions either relies on\nrestrictive parametric assumptions or yields only coarse identification\nresults, limiting their applicability to biomedical research that favors a\ndetailed understanding of the mechanisms.\n  In this work, we aim to develop flexible identification conditions for\nmultimodal data and principled methods to facilitate the understanding of\nbiomedical datasets. Theoretically, we consider a nonparametric latent\ndistribution (c.f., parametric assumptions in previous work) that allows for\ncausal relationships across potentially different modalities. We establish\nidentifiability guarantees for each latent component, extending the subspace\nidentification results from previous work. Our key theoretical contribution is\nthe structural sparsity of causal connections between modalities, which, as we\nwill discuss, is natural for a large collection of biomedical systems.\nEmpirically, we present a practical framework to instantiate our theoretical\ninsights. We demonstrate the effectiveness of our approach through extensive\nexperiments on both numerical and synthetic datasets. Results on a real-world\nhuman phenotype dataset are consistent with established biomedical research,\nvalidating our theoretical and methodological framework.\n","authors":["Yuewen Sun","Lingjing Kong","Guangyi Chen","Loka Li","Gongxu Luo","Zijian Li","Yixuan Zhang","Yujia Zheng","Mengyue Yang","Petar Stojanov","Eran Segal","Eric P. Xing","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02175v5","updated":"2025-03-13T08:48:26Z","published":"2024-04-01T11:23:31Z","title":"Symmetries, Scaling Laws and Phase Transitions in Consumer Advertising\n  Response","summary":"  Understanding how consumers respond to business advertising efforts is\nessential for optimizing marketing investment. This research introduces a new\nmodeling approach based on the concepts of symmetries and scaling laws in\nphysics to describe consumer response to advertising dynamics. Drawing from\nmathematical frameworks used in physics and social sciences, we propose a model\nthat accounts for a key aspect: the saturation effect. The model is validated\nagainst commonly used models, including the Michaelis-Menten and Hill\nequations, showing its ability to better capture nonlinearities in advertising\neffects. We introduce new key parameters like Marketing Sensitivity, Response\nSensitivity, and Behavioral Sensitivit, that offer additional insights into the\ndrivers of audience engagement and advertising performance. Our model provides\na rigorous yet practical tool for understanding audience behavior, contributing\nto the improvement of budget allocation strategies.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2404.02175v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10800v2","updated":"2025-03-13T08:43:27Z","published":"2025-01-18T15:39:53Z","title":"Jailbreaking Large Language Models in Infinitely Many Ways","summary":"  We discuss the ``Infinitely Many Paraphrases'' attacks (IMP), a category of\njailbreaks that leverages the increasing capabilities of a model to handle\nparaphrases and encoded communications to bypass their defensive mechanisms.\nIMPs' viability pairs and grows with a model's capabilities to handle and bind\nthe semantics of simple mappings between tokens and work extremely well in\npractice, posing a concrete threat to the users of the most powerful LLMs in\ncommerce. We show how one can bypass the safeguards of the most powerful open-\nand closed-source LLMs and generate content that explicitly violates their\nsafety policies. One can protect against IMPs by improving the guardrails and\nmaking them scale with the LLMs' capabilities. For two categories of attacks\nthat are straightforward to implement, i.e., bijection and encoding, we discuss\ntwo defensive strategies, one in token and the other in embedding space. We\nconclude with some research questions we believe should be prioritised to\nenhance the defensive mechanisms of LLMs and our understanding of their safety.\n","authors":["Oliver Goldstein","Emanuele La Malfa","Felix Drinkall","Samuele Marro","Michael Wooldridge"],"pdf_url":"https://arxiv.org/pdf/2501.10800v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05491v2","updated":"2025-03-13T08:41:29Z","published":"2025-03-07T15:00:28Z","title":"Statistical Deficiency for Task Inclusion Estimation","summary":"  Tasks are central in machine learning, as they are the most natural objects\nto assess the capabilities of current models. The trend is to build general\nmodels able to address any task. Even though transfer learning and multitask\nlearning try to leverage the underlying task space, no well-founded tools are\navailable to study its structure. This study proposes a theoretically grounded\nsetup to define the notion of task and to compute the {\\bf inclusion} between\ntwo tasks from a statistical deficiency point of view. We propose a tractable\nproxy as information sufficiency to estimate the degree of inclusion between\ntasks, show its soundness on synthetic data, and use it to reconstruct\nempirically the classic NLP pipeline.\n","authors":["Loïc Fosse","Frédéric Béchet","Benoît Favre","Géraldine Damnati","Gwénolé Lecorvé","Maxime Darrin","Philippe Formont","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2503.05491v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2503.10154v1","updated":"2025-03-13T08:29:17Z","published":"2025-03-13T08:29:17Z","title":"Data augmentation using diffusion models to enhance inverse Ising\n  inference","summary":"  Identifying model parameters from observed configurations poses a fundamental\nchallenge in data science, especially with limited data. Recently, diffusion\nmodels have emerged as a novel paradigm in generative machine learning, capable\nof producing new samples that closely mimic observed data. These models learn\nthe gradient of model probabilities, bypassing the need for cumbersome\ncalculations of partition functions across all possible configurations. We\nexplore whether diffusion models can enhance parameter inference by augmenting\nsmall datasets. Our findings demonstrate this potential through a synthetic\ntask involving inverse Ising inference and a real-world application of\nreconstructing missing values in neural activity data. This study serves as a\nproof-of-concept for using diffusion models for data augmentation in\nphysics-related problems, thereby opening new avenues in data science.\n","authors":["Yechan Lim","Sangwon Lee","Junghyo Jo"],"pdf_url":"https://arxiv.org/pdf/2503.10154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00733v4","updated":"2025-03-13T08:23:27Z","published":"2024-12-01T08:54:30Z","title":"Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Video\n  Diffusion Transformer","summary":"  Existing methodologies for animating portrait images face significant\nchallenges, particularly in handling non-frontal perspectives, rendering\ndynamic objects around the portrait, and generating immersive, realistic\nbackgrounds. In this paper, we introduce the first application of a pretrained\ntransformer-based video generative model that demonstrates strong\ngeneralization capabilities and generates highly dynamic, realistic videos for\nportrait animation, effectively addressing these challenges. The adoption of a\nnew video backbone model makes previous U-Net-based methods for identity\nmaintenance, audio conditioning, and video extrapolation inapplicable. To\naddress this limitation, we design an identity reference network consisting of\na causal 3D VAE combined with a stacked series of transformer layers, ensuring\nconsistent facial identity across video sequences. Additionally, we investigate\nvarious speech audio conditioning and motion frame mechanisms to enable the\ngeneration of continuous video driven by speech audio. Our method is validated\nthrough experiments on benchmark and newly proposed wild datasets,\ndemonstrating substantial improvements over prior methods in generating\nrealistic portraits characterized by diverse orientations within dynamic and\nimmersive scenes. Further visualizations and the source code are available at:\nhttps://fudan-generative-vision.github.io/hallo3/.\n","authors":["Jiahao Cui","Hui Li","Yun Zhan","Hanlin Shang","Kaihui Cheng","Yuqi Ma","Shan Mu","Hang Zhou","Jingdong Wang","Siyu Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.00733v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10144v1","updated":"2025-03-13T08:14:00Z","published":"2025-03-13T08:14:00Z","title":"Multiplicative Learning","summary":"  Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.\n","authors":["Han Kim","Hyungjoon Soh","Vipul Periwal","Junghyo Jo"],"pdf_url":"https://arxiv.org/pdf/2503.10144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05116v3","updated":"2025-03-13T08:12:07Z","published":"2024-10-07T15:12:01Z","title":"HERO: Human-Feedback Efficient Reinforcement Learning for Online\n  Diffusion Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback. The code and project page are available\nat https://hero-dm.github.io/.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v3.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2403.14404v4","updated":"2025-03-13T08:07:40Z","published":"2024-03-21T13:52:55Z","title":"Physics-Informed Diffusion Models","summary":"  Generative models such as denoising diffusion models are quickly advancing\ntheir ability to approximate highly complex data distributions. They are also\nincreasingly leveraged in scientific machine learning, where samples from the\nimplied data distribution are expected to adhere to specific governing\nequations. We present a framework that unifies generative modeling and partial\ndifferential equation fulfillment by introducing a first-principle-based loss\nterm that enforces generated samples to fulfill the underlying physical\nconstraints. Our approach reduces the residual error by up to two orders of\nmagnitude compared to previous work in a fluid flow case study and outperforms\ntask-specific frameworks in relevant metrics for structural topology\noptimization. We also present numerical evidence that our extended training\nobjective acts as a natural regularization mechanism against overfitting. Our\nframework is simple to implement and versatile in its applicability for\nimposing equality and inequality constraints as well as auxiliary optimization\nobjectives.\n","authors":["Jan-Hendrik Bastek","WaiChing Sun","Dennis M. Kochmann"],"pdf_url":"https://arxiv.org/pdf/2403.14404v4.pdf","comment":"26 pages, 9 figures, 3 tables; ICLR 2025 camera ready contribution"},{"id":"http://arxiv.org/abs/2410.05609v3","updated":"2025-03-13T08:01:35Z","published":"2024-10-08T01:45:37Z","title":"The Breakdown of Gaussian Universality in Classification of\n  High-dimensional Linear Factor Mixtures","summary":"  The assumption of Gaussian or Gaussian mixture data has been extensively\nexploited in a long series of precise performance analyses of machine learning\n(ML) methods, on large datasets having comparably numerous samples and\nfeatures. To relax this restrictive assumption, subsequent efforts have been\ndevoted to establish \"Gaussian equivalent principles\" by studying scenarios of\nGaussian universality where the asymptotic performance of ML methods on\nnon-Gaussian data remains unchanged when replaced with Gaussian data having the\nsame mean and covariance. Beyond the realm of Gaussian universality, there are\nfew exact results on how the data distribution affects the learning\nperformance.\n  In this article, we provide a precise high-dimensional characterization of\nempirical risk minimization, for classification under a general mixture data\nsetting of linear factor models that extends Gaussian mixtures. The Gaussian\nuniversality is shown to break down under this setting, in the sense that the\nasymptotic learning performance depends on the data distribution beyond the\nclass means and covariances. To clarify the limitations of Gaussian\nuniversality in the classification of mixture data and to understand the impact\nof its breakdown, we specify conditions for Gaussian universality and discuss\ntheir implications for the choice of loss function.\n","authors":["Xiaoyi Mai","Zhenyu Liao"],"pdf_url":"https://arxiv.org/pdf/2410.05609v3.pdf","comment":"34 pages, 10 figures, accepted by ICLR 2025\n  (https://openreview.net/forum?id=UrKbn51HjA)"},{"id":"http://arxiv.org/abs/2503.10138v1","updated":"2025-03-13T07:56:18Z","published":"2025-03-13T07:56:18Z","title":"Are Convex Optimization Curves Convex?","summary":"  In this paper, we study when we might expect the optimization curve induced\nby gradient descent to be \\emph{convex} -- precluding, for example, an initial\nplateau followed by a sharp decrease, making it difficult to decide when\noptimization should stop. Although such undesirable behavior can certainly\noccur when optimizing general functions, might it also occur in the benign and\nwell-studied case of smooth convex functions? As far as we know, this question\nhas not been tackled in previous work. We show, perhaps surprisingly, that the\nanswer crucially depends on the choice of the step size. In particular, for the\nrange of step sizes which are known to result in monotonic convergence to an\noptimal value, there is a regime where the optimization curve will be provably\nconvex, and there is a regime where the curve can be non-convex. We also extend\nour results to gradient flow, and to the closely-related but different question\nof whether the gradient norm decreases monotonically.\n","authors":["Guy Barzilai","Ohad Shamir"],"pdf_url":"https://arxiv.org/pdf/2503.10138v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2503.10135v1","updated":"2025-03-13T07:55:38Z","published":"2025-03-13T07:55:38Z","title":"Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative\n  Decoding","summary":"  Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.\n","authors":["Jinze Li","Yixing Xu","Haiduo Huang","Xuanwu Yin","Dong Li","Edith C. H. Ngai","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2503.10135v1.pdf","comment":"Paper under review"},{"id":"http://arxiv.org/abs/2501.05031v2","updated":"2025-03-13T07:45:55Z","published":"2025-01-09T07:43:49Z","title":"ECBench: Can Multi-modal Foundation Models Understand the Egocentric\n  World? A Holistic Embodied Cognition Benchmark","summary":"  The enhancement of generalization in robots by large vision-language models\n(LVLMs) is increasingly evident. Therefore, the embodied cognitive abilities of\nLVLMs based on egocentric videos are of great interest. However, current\ndatasets for embodied video question answering lack comprehensive and\nsystematic evaluation frameworks. Critical embodied cognitive issues, such as\nrobotic self-cognition, dynamic scene perception, and hallucination, are rarely\naddressed. To tackle these challenges, we propose ECBench, a high-quality\nbenchmark designed to systematically evaluate the embodied cognitive abilities\nof LVLMs. ECBench features a diverse range of scene video sources, open and\nvaried question formats, and 30 dimensions of embodied cognition. To ensure\nquality, balance, and high visual dependence, ECBench uses class-independent\nmeticulous human annotation and multi-round question screening strategies.\nAdditionally, we introduce ECEval, a comprehensive evaluation system that\nensures the fairness and rationality of the indicators. Utilizing ECBench, we\nconduct extensive evaluations of proprietary, open-source, and task-specific\nLVLMs. ECBench is pivotal in advancing the embodied cognitive capabilities of\nLVLMs, laying a solid foundation for developing reliable core models for\nembodied agents. All data and code are available at\nhttps://github.com/Rh-Dang/ECBench.\n","authors":["Ronghao Dang","Yuqian Yuan","Wenqi Zhang","Yifei Xin","Boqiang Zhang","Long Li","Liuyi Wang","Qinyang Zeng","Xin Li","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2501.05031v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08552v2","updated":"2025-03-13T07:31:10Z","published":"2025-01-15T03:23:06Z","title":"Reinforcement Learning-Enhanced Procedural Generation for Dynamic\n  Narrative-Driven AR Experiences","summary":"  Procedural Content Generation (PCG) is widely used to create scalable and\ndiverse environments in games. However, existing methods, such as the Wave\nFunction Collapse (WFC) algorithm, are often limited to static scenarios and\nlack the adaptability required for dynamic, narrative-driven applications,\nparticularly in augmented reality (AR) games. This paper presents a\nreinforcement learning-enhanced WFC framework designed for mobile AR\nenvironments. By integrating environment-specific rules and dynamic tile weight\nadjustments informed by reinforcement learning (RL), the proposed method\ngenerates maps that are both contextually coherent and responsive to gameplay\nneeds. Comparative evaluations and user studies demonstrate that the framework\nachieves superior map quality and delivers immersive experiences, making it\nwell-suited for narrative-driven AR games. Additionally, the method holds\npromise for broader applications in education, simulation training, and\nimmersive extended reality (XR) experiences, where dynamic and adaptive\nenvironments are critical.\n","authors":["Aniruddha Srinivas Joshi"],"pdf_url":"https://arxiv.org/pdf/2501.08552v2.pdf","comment":"Published in Proceedings of the 20th International Joint Conference\n  on Computer Vision, Imaging and Computer Graphics Theory and Applications -\n  GRAPP 2025\n  https://www.scitepress.org/PublicationsDetail.aspx?ID=LfPv9Lfiya8=&t=1"},{"id":"http://arxiv.org/abs/2503.10118v1","updated":"2025-03-13T07:27:05Z","published":"2025-03-13T07:27:05Z","title":"An Real-Sim-Real (RSR) Loop Framework for Generalizable Robotic Policy\n  Transfer with Differentiable Simulation","summary":"  The sim-to-real gap remains a critical challenge in robotics, hindering the\ndeployment of algorithms trained in simulation to real-world systems. This\npaper introduces a novel Real-Sim-Real (RSR) loop framework leveraging\ndifferentiable simulation to address this gap by iteratively refining\nsimulation parameters, aligning them with real-world conditions, and enabling\nrobust and efficient policy transfer. A key contribution of our work is the\ndesign of an informative cost function that encourages the collection of\ndiverse and representative real-world data, minimizing bias and maximizing the\nutility of each data point for simulation refinement. This cost function\nintegrates seamlessly into existing reinforcement learning algorithms (e.g.,\nPPO, SAC) and ensures a balanced exploration of critical regions in the real\ndomain. Furthermore, our approach is implemented on the versatile Mujoco MJX\nplatform, and our framework is compatible with a wide range of robotic systems.\nExperimental results on several robotic manipulation tasks demonstrate that our\nmethod significantly reduces the sim-to-real gap, achieving high task\nperformance and generalizability across diverse scenarios of both explicit and\nimplicit environmental uncertainties.\n","authors":["Lu Shi","Yuxuan Xu","Shiyu Wang","Jinhao Huang","Wenhao Zhao","Yufei Jia","Zike Yan","Weibin Gu","Guyue Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.10118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18883v2","updated":"2025-03-13T07:23:59Z","published":"2025-01-31T04:34:43Z","title":"Predictive Prompt Analysis","summary":"  Large Language Models (LLMs) are machine learning models that have seen\nwidespread adoption due to their capability of handling previously difficult\ntasks. LLMs, due to their training, are sensitive to how exactly a question is\npresented, also known as prompting. However, prompting well is challenging, as\nit has been difficult to uncover principles behind prompting -- generally,\ntrial-and-error is the most common way of improving prompts, despite its\nsignificant computational cost. In this context, we argue it would be useful to\nperform `predictive prompt analysis', in which an automated technique would\nperform a quick analysis of a prompt and predict how the LLM would react to it,\nrelative to a goal provided by the user. As a demonstration of the concept, we\npresent Syntactic Prevalence Analyzer (SPA), a predictive prompt analysis\napproach based on sparse autoencoders (SAEs). SPA accurately predicted how\noften an LLM would generate target syntactic structures during code synthesis,\nwith up to 0.994 Pearson correlation between the predicted and actual\nprevalence of the target structure. At the same time, SPA requires only 0.4\\%\nof the time it takes to run the LLM on a benchmark. As LLMs are increasingly\nused during and integrated into modern software development, our proposed\npredictive prompt analysis concept has the potential to significantly ease the\nuse of LLMs for both practitioners and researchers.\n","authors":["Jae Yong Lee","Sungmin Kang","Shin Yoo"],"pdf_url":"https://arxiv.org/pdf/2501.18883v2.pdf","comment":"Accepted by FSE 2025, 5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.10115v1","updated":"2025-03-13T07:21:29Z","published":"2025-03-13T07:21:29Z","title":"Reconsidering Feature Structure Information and Latent Space Alignment\n  in Partial Multi-label Feature Selection","summary":"  The purpose of partial multi-label feature selection is to select the most\nrepresentative feature subset, where the data comes from partial multi-label\ndatasets that have label ambiguity issues. For label disambiguation, previous\nmethods mainly focus on utilizing the information inside the labels and the\nrelationship between the labels and features. However, the information existing\nin the feature space is rarely considered, especially in partial multi-label\nscenarios where the noises is considered to be concentrated in the label space\nwhile the feature information is correct. This paper proposes a method based on\nlatent space alignment, which uses the information mined in feature space to\ndisambiguate in latent space through the structural consistency between labels\nand features. In addition, previous methods overestimate the consistency of\nfeatures and labels in the latent space after convergence. We comprehensively\nconsider the similarity of latent space projections to feature space and label\nspace, and propose new feature selection term. This method also significantly\nimproves the positive label identification ability of the selected features.\nComprehensive experiments demonstrate the superiority of the proposed method.\n","authors":["Hanlin Pan","Kunpeng Liu","Wanfu Gao"],"pdf_url":"https://arxiv.org/pdf/2503.10115v1.pdf","comment":"9pages,6 figures,accept at AAAI 25"},{"id":"http://arxiv.org/abs/2312.10052v2","updated":"2025-03-13T07:17:58Z","published":"2023-12-03T12:26:32Z","title":"ESTformer: Transformer Utilizing Spatiotemporal Dependencies for\n  Electroencaphalogram Super-resolution","summary":"  Towards practical applications of Electroencephalography (EEG), lightweight\nacquisition devices garner significant attention. However, EEG channel\nselection methods are commonly data-sensitive and cannot establish a unified\nsound paradigm for EEG acquisition devices. Through reverse conceptualisation,\nwe formulated EEG applications in an EEG super-resolution (SR) manner, but\nsuffered from high computation costs, extra interpolation bias, and few\ninsights into spatiotemporal dependency modelling. To this end, we propose\nESTformer, an EEG SR framework that utilises spatiotemporal dependencies based\non the transformer. ESTformer applies positional encoding methods and a\nmultihead self-attention mechanism to the space and time dimensions, which can\nlearn spatial structural correlations and temporal functional variations.\nESTformer, with the fixed mask strategy, adopts a mask token to upsample\nlow-resolution (LR) EEG data in the case of disturbance from mathematical\ninterpolation methods. On this basis, we designed various transformer blocks to\nconstruct a spatial interpolation module (SIM) and a temporal reconstruction\nmodule (TRM). Finally, ESTformer cascades the SIM and TRM to capture and model\nthe spatiotemporal dependencies for EEG SR with fidelity. Extensive\nexperimental results on two EEG datasets show the effectiveness of ESTformer\nagainst previous state-of-the-art methods, demonstrating the versatility of the\nTransformer for EEG SR tasks. The superiority of the SR data was verified in an\nEEG-based person identification and emotion recognition task, achieving a 2% to\n38% improvement compared with the LR data at different sampling scales.\n","authors":["Dongdong Li","Zhongliang Zeng","Zhe Wang","Hai Yang"],"pdf_url":"https://arxiv.org/pdf/2312.10052v2.pdf","comment":"Accepted by Knowledge-Based Systems"},{"id":"http://arxiv.org/abs/2503.10110v1","updated":"2025-03-13T07:09:00Z","published":"2025-03-13T07:09:00Z","title":"IMPACT: Intelligent Motion Planning with Acceptable Contact Trajectories\n  via Vision-Language Models","summary":"  Motion planning involves determining a sequence of robot configurations to\nreach a desired pose, subject to movement and safety constraints. Traditional\nmotion planning finds collision-free paths, but this is overly restrictive in\nclutter, where it may not be possible for a robot to accomplish a task without\ncontact. In addition, contacts range from relatively benign (e.g., brushing a\nsoft pillow) to more dangerous (e.g., toppling a glass vase). Due to this\ndiversity, it is difficult to characterize which contacts may be acceptable or\nunacceptable. In this paper, we propose IMPACT, a novel motion planning\nframework that uses Vision-Language Models (VLMs) to infer environment\nsemantics, identifying which parts of the environment can best tolerate contact\nbased on object properties and locations. Our approach uses the VLM's outputs\nto produce a dense 3D \"cost map\" that encodes contact tolerances and seamlessly\nintegrates with standard motion planners. We perform experiments using 20\nsimulation and 10 real-world scenes and assess using task success rate, object\ndisplacements, and feedback from human evaluators. Our results over 3620\nsimulation and 200 real-world trials suggest that IMPACT enables efficient\ncontact-rich motion planning in cluttered settings while outperforming\nalternative methods and ablations. Supplementary material is available at\nhttps://impact-planning.github.io/.\n","authors":["Yiyang Ling","Karan Owalekar","Oluwatobiloba Adesanya","Erdem Bıyık","Daniel Seita"],"pdf_url":"https://arxiv.org/pdf/2503.10110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10103v1","updated":"2025-03-13T07:00:27Z","published":"2025-03-13T07:00:27Z","title":"Improving Diffusion-based Inverse Algorithms under Few-Step Constraint\n  via Learnable Linear Extrapolation","summary":"  Diffusion models have demonstrated remarkable performance in modeling complex\ndata priors, catalyzing their widespread adoption in solving various inverse\nproblems. However, the inherently iterative nature of diffusion-based inverse\nalgorithms often requires hundreds to thousands of steps, with performance\ndegradation occurring under fewer steps which limits their practical\napplicability. While high-order diffusion ODE solvers have been extensively\nexplored for efficient diffusion sampling without observations, their\napplication to inverse problems remains underexplored due to the diverse forms\nof inverse algorithms and their need for repeated trajectory correction based\non observations. To address this gap, we first introduce a canonical form that\ndecomposes existing diffusion-based inverse algorithms into three modules to\nunify their analysis. Inspired by the linear subspace search strategy in the\ndesign of high-order diffusion ODE solvers, we propose the Learnable Linear\nExtrapolation (LLE) method, a lightweight approach that universally enhances\nthe performance of any diffusion-based inverse algorithm that fits the proposed\ncanonical form. Extensive experiments demonstrate consistent improvements of\nthe proposed LLE method across multiple algorithms and tasks, indicating its\npotential for more efficient solutions and boosted performance of\ndiffusion-based inverse algorithms with limited steps. Codes for reproducing\nour experiments are available at\n\\href{https://github.com/weigerzan/LLE_inverse_problem}{https://github.com/weigerzan/LLE\\_inverse\\_problem}.\n","authors":["Jiawei Zhang","Ziyuan Liu","Leon Yan","Gen Li","Yuantao Gu"],"pdf_url":"https://arxiv.org/pdf/2503.10103v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2503.06669v2","updated":"2025-03-13T06:59:16Z","published":"2025-03-09T15:40:29Z","title":"AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable\n  and Intelligent Embodied Systems","summary":"  We explore how scalable robot data can address real-world challenges for\ngeneralized robotic manipulation. Introducing AgiBot World, a large-scale\nplatform comprising over 1 million trajectories across 217 tasks in five\ndeployment scenarios, we achieve an order-of-magnitude increase in data scale\ncompared to existing datasets. Accelerated by a standardized collection\npipeline with human-in-the-loop verification, AgiBot World guarantees\nhigh-quality and diverse data distribution. It is extensible from grippers to\ndexterous hands and visuo-tactile sensors for fine-grained skill acquisition.\nBuilding on top of data, we introduce Genie Operator-1 (GO-1), a novel\ngeneralist policy that leverages latent action representations to maximize data\nutilization, demonstrating predictable performance scaling with increased data\nvolume. Policies pre-trained on our dataset achieve an average performance\nimprovement of 30% over those trained on Open X-Embodiment, both in in-domain\nand out-of-distribution scenarios. GO-1 exhibits exceptional capability in\nreal-world dexterous and long-horizon tasks, achieving over 60% success rate on\ncomplex tasks and outperforming prior RDT approach by 32%. By open-sourcing the\ndataset, tools, and models, we aim to democratize access to large-scale,\nhigh-quality robot data, advancing the pursuit of scalable and general-purpose\nintelligence.\n","authors":[" AgiBot-World-Contributors","Qingwen Bu","Jisong Cai","Li Chen","Xiuqi Cui","Yan Ding","Siyuan Feng","Shenyuan Gao","Xindong He","Xu Huang","Shu Jiang","Yuxin Jiang","Cheng Jing","Hongyang Li","Jialu Li","Chiming Liu","Yi Liu","Yuxiang Lu","Jianlan Luo","Ping Luo","Yao Mu","Yuehan Niu","Yixuan Pan","Jiangmiao Pang","Yu Qiao","Guanghui Ren","Cheng Ruan","Jiaqi Shan","Yongjian Shen","Chengshi Shi","Mingkang Shi","Modi Shi","Chonghao Sima","Jianheng Song","Huijie Wang","Wenhao Wang","Dafeng Wei","Chengen Xie","Guo Xu","Junchi Yan","Cunbiao Yang","Lei Yang","Shukai Yang","Maoqing Yao","Jia Zeng","Chi Zhang","Qinglin Zhang","Bin Zhao","Chengyue Zhao","Jiaqi Zhao","Jianchao Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.06669v2.pdf","comment":"Project website: https://agibot-world.com/. Github repo:\n  https://github.com/OpenDriveLab/AgiBot-World. The author list is ordered\n  alphabetically by surname, with detailed contributions provided in the\n  appendix"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2503.10638v1","updated":"2025-03-13T17:59:59Z","published":"2025-03-13T17:59:59Z","title":"Studying Classifier(-Free) Guidance From a Classifier-Centric\n  Perspective","summary":"  Classifier-free guidance has become a staple for conditional generation with\ndenoising diffusion models. However, a comprehensive understanding of\nclassifier-free guidance is still missing. In this work, we carry out an\nempirical study to provide a fresh perspective on classifier-free guidance.\nConcretely, instead of solely focusing on classifier-free guidance, we trace\nback to the root, i.e., classifier guidance, pinpoint the key assumption for\nthe derivation, and conduct a systematic study to understand the role of the\nclassifier. We find that both classifier guidance and classifier-free guidance\nachieve conditional generation by pushing the denoising diffusion trajectories\naway from decision boundaries, i.e., areas where conditional information is\nusually entangled and is hard to learn. Based on this classifier-centric\nunderstanding, we propose a generic postprocessing step built upon\nflow-matching to shrink the gap between the learned distribution for a\npre-trained denoising diffusion model and the real data distribution, majorly\naround the decision boundaries. Experiments on various datasets verify the\neffectiveness of the proposed approach.\n","authors":["Xiaoming Zhao","Alexander G. Schwing"],"pdf_url":"https://arxiv.org/pdf/2503.10638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10635v1","updated":"2025-03-13T17:59:55Z","published":"2025-03-13T17:59:55Z","title":"A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90%\n  Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1","summary":"  Despite promising performance on open-source large vision-language models\n(LVLMs), transfer-based targeted attacks often fail against black-box\ncommercial LVLMs. Analyzing failed adversarial perturbations reveals that the\nlearned perturbations typically originate from a uniform distribution and lack\nclear semantic details, resulting in unintended responses. This critical\nabsence of semantic information leads commercial LVLMs to either ignore the\nperturbation entirely or misinterpret its embedded semantics, thereby causing\nthe attack to fail. To overcome these issues, we notice that identifying core\nsemantic objects is a key objective for models trained with various datasets\nand methodologies. This insight motivates our approach that refines semantic\nclarity by encoding explicit semantic details within local regions, thus\nensuring interoperability and capturing finer-grained features, and by\nconcentrating modifications on semantically rich areas rather than applying\nthem uniformly. To achieve this, we propose a simple yet highly effective\nsolution: at each optimization step, the adversarial image is cropped randomly\nby a controlled aspect ratio and scale, resized, and then aligned with the\ntarget image in the embedding space. Experimental results confirm our\nhypothesis. Our adversarial examples crafted with local-aggregated\nperturbations focused on crucial regions exhibit surprisingly good\ntransferability to commercial LVLMs, including GPT-4.5, GPT-4o,\nGemini-2.0-flash, Claude-3.5-sonnet, Claude-3.7-sonnet, and even reasoning\nmodels like o1, Claude-3.7-thinking and Gemini-2.0-flash-thinking. Our approach\nachieves success rates exceeding 90% on GPT-4.5, 4o, and o1, significantly\noutperforming all prior state-of-the-art attack methods. Our optimized\nadversarial examples under different configurations and training code are\navailable at https://github.com/VILA-Lab/M-Attack.\n","authors":["Zhaoyi Li","Xiaohan Zhao","Dong-Dong Wu","Jiacheng Cui","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2503.10635v1.pdf","comment":"Code at: https://github.com/VILA-Lab/M-Attack"},{"id":"http://arxiv.org/abs/2503.10628v1","updated":"2025-03-13T17:59:41Z","published":"2025-03-13T17:59:41Z","title":"Uncertainty in Action: Confidence Elicitation in Embodied Agents","summary":"  Expressing confidence is challenging for embodied agents navigating dynamic\nmultimodal environments, where uncertainty arises from both perception and\ndecision-making processes. We present the first work investigating embodied\nconfidence elicitation in open-ended multimodal environments. We introduce\nElicitation Policies, which structure confidence assessment across inductive,\ndeductive, and abductive reasoning, along with Execution Policies, which\nenhance confidence calibration through scenario reinterpretation, action\nsampling, and hypothetical reasoning. Evaluating agents in calibration and\nfailure prediction tasks within the Minecraft environment, we show that\nstructured reasoning approaches, such as Chain-of-Thoughts, improve confidence\ncalibration. However, our findings also reveal persistent challenges in\ndistinguishing uncertainty, particularly under abductive settings, underscoring\nthe need for more sophisticated embodied confidence elicitation methods.\n","authors":["Tianjiao Yu","Vedant Shah","Muntasir Wahed","Kiet A. Nguyen","Adheesh Juvekar","Tal August","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2503.10628v1.pdf","comment":"Project page: https://plan-lab.github.io/ece/"},{"id":"http://arxiv.org/abs/2503.10627v1","updated":"2025-03-13T17:59:32Z","published":"2025-03-13T17:59:32Z","title":"SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of\n  LMMs on Multi-modal Scientific Problems","summary":"  The rapid advancement of Large Multi-modal Models (LMMs) has enabled their\napplication in scientific problem-solving, yet their fine-grained capabilities\nremain under-explored. In this paper, we introduce SciVerse, a multi-modal\nscientific evaluation benchmark to thoroughly assess LMMs across 5,735 test\ninstances in five distinct versions. We aim to investigate three key dimensions\nof LMMs: scientific knowledge comprehension, multi-modal content\ninterpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs\npossess sufficient scientific expertise, we first transform each problem into\nthree versions containing different levels of knowledge required for solving,\ni.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret\nmulti-modal scientific content, we annotate another two versions, i.e.,\nVision-rich and -only, marking more question information from texts to\ndiagrams. Comparing the results of different versions, SciVerse systematically\nexamines the professional knowledge stock and visual perception skills of LMMs\nin scientific domains. In addition, to rigorously assess CoT reasoning, we\npropose a new scientific CoT evaluation strategy, conducting a step-wise\nassessment on knowledge and logical errors in model outputs. Our extensive\nevaluation of different LMMs on SciVerse reveals critical limitations in their\nscientific proficiency and provides new insights into future developments.\nProject page: https://sciverse-cuhk.github.io\n","authors":["Ziyu Guo","Ray Zhang","Hao Chen","Jialin Gao","Dongzhi Jiang","Jiaze Wang","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2503.10627v1.pdf","comment":"Initially released in September 2024. Project page:\n  https://sciverse-cuhk.github.io"},{"id":"http://arxiv.org/abs/2503.10626v1","updated":"2025-03-13T17:59:24Z","published":"2025-03-13T17:59:24Z","title":"NIL: No-data Imitation Learning by Leveraging Pre-trained Video\n  Diffusion Models","summary":"  Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.\n","authors":["Mert Albaba","Chenhao Li","Markos Diomataris","Omid Taheri","Andreas Krause","Michael Black"],"pdf_url":"https://arxiv.org/pdf/2503.10626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10625v1","updated":"2025-03-13T17:59:21Z","published":"2025-03-13T17:59:21Z","title":"LHM: Large Animatable Human Reconstruction Model from a Single Image in\n  Seconds","summary":"  Animatable 3D human reconstruction from a single image is a challenging\nproblem due to the ambiguity in decoupling geometry, appearance, and\ndeformation. Recent advances in 3D human reconstruction mainly focus on static\nhuman modeling, and the reliance of using synthetic 3D scans for training\nlimits their generalization ability. Conversely, optimization-based video\nmethods achieve higher fidelity but demand controlled capture conditions and\ncomputationally intensive refinement processes. Motivated by the emergence of\nlarge reconstruction models for efficient static reconstruction, we propose LHM\n(Large Animatable Human Reconstruction Model) to infer high-fidelity avatars\nrepresented as 3D Gaussian splatting in a feed-forward pass. Our model\nleverages a multimodal transformer architecture to effectively encode the human\nbody positional features and image features with attention mechanism, enabling\ndetailed preservation of clothing geometry and texture. To further boost the\nface identity preservation and fine detail recovery, we propose a head feature\npyramid encoding scheme to aggregate multi-scale features of the head regions.\nExtensive experiments demonstrate that our LHM generates plausible animatable\nhuman in seconds without post-processing for face and hands, outperforming\nexisting methods in both reconstruction accuracy and generalization ability.\n","authors":["Lingteng Qiu","Xiaodong Gu","Peihao Li","Qi Zuo","Weichao Shen","Junfei Zhang","Kejie Qiu","Weihao Yuan","Guanying Chen","Zilong Dong","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2503.10625v1.pdf","comment":"Project Page: https://lingtengqiu.github.io/LHM/"},{"id":"http://arxiv.org/abs/2503.10624v1","updated":"2025-03-13T17:59:14Z","published":"2025-03-13T17:59:14Z","title":"ETCH: Generalizing Body Fitting to Clothed Humans via Equivariant\n  Tightness","summary":"  Fitting a body to a 3D clothed human point cloud is a common yet challenging\ntask. Traditional optimization-based approaches use multi-stage pipelines that\nare sensitive to pose initialization, while recent learning-based methods often\nstruggle with generalization across diverse poses and garment types. We propose\nEquivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline\nthat estimates cloth-to-body surface mapping through locally approximate SE(3)\nequivariance, encoding tightness as displacement vectors from the cloth surface\nto the underlying body. Following this mapping, pose-invariant body features\nregress sparse body markers, simplifying clothed human fitting into an\ninner-body marker fitting task. Extensive experiments on CAPE and 4D-Dress show\nthat ETCH significantly outperforms state-of-the-art methods -- both\ntightness-agnostic and tightness-aware -- in body fitting accuracy on loose\nclothing (16.7% ~ 69.5%) and shape accuracy (average 49.9%). Our equivariant\ntightness design can even reduce directional errors by (67.2% ~ 89.8%) in\none-shot (or out-of-distribution) settings. Qualitative results demonstrate\nstrong generalization of ETCH, regardless of challenging poses, unseen shapes,\nloose clothing, and non-rigid dynamics. We will release the code and models\nsoon for research purposes at https://boqian-li.github.io/ETCH/.\n","authors":["Boqian Li","Haiwen Feng","Zeyu Cai","Michael J. Black","Yuliang Xiu"],"pdf_url":"https://arxiv.org/pdf/2503.10624v1.pdf","comment":"Page: https://boqian-li.github.io/ETCH/, Code:\n  https://github.com/boqian-li/ETCH"},{"id":"http://arxiv.org/abs/2503.10622v1","updated":"2025-03-13T17:59:06Z","published":"2025-03-13T17:59:06Z","title":"Transformers without Normalization","summary":"  Normalization layers are ubiquitous in modern neural networks and have long\nbeen considered essential. This work demonstrates that Transformers without\nnormalization can achieve the same or better performance using a remarkably\nsimple technique. We introduce Dynamic Tanh (DyT), an element-wise operation\n$DyT($x$) = \\tanh(\\alpha $x$)$, as a drop-in replacement for normalization\nlayers in Transformers. DyT is inspired by the observation that layer\nnormalization in Transformers often produces tanh-like, $S$-shaped input-output\nmappings. By incorporating DyT, Transformers without normalization can match or\nexceed the performance of their normalized counterparts, mostly without\nhyperparameter tuning. We validate the effectiveness of Transformers with DyT\nacross diverse settings, ranging from recognition to generation, supervised to\nself-supervised learning, and computer vision to language models. These\nfindings challenge the conventional understanding that normalization layers are\nindispensable in modern neural networks, and offer new insights into their role\nin deep networks.\n","authors":["Jiachen Zhu","Xinlei Chen","Kaiming He","Yann LeCun","Zhuang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.10622v1.pdf","comment":"CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/"},{"id":"http://arxiv.org/abs/2503.10619v1","updated":"2025-03-13T17:57:32Z","published":"2025-03-13T17:57:32Z","title":"Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with\n  Tree Search","summary":"  We introduce Siege, a multi-turn adversarial framework that models the\ngradual erosion of Large Language Model (LLM) safety through a tree search\nperspective. Unlike single-turn jailbreaks that rely on one meticulously\nengineered prompt, Siege expands the conversation at each turn in a\nbreadth-first fashion, branching out multiple adversarial prompts that exploit\npartial compliance from previous responses. By tracking these incremental\npolicy leaks and re-injecting them into subsequent queries, Siege reveals how\nminor concessions can accumulate into fully disallowed outputs. Evaluations on\nthe JailbreakBench dataset show that Siege achieves a 100% success rate on\nGPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries\nthan baselines such as Crescendo or GOAT. This tree search methodology offers\nan in-depth view of how model safeguards degrade over successive dialogue\nturns, underscoring the urgency of robust multi-turn testing procedures for\nlanguage models.\n","authors":["Andy Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.10619v1.pdf","comment":"Accepted to ICLR 2025 Trustworthy LLM"},{"id":"http://arxiv.org/abs/2503.10617v1","updated":"2025-03-13T17:57:04Z","published":"2025-03-13T17:57:04Z","title":"Compositional Subspace Representation Fine-tuning for Adaptive Large\n  Language Models","summary":"  Adapting large language models to multiple tasks can cause cross-skill\ninterference, where improvements for one skill degrade another. While methods\nsuch as LoRA impose orthogonality constraints at the weight level, they do not\nfully address interference in hidden-state representations. We propose\nCompositional Subspace Representation Fine-tuning (CS-ReFT), a novel\nrepresentation-based approach that learns multiple orthonormal subspace\ntransformations, each specializing in a distinct skill, and composes them via a\nlightweight router. By isolating these subspace edits in the hidden state,\nrather than weight matrices, CS-ReFT prevents cross-task conflicts more\neffectively. On the AlpacaEval benchmark, applying CS-ReFT to Llama-2-7B\nachieves a 93.94% win rate, surpassing GPT-3.5 Turbo (86.30%) while requiring\nonly 0.0098% of model parameters. These findings show that specialized\nrepresentation edits, composed via a simple router, significantly enhance\nmulti-task instruction following with minimal overhead.\n","authors":["Andy Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.10617v1.pdf","comment":"Accepted to ICLR 2025 SCOPE"},{"id":"http://arxiv.org/abs/2503.08679v2","updated":"2025-03-13T17:49:58Z","published":"2025-03-11T17:56:30Z","title":"Chain-of-Thought Reasoning In The Wild Is Not Always Faithful","summary":"  Chain-of-Thought (CoT) reasoning has significantly advanced state-of-the-art\nAI capabilities. However, recent studies have shown that CoT reasoning is not\nalways faithful, i.e. CoT reasoning does not always reflect how models arrive\nat conclusions. So far, most of these studies have focused on unfaithfulness in\nunnatural contexts where an explicit bias has been introduced. In contrast, we\nshow that unfaithful CoT can occur on realistic prompts with no artificial\nbias. Our results reveal non-negligible rates of several forms of unfaithful\nreasoning in frontier models: Sonnet 3.7 (16.3%), DeepSeek R1 (5.3%) and\nChatGPT-4o (7.0%) all answer a notable proportion of question pairs\nunfaithfully. Specifically, we find that models rationalize their implicit\nbiases in answers to binary questions (\"implicit post-hoc rationalization\").\nFor example, when separately presented with the questions \"Is X bigger than Y?\"\nand \"Is Y bigger than X?\", models sometimes produce superficially coherent\narguments to justify answering Yes to both questions or No to both questions,\ndespite such responses being logically contradictory. We also investigate\nrestoration errors (Dziri et al., 2023), where models make and then silently\ncorrect errors in their reasoning, and unfaithful shortcuts, where models use\nclearly illogical reasoning to simplify solving problems in Putnam questions (a\nhard benchmark). Our findings raise challenges for AI safety work that relies\non monitoring CoT to detect undesired behavior.\n","authors":["Iván Arcuschin","Jett Janiak","Robert Krzyzanowski","Senthooran Rajamanoharan","Neel Nanda","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2503.08679v2.pdf","comment":"Accepted to the Reasoning and Planning for Large Language Models\n  Workshop (ICLR 25), 10 main paper pages, 38 appendix pages"},{"id":"http://arxiv.org/abs/2503.10603v1","updated":"2025-03-13T17:46:16Z","published":"2025-03-13T17:46:16Z","title":"Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional\n  Mimicry Intensity Estimation","summary":"  Emotional Mimicry Intensity (EMI) estimation serves as a critical technology\nfor understanding human social behavior and enhancing human-computer\ninteraction experiences, where the core challenge lies in dynamic correlation\nmodeling and robust fusion of multimodal temporal signals. To address the\nlimitations of existing methods in insufficient exploitation of modal\nsynergistic effects, noise sensitivity, and limited fine-grained alignment\ncapabilities, this paper proposes a dual-stage cross-modal alignment framework.\nFirst, we construct vision-text and audio-text contrastive learning networks\nbased on an improved CLIP architecture, achieving preliminary alignment in the\nfeature space through modality-decoupled pre-training. Subsequently, we design\na temporal-aware dynamic fusion module that combines Temporal Convolutional\nNetworks (TCN) and gated bidirectional LSTM to respectively capture the\nmacro-evolution patterns of facial expressions and local dynamics of acoustic\nfeatures. Innovatively, we introduce a quality-guided modality fusion strategy\nthat enables modality compensation under occlusion and noisy scenarios through\ndifferentiable weight allocation. Experimental results on the Hume-Vidmimic2\ndataset demonstrate that our method achieves an average Pearson correlation\ncoefficient of 0.35 across six emotion dimensions, outperforming the best\nbaseline by 40\\%. Ablation studies further validate the effectiveness of the\ndual-stage training strategy and dynamic fusion mechanism, providing a novel\ntechnical pathway for fine-grained emotion analysis in open environments.\n","authors":["Jun Yu","Lingsi Zhu","Yanjun Chi","Yunxiang Zhang","Yang Zheng","Yongqi Wang","Xilong Lu"],"pdf_url":"https://arxiv.org/pdf/2503.10603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10602v1","updated":"2025-03-13T17:46:06Z","published":"2025-03-13T17:46:06Z","title":"TruthPrInt: Mitigating LVLM Object Hallucination Via Latent\n  Truthful-Guided Pre-Intervention","summary":"  Object Hallucination (OH) has been acknowledged as one of the major\ntrustworthy challenges in Large Vision-Language Models (LVLMs). Recent\nadvancements in Large Language Models (LLMs) indicate that internal states,\nsuch as hidden states, encode the \"overall truthfulness\" of generated\nresponses. However, it remains under-explored how internal states in LVLMs\nfunction and whether they could serve as \"per-token\" hallucination indicators,\nwhich is essential for mitigating OH. In this paper, we first conduct an\nin-depth exploration of LVLM internal states in relation to OH issues and\ndiscover that (1) LVLM internal states are high-specificity per-token\nindicators of hallucination behaviors. Moreover, (2) different LVLMs encode\nuniversal patterns of hallucinations in common latent subspaces, indicating\nthat there exist \"generic truthful directions\" shared by various LVLMs. Based\non these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt)\nthat first learns the truthful direction of LVLM decoding and then applies\ntruthful-guided inference-time intervention during LVLM decoding. We further\npropose ComnHallu to enhance both cross-LVLM and cross-data hallucination\ndetection transferability by constructing and aligning hallucination latent\nsubspaces. We evaluate TruthPrInt in extensive experimental settings, including\nin-domain and out-of-domain scenarios, over popular LVLMs and OH benchmarks.\nExperimental results indicate that TruthPrInt significantly outperforms\nstate-of-the-art methods. Codes will be available at\nhttps://github.com/jinhaoduan/TruthPrInt.\n","authors":["Jinhao Duan","Fei Kong","Hao Cheng","James Diffenderfer","Bhavya Kailkhura","Lichao Sun","Xiaofeng Zhu","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.10602v1.pdf","comment":"15 pages, 9 figures, the first two authors contributed equally"},{"id":"http://arxiv.org/abs/2503.10587v1","updated":"2025-03-13T17:36:46Z","published":"2025-03-13T17:36:46Z","title":"The Spectral Bias of Shallow Neural Network Learning is Shaped by the\n  Choice of Non-linearity","summary":"  Despite classical statistical theory predicting severe overfitting, modern\nmassively overparameterized neural networks still generalize well. This\nunexpected property is attributed to the network's so-called implicit bias,\nwhich describes its propensity to converge to solutions that generalize\neffectively, among the many possible that correctly label the training data.\nThe aim of our research is to explore this bias from a new perspective,\nfocusing on how non-linear activation functions contribute to shaping it.\nFirst, we introduce a reparameterization which removes a continuous weight\nrescaling symmetry. Second, in the kernel regime, we leverage this\nreparameterization to generalize recent findings that relate shallow Neural\nNetworks to the Radon transform, deriving an explicit formula for the implicit\nbias induced by a broad class of activation functions. Specifically, by\nutilizing the connection between the Radon transform and the Fourier transform,\nwe interpret the kernel regime's inductive bias as minimizing a spectral\nseminorm that penalizes high-frequency components, in a manner dependent on the\nactivation function. Finally, in the adaptive regime, we demonstrate the\nexistence of local dynamical attractors that facilitate the formation of\nclusters of hyperplanes where the input to a neuron's activation function is\nzero, yielding alignment between many neurons' response functions. We confirm\nthese theoretical results with simulations. All together, our work provides a\ndeeper understanding of the mechanisms underlying the generalization\ncapabilities of overparameterized neural networks and its relation with the\nimplicit bias, offering potential pathways for designing more efficient and\nrobust models.\n","authors":["Justin Sahs","Ryan Pyle","Fabio Anselmi","Ankit Patel"],"pdf_url":"https://arxiv.org/pdf/2503.10587v1.pdf","comment":"18 pages, 10 figures in main text"},{"id":"http://arxiv.org/abs/2403.03185v4","updated":"2025-03-13T17:35:13Z","published":"2024-03-05T18:22:15Z","title":"Correlated Proxies: A New Definition and Improved Mitigation for Reward\n  Hacking","summary":"  Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using proxy reward\nfunctions that only approximate the true goal. However, optimizing proxy\nrewards frequently leads to reward hacking: the optimized reward function\nceases to be a good proxy and the resulting policy performs poorly with respect\nto the unspecified true reward. Principled solutions to reward hacking have\nbeen impeded by the lack of a good definition for the problem. To address this\ngap, we introduce a definition of reward hacking based on the correlation\nbetween proxy and true rewards for states and actions seen by a \"reference\npolicy\" that breaks down under optimization. We show that this definition\ncaptures reward hacking behavior across several realistic settings, including\nin reinforcement learning from human feedback (RLHF). Using our formulation, we\nshow theoretically that regularization to the reference policy can effectively\nprevent reward hacking. While the current practice in RLHF applies a KL penalty\nbetween action distributions for this purpose, our theory suggests regularizing\nthe $\\chi^2$ divergence between the policies' occupancy measures can be more\neffective. We intuitively show the benefits of this type of regularization and\ndemonstrate that it better mitigates reward hacking in practice across four\nrealistic settings, including RLHF. Our code is available at\nhttps://github.com/cassidylaidlaw/orpo.\n","authors":["Cassidy Laidlaw","Shivam Singhal","Anca Dragan"],"pdf_url":"https://arxiv.org/pdf/2403.03185v4.pdf","comment":"Spotlight at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10582v1","updated":"2025-03-13T17:32:48Z","published":"2025-03-13T17:32:48Z","title":"VisualWebInstruct: Scaling up Multimodal Instruction Data through Web\n  Search","summary":"  Vision-Language Models have made significant progress on many\nperception-focused tasks, however, their progress on reasoning-focused tasks\nseem to be limited due to the lack of high-quality and diverse training data.\nIn this work, we aim to address the scarcity issue of reasoning-focused\nmultimodal datasets. We propose VisualWebInstruct - a novel approach that\nleverages search engine to create a diverse, and high-quality dataset spanning\nmultiple disciplines like math, physics, finance, chemistry, etc. Starting with\nmeticulously selected 30,000 seed images, we employ Google Image search to\nidentify websites containing similar images. We collect and process the HTMLs\nfrom over 700K unique URL sources. Through a pipeline of content extraction,\nfiltering and synthesis, we build a dataset of approximately 900K\nquestion-answer pairs, with 40% being visual QA pairs and the rest as text QA\npairs. Models fine-tuned on VisualWebInstruct demonstrate significant\nperformance gains: (1) training from Llava-OV-mid shows 10-20% absolute point\ngains across benchmarks, (2) training from MAmmoTH-VL shows 5% absoluate gain.\nOur best model MAmmoTH-VL2 shows state-of-the-art performance within the 10B\nparameter class on MMMU-Pro-std (40.7%), MathVerse (42.6%), and DynaMath\n(55.7%). These remarkable results highlight the effectiveness of our dataset in\nenhancing VLMs' reasoning capabilities for complex multimodal tasks.\n","authors":["Yiming Jia","Jiachen Li","Xiang Yue","Bo Li","Ping Nie","Kai Zou","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10582v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.06215v3","updated":"2025-03-13T17:30:48Z","published":"2024-10-08T17:20:37Z","title":"DataEnvGym: Data Generation Agents in Teacher Environments with Student\n  Feedback","summary":"  The process of creating training data to teach models is currently driven by\nhumans, who manually analyze model weaknesses and plan how to create data that\nimproves a student model. Approaches using LLMs as annotators reduce human\neffort, but still require humans to interpret feedback from evaluations and\ncontrol the LLM to produce data the student needs. Automating this\nlabor-intensive process by creating autonomous data generation agents - or\nteachers - is desirable, but requires environments that can simulate the\nfeedback-driven, iterative, closed loop of data creation. To enable rapid,\nscalable testing for such agents and their modules, we introduce DataEnvGym, a\ntestbed of teacher environments for data generation agents. DataEnvGym frames\ndata generation as a sequential decision-making task, involving an agent\nconsisting of a data generation policy (which generates a plan for creating\ntraining data) and a data generation engine (which transforms the plan into\ndata), inside an environment that provides student feedback. The agent's goal\nis to improve student performance. Students are iteratively trained and\nevaluated on generated data, and their feedback (in the form of errors or weak\nskills) is reported to the agent after each iteration. DataEnvGym includes\nmultiple teacher environment instantiations across 3 levels of structure in the\nstate representation and action space. More structured environments are based\non inferred skills and offer more interpretability and curriculum control. We\nsupport 4 domains (math, code, VQA, and tool-use) and test multiple students\nand teachers. Example agents in our teaching environments can iteratively\nimprove students across tasks and settings. Moreover, we show that environments\nteach different skill levels and test variants of key modules, pointing to\nfuture work in improving data generation agents, engines, and feedback\nmechanisms.\n","authors":["Zaid Khan","Elias Stengel-Eskin","Jaemin Cho","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2410.06215v3.pdf","comment":"ICLR 2025 Spotlight; Project Page: https://DataEnvGym.github.io"},{"id":"http://arxiv.org/abs/2503.10546v1","updated":"2025-03-13T16:59:17Z","published":"2025-03-13T16:59:17Z","title":"KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for\n  Open-Vocabulary Robotic Manipulation","summary":"  With the rapid advancement of large language models (LLMs) and\nvision-language models (VLMs), significant progress has been made in developing\nopen-vocabulary robotic manipulation systems. However, many existing approaches\noverlook the importance of object dynamics, limiting their applicability to\nmore complex, dynamic tasks. In this work, we introduce KUDA, an\nopen-vocabulary manipulation system that integrates dynamics learning and\nvisual prompting through keypoints, leveraging both VLMs and learning-based\nneural dynamics models. Our key insight is that a keypoint-based target\nspecification is simultaneously interpretable by VLMs and can be efficiently\ntranslated into cost functions for model-based planning. Given language\ninstructions and visual observations, KUDA first assigns keypoints to the RGB\nimage and queries the VLM to generate target specifications. These abstract\nkeypoint-based representations are then converted into cost functions, which\nare optimized using a learned dynamics model to produce robotic trajectories.\nWe evaluate KUDA on a range of manipulation tasks, including free-form language\ninstructions across diverse object categories, multi-object interactions, and\ndeformable or granular objects, demonstrating the effectiveness of our\nframework. The project page is available at http://kuda-dynamics.github.io.\n","authors":["Zixian Liu","Mingtong Zhang","Yunzhu Li"],"pdf_url":"https://arxiv.org/pdf/2503.10546v1.pdf","comment":"Project website: http://kuda-dynamics.github.io"},{"id":"http://arxiv.org/abs/2503.10542v1","updated":"2025-03-13T16:56:47Z","published":"2025-03-13T16:56:47Z","title":"Language Models, Graph Searching, and Supervision Adulteration: When\n  More Supervision is Less and How to Make More More","summary":"  This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction.\n","authors":["Arvid Frydenlund"],"pdf_url":"https://arxiv.org/pdf/2503.10542v1.pdf","comment":"A reduced version of this work has been accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025. Full version under review"},{"id":"http://arxiv.org/abs/2503.10539v1","updated":"2025-03-13T16:52:43Z","published":"2025-03-13T16:52:43Z","title":"GBSVR: Granular Ball Support Vector Regression","summary":"  Support Vector Regression (SVR) and its variants are widely used to handle\nregression tasks, however, since their solution involves solving an expensive\nquadratic programming problem, it limits its application, especially when\ndealing with large datasets. Additionally, SVR uses an epsilon-insensitive loss\nfunction which is sensitive to outliers and therefore can adversely affect its\nperformance. We propose Granular Ball Support Vector Regression (GBSVR) to\ntackle problem of regression by using granular ball concept. These balls are\nuseful in simplifying complex data spaces for machine learning tasks, however,\nto the best of our knowledge, they have not been sufficiently explored for\nregression problems. Granular balls group the data points into balls based on\ntheir proximity and reduce the computational cost in SVR by replacing the large\nnumber of data points with far fewer granular balls. This work also suggests a\ndiscretization method for continuous-valued attributes to facilitate the\nconstruction of granular balls. The effectiveness of the proposed approach is\nevaluated on several benchmark datasets and it outperforms existing\nstate-of-the-art approaches\n","authors":["Reshma Rastogi","Ankush Bisht","Sanjay Kumar","Suresh Chandra"],"pdf_url":"https://arxiv.org/pdf/2503.10539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18548v3","updated":"2025-03-13T16:48:34Z","published":"2025-02-25T15:56:56Z","title":"What is the Alignment Objective of GRPO?","summary":"  In this note, we examine the aggregation of preferences achieved by the Group\nPolicy Optimisation (GRPO) algorithm, a reinforcement learning method used to\ntrain advanced artificial intelligence models such as DeepSeek-R1-Zero and\nDeepSeekMath. The GRPO algorithm trains a policy using a reward preference\nmodel, which is computed by sampling a set of outputs for a given context,\nobserving the corresponding rewards, and applying shift-and-scale normalisation\nto these reward values. Additionally, it incorporates a penalty function to\ndiscourage deviations from a reference policy.\n  We present a framework that enables us to characterise the stationary\npolicies of the GRPO algorithm. This analysis reveals that the aggregation of\npreferences differs fundamentally from standard logarithmic pooling, which is\nimplemented by other approaches such as RLHF. The precise form of preference\naggregation arises from the way the reward preference model is defined and from\nthe penalty function, which we show to essentially correspond to the reverse\nKullback-Leibler (KL) divergence between the aggregation policy and the\nreference policy.\n  Interestingly, we demonstrate that for groups of size two, the reward\npreference model corresponds to pairwise comparison preferences, similar to\nthose in other alignment methods based on pairwise comparison feedback. We\nprovide explicit characterisations of the aggregate preference for binary\nquestions, for groups of size two, and in the limit of large group size. This\nprovides insights into the dependence of the aggregate preference on parameters\nsuch as the regularisation constant and the confidence margin of question\nanswers.\n  Finally, we discuss the aggregation of preferences obtained by modifying the\nGRPO algorithm to use direct KL divergence as the penalty or to use rewards\nwithout scale normalisation.\n","authors":["Milan Vojnovic","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2502.18548v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10533v1","updated":"2025-03-13T16:47:07Z","published":"2025-03-13T16:47:07Z","title":"The Impact of Item-Writing Flaws on Difficulty and Discrimination in\n  Item Response Theory","summary":"  High-quality test items are essential for educational assessments,\nparticularly within Item Response Theory (IRT). Traditional validation methods\nrely on resource-intensive pilot testing to estimate item difficulty and\ndiscrimination. More recently, Item-Writing Flaw (IWF) rubrics emerged as a\ndomain-general approach for evaluating test items based on textual features.\nHowever, their relationship to IRT parameters remains underexplored. To address\nthis gap, we conducted a study involving over 7,000 multiple-choice questions\nacross various STEM subjects (e.g., math and biology). Using an automated\napproach, we annotated each question with a 19-criteria IWF rubric and studied\nrelationships to data-driven IRT parameters. Our analysis revealed\nstatistically significant links between the number of IWFs and IRT difficulty\nand discrimination parameters, particularly in life and physical science\ndomains. We further observed how specific IWF criteria can impact item quality\nmore and less severely (e.g., negative wording vs. implausible distractors).\nOverall, while IWFs are useful for predicting IRT parameters--particularly for\nscreening low-difficulty MCQs--they cannot replace traditional data-driven\nvalidation methods. Our findings highlight the need for further research on\ndomain-general evaluation rubrics and algorithms that understand\ndomain-specific content for robust item validation.\n","authors":["Robin Schmucker","Steven Moore"],"pdf_url":"https://arxiv.org/pdf/2503.10533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10530v1","updated":"2025-03-13T16:38:33Z","published":"2025-03-13T16:38:33Z","title":"Lightweight Models for Emotional Analysis in Video","summary":"  In this study, we present an approach for efficient spatiotemporal feature\nextraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal\naggregation module. MobileNetV4, with its Universal Inverted Bottleneck (UIB)\nblocks, serves as the backbone for extracting hierarchical feature\nrepresentations from input image sequences, ensuring both computational\nefficiency and rich semantic encoding. To capture temporal dependencies, we\nintroduce a three-level MLP-Mixer module, which processes spatial features at\nmultiple resolutions while maintaining structural integrity. Experimental\nresults on the ABAW 8th competition demonstrate the effectiveness of our\napproach, showing promising performance in affective behavior analysis. By\nintegrating an efficient vision backbone with a structured temporal modeling\nmechanism, the proposed framework achieves a balance between computational\nefficiency and predictive accuracy, making it well-suited for real-time\napplications in mobile and embedded computing environments.\n","authors":["Quoc-Tien Nguyen","Hong-Hai Nguyen","Van-Thong Huynh"],"pdf_url":"https://arxiv.org/pdf/2503.10530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10529v1","updated":"2025-03-13T16:37:26Z","published":"2025-03-13T16:37:26Z","title":"PiSA: A Self-Augmented Data Engine and Training Strategy for 3D\n  Understanding with Large Models","summary":"  3D Multimodal Large Language Models (MLLMs) have recently made substantial\nadvancements. However, their potential remains untapped, primarily due to the\nlimited quantity and suboptimal quality of 3D datasets. Current approaches\nattempt to transfer knowledge from 2D MLLMs to expand 3D instruction data, but\nstill face modality and domain gaps. To this end, we introduce PiSA-Engine\n(Point-Self-Augmented-Engine), a new framework for generating instruction\npoint-language datasets enriched with 3D spatial semantics. We observe that\nexisting 3D MLLMs offer a comprehensive understanding of point clouds for\nannotation, while 2D MLLMs excel at cross-validation by providing complementary\ninformation. By integrating holistic 2D and 3D insights from off-the-shelf\nMLLMs, PiSA-Engine enables a continuous cycle of high-quality data generation.\nWe select PointLLM as the baseline and adopt this co-evolution training\nframework to develop an enhanced 3D MLLM, termed PointLLM-PiSA. Additionally,\nwe identify limitations in previous 3D benchmarks, which often feature coarse\nlanguage captions and insufficient category diversity, resulting in inaccurate\nevaluations. To address this gap, we further introduce PiSA-Bench, a\ncomprehensive 3D benchmark covering six key aspects with detailed and diverse\nlabels. Experimental results demonstrate PointLLM-PiSA's state-of-the-art\nperformance in zero-shot 3D object captioning and generative classification on\nour PiSA-Bench, achieving significant improvements of 46.45% (+8.33%) and\n63.75% (+16.25%), respectively. We will release the code, datasets, and\nbenchmark.\n","authors":["Zilu Guo","Hongbin Lin","Zhihao Yuan","Chaoda Zheng","Pengshuo Qiu","Dongzhi Jiang","Renrui Zhang","Chun-Mei Feng","Zhen Li"],"pdf_url":"https://arxiv.org/pdf/2503.10529v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2503.10520v1","updated":"2025-03-13T16:29:16Z","published":"2025-03-13T16:29:16Z","title":"CountPath: Automating Fragment Counting in Digital Pathology","summary":"  Quality control of medical images is a critical component of digital\npathology, ensuring that diagnostic images meet required standards. A\npre-analytical task within this process is the verification of the number of\nspecimen fragments, a process that ensures that the number of fragments on a\nslide matches the number documented in the macroscopic report. This step is\nimportant to ensure that the slides contain the appropriate diagnostic material\nfrom the grossing process, thereby guaranteeing the accuracy of subsequent\nmicroscopic examination and diagnosis. Traditionally, this assessment is\nperformed manually, requiring significant time and effort while being subject\nto significant variability due to its subjective nature. To address these\nchallenges, this study explores an automated approach to fragment counting\nusing the YOLOv9 and Vision Transformer models. Our results demonstrate that\nthe automated system achieves a level of performance comparable to expert\nassessments, offering a reliable and efficient alternative to manual counting.\nAdditionally, we present findings on interobserver variability, showing that\nthe automated approach achieves an accuracy of 86%, which falls within the\nrange of variation observed among experts (82-88%), further supporting its\npotential for integration into routine pathology workflows.\n","authors":["Ana Beatriz Vieira","Maria Valente","Diana Montezuma","Tomé Albuquerque","Liliana Ribeiro","Domingos Oliveira","João Monteiro","Sofia Gonçalves","Isabel M. Pinto","Jaime S. Cardoso","Arlindo L. Oliveira"],"pdf_url":"https://arxiv.org/pdf/2503.10520v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.10518v1","updated":"2025-03-13T16:27:42Z","published":"2025-03-13T16:27:42Z","title":"Why the Brain Cannot Be a Digital Computer: History-Dependence and the\n  Computational Limits of Consciousness","summary":"  This paper presents a novel information-theoretic proof demonstrating that\nthe human brain as currently understood cannot function as a classical digital\ncomputer. Through systematic quantification of distinguishable conscious states\nand their historical dependencies, we establish that the minimum information\nrequired to specify a conscious state exceeds the physical information capacity\nof the human brain by a significant factor. Our analysis calculates the\nbit-length requirements for representing consciously distinguishable sensory\n\"stimulus frames\" and demonstrates that consciousness exhibits mandatory\ntemporal-historical dependencies that multiply these requirements beyond the\nbrain's storage capabilities. This mathematical approach offers new insights\ninto the fundamental limitations of computational models of consciousness and\nsuggests that non-classical information processing mechanisms may be necessary\nto account for conscious experience.\n","authors":["Andrew Knight"],"pdf_url":"https://arxiv.org/pdf/2503.10518v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.05039v2","updated":"2025-03-13T16:17:21Z","published":"2024-11-06T17:58:01Z","title":"YouTube Comments Decoded: Leveraging LLMs for Low Resource Language\n  Classification","summary":"  Sarcasm detection is a significant challenge in sentiment analysis,\nparticularly due to its nature of conveying opinions where the intended meaning\ndeviates from the literal expression. This challenge is heightened in social\nmedia contexts where code-mixing, especially in Dravidian languages, is\nprevalent. Code-mixing involves the blending of multiple languages within a\nsingle utterance, often with non-native scripts, complicating the task for\nsystems trained on monolingual data. This shared task introduces a novel gold\nstandard corpus designed for sarcasm and sentiment detection within code-mixed\ntexts, specifically in Tamil-English and Malayalam-English languages. The\nprimary objective of this task is to identify sarcasm and sentiment polarity\nwithin a code-mixed dataset of Tamil-English and Malayalam-English comments and\nposts collected from social media platforms. Each comment or post is annotated\nat the message level for sentiment polarity, with particular attention to the\nchallenges posed by class imbalance, reflecting real-world scenarios.In this\nwork, we experiment with state-of-the-art large language models like GPT-3.5\nTurbo via prompting to classify comments into sarcastic or non-sarcastic\ncategories. We obtained a macro-F1 score of 0.61 for Tamil language. We\nobtained a macro-F1 score of 0.50 for Malayalam language.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.05039v2.pdf","comment":"Updated and Final Version"},{"id":"http://arxiv.org/abs/2410.06846v4","updated":"2025-03-13T16:17:19Z","published":"2024-10-09T13:06:43Z","title":"Joint Fine-tuning and Conversion of Pretrained Speech and Language\n  Models towards Linear Complexity","summary":"  Architectures such as Linformer and Mamba have recently emerged as\ncompetitive linear time replacements for transformers. However, corresponding\nlarge pretrained models are often unavailable, especially in non-text domains.\nTo remedy this, we present a Cross-Architecture Layerwise Distillation (CALD)\napproach that jointly converts a transformer model to a linear time substitute\nand fine-tunes it to a target task. We also compare several means to guide the\nfine-tuning to optimally retain the desired inference capability from the\noriginal model. The methods differ in their use of the target model and the\ntrajectory of the parameters. In a series of empirical studies on language\nprocessing, language modeling, and speech processing, we show that CALD can\neffectively recover the result of the original model, and that the guiding\nstrategy contributes to the result. Some reasons for the variation are\nsuggested.\n","authors":["Mutian He","Philip N. Garner"],"pdf_url":"https://arxiv.org/pdf/2410.06846v4.pdf","comment":"18 pages, 5 figures; ICLR 2025 camera ready. Code:\n  https://github.com/idiap/linearize-distill-pretrained-transformers"},{"id":"http://arxiv.org/abs/2503.10512v1","updated":"2025-03-13T16:16:23Z","published":"2025-03-13T16:16:23Z","title":"Conformal Prediction Sets for Deep Generative Models via Reduction to\n  Conformal Regression","summary":"  We consider the problem of generating valid and small prediction sets by\nsampling outputs (e.g., software code and natural language text) from a\nblack-box deep generative model for a given input (e.g., textual prompt). The\nvalidity of a prediction set is determined by a user-defined binary\nadmissibility function depending on the target application. For example,\nrequiring at least one program in the set to pass all test cases in code\ngeneration application. To address this problem, we develop a simple and\neffective conformal inference algorithm referred to as Generative Prediction\nSets (GPS). Given a set of calibration examples and black-box access to a deep\ngenerative model, GPS can generate prediction sets with provable guarantees.\nThe key insight behind GPS is to exploit the inherent structure within the\ndistribution over the minimum number of samples needed to obtain an admissible\noutput to develop a simple conformal regression approach over the minimum\nnumber of samples. Experiments on multiple datasets for code and math word\nproblems using different large language models demonstrate the efficacy of GPS\nover state-of-the-art methods.\n","authors":["Hooman Shahrokhi","Devjeet Raj Roy","Yan Yan","Venera Arnaoudova","Janaradhan Rao Doppa"],"pdf_url":"https://arxiv.org/pdf/2503.10512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13640v2","updated":"2025-03-13T16:16:12Z","published":"2024-10-17T15:09:24Z","title":"Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation","summary":"  LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.\n","authors":["Yiming Wang","Pei Zhang","Baosong Yang","Derek F. Wong","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.13640v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2412.09165v2","updated":"2025-03-13T16:11:43Z","published":"2024-12-12T10:50:26Z","title":"When Text Embedding Meets Large Language Model: A Comprehensive Survey","summary":"  Text embedding has become a foundational technology in natural language\nprocessing (NLP) during the deep learning era, driving advancements across a\nwide array of downstream tasks. While many natural language understanding\nchallenges can now be modeled using generative paradigms and leverage the\nrobust generative and comprehension capabilities of large language models\n(LLMs), numerous practical applications-such as semantic matching, clustering,\nand information retrieval-continue to rely on text embeddings for their\nefficiency and effectiveness. Therefore, how to combine the LLMs and the text\nembeddings has become one of the hotspots of academic attention in recent\nyears. In this survey, we categorize the interplay between LLMs and text\nembeddings into three overarching themes: (1) LLM-augmented text embedding,\nenhancing traditional embedding methods with LLMs; (2) LLMs as text embedders,\nadapting their innate capabilities for high-quality embedding; and (3) Text\nembedding understanding with LLMs, leveraging LLMs to analyze and interpret\nembeddings. By organizing recent works based on interaction patterns rather\nthan specific downstream applications, we offer a novel and systematic overview\nof contributions from various research and application domains in the era of\nLLMs. Furthermore, we highlight the unresolved challenges that persisted in the\npre-LLM era with pre-trained language models (PLMs) and explore the emerging\nobstacles brought forth by LLMs. Building on this analysis, we outline\nprospective directions for the evolution of text embedding, addressing both\ntheoretical and practical opportunities in the rapidly advancing landscape of\nNLP.\n","authors":["Zhijie Nie","Zhangchi Feng","Mingxin Li","Cunwang Zhang","Yanzhao Zhang","Dingkun Long","Richong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09165v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2306.06192v9","updated":"2025-03-13T16:06:02Z","published":"2023-06-09T18:45:15Z","title":"Confidence-Controlled Exploration: Efficient Sparse-Reward Policy\n  Learning for Robot Navigation","summary":"  Reinforcement learning (RL) is a promising approach for robotic navigation,\nallowing robots to learn through trial and error. However, real-world robotic\ntasks often suffer from sparse rewards, leading to inefficient exploration and\nsuboptimal policies due to sample inefficiency of RL. In this work, we\nintroduce Confidence-Controlled Exploration (CCE), a novel method that improves\nsample efficiency in RL-based robotic navigation without modifying the reward\nfunction. Unlike existing approaches, such as entropy regularization and reward\nshaping, which can introduce instability by altering rewards, CCE dynamically\nadjusts trajectory length based on policy entropy. Specifically, it shortens\ntrajectories when uncertainty is high to enhance exploration and extends them\nwhen confidence is high to prioritize exploitation. CCE is a principled and\npractical solution inspired by a theoretical connection between policy entropy\nand gradient estimation. It integrates seamlessly with on-policy and off-policy\nRL methods and requires minimal modifications. We validate CCE across\nREINFORCE, PPO, and SAC in both simulated and real-world navigation tasks. CCE\noutperforms fixed-trajectory and entropy-regularized baselines, achieving an\n18\\% higher success rate, 20-38\\% shorter paths, and 9.32\\% lower elevation\ncosts under a fixed training sample budget. Finally, we deploy CCE on a\nClearpath Husky robot, demonstrating its effectiveness in complex outdoor\nenvironments.\n","authors":["Bhrij Patel","Kasun Weerakoon","Wesley A. Suttle","Alec Koppel","Brian M. Sadler","Tianyi Zhou","Amrit Singh Bedi","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2306.06192v9.pdf","comment":"10 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.06692v2","updated":"2025-03-13T16:00:47Z","published":"2025-03-09T16:59:14Z","title":"InftyThink: Breaking the Length Limits of Long-Context Reasoning in\n  Large Language Models","summary":"  Advanced reasoning in large language models has achieved remarkable\nperformance on challenging tasks, but the prevailing long-context reasoning\nparadigm faces critical limitations: quadratic computational scaling with\nsequence length, reasoning constrained by maximum context boundaries, and\nperformance degradation beyond pre-training context windows. Existing\napproaches primarily compress reasoning chains without addressing the\nfundamental scaling problem. To overcome these challenges, we introduce\nInftyThink, a paradigm that transforms monolithic reasoning into an iterative\nprocess with intermediate summarization. By interleaving short reasoning\nsegments with concise progress summaries, our approach enables unbounded\nreasoning depth while maintaining bounded computational costs. This creates a\ncharacteristic sawtooth memory pattern that significantly reduces computational\ncomplexity compared to traditional approaches. Furthermore, we develop a\nmethodology for reconstructing long-context reasoning datasets into our\niterative format, transforming OpenR1-Math into 333K training instances.\nExperiments across multiple model architectures demonstrate that our approach\nreduces computational costs while improving performance, with Qwen2.5-Math-7B\nshowing 3-13% improvements across MATH500, AIME24, and GPQA_diamond benchmarks.\nOur work challenges the assumed trade-off between reasoning depth and\ncomputational efficiency, providing a more scalable approach to complex\nreasoning without architectural modifications.\n","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.06692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10496v1","updated":"2025-03-13T15:59:03Z","published":"2025-03-13T15:59:03Z","title":"Explainable Bayesian deep learning through input-skip Latent Binary\n  Bayesian Neural Networks","summary":"  Modeling natural phenomena with artificial neural networks (ANNs) often\nprovides highly accurate predictions. However, ANNs often suffer from\nover-parameterization, complicating interpretation and raising uncertainty\nissues. Bayesian neural networks (BNNs) address the latter by representing\nweights as probability distributions, allowing for predictive uncertainty\nevaluation. Latent binary Bayesian neural networks (LBBNNs) further handle\nstructural uncertainty and sparsify models by removing redundant weights. This\narticle advances LBBNNs by enabling covariates to skip to any succeeding layer\nor be excluded, simplifying networks and clarifying input impacts on\npredictions. Ultimately, a linear model or even a constant can be found to be\noptimal for a specific problem at hand. Furthermore, the input-skip LBBNN\napproach reduces network density significantly compared to standard LBBNNs,\nachieving over 99% reduction for small networks and over 99.9% for larger ones,\nwhile still maintaining high predictive accuracy and uncertainty measurement.\nFor example, on MNIST, we reached 97% accuracy and great calibration with just\n935 weights, reaching state-of-the-art for compression of neural networks.\nFurthermore, the proposed method accurately identifies the true covariates and\nadjusts for system non-linearity. The main contribution is the introduction of\nactive paths, enhancing directly designed global and local explanations within\nthe LBBNN framework, that have theoretical guarantees and do not require post\nhoc external tools for explanations.\n","authors":["Eirik Høyheim","Lars Skaaret-Lund","Solve Sæbø","Aliaksandr Hubin"],"pdf_url":"https://arxiv.org/pdf/2503.10496v1.pdf","comment":"44 pages, 19 tables, 25 figures. Code available at\n  https://github.com/eirihoyh/ISLaB-LBBNN"},{"id":"http://arxiv.org/abs/2411.13022v2","updated":"2025-03-13T15:54:28Z","published":"2024-11-20T03:53:41Z","title":"Fast MRI for All: Bridging Equity Gaps via Training without Raw Data\n  Access","summary":"  Physics-driven deep learning (PD-DL) approaches have become popular for\nimproved reconstruction of fast magnetic resonance imaging (MRI) scans. Though\nPD-DL offers higher acceleration rates than existing clinical fast MRI\ntechniques, their use has been limited outside specialized MRI centers. A key\nchallenge is generalization to underrepresented pathologies or populations,\nnoted in multiple studies, with fine-tuning on target populations suggested for\nimprovement. However, current approaches for PD-DL training require access to\nraw k-space measurements, which is typically only available at specialized MRI\ncenters that have research agreements for such data access. This is especially\nan issue for rural and underserved areas, where commercial MRI scanners only\nprovide access to a final reconstructed image. To tackle these challenges, we\npropose Compressibility-inspired Unsupervised Learning via Parallel Imaging\nFidelity (CUPID) for high-quality PD-DL training using only routine clinical\nreconstructed images exported from an MRI scanner. CUPID evaluates output\nquality with a compressibility-based approach while ensuring that the output\nstays consistent with the clinical parallel imaging reconstruction through\nwell-designed perturbations. Our results show CUPID achieves similar quality to\nestablished PD-DL training that requires k-space data while outperforming\ncompressed sensing (CS) and diffusion-based generative methods. We further\ndemonstrate its effectiveness in a zero-shot training setup for retrospectively\nand prospectively sub-sampled acquisitions, attesting to its minimal training\nburden. As an approach that radically deviates from existing strategies, CUPID\npresents an opportunity to provide equitable access to fast MRI for underserved\npopulations in an attempt to reduce the inequalities associated with this\nexpensive imaging modality.\n","authors":["Yaşar Utku Alçalar","Merve Gülle","Mehmet Akçakaya"],"pdf_url":"https://arxiv.org/pdf/2411.13022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10486v1","updated":"2025-03-13T15:54:26Z","published":"2025-03-13T15:54:26Z","title":"LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3\n  Mini Across Chronic Health Conditions","summary":"  Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.\n","authors":["Gaurav Kumar Gupta","Pranal Pande"],"pdf_url":"https://arxiv.org/pdf/2503.10486v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.10479v1","updated":"2025-03-13T15:49:29Z","published":"2025-03-13T15:49:29Z","title":"DeclareAligner: A Leap Towards Efficient Optimal Alignments for\n  Declarative Process Model Conformance Checking","summary":"  In many engineering applications, processes must be followed precisely,\nmaking conformance checking between event logs and declarative process models\ncrucial for ensuring adherence to desired behaviors. This is a critical area\nwhere Artificial Intelligence (AI) plays a pivotal role in driving effective\nprocess improvement. However, computing optimal alignments poses significant\ncomputational challenges due to the vast search space inherent in these models.\nConsequently, existing approaches often struggle with scalability and\nefficiency, limiting their applicability in real-world settings. This paper\nintroduces DeclareAligner, a novel algorithm that uses the A* search algorithm,\nan established AI pathfinding technique, to tackle the problem from a fresh\nperspective leveraging the flexibility of declarative models. Key features of\nDeclareAligner include only performing actions that actively contribute to\nfixing constraint violations, utilizing a tailored heuristic to navigate\ntowards optimal solutions, and employing early pruning to eliminate\nunproductive branches, while also streamlining the process through\npreprocessing and consolidating multiple fixes into unified actions. The\nproposed method is evaluated using 8,054 synthetic and real-life alignment\nproblems, demonstrating its ability to efficiently compute optimal alignments\nby significantly outperforming the current state of the art. By enabling\nprocess analysts to more effectively identify and understand conformance\nissues, DeclareAligner has the potential to drive meaningful process\nimprovement and management.\n","authors":["Jacobo Casas-Ramos","Manuel Lama","Manuel Mucientes"],"pdf_url":"https://arxiv.org/pdf/2503.10479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10471v1","updated":"2025-03-13T15:44:16Z","published":"2025-03-13T15:44:16Z","title":"Siamese Foundation Models for Crystal Structure Prediction","summary":"  Crystal Structure Prediction (CSP), which aims to generate stable crystal\nstructures from compositions, represents a critical pathway for discovering\nnovel materials. While structure prediction tasks in other domains, such as\nproteins, have seen remarkable progress, CSP remains a relatively underexplored\narea due to the more complex geometries inherent in crystal structures. In this\npaper, we propose Siamese foundation models specifically designed to address\nCSP. Our pretrain-finetune framework, named DAO, comprises two complementary\nfoundation models: DAO-G for structure generation and DAO-P for energy\nprediction. Experiments on CSP benchmarks (MP-20 and MPTS-52) demonstrate that\nour DAO-G significantly surpasses state-of-the-art (SOTA) methods across all\nmetrics. Extensive ablation studies further confirm that DAO-G excels in\ngenerating diverse polymorphic structures, and the dataset relaxation and\nenergy guidance provided by DAO-P are essential for enhancing DAO-G's\nperformance. When applied to three real-world superconductors\n($\\text{CsV}_3\\text{Sb}_5$, $ \\text{Zr}_{16}\\text{Rh}_8\\text{O}_4$ and\n$\\text{Zr}_{16}\\text{Pd}_8\\text{O}_4$) that are known to be challenging to\nanalyze, our foundation models achieve accurate critical temperature\npredictions and structure generations. For instance, on\n$\\text{CsV}_3\\text{Sb}_5$, DAO-G generates a structure close to the\nexperimental one with an RMSE of 0.0085; DAO-P predicts the $T_c$ value with\nhigh accuracy (2.26 K vs. the ground-truth value of 2.30 K). In contrast,\nconventional DFT calculators like Quantum Espresso only successfully derive the\nstructure of the first superconductor within an acceptable time, while the RMSE\nis nearly 8 times larger, and the computation speed is more than 1000 times\nslower. These compelling results collectively highlight the potential of our\napproach for advancing materials science research and development.\n","authors":["Liming Wu","Wenbing Huang","Rui Jiao","Jianxing Huang","Liwei Liu","Yipeng Zhou","Hao Sun","Yang Liu","Fuchun Sun","Yuxiang Ren","Jirong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.10471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19363v2","updated":"2025-03-13T15:42:07Z","published":"2025-02-26T18:01:19Z","title":"DataMan: Data Manager for Pre-training Large Language Models","summary":"  The performance emergence of large language models (LLMs) driven by data\nscaling laws makes the selection of pre-training data increasingly important.\nHowever, existing methods rely on limited heuristics and human intuition,\nlacking comprehensive and clear guidelines. To address this, we are inspired by\n``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit\nits performance. As its pre-training capabilities are related to perplexity\n(PPL), we derive 14 quality criteria from the causes of text perplexity\nanomalies and introduce 15 common application domains to support domain mixing.\nIn this paper, we train a Data Manager (DataMan) to learn quality ratings and\ndomain recognition from pointwise rating, and use it to annotate a 447B token\npre-training corpus with 14 quality ratings and domain type. Our experiments\nvalidate our approach, using DataMan to select 30B tokens to train a\n1.3B-parameter language model, demonstrating significant improvements in\nin-context learning (ICL), perplexity, and instruction-following ability over\nthe state-of-the-art baseline. The best-performing model, based on the Overall\nScore l=5 surpasses a model trained with 50% more data using uniform sampling.\nWe continue pre-training with high-rated, domain-specific data annotated by\nDataMan to enhance domain-specific ICL performance and thus verify DataMan's\ndomain mixing ability. Our findings emphasize the importance of quality\nranking, the complementary nature of quality criteria, and their low\ncorrelation with perplexity, analyzing misalignment between PPL and ICL\nperformance. We also thoroughly analyzed our pre-training dataset, examining\nits composition, the distribution of quality ratings, and the original document\nsources.\n","authors":["Ru Peng","Kexin Yang","Yawen Zeng","Junyang Lin","Dayiheng Liu","Junbo Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.19363v2.pdf","comment":"ICLR2025 paper"},{"id":"http://arxiv.org/abs/2405.10075v2","updated":"2025-03-13T15:27:41Z","published":"2024-05-16T13:14:43Z","title":"HecVL: Hierarchical Video-Language Pretraining for Zero-shot Surgical\n  Phase Recognition","summary":"  Natural language could play an important role in developing generalist\nsurgical models by providing a broad source of supervision from raw texts. This\nflexible form of supervision can enable the model's transferability across\ndatasets and tasks as natural language can be used to reference learned visual\nconcepts or describe new ones. In this work, we present HecVL, a novel\nhierarchical video-language pretraining approach for building a generalist\nsurgical model. Specifically, we construct a hierarchical video-text paired\ndataset by pairing the surgical lecture video with three hierarchical levels of\ntexts: at clip-level, atomic actions using transcribed audio texts; at\nphase-level, conceptual text summaries; and at video-level, overall abstract\ntext of the surgical procedure. Then, we propose a novel fine-to-coarse\ncontrastive learning framework that learns separate embedding spaces for the\nthree video-text hierarchies using a single model. By disentangling embedding\nspaces of different hierarchical levels, the learned multi-modal\nrepresentations encode short-term and long-term surgical concepts in the same\nmodel. Thanks to the injected textual semantics, we demonstrate that the HecVL\napproach can enable zero-shot surgical phase recognition without any human\nannotation. Furthermore, we show that the same HecVL model for surgical phase\nrecognition can be transferred across different surgical procedures and medical\ncenters. The code is available at https://github.com/CAMMA-public/SurgVLP\n","authors":["Kun Yuan","Vinkle Srivastav","Nassir Navab","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2405.10075v2.pdf","comment":"Accepted by MICCAI2024"},{"id":"http://arxiv.org/abs/2410.00263v2","updated":"2025-03-13T15:21:36Z","published":"2024-09-30T22:21:05Z","title":"Procedure-Aware Surgical Video-language Pretraining with Hierarchical\n  Knowledge Augmentation","summary":"  Surgical video-language pretraining (VLP) faces unique challenges due to the\nknowledge domain gap and the scarcity of multi-modal data. This study aims to\nbridge the gap by addressing issues regarding textual information loss in\nsurgical lecture videos and the spatial-temporal challenges of surgical VLP. We\npropose a hierarchical knowledge augmentation approach and a novel\nProcedure-Encoded Surgical Knowledge-Augmented Video-Language Pretraining\n(PeskaVLP) framework to tackle these issues. The knowledge augmentation uses\nlarge language models (LLM) for refining and enriching surgical concepts, thus\nproviding comprehensive language supervision and reducing the risk of\noverfitting. PeskaVLP combines language supervision with visual\nself-supervision, constructing hard negative samples and employing a Dynamic\nTime Warping (DTW) based loss function to effectively comprehend the\ncross-modal procedural alignment. Extensive experiments on multiple public\nsurgical scene understanding and cross-modal retrieval datasets show that our\nproposed method significantly improves zero-shot transferring performance and\noffers a generalist visual representation for further advancements in surgical\nscene understanding.The code is available at\nhttps://github.com/CAMMA-public/SurgVLP\n","authors":["Kun Yuan","Vinkle Srivastav","Nassir Navab","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2410.00263v2.pdf","comment":"Accepted at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024 Spolight)"},{"id":"http://arxiv.org/abs/2503.10452v1","updated":"2025-03-13T15:18:56Z","published":"2025-03-13T15:18:56Z","title":"DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large\n  Language Models in Code Generation","summary":"  The rapid advancement of large language models (LLMs) has significantly\nimproved their performance in code generation tasks. However, existing code\nbenchmarks remain static, consisting of fixed datasets with predefined\nproblems. This makes them vulnerable to memorization during training, where\nLLMs recall specific test cases instead of generalizing to new problems,\nleading to data contamination and unreliable evaluation results. To address\nthese issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that\novercomes the limitations of static datasets. DynaCode evaluates LLMs\nsystematically using a complexity-aware metric, incorporating both code\ncomplexity and call-graph structures. DynaCode achieves large-scale diversity,\ngenerating up to 189 million unique nested code problems across four distinct\nlevels of code complexity, referred to as units, and 16 types of call graphs.\nResults on 12 latest LLMs show an average performance drop of 16.8% to 45.7%\ncompared to MBPP+, a static code generation benchmark, with performance\nprogressively decreasing as complexity increases. This demonstrates DynaCode's\nability to effectively differentiate LLMs. Additionally, by leveraging call\ngraphs, we gain insights into LLM behavior, particularly their preference for\nhandling subfunction interactions within nested code.\n","authors":["Wenhao Hu","Jinhao Duan","Chunchen Wei","Li Zhang","Yue Zhang","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.10452v1.pdf","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.10446v1","updated":"2025-03-13T15:11:28Z","published":"2025-03-13T15:11:28Z","title":"Whisper Speaker Identification: Leveraging Pre-Trained Multilingual\n  Transformers for Robust Speaker Embeddings","summary":"  Speaker identification in multilingual settings presents unique challenges,\nparticularly when conventional models are predominantly trained on English\ndata. In this paper, we propose WSI (Whisper Speaker Identification), a\nframework that repurposes the encoder of the Whisper automatic speech\nrecognition model pre trained on extensive multilingual data to generate robust\nspeaker embeddings via a joint loss optimization strategy that leverages online\nhard triplet mining and self supervised Normalized Temperature-scaled Cross\nEntropy loss. By capitalizing on Whisper language-agnostic acoustic\nrepresentations, our approach effectively distinguishes speakers across diverse\nlanguages and recording conditions. Extensive evaluations on multiple corpora,\nincluding VoxTube (multilingual), JVS (Japanese), CallHome (German, Spanish,\nChinese, and Japanese), and Voxconverse (English), demonstrate that WSI\nconsistently outperforms state-of-the-art baselines, namely Pyannote Embedding,\nECAPA TDNN, and Xvector, in terms of lower equal error rates and higher AUC\nscores. These results validate our hypothesis that a multilingual pre-trained\nASR encoder, combined with joint loss optimization, substantially improves\nspeaker identification performance in non-English languages.\n","authors":["Jakaria Islam Emon","Md Abu Salek","Kazi Tamanna Alam"],"pdf_url":"https://arxiv.org/pdf/2503.10446v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2404.10775v2","updated":"2025-03-13T14:56:47Z","published":"2024-04-16T17:59:11Z","title":"COMBO: Compositional World Models for Embodied Multi-Agent Cooperation","summary":"  In this paper, we investigate the problem of embodied multi-agent\ncooperation, where decentralized agents must cooperate given only egocentric\nviews of the world. To effectively plan in this setting, in contrast to\nlearning world dynamics in a single-agent scenario, we must simulate world\ndynamics conditioned on an arbitrary number of agents' actions given only\npartial egocentric visual observations of the world. To address this issue of\npartial observability, we first train generative models to estimate the overall\nworld state given partial egocentric observations. To enable accurate\nsimulation of multiple sets of actions on this world state, we then propose to\nlearn a compositional world model for multi-agent cooperation by factorizing\nthe naturally composable joint actions of multiple agents and compositionally\ngenerating the video conditioned on the world state. By leveraging this\ncompositional world model, in combination with Vision Language Models to infer\nthe actions of other agents, we can use a tree search procedure to integrate\nthese modules and facilitate online cooperative planning. We evaluate our\nmethods on three challenging benchmarks with 2-4 agents. The results show our\ncompositional world model is effective and the framework enables the embodied\nagents to cooperate efficiently with different agents across various tasks and\nan arbitrary number of agents, showing the promising future of our proposed\nmethods. More videos can be found at https://embodied-agi.cs.umass.edu/combo/.\n","authors":["Hongxin Zhang","Zeyuan Wang","Qiushi Lyu","Zheyuan Zhang","Sunli Chen","Tianmin Shu","Behzad Dariush","Kwonjoon Lee","Yilun Du","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2404.10775v2.pdf","comment":"Published at ICLR 2025. 24 pages. The first three authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2404.17365v3","updated":"2025-03-13T14:48:27Z","published":"2024-04-26T12:30:32Z","title":"Similarity Equivariant Graph Neural Networks for Homogenization of\n  Metamaterials","summary":"  Soft, porous mechanical metamaterials exhibit pattern transformations that\nmay have important applications in soft robotics, sound reduction and\nbiomedicine. To design these innovative materials, it is important to be able\nto simulate them accurately and quickly, in order to tune their mechanical\nproperties. Since conventional simulations using the finite element method\nentail a high computational cost, in this article we aim to develop a machine\nlearning-based approach that scales favorably to serve as a surrogate model. To\nensure that the model is also able to handle various microstructures, including\nthose not encountered during training, we include the microstructure as part of\nthe network input. Therefore, we introduce a graph neural network that predicts\nglobal quantities (energy, stress stiffness) as well as the pattern\ntransformations that occur (the kinematics). To make our model as accurate and\ndata-efficient as possible, various symmetries are incorporated into the model.\nThe starting point is an E(n)-equivariant graph neural network (which respects\ntranslation, rotation and reflection) that has periodic boundary conditions\n(i.e., it is in-/equivariant with respect to the choice of RVE), is scale\nin-/equivariant, can simulate large deformations, and can predict scalars,\nvectors as well as second and fourth order tensors (specifically energy, stress\nand stiffness). The incorporation of scale equivariance makes the model\nequivariant with respect to the similarities group, of which the Euclidean\ngroup E(n) is a subgroup. We show that this network is more accurate and\ndata-efficient than graph neural networks with fewer symmetries. To create an\nefficient graph representation of the finite element discretization, we use\nonly the internal geometrical hole boundaries from the finite element mesh to\nachieve a better speed-up and scaling with the mesh size.\n","authors":["Fleur Hendriks","Vlado Menkovski","Martin Doškář","Marc G. D. Geers","Ondřej Rokoš"],"pdf_url":"https://arxiv.org/pdf/2404.17365v3.pdf","comment":"60 pages, 22 figures. Published in CMAME (Computer Methods in Applied\n  Mechanics and Engineering)"},{"id":"http://arxiv.org/abs/2503.10412v1","updated":"2025-03-13T14:35:47Z","published":"2025-03-13T14:35:47Z","title":"dFLMoE: Decentralized Federated Learning via Mixture of Experts for\n  Medical Data Analysis","summary":"  Federated learning has wide applications in the medical field. It enables\nknowledge sharing among different healthcare institutes while protecting\npatients' privacy. However, existing federated learning systems are typically\ncentralized, requiring clients to upload client-specific knowledge to a central\nserver for aggregation. This centralized approach would integrate the knowledge\nfrom each client into a centralized server, and the knowledge would be already\nundermined during the centralized integration before it reaches back to each\nclient. Besides, the centralized approach also creates a dependency on the\ncentral server, which may affect training stability if the server malfunctions\nor connections are unstable. To address these issues, we propose a\ndecentralized federated learning framework named dFLMoE. In our framework,\nclients directly exchange lightweight head models with each other. After\nexchanging, each client treats both local and received head models as\nindividual experts, and utilizes a client-specific Mixture of Experts (MoE)\napproach to make collective decisions. This design not only reduces the\nknowledge damage with client-specific aggregations but also removes the\ndependency on the central server to enhance the robustness of the framework. We\nvalidate our framework on multiple medical tasks, demonstrating that our method\nevidently outperforms state-of-the-art approaches under both model homogeneity\nand heterogeneity settings.\n","authors":["Luyuan Xie","Tianyu Luan","Wenyuan Cai","Guochen Yan","Zhaoyu Chen","Nan Xi","Yuejian Fang","Qingni Shen","Zhonghai Wu","Junsong Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.10412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10406v1","updated":"2025-03-13T14:31:52Z","published":"2025-03-13T14:31:52Z","title":"RealGeneral: Unifying Visual Generation via Temporal In-Context Learning\n  with Video Models","summary":"  Unifying diverse image generation tasks within a single framework remains a\nfundamental challenge in visual generation. While large language models (LLMs)\nachieve unification through task-agnostic data and generation, existing visual\ngeneration models fail to meet these principles. Current approaches either rely\non per-task datasets and large-scale training or adapt pre-trained image models\nwith task-specific modifications, limiting their generalizability. In this\nwork, we explore video models as a foundation for unified image generation,\nleveraging their inherent ability to model temporal correlations. We introduce\nRealGeneral, a novel framework that reformulates image generation as a\nconditional frame prediction task, analogous to in-context learning in LLMs. To\nbridge the gap between video models and condition-image pairs, we propose (1) a\nUnified Conditional Embedding module for multi-modal alignment and (2) a\nUnified Stream DiT Block with decoupled adaptive LayerNorm and attention mask\nto mitigate cross-modal interference. RealGeneral demonstrates effectiveness in\nmultiple important visual generation tasks, e.g., it achieves a 14.5%\nimprovement in subject similarity for customized generation and a 10%\nenhancement in image quality for canny-to-image task. Project page:\nhttps://lyne1.github.io/RealGeneral/\n","authors":["Yijing Lin","Mengqi Huang","Shuhan Zhuang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2503.10406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03021v3","updated":"2025-03-13T14:22:12Z","published":"2024-12-04T04:24:15Z","title":"PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm","summary":"  Video Virtual Try-on aims to seamlessly transfer a reference garment onto a\ntarget person in a video while preserving both visual fidelity and temporal\ncoherence. Existing methods typically rely on inpainting masks to define the\ntry-on area, enabling accurate garment transfer for simple scenes (e.g.,\nin-shop videos). However, these mask-based approaches struggle with complex\nreal-world scenarios, as overly large and inconsistent masks often destroy\nspatial-temporal information, leading to distorted results. Mask-free methods\nalleviate this issue but face challenges in accurately determining the try-on\narea, especially for videos with dynamic body movements. To address these\nlimitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video\nVirtual Try-On framework that leverages sparse point alignments to explicitly\nguide garment transfer. Our key innovation is the introduction of\npoint-enhanced guidance, which provides flexible and reliable control over both\nspatial-level garment transfer and temporal-level video coherence.\nSpecifically, we design a Point-Enhanced Transformer (PET) with two core\ncomponents: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth\npoint alignments to precisely guide garment transfer, and Point-Enhanced\nTemporal Attention (PTA), which leverages frame-frame point correspondences to\nenhance temporal coherence and ensure smooth transitions across frames.\nExtensive experiments demonstrate that our PEMF-VTO outperforms\nstate-of-the-art methods, generating more natural, coherent, and visually\nappealing try-on videos, particularly for challenging in-the-wild scenarios.\n","authors":["Tianyu Chang","Xiaohao Chen","Zhichao Wei","Xuanpu Zhang","Qing-Guo Chen","Weihua Luo","Peipei Song","Xun Yang"],"pdf_url":"https://arxiv.org/pdf/2412.03021v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05473v2","updated":"2025-03-13T14:20:53Z","published":"2025-03-07T14:45:03Z","title":"The Society of HiveMind: Multi-Agent Optimization of Foundation Model\n  Swarms to Unlock the Potential of Collective Intelligence","summary":"  Multi-agent systems address issues of accessibility and scalability of\nartificial intelligence (AI) foundation models, which are often represented by\nlarge language models. We develop a framework - the \"Society of HiveMind\"\n(SOHM) - that orchestrates the interaction between multiple AI foundation\nmodels, imitating the observed behavior of animal swarms in nature by following\nmodern evolutionary theories. On the one hand, we find that the SOHM provides a\nnegligible benefit on tasks that mainly require real-world knowledge. On the\nother hand, we remark a significant improvement on tasks that require intensive\nlogical reasoning, indicating that multi-agent systems are capable of\nincreasing the reasoning capabilities of the collective compared to the\nindividual agents. Our findings demonstrate the potential of combining a\nmultitude of diverse AI foundation models to form an artificial swarm\nintelligence capable of self-improvement through interactions with a given\nenvironment.\n","authors":["Noah Mamie","Susie Xi Rao"],"pdf_url":"https://arxiv.org/pdf/2503.05473v2.pdf","comment":"11 pages (excl. appendix)"},{"id":"http://arxiv.org/abs/2501.10736v2","updated":"2025-03-13T14:18:36Z","published":"2025-01-18T11:57:20Z","title":"Semi-supervised Semantic Segmentation for Remote Sensing Images via\n  Multi-scale Uncertainty Consistency and Cross-Teacher-Student Attention","summary":"  Semi-supervised learning offers an appealing solution for remote sensing (RS)\nimage segmentation to relieve the burden of labor-intensive pixel-level\nlabeling. However, RS images pose unique challenges, including rich multi-scale\nfeatures and high inter-class similarity. To address these problems, this paper\nproposes a novel semi-supervised Multi-Scale Uncertainty and\nCross-Teacher-Student Attention (MUCA) model for RS image semantic segmentation\ntasks. Specifically, MUCA constrains the consistency among feature maps at\ndifferent layers of the network by introducing a multi-scale uncertainty\nconsistency regularization. It improves the multi-scale learning capability of\nsemi-supervised algorithms on unlabeled data. Additionally, MUCA utilizes a\nCross-Teacher-Student attention mechanism to guide the student network, guiding\nthe student network to construct more discriminative feature representations\nthrough complementary features from the teacher network. This design\neffectively integrates weak and strong augmentations (WA and SA) to further\nboost segmentation performance. To verify the effectiveness of our model, we\nconduct extensive experiments on ISPRS-Potsdam and LoveDA datasets. The\nexperimental results show the superiority of our method over state-of-the-art\nsemi-supervised methods. Notably, our model excels in distinguishing highly\nsimilar objects, showcasing its potential for advancing semi-supervised RS\nimage segmentation tasks.\n","authors":["Shanwen Wang","Xin Sun","Changrui Chen","Danfeng Hong","Jungong Han"],"pdf_url":"https://arxiv.org/pdf/2501.10736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02766v5","updated":"2025-03-13T14:14:01Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"  We introduce networked communication to the mean-field game framework, in\nparticular to oracle-free settings where $N$ decentralised agents learn along a\nsingle, non-episodic run of the empirical system. We prove that our\narchitecture has sample guarantees bounded between those of the centralised-\nand independent-learning cases. We provide the order of the difference in these\nbounds in terms of network structure and number of communication rounds, and\nalso contribute a policy-update stability guarantee. We discuss how the sample\nguarantees of the three theoretical algorithms do not actually result in\npractical convergence. We therefore show that in practical settings where the\ntheoretical parameters are not observed (leading to poor estimation of the\nQ-function), our communication scheme considerably accelerates learning over\nthe independent case, often performing similarly to a centralised learner while\nremoving the restrictive assumption of the latter. We contribute further\npractical enhancements to all three theoretical algorithms, allowing us to\npresent their first empirical demonstrations. Our experiments confirm that we\ncan remove several of the theoretical assumptions of the algorithms, and\ndisplay the empirical convergence benefits brought by our new networked\ncommunication. We additionally show that our networked approach has significant\nadvantages over both alternatives in terms of robustness to update failures and\nto changes in population size.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2306.02766v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10392v1","updated":"2025-03-13T14:09:18Z","published":"2025-03-13T14:09:18Z","title":"RoMA: Scaling up Mamba-based Foundation Models for Remote Sensing","summary":"  Recent advances in self-supervised learning for Vision Transformers (ViTs)\nhave fueled breakthroughs in remote sensing (RS) foundation models. However,\nthe quadratic complexity of self-attention poses a significant barrier to\nscalability, particularly for large models and high-resolution images. While\nthe linear-complexity Mamba architecture offers a promising alternative,\nexisting RS applications of Mamba remain limited to supervised tasks on small,\ndomain-specific datasets. To address these challenges, we propose RoMA, a\nframework that enables scalable self-supervised pretraining of Mamba-based RS\nfoundation models using large-scale, diverse, unlabeled data. RoMA enhances\nscalability for high-resolution images through a tailored auto-regressive\nlearning strategy, incorporating two key innovations: 1) a rotation-aware\npretraining mechanism combining adaptive cropping with angular embeddings to\nhandle sparsely distributed objects with arbitrary orientations, and 2)\nmulti-scale token prediction objectives that address the extreme variations in\nobject scales inherent to RS imagery. Systematic empirical studies validate\nthat Mamba adheres to RS data and parameter scaling laws, with performance\nscaling reliably as model and data size increase. Furthermore, experiments\nacross scene classification, object detection, and semantic segmentation tasks\ndemonstrate that RoMA-pretrained Mamba models consistently outperform ViT-based\ncounterparts in both accuracy and computational efficiency. The source code and\npretrained models will be released at https://github.com/MiliLab/RoMA.\n","authors":["Fengxiang Wang","Hongzhen Wang","Yulin Wang","Di Wang","Mingshuo Chen","Haiyan Zhao","Yangang Sun","Shuo Wang","Long Lan","Wenjing Yang","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.10392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10391v1","updated":"2025-03-13T14:07:58Z","published":"2025-03-13T14:07:58Z","title":"CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance","summary":"  Video generation has witnessed remarkable progress with the advent of deep\ngenerative models, particularly diffusion models. While existing methods excel\nin generating high-quality videos from text prompts or single images,\npersonalized multi-subject video generation remains a largely unexplored\nchallenge. This task involves synthesizing videos that incorporate multiple\ndistinct subjects, each defined by separate reference images, while ensuring\ntemporal and spatial consistency. Current approaches primarily rely on mapping\nsubject images to keywords in text prompts, which introduces ambiguity and\nlimits their ability to model subject relationships effectively. In this paper,\nwe propose CINEMA, a novel framework for coherent multi-subject video\ngeneration by leveraging Multimodal Large Language Model (MLLM). Our approach\neliminates the need for explicit correspondences between subject images and\ntext entities, mitigating ambiguity and reducing annotation effort. By\nleveraging MLLM to interpret subject relationships, our method facilitates\nscalability, enabling the use of large and diverse datasets for training.\nFurthermore, our framework can be conditioned on varying numbers of subjects,\noffering greater flexibility in personalized content creation. Through\nextensive evaluations, we demonstrate that our approach significantly improves\nsubject consistency, and overall video coherence, paving the way for advanced\napplications in storytelling, interactive media, and personalized video\ngeneration.\n","authors":["Yufan Deng","Xun Guo","Yizhi Wang","Jacob Zhiyuan Fang","Angtian Wang","Shenghai Yuan","Yiding Yang","Bo Liu","Haibin Huang","Chongyang Ma"],"pdf_url":"https://arxiv.org/pdf/2503.10391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16496v2","updated":"2025-03-13T13:56:43Z","published":"2024-05-26T09:16:34Z","title":"Exploring a Multimodal Fusion-based Deep Learning Network for Detecting\n  Facial Palsy","summary":"  Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessment by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes unstructured data (i.e. an image frame with facial line\nsegments) and structured data (i.e. features of facial expressions) to detect\nfacial palsy. We then contribute to a study to analyze the effect of different\ndata modalities and the benefits of a multimodal fusion-based approach using\nvideos of 21 facial palsy patients. Our experimental results show that among\nvarious data modalities (i.e. unstructured data - RGB images and images of\nfacial line segments and structured data - coordinates of facial landmarks and\nfeatures of facial expressions), the feed-forward neural network using features\nof facial expression achieved the highest precision of 76.22 while the\nResNet-based model using images of facial line segments achieved the highest\nrecall of 83.47. When we leveraged both images of facial line segments and\nfeatures of facial expressions, our multimodal fusion-based deep learning model\nslightly improved the precision score to 77.05 at the expense of a decrease in\nthe recall score.\n","authors":["Heng Yim Nicole Oo","Min Hun Lee","Jeong Hoon Lim"],"pdf_url":"https://arxiv.org/pdf/2405.16496v2.pdf","comment":"IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)"},{"id":"http://arxiv.org/abs/2409.06214v4","updated":"2025-03-13T13:55:30Z","published":"2024-09-10T04:45:25Z","title":"Towards Generalizable Scene Change Detection","summary":"  While current state-of-the-art Scene Change Detection (SCD) approaches\nachieve impressive results in well-trained research data, they become\nunreliable under unseen environments and different temporal conditions;\nin-domain performance drops from 77.6% to 8.0% in a previously unseen\nenvironment and to 4.6% under a different temporal condition -- calling for\ngeneralizable SCD and benchmark. In this work, we propose the Generalizable\nScene Change Detection Framework (GeSCF), which addresses unseen domain\nperformance and temporal consistency -- to meet the growing demand for anything\nSCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a\nzero-shot manner. For this, we design Initial Pseudo-mask Generation and\nGeometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and\nsingle-image based segmentation into scene change detection for a pair of\ninputs without guidance. Furthermore, we define the Generalizable Scene Change\nDetection (GeSCD) benchmark along with novel metrics and an evaluation protocol\nto facilitate SCD research in generalizability. In the process, we introduce\nthe ChangeVPR dataset, a collection of challenging image pairs with diverse\nenvironmental scenarios -- including urban, suburban, and rural settings.\nExtensive experiments across various datasets demonstrate that GeSCF achieves\nan average performance gain of 19.2% on existing SCD datasets and 30.0% on the\nChangeVPR dataset, nearly doubling the prior art performance. We believe our\nwork can lay a solid foundation for robust and generalizable SCD research.\n","authors":["Jaewoo Kim","Uehwan Kim"],"pdf_url":"https://arxiv.org/pdf/2409.06214v4.pdf","comment":"Camera-ready version. Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.08179v3","updated":"2025-03-13T13:54:27Z","published":"2025-03-11T08:43:05Z","title":"ProtTeX: Structure-In-Context Reasoning and Editing of Proteins with\n  Large Language Models","summary":"  Large language models have made remarkable progress in the field of molecular\nscience, particularly in understanding and generating functional small\nmolecules. This success is largely attributed to the effectiveness of molecular\ntokenization strategies. In protein science, the amino acid sequence serves as\nthe sole tokenizer for LLMs. However, many fundamental challenges in protein\nscience are inherently structure-dependent. The absence of structure-aware\ntokens significantly limits the capabilities of LLMs for comprehensive\nbiomolecular comprehension and multimodal generation. To address these\nchallenges, we introduce a novel framework, ProtTeX, which tokenizes the\nprotein sequences, structures, and textual information into a unified discrete\nspace. This innovative approach enables joint training of the LLM exclusively\nthrough the Next-Token Prediction paradigm, facilitating multimodal protein\nreasoning and generation. ProtTeX enables general LLMs to perceive and process\nprotein structures through sequential text input, leverage structural\ninformation as intermediate reasoning components, and generate or manipulate\nstructures via sequential text output. Experiments demonstrate that our model\nachieves significant improvements in protein function prediction, outperforming\nthe state-of-the-art domain expert model with a twofold increase in accuracy.\nOur framework enables high-quality conformational generation and customizable\nprotein design. For the first time, we demonstrate that by adopting the\nstandard training and inference pipelines from the LLM domain, ProtTeX empowers\ndecoder-only LLMs to effectively address diverse spectrum of protein-related\ntasks.\n","authors":["Zicheng Ma","Chuanliu Fan","Zhicong Wang","Zhenyu Chen","Xiaohan Lin","Yanheng Li","Shihao Feng","Jun Zhang","Ziqiang Cao","Yi Qin Gao"],"pdf_url":"https://arxiv.org/pdf/2503.08179v3.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2502.18008v4","updated":"2025-03-13T13:50:00Z","published":"2025-02-25T09:12:07Z","title":"NotaGen: Advancing Musicality in Symbolic Music Generation with Large\n  Language Model Training Paradigms","summary":"  We introduce NotaGen, a symbolic music generation model aiming to explore the\npotential of producing high-quality classical sheet music. Inspired by the\nsuccess of Large Language Models (LLMs), NotaGen adopts pre-training,\nfine-tuning, and reinforcement learning paradigms (henceforth referred to as\nthe LLM training paradigms). It is pre-trained on 1.6M pieces of music in ABC\nnotation, and then fine-tuned on approximately 9K high-quality classical\ncompositions conditioned on \"period-composer-instrumentation\" prompts. For\nreinforcement learning, we propose the CLaMP-DPO method, which further enhances\ngeneration quality and controllability without requiring human annotations or\npredefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in\nsymbolic music generation models with different architectures and encoding\nschemes. Furthermore, subjective A/B tests show that NotaGen outperforms\nbaseline models against human compositions, greatly advancing musical\naesthetics in symbolic music generation.\n","authors":["Yashan Wang","Shangda Wu","Jianhuai Hu","Xingjian Du","Yueqi Peng","Yongxin Huang","Shuai Fan","Xiaobing Li","Feng Yu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.18008v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10371v1","updated":"2025-03-13T13:48:35Z","published":"2025-03-13T13:48:35Z","title":"A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted\n  Features-based Deep Learning Networks for Facial Palsy Detection","summary":"  Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessments by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes an MLP mixer-based model to process unstructured data (i.e.\nRGB images or images with facial line segments) and a feed-forward neural\nnetwork to process structured data (i.e. facial landmark coordinates, features\nof facial expressions, or handcrafted features) for detecting facial palsy. We\nthen contribute to a study to analyze the effect of different data modalities\nand the benefits of a multimodal fusion-based approach using videos of 20\nfacial palsy patients and 20 healthy subjects. Our multimodal fusion model\nachieved 96.00 F1, which is significantly higher than the feed-forward neural\nnetwork trained on handcrafted features alone (82.80 F1) and an MLP mixer-based\nmodel trained on raw RGB images (89.00 F1).\n","authors":["Heng Yim Nicole Oo","Min Hun Lee","Jeong Hoon Lim"],"pdf_url":"https://arxiv.org/pdf/2503.10371v1.pdf","comment":"PAKDD 2025. arXiv admin note: text overlap with arXiv:2405.16496"},{"id":"http://arxiv.org/abs/2503.10367v1","updated":"2025-03-13T13:47:03Z","published":"2025-03-13T13:47:03Z","title":"G-Boost: Boosting Private SLMs with General LLMs","summary":"  Due to the limited computational resources, most Large Language Models (LLMs)\ndevelopers can only fine-tune Small Language Models (SLMs) on their own data.\nThese private SLMs typically have limited effectiveness. To boost the\nperformance of private SLMs, this paper proposes to ask general LLMs for help.\nThe general LLMs can be APIs or larger LLMs whose inference cost the developers\ncan afford. Specifically, we propose the G-Boost framework where a private SLM\nadaptively performs collaborative inference with a general LLM under the guide\nof process reward. Experiments demonstrate that our framework can significantly\nboost the performance of private SLMs.\n","authors":["Yijiang Fan","Yuren Mao","Longbin Lai","Ying Zhang","Zhengping Qian","Yunjun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.10367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08658v2","updated":"2025-03-13T13:42:00Z","published":"2025-02-09T05:10:46Z","title":"Knowledge-data fusion dominated vehicle platoon dynamics modeling and\n  analysis: A physics-encoded deep learning approach","summary":"  Recently, artificial intelligence (AI)-enabled nonlinear vehicle platoon\ndynamics modeling plays a crucial role in predicting and optimizing the\ninteractions between vehicles. Existing efforts lack the extraction and capture\nof vehicle behavior interaction features at the platoon scale. More\nimportantly, maintaining high modeling accuracy without losing physical\nanalyzability remains to be solved. To this end, this paper proposes a novel\nphysics-encoded deep learning network, named PeMTFLN, to model the nonlinear\nvehicle platoon dynamics. Specifically, an analyzable parameters encoded\ncomputational graph (APeCG) is designed to guide the platoon to respond to the\ndriving behavior of the lead vehicle while ensuring local stability. Besides, a\nmulti-scale trajectory feature learning network (MTFLN) is constructed to\ncapture platoon following patterns and infer the physical parameters required\nfor APeCG from trajectory data. The human-driven vehicle trajectory datasets\n(HIGHSIM) were used to train the proposed PeMTFLN. The trajectories prediction\nexperiments show that PeMTFLN exhibits superior compared to the baseline models\nin terms of predictive accuracy in speed and gap. The stability analysis result\nshows that the physical parameters in APeCG is able to reproduce the platoon\nstability in real-world condition. In simulation experiments, PeMTFLN performs\nlow inference error in platoon trajectories generation. Moreover, PeMTFLN also\naccurately reproduces ground-truth safety statistics. The code of proposed\nPeMTFLN is open source.\n","authors":["Hao Lyu","Yanyong Guo","Pan Liu","Shuo Feng","Weilin Ren","Quansheng Yue"],"pdf_url":"https://arxiv.org/pdf/2502.08658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04070v7","updated":"2025-03-13T13:37:57Z","published":"2024-10-05T08:00:55Z","title":"PAD: Personalized Alignment of LLMs at Decoding-Time","summary":"  Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.\n","authors":["Ruizhe Chen","Xiaotian Zhang","Meng Luo","Wenhao Chai","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04070v7.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10356v1","updated":"2025-03-13T13:33:27Z","published":"2025-03-13T13:33:27Z","title":"Object detection characteristics in a learning factory environment using\n  YOLOv8","summary":"  AI-based object detection, and efforts to explain and investigate their\ncharacteristics, is a topic of high interest. The impact of, e.g., complex\nbackground structures with similar appearances as the objects of interest, on\nthe detection accuracy and, beforehand, the necessary dataset composition are\ntopics of ongoing research. In this paper, we present a systematic\ninvestigation of background influences and different features of the object to\nbe detected. The latter includes various materials and surfaces, partially\ntransparent and with shiny reflections in the context of an Industry 4.0\nlearning factory. Different YOLOv8 models have been trained for each of the\nmaterials on different sized datasets, where the appearance was the only\nchanging parameter. In the end, similar characteristics tend to show different\nbehaviours and sometimes unexpected results. While some background components\ntend to be detected, others with the same features are not part of the\ndetection. Additionally, some more precise conclusions can be drawn from the\nresults. Therefore, we contribute a challenging dataset with detailed\ninvestigations on 92 trained YOLO models, addressing some issues on the\ndetection accuracy and possible overfitting.\n","authors":["Toni Schneidereit","Stefan Gohrenz","Michael Breuß"],"pdf_url":"https://arxiv.org/pdf/2503.10356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11607v2","updated":"2025-03-13T13:32:53Z","published":"2024-08-21T13:32:46Z","title":"Networked Communication for Mean-Field Games with Function Approximation\n  and Empirical Mean-Field Estimation","summary":"  Recent algorithms allow decentralised agents, possibly connected via a\ncommunication network, to learn equilibria in Mean-Field Games from a\nnon-episodic run of the empirical system. However, these algorithms are for\ntabular settings: this computationally limits the size of agents' observation\nspace, meaning the algorithms cannot handle anything but small state spaces,\nnor generalise beyond policies depending only on the agent's local state to\nso-called 'population-dependent' policies. We address this limitation by\nintroducing function approximation to the existing setting, drawing on the\nMunchausen Online Mirror Descent method that has previously been employed only\nin finite-horizon, episodic, centralised settings. While this permits us to\ninclude the mean field in the observation for players' policies, it is\nunrealistic to assume decentralised agents have access to this global\ninformation: we therefore also provide new algorithms allowing agents to\nlocally estimate the global empirical distribution, and to improve this\nestimate via inter-agent communication. We show theoretically that exchanging\npolicy information helps networked agents outperform both independent and even\ncentralised agents in function-approximation settings. Our experiments\ndemonstrate this happening empirically, by an even greater margin than in\ntabular settings, and show that the communication network allows decentralised\nagents to estimate the mean field for population-dependent policies.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2408.11607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05158v2","updated":"2025-03-13T13:27:47Z","published":"2024-03-08T08:51:37Z","title":"Adaptive Split Learning over Energy-Constrained Wireless Edge Networks","summary":"  Split learning (SL) is a promising approach for training artificial\nintelligence (AI) models, in which devices collaborate with a server to train\nan AI model in a distributed manner, based on a same fixed split point.\nHowever, due to the device heterogeneity and variation of channel conditions,\nthis way is not optimal in training delay and energy consumption. In this\npaper, we design an adaptive split learning (ASL) scheme which can dynamically\nselect split points for devices and allocate computing resource for the server\nin wireless edge networks. We formulate an optimization problem to minimize the\naverage training latency subject to long-term energy consumption constraint.\nThe difficulties in solving this problem are the lack of future information and\nmixed integer programming (MIP). To solve it, we propose an online algorithm\nleveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP\nproblem only with the current information. Then, a two-layer optimization\nmethod is proposed to solve the MIP problem. Extensive simulation results\ndemonstrate that the ASL scheme can reduce the average training delay and\nenergy consumption by 53.7% and 22.1%, respectively, as compared to the\nexisting SL schemes.\n","authors":["Zuguang Li","Wen Wu","Shaohua Wu","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.05158v2.pdf","comment":"6 pages, 5 figures, 20 conferences"},{"id":"http://arxiv.org/abs/2502.12029v2","updated":"2025-03-13T13:22:46Z","published":"2025-02-17T17:02:01Z","title":"KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths\n  over Knowledge Graphs","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious complex tasks, yet they still suffer from hallucinations. Introducing\nexternal knowledge, such as knowledge graph, can enhance the LLMs' ability to\nprovide factual answers. LLMs have the ability to interactively explore\nknowledge graphs. However, most approaches have been affected by insufficient\ninternal knowledge excavation in LLMs, limited generation of trustworthy\nknowledge reasoning paths, and a vague integration between internal and\nexternal knowledge. Therefore, we propose KnowPath, a knowledge-enhanced large\nmodel framework driven by the collaboration of internal and external knowledge.\nIt relies on the internal knowledge of the LLM to guide the exploration of\ninterpretable directed subgraphs in external knowledge graphs, better\nintegrating the two knowledge sources for more accurate reasoning. Extensive\nexperiments on multiple real-world datasets confirm the superiority of\nKnowPath.\n","authors":["Qi Zhao","Hongyu Yang","Qi Song","Xinwei Yao","Xiangyang Li"],"pdf_url":"https://arxiv.org/pdf/2502.12029v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13191v2","updated":"2025-03-13T13:20:17Z","published":"2024-09-20T03:47:54Z","title":"Diabetica: Adapting Large Language Model to Enhance Multiple Medical\n  Tasks in Diabetes Care and Management","summary":"  Diabetes is a chronic disease with a significant global health burden,\nrequiring multi-stakeholder collaboration for optimal management. Large\nlanguage models (LLMs) have shown promise in various healthcare scenarios, but\ntheir effectiveness across diverse diabetes tasks remains unproven. Our study\nintroduced a framework to train and validate diabetes-specific LLMs. We first\ndeveloped a comprehensive data processing pipeline that includes data\ncollection, filtering, augmentation and refinement. This created a\nhigh-quality, diabetes-specific dataset and evaluation benchmarks from scratch.\nFine-tuned on the collected training dataset, our diabetes-specific LLM family\ndemonstrated state-of-the-art proficiency in processing various diabetes tasks\ncompared to other LLMs. Furthermore, clinical studies revealed the potential\napplications of our models in diabetes care, including providing personalized\nhealthcare, assisting medical education, and streamlining clinical tasks.\nGenerally, our introduced framework helps develop diabetes-specific LLMs and\nhighlights their potential to enhance clinical practice and provide\npersonalized, data-driven support for diabetes management across different end\nusers. Our codes, benchmarks and models are available at\nhttps://github.com/waltonfuture/Diabetica.\n","authors":["Lai Wei","Zhen Ying","Muyang He","Yutong Chen","Qian Yang","Yanzhe Hong","Jiaping Lu","Kaipeng Zheng","Shaoting Zhang","Xiaoying Li","Weiran Huang","Ying Chen"],"pdf_url":"https://arxiv.org/pdf/2409.13191v2.pdf","comment":"Accepted by ICLR 2025 SCI-FM workshop"},{"id":"http://arxiv.org/abs/2502.01129v3","updated":"2025-03-13T13:17:05Z","published":"2025-02-03T07:49:00Z","title":"Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless\n  Networks","summary":"  This report investigates the application of deep reinforcement learning (DRL)\nalgorithms for dynamic resource allocation in wireless communication systems.\nAn environment that includes a base station, multiple antennas, and user\nequipment is created. Using the RLlib library, various DRL algorithms such as\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.\nThese algorithms are compared based on their ability to optimize resource\nallocation, focusing on the impact of different learning rates and scheduling\npolicies. The findings demonstrate that the choice of algorithm and learning\nrate significantly influences system performance, with DRL providing more\nefficient resource allocation compared to traditional methods.\n","authors":["Shubham Malhotra","Fnu Yashu","Muhammad Saqib","Dipkumar Mehta","Jagdish Jangid","Sachin Dixit"],"pdf_url":"https://arxiv.org/pdf/2502.01129v3.pdf","comment":"Upon further review, we found inconsistencies in our analysis and\n  decided to conduct additional research before resubmitting a revised version"},{"id":"http://arxiv.org/abs/2503.10337v1","updated":"2025-03-13T13:15:28Z","published":"2025-03-13T13:15:28Z","title":"KV-Distill: Nearly Lossless Learnable Context Compression for LLMs","summary":"  Sequence-to-sequence tasks often benefit from long contexts, but the\nquadratic complexity of self-attention in standard Transformers renders this\nnon-trivial. During generation, temporary representations -stored in the\nso-called KV cache-account for a large portion of GPU memory usage and scale\nlinearly with context length. We introduce KV-Distill, a Transformer\ncompression framework that distills long context KV caches into significantly\nshorter representations in a question-independent fashion. KV-Distill can be\ntrained as a parameter-efficient adaptor for pretrained models, and enables the\ncompression of arbitrary spans of a context while preserving pre-trained model\ncapabilities. We treat a compressed-uncompressed cache as a student-teacher\npairing and apply a KL-type divergence to match the generated outputs.\nKV-Distill outperforms other compression techniques in worst-case extractive\ntasks and approaches uncompressed performance in long context question\nanswering and summarization, and it can be fine-tuned on domain-specific\ncontexts to reduce lengths by up to 99% while preserving downstream\nperformance. We demonstrate the generalizability of KV-Distill across various\nmodel sizes and architectures.\n","authors":["Vivek Chari","Guanghui Qin","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2503.10337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11809v2","updated":"2025-03-13T13:14:55Z","published":"2025-02-17T13:54:02Z","title":"Revealing Bias Formation in Deep Neural Networks Through the Geometric\n  Mechanisms of Human Visual Decoupling","summary":"  Deep neural networks (DNNs) often exhibit biases toward certain categories\nduring object recognition, even under balanced training data conditions. The\nintrinsic mechanisms underlying these biases remain unclear. Inspired by the\nhuman visual system, which decouples object manifolds through hierarchical\nprocessing to achieve object recognition, we propose a geometric analysis\nframework linking the geometric complexity of class-specific perceptual\nmanifolds in DNNs to model bias. Our findings reveal that differences in\ngeometric complexity can lead to varying recognition capabilities across\ncategories, introducing biases. To support this analysis, we present the\nPerceptual-Manifold-Geometry library, designed for calculating the geometric\nproperties of perceptual manifolds.\n","authors":["Yanbiao Ma","Bowei Liu","Boyuan Gao","Wei Dai","Jiayi Chen","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2502.11809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10331v1","updated":"2025-03-13T13:07:51Z","published":"2025-03-13T13:07:51Z","title":"OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting\n  Conditions","summary":"  Open Semantic Mapping (OSM) is a key technology in robotic perception,\ncombining semantic segmentation and SLAM techniques. This paper introduces a\ndynamically configurable and highly automated LLM/LVLM-powered pipeline for\nevaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).\nThe study focuses on evaluating state-of-the-art semantic mapping algorithms\nunder varying indoor lighting conditions, a critical challenge in indoor\nenvironments. We introduce a novel dataset with simulated RGB-D sequences and\nground truth 3D reconstructions, facilitating the rigorous analysis of mapping\nperformance across different lighting conditions. Through experiments on\nleading models such as ConceptGraphs, BBQ and OpenScene, we evaluate the\nsemantic fidelity of object recognition and segmentation. Additionally, we\nintroduce a Scene Graph evaluation method to analyze the ability of models to\ninterpret semantic structure. The results provide insights into the robustness\nof these models, forming future research directions for developing resilient\nand adaptable robotic systems. Our code is available at\nhttps://be2rlab.github.io/OSMa-Bench/.\n","authors":["Maxim Popov","Regina Kurkova","Mikhail Iumanov","Jaafar Mahmoud","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2503.10331v1.pdf","comment":"Project page: https://be2rlab.github.io/OSMa-Bench/"},{"id":"http://arxiv.org/abs/2503.08489v2","updated":"2025-03-13T12:57:09Z","published":"2025-03-11T14:42:17Z","title":"A Triple-Inertial Accelerated Alternating Optimization Method for Deep\n  Learning Training","summary":"  The stochastic gradient descent (SGD) algorithm has achieved remarkable\nsuccess in training deep learning models. However, it has several limitations,\nincluding susceptibility to vanishing gradients, sensitivity to input data, and\na lack of robust theoretical guarantees. In recent years, alternating\nminimization (AM) methods have emerged as a promising alternative for model\ntraining by employing gradient-free approaches to iteratively update model\nparameters. Despite their potential, these methods often exhibit slow\nconvergence rates. To address this challenge, we propose a novel\nTriple-Inertial Accelerated Alternating Minimization (TIAM) framework for\nneural network training. The TIAM approach incorporates a triple-inertial\nacceleration strategy with a specialized approximation method, facilitating\ntargeted acceleration of different terms in each sub-problem optimization. This\nintegration improves the efficiency of convergence, achieving superior\nperformance with fewer iterations. Additionally, we provide a convergence\nanalysis of the TIAM algorithm, including its global convergence properties and\nconvergence rate. Extensive experiments validate the effectiveness of the TIAM\nmethod, showing significant improvements in generalization capability and\ncomputational efficiency compared to existing approaches, particularly when\napplied to the rectified linear unit (ReLU) and its variants.\n","authors":["Chengcheng Yan","Jiawei Xu","Qingsong Wang","Zheng Peng"],"pdf_url":"https://arxiv.org/pdf/2503.08489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10318v1","updated":"2025-03-13T12:53:42Z","published":"2025-03-13T12:53:42Z","title":"Enhance Exploration in Safe Reinforcement Learning with Contrastive\n  Representation Learning","summary":"  In safe reinforcement learning, agent needs to balance between exploration\nactions and safety constraints. Following this paradigm, domain transfer\napproaches learn a prior Q-function from the related environments to prevent\nunsafe actions. However, because of the large number of false positives, some\nsafe actions are never executed, leading to inadequate exploration in\nsparse-reward environments. In this work, we aim to learn an efficient state\nrepresentation to balance the exploration and safety-prefer action in a\nsparse-reward environment. Firstly, the image input is mapped to latent\nrepresentation by an auto-encoder. A further contrastive learning objective is\nemployed to distinguish safe and unsafe states. In the learning phase, the\nlatent distance is used to construct an additional safety check, which allows\nthe agent to bias the exploration if it visits an unsafe state. To verify the\neffectiveness of our method, the experiment is carried out in three\nnavigation-based MiniGrid environments. The result highlights that our method\ncan explore the environment better while maintaining a good balance between\nsafety and efficiency.\n","authors":["Duc Kien Doan","Bang Giang Le","Viet Cuong Ta"],"pdf_url":"https://arxiv.org/pdf/2503.10318v1.pdf","comment":"Accepted at ACIIDS 2025"},{"id":"http://arxiv.org/abs/2502.06432v2","updated":"2025-03-13T12:49:20Z","published":"2025-02-10T13:09:47Z","title":"Prompt-SID: Learning Structural Representation Prompt via Latent\n  Diffusion for Single-Image Denoising","summary":"  Many studies have concentrated on constructing supervised models utilizing\npaired datasets for image denoising, which proves to be expensive and\ntime-consuming. Current self-supervised and unsupervised approaches typically\nrely on blind-spot networks or sub-image pairs sampling, resulting in pixel\ninformation loss and destruction of detailed structural information, thereby\nsignificantly constraining the efficacy of such methods. In this paper, we\nintroduce Prompt-SID, a prompt-learning-based single image denoising framework\nthat emphasizes preserving of structural details. This approach is trained in a\nself-supervised manner using downsampled image pairs. It captures\noriginal-scale image information through structural encoding and integrates\nthis prompt into the denoiser. To achieve this, we propose a structural\nrepresentation generation model based on the latent diffusion process and\ndesign a structural attention module within the transformer-based denoiser\narchitecture to decode the prompt. Additionally, we introduce a scale replay\ntraining mechanism, which effectively mitigates the scale gap from images of\ndifferent resolutions. We conduct comprehensive experiments on synthetic,\nreal-world, and fluorescence imaging datasets, showcasing the remarkable\neffectiveness of Prompt-SID. Our code will be released at\nhttps://github.com/huaqlili/Prompt-SID.\n","authors":["Huaqiu Li","Wang Zhang","Xiaowan Hu","Tao Jiang","Zikang Chen","Haoqian Wang"],"pdf_url":"https://arxiv.org/pdf/2502.06432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11282v2","updated":"2025-03-13T12:40:10Z","published":"2024-11-18T04:54:04Z","title":"Continuous K-space Recovery Network with Image Guidance for Fast MRI\n  Reconstruction","summary":"  Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis\nwhile facing the challenge of long scanning time. To reduce the acquisition\ntime, fast MRI reconstruction aims to restore high-quality images from the\nundersampled k-space. Existing methods typically train deep learning models to\nmap the undersampled data to artifact-free MRI images. However, these studies\noften overlook the unique properties of k-space and directly apply general\nnetworks designed for image processing to k-space recovery, leaving the precise\nlearning of k-space largely underexplored. In this work, we propose a\ncontinuous k-space recovery network from a new perspective of implicit neural\nrepresentation with image domain guidance, which boosts the performance of MRI\nreconstruction. Specifically, (1) an implicit neural representation based\nencoder-decoder structure is customized to continuously query unsampled\nk-values. (2) an image guidance module is designed to mine the semantic\ninformation from the low-quality MRI images to further guide the k-space\nrecovery. (3) a multi-stage training strategy is proposed to recover dense\nk-space progressively. Extensive experiments conducted on CC359, fastMRI, and\nIXI datasets demonstrate the effectiveness of our method and its superiority\nover other competitors.\n","authors":["Yucong Meng","Zhiwei Yang","Minghong Duan","Yonghong Shi","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2411.11282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.07384v2","updated":"2025-03-13T12:37:37Z","published":"2025-03-10T14:32:56Z","title":"Is My Text in Your AI Model? Gradient-based Membership Inference Test\n  applied to LLMs","summary":"  This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies.\n","authors":["Gonzalo Mancera","Daniel DeAlcala","Julian Fierrez","Ruben Tolosana","Aythami Morales"],"pdf_url":"https://arxiv.org/pdf/2503.07384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06532v2","updated":"2025-03-13T12:31:03Z","published":"2025-01-11T12:42:07Z","title":"Determination of galaxy photometric redshifts using Conditional\n  Generative Adversarial Networks (CGANs)","summary":"  Accurate and reliable photometric redshift determination is one of the key\naspects for wide-field photometric surveys. Determination of photometric\nredshift for galaxies, has been traditionally solved by use of machine-learning\nand artificial intelligence techniques trained on a calibration sample of\ngalaxies, where both photometry and spectrometry are available. On this paper,\nwe present a new algorithmic approach for determining photometric redshifts of\ngalaxies using Conditional Generative Adversarial Networks (CGANs). The\nproposed implementation is able to determine both point-estimation and\nprobability-density estimations for photometric redshifts. The methodology is\ntested with data from Dark Energy Survey (DES) Y1 data and compared with other\nexisting algorithm such as a Mixture Density Network (MDN). Although results\nobtained show a superiority of MDN, CGAN quality-metrics are close to the MDN\nresults, opening the door to the use of CGAN at photometric redshift\nestimation.\n","authors":["M. Garcia-Fernandez"],"pdf_url":"https://arxiv.org/pdf/2501.06532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10304v1","updated":"2025-03-13T12:25:36Z","published":"2025-03-13T12:25:36Z","title":"Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement\n  Learning","summary":"  Many online advertising platforms provide advertisers with auto-bidding\nservices to enhance their advertising performance. However, most existing\nauto-bidding algorithms fail to accurately capture the auto-bidding problem\nformulation that the platform truly faces, let alone solve it. Actually, we\nargue that the platform should try to help optimize each advertiser's\nperformance to the greatest extent -- which makes $\\epsilon$-Nash Equilibrium\n($\\epsilon$-NE) a necessary solution concept -- while maximizing the social\nwelfare of all the advertisers for the platform's long-term value. Based on\nthis, we introduce the \\emph{Nash-Equilibrium Constrained Bidding} (NCB), a new\nformulation of the auto-bidding problem from the platform's perspective.\nSpecifically, it aims to maximize the social welfare of all advertisers under\nthe $\\epsilon$-NE constraint. However, the NCB problem presents significant\nchallenges due to its constrained bi-level structure and the typically large\nnumber of advertisers involved. To address these challenges, we propose a\n\\emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.\nNotably, its computational complexity is independent of the number of\nadvertisers, and the associated gradients are straightforward to compute.\nExtensive simulated and real-world experiments validate the effectiveness of\nthe BPG framework.\n","authors":["Zhiyu Mou","Miao Xu","Rongquan Bai","Zhuoran Yang","Chuan Yu","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.10304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10301v1","updated":"2025-03-13T12:23:11Z","published":"2025-03-13T12:23:11Z","title":"Bilingual Dual-Head Deep Model for Parkinson's Disease Detection from\n  Speech","summary":"  This work aims to tackle the Parkinson's disease (PD) detection problem from\nthe speech signal in a bilingual setting by proposing an ad-hoc dual-head deep\nneural architecture for type-based binary classification. One head is\nspecialized for diadochokinetic patterns. The other head looks for natural\nspeech patterns present in continuous spoken utterances. Only one of the two\nheads is operative accordingly to the nature of the input. Speech\nrepresentations are extracted from self-supervised learning (SSL) models and\nwavelet transforms. Adaptive layers, convolutional bottlenecks, and contrastive\nlearning are exploited to reduce variations across languages. Our solution is\nassessed against two distinct datasets, EWA-DB, and PC-GITA, which cover Slovak\nand Spanish languages, respectively. Results indicate that conventional models\ntrained on a single language dataset struggle with cross-linguistic\ngeneralization, and naive combinations of datasets are suboptimal. In contrast,\nour model improves generalization on both languages, simultaneously.\n","authors":["Moreno La Quatra","Juan Rafael Orozco-Arroyave","Marco Sabato Siniscalchi"],"pdf_url":"https://arxiv.org/pdf/2503.10301v1.pdf","comment":"Accepted at ICASSP 2025 - Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses"},{"id":"http://arxiv.org/abs/2503.10296v1","updated":"2025-03-13T12:12:44Z","published":"2025-03-13T12:12:44Z","title":"CODEI: Resource-Efficient Task-Driven Co-Design of Perception and\n  Decision Making for Mobile Robots Applied to Autonomous Vehicles","summary":"  This paper discusses the integration challenges and strategies for designing\nmobile robots, by focusing on the task-driven, optimal selection of hardware\nand software to balance safety, efficiency, and minimal usage of resources such\nas costs, energy, computational requirements, and weight. We emphasize the\ninterplay between perception and motion planning in decision-making by\nintroducing the concept of occupancy queries to quantify the perception\nrequirements for sampling-based motion planners. Sensor and algorithm\nperformance are evaluated using False Negative Rates (FPR) and False Positive\nRates (FPR) across various factors such as geometric relationships, object\nproperties, sensor resolution, and environmental conditions. By integrating\nperception requirements with perception performance, an Integer Linear\nProgramming (ILP) approach is proposed for efficient sensor and algorithm\nselection and placement. This forms the basis for a co-design optimization that\nincludes the robot body, motion planner, perception pipeline, and computing\nunit. We refer to this framework for solving the co-design problem of mobile\nrobots as CODEI, short for Co-design of Embodied Intelligence. A case study on\ndeveloping an Autonomous Vehicle (AV) for urban scenarios provides actionable\ninformation for designers, and shows that complex tasks escalate resource\ndemands, with task performance affecting choices of the autonomy stack. The\nstudy demonstrates that resource prioritization influences sensor choice:\ncameras are preferred for cost-effective and lightweight designs, while lidar\nsensors are chosen for better energy and computational efficiency.\n","authors":["Dejan Milojevic","Gioele Zardini","Miriam Elser","Andrea Censi","Emilio Frazzoli"],"pdf_url":"https://arxiv.org/pdf/2503.10296v1.pdf","comment":"20 pages, 33 images, IEEE Transactions on Robotics"},{"id":"http://arxiv.org/abs/2503.10284v1","updated":"2025-03-13T11:52:23Z","published":"2025-03-13T11:52:23Z","title":"PyGDA: A Python Library for Graph Domain Adaptation","summary":"  Graph domain adaptation has emerged as a promising approach to facilitate\nknowledge transfer across different domains. Recently, numerous models have\nbeen proposed to enhance their generalization capabilities in this field.\nHowever, there is still no unified library that brings together existing\ntechniques and simplifies their implementation. To fill this gap, we introduce\nPyGDA, an open-source Python library tailored for graph domain adaptation. As\nthe first comprehensive library in this area, PyGDA covers more than 20 widely\nused graph domain adaptation methods together with different types of graph\ndatasets. Specifically, PyGDA offers modular components, enabling users to\nseamlessly build custom models with a variety of commonly used utility\nfunctions. To handle large-scale graphs, PyGDA includes support for features\nsuch as sampling and mini-batch processing, ensuring efficient computation. In\naddition, PyGDA also includes comprehensive performance benchmarks and\nwell-documented user-friendly API for both researchers and practitioners. To\nfoster convenient accessibility, PyGDA is released under the MIT license at\nhttps://github.com/pygda-team/pygda, and the API documentation is\nhttps://pygda.readthedocs.io/en/stable/.\n","authors":["Zhen Zhang","Meihan Liu","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2503.10284v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2312.09672v3","updated":"2025-03-13T11:47:05Z","published":"2023-12-15T10:34:53Z","title":"InstructPipe: Generating Visual Blocks Pipelines with Human Instructions\n  and LLMs","summary":"  Visual programming has the potential of providing novice programmers with a\nlow-code experience to build customized processing pipelines. Existing systems\ntypically require users to build pipelines from scratch, implying that novice\nusers are expected to set up and link appropriate nodes from a blank workspace.\nIn this paper, we introduce InstructPipe, an AI assistant for prototyping\nmachine learning (ML) pipelines with text instructions. We contribute two large\nlanguage model (LLM) modules and a code interpreter as part of our framework.\nThe LLM modules generate pseudocode for a target pipeline, and the interpreter\nrenders the pipeline in the node-graph editor for further human-AI\ncollaboration. Both technical and user evaluation (N=16) shows that\nInstructPipe empowers users to streamline their ML pipeline workflow, reduce\ntheir learning curve, and leverage open-ended commands to spark innovative\nideas.\n","authors":["Zhongyi Zhou","Jing Jin","Vrushank Phadnis","Xiuxiu Yuan","Jun Jiang","Xun Qian","Kristen Wright","Mark Sherwood","Jason Mayes","Jingtao Zhou","Yiyi Huang","Zheng Xu","Yinda Zhang","Johnny Lee","Alex Olwal","David Kim","Ram Iyengar","Na Li","Ruofei Du"],"pdf_url":"https://arxiv.org/pdf/2312.09672v3.pdf","comment":"CHI 2025"},{"id":"http://arxiv.org/abs/2502.07842v2","updated":"2025-03-13T11:32:19Z","published":"2025-02-11T05:32:14Z","title":"Column-wise Quantization of Weights and Partial Sums for Accurate and\n  Efficient Compute-In-Memory Accelerators","summary":"  Compute-in-memory (CIM) is an efficient method for implementing deep neural\nnetworks (DNNs) but suffers from substantial overhead from analog-to-digital\nconverters (ADCs), especially as ADC precision increases. Low-precision ADCs\ncan reduce this overhead but introduce partial-sum quantization errors\ndegrading accuracy. Additionally, low-bit weight constraints, imposed by cell\nlimitations and the need for multiple cells for higher-bit weights, present\nfurther challenges. While fine-grained partial-sum quantization has been\nstudied to lower ADC resolution effectively, weight granularity, which limits\noverall partial-sum quantized accuracy, remains underexplored. This work\naddresses these challenges by aligning weight and partial-sum quantization\ngranularities at the column-wise level. Our method improves accuracy while\nmaintaining dequantization overhead, simplifies training by removing two-stage\nprocesses, and ensures robustness to memory cell variations via independent\ncolumn-wise scale factors. We also propose an open-source CIM-oriented\nconvolution framework to handle fine-grained weights and partial-sums\nefficiently, incorporating a novel tiling method and group convolution.\nExperimental results on ResNet-20 (CIFAR-10, CIFAR-100) and ResNet-18\n(ImageNet) show accuracy improvements of 0.99%, 2.69%, and 1.01%, respectively,\ncompared to the best-performing related works. Additionally, variation analysis\nreveals the robustness of our method against memory cell variations. These\nfindings highlight the effectiveness of our quantization scheme in enhancing\naccuracy and robustness while maintaining hardware efficiency in CIM-based DNN\nimplementations. Our code is available at\nhttps://github.com/jiyoonkm/ColumnQuant.\n","authors":["Jiyoon Kim","Kang Eun Jeon","Yulhwa Kim","Jong Hwan Ko"],"pdf_url":"https://arxiv.org/pdf/2502.07842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10265v1","updated":"2025-03-13T11:23:13Z","published":"2025-03-13T11:23:13Z","title":"SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for\n  Surgical Intelligence","summary":"  Integration of Vision-Language Models (VLMs) in surgical intelligence is\nhindered by hallucinations, domain knowledge gaps, and limited understanding of\ntask interdependencies within surgical scenes, undermining clinical\nreliability. While recent VLMs demonstrate strong general reasoning and\nthinking capabilities, they still lack the domain expertise and task-awareness\nrequired for precise surgical scene interpretation. Although Chain-of-Thought\n(CoT) can structure reasoning more effectively, current approaches rely on\nself-generated CoT steps, which often exacerbate inherent domain gaps and\nhallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent\nframework that delivers transparent, interpretable insights for most tasks in\nrobotic-assisted surgery. By employing specialized CoT prompts across five\ntasks: instrument recognition, action recognition, action prediction, patient\ndata extraction, and outcome assessment, SurgRAW mitigates hallucinations\nthrough structured, domain-aware reasoning. Retrieval-Augmented Generation\n(RAG) is also integrated to external medical knowledge to bridge domain gaps\nand improve response reliability. Most importantly, a hierarchical agentic\nsystem ensures that CoT-embedded VLM agents collaborate effectively while\nunderstanding task interdependencies, with a panel discussion mechanism\npromotes logical consistency. To evaluate our method, we introduce\nSurgCoTBench, the first reasoning-based dataset with structured frame-level\nannotations. With comprehensive experiments, we demonstrate the effectiveness\nof proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12\nrobotic procedures, achieving the state-of-the-art performance and advancing\nexplainable, trustworthy, and autonomous surgical assistance.\n","authors":["Chang Han Low","Ziyue Wang","Tianyi Zhang","Zhitao Zeng","Zhu Zhuo","Evangelos B. Mazomenos","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2503.10265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08725v2","updated":"2025-03-13T11:16:38Z","published":"2025-03-11T00:20:56Z","title":"The Algorithmic State Architecture (ASA): An Integrated Framework for\n  AI-Enabled Government","summary":"  As artificial intelligence transforms public sector operations, governments\nstruggle to integrate technological innovations into coherent systems for\neffective service delivery. This paper introduces the Algorithmic State\nArchitecture (ASA), a novel four-layer framework conceptualising how Digital\nPublic Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and\nGovTech interact as an integrated system in AI-enabled states. Unlike\napproaches that treat these as parallel developments, ASA positions them as\ninterdependent layers with specific enabling relationships and feedback\nmechanisms. Through comparative analysis of implementations in Estonia,\nSingapore, India, and the UK, we demonstrate how foundational digital\ninfrastructure enables systematic data collection, which powers algorithmic\ndecision-making processes, ultimately manifesting in user-facing services. Our\nanalysis reveals that successful implementations require balanced development\nacross all layers, with particular attention to integration mechanisms between\nthem. The framework contributes to both theory and practice by bridging\npreviously disconnected domains of digital government research, identifying\ncritical dependencies that influence implementation success, and providing a\nstructured approach for analysing the maturity and development pathways of\nAI-enabled government systems.\n","authors":["Zeynep Engin","Jon Crowcroft","David Hand","Philip Treleaven"],"pdf_url":"https://arxiv.org/pdf/2503.08725v2.pdf","comment":"Main text: 25 pages, with references: 35 pages, 2 figures"},{"id":"http://arxiv.org/abs/2412.07752v3","updated":"2025-03-13T11:14:49Z","published":"2024-12-10T18:50:37Z","title":"FlashRNN: I/O-Aware Optimization of Traditional RNNs on modern hardware","summary":"  While Transformers and other sequence-parallelizable neural network\narchitectures seem like the current state of the art in sequence modeling, they\nspecifically lack state-tracking capabilities. These are important for\ntime-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,\nas well as modern variants like sLSTM do have these capabilities at the cost of\nstrictly sequential processing. While this is often seen as a strong\nlimitation, we show how fast these networks can get with our\nhardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the\nregister level on modern GPUs. We extend traditional RNNs with a\nparallelization variant that processes multiple RNNs of smaller hidden state in\nparallel, similar to the head-wise processing in Transformers. To enable\nflexibility on different GPU variants, we introduce a new optimization\nframework for hardware-internal cache sizes, memory and compute handling. It\nmodels the hardware in a setting using polyhedral-like constraints, including\nthe notion of divisibility. This speeds up the solution process in our\nConstrINT library for general integer constraint satisfaction problems (integer\nCSPs). We show that our kernels can achieve 50x speed-ups over a vanilla\nPyTorch implementation and allow 40x larger hidden sizes compared to our Triton\nimplementation. Our open-source kernels and the optimization library are\nreleased here to boost research in the direction of state-tracking enabled RNNs\nand sequence modeling: https://github.com/NX-AI/flashrnn\n","authors":["Korbinian Pöppel","Maximilian Beck","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2412.07752v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10253v1","updated":"2025-03-13T11:01:03Z","published":"2025-03-13T11:01:03Z","title":"PIMRL: Physics-Informed Multi-Scale Recurrent Learning for\n  Spatiotemporal Prediction","summary":"  Simulation of spatiotemporal systems governed by partial differential\nequations is widely applied in fields such as biology, chemistry, aerospace\ndynamics, and meteorology. Traditional numerical methods incur high\ncomputational costs due to the requirement of small time steps for accurate\npredictions. While machine learning has reduced these costs, long-term\npredictions remain challenged by error accumulation, particularly in scenarios\nwith insufficient data or varying time scales, where stability and accuracy are\ncompromised. Existing methods often neglect the effective utilization of\nmulti-scale data, leading to suboptimal robustness in predictions. To address\nthese issues, we propose a novel multi-scale learning framework, namely, the\nPhysics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively\nleverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL\nframework comprises two modules: the micro-scale module embeds physical\nknowledge into neural networks via pretraining, and the macro-scale module\nadopts a data-driven approach to learn the temporal evolution of physics in the\nlatent space. Experimental results demonstrate that the PIMRL framework\nconsistently achieves state-of-the-art performance across five benchmark\ndatasets ranging from one to three dimensions, showing average improvements of\nover 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements\nreaching up to 80%.\n","authors":["Han Wan","Qi Wang","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2503.10253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10248v1","updated":"2025-03-13T10:47:03Z","published":"2025-03-13T10:47:03Z","title":"LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns","summary":"  We investigate the choice patterns of Large Language Models (LLMs) in the\ncontext of Decisions from Experience tasks that involve repeated choice and\nlearning from feedback, and compare their behavior to human participants. We\nfind that on the aggregate, LLMs appear to display behavioral biases similar to\nhumans: both exhibit underweighting rare events and correlation effects.\nHowever, more nuanced analyses of the choice patterns reveal that this happens\nfor very different reasons. LLMs exhibit strong recency biases, unlike humans,\nwho appear to respond in more sophisticated ways. While these different\nprocesses may lead to similar behavior on average, choice patterns contingent\non recent events differ vastly between the two groups. Specifically, phenomena\nsuch as ``surprise triggers change\" and the ``wavy recency effect of rare\nevents\" are robustly observed in humans, but entirely absent in LLMs. Our\nfindings provide insights into the limitations of using LLMs to simulate and\npredict humans in learning environments and highlight the need for refined\nanalyses of their behavior when investigating whether they replicate human\ndecision making tendencies.\n","authors":["Idan Horowitz","Ori Plonsky"],"pdf_url":"https://arxiv.org/pdf/2503.10248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08708v2","updated":"2025-03-13T10:37:18Z","published":"2025-03-10T02:55:05Z","title":"TH-Bench: Evaluating Evading Attacks via Humanizing AI Text on\n  Machine-Generated Text Detectors","summary":"  As Large Language Models (LLMs) advance, Machine-Generated Texts (MGTs) have\nbecome increasingly fluent, high-quality, and informative. Existing wide-range\nMGT detectors are designed to identify MGTs to prevent the spread of plagiarism\nand misinformation. However, adversaries attempt to humanize MGTs to evade\ndetection (named evading attacks), which requires only minor modifications to\nbypass MGT detectors. Unfortunately, existing attacks generally lack a unified\nand comprehensive evaluation framework, as they are assessed using different\nexperimental settings, model architectures, and datasets. To fill this gap, we\nintroduce the Text-Humanization Benchmark (TH-Bench), the first comprehensive\nbenchmark to evaluate evading attacks against MGT detectors. TH-Bench evaluates\nattacks across three key dimensions: evading effectiveness, text quality, and\ncomputational overhead. Our extensive experiments evaluate 6 state-of-the-art\nattacks against 13 MGT detectors across 6 datasets, spanning 19 domains and\ngenerated by 11 widely used LLMs. Our findings reveal that no single evading\nattack excels across all three dimensions. Through in-depth analysis, we\nhighlight the strengths and limitations of different attacks. More importantly,\nwe identify a trade-off among three dimensions and propose two optimization\ninsights. Through preliminary experiments, we validate their correctness and\neffectiveness, offering potential directions for future research.\n","authors":["Jingyi Zheng","Junfeng Wang","Zhen Sun","Wenhan Dong","Yule Liu","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2503.08708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10242v1","updated":"2025-03-13T10:34:43Z","published":"2025-03-13T10:34:43Z","title":"MinorBench: A hand-built benchmark for content-based risks for children","summary":"  Large Language Models (LLMs) are rapidly entering children's lives - through\nparent-driven adoption, schools, and peer networks - yet current AI ethics and\nsafety research do not adequately address content-related risks specific to\nminors. In this paper, we highlight these gaps with a real-world case study of\nan LLM-based chatbot deployed in a middle school setting, revealing how\nstudents used and sometimes misused the system. Building on these findings, we\npropose a new taxonomy of content-based risks for minors and introduce\nMinorBench, an open-source benchmark designed to evaluate LLMs on their ability\nto refuse unsafe or inappropriate queries from children. We evaluate six\nprominent LLMs under different system prompts, demonstrating substantial\nvariability in their child-safety compliance. Our results inform practical\nsteps for more robust, child-focused safety mechanisms and underscore the\nurgency of tailoring AI systems to safeguard young users.\n","authors":["Shaun Khoo","Gabriel Chua","Rachel Shong"],"pdf_url":"https://arxiv.org/pdf/2503.10242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04653v4","updated":"2025-03-13T10:33:15Z","published":"2024-12-05T22:50:42Z","title":"Hidden in the Noise: Two-Stage Robust Watermarking for Images","summary":"  As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.\n","authors":["Kasra Arabi","Benjamin Feuer","R. Teal Witter","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2412.04653v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15658v2","updated":"2025-03-13T10:15:59Z","published":"2024-09-24T01:47:23Z","title":"Long-horizon Embodied Planning with Implicit Logical Inference and\n  Hallucination Mitigation","summary":"  Long-horizon embodied planning underpins embodied AI. To accomplish\nlong-horizon tasks, one of the most feasible ways is to decompose abstract\ninstructions into a sequence of actionable steps. Foundation models still face\nlogical errors and hallucinations in long-horizon planning, unless provided\nwith highly relevant examples to the tasks. However, providing highly relevant\nexamples for any random task is unpractical. Therefore, we present ReLEP, a\nnovel framework for Real-time Long-horizon Embodied Planning. ReLEP can\ncomplete a wide range of long-horizon tasks without in-context examples by\nlearning implicit logical inference through fine-tuning. The fine-tuned large\nvision-language model formulates plans as sequences of skill functions. These\nfunctions are selected from a carefully designed skill library. ReLEP is also\nequipped with a Memory module for plan and status recall, and a Robot\nConfiguration module for versatility across robot types. In addition, we\npropose a data generation pipeline to tackle dataset scarcity. When\nconstructing the dataset, we considered the implicit logical relationships,\nenabling the model to learn implicit logical relationships and dispel\nhallucinations. Through comprehensive evaluations across various long-horizon\ntasks, ReLEP demonstrates high success rates and compliance to execution even\non unseen tasks and outperforms state-of-the-art baseline methods.\n","authors":["Siyuan Liu","Jiawei Du","Sicheng Xiang","Zibo Wang","Dingsheng Luo"],"pdf_url":"https://arxiv.org/pdf/2409.15658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10217v1","updated":"2025-03-13T09:59:16Z","published":"2025-03-13T09:59:16Z","title":"Efficient Federated Fine-Tuning of Large Language Models with Layer\n  Dropout","summary":"  Fine-tuning plays a crucial role in enabling pre-trained LLMs to evolve from\ngeneral language comprehension to task-specific expertise. To preserve user\ndata privacy, federated fine-tuning is often employed and has emerged as the de\nfacto paradigm. However, federated fine-tuning is prohibitively inefficient due\nto the tension between LLM complexity and the resource constraint of end\ndevices, incurring unaffordable fine-tuning overhead. Existing literature\nprimarily utilizes parameter-efficient fine-tuning techniques to mitigate\ncommunication costs, yet computational and memory burdens continue to pose\nsignificant challenges for developers. This work proposes DropPEFT, an\ninnovative federated PEFT framework that employs a novel stochastic transformer\nlayer dropout method, enabling devices to deactivate a considerable fraction of\nLLMs layers during training, thereby eliminating the associated computational\nload and memory footprint. In DropPEFT, a key challenge is the proper\nconfiguration of dropout ratios for layers, as overhead and training\nperformance are highly sensitive to this setting. To address this challenge, we\nadaptively assign optimal dropout-ratio configurations to devices through an\nexploration-exploitation strategy, achieving efficient and effective\nfine-tuning. Extensive experiments show that DropPEFT can achieve a\n1.3-6.3\\times speedup in model convergence and a 40%-67% reduction in memory\nfootprint compared to state-of-the-art methods.\n","authors":["Shilong Wang","Jianchun Liu","Hongli Xu","Jiaming Yan","Xianjun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.10217v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2503.10215v1","updated":"2025-03-13T09:57:41Z","published":"2025-03-13T09:57:41Z","title":"Adaptive Preference Aggregation","summary":"  AI alignment, the challenge of ensuring AI systems act in accordance with\nhuman values, has emerged as a critical problem in the development of systems\nsuch as foundation models and recommender systems. Still, the current dominant\napproach, reinforcement learning with human feedback (RLHF) faces known\ntheoretical limitations in aggregating diverse human preferences. Social choice\ntheory provides a framework to aggregate preferences, but was not developed for\nthe multidimensional applications typical of AI. Leveraging insights from a\nrecently published urn process, this work introduces a preference aggregation\nstrategy that adapts to the user's context and that inherits the good\nproperties of the maximal lottery, a Condorcet-consistent solution concept.\n","authors":["Benjamin Heymann"],"pdf_url":"https://arxiv.org/pdf/2503.10215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10198v1","updated":"2025-03-13T09:32:01Z","published":"2025-03-13T09:32:01Z","title":"Deep Learning for Time Series Forecasting: A Survey","summary":"  Time series forecasting (TSF) has long been a crucial task in both industry\nand daily life. Most classical statistical models may have certain limitations\nwhen applied to practical scenarios in fields such as energy, healthcare,\ntraffic, meteorology, and economics, especially when high accuracy is required.\nWith the continuous development of deep learning, numerous new models have\nemerged in the field of time series forecasting in recent years. However,\nexisting surveys have not provided a unified summary of the wide range of model\narchitectures in this field, nor have they given detailed summaries of works in\nfeature extraction and datasets. To address this gap, in this review, we\ncomprehensively study the previous works and summarize the general paradigms of\nDeep Time Series Forecasting (DTSF) in terms of model architectures. Besides,\nwe take an innovative approach by focusing on the composition of time series\nand systematically explain important feature extraction methods. Additionally,\nwe provide an overall compilation of datasets from various domains in existing\nworks. Finally, we systematically emphasize the significant challenges faced\nand future research directions in this field.\n","authors":["Xiangjie Kong","Zhenghao Chen","Weiyao Liu","Kaili Ning","Lechao Zhang","Syauqie Muhammad Marier","Yichen Liu","Yuhao Chen","Feng Xia"],"pdf_url":"https://arxiv.org/pdf/2503.10198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10197v1","updated":"2025-03-13T09:31:51Z","published":"2025-03-13T09:31:51Z","title":"Predicting Chemical Reaction Outcomes Based on Electron Movements Using\n  Machine Learning","summary":"  Accurately predicting chemical reaction outcomes and potential byproducts is\na fundamental task of modern chemistry, enabling the efficient design of\nsynthetic pathways and driving progress in chemical science. Reaction\nmechanism, which tracks electron movements during chemical reactions, is\ncritical for understanding reaction kinetics and identifying unexpected\nproducts. Here, we present Reactron, the first electron-based machine learning\nmodel for general reaction prediction. Reactron integrates electron movement\ninto its predictions, generating detailed arrow-pushing diagrams that elucidate\neach mechanistic step leading to product formation. We demonstrate the high\npredictive performance of Reactron over existing product-only models by a\nlarge-scale reaction outcome prediction benchmark, and the adaptability of the\nmodel to learn new reactivity upon providing a few examples. Furthermore, it\nexplores combinatorial reaction spaces, uncovering novel reactivities beyond\nits training data. With robust performance in both in- and out-of-distribution\npredictions, Reactron embodies human-like reasoning in chemistry and opens new\nfrontiers in reaction discovery and synthesis design.\n","authors":["Shuan Chen","Kye Sung Park","Taewan Kim","Sunkyu Han","Yousung Jung"],"pdf_url":"https://arxiv.org/pdf/2503.10197v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2409.07486v2","updated":"2025-03-13T09:26:41Z","published":"2024-09-04T08:16:22Z","title":"MarS: a Financial Market Simulation Engine Powered by Generative\n  Foundation Model","summary":"  Generative models aim to simulate realistic effects of various actions across\ndifferent contexts, from text generation to visual effects. Despite significant\nefforts to build real-world simulators, the application of generative models to\nvirtual worlds, like financial markets, remains under-explored. In financial\nmarkets, generative models can simulate complex market effects of participants\nwith various behaviors, enabling interaction under different market conditions,\nand training strategies without financial risk. This simulation relies on the\nfinest structured data in financial market like orders thus building the finest\nrealistic simulation. We propose Large Market Model (LMM), an order-level\ngenerative foundation model, for financial market simulation, akin to language\nmodeling in the digital world. Our financial Market Simulation engine (MarS),\npowered by LMM, addresses the domain-specific need for realistic, interactive\nand controllable order generation. Key observations include LMM's strong\nscalability across data size and model complexity, and MarS's robust and\npracticable realism in controlled generation with market impact. We showcase\nMarS as a forecast tool, detection system, analysis platform, and agent\ntraining environment, thus demonstrating MarS's \"paradigm shift\" potential for\na variety of financial applications. We release the code of MarS at\nhttps://github.com/microsoft/MarS/.\n","authors":["Junjie Li","Yang Liu","Weiqing Liu","Shikai Fang","Lewen Wang","Chang Xu","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2409.07486v2.pdf","comment":"35 pages, 26 figures, ICLR 2025"},{"id":"http://arxiv.org/abs/2503.10191v1","updated":"2025-03-13T09:26:19Z","published":"2025-03-13T09:26:19Z","title":"Robustness Tokens: Towards Adversarial Robustness of Transformers","summary":"  Recently, large pre-trained foundation models have become widely adopted by\nmachine learning practitioners for a multitude of tasks. Given that such models\nare publicly available, relying on their use as backbone models for downstream\ntasks might result in high vulnerability to adversarial attacks crafted with\nthe same public model. In this work, we propose Robustness Tokens, a novel\napproach specific to the transformer architecture that fine-tunes a few\nadditional private tokens with low computational requirements instead of tuning\nmodel parameters as done in traditional adversarial training. We show that\nRobustness Tokens make Vision Transformer models significantly more robust to\nwhite-box adversarial attacks while also retaining the original downstream\nperformances.\n","authors":["Brian Pulfer","Yury Belousov","Slava Voloshynovskiy"],"pdf_url":"https://arxiv.org/pdf/2503.10191v1.pdf","comment":"This paper has been accepted for publication at the European\n  Conference on Computer Vision (ECCV), 2024"},{"id":"http://arxiv.org/abs/2503.10186v1","updated":"2025-03-13T09:16:51Z","published":"2025-03-13T09:16:51Z","title":"Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to\n  Exploration and Sparsity","summary":"  Beyond specific settings, many multi-agent learning algorithms fail to\nconverge to an equilibrium solution, and instead display complex,\nnon-stationary behaviours such as recurrent or chaotic orbits. In fact, recent\nliterature suggests that such complex behaviours are likely to occur when the\nnumber of agents increases. In this paper, we study Q-learning dynamics in\nnetwork polymatrix games where the network structure is drawn from classical\nrandom graph models. In particular, we focus on the Erdos-Renyi model, a\nwell-studied model for social networks, and the Stochastic Block model, which\ngeneralizes the above by accounting for community structures within the\nnetwork. In each setting, we establish sufficient conditions under which the\nagents' joint strategies converge to a unique equilibrium. We investigate how\nthis condition depends on the exploration rates, payoff matrices and,\ncrucially, the sparsity of the network. Finally, we validate our theoretical\nfindings through numerical simulations and demonstrate that convergence can be\nreliably achieved in many-agent systems, provided network sparsity is\ncontrolled.\n","authors":["Aamal Hussain","Dan Leonte","Francesco Belardinelli","Raphael Huser","Dario Paccagnan"],"pdf_url":"https://arxiv.org/pdf/2503.10186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10183v1","updated":"2025-03-13T09:14:11Z","published":"2025-03-13T09:14:11Z","title":"Through the Magnifying Glass: Adaptive Perception Magnification for\n  Hallucination-Free VLM Decoding","summary":"  Existing vision-language models (VLMs) often suffer from visual\nhallucination, where the generated responses contain inaccuracies that are not\ngrounded in the visual input. Efforts to address this issue without model\nfinetuning primarily mitigate hallucination by reducing biases contrastively or\namplifying the weights of visual embedding during decoding. However, these\napproaches improve visual perception at the cost of impairing the language\nreasoning capability. In this work, we propose the Perception Magnifier (PM), a\nnovel visual decoding method that iteratively isolates relevant visual tokens\nbased on attention and magnifies the corresponding regions, spurring the model\nto concentrate on fine-grained visual details during decoding. Specifically, by\nmagnifying critical regions while preserving the structural and contextual\ninformation at each decoding step, PM allows the VLM to enhance its scrutiny of\nthe visual input, hence producing more accurate and faithful responses.\nExtensive experimental results demonstrate that PM not only achieves superior\nhallucination mitigation but also enhances language generation while preserving\nstrong reasoning capabilities.Code is available at\nhttps://github.com/ShunqiM/PM .\n","authors":["Shunqi Mao","Chaoyi Zhang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2503.10183v1.pdf","comment":"19 pages, 5 figures, 9 tables"},{"id":"http://arxiv.org/abs/2406.08426v5","updated":"2025-03-13T08:45:35Z","published":"2024-06-12T17:13:17Z","title":"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL","summary":"  Generating accurate SQL from users' natural language questions (text-to-SQL)\nremains a long-standing challenge due to the complexities involved in user\nquestion understanding, database schema comprehension, and SQL generation.\nTraditional text-to-SQL systems, which combine human engineering and deep\nneural networks, have made significant progress. Subsequently, pre-trained\nlanguage models (PLMs) have been developed for text-to-SQL tasks, achieving\npromising results. However, as modern databases and user questions grow more\ncomplex, PLMs with a limited parameter size often produce incorrect SQL. This\nnecessitates more sophisticated and tailored optimization methods, which\nrestricts the application of PLM-based systems. Recently, large language models\n(LLMs) have shown significant capabilities in natural language understanding as\nmodel scale increases. Thus, integrating LLM-based solutions can bring unique\nopportunities, improvements, and solutions to text-to-SQL research. In this\nsurvey, we provide a comprehensive review of existing LLM-based text-to-SQL\nstudies. Specifically, we offer a brief overview of the technical challenges\nand evolutionary process of text-to-SQL. Next, we introduce the datasets and\nmetrics designed to evaluate text-to-SQL systems. Subsequently, we present a\nsystematic analysis of recent advances in LLM-based text-to-SQL. Finally, we\nmake a summarization and discuss the remaining challenges in this field and\nsuggest expectations for future research directions.\n","authors":["Zijin Hong","Zheng Yuan","Qinggang Zhang","Hao Chen","Junnan Dong","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2406.08426v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10166v1","updated":"2025-03-13T08:43:24Z","published":"2025-03-13T08:43:24Z","title":"ImageScope: Unifying Language-Guided Image Retrieval via Large\n  Multimodal Model Collective Reasoning","summary":"  With the proliferation of images in online content, language-guided image\nretrieval (LGIR) has emerged as a research hotspot over the past decade,\nencompassing a variety of subtasks with diverse input forms. While the\ndevelopment of large multimodal models (LMMs) has significantly facilitated\nthese tasks, existing approaches often address them in isolation, requiring the\nconstruction of separate systems for each task. This not only increases system\ncomplexity and maintenance costs, but also exacerbates challenges stemming from\nlanguage ambiguity and complex image content, making it difficult for retrieval\nsystems to provide accurate and reliable results. To this end, we propose\nImageScope, a training-free, three-stage framework that leverages collective\nreasoning to unify LGIR tasks. The key insight behind the unification lies in\nthe compositional nature of language, which transforms diverse LGIR tasks into\na generalized text-to-image retrieval process, along with the reasoning of LMMs\nserving as a universal verification to refine the results. To be specific, in\nthe first stage, we improve the robustness of the framework by synthesizing\nsearch intents across varying levels of semantic granularity using\nchain-of-thought (CoT) reasoning. In the second and third stages, we then\nreflect on retrieval results by verifying predicate propositions locally, and\nperforming pairwise evaluations globally. Experiments conducted on six LGIR\ndatasets demonstrate that ImageScope outperforms competitive baselines.\nComprehensive evaluations and ablation studies further confirm the\neffectiveness of our design.\n","authors":["Pengfei Luo","Jingbo Zhou","Tong Xu","Yuan Xia","Linli Xu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.10166v1.pdf","comment":"WWW 2025"},{"id":"http://arxiv.org/abs/2411.00915v4","updated":"2025-03-13T08:38:15Z","published":"2024-11-01T13:43:33Z","title":"V-LoRA: An Efficient and Flexible System Boosts Vision Applications with\n  LoRA LMM","summary":"  Large Multimodal Models (LMMs) have shown significant progress in various\ncomplex vision tasks with the solid linguistic and reasoning capacity inherited\nfrom large language models (LMMs). Low-rank adaptation (LoRA) offers a\npromising method to integrate external knowledge into LMMs, compensating for\ntheir limitations on domain-specific tasks. However, the existing LoRA model\nserving is excessively computationally expensive and causes extremely high\nlatency. In this paper, we present an end-to-end solution that empowers diverse\nvision tasks and enriches vision applications with LoRA LMMs. Our system,\nVaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware\nLoRA adapter generation approach that generates LoRA adapters rich in\ndomain-specific knowledge to meet application-specific accuracy requirements,\n2) an adaptive-tiling LoRA adapters batching operator that efficiently computes\nconcurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter\norchestration mechanism that manages application requests and LoRA adapters to\nachieve the lowest average response latency. We prototype VaLoRA on five\npopular vision tasks on three LMMs. Experiment results reveal that VaLoRA\nimproves 24-62% of the accuracy compared to the original LMMs and reduces\n20-89% of the latency compared to the state-of-the-art LoRA model serving\nsystems.\n","authors":["Liang Mi","Weijun Wang","Wenming Tu","Qingfeng He","Rui Kong","Xinyu Fang","Yazhu Dong","Yikang Zhang","Yunchun Li","Meng Li","Haipeng Dai","Guihai Chen","Yunxin Liu"],"pdf_url":"https://arxiv.org/pdf/2411.00915v4.pdf","comment":"EuroSys'2025"},{"id":"http://arxiv.org/abs/2503.10150v1","updated":"2025-03-13T08:22:31Z","published":"2025-03-13T08:22:31Z","title":"Retrieval-Augmented Generation with Hierarchical Knowledge","summary":"  Graph-based Retrieval-Augmented Generation (RAG) methods have significantly\nenhanced the performance of large language models (LLMs) in domain-specific\ntasks. However, existing RAG methods do not adequately utilize the naturally\ninherent hierarchical knowledge in human cognition, which limits the\ncapabilities of RAG systems. In this paper, we introduce a new RAG approach,\ncalled HiRAG, which utilizes hierarchical knowledge to enhance the semantic\nunderstanding and structure capturing capabilities of RAG systems in the\nindexing and retrieval processes. Our extensive experiments demonstrate that\nHiRAG achieves significant performance improvements over the state-of-the-art\nbaseline methods. The code of our proposed method is available at\n\\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.\n","authors":["Haoyu Huang","Yongfeng Huang","Junjie Yang","Zhenyu Pan","Yongqiang Chen","Kaili Ma","Hongzhi Chen","James Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.10150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10144v1","updated":"2025-03-13T08:14:00Z","published":"2025-03-13T08:14:00Z","title":"Multiplicative Learning","summary":"  Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.\n","authors":["Han Kim","Hyungjoon Soh","Vipul Periwal","Junghyo Jo"],"pdf_url":"https://arxiv.org/pdf/2503.10144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05116v3","updated":"2025-03-13T08:12:07Z","published":"2024-10-07T15:12:01Z","title":"HERO: Human-Feedback Efficient Reinforcement Learning for Online\n  Diffusion Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback. The code and project page are available\nat https://hero-dm.github.io/.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v3.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2503.10135v1","updated":"2025-03-13T07:55:38Z","published":"2025-03-13T07:55:38Z","title":"Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative\n  Decoding","summary":"  Speculative decoding (SPD) aims to accelerate the auto-regressive token\ngeneration process of a target Large Language Model (LLM). Some approaches\nemploy a draft model with multiple heads to predict a sequence of future\ntokens, where each head handles a token in the sequence. The target LLM\nverifies the predicted sequence and accepts aligned tokens, enabling efficient\nmulti-token generation. However, existing methods assume that all tokens within\na sequence are equally important, employing identical head structures and\nrelying on a single-generation paradigm, either serial or parallel. To this\nend, we theoretically demonstrate that initial tokens in the draft sequence are\nmore important than later ones. Building on this insight, we propose Gumiho, a\nhybrid model combining serial and parallel heads. Specifically, given the\ncritical importance of early tokens, we employ a sophisticated Transformer\narchitecture for the early draft heads in a serial configuration to improve\naccuracy. For later tokens, we utilize multiple lightweight MLP heads operating\nin parallel to enhance efficiency. By allocating more advanced model structures\nand longer running times to the early heads, Gumiho achieves improved overall\nperformance. The experimental results demonstrate that our method outperforms\nexisting approaches, fully validating its effectiveness.\n","authors":["Jinze Li","Yixing Xu","Haiduo Huang","Xuanwu Yin","Dong Li","Edith C. H. Ngai","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2503.10135v1.pdf","comment":"Paper under review"},{"id":"http://arxiv.org/abs/2503.04779v2","updated":"2025-03-13T07:41:37Z","published":"2025-02-22T13:27:31Z","title":"Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of\n  LLMs on Formal Specification Inference","summary":"  Large Language Models (LLMs) are increasingly being used to automate\nprogramming tasks. Yet, LLMs' capabilities in reasoning about program semantics\nare still inadequately studied, leaving significant potential for further\nexploration. This paper introduces FormalBench, a comprehensive benchmark\ndesigned to evaluate LLMs' reasoning abilities on program semantics,\nparticularly via the task of synthesizing formal program specifications to\nassist verifying program correctness. This task requires both comprehensive\nreasoning over all possible program executions and the generation of precise,\nsyntactically correct expressions that adhere to formal syntax and semantics.\nUsing this benchmark, we evaluated the ability of LLMs in synthesizing\nconsistent and complete specifications. Our findings show that LLMs perform\nwell with simple control flows but struggle with more complex structures,\nespecially loops, even with advanced prompting. Additionally, LLMs exhibit\nlimited robustness against semantic-preserving transformations. We also\nhighlight common failure patterns and design self-repair prompts, improving\nsuccess rates by 25%.\n","authors":["Thanh Le-Cong","Bach Le","Toby Murray"],"pdf_url":"https://arxiv.org/pdf/2503.04779v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10129v1","updated":"2025-03-13T07:39:09Z","published":"2025-03-13T07:39:09Z","title":"Deep Learning-Based Direct Leaf Area Estimation using Two RGBD Datasets\n  for Model Development","summary":"  Estimation of a single leaf area can be a measure of crop growth and a\nphenotypic trait to breed new varieties. It has also been used to measure leaf\narea index and total leaf area. Some studies have used hand-held cameras, image\nprocessing 3D reconstruction and unsupervised learning-based methods to\nestimate the leaf area in plant images. Deep learning works well for object\ndetection and segmentation tasks; however, direct area estimation of objects\nhas not been explored. This work investigates deep learning-based leaf area\nestimation, for RGBD images taken using a mobile camera setup in real-world\nscenarios. A dataset for attached leaves captured with a top angle view and a\ndataset for detached single leaves were collected for model development and\ntesting. First, image processing-based area estimation was tested on manually\nsegmented leaves. Then a Mask R-CNN-based model was investigated, and modified\nto accept RGBD images and to estimate the leaf area. The detached-leaf data set\nwas then mixed with the attached-leaf plant data set to estimate the single\nleaf area for plant images, and another network design with two backbones was\nproposed: one for segmentation and the other for area estimation. Instead of\ntrying all possibilities or random values, an agile approach was used in\nhyperparameter tuning. The final model was cross-validated with 5-folds and\ntested with two unseen datasets: detached and attached leaves. The F1 score\nwith 90% IoA for segmentation result on unseen detached-leaf data was 1.0,\nwhile R-squared of area estimation was 0.81. For unseen plant data\nsegmentation, the F1 score with 90% IoA was 0.59, while the R-squared score was\n0.57. The research suggests using attached leaves with ground truth area to\nimprove the results.\n","authors":["Namal Jayasuriya","Yi Guo","Wen Hu","Oula Ghannoum"],"pdf_url":"https://arxiv.org/pdf/2503.10129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08552v2","updated":"2025-03-13T07:31:10Z","published":"2025-01-15T03:23:06Z","title":"Reinforcement Learning-Enhanced Procedural Generation for Dynamic\n  Narrative-Driven AR Experiences","summary":"  Procedural Content Generation (PCG) is widely used to create scalable and\ndiverse environments in games. However, existing methods, such as the Wave\nFunction Collapse (WFC) algorithm, are often limited to static scenarios and\nlack the adaptability required for dynamic, narrative-driven applications,\nparticularly in augmented reality (AR) games. This paper presents a\nreinforcement learning-enhanced WFC framework designed for mobile AR\nenvironments. By integrating environment-specific rules and dynamic tile weight\nadjustments informed by reinforcement learning (RL), the proposed method\ngenerates maps that are both contextually coherent and responsive to gameplay\nneeds. Comparative evaluations and user studies demonstrate that the framework\nachieves superior map quality and delivers immersive experiences, making it\nwell-suited for narrative-driven AR games. Additionally, the method holds\npromise for broader applications in education, simulation training, and\nimmersive extended reality (XR) experiences, where dynamic and adaptive\nenvironments are critical.\n","authors":["Aniruddha Srinivas Joshi"],"pdf_url":"https://arxiv.org/pdf/2501.08552v2.pdf","comment":"Published in Proceedings of the 20th International Joint Conference\n  on Computer Vision, Imaging and Computer Graphics Theory and Applications -\n  GRAPP 2025\n  https://www.scitepress.org/PublicationsDetail.aspx?ID=LfPv9Lfiya8=&t=1"},{"id":"http://arxiv.org/abs/2503.10105v1","updated":"2025-03-13T07:02:53Z","published":"2025-03-13T07:02:53Z","title":"StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes\n  through Tree-of-Error","summary":"  Evaluating mathematical capabilities is critical for assessing the overall\nperformance of large language models (LLMs). However, existing evaluation\nmethods often focus solely on final answers, resulting in highly inaccurate and\nuninterpretable evaluation outcomes, as well as their failure to assess proof\nor open-ended problems. To address these issues, we propose a novel\nmathematical process evaluation agent based on Tree-of-Error, called\nStepMathAgent. This agent incorporates four internal core operations: logical\nstep segmentation, step scoring, score aggregation and error tree generation,\nalong with four external extension modules: difficulty calibration, simplicity\nevaluation, completeness validation and format assessment. Furthermore, we\nintroduce StepMathBench, a benchmark comprising 1,000 step-divided process\nevaluation instances, derived from 200 high-quality math problems grouped by\nproblem type, subject category and difficulty level. Experiments on\nStepMathBench show that our proposed StepMathAgent outperforms all\nstate-of-the-art methods, demonstrating human-aligned evaluation preferences\nand broad applicability to various scenarios. Our data and code are available\nat https://github.com/SHU-XUN/StepMathAgent.\n","authors":["Shu-Xun Yang","Cunxiang Wang","Yidong Wang","Xiaotao Gu","Minlie Huang","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2503.10105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10095v1","updated":"2025-03-13T06:42:37Z","published":"2025-03-13T06:42:37Z","title":"Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for\n  Mental Health Prediction via Online Text","summary":"  Large Language Models (LLMs) have demonstrated potential in predicting mental\nhealth outcomes from online text, yet traditional classification methods often\nlack interpretability and robustness. This study evaluates structured reasoning\ntechniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and\nTree-of-Thought (ToT)-to improve classification accuracy across multiple mental\nhealth datasets sourced from Reddit. We analyze reasoning-driven prompting\nstrategies, including Zero-shot CoT and Few-shot CoT, using key performance\nmetrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our\nfindings indicate that reasoning-enhanced techniques improve classification\nperformance over direct prediction, particularly in complex cases. Compared to\nbaselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained\ntransformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs\nsuch as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable\ngains on datasets like Dreaddit (+0.52\\% over M-LLM, +0.82\\% over BERT) and\nSDCNL (+4.67\\% over M-LLM, +2.17\\% over BERT). However, performance declines in\nDepression Severity, and CSSRS predictions suggest dataset-specific\nlimitations, likely due to our using a more extensive test set. Among prompting\nstrategies, Few-shot CoT consistently outperforms others, reinforcing the\neffectiveness of reasoning-driven LLMs. Nonetheless, dataset variability\nhighlights challenges in model reliability and interpretability. This study\nprovides a comprehensive benchmark of reasoning-based LLM techniques for mental\nhealth text classification. It offers insights into their potential for\nscalable clinical applications while identifying key challenges for future\nimprovements.\n","authors":["Avinash Patil","Amardeep Kour Gedhu"],"pdf_url":"https://arxiv.org/pdf/2503.10095v1.pdf","comment":"8 pages, 4 Figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.10094v1","updated":"2025-03-13T06:41:26Z","published":"2025-03-13T06:41:26Z","title":"Semantic Synergy: Unlocking Policy Insights and Learning Pathways\n  Through Advanced Skill Mapping","summary":"  This research introduces a comprehensive system based on state-of-the-art\nnatural language processing, semantic embedding, and efficient search\ntechniques for retrieving similarities and thus generating actionable insights\nfrom raw textual information. The system automatically extracts and aggregates\nnormalized competencies from multiple documents (such as policy files and\ncurricula vitae) and creates strong relationships between recognized\ncompetencies, occupation profiles, and related learning courses. To validate\nits performance, we conducted a multi-tier evaluation that included both\nexplicit and implicit skill references in synthetic and real-world documents.\nThe results showed near-human-level accuracy, with F1 scores exceeding 0.95 for\nexplicit skill detection and above 0.93 for implicit mentions. The system\nthereby establishes a sound foundation for supporting in-depth collaboration\nacross the AE4RIA network. The methodology involves a multi-stage pipeline\nbased on extensive preprocessing and data cleaning, semantic embedding and\nsegmentation via SentenceTransformer, and skill extraction using a FAISS-based\nsearch method. The extracted skills are associated with occupation frameworks\n(as formulated in the ESCO ontology) and with learning paths offered through\nthe Sustainable Development Goals Academy. Moreover, interactive visualization\nsoftware, implemented with Dash and Plotly, presents graphs and tables for\nreal-time exploration and informed decision-making by those involved in\npolicymaking, training and learning supply, career transitions, and\nrecruitment. Overall, this system, backed by rigorous validation, offers\npromising prospects for improved policymaking, human resource development, and\nlifelong learning by providing structured and actionable insights from raw,\ncomplex textual information.\n","authors":["Phoebe Koundouri","Conrad Landis","Georgios Feretzakis"],"pdf_url":"https://arxiv.org/pdf/2503.10094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12854v2","updated":"2025-03-13T06:40:44Z","published":"2024-10-10T22:22:05Z","title":"TPO: Aligning Large Language Models with Multi-branch & Multi-step\n  Preference Trees","summary":"  In the domain of complex reasoning tasks, such as mathematical reasoning,\nrecent advancements have proposed the use of Direct Preference Optimization\n(DPO) to suppress output of dispreferred responses, thereby enhancing the\nlong-chain reasoning capabilities of large language models (LLMs). To this end,\nthese studies employed LLMs to generate preference trees via Tree-of-thoughts\n(ToT) and sample the paired preference responses required by the DPO algorithm.\nHowever, the DPO algorithm based on binary preference optimization is unable to\nlearn multiple responses with varying degrees of preference/dispreference that\nprovided by the preference trees, resulting in incomplete preference learning.\nIn this work, we introduce Tree Preference Optimization (TPO), that does not\nsample paired preference responses from the preference tree; instead, it\ndirectly learns from the entire preference tree during the fine-tuning.\nSpecifically, TPO formulates the language model alignment as a Preference List\nRanking problem, where the policy can potentially learn more effectively from a\nranked preference list of responses given the prompt. In addition, to further\nassist LLMs in identifying discriminative steps within long-chain reasoning and\nincrease the relative reward margin in the preference list, TPO utilizes\nAdaptive Step Reward to adjust the reward values of each step in trajectory for\nperforming fine-grained preference optimization. We carry out extensive\nexperiments on mathematical reasoning tasks to evaluate TPO. The experimental\nresults indicate that TPO consistently outperforms DPO across five public large\nlanguage models on four datasets.\n","authors":["Weibin Liao","Xu Chu","Yasha Wang"],"pdf_url":"https://arxiv.org/pdf/2410.12854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.20560v2","updated":"2025-03-13T06:17:58Z","published":"2024-09-30T17:58:18Z","title":"LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and\n  Planning with LM-Driven PDDL Planner","summary":"  Language models (LMs) possess a strong capability to comprehend natural\nlanguage, making them effective in translating human instructions into detailed\nplans for simple robot tasks. Nevertheless, it remains a significant challenge\nto handle long-horizon tasks, especially in subtask identification and\nallocation for cooperative heterogeneous robot teams. To address this issue, we\npropose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel\nmulti-agent task planning framework that achieves state-of-the-art performance\non long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning\ncapability and the traditional heuristic search planner to achieve a high\nsuccess rate and efficiency while demonstrating strong generalization across\ntasks. Additionally, we create MAT-THOR, a comprehensive benchmark that\nfeatures household tasks with two different levels of complexity based on the\nAI2-THOR environment. The experimental results demonstrate that LaMMA-P\nachieves a 105% higher success rate and 36% higher efficiency than existing\nLM-based multiagent planners. The experimental videos, code, datasets, and\ndetailed prompts used in each module can be found on the project website:\nhttps://lamma-p.github.io.\n","authors":["Xiaopan Zhang","Hao Qin","Fuquan Wang","Yue Dong","Jiachen Li"],"pdf_url":"https://arxiv.org/pdf/2409.20560v2.pdf","comment":"IEEE Conference on Robotics and Automation (ICRA 2025); Project\n  website: https://lamma-p.github.io/"},{"id":"http://arxiv.org/abs/2407.20657v2","updated":"2025-03-13T06:16:16Z","published":"2024-07-30T08:52:16Z","title":"Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks","summary":"  Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.\n","authors":["Hunmin Yang","Jongoh Jeong","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2407.20657v2.pdf","comment":"Accepted to ECCV 2024 (Oral), Project Page:\n  https://PDCL-Attack.github.io"},{"id":"http://arxiv.org/abs/2503.08741v2","updated":"2025-03-13T06:15:32Z","published":"2025-03-11T08:25:40Z","title":"Oasis: One Image is All You Need for Multimodal Instruction Data\n  Synthesis","summary":"  The success of multi-modal large language models (MLLMs) has been largely\nattributed to the large-scale training data. However, the training data of many\nMLLMs is unavailable due to privacy concerns. The expensive and labor-intensive\nprocess of collecting multi-modal data further exacerbates the problem. Is it\npossible to synthesize multi-modal training data automatically without\ncompromising diversity and quality? In this paper, we propose a new method,\nOasis, to synthesize high-quality multi-modal data with only images. Oasis\nbreaks through traditional methods by prompting only images to the MLLMs, thus\nextending the data diversity by a large margin. Our method features a delicate\nquality control method which ensures the data quality. We collected over 500k\ndata and conducted incremental experiments on LLaVA-NeXT. Extensive experiments\ndemonstrate that our method can significantly improve the performance of MLLMs.\nThe image-based synthesis also allows us to focus on the specific-domain\nability of MLLMs. Code and data will be publicly available.\n","authors":["Letian Zhang","Quan Cui","Bingchen Zhao","Cheng Yang"],"pdf_url":"https://arxiv.org/pdf/2503.08741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09257v2","updated":"2025-03-13T05:53:58Z","published":"2025-03-12T10:56:02Z","title":"DeepInnovation AI: A Global Dataset Mapping the AI innovation from\n  Academic Research to Industrial Patents","summary":"  In the rapidly evolving field of artificial intelligence (AI), mapping\ninnovation patterns and understanding effective technology transfer from\nresearch to applications are essential for economic growth. However, existing\ndata infrastructures suffer from fragmentation, incomplete coverage, and\ninsufficient evaluative capacity. Here, we present DeepInnovationAI, a\ncomprehensive global dataset containing three structured files.\nDeepPatentAI.csv: Contains 2,356,204 patent records with 8 field-specific\nattributes. DeepDiveAI.csv: Encompasses 3,511,929 academic publications with 13\nmetadata fields. These two datasets leverage large language models,\nmultilingual text analysis and dual-layer BERT classifiers to accurately\nidentify AI-related content, while utilizing hypergraph analysis to create\nrobust innovation metrics. Additionally, DeepCosineAI.csv: By applying semantic\nvector proximity analysis, this file presents approximately one hundred million\ncalculated paper-patent similarity pairs to enhance understanding of how\ntheoretical advancements translate into commercial technologies.\nDeepInnovationAI enables researchers, policymakers, and industry leaders to\nanticipate trends and identify collaboration opportunities. With extensive\ntemporal and geographical scope, it supports detailed analysis of technological\ndevelopment patterns and international competition dynamics, establishing a\nfoundation for modeling AI innovation and technology transfer processes.\n","authors":["Haixing Gong","Hui Zou","Xingzhou Liang","Shiyuan Meng","Pinlong Cai","Xingcheng Xu","Jingjing Qu"],"pdf_url":"https://arxiv.org/pdf/2503.09257v2.pdf","comment":"32 pages and 8 figures"},{"id":"http://arxiv.org/abs/2503.10075v1","updated":"2025-03-13T05:43:49Z","published":"2025-03-13T05:43:49Z","title":"Parallelizing Multi-objective A* Search","summary":"  The Multi-objective Shortest Path (MOSP) problem is a classic network\noptimization problem that aims to find all Pareto-optimal paths between two\npoints in a graph with multiple edge costs. Recent studies on multi-objective\nsearch with A* (MOA*) have demonstrated superior performance in solving\ndifficult MOSP instances. This paper presents a novel search framework that\nallows efficient parallelization of MOA* with different objective orders. The\nframework incorporates a unique upper bounding strategy that helps the search\nreduce the problem's dimensionality to one in certain cases. Experimental\nresults demonstrate that the proposed framework can enhance the performance of\nrecent A*-based solutions, with the speed-up proportional to the problem\ndimension.\n","authors":["Saman Ahmadi","Nathan R. Sturtevant","Andrea Raith","Daniel Harabor","Mahdi Jalili"],"pdf_url":"https://arxiv.org/pdf/2503.10075v1.pdf","comment":"8 page, 2 tables, 2 figures"},{"id":"http://arxiv.org/abs/2503.10071v1","updated":"2025-03-13T05:39:00Z","published":"2025-03-13T05:39:00Z","title":"Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop\n  Framework Using LLM","summary":"  The combination of LLM agents with external tools enables models to solve\ncomplex tasks beyond their knowledge base. Human-designed tools are inflexible\nand restricted to solutions within the scope of pre-existing tools created by\nexperts. To address this problem, we propose ATLASS, an advanced tool learning\nand selection system designed as a closed-loop framework. It enables the LLM to\nsolve problems by dynamically generating external tools on demand. In this\nframework, agents play a crucial role in orchestrating tool selection,\nexecution, and refinement, ensuring adaptive problem-solving capabilities. The\noperation of ATLASS follows three phases: The first phase, Understanding Tool\nRequirements, involves the Agents determining whether tools are required and\nspecifying their functionality; the second phase, Tool Retrieval/Generation,\ninvolves the Agents retrieving or generating tools based on their availability;\nand the third phase, Task Solving, involves combining all the component tools\nnecessary to complete the initial task. The Tool Dataset stores the generated\ntools, ensuring reusability and minimizing inference cost. Current LLM-based\ntool generation systems have difficulty creating complex tools that need APIs\nor external packages. In ATLASS, we solve the problem by automatically setting\nup the environment, fetching relevant API documentation online, and using a\nPython interpreter to create a reliable, versatile tool that works in a wider\nrange of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and\nethical concerns are handled through human feedback before executing generated\ncode. By addressing the limitations of predefined toolsets and enhancing\nadaptability, ATLASS serves as a real-world solution that empowers users with\ndynamically generated tools for complex problem-solving.\n","authors":["Mohd Ariful Haque","Justin Williams","Sunzida Siddique","Md. Hujaifa Islam","Hasmot Ali","Kishor Datta Gupta","Roy George"],"pdf_url":"https://arxiv.org/pdf/2503.10071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10070v1","updated":"2025-03-13T05:34:43Z","published":"2025-03-13T05:34:43Z","title":"AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for\n  Embodied AI","summary":"  Navigation and manipulation in open-world environments remain unsolved\nchallenges in the Embodied AI. The high cost of commercial mobile manipulation\nrobots significantly limits research in real-world scenes. To address this\nissue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile\nmanipulation robot system with a hardware cost of only $1,000 (excluding\noptional computational resources), which is less than 1/15 of the cost of\npopular mobile robots. The AhaRobot system consists of three components: (1) a\nnovel low-cost hardware architecture primarily composed of off-the-shelf\ncomponents, (2) an optimized control solution to enhance operational precision\nintegrating dual-motor backlash control and static friction compensation, and\n(3) a simple remote teleoperation method RoboPilot. We use handles to control\nthe dual arms and pedals for whole-body movement. The teleoperation process is\nlow-burden and easy to operate, much like piloting. RoboPilot is designed for\nremote data collection in embodied scenarios. Experimental results demonstrate\nthat RoboPilot significantly enhances data collection efficiency in complex\nmanipulation tasks, achieving a 30% increase compared to methods using 3D mouse\nand leader-follower systems. It also excels at completing extremely\nlong-horizon tasks in one go. Furthermore, AhaRobot can be used to learn\nend-to-end policies and autonomously perform complex manipulation tasks, such\nas pen insertion and cleaning up the floor. We aim to build an affordable yet\npowerful platform to promote the development of embodied tasks on real devices,\nadvancing more robust and reliable embodied AI. All hardware and software\nsystems are available at https://aha-robot.github.io.\n","authors":["Haiqin Cui","Yifu Yuan","Yan Zheng","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2503.10070v1.pdf","comment":"The first two authors contributed equally. Website:\n  https://aha-robot.github.io"},{"id":"http://arxiv.org/abs/2503.10061v1","updated":"2025-03-13T05:21:22Z","published":"2025-03-13T05:21:22Z","title":"Compute Optimal Scaling of Skills: Knowledge vs Reasoning","summary":"  Scaling laws are a critical component of the LLM development pipeline, most\nfamously as a way to forecast training decisions such as 'compute-optimally'\ntrading-off parameter count and dataset size, alongside a more recent growing\nlist of other crucial decisions. In this work, we ask whether compute-optimal\nscaling behaviour can be skill-dependent. In particular, we examine knowledge\nand reasoning-based skills such as knowledge-based QA and code generation, and\nwe answer this question in the affirmative: $\\textbf{scaling laws are\nskill-dependent}$. Next, to understand whether skill-dependent scaling is an\nartefact of the pretraining datamix, we conduct an extensive ablation of\ndifferent datamixes and find that, also when correcting for datamix\ndifferences, $\\textbf{knowledge and code exhibit fundamental differences in\nscaling behaviour}$. We conclude with an analysis of how our findings relate to\nstandard compute-optimal scaling using a validation set, and find that\n$\\textbf{a misspecified validation set can impact compute-optimal parameter\ncount by nearly 50%,}$ depending on its skill composition.\n","authors":["Nicholas Roberts","Niladri Chatterji","Sharan Narang","Mike Lewis","Dieuwke Hupkes"],"pdf_url":"https://arxiv.org/pdf/2503.10061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10058v1","updated":"2025-03-13T05:19:44Z","published":"2025-03-13T05:19:44Z","title":"Deep Learning Approaches for Anti-Money Laundering on Mobile\n  Transactions: Review, Framework, and Directions","summary":"  Money laundering is a financial crime that obscures the origin of illicit\nfunds, necessitating the development and enforcement of anti-money laundering\n(AML) policies by governments and organizations. The proliferation of mobile\npayment platforms and smart IoT devices has significantly complicated AML\ninvestigations. As payment networks become more interconnected, there is an\nincreasing need for efficient real-time detection to process large volumes of\ntransaction data on heterogeneous payment systems by different operators such\nas digital currencies, cryptocurrencies and account-based payments. Most of\nthese mobile payment networks are supported by connected devices, many of which\nare considered loT devices in the FinTech space that constantly generate data.\nFurthermore, the growing complexity and unpredictability of transaction\npatterns across these networks contribute to a higher incidence of false\npositives. While machine learning solutions have the potential to enhance\ndetection efficiency, their application in AML faces unique challenges, such as\naddressing privacy concerns tied to sensitive financial data and managing the\nreal-world constraint of limited data availability due to data regulations.\nExisting surveys in the AML literature broadly review machine learning\napproaches for money laundering detection, but they often lack an in-depth\nexploration of advanced deep learning techniques - an emerging field with\nsignificant potential. To address this gap, this paper conducts a comprehensive\nreview of deep learning solutions and the challenges associated with their use\nin AML. Additionally, we propose a novel framework that applies the\nleast-privilege principle by integrating machine learning techniques, codifying\nAML red flags, and employing account profiling to provide context for\npredictions and enable effective fraud detection under limited data\navailability....\n","authors":["Jiani Fan","Lwin Khin Shar","Ruichen Zhang","Ziyao Liu","Wenzhuo Yang","Dusit Niyato","Bomin Mao","Kwok-Yan Lam"],"pdf_url":"https://arxiv.org/pdf/2503.10058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10052v1","updated":"2025-03-13T05:09:48Z","published":"2025-03-13T05:09:48Z","title":"DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks","summary":"  Spiking Neural Networks (SNNs) present a more energy-efficient alternative to\nArtificial Neural Networks (ANNs) by harnessing spatio-temporal dynamics and\nevent-driven spikes. Effective utilization of temporal information is crucial\nfor SNNs, leading to the exploration of attention mechanisms to enhance this\ncapability. Conventional attention operations either apply identical operation\nor employ non-identical operations across target dimensions. We identify that\nthese approaches provide distinct perspectives on temporal information. To\nleverage the strengths of both operations, we propose a novel Dual\nTemporal-channel-wise Attention (DTA) mechanism that integrates both\nidentical/non-identical attention strategies. To the best of our knowledge,\nthis is the first attempt to concentrate on both the correlation and dependency\nof temporal-channel using both identical and non-identical attention\noperations. Experimental results demonstrate that the DTA mechanism achieves\nstate-of-the-art performance on both static datasets (CIFAR10, CIFAR100,\nImageNet-1k) and dynamic dataset (CIFAR10-DVS), elevating spike representation\nand capturing complex temporal-channel relationship. We open-source our code:\nhttps://github.com/MnJnKIM/DTA-SNN.\n","authors":["Minje Kim","Minjun Kim","Xu Yang"],"pdf_url":"https://arxiv.org/pdf/2503.10052v1.pdf","comment":"Accepted by IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2503.10040v1","updated":"2025-03-13T04:45:38Z","published":"2025-03-13T04:45:38Z","title":"Rapid analysis of point-contact Andreev reflection spectra via machine\n  learning with adaptive data augmentation","summary":"  Delineating the superconducting order parameters is a pivotal task in\ninvestigating superconductivity for probing pairing mechanisms, as well as\ntheir symmetry and topology. Point-contact Andreev reflection (PCAR)\nmeasurement is a simple yet powerful tool for identifying the order parameters.\nThe PCAR spectra exhibit significant variations depending on the type of the\norder parameter in a superconductor, including its magnitude\n($\\mathit{\\Delta}$), as well as temperature, interfacial quality, Fermi\nvelocity mismatch, and other factors. The information on the order parameter\ncan be obtained by finding the combination of these parameters, generating a\ntheoretical spectrum that fits a measured experimental spectrum. However, due\nto the complexity of the spectra and the high dimensionality of parameters,\nextracting the fitting parameters is often time-consuming and labor-intensive.\nIn this study, we employ a convolutional neural network (CNN) algorithm to\ncreate models for rapid and automated analysis of PCAR spectra of various\nsuperconductors with different pairing symmetries (conventional $s$-wave,\nchiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave). The training datasets are\ngenerated based on the Blonder-Tinkham-Klapwijk (BTK) theory and further\nmodified and augmented by selectively incorporating noise and peaks according\nto the bias voltages. This approach not only replicates the experimental\nspectra but also brings the model's attention to important features within the\nspectra. The optimized models provide fitting parameters for experimentally\nmeasured spectra in less than 100 ms per spectrum. Our approaches and findings\npave the way for rapid and automated spectral analysis which will help\naccelerate research on superconductors with complex order parameters.\n","authors":["Dongik Lee","Valentin Stanev","Xiaohang Zhang","Mijeong Kang","Ichiro Takeuchi","Seunghun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.10040v1.pdf","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.09567v2","updated":"2025-03-13T04:34:15Z","published":"2025-03-12T17:35:03Z","title":"Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning\n  Large Language Models","summary":"  Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"test-time scaling.\" This survey seeks to\nfill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and test-time scaling, offering\ninsights into how these processes manifest in practice. (4) Finally, we\nidentify significant research gaps and highlight promising future directions,\nincluding the integration of multi-modal reasoning, efficiency improvements,\nand enhanced knowledge frameworks. By providing a structured overview, this\nsurvey aims to inspire future research and further the development of logical\nreasoning in artificial intelligence.\n","authors":["Qiguang Chen","Libo Qin","Jinhao Liu","Dengyun Peng","Jiannan Guan","Peng Wang","Mengkang Hu","Yuhang Zhou","Te Gao","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2503.09567v2.pdf","comment":"Paper are available at https://long-cot.github.io/"},{"id":"http://arxiv.org/abs/2503.06529v2","updated":"2025-03-13T04:18:40Z","published":"2025-03-09T09:24:24Z","title":"AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection","summary":"  As object detection becomes integral to many safety-critical applications,\nunderstanding its vulnerabilities is essential. Backdoor attacks, in\nparticular, pose a serious threat by implanting hidden triggers in victim\nmodels, which adversaries can later exploit to induce malicious behaviors\nduring inference. However, current understanding is limited to single-target\nattacks, where adversaries must define a fixed malicious behavior (target)\nbefore training, making inference-time adaptability impossible. Given the large\noutput space of object detection (including object existence prediction,\nbounding box estimation, and classification), the feasibility of flexible,\ninference-time model control remains unexplored. This paper introduces\nAnywhereDoor, a multi-target backdoor attack for object detection. Once\nimplanted, AnywhereDoor allows adversaries to make objects disappear, fabricate\nnew ones, or mislabel them, either across all object classes or specific ones,\noffering an unprecedented degree of control. This flexibility is enabled by\nthree key innovations: (i) objective disentanglement to scale the number of\nsupported targets; (ii) trigger mosaicking to ensure robustness even against\nregion-based detectors; and (iii) strategic batching to address object-level\ndata imbalances that hinder manipulation. Extensive experiments demonstrate\nthat AnywhereDoor grants attackers a high degree of control, improving attack\nsuccess rates by 26% compared to adaptations of existing methods for such\nflexible control.\n","authors":["Jialin Lu","Junjie Shan","Ziqi Zhao","Ka-Ho Chow"],"pdf_url":"https://arxiv.org/pdf/2503.06529v2.pdf","comment":"This work was intended as a replacement of arXiv:2411.14243 and any\n  subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2410.04759v2","updated":"2025-03-13T04:00:16Z","published":"2024-10-07T05:27:22Z","title":"Driving with Regulation: Interpretable Decision-Making for Autonomous\n  Vehicles with Retrieval-Augmented Reasoning via LLM","summary":"  This work presents an interpretable decision-making framework for autonomous\nvehicles that integrates traffic regulations, norms, and safety guidelines\ncomprehensively and enables seamless adaptation to different regions. While\ntraditional rule-based methods struggle to incorporate the full scope of\ntraffic rules, we develop a Traffic Regulation Retrieval (TRR) Agent based on\nRetrieval-Augmented Generation (RAG) to automatically retrieve relevant traffic\nrules and guidelines from extensive regulation documents and relevant records\nbased on the ego vehicle's situation. Given the semantic complexity of the\nretrieved rules, we also design a reasoning module powered by a Large Language\nModel (LLM) to interpret these rules, differentiate between mandatory rules and\nsafety guidelines, and assess actions on legal compliance and safety.\nAdditionally, the reasoning is designed to be interpretable, enhancing both\ntransparency and reliability. The framework demonstrates robust performance on\nboth hypothesized and real-world cases across diverse scenarios, along with the\nability to adapt to different regions with ease.\n","authors":["Tianhui Cai","Yifan Liu","Zewei Zhou","Haoxuan Ma","Seth Z. Zhao","Zhiwen Wu","Jiaqi Ma"],"pdf_url":"https://arxiv.org/pdf/2410.04759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14225v2","updated":"2025-03-13T03:55:17Z","published":"2025-01-24T04:09:03Z","title":"Multi-agent KTO: Reinforcing Strategic Interactions of Large Language\n  Model in Language Game","summary":"  Achieving Artificial General Intelligence (AGI) requires AI agents that can\nnot only make stratigic decisions but also engage in flexible and meaningful\ncommunication. Inspired by Wittgenstein's language game theory in Philosophical\nInvestigations, we propose that language agents can learn through in-context\ninteraction rather than traditional multi-stage frameworks that separate\ndecision-making from language expression. Using Werewolf, a social deduction\ngame that tests language understanding, strategic interaction, and\nadaptability, we develop the Multi-agent Kahneman & Tversky's Optimization\n(MaKTO). MaKTO engages diverse models in extensive gameplay to generate\nunpaired desirable and unacceptable responses, then employs KTO to refine the\nmodel's decision-making process. In 9-player Werewolf games, MaKTO achieves a\n61% average win rate across various models, outperforming GPT-4o and two-stage\nRL agents by relative improvements of 23.0% and 10.9%, respectively. Notably,\nMaKTO also demonstrates human-like performance, winning 60% against expert\nplayers and showing only 49% detectability in Turing-style blind tests.\n","authors":["Rong Ye","Yongxin Zhang","Yikai Zhang","Haoyu Kuang","Zhongyu Wei","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2501.14225v2.pdf","comment":"Preprint. Code and data will be available at\n  https://reneeye.github.io/MaKTO.html"},{"id":"http://arxiv.org/abs/2503.10009v1","updated":"2025-03-13T03:40:50Z","published":"2025-03-13T03:40:50Z","title":"OR-LLM-Agent: Automating Modeling and Solving of Operations Research\n  Optimization Problem with Reasoning Large Language Model","summary":"  Operations Research (OR) has been widely applied in various fields such as\nresource allocation, production planning, and supply chain management. However,\naddressing real-world OR problems requires OR experts to perform mathematical\nmodeling and programmers to develop solution algorithms. This traditional\nmethod, heavily reliant on experts, is costly and has long development cycles,\nseverely limiting the widespread adoption of OR techniques. Few have considered\nusing Artificial Intelligence (AI) to replace professionals to achieve fully\nautomated solutions for OR problems. We propose OR-LLM-Agent, the first AI\nagent that enables end-to-end automation for solving real-world OR problems.\nOR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of\nLarge Language Models (LLMs) to translate natural language problem descriptions\ninto formal mathematical models and automatically generate Gurobi solver code.\nIn OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair\nwithin a sandbox environment, facilitating the derivation of the final\nsolution. Due to the lack of dedicated benchmark datasets for evaluating the\nautomated solving of OR problems, we construct a benchmark dataset comprising\n83 real-world OR problems described in natural language. We conduct comparative\nexperiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,\nDeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the\nhighest pass rate of 100% and the highest solution accuracy of 85%,\ndemonstrating the feasibility of automated OR problem-solving. Data and code\nhave been publicly available at https://github.com/bwz96sco/or_llm_agent.\n","authors":["Bowen Zhang","Pengcheng Luo"],"pdf_url":"https://arxiv.org/pdf/2503.10009v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.04823v2","updated":"2025-03-13T03:39:44Z","published":"2025-03-05T03:42:49Z","title":"DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature\n  Extraction","summary":"  The importance of four-dimensional (4D) trajectory prediction within air\ntraffic management systems is on the rise. Key operations such as conflict\ndetection and resolution, aircraft anomaly monitoring, and the management of\ncongested flight paths are increasingly reliant on this foundational\ntechnology, underscoring the urgent demand for intelligent solutions. The\ndynamics in airport terminal zones and crowded airspaces are intricate and\never-changing; however, current methodologies do not sufficiently account for\nthe interactions among aircraft. To tackle these challenges, we propose\nDA-STGCN, an innovative spatiotemporal graph convolutional network that\nintegrates a dual attention mechanism. Our model reconstructs the adjacency\nmatrix through a self-attention approach, enhancing the capture of node\ncorrelations, and employs graph attention to distill spatiotemporal\ncharacteristics, thereby generating a probabilistic distribution of predicted\ntrajectories. This novel adjacency matrix, reconstructed with the\nself-attention mechanism, is dynamically optimized throughout the network's\ntraining process, offering a more nuanced reflection of the inter-node\nrelationships compared to traditional algorithms. The performance of the model\nis validated on two ADS-B datasets, one near the airport terminal area and the\nother in dense airspace. Experimental results demonstrate a notable improvement\nover current 4D trajectory prediction methods, achieving a 20% and 30%\nreduction in the Average Displacement Error (ADE) and Final Displacement Error\n(FDE), respectively. The incorporation of a Dual-Attention module has been\nshown to significantly enhance the extraction of node correlations, as verified\nby ablation experiments.\n","authors":["Yuheng Kuang","Zhengning Wang","Jianping Zhang","Zhenyu Shi","Yuding Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04823v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.10003v1","updated":"2025-03-13T03:25:29Z","published":"2025-03-13T03:25:29Z","title":"A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the\n  Upper Bound","summary":"  Class-incremental learning (CIL) aims to continuously adapt to emerging\nclasses while retaining knowledge of previously learned ones. Few-shot\nclass-incremental learning (FSCIL) presents an even greater challenge which\nrequires the model to learn incremental classes with only a limited number of\nsamples. In conventional CIL, joint training is widely considered the upper\nbound, serving as both a benchmark and a methodological guide. However, we find\nthat joint training fails to be a meaningful upper bound in FSCIL due to the\ninherent difficulty of inter-task class separation (ICS) caused by severe class\nimbalance. In this work, we introduce a new joint training benchmark tailored\nfor FSCIL by integrating imbalance-aware techniques, effectively bridging the\nperformance gap between base and incremental classes. Furthermore, we point out\ninconsistencies in the experimental setup and evaluation of existing FSCIL\nmethods. To ensure fair comparisons between different FSCIL approaches and\njoint training, we standardize training conditions and propose a unified\nevaluation protocol that simultaneously considers the validation set and\ncomputational complexity. By establishing a reliable upper bound and a\nstandardized evaluation framework for FSCIL, our work provides a clear\nbenchmark and a practical foundation for future research.\n","authors":["Shiwon Kim","Dongjun Hwang","Sungwon Woo","Rita Singh"],"pdf_url":"https://arxiv.org/pdf/2503.10003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16833v3","updated":"2025-03-13T03:05:30Z","published":"2024-12-22T02:40:59Z","title":"KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge\n  Graph Enhancement for Medical Diagnosis","summary":"  Integrating Large Language Models (LLMs) in healthcare diagnosis demands\nsystematic frameworks that can handle complex medical scenarios while\nmaintaining specialized expertise. We present KG4Diagnosis, a novel\nhierarchical multi-agent framework that combines LLMs with automated knowledge\ngraph construction, encompassing 362 common diseases across medical\nspecialties. Our framework mirrors real-world medical systems through a\ntwo-tier architecture: a general practitioner (GP) agent for initial assessment\nand triage, coordinating with specialized agents for in-depth diagnosis in\nspecific domains. The core innovation lies in our end-to-end knowledge graph\ngeneration methodology, incorporating: (1) semantic-driven entity and relation\nextraction optimized for medical terminology, (2) multi-dimensional decision\nrelationship reconstruction from unstructured medical texts, and (3)\nhuman-guided reasoning for knowledge expansion. KG4Diagnosis serves as an\nextensible foundation for specialized medical diagnosis systems, with\ncapabilities to incorporate new diseases and medical knowledge. The framework's\nmodular design enables seamless integration of domain-specific enhancements,\nmaking it valuable for developing targeted medical diagnosis systems. We\nprovide architectural guidelines and protocols to facilitate adoption across\nmedical contexts.\n","authors":["Kaiwen Zuo","Yirui Jiang","Fan Mo","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2412.16833v3.pdf","comment":"10 pages,5 figures,published to AAAI-25 Bridge Program"},{"id":"http://arxiv.org/abs/2503.09988v1","updated":"2025-03-13T02:55:06Z","published":"2025-03-13T02:55:06Z","title":"Label Unbalance in High-frequency Trading","summary":"  In financial trading, return prediction is one of the foundation for a\nsuccessful trading system. By the fast development of the deep learning in\nvarious areas such as graphical processing, natural language, it has also\ndemonstrate significant edge in handling with financial data. While the success\nof the deep learning relies on huge amount of labeled sample, labeling each\ntime/event as profitable or unprofitable, under the transaction cost,\nespecially in the high-frequency trading world, suffers from serious label\nimbalance issue.In this paper, we adopts rigurious end-to-end deep learning\nframework with comprehensive label imbalance adjustment methods and succeed in\npredicting in high-frequency return in the Chinese future market. The code for\nour method is publicly available at\nhttps://github.com/RS2002/Label-Unbalance-in-High-Frequency-Trading .\n","authors":["Zijian Zhao","Xuming Chen","Jiayu Wen","Mingwen Liu","Xiaoteng Ma"],"pdf_url":"https://arxiv.org/pdf/2503.09988v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2411.14871v3","updated":"2025-03-13T02:36:28Z","published":"2024-11-22T11:45:33Z","title":"Preference Alignment for Diffusion Model via Explicit Denoised\n  Distribution Estimation","summary":"  Diffusion models have shown remarkable success in text-to-image generation,\nmaking preference alignment for these models increasingly important. The\npreference labels are typically available only at the terminal of denoising\ntrajectories, which poses challenges in optimizing the intermediate denoising\nsteps. In this paper, we propose to conduct Denoised Distribution Estimation\n(DDE) that explicitly connects intermediate steps to the terminal denoised\ndistribution. Therefore, preference labels can be used for the entire\ntrajectory optimization. To this end, we design two estimation strategies for\nour DDE. The first is stepwise estimation, which utilizes the conditional\ndenoised distribution to estimate the model denoised distribution. The second\nis single-shot estimation, which converts the model output into the terminal\ndenoised distribution via DDIM modeling. Analytically and empirically, we\nreveal that DDE equipped with two estimation strategies naturally derives a\nnovel credit assignment scheme that prioritizes optimizing the middle part of\nthe denoising trajectory. Extensive experiments demonstrate that our approach\nachieves superior performance, both quantitatively and qualitatively.\n","authors":["Dingyuan Shi","Yong Wang","Hangyu Li","Xiangxiang Chu"],"pdf_url":"https://arxiv.org/pdf/2411.14871v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18947v3","updated":"2025-03-13T02:29:47Z","published":"2024-12-25T16:51:29Z","title":"MedHallBench: A New Benchmark for Assessing Hallucination in Medical\n  Large Language Models","summary":"  Medical Large Language Models (MLLMs) have demonstrated potential in\nhealthcare applications, yet their propensity for hallucinations -- generating\nmedically implausible or inaccurate information -- presents substantial risks\nto patient care. This paper introduces MedHallBench, a comprehensive benchmark\nframework for evaluating and mitigating hallucinations in MLLMs. Our\nmethodology integrates expert-validated medical case scenarios with established\nmedical databases to create a robust evaluation dataset. The framework employs\na sophisticated measurement system that combines automated ACHMI (Automatic\nCaption Hallucination Measurement in Medical Imaging) scoring with rigorous\nclinical expert evaluations and utilizes reinforcement learning methods to\nachieve automatic annotation. Through an optimized reinforcement learning from\nhuman feedback (RLHF) training pipeline specifically designed for medical\napplications, MedHallBench enables thorough evaluation of MLLMs across diverse\nclinical contexts while maintaining stringent accuracy standards. We conducted\ncomparative experiments involving various models, utilizing the benchmark to\nestablish a baseline for widely adopted large language models (LLMs). Our\nfindings indicate that ACHMI provides a more nuanced understanding of the\neffects of hallucinations compared to traditional metrics, thereby highlighting\nits advantages in hallucination assessment. This research establishes a\nfoundational framework for enhancing MLLMs' reliability in healthcare settings\nand presents actionable strategies for addressing the critical challenge of AI\nhallucinations in medical applications.\n","authors":["Kaiwen Zuo","Yirui Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.18947v3.pdf","comment":"Published to AAAI-25 Bridge Program"},{"id":"http://arxiv.org/abs/2503.09974v1","updated":"2025-03-13T02:21:04Z","published":"2025-03-13T02:21:04Z","title":"Uncertainty-aware Long-tailed Weights Model the Utility of Pseudo-labels\n  for Semi-supervised Learning","summary":"  Current Semi-supervised Learning (SSL) adopts the pseudo-labeling strategy\nand further filters pseudo-labels based on confidence thresholds. However, this\nmechanism has notable drawbacks: 1) setting the reasonable threshold is an open\nproblem which significantly influences the selection of the high-quality\npseudo-labels; and 2) deep models often exhibit the over-confidence phenomenon\nwhich makes the confidence value an unreliable indicator for assessing the\nquality of pseudo-labels due to the scarcity of labeled data. In this paper, we\npropose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of\npseudo-labels for unlabeled samples. We further model the utility of\npseudo-labels as long-tailed weights to avoid the open problem of setting the\nthreshold. Concretely, the advantage of the long-tailed weights ensures that\neven unreliable pseudo-labels still contribute to enhancing the model's\nrobustness. Besides, UES is lightweight and architecture-agnostic, easily\nextending to various computer vision tasks, including classification and\nregression. Experimental results demonstrate that combining the proposed method\nwith DualPose leads to a 3.47% improvement in Percentage of Correct Keypoints\n(PCK) on the Sniffing dataset with 100 data points (30 labeled), a 7.29\\%\nimprovement in PCK on the FLIC dataset with 100 data points (50 labeled), and a\n3.91% improvement in PCK on the LSP dataset with 200 data points (100 labeled).\nFurthermore, when combined with FixMatch, the proposed method achieves a 0.2%\naccuracy improvement on the CIFAR-10 dataset with 40 labeled data points and a\n0.26% accuracy improvement on the CIFAR-100 dataset with 400 labeled data\npoints.\n","authors":["Jiaqi Wu","Junbiao Pang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2503.09974v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2408.04150"},{"id":"http://arxiv.org/abs/2503.09969v1","updated":"2025-03-13T02:16:48Z","published":"2025-03-13T02:16:48Z","title":"Detecting Dataset Bias in Medical AI: A Generalized and\n  Modality-Agnostic Auditing Framework","summary":"  Data-driven AI is establishing itself at the center of evidence-based\nmedicine. However, reports of shortcomings and unexpected behavior are growing\ndue to AI's reliance on association-based learning. A major reason for this\nbehavior: latent bias in machine learning datasets can be amplified during\ntraining and/or hidden during testing. We present a data modality-agnostic\nauditing framework for generating targeted hypotheses about sources of bias\nwhich we refer to as Generalized Attribute Utility and Detectability-Induced\nbias Testing (G-AUDIT) for datasets. Our method examines the relationship\nbetween task-level annotations and data properties including protected\nattributes (e.g., race, age, sex) and environment and acquisition\ncharacteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically\nquantifies the extent to which the observed data attributes may enable shortcut\nlearning, or in the case of testing data, hide predictions made based on\nspurious associations. We demonstrate the broad applicability and value of our\nmethod by analyzing large-scale medical datasets for three distinct modalities\nand learning tasks: skin lesion classification in images, stigmatizing language\nclassification in Electronic Health Records (EHR), and mortality prediction for\nICU tabular data. In each setting, G-AUDIT successfully identifies subtle\nbiases commonly overlooked by traditional qualitative methods that focus\nprimarily on social and ethical objectives, underscoring its practical value in\nexposing dataset-level risks and supporting the downstream development of\nreliable AI systems. Our method paves the way for achieving deeper\nunderstanding of machine learning datasets throughout the AI development\nlife-cycle from initial prototyping all the way to regulation, and creates\nopportunities to reduce model bias, enabling safer and more trustworthy AI\nsystems.\n","authors":["Nathan Drenkow","Mitchell Pavlak","Keith Harrigian","Ayah Zirikly","Adarsh Subbaswamy","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2503.09969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19105v3","updated":"2025-03-13T02:16:15Z","published":"2024-10-24T19:13:13Z","title":"Conditional diffusions for amortized neural posterior estimation","summary":"  Neural posterior estimation (NPE), a simulation-based computational approach\nfor Bayesian inference, has shown great success in approximating complex\nposterior distributions. Existing NPE methods typically rely on normalizing\nflows, which approximate a distribution by composing many simple, invertible\ntransformations. But flow-based models, while state of the art for NPE, are\nknown to suffer from several limitations, including training instability and\nsharp trade-offs between representational power and computational cost. In this\nwork, we demonstrate the effectiveness of conditional diffusions coupled with\nhigh-capacity summary networks for amortized NPE. Conditional diffusions\naddress many of the challenges faced by flow-based methods. Our results show\nthat, across a highly varied suite of benchmarking problems for NPE\narchitectures, diffusions offer improved stability, superior accuracy, and\nfaster training times, even with simpler, shallower models. Building on prior\nwork on diffusions for NPE, we show that these gains persist across a variety\nof different summary network architectures. Code is available at\nhttps://github.com/TianyuCodings/cDiff.\n","authors":["Tianyu Chen","Vansh Bansal","James G. Scott"],"pdf_url":"https://arxiv.org/pdf/2410.19105v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09960v1","updated":"2025-03-13T02:07:14Z","published":"2025-03-13T02:07:14Z","title":"Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine\n  Learning Techniques","summary":"  Fire safety practices are important to reduce the extent of destruction\ncaused by fire. While smoke alarms help save lives, firefighters struggle with\nthe increasing number of false alarms. This paper presents a precise and\nefficient Weighted ensemble model for decreasing false alarms. It estimates the\ndensity, computes weights according to the high and low-density regions,\nforwards the high region weights to KNN and low region weights to XGBoost and\ncombines the predictions. The proposed model is effective at reducing response\ntime, increasing fire safety, and minimizing the damage that fires cause. A\nspecifically designed dataset for smoke detection is utilized to test the\nproposed model. In addition, a variety of ML models, such as Logistic\nRegression (LR), Decision Tree (DT), Random Forest (RF), Nai:ve Bayes (NB),\nK-Nearest Neighbour (KNN), Support Vector Machine (SVM), Extreme Gradient\nBoosting (XGBoost), Adaptive Boosting (ADAB), have also been utilized. To\nmaximize the use of the smoke detection dataset, all the algorithms utilize the\nSMOTE re-sampling technique. After evaluating the assessment criteria, this\npaper presents a concise summary of the comprehensive findings obtained by\ncomparing the outcomes of all models.\n","authors":["Muhammad Hassan Jamal","Abdulwahab Alazeb","Shahid Allah Bakhsh","Wadii Boulila","Syed Aziz Shah","Aizaz Ahmad Khattak","Muhammad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2503.09960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06571v2","updated":"2025-03-13T02:01:30Z","published":"2025-03-09T11:58:03Z","title":"SHIP: A Shapelet-based Approach for Interpretable Patient-Ventilator\n  Asynchrony Detection","summary":"  Patient-ventilator asynchrony (PVA) is a common and critical issue during\nmechanical ventilation, affecting up to 85% of patients. PVA can result in\nclinical complications such as discomfort, sleep disruption, and potentially\nmore severe conditions like ventilator-induced lung injury and diaphragm\ndysfunction. Traditional PVA management, which relies on manual adjustments by\nhealthcare providers, is often inadequate due to delays and errors. While\nvarious computational methods, including rule-based, statistical, and deep\nlearning approaches, have been developed to detect PVA events, they face\nchallenges related to dataset imbalances and lack of interpretability. In this\nwork, we propose a shapelet-based approach SHIP for PVA detection, utilizing\nshapelets - discriminative subsequences in time-series data - to enhance\ndetection accuracy and interpretability. Our method addresses dataset\nimbalances through shapelet-based data augmentation and constructs a shapelet\npool to transform the dataset for more effective classification. The combined\nshapelet and statistical features are then used in a classifier to identify PVA\nevents. Experimental results on medical datasets show that SHIP significantly\nimproves PVA detection while providing interpretable insights into model\ndecisions.\n","authors":["Xuan-May Le","Ling Luo","Uwe Aickelin","Minh-Tuan Tran","David Berlowitz","Mark Howard"],"pdf_url":"https://arxiv.org/pdf/2503.06571v2.pdf","comment":"Accepted at PAKDD 2025"},{"id":"http://arxiv.org/abs/2503.09956v1","updated":"2025-03-13T01:59:11Z","published":"2025-03-13T01:59:11Z","title":"Exploring Mutual Empowerment Between Wireless Networks and RL-based\n  LLMs: A Survey","summary":"  Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have gained significant attention for their\nexceptional capabilities in natural language processing and multimodal data\nunderstanding. Meanwhile, the rapid expansion of information services has\ndriven the growing need for intelligence, efficient, and adaptable wireless\nnetworks. Wireless networks require the empowerment of RL-based LLMs while\nthese models also benefit from wireless networks to broaden their application\nscenarios. Specifically, RL-based LLMs can enhance wireless communication\nsystems through intelligent resource allocation, adaptive network optimization,\nand real-time decision-making. Conversely, wireless networks provide a vital\ninfrastructure for the efficient training, deployment, and distributed\ninference of RL-based LLMs, especially in decentralized and edge computing\nenvironments. This mutual empowerment highlights the need for a deeper\nexploration of the interplay between these two domains. We first review recent\nadvancements in wireless communications, highlighting the associated challenges\nand potential solutions. We then discuss the progress of RL-based LLMs,\nfocusing on key technologies for LLM training, challenges, and potential\nsolutions. Subsequently, we explore the mutual empowerment between these two\nfields, highlighting key motivations, open challenges, and potential solutions.\nFinally, we provide insights into future directions, applications, and their\nsocietal impact to further explore this intersection, paving the way for\nnext-generation intelligent communication systems. Overall, this survey\nprovides a comprehensive overview of the relationship between RL-based LLMs and\nwireless networks, offering a vision where these domains empower each other to\ndrive innovations.\n","authors":["Yu Qiao","Phuong-Nam Tran","Ji Su Yoon","Loc X. Nguyen","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2503.09956v1.pdf","comment":"25 pages, 13 figures"},{"id":"http://arxiv.org/abs/2503.09950v1","updated":"2025-03-13T01:53:05Z","published":"2025-03-13T01:53:05Z","title":"MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via\n  Implicit Maximum Likelihood Estimation based Distillation","summary":"  In this paper, we address the problem of human trajectory forecasting, which\naims to predict the inherently multi-modal future movements of humans based on\ntheir past trajectories and other contextual cues. We propose a novel motion\nprediction conditional flow matching model, termed MoFlow, to predict K-shot\nfuture trajectories for all agents in a given scene. We design a novel flow\nmatching loss function that not only ensures at least one of the $K$ sets of\nfuture trajectories is accurate but also encourages all $K$ sets of future\ntrajectories to be diverse and plausible. Furthermore, by leveraging the\nimplicit maximum likelihood estimation (IMLE), we propose a novel distillation\nmethod for flow models that only requires samples from the teacher model.\nExtensive experiments on the real-world datasets, including SportVU NBA games,\nETH-UCY, and SDD, demonstrate that both our teacher flow model and the\nIMLE-distilled student model achieve state-of-the-art performance. These models\ncan generate diverse trajectories that are physically and socially plausible.\nMoreover, our one-step student model is $\\textbf{100}$ times faster than the\nteacher flow model during sampling. The code, model, and data are available at\nour project page: https://moflow-imle.github.io\n","authors":["Yuxiang Fu","Qi Yan","Lele Wang","Ke Li","Renjie Liao"],"pdf_url":"https://arxiv.org/pdf/2503.09950v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.09947v1","updated":"2025-03-13T01:50:50Z","published":"2025-03-13T01:50:50Z","title":"Identifying Trustworthiness Challenges in Deep Learning Models for\n  Continental-Scale Water Quality Prediction","summary":"  Water quality is foundational to environmental sustainability, ecosystem\nresilience, and public health. Deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, offer transformative potential for\nlarge-scale water quality prediction and scientific insights generation.\nHowever, their widespread adoption in high-stakes decision-making, such as\npollution mitigation and equitable resource allocation, is prevented by\nunresolved trustworthiness challenges including fairness, uncertainty,\ninterpretability, robustness, generalizability, and reproducibility. In this\nwork, we present the first comprehensive evaluation of trustworthiness in a\ncontinental-scale multi-task LSTM model predicting 20 water quality variables\n(encompassing physical/chemical processes, geochemical weathering, and nutrient\ncycling) across 482 U.S. basins. Our investigation uncovers systematic patterns\nof model performance disparities linked to basin characteristics, the inherent\ncomplexity of biogeochemical processes, and variable predictability,\nemphasizing critical performance fairness concerns. We further propose\nmethodological frameworks for quantitatively evaluating critical aspects of\ntrustworthiness, including uncertainty, interpretability, and robustness,\nidentifying key limitations that could challenge reliable real-world\ndeployment. This work serves as a timely call to action for advancing\ntrustworthy data-driven methods for water resources management and provides a\npathway to offering critical insights for researchers, decision-makers, and\npractitioners seeking to leverage artificial intelligence (AI) responsibly in\nenvironmental management.\n","authors":["Xiaobo Xia","Xiaofeng Liu","Jiale Liu","Kuai Fang","Lu Lu","Samet Oymak","William S. Currie","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.09947v1.pdf","comment":"33 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2503.02597v2","updated":"2025-03-13T01:48:08Z","published":"2025-03-04T13:18:33Z","title":"Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual\n  Attention for Multimodal LLMs","summary":"  Recent Multimodal Large Language Models (MLLMs) have demonstrated significant\nprogress in perceiving and reasoning over multimodal inquiries, ushering in a\nnew research era for foundation models. However, vision-language misalignment\nin MLLMs has emerged as a critical challenge, where the textual responses\ngenerated by these models are not factually aligned with the given text-image\ninputs. Existing efforts to address vision-language misalignment have focused\non developing specialized vision-language connectors or leveraging visual\ninstruction tuning from diverse domains. In this paper, we tackle this issue\nfrom a fundamental yet unexplored perspective by revisiting the core\narchitecture of MLLMs. Most MLLMs are typically built on decoder-only LLMs\nconsisting of a causal attention mechanism, which limits the ability of the\nearlier modalities (e.g., images) to incorporate information from the latter\nmodalities (e.g., text). To address this problem, we propose \\MapleLeaf AKI, a\nnovel MLLM that unlocks causal attention into modality-mutual attention (MMA)\nto enable image tokens to attend to text tokens. This simple yet effective\ndesign allows AKI to achieve superior performance in 12 multimodal\nunderstanding benchmarks (+7.2% on average) without introducing additional\nparameters and increasing training time. Our MMA design is intended to be\ngeneric, allowing for application across various modalities, and scalable to\naccommodate diverse multimodal scenarios. The code and model are publicly\navailable at https://github.com/sony/aki to encourage further advancements in\nMLLMs across various directions.\n","authors":["Wei-Yao Wang","Zhao Wang","Helen Suzuki","Yoshiyuki Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2503.02597v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.09941v1","updated":"2025-03-13T01:35:04Z","published":"2025-03-13T01:35:04Z","title":"TGP: Two-modal occupancy prediction with 3D Gaussian and sparse points\n  for 3D Environment Awareness","summary":"  3D semantic occupancy has rapidly become a research focus in the fields of\nrobotics and autonomous driving environment perception due to its ability to\nprovide more realistic geometric perception and its closer integration with\ndownstream tasks. By performing occupancy prediction of the 3D space in the\nenvironment, the ability and robustness of scene understanding can be\neffectively improved. However, existing occupancy prediction tasks are\nprimarily modeled using voxel or point cloud-based approaches: voxel-based\nnetwork structures often suffer from the loss of spatial information due to the\nvoxelization process, while point cloud-based methods, although better at\nretaining spatial location information, face limitations in representing\nvolumetric structural details. To address this issue, we propose a dual-modal\nprediction method based on 3D Gaussian sets and sparse points, which balances\nboth spatial location and volumetric structural information, achieving higher\naccuracy in semantic occupancy prediction. Specifically, our method adopts a\nTransformer-based architecture, taking 3D Gaussian sets, sparse points, and\nqueries as inputs. Through the multi-layer structure of the Transformer, the\nenhanced queries and 3D Gaussian sets jointly contribute to the semantic\noccupancy prediction, and an adaptive fusion mechanism integrates the semantic\noutputs of both modalities to generate the final prediction results.\nAdditionally, to further improve accuracy, we dynamically refine the point\ncloud at each layer, allowing for more precise location information during\noccupancy prediction. We conducted experiments on the Occ3DnuScenes dataset,\nand the experimental results demonstrate superior performance of the proposed\nmethod on IoU based metrics.\n","authors":["Mu Chen","Wenyu Chen","Mingchuan Yang","Yuan Zhang","Tao Han","Xinchi Li","Yunlong Li","Huaici Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.09941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23530v2","updated":"2025-03-13T01:33:51Z","published":"2024-10-31T00:30:35Z","title":"There and Back Again: On the relation between Noise and Image Inversions\n  in Diffusion Models","summary":"  Diffusion Models achieve state-of-the-art performance in generating new\nsamples but lack low-dimensional latent space that encodes the data into\nmeaningful features. Inversion-based techniques try to solve this issue by\nreversing the denoising process and mapping images back to their approximated\nstarting noise. In this work, we thoroughly analyze this procedure and focus on\nthe relation between the initial Gaussian noise, the generated samples, and\ntheir corresponding latent encodings obtained through the DDIM inversion.\nFirst, we show that latents exhibit structural patterns in the form of less\ndiverse noise predicted for smooth image regions. Next, we explain the origin\nof this phenomenon, demonstrating that, during the first inversion steps, the\nnoise prediction error is much more significant for the plain areas than for\nthe rest of the image. Finally, we present the consequences of the divergence\nbetween latents and noises by showing that the space of image inversions is\nnotably less manipulative than the original Gaussian noise. This leads to a low\ndiversity of generated interpolations or editions based on the DDIM inversion\nprocedure and ill-defined latent-to-image mapping. Code is available at\nhttps://github.com/luk-st/taba.\n","authors":["Łukasz Staniszewski","Łukasz Kuciński","Kamil Deja"],"pdf_url":"https://arxiv.org/pdf/2410.23530v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05536v3","updated":"2025-03-13T00:58:05Z","published":"2024-10-07T22:25:37Z","title":"Accelerating Flood Warnings by 10 Hours: The Power of River Network\n  Topology in AI-enhanced Flood Forecasting","summary":"  Climate change-driven floods demand advanced forecasting models, yet Graph\nNeural Networks (GNNs) underutilize river network topology due to tree-like\nstructures causing over-squashing from high node resistance distances. This\nstudy identifies this limitation and introduces a reachability-based graph\ntransformation to densify topological connections, reducing resistance\ndistances. Empirical tests show transformed-GNNs outperform EA-LSTM in extreme\nflood prediction, achieving 24-h water level accuracy equivalent to EA-LSTM's\n14-h forecasts - a 71% improvement in long-term predictive horizon. The dense\ngraph retains flow dynamics across hierarchical river branches, enabling GNNs\nto capture distal node interactions critical for rare flood events. This\ntopological innovation bridges the gap between river network structure and GNN\nmodeling, offering a scalable framework for early warning systems.\n","authors":["Hongjun Wang","Jiyuan Chen","Yinqiang Zheng","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2410.05536v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09927v1","updated":"2025-03-13T00:48:48Z","published":"2025-03-13T00:48:48Z","title":"Developing and Evaluating an AI-Assisted Prediction Model for Unplanned\n  Intensive Care Admissions following Elective Neurosurgery using Natural\n  Language Processing within an Electronic Healthcare Record System","summary":"  Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.\n","authors":["Julia Ive","Olatomiwa Olukoya","Jonathan P. Funnell","James Booker","Sze H M Lam","Ugan Reddy","Kawsar Noor","Richard JB Dobson","Astri M. V. Luoma","Hani J Marcus"],"pdf_url":"https://arxiv.org/pdf/2503.09927v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02249v2","updated":"2025-03-13T00:22:34Z","published":"2024-03-04T17:34:59Z","title":"Non-autoregressive Sequence-to-Sequence Vision-Language Models","summary":"  Sequence-to-sequence vision-language models are showing promise, but their\napplicability is limited by their inference latency due to their autoregressive\nway of generating predictions. We propose a parallel decoding\nsequence-to-sequence vision-language model, trained with a Query-CTC loss, that\nmarginalizes over multiple inference paths in the decoder. This allows us to\nmodel the joint distribution of tokens, rather than restricting to conditional\ndistribution as in an autoregressive model. The resulting model, NARVL,\nachieves performance on-par with its state-of-the-art autoregressive\ncounterpart, but is faster at inference time, reducing from the linear\ncomplexity associated with the sequential generation of tokens to a paradigm of\nconstant time joint inference.\n","authors":["Kunyu Shi","Qi Dong","Luis Goncalves","Zhuowen Tu","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2403.02249v2.pdf","comment":"Accepted to CVPR 2024"},{"id":"http://arxiv.org/abs/2503.05336v3","updated":"2025-03-13T00:09:08Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Inioluwa Deborah Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v3.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2503.09910v1","updated":"2025-03-13T00:01:36Z","published":"2025-03-13T00:01:36Z","title":"eXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks","summary":"  Constraining deep neural networks (DNNs) to learn individual logic types per\nnode, as performed using the DiffLogic network architecture, opens the door to\nmodel-specific explanation techniques that quell the complexity inherent to\nDNNs. Inspired by principles of circuit analysis from computer engineering,\nthis work presents an algorithm (eXpLogic) for producing saliency maps which\nexplain input patterns that activate certain functions. The eXpLogic\nexplanations: (1) show the exact set of inputs responsible for a decision,\nwhich helps interpret false negative and false positive predictions, (2)\nhighlight common input patterns that activate certain outputs, and (3) help\nreduce the network size to improve class-specific inference. To evaluate the\neXpLogic saliency map, we introduce a metric that quantifies how much an input\nchanges before switching a model's class prediction (the SwitchDist) and use\nthis metric to compare eXpLogic against the Vanilla Gradients (VG) and\nIntegrated Gradient (IG) methods. Generally, we show that eXpLogic saliency\nmaps are better at predicting which inputs will change the class score. These\nmaps help reduce the network size and inference times by 87\\% and 8\\%,\nrespectively, while having a limited impact (-3.8\\%) on class-specific\npredictions. The broader value of this work to machine learning is in\ndemonstrating how certain DNN architectures promote explainability, which is\nrelevant to healthcare, defense, and law.\n","authors":["Stephen Wormald","David Koblah","Matheus Kunzler Maldaner","Domenic Forte","Damon L. Woodard"],"pdf_url":"https://arxiv.org/pdf/2503.09910v1.pdf","comment":"Conference submission, 6 pages, 2 figures"}]}}